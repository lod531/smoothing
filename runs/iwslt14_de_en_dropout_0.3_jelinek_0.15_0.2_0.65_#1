Sender: LSF System <lsfadmin@eu-g3-059>
Subject: Job 210595604: <iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:38:16 2022
Job was executed on host(s) <eu-g3-059>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:38:28 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:38:28 2022
Terminated at Wed Mar 23 12:46:01 2022
Results reported at Wed Mar 23 12:46:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.15,0.2,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4044.97 sec.
    Max Memory :                                 5339 MB
    Average Memory :                             4137.11 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14661.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4052 sec.
    Turnaround time :                            4065 sec.

The output (if any) follows:

2022-03-23 11:38:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.15,0.2,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.15,0.2,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:38:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:38:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:38:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:38:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:38:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1090/160239 [00:00<00:14, 10893.70it/s]  1%|▏         | 2394/160239 [00:00<00:12, 12153.77it/s]  2%|▏         | 3721/160239 [00:00<00:12, 12658.93it/s]  3%|▎         | 5051/160239 [00:00<00:12, 12910.93it/s]  4%|▍         | 6343/160239 [00:00<00:12, 12716.97it/s]  5%|▍         | 7616/160239 [00:00<00:12, 12651.20it/s]  6%|▌         | 8882/160239 [00:00<00:12, 12417.93it/s]  6%|▋         | 10194/160239 [00:00<00:11, 12634.53it/s]  7%|▋         | 11508/160239 [00:00<00:11, 12789.56it/s]  8%|▊         | 12788/160239 [00:01<00:11, 12715.77it/s]  9%|▉         | 14061/160239 [00:01<00:11, 12688.59it/s] 10%|▉         | 15331/160239 [00:01<00:11, 12544.29it/s] 10%|█         | 16586/160239 [00:01<00:11, 12208.98it/s] 11%|█         | 17818/160239 [00:01<00:11, 12241.17it/s] 12%|█▏        | 19062/160239 [00:01<00:11, 12297.92it/s] 13%|█▎        | 20453/160239 [00:01<00:10, 12774.14it/s] 14%|█▎        | 21732/160239 [00:01<00:11, 12447.58it/s] 14%|█▍        | 22980/160239 [00:01<00:11, 12369.77it/s] 15%|█▌        | 24230/160239 [00:01<00:10, 12404.29it/s] 16%|█▌        | 25512/160239 [00:02<00:10, 12525.17it/s] 17%|█▋        | 26766/160239 [00:02<00:10, 12300.76it/s] 18%|█▊        | 28107/160239 [00:02<00:10, 12625.50it/s] 18%|█▊        | 29372/160239 [00:02<00:10, 12534.08it/s] 19%|█▉        | 30627/160239 [00:02<00:10, 12045.19it/s] 20%|█▉        | 31997/160239 [00:02<00:10, 12519.85it/s] 21%|██        | 33254/160239 [00:02<00:10, 12318.03it/s] 22%|██▏       | 34490/160239 [00:02<00:10, 12212.17it/s] 22%|██▏       | 35714/160239 [00:02<00:10, 12017.89it/s] 23%|██▎       | 36973/160239 [00:02<00:10, 12182.29it/s] 24%|██▍       | 38257/160239 [00:03<00:09, 12373.62it/s] 25%|██▍       | 39497/160239 [00:03<00:09, 12322.86it/s] 25%|██▌       | 40805/160239 [00:03<00:09, 12545.11it/s] 26%|██▌       | 42061/160239 [00:03<00:09, 12321.20it/s] 27%|██▋       | 43295/160239 [00:03<00:09, 12009.62it/s] 28%|██▊       | 44499/160239 [00:03<00:09, 11755.42it/s] 29%|██▊       | 45871/160239 [00:03<00:09, 12320.86it/s] 29%|██▉       | 47107/160239 [00:03<00:09, 12308.03it/s] 30%|███       | 48366/160239 [00:03<00:09, 12387.91it/s] 31%|███       | 49607/160239 [00:04<00:08, 12378.67it/s] 32%|███▏      | 50873/160239 [00:04<00:08, 12460.58it/s] 33%|███▎      | 52121/160239 [00:04<00:08, 12442.98it/s] 33%|███▎      | 53382/160239 [00:04<00:08, 12491.43it/s] 34%|███▍      | 54632/160239 [00:04<00:08, 12274.96it/s] 35%|███▍      | 55883/160239 [00:04<00:08, 12343.23it/s] 36%|███▌      | 57180/160239 [00:04<00:08, 12523.90it/s] 37%|███▋      | 58508/160239 [00:04<00:07, 12746.20it/s] 37%|███▋      | 59788/160239 [00:04<00:07, 12758.43it/s] 38%|███▊      | 61065/160239 [00:04<00:07, 12547.54it/s] 39%|███▉      | 62363/160239 [00:05<00:07, 12674.21it/s] 40%|███▉      | 63640/160239 [00:05<00:07, 12702.42it/s] 41%|████      | 65128/160239 [00:05<00:07, 13345.36it/s] 41%|████▏     | 66464/160239 [00:05<00:07, 13268.58it/s] 42%|████▏     | 67792/160239 [00:05<00:07, 12786.40it/s] 43%|████▎     | 69075/160239 [00:05<00:07, 12430.30it/s] 44%|████▍     | 70376/160239 [00:05<00:07, 12594.66it/s] 45%|████▍     | 71640/160239 [00:05<00:07, 12519.29it/s] 45%|████▌     | 72895/160239 [00:05<00:07, 12443.39it/s] 46%|████▋     | 74141/160239 [00:05<00:06, 12347.25it/s] 47%|████▋     | 75377/160239 [00:06<00:06, 12333.51it/s] 48%|████▊     | 76623/160239 [00:06<00:06, 12369.42it/s] 49%|████▊     | 77966/160239 [00:06<00:06, 12683.43it/s] 49%|████▉     | 79243/160239 [00:06<00:06, 12702.64it/s] 50%|█████     | 80591/160239 [00:06<00:06, 12933.77it/s] 51%|█████     | 81897/160239 [00:06<00:06, 12966.37it/s] 52%|█████▏    | 83201/160239 [00:06<00:05, 12986.31it/s] 53%|█████▎    | 84500/160239 [00:06<00:05, 12912.46it/s] 54%|█████▎    | 85863/160239 [00:06<00:05, 13125.35it/s] 54%|█████▍    | 87182/160239 [00:06<00:05, 13138.26it/s] 55%|█████▌    | 88497/160239 [00:07<00:05, 12918.08it/s] 56%|█████▌    | 89842/160239 [00:07<00:05, 13074.07it/s] 57%|█████▋    | 91151/160239 [00:07<00:05, 12891.85it/s] 58%|█████▊    | 92442/160239 [00:07<00:05, 12816.87it/s] 58%|█████▊    | 93725/160239 [00:07<00:05, 12642.14it/s] 59%|█████▉    | 94990/160239 [00:07<00:05, 12231.08it/s] 60%|██████    | 96280/160239 [00:07<00:05, 12422.62it/s] 61%|██████    | 97546/160239 [00:07<00:05, 12490.93it/s] 62%|██████▏   | 98835/160239 [00:07<00:04, 12608.01it/s] 63%|██████▎   | 100193/160239 [00:07<00:04, 12893.92it/s] 63%|██████▎   | 101484/160239 [00:08<00:04, 12844.50it/s] 64%|██████▍   | 102770/160239 [00:08<00:04, 12715.16it/s] 65%|██████▍   | 104043/160239 [00:08<00:04, 12584.00it/s] 66%|██████▌   | 105402/160239 [00:08<00:04, 12879.74it/s] 67%|██████▋   | 106692/160239 [00:08<00:04, 12832.96it/s] 67%|██████▋   | 107977/160239 [00:08<00:04, 12438.85it/s] 68%|██████▊   | 109224/160239 [00:08<00:04, 12164.97it/s] 69%|██████▉   | 110472/160239 [00:08<00:04, 12253.09it/s] 70%|██████▉   | 111838/160239 [00:08<00:03, 12662.07it/s] 71%|███████   | 113107/160239 [00:09<00:03, 12425.70it/s] 71%|███████▏  | 114405/160239 [00:09<00:03, 12584.68it/s] 72%|███████▏  | 115666/160239 [00:09<00:03, 12587.84it/s] 73%|███████▎  | 116927/160239 [00:09<00:03, 12373.00it/s] 74%|███████▍  | 118236/160239 [00:09<00:03, 12581.00it/s] 75%|███████▍  | 119561/160239 [00:09<00:03, 12778.06it/s] 75%|███████▌  | 120841/160239 [00:09<00:03, 12537.95it/s] 76%|███████▋  | 122269/160239 [00:09<00:02, 13047.64it/s] 77%|███████▋  | 123577/160239 [00:09<00:02, 12829.36it/s] 78%|███████▊  | 124863/160239 [00:09<00:02, 12558.69it/s] 79%|███████▊  | 126122/160239 [00:10<00:02, 12497.95it/s] 80%|███████▉  | 127397/160239 [00:10<00:02, 12569.82it/s] 80%|████████  | 128689/160239 [00:10<00:02, 12671.58it/s] 81%|████████  | 129958/160239 [00:10<00:02, 12501.28it/s] 82%|████████▏ | 131210/160239 [00:10<00:02, 12376.04it/s] 83%|████████▎ | 132449/160239 [00:10<00:02, 12339.89it/s] 83%|████████▎ | 133684/160239 [00:10<00:02, 12156.09it/s] 84%|████████▍ | 134911/160239 [00:10<00:02, 12185.66it/s] 85%|████████▍ | 136153/160239 [00:10<00:01, 12254.33it/s] 86%|████████▌ | 137422/160239 [00:10<00:01, 12381.28it/s] 87%|████████▋ | 138743/160239 [00:11<00:01, 12626.81it/s] 87%|████████▋ | 140075/160239 [00:11<00:01, 12832.62it/s] 88%|████████▊ | 141396/160239 [00:11<00:01, 12943.58it/s] 89%|████████▉ | 142691/160239 [00:11<00:01, 12628.26it/s] 90%|████████▉ | 143956/160239 [00:11<00:01, 12621.85it/s] 91%|█████████ | 145220/160239 [00:11<00:01, 12557.39it/s] 91%|█████████▏| 146477/160239 [00:11<00:01, 12321.34it/s] 92%|█████████▏| 147711/160239 [00:11<00:01, 12302.35it/s] 93%|█████████▎| 148943/160239 [00:11<00:00, 11987.18it/s] 94%|█████████▎| 150203/160239 [00:11<00:00, 12164.65it/s] 95%|█████████▍| 151462/160239 [00:12<00:00, 12288.15it/s] 95%|█████████▌| 152742/160239 [00:12<00:00, 12437.86it/s] 96%|█████████▌| 153988/160239 [00:12<00:00, 12337.27it/s] 97%|█████████▋| 155349/160239 [00:12<00:00, 12713.10it/s] 98%|█████████▊| 156622/160239 [00:12<00:00, 12495.77it/s] 99%|█████████▊| 157882/160239 [00:12<00:00, 12524.35it/s] 99%|█████████▉| 159136/160239 [00:12<00:00, 12509.98it/s]100%|██████████| 160239/160239 [00:12<00:00, 12537.16it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3893/160239 [00:00<00:04, 38925.49it/s]  5%|▍         | 7818/160239 [00:00<00:03, 39111.56it/s]  7%|▋         | 11807/160239 [00:00<00:03, 39465.62it/s] 10%|▉         | 15754/160239 [00:00<00:03, 39374.50it/s] 12%|█▏        | 19692/160239 [00:00<00:03, 39074.51it/s] 15%|█▍        | 23600/160239 [00:00<00:03, 39010.16it/s] 17%|█▋        | 27502/160239 [00:00<00:03, 38779.26it/s] 20%|█▉        | 31455/160239 [00:00<00:03, 39014.53it/s] 22%|██▏       | 35357/160239 [00:00<00:03, 38510.30it/s] 25%|██▍       | 39360/160239 [00:01<00:03, 38971.89it/s] 27%|██▋       | 43259/160239 [00:01<00:03, 38703.92it/s] 29%|██▉       | 47134/160239 [00:01<00:02, 38713.16it/s] 32%|███▏      | 51074/160239 [00:01<00:02, 38917.74it/s] 34%|███▍      | 55004/160239 [00:01<00:02, 39029.48it/s] 37%|███▋      | 59087/160239 [00:01<00:02, 39569.22it/s] 39%|███▉      | 63050/160239 [00:01<00:02, 39586.35it/s] 42%|████▏     | 67160/160239 [00:01<00:02, 40039.31it/s] 44%|████▍     | 71165/160239 [00:01<00:02, 39819.07it/s] 47%|████▋     | 75148/160239 [00:01<00:02, 39487.76it/s] 49%|████▉     | 79208/160239 [00:02<00:02, 39814.82it/s] 52%|█████▏    | 83297/160239 [00:02<00:01, 40133.04it/s] 55%|█████▍    | 87452/160239 [00:02<00:01, 40553.84it/s] 57%|█████▋    | 91509/160239 [00:02<00:01, 40254.16it/s] 60%|█████▉    | 95536/160239 [00:02<00:01, 39839.14it/s] 62%|██████▏   | 99534/160239 [00:02<00:01, 39877.48it/s] 65%|██████▍   | 103535/160239 [00:02<00:01, 39916.50it/s] 67%|██████▋   | 107528/160239 [00:02<00:01, 39806.08it/s] 70%|██████▉   | 111510/160239 [00:02<00:01, 39605.49it/s] 72%|███████▏  | 115516/160239 [00:02<00:01, 39736.67it/s] 75%|███████▍  | 119547/160239 [00:03<00:01, 39906.28it/s] 77%|███████▋  | 123589/160239 [00:03<00:00, 40057.87it/s] 80%|███████▉  | 127596/160239 [00:03<00:00, 39828.24it/s] 82%|████████▏ | 131580/160239 [00:03<00:00, 39466.57it/s] 85%|████████▍ | 135528/160239 [00:03<00:00, 39235.19it/s] 87%|████████▋ | 139570/160239 [00:03<00:00, 39585.32it/s] 90%|████████▉ | 143561/160239 [00:03<00:00, 39680.95it/s] 92%|█████████▏| 147530/160239 [00:03<00:00, 39320.94it/s] 95%|█████████▍| 151464/160239 [00:03<00:00, 39212.96it/s] 97%|█████████▋| 155549/160239 [00:03<00:00, 39696.11it/s]100%|█████████▉| 159528/160239 [00:04<00:00, 39721.67it/s]100%|██████████| 160239/160239 [00:04<00:00, 39521.00it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2404.99it/s]2022-03-23 11:38:57 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:38:57 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:38:57 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:38:57 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:38:57 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:38:57 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:38:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:38:57 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:38:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:38:58 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:38:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:38:58 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:38:58 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:38:58 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:38:58 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:38:58 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 11:38:58 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 11:38:58 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:38:58 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:38:58 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:38:58 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:38:58 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:38:58 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:38:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:39:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:39:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:39:39 | INFO | train_inner | epoch 001:    104 / 157 loss=13.29, ppl=10015.5, wps=66735.2, ups=2.65, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.152, loss_scale=8, train_wall=40, gb_free=12.1, wall=41
2022-03-23 11:39:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:40:02 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:40:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:40:05 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:40:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:40:07 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:40:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:40:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:40:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:40:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:40:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:40:23 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:40:28 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:40:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:40:37 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:40:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.945 | ppl 7886.66 | bleu 0.02 | wps 4601.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:40:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 1.6159966951236129 seconds)
2022-03-23 11:40:39 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:40:39 | INFO | train | epoch 001 | loss 12.856 | ppl 7412.8 | wps 39195.2 | ups 1.56 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.46 | loss_scale 8 | train_wall 59 | gb_free 22.3 | wall 101
KL Stats: Epoch 1 Divergences: Uniform: 0.5501224107490286 Unigram: 1.4386493153685957
2022-03-23 11:40:39 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:40:57 | INFO | train_inner | epoch 002:     47 / 157 loss=11.717, ppl=3366.76, wps=32412.4, ups=1.28, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.04, loss_scale=8, train_wall=37, gb_free=12.9, wall=119
2022-03-23 11:41:35 | INFO | train_inner | epoch 002:    147 / 157 loss=11.281, ppl=2489.17, wps=66814.6, ups=2.65, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.984, loss_scale=8, train_wall=37, gb_free=12.2, wall=157
2022-03-23 11:41:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the.
2022-03-23 11:41:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:41:48 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the.
2022-03-23 11:41:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:42:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:42:07 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:20 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:42:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:22 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.232 | ppl 4809.59 | bleu 0.02 | wps 3953.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.716409832239151 seconds)
2022-03-23 11:42:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:42:24 | INFO | train | epoch 002 | loss 11.318 | ppl 2553.16 | wps 37420.1 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.943 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 207
KL Stats: Epoch 2 Divergences: Uniform: 0.6959247261917925 Unigram: 0.34419897225660967
2022-03-23 11:42:25 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:58 | INFO | train_inner | epoch 003:     90 / 157 loss=11.043, ppl=2109.79, wps=29385.2, ups=1.2, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.707, loss_scale=8, train_wall=36, gb_free=11.8, wall=241
2022-03-23 11:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:27 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-23 11:43:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:43:30 | INFO | fairseq.tasks.translation | example hypothesis: it's the the.
2022-03-23 11:43:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:43:36 | INFO | fairseq.tasks.translation | example hypothesis: and it's.
2022-03-23 11:43:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, it's, it's's's's.
2022-03-23 11:43:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example hypothesis: and the, and the, and the, and the, and the the the, and and and and and the the the, and the.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:43:49 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's's, it's's, and it's's, and it's, it's, it's's's, it's's, it's, and it's's's.
2022-03-23 11:43:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:55 | INFO | fairseq.tasks.translation | example hypothesis: and we, and the, and the, and the, and we, and the the the, and the, and the, and the, and the the, and the, and the, and the, and the, and the, and the, and the, and the the, and the the, and the the, and the the, and the the, and the the, and the the the, and the the the, and the the the the the
2022-03-23 11:43:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:02 | INFO | fairseq.tasks.translation | example hypothesis: and i, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:44:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:05 | INFO | fairseq.tasks.translation | example hypothesis: it's a, the, and the, and the, and the, and the, and the, and the, the, the, and the, and the the, the, the, the, the, the, and the, and the, and the, the, the the, the, the, the, the, the, the the the the, the, and the, and the, and the, and the, and the, and the, and the the the, and the, and the, and the the the the the, and the, and the, and the, and the, and the, and the, and the, and the the the the, the, the, the, the, the, the, the, the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the
2022-03-23 11:44:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:05 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.098 | ppl 4385.21 | bleu 0.31 | wps 4301.7 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.31
2022-03-23 11:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.31) (writing took 1.734696710947901 seconds)
2022-03-23 11:44:06 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:44:06 | INFO | train | epoch 003 | loss 10.948 | ppl 1975.47 | wps 38641 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.892 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 309
KL Stats: Epoch 3 Divergences: Uniform: 0.889823724201738 Unigram: 0.23978576040444088
2022-03-23 11:44:07 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:20 | INFO | train_inner | epoch 004:     33 / 157 loss=10.856, ppl=1852.89, wps=31315.5, ups=1.23, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.043, loss_scale=8, train_wall=37, gb_free=12, wall=322
2022-03-23 11:44:57 | INFO | train_inner | epoch 004:    133 / 157 loss=10.762, ppl=1736.76, wps=67140, ups=2.66, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.026, loss_scale=8, train_wall=37, gb_free=10.8, wall=360
2022-03-23 11:45:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:09 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:45:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the that's the of the.
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example hypothesis: so, you're a of the of the.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:45:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a of it's.
2022-03-23 11:45:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:45:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not not it's a that we're not not not not not.
2022-03-23 11:45:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example hypothesis: and this is that's a in the of the of the of the of the world, and the world of the world.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:45:35 | INFO | fairseq.tasks.translation | example hypothesis: but they're are, but they're a, but they're the are are are are are are are, but they're the world, but they're the world, but they're the world, but they're're the world, but they're the world, but they're the world.
2022-03-23 11:45:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:41 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can see the of the world, and we can can can can can can can can can can can can can can can can can can can can can see the of the world, and we're the of the world, and we're the world.
2022-03-23 11:45:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:48 | INFO | fairseq.tasks.translation | example hypothesis: and "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:45:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to have to be, and we have to be a, and we have to have to be, and we have a, and we have a to be a to be be be be a to be, and it's a to be a, and we have to have to be be be, and we have to be be be be be be be be be be be be be be be, and we have to be be be be be be be be be, and it, and we have to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, and we have, and we have to be be be be be, and we have, and we have, and we have to be be be be be be be be be be be be be, and we have, and we have to be be be be be be be be be be be be be be be be be be be be
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:50 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.836 | ppl 3656.02 | bleu 1.14 | wps 3997 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.14
2022-03-23 11:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.14) (writing took 1.754398320801556 seconds)
2022-03-23 11:45:52 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:45:52 | INFO | train | epoch 004 | loss 10.759 | ppl 1732.54 | wps 37428.9 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.992 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 414
KL Stats: Epoch 4 Divergences: Uniform: 0.9169880326315172 Unigram: 0.3406015178664976
2022-03-23 11:45:52 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:21 | INFO | train_inner | epoch 005:     76 / 157 loss=10.71, ppl=1675.28, wps=29339.4, ups=1.19, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.178, loss_scale=8, train_wall=36, gb_free=11.5, wall=443
2022-03-23 11:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:55 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 11:46:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:46:58 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world.
2022-03-23 11:46:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have to be a lot.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example hypothesis: and there's a
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:47:09 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do it's going to do that we're going to do it's going to do that we're going to do it's going to do it.
2022-03-23 11:47:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:47:14 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and we have to be a lot of the world.
2022-03-23 11:47:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:47:18 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be a lot of the world, but they're a lot of the world, but they're not not not not going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world.
2022-03-23 11:47:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example hypothesis: and we're a lot of the world, and we're going to have a lot of the world, and we're a lot of the world of the world, and we have a lot of the world of the world of the world, and we have to have to make the world, and we're the world, and we have to have to have to have to be a lot of the world, and we need to be a lot of the world, and we
2022-03-23 11:47:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:31 | INFO | fairseq.tasks.translation | example hypothesis: and if you're a lot of the, "" "" you're a "" "" you're a lot, "you're a lot," you're a lot of, "you're a lot of the," "" you're a lot, "you're a lot of the world," "" "you're a lot," you're a lot, "you're a lot," you're a lot of the "" "" "" "" "" "" "" "" "" "" "" and we have to go to go to go to go to go to go to go to go to go to go to go to be a lot, "" "and we have to be a lot," "" and we have to be a lot, "" "" "" "" "" "" "" "" "" "
2022-03-23 11:47:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:33 | INFO | fairseq.tasks.translation | example hypothesis: and if we're a lot of a lot of the world, and we're a lot of the world, and we're a lot of the world, and we have a lot of the world, and we're a lot of the world, and we're a lot of the world, and we have a lot of the world, and we have to have to have to be a lot of the world, and we have a lot of the world, and we're a lot of the world, and we have a lot of the world is a lot of the world, and we have a lot of the world, and we have to have to be a lot of the world, and we have a lot of the world, and we have a lot of the world, and we have to have to be a lot of the world, and we have to be a lot of the world, and we have to have to have to have to have to go to be a lot of the world, and we have a lot of the world, and we have to be
2022-03-23 11:47:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:33 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.623 | ppl 3154.17 | bleu 1.79 | wps 4281.4 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.79
2022-03-23 11:47:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:47:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.79) (writing took 1.741768847219646 seconds)
2022-03-23 11:47:35 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:47:35 | INFO | train | epoch 005 | loss 10.531 | ppl 1479.7 | wps 38446.2 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.03 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 517
KL Stats: Epoch 5 Divergences: Uniform: 0.9557138294371305 Unigram: 0.4622912922800253
2022-03-23 11:47:35 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:42 | INFO | train_inner | epoch 006:     19 / 157 loss=10.385, ppl=1337.35, wps=31258, ups=1.23, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=0.95, loss_scale=8, train_wall=37, gb_free=12.7, wall=524
2022-03-23 11:48:20 | INFO | train_inner | epoch 006:    119 / 157 loss=10.32, ppl=1278.69, wps=67286.3, ups=2.66, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=0.971, loss_scale=8, train_wall=37, gb_free=11.9, wall=562
2022-03-23 11:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the world.
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:48:46 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world, and they're going to be going to be going to be going to be going to be going to be two.
2022-03-23 11:48:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:48:51 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and there's, there's a lot of, and there's a lot of, and there's, and there's, and there's, and there's a lot of
2022-03-23 11:48:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do it, and it's going to do that we're going to do it.
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:49:01 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and in the world, and
2022-03-23 11:49:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be not not not
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:13 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see, we're going to see the world, and we can see, and we can see the world, and we can see, and we can see, and we can see that we can see the world, and we can see the world.
2022-03-23 11:49:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:20 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "you know," you know, "it's going to say," it's going to say, "you know," it's going to say, "it's going to say," you know, "it's going to say," it's going to say, "" it's going to say, "" it's going to say, "you know," it's going to say, "" "" "" "it's going to say," you know, "it's going to say," you know, "you know," it's going to say, "" it's going to say, "you know," it's going to say, "
2022-03-23 11:49:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:22 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, it's a lot of the world, and we're going to do that we're going to be, and it's going to be, and it's going to be, and it, and it's a, and it's going to be, and it's a, and it's going to be, and it's going to be, and it's going to be a lot of the world, and it's going to be, and it, and it's, and it's a lot of the world, and it's a lot of the world, and it's going to be, and it's going to be, and it's going to be, and it's going to be, and it's a lot of the world, and it's going to be, and it's a lot of the world, and it's going to be, and it's, and it's, and it's, and it's, and it's, and it's going to be, and it's a, and it's a
2022-03-23 11:49:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.426 | ppl 2751.63 | bleu 1.71 | wps 3659.7 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.79
2022-03-23 11:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 11:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 11:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.71) (writing took 0.7576407357119024 seconds)
2022-03-23 11:49:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:49:23 | INFO | train | epoch 006 | loss 10.34 | ppl 1296.07 | wps 36434.2 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.038 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 625
KL Stats: Epoch 6 Divergences: Uniform: 0.9976051619882437 Unigram: 0.5542487736233319
2022-03-23 11:49:23 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:47 | INFO | train_inner | epoch 007:     62 / 157 loss=10.248, ppl=1216.46, wps=28953.4, ups=1.15, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.959, loss_scale=8, train_wall=37, gb_free=11.6, wall=649
2022-03-23 11:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:26 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 11:50:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most of the most most of the most of the most most of the most of the most.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:50:34 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be going to be new new new new new new new new new new new.
2022-03-23 11:50:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of, and it's going to be, and it's going to be, and it's going to be a.
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do it, and it's going to do that we're going to do that we're going to do it.
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people for the people for the people, for the people, for the people, and the people for the people for the people for the people.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:50:54 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be a lot of the, they're not not, they're going to be a lot of the, but they're going to be, but they're going to be, but they're going to be, but they're going to be a lot of the, but they're going to be, but they're going to be
2022-03-23 11:50:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the, and we can see that we're going to get a lot of the, and we can see that we can see the brain.
2022-03-23 11:50:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you're going to say," you know, "you know," you know, "we're going to get a lot of this," you're going to go to say, "you're going to get to get a lot of," you know, "you know," we're going to say, "we're going to get to go to say," we're going to get a lot of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, "
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:08 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the way that we're going to see that we're going to get a lot of the, and we're going to be a lot of the, and we're going to be a lot of the world, and we're going to be going to be a lot of the world, and we're going to be going to be going to be a lot of the world, and we're going to be going to be a lot of the, and then we're going to be going to be a lot of the, and then we're going to be able to be a lot of the, and then we're going to be going to be a lot of the, and then we're going to be going to be a lot of the, and then we're going to be able to be a lot of the way that we're going to be able to see that we're going to be able to be able to be able to get to be able to be able to be able to be able to be able to
2022-03-23 11:51:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:08 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.279 | ppl 2484.51 | bleu 2.21 | wps 3831.9 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.21
2022-03-23 11:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.21) (writing took 1.7086085733026266 seconds)
2022-03-23 11:51:10 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:51:10 | INFO | train | epoch 007 | loss 10.17 | ppl 1152.05 | wps 36862 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.908 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 733
KL Stats: Epoch 7 Divergences: Uniform: 1.0298997308538327 Unigram: 0.6218496441695359
2022-03-23 11:51:11 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:12 | INFO | train_inner | epoch 008:      5 / 157 loss=10.17, ppl=1152.18, wps=29149.5, ups=1.17, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.916, loss_scale=8, train_wall=37, gb_free=12, wall=735
2022-03-23 11:51:50 | INFO | train_inner | epoch 008:    105 / 157 loss=9.985, ppl=1013.6, wps=67488.1, ups=2.68, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.89, loss_scale=8, train_wall=37, gb_free=12.3, wall=772
2022-03-23 11:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:13 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-23 11:52:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most of the most most most of the most most of the most most most of the most of the most most most of the
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:52:21 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 11:52:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:52:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a
2022-03-23 11:52:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to see what we're going to do.
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:52:35 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the world, the most people who are in the people in the people in the people in the people in the people in the people in the people in the people in the people in the people for the people, and the people who are the people in the
2022-03-23 11:52:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:52:41 | INFO | fairseq.tasks.translation | example hypothesis: now, some of some of some of the but they're not, but it's not, but it's not, but if you can't have a, but if you're not, but it, but it's not, but it's not, but it's not, but it's not, but it's the same.
2022-03-23 11:52:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:46 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see that, we can see that we can see the brain, and then we can see that we can see the brain, and we can see that we can see that we can see the
2022-03-23 11:52:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:52 | INFO | fairseq.tasks.translation | example hypothesis: one: you know, "it's a," we know, "it's a," it's, "it's," it's, "and it's a," we've got to say, "you know," you know, "and it's a," you know, "it's a," it's a, "it's a," it's, "it's a," you know, "what we know," it's, "and it's a" it's, "it's," and it's a, "and it's a," we know, "we know," it's a, "it's a," you know, "you know," you know, "you know," what we know, "you know," it's a, "it's a," it's, "it's
2022-03-23 11:52:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's the way that we're going to be a, if we're going to get a, and we can see that we're going to get a, and then we're going to get a, that we're going to be a, and then we're going to be a, and then we can see that we're going to be a little bit of the way that we're going to be a, it's going to be a, it's a, and then we're going to be a, and then we're going to be a, and then we're going to be a, it's going to be a, and then we can see that we're going to be a, if we're going to be a, if we're going to be a, if we're going to be a, if we're going to be a, it's going to be a, it's going to get to get to get to get to be a, if we're going to be a lot of the way that we can see that we can
2022-03-23 11:52:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:54 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.118 | ppl 2222.56 | bleu 3.56 | wps 3962.1 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.56
2022-03-23 11:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:52:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.56) (writing took 1.7442268948070705 seconds)
2022-03-23 11:52:56 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:52:56 | INFO | train | epoch 008 | loss 10.032 | ppl 1047.16 | wps 37240.9 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.883 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 839
KL Stats: Epoch 8 Divergences: Uniform: 1.060893430035115 Unigram: 0.6692988852631521
2022-03-23 11:52:57 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:15 | INFO | train_inner | epoch 009:     48 / 157 loss=9.916, ppl=965.99, wps=30155.1, ups=1.17, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.81, loss_scale=8, train_wall=37, gb_free=12.6, wall=857
2022-03-23 11:53:52 | INFO | train_inner | epoch 009:    148 / 157 loss=9.927, ppl=973.62, wps=66754.3, ups=2.69, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.837, loss_scale=8, train_wall=37, gb_free=11.9, wall=895
2022-03-23 11:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example hypothesis: we had this in this.
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most of the most most of the most most of the most most
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're not just just just just just just just just just just just just just just just just just a few years of what's going to do.
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:54:23 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, as the people who were in the united states, for people in the people who had been able to get a lot of people in the united states, and it's a lot of people in the united states.
2022-03-23 11:54:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of the
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see that we can see that we can see that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the
2022-03-23 11:54:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the world, and it's a lot of people who said, "you know," you know, "you know," you know, "you know," you're going to say, "you know," you're going to say, "you know," well, "it's going to say," you're going to say, "you're going to say," you're going to say, "well," well, "you know," well, "the first first first first first first first first first first first first," you're going to say, "you're going to say," you're going to say, "you know," you know, "you know," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:44 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in fact, in fact, if we're going to be a lot of course, we're going to do that we're going to get a lot of the world, and we're going to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 11:54:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.952 | ppl 1980.66 | bleu 4.24 | wps 3685.6 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.24
2022-03-23 11:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:54:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.24) (writing took 1.779682288877666 seconds)
2022-03-23 11:54:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:54:46 | INFO | train | epoch 009 | loss 9.867 | ppl 933.7 | wps 36092.7 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.82 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 948
KL Stats: Epoch 9 Divergences: Uniform: 1.0917010623660597 Unigram: 0.7171796968708214
2022-03-23 11:54:46 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:21 | INFO | train_inner | epoch 010:     91 / 157 loss=9.809, ppl=897.04, wps=28446, ups=1.13, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.798, loss_scale=8, train_wall=37, gb_free=12.6, wall=983
2022-03-23 11:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:48 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:55:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:55:52 | INFO | fairseq.tasks.translation | example hypothesis: and that's the most of the most of the most most of the most most most most.
2022-03-23 11:55:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:55:56 | INFO | fairseq.tasks.translation | example hypothesis: the new new new new new new new new new new new two two.
2022-03-23 11:55:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a.
2022-03-23 11:55:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:56:04 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just a few years, and what's going to do.
2022-03-23 11:56:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:56:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaas people like the most people for the most people for the people, and it's a few years.
2022-03-23 11:56:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of you're going to go to the.
2022-03-23 11:56:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:56:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can use this.
2022-03-23 11:56:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:22 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reasons, and it's very interesting, and it's very interesting for me, and it's the first time that we've been working for me, and then you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know
2022-03-23 11:56:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:25 | INFO | fairseq.tasks.translation | example hypothesis: well, it's always always always always always always always been a lot of the work, and when we're going to have a lot of work, if we're going to have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:56:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:25 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.724 | ppl 1691.71 | bleu 7.2 | wps 4549.3 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 7.2
2022-03-23 11:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 11:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 10 @ 1566 updates, score 7.2) (writing took 1.7767929607070982 seconds)
2022-03-23 11:56:26 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:56:26 | INFO | train | epoch 010 | loss 9.693 | ppl 827.94 | wps 39224.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 0.776 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1049
KL Stats: Epoch 10 Divergences: Uniform: 1.125034887734429 Unigram: 0.7596873401372826
2022-03-23 11:56:27 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:39 | INFO | train_inner | epoch 011:     34 / 157 loss=9.643, ppl=799.48, wps=31463.5, ups=1.27, wpb=24827.9, bsz=1010.3, num_updates=1600, lr=0.0002, gnorm=0.8, loss_scale=8, train_wall=36, gb_free=13.1, wall=1062
2022-03-23 11:57:17 | INFO | train_inner | epoch 011:    134 / 157 loss=9.385, ppl=668.43, wps=68004.4, ups=2.67, wpb=25502, bsz=1063, num_updates=1700, lr=0.0002125, gnorm=0.761, loss_scale=8, train_wall=37, gb_free=12.6, wall=1099
2022-03-23 11:57:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:29 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the end.
2022-03-23 11:57:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:57:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the, most of most of most of most of most of most of the most.
2022-03-23 11:57:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:57:37 | INFO | fairseq.tasks.translation | example hypothesis: these are new. the new new new new new new new new.
2022-03-23 11:57:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:57:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese, where he's going to go with the head.
2022-03-23 11:57:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:57:45 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few feet on his head, and what's going to understand.
2022-03-23 11:57:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:57:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamay of people who had been used for the number of animals, and the number of the number of the number of the number of the number.
2022-03-23 11:57:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:57:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to go from the, but if you don't need to go into the ground, it doesn't need the energy, and if you need the energy, you need the energy.
2022-03-23 11:57:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information the information that we can create a structure, we can create the structure of the structure, and we can create a structure of information, and all the structure of the structure of the information, and all the information.
2022-03-23 11:57:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:02 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, it's interesting, and it's interesting for me for me, "if you know," you know, you know, you know, you know, you know, "you know, you know, you know, you know, you know," if you're going to say, "you know," you're going to go to say, "you know," you're going to say, "you know," you know, "you know," you're going to be a young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young young women, "you're going to go back to go back to go back to go back to you know," you know, and you know, "and then we're going to be the first
2022-03-23 11:58:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and we have a lot of work that we had to see the system that we had to be a new system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.547 | ppl 1496.18 | bleu 9.67 | wps 4679.2 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 9.67
2022-03-23 11:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 11:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 11 @ 1723 updates, score 9.67) (writing took 1.7658985266461968 seconds)
2022-03-23 11:58:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:58:06 | INFO | train | epoch 011 | loss 9.523 | ppl 735.95 | wps 39669.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 0.79 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 1148
KL Stats: Epoch 11 Divergences: Uniform: 1.156775438542102 Unigram: 0.7945045785208446
2022-03-23 11:58:06 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:35 | INFO | train_inner | epoch 012:     77 / 157 loss=9.468, ppl=708.42, wps=31972.1, ups=1.28, wpb=24985.4, bsz=970.8, num_updates=1800, lr=0.000225, gnorm=0.773, loss_scale=8, train_wall=37, gb_free=12.1, wall=1178
2022-03-23 11:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:09 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 11:59:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:59:13 | INFO | fairseq.tasks.translation | example hypothesis: and this is the cist, most of you know, most of most.
2022-03-23 11:59:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:59:17 | INFO | fairseq.tasks.translation | example hypothesis: new stars will be going to be able to be two kinds of the new new new.
2022-03-23 11:59:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:59:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese chinese chinese chinese chinese, where they're going to get with.
2022-03-23 11:59:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:59:26 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we're just just just just just a few of his head on his head, and what's going to understand his mind.
2022-03-23 11:59:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:59:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamay of the responsibility for people, the number of animals, the number of animals, and this is a number of animals, and this is a lot of, and this is a lot of the cocoiiiiiiiiiii
2022-03-23 11:59:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to see a little bit of the brain, but if you don't need it in the energy, it doesn't need the energy, and if you need the energy, you need the energy.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information the information that we can start from this structure, we can start with a huge structure of the structure of the structure, and the structure of the structure of the structure of the structure, and the structure of the structure of the structure, and all the structure of the structure.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:43 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons, it's interesting to be interesting, and i'm going to be able to be able to tell you, "well," if we're going to say, "you know," if you're going to say, "you're going to say," you know, "if you're going to say," you're going to say, "well," well, "if you're going to say," you're going to do it's a long time. "
2022-03-23 11:59:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and we're going to see a lot of design, and if we had to see the same thing that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to
2022-03-23 11:59:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.358 | ppl 1312.24 | bleu 11.56 | wps 4521.8 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 11.56
2022-03-23 11:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 11:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 12 @ 1880 updates, score 11.56) (writing took 1.7544170157052577 seconds)
2022-03-23 11:59:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 11:59:47 | INFO | train | epoch 012 | loss 9.337 | ppl 646.78 | wps 39225.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 0.781 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 1249
KL Stats: Epoch 12 Divergences: Uniform: 1.187748612681597 Unigram: 0.822891277116525
2022-03-23 11:59:47 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 11:59:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:55 | INFO | train_inner | epoch 013:     20 / 157 loss=9.247, ppl=607.74, wps=31617.8, ups=1.26, wpb=25105.5, bsz=1045.6, num_updates=1900, lr=0.0002375, gnorm=0.844, loss_scale=8, train_wall=37, gb_free=12.3, wall=1257
2022-03-23 12:00:32 | INFO | train_inner | epoch 013:    120 / 157 loss=9.183, ppl=581.09, wps=67237.4, ups=2.66, wpb=25276.1, bsz=1044.4, num_updates=2000, lr=0.00025, gnorm=0.76, loss_scale=8, train_wall=37, gb_free=13.1, wall=1295
2022-03-23 12:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppm in the clinic.
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:00:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the right line of doha, most of most of you know here.
2022-03-23 12:00:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new ororororores.
2022-03-23 12:00:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:01:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where you're going to get with.
2022-03-23 12:01:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:01:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just just a couple of electrodes on his head, and what all of his mind are on his mind.
2022-03-23 12:01:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:01:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamase people like the responsibility of animals, the number of animals, and that's a number of animals that has been in the public, and that has become a congress.
2022-03-23 12:01:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:01:13 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the bbbbbbbbble, but it doesn't have to move their energy, but if you don't need your energy energy, you need the energy, and you need the energy.
2022-03-23 12:01:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:01:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information the information that we can start from this.
2022-03-23 12:01:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to be interesting, and i'm talking about tedtedo... "yeah," yeah, "yeah," you know, you know, "you know, you know," you know, you know, you know, "if you're going to have a lot of the best revolution," you're going to be working with the best revolution, "you're going to have a long revolution."
2022-03-23 12:01:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still true to the invention of the invention of our work, and we've been able to see the beginning of our airplane, and we've had to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:01:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:25 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.208 | ppl 1182.58 | bleu 12.68 | wps 4587.5 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 12.68
2022-03-23 12:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 12:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 13 @ 2037 updates, score 12.68) (writing took 1.7737538376823068 seconds)
2022-03-23 12:01:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:01:27 | INFO | train | epoch 013 | loss 9.16 | ppl 571.9 | wps 39264.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 0.791 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 1350
KL Stats: Epoch 13 Divergences: Uniform: 1.219615313611876 Unigram: 0.8509529393359395
2022-03-23 12:01:27 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:51 | INFO | train_inner | epoch 014:     63 / 157 loss=9.091, ppl=545.29, wps=31590.3, ups=1.26, wpb=24981.2, bsz=975.8, num_updates=2100, lr=0.0002625, gnorm=0.736, loss_scale=8, train_wall=37, gb_free=12.8, wall=1374
2022-03-23 12:02:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppk in the clinic.
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of doha doha, probably most of the most of you know here.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese food, where the legs are happy, and they're going to get up with.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:02:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just just a couple of electroelectrodes on his head, and what all of his mind are on the mind.
2022-03-23 12:02:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamated people like the responsibility of the responsibility, and the number of animals, and this is a number of dollars.
2022-03-23 12:02:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of them are the magic of magnetic lines in the lines, but it doesn't like this, and if they need their energy, and they need the energy.
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of this reflection, we can come from a traditional, we can start with a traditional traditional form of the shape of the information, and the whole structure of all the information.
2022-03-23 12:02:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:03:03 | INFO | fairseq.tasks.translation | example hypothesis: th reasons: one of the reasons it's interesting, and it's interesting for me to make tedtedtedtedtedtedwomen, "well, if you've got a long time to tell you, and then we've got a long revolution."
2022-03-23 12:03:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:03:04 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the
2022-03-23 12:03:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:03:04 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.065 | ppl 1071.51 | bleu 15.48 | wps 4872.1 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 15.48
2022-03-23 12:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 12:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 14 @ 2194 updates, score 15.48) (writing took 1.7933197682723403 seconds)
2022-03-23 12:03:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:03:06 | INFO | train | epoch 014 | loss 8.962 | ppl 498.78 | wps 40108 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 0.686 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1448
KL Stats: Epoch 14 Divergences: Uniform: 1.2592130264443588 Unigram: 0.8771020106169036
2022-03-23 12:03:06 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:08 | INFO | train_inner | epoch 015:      6 / 157 loss=8.817, ppl=450.93, wps=33086, ups=1.3, wpb=25546.6, bsz=1077.7, num_updates=2200, lr=0.000275, gnorm=0.653, loss_scale=8, train_wall=37, gb_free=12.2, wall=1451
2022-03-23 12:03:46 | INFO | train_inner | epoch 015:    106 / 157 loss=8.795, ppl=444.21, wps=67182.8, ups=2.67, wpb=25207.9, bsz=1066.4, num_updates=2300, lr=0.0002875, gnorm=0.754, loss_scale=8, train_wall=37, gb_free=12.8, wall=1488
2022-03-23 12:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:09 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppk in the clinic clinic.
2022-03-23 12:04:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably the most know here.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will be able to create new.
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:04:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where happy legs are going to be, and they're going to be able.
2022-03-23 12:04:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:04:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all of his thoughts are on the mind.
2022-03-23 12:04:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaking, people who took the responsibility for life, grew up the number of animals, and this is a number of animals.
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:04:34 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of them are a little bit of magic, in the field, but it doesn't like this, if they don't need the energy, they need to move their energy, and they need their energy.
2022-03-23 12:04:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face of the traditional face, and we can begin to start with a big form of the information, and the whole structure of the information.
2022-03-23 12:04:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here to be here for ted.
2022-03-23 12:04:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a big design part of the airplane is that we had to solve the airplane of our airplane, and that we had to solve a unique result of the problem, and if we had to solve it, it's a unique, it's a unique system, it's to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're able to see that the
2022-03-23 12:04:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.87 | ppl 935.86 | bleu 16.74 | wps 4552.3 | wpb 17862.2 | bsz 728.3 | num_updates 2351 | best_bleu 16.74
2022-03-23 12:04:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2351 updates
2022-03-23 12:04:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 15 @ 2351 updates, score 16.74) (writing took 1.8432750147767365 seconds)
2022-03-23 12:04:46 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:04:46 | INFO | train | epoch 015 | loss 8.823 | ppl 452.75 | wps 39137 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2351 | lr 0.000293875 | gnorm 0.719 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1549
KL Stats: Epoch 15 Divergences: Uniform: 1.2894312124843752 Unigram: 0.8886495384166314
2022-03-23 12:04:47 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:04:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:06 | INFO | train_inner | epoch 016:     49 / 157 loss=8.739, ppl=427.19, wps=31939.3, ups=1.26, wpb=25434.7, bsz=926.5, num_updates=2400, lr=0.0003, gnorm=0.666, loss_scale=8, train_wall=37, gb_free=11.2, wall=1568
2022-03-23 12:05:43 | INFO | train_inner | epoch 016:    149 / 157 loss=8.73, ppl=424.62, wps=66716.1, ups=2.7, wpb=24694, bsz=1031.8, num_updates=2500, lr=0.0003125, gnorm=0.647, loss_scale=8, train_wall=37, gb_free=12.8, wall=1605
2022-03-23 12:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:49 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:05:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha.
2022-03-23 12:05:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:05:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 12:05:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:06:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french.
2022-03-23 12:06:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:06:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all the thoughts are on the thoughts.
2022-03-23 12:06:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:06:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the mabia, the people who grew up for life and grew back to the number of animals.
2022-03-23 12:06:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:06:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but it doesn't be able to move, if they don't need their energy, if they don't need their energy.
2022-03-23 12:06:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of traditional face, which can begin to start able to start with a traditional face of the face of the face of the face of the face, and the information of the information.
2022-03-23 12:06:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here, "yes, that's the best thing that it was the best thing that someone said," well, "when someone said," when we're talking about them. "
2022-03-23 12:06:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:20 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the invention of the invention, and one part of the design that we have to see in our airplane.
2022-03-23 12:06:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:20 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.842 | ppl 917.46 | bleu 12.74 | wps 5412.7 | wpb 17862.2 | bsz 728.3 | num_updates 2508 | best_bleu 16.74
2022-03-23 12:06:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2508 updates
2022-03-23 12:06:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:06:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:06:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 16 @ 2508 updates, score 12.74) (writing took 0.7986110602505505 seconds)
2022-03-23 12:06:20 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:06:20 | INFO | train | epoch 016 | loss 8.661 | ppl 404.69 | wps 42008 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2508 | lr 0.0003135 | gnorm 0.666 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 1643
KL Stats: Epoch 16 Divergences: Uniform: 1.3194570553618676 Unigram: 0.9086923818362461
2022-03-23 12:06:21 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:56 | INFO | train_inner | epoch 017:     92 / 157 loss=8.566, ppl=378.95, wps=34584.9, ups=1.37, wpb=25239.3, bsz=1052.8, num_updates=2600, lr=0.000325, gnorm=0.677, loss_scale=8, train_wall=37, gb_free=11.9, wall=1678
2022-03-23 12:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:24 | INFO | fairseq.tasks.translation | example hypothesis: we did these pills in the clinic clinic clinic in the clinic clinic.
2022-03-23 12:07:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:07:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of the most know here.
2022-03-23 12:07:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:07:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to create the two new picks.
2022-03-23 12:07:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where happy legs are, and they're going to be served with salt.
2022-03-23 12:07:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electroelectrodes on his head and understand what all his thoughts are.
2022-03-23 12:07:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the wild animals, the number of animals grew up, and this is a foundation for conservation in namibia.
2022-03-23 12:07:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example hypothesis: first of first, a few bols of magnetic field, but the susucks, but the susucks don't like the energy, if you need your energy, and you need a couple of energy, you need a few bloop of the sucks, and so you need a few bloop of magnetic field of magnetic field in the
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face with a traditional face, which is the real shape of the information and the information, and the whole structure of the information, which is a whole structure, which is all the structure of the structure, and all the structure, and all the structure of the structure that is going to be able to be able to be able to do, and all the structure,
2022-03-23 12:07:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:08:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here in tedwomen, "well, it was the best thing that someone said," when we say, "when we're going to support you," and then we're going to support you, "when we're going to support you're going to support you're going to support the truth," and then we've been working with you're going to support you know, "
2022-03-23 12:08:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:08:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the need is still the mother of invention, and a big part of the design of the plane that we've got to see that we had to solve a unique amount of problems in the ground, or if you were connected to the ground, it is to see that it is to see that all the things that we're going to be able to be able to be able to see that if you're going to see that if you're going to see that, or to see that if you're going to be able to be able to see, or to see that if you're going to see that if you're going to be able to see that, you're going to be able to be able to see, or to see that, or a specific, you're going to see that, you're going to be able to be able to be able to be able to be able to be able to be able to be able to see, or to see, or to see that it's a specific, or to see, you're able to
2022-03-23 12:08:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:08:04 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.694 | ppl 828.39 | bleu 16.86 | wps 4043.3 | wpb 17862.2 | bsz 728.3 | num_updates 2665 | best_bleu 16.86
2022-03-23 12:08:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2665 updates
2022-03-23 12:08:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 17 @ 2665 updates, score 16.86) (writing took 1.734309421852231 seconds)
2022-03-23 12:08:06 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:08:06 | INFO | train | epoch 017 | loss 8.543 | ppl 372.95 | wps 37396.6 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 2665 | lr 0.000333125 | gnorm 0.662 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1749
KL Stats: Epoch 17 Divergences: Uniform: 1.3474987460331571 Unigram: 0.9230209124593579
2022-03-23 12:08:06 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:20 | INFO | train_inner | epoch 018:     35 / 157 loss=8.434, ppl=345.96, wps=29970.7, ups=1.19, wpb=25247.6, bsz=1001.6, num_updates=2700, lr=0.0003375, gnorm=0.651, loss_scale=8, train_wall=37, gb_free=11.9, wall=1762
2022-03-23 12:08:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 12:08:58 | INFO | train_inner | epoch 018:    136 / 157 loss=8.499, ppl=361.8, wps=65554.3, ups=2.65, wpb=24742.2, bsz=1020.5, num_updates=2800, lr=0.00035, gnorm=0.597, loss_scale=4, train_wall=37, gb_free=12.3, wall=1800
2022-03-23 12:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:09:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 12:09:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:09:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golf locks. the two new pigs will be transformed.
2022-03-23 12:09:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:09:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where frozen legs are involved with salz and fat.
2022-03-23 12:09:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:09:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all of the thoughts are.
2022-03-23 12:09:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:09:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers, the responsibility of the wild responsibility grew up with the number of wild animals, and this is a foundation of conservation in the namibia.
2022-03-23 12:09:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:09:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are bloop lines in magnetic field, but the sususuck doesn't like the susuick, if you're moving, you need your energy, and so you need the sucks.
2022-03-23 12:09:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial facial face, which is the great concrete of the face of the face, and the shape of the information, and the information that's all the structure.
2022-03-23 12:09:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting, for me to be here in tedwomen, "is that..." yes, it was the best thing that someone said, "and someone said," you know, "if you're working on a table," and if we're going to support you have a long time to support you. "
2022-03-23 12:09:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design that we're going to see in our plane, was a result that we had to solve the unique problems that were connected to the ground -- it was to be connected to the ground, and that if you're all the way you're able to be able to be able to be able to see the power of a deployment system, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the power of a specific, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:09:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:44 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.511 | ppl 729.47 | bleu 21.58 | wps 4722.9 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.58
2022-03-23 12:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.58) (writing took 1.794120142236352 seconds)
2022-03-23 12:09:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:09:46 | INFO | train | epoch 018 | loss 8.413 | ppl 340.85 | wps 39291.8 | ups 1.56 | wpb 25119 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.591 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1848
KL Stats: Epoch 18 Divergences: Uniform: 1.3664747425449744 Unigram: 0.9349792092435012
2022-03-23 12:09:46 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:16 | INFO | train_inner | epoch 019:     79 / 157 loss=8.298, ppl=314.82, wps=32532.1, ups=1.27, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.567, loss_scale=4, train_wall=37, gb_free=12.2, wall=1879
2022-03-23 12:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyskyline of doha, which is probably most familiar here.
2022-03-23 12:10:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldies that are going to become the two new pigs.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs will become salt with salz and pppeer.
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:11:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are on.
2022-03-23 12:11:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:11:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the people, the number of wild animals grew up, and this is a foundation of conservation in namibia.
2022-03-23 12:11:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:11:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some bbols of magnetic field lines, but the sususulalalalal doesn't like it, because they need their energy.
2022-03-23 12:11:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face of the face and repeat it through the entire information, which is the entire information, and all of this reflection.
2022-03-23 12:11:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was interesting, and measure for me here at tedwomen, is that [[[[[[[[[[[[[[[["'' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '[[[[[[[[[[[[[[[[' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '
2022-03-23 12:11:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother was still the invention of invention, and a big part of the design work on our airplane was a result that we had to solve the unique problems that were interconnected to the ground -- everything that we had to be connected to the ground -- and a large part of the ground, which is that if you're going to see the ririridge, or a ridge, or to see that we're going to see the ridge the greenground, it's all the united states in the ridge, it's all the rivers of the riggarbarbage of the greenground, or to see that we're going to see that we're going to see that we're going to be a fufufufufufufufueleleling the ririridge, or to be connected to be a ridge, or the ridge, or the ground, or to be a ridge, it's all the united states, it's all the united states, it was to be connected to
2022-03-23 12:11:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:23 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.523 | ppl 735.81 | bleu 21.03 | wps 4754.8 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.58
2022-03-23 12:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 19 @ 2978 updates, score 21.03) (writing took 0.8687395919114351 seconds)
2022-03-23 12:11:24 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:11:24 | INFO | train | epoch 019 | loss 8.281 | ppl 310.95 | wps 40081.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.578 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1947
KL Stats: Epoch 19 Divergences: Uniform: 1.3821189812696546 Unigram: 0.9505560562502428
2022-03-23 12:11:25 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:33 | INFO | train_inner | epoch 020:     22 / 157 loss=8.259, ppl=306.25, wps=32308.7, ups=1.3, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.572, loss_scale=4, train_wall=36, gb_free=12.8, wall=1956
2022-03-23 12:12:11 | INFO | train_inner | epoch 020:    122 / 157 loss=8.093, ppl=273.02, wps=67970.2, ups=2.63, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.497, loss_scale=4, train_wall=38, gb_free=11.8, wall=1994
2022-03-23 12:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:12:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably knows most of the most familiar here.
2022-03-23 12:12:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks.
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are going to be involved with salsalz and pin.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a couple of electrodes on his head and understand what all his thoughts are on the road.
2022-03-23 12:12:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, as people took responsibility for the wild animals, the number of wild animals grew up, and this is a foundation of conservation in namibia.
2022-03-23 12:12:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, there are some of magnetic field lines in the inside the inner lines, but the susuicide doesn't like that if they're moving, they need their energy movements, and the superconductive disorders of magnetic field.
2022-03-23 12:12:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional facial facial of the face of the real face, and the basic shape of the information, and it gives him the whole structure of this reflection, which is the whole structure of this reflection and fold the whole structure and fold the whole structure.
2022-03-23 12:12:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure, for me to be here at tedwomen, is that... "yes, when someone was in the best time," someone said, "the men who said," the men in a table, "the men who are doing it interesting and measure it interesting," and if we're going to support them, "if we've been supported to support you,"
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily is still the mother of invention, and a big part of the design work that we're in our airplane, or a result of it was a unique problem that we had to solve the unique problems that were connected to the ground -- the mother of invention of the invention of the invention of the invention of the invention of the invention of the invention of the invention, and a lot of design, and a big part of design work, and a big part of design of design work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to put it, or a huge part of a remove it, or a remove it, or a, or a, or a huge part of the decrease that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 12:13:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:04 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.413 | ppl 681.61 | bleu 23.67 | wps 4467.9 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.67
2022-03-23 12:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:13:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.67) (writing took 1.758856421802193 seconds)
2022-03-23 12:13:06 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:13:06 | INFO | train | epoch 020 | loss 8.168 | ppl 287.71 | wps 38852.1 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.538 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2048
KL Stats: Epoch 20 Divergences: Uniform: 1.392190156387438 Unigram: 0.9590193172585099
2022-03-23 12:13:06 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:13:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:31 | INFO | train_inner | epoch 021:     65 / 157 loss=8.066, ppl=268.03, wps=31246.8, ups=1.26, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.563, loss_scale=4, train_wall=36, gb_free=12, wall=2073
2022-03-23 12:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic.
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks.
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:14:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:14:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:14:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a couple of electrodes on his head, and understand exactly what all his thoughts are on the road.
2022-03-23 12:14:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:14:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild animals, the number of wild animals grew back, and this is a foundation of conservation in namibia.
2022-03-23 12:14:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bars of magnetic fields are caught in the inner field, but the suouter eggs may not like it, if they move to move, they need their energy, and so the superconductive disorders.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape, and it gives him to the information, which is the whole structure and fold.
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting, for me to be here at tedwomen, is that...
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of invention is still the invention, and a big part of the design work that we're in the plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation, and that allows us to be able to use a refrigering system, or to see that's a refrigergergergerator, and that allows us to be able to use the propelled.
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:44 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.301 | ppl 630.7 | bleu 24.63 | wps 4675.2 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.63
2022-03-23 12:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.63) (writing took 1.8109946041367948 seconds)
2022-03-23 12:14:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:14:46 | INFO | train | epoch 021 | loss 8.089 | ppl 272.36 | wps 39628 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.539 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2148
KL Stats: Epoch 21 Divergences: Uniform: 1.4025793548151038 Unigram: 0.9649023028545222
2022-03-23 12:14:46 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:49 | INFO | train_inner | epoch 022:      8 / 157 loss=8.196, ppl=293.19, wps=31610.9, ups=1.28, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.541, loss_scale=4, train_wall=37, gb_free=12, wall=2152
2022-03-23 12:15:26 | INFO | train_inner | epoch 022:    108 / 157 loss=8.109, ppl=276.11, wps=66123.1, ups=2.68, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.553, loss_scale=4, train_wall=37, gb_free=12, wall=2189
2022-03-23 12:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:15:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:15:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:15:56 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:15:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:16:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz.
2022-03-23 12:16:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:16:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding what all his thoughts are on the track.
2022-03-23 12:16:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:16:07 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of how people took responsibility for the wild animals, and this is a foundation for conservation.
2022-03-23 12:16:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:16:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field, but the suconductor may not like it when they're moving, and so the suicide disorder.
2022-03-23 12:16:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which gives the big constructions of the face.
2022-03-23 12:16:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen, is that... "well, you know, you know, you know, you know, you know, you know, you know, you know, you know," and then you know, you know, you know, you know, you know, you know, you know, you know, you know, "
2022-03-23 12:16:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our plane, was a result that we had to solve the unique problems that were connected to the ground so that we had to be connected to the mother of the ground, and it would be connected to the ground -- and it allows us to be a refrigerators, or if you can use it to use it to use the air, or if you can use it to use it to use it.
2022-03-23 12:16:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:21 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.291 | ppl 626.33 | bleu 22.99 | wps 5121.4 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.63
2022-03-23 12:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:16:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 22.99) (writing took 0.7900485629215837 seconds)
2022-03-23 12:16:21 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:16:21 | INFO | train | epoch 022 | loss 8.019 | ppl 259.44 | wps 41281.3 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.517 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2244
KL Stats: Epoch 22 Divergences: Uniform: 1.409548492193033 Unigram: 0.9707869703060658
2022-03-23 12:16:22 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:41 | INFO | train_inner | epoch 023:     51 / 157 loss=7.971, ppl=250.94, wps=34195.3, ups=1.34, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.441, loss_scale=4, train_wall=37, gb_free=11.9, wall=2263
2022-03-23 12:17:18 | INFO | train_inner | epoch 023:    151 / 157 loss=7.813, ppl=224.88, wps=68157, ups=2.68, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.489, loss_scale=4, train_wall=37, gb_free=11.9, wall=2301
2022-03-23 12:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:24 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic.
2022-03-23 12:17:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:17:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:17:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:17:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pbump.
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand what all his thoughts are on the track.
2022-03-23 12:17:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back. and this is a basis for conservation in namibia.
2022-03-23 12:17:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:48 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines are caught in the inner, but the superconductor doesn't like it when they move, they need their energy, and so the superconductive disorder.
2022-03-23 12:17:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:53 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, which is the big consequence of the face and the basic basic constructions of the real face, and through the fundamental information that gives it back, and through the top of this reflection.
2022-03-23 12:17:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me here at tedwomen, is that... tall, in the strike dinner dinner, it was the best time when someone said, "turn you to the men on a table," turn you on a table and say, "turn it up to you on a table."
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that we had to be unique problems that we had to be connected to the ground, so that we were connected to the ground, so that it was connected to a continuous, and it's all of a continuous, or that it's all of a lot of refrigeration, to be able to be able to use it.
2022-03-23 12:18:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:00 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.263 | ppl 614.46 | bleu 25.5 | wps 4645.8 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.5
2022-03-23 12:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.5) (writing took 1.7626855811104178 seconds)
2022-03-23 12:18:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:18:01 | INFO | train | epoch 023 | loss 7.925 | ppl 243.11 | wps 39441.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.473 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2344
KL Stats: Epoch 23 Divergences: Uniform: 1.408954343674926 Unigram: 0.9769269783677825
2022-03-23 12:18:02 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:37 | INFO | train_inner | epoch 024:     94 / 157 loss=7.951, ppl=247.52, wps=31591.1, ups=1.27, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.471, loss_scale=4, train_wall=37, gb_free=11.9, wall=2380
2022-03-23 12:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:19:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:19:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:19:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:19:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks.
2022-03-23 12:19:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:19:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pure.
2022-03-23 12:19:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:19:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand what all of your thoughts are on the track.
2022-03-23 12:19:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:19:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people as the responsibility for the wild, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 12:19:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field lines in the inside, but the superconductor may not like if they move, because their movements need their energy, and so the superconducting disorders.
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection of the face and the basic form, and through the theft of information, which refers all the ports.
2022-03-23 12:19:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured to me here at tedwomen is that... tyes, in the striking dinner, when someone said, "turn you on a table and say," if the revolution starts to support you. "
2022-03-23 12:19:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continually variable system that allows us to refrigerate, or that if you look at the aircraft.
2022-03-23 12:19:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:36 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.133 | ppl 561.45 | bleu 27.36 | wps 5097.7 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.36
2022-03-23 12:19:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:19:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.36) (writing took 1.8053411273285747 seconds)
2022-03-23 12:19:38 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:19:38 | INFO | train | epoch 024 | loss 7.869 | ppl 233.7 | wps 40800.7 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.441 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2441
KL Stats: Epoch 24 Divergences: Uniform: 1.4146302735040017 Unigram: 0.9819656359535645
2022-03-23 12:19:39 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:53 | INFO | train_inner | epoch 025:     37 / 157 loss=7.739, ppl=213.62, wps=33742.7, ups=1.32, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.411, loss_scale=4, train_wall=37, gb_free=12.1, wall=2455
2022-03-23 12:20:30 | INFO | train_inner | epoch 025:    137 / 157 loss=7.838, ppl=228.87, wps=66885.3, ups=2.67, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.453, loss_scale=4, train_wall=37, gb_free=12, wall=2493
2022-03-23 12:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:20:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 12:20:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:20:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigments.
2022-03-23 12:20:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:20:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:21:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:21:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:21:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field lines in the inside, but the supraleiter may not like it when they move, and so the superconductor disorders of magnetic field may not be caught in the inner, but the superconductor may not like it.
2022-03-23 12:21:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which is the big configurations of the face and the basic information that includes the whole porter structure and fold a fold.
2022-03-23 12:21:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured for me here at tedwomen, is that... well, when someone said, "turn you to a table and tell you," if the revolution starts supporting you. "
2022-03-23 12:21:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane, was a result that we had to operate it on the ground -- everything from a continually variable system that allows us to do with a continuously variable and liquid system that allows us to use it in the air, and we're going to use it.
2022-03-23 12:21:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:14 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.148 | ppl 567.46 | bleu 27.23 | wps 4923.6 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.36
2022-03-23 12:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:21:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.23) (writing took 0.7797647654078901 seconds)
2022-03-23 12:21:15 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:21:15 | INFO | train | epoch 025 | loss 7.811 | ppl 224.63 | wps 40709.5 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.447 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2538
KL Stats: Epoch 25 Divergences: Uniform: 1.417654388528311 Unigram: 0.9856988203973643
2022-03-23 12:21:16 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:46 | INFO | train_inner | epoch 026:     80 / 157 loss=7.7, ppl=207.89, wps=33536.1, ups=1.32, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.415, loss_scale=4, train_wall=37, gb_free=12.2, wall=2568
2022-03-23 12:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:22:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:22:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:22:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:22:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature, people like the responsibility for wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the bands of magnetic fields are caught in the inner, but the superconductor doesn't like when they move, because they use their movements, and so the superconductor disorder.
2022-03-23 12:22:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constraints of the face and the basic shape, and through the one of the information that refers the whole portural structure and all the folds.
2022-03-23 12:22:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... well, in the dinner dinner, it was best summarized when someone said, "turn to the men in your table and tell you," if the revolution starts to support you. "'" the truth is that we've already been supported with you for a long time. "
2022-03-23 12:22:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to operate in the ground -- everything that was connected to a continuous variation and a refrigerator system that allows us to use a refrigerator in the aircraft, to be, or to be able to be able to be able to use the aircraft.
2022-03-23 12:22:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:53 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.002 | ppl 512.69 | bleu 29.76 | wps 4737 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.76
2022-03-23 12:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.76) (writing took 1.7979439990594983 seconds)
2022-03-23 12:22:55 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:22:55 | INFO | train | epoch 026 | loss 7.745 | ppl 214.51 | wps 39704.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.411 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2637
KL Stats: Epoch 26 Divergences: Uniform: 1.4169080631738278 Unigram: 0.9875511059815675
2022-03-23 12:22:55 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:22:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:04 | INFO | train_inner | epoch 027:     23 / 157 loss=7.781, ppl=219.97, wps=31987.5, ups=1.28, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.431, loss_scale=4, train_wall=37, gb_free=12.9, wall=2646
2022-03-23 12:23:41 | INFO | train_inner | epoch 027:    123 / 157 loss=7.721, ppl=210.98, wps=67010.2, ups=2.68, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.414, loss_scale=4, train_wall=37, gb_free=11.7, wall=2684
2022-03-23 12:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know here.
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transformed two new pigs.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:24:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:24:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:24:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife grew again. and that's become a foundation for conservation in namibia.
2022-03-23 12:24:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:24:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inside, but the superconductor may not be able to move because your energy movements are, and so the superconducting disorder.
2022-03-23 12:24:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that gives the big constraints of the face and restores the basic shape, and through the one of the ports structure and all the folds.
2022-03-23 12:24:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when dinner was the best summit when someone said, "turn you to your table and tell you," when the revolution begins, we're supporting you for a long time, "and then we're supporting."
2022-03-23 12:24:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane at the stumber toes, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation and a refrigerating system that allows us to be able to see, or if you can see the trajectory of an aircraft, or if you're going to the car, you're going to be able to be able to be able to see the engine, you're able to use it, you're either, you're able to use it, you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:24:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.994 | ppl 509.91 | bleu 29.66 | wps 4786 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.76
2022-03-23 12:24:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:24:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.66) (writing took 0.7882022187113762 seconds)
2022-03-23 12:24:33 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:24:33 | INFO | train | epoch 027 | loss 7.703 | ppl 208.35 | wps 40323.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.415 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2735
KL Stats: Epoch 27 Divergences: Uniform: 1.4204567946317415 Unigram: 0.992055787097464
2022-03-23 12:24:33 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:24:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:58 | INFO | train_inner | epoch 028:     66 / 157 loss=7.719, ppl=210.69, wps=32620.7, ups=1.31, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.391, loss_scale=4, train_wall=37, gb_free=12.8, wall=2760
2022-03-23 12:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:25:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 12:25:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that become two new pigs.
2022-03-23 12:25:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:25:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:25:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:25:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:25:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, the number of wildlife animals grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:25:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:25:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like if you move, because your energy movements use, and so the superconducting disorder.
2022-03-23 12:25:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that gives the big constructions of the face and restores the basic shape, and through the one of the information that pulls the whole por-structure and all the folds.
2022-03-23 12:26:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to your men on your table and say," if the revolution starts to support you. '"the truth is that we've already been supporting you for a long time, we've already started with silly."
2022-03-23 12:26:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane at the stest toe, was a result that we had to solve the unique problems that were connected to operating it on the ground -- all from a continuous variation and a refrigeration system that allows us to use a ridge in the aircraft, or if you can either be able, or if you can see the aircraft, or if you can see the most specific, or if you can see the aircraft, or if you can either, or the aircraft, or you can see the aircraft, or if you can use it's a mechanism, you can use it's a mechanism, or if you can use it's the aircraft, or if you can use it's a mechanism, or if you can either, you can see the aircraft, or if you can use it's a mechanism, or if you can see the most specific, you can see the
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:09 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.945 | ppl 492.98 | bleu 30.41 | wps 4809.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.41
2022-03-23 12:26:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:26:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:26:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.41) (writing took 1.7712476700544357 seconds)
2022-03-23 12:26:11 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:26:11 | INFO | train | epoch 028 | loss 7.654 | ppl 201.41 | wps 40082.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.402 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2834
KL Stats: Epoch 28 Divergences: Uniform: 1.4194858623963003 Unigram: 0.9927624083546449
2022-03-23 12:26:12 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:26:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:15 | INFO | train_inner | epoch 029:      9 / 157 loss=7.614, ppl=195.9, wps=32671.6, ups=1.3, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.423, loss_scale=4, train_wall=37, gb_free=11.8, wall=2837
2022-03-23 12:26:52 | INFO | train_inner | epoch 029:    109 / 157 loss=7.638, ppl=199.12, wps=66985.5, ups=2.66, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.389, loss_scale=4, train_wall=37, gb_free=11.7, wall=2875
2022-03-23 12:27:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:14 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:27:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:27:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:27:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:27:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and psuitcase.
2022-03-23 12:27:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:27:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the mainframe of people as the responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:27:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like when they move, and so the superconductor disorder.
2022-03-23 12:27:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:43 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic form of information that draws the whole porting structure and all the floods.
2022-03-23 12:27:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tyes, when congestion, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution starts to support you. "'" the truth is that we've been supporting you for a long time, "
2022-03-23 12:27:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are on our plane at the stumbling toes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft to use, or if you can see the promoting, or when you can see the promoting mechanism, it's either of a mechanism, it's all of a mechanism, it's all of a mechanism, it's all, it's all, it's all, it's all, it's all of us to make a mechanism that if you can use of us.
2022-03-23 12:27:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:49 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.923 | ppl 485.34 | bleu 30.75 | wps 4702.8 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.75
2022-03-23 12:27:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:27:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.75) (writing took 1.8274326799437404 seconds)
2022-03-23 12:27:51 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:27:51 | INFO | train | epoch 029 | loss 7.609 | ppl 195.25 | wps 39519.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.395 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2934
KL Stats: Epoch 29 Divergences: Uniform: 1.418723640273816 Unigram: 0.9963874120495291
2022-03-23 12:27:51 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:27:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:11 | INFO | train_inner | epoch 030:     52 / 157 loss=7.615, ppl=196, wps=31849.6, ups=1.27, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.374, loss_scale=4, train_wall=37, gb_free=12.1, wall=2954
2022-03-23 12:28:48 | INFO | train_inner | epoch 030:    152 / 157 loss=7.537, ppl=185.76, wps=68116.7, ups=2.69, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.338, loss_scale=4, train_wall=37, gb_free=12.9, wall=2991
2022-03-23 12:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:54 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:28:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:28:58 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most of you know here.
2022-03-23 12:28:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will be transmitted two new pigs.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:29:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:29:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the, like people's responsibility for the wild, the number of wildlife animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements are using energy, and the superconducting disorder.
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constraints of the face and the basic shape, and we recover it through this one that refers the entire por-structure and all the folds.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when dinner dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," the truth is that we've already been supporting you for a long time. "
2022-03-23 12:29:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system that allows us to use in the aircraft to a particular basis.
2022-03-23 12:29:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:26 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.886 | ppl 472.98 | bleu 30.93 | wps 5038.8 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.93
2022-03-23 12:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:29:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.93) (writing took 1.8629799033515155 seconds)
2022-03-23 12:29:28 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:29:28 | INFO | train | epoch 030 | loss 7.561 | ppl 188.84 | wps 40635.4 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.349 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3031
KL Stats: Epoch 30 Divergences: Uniform: 1.418512647999456 Unigram: 0.998747496087537
2022-03-23 12:29:29 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:05 | INFO | train_inner | epoch 031:     95 / 157 loss=7.481, ppl=178.71, wps=33445.1, ups=1.31, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.374, loss_scale=4, train_wall=37, gb_free=11.7, wall=3067
2022-03-23 12:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:30:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:30:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will be transmitted two new pigs.
2022-03-23 12:30:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppepper.
2022-03-23 12:30:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:30:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:30:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:30:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:30:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and restores the basic shape, and the one of those information that refers the whole por-structure and all the fits.
2022-03-23 12:30:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... tja, when dinner was the best summarized when someone said, "turn it to the men on your table and tell you," 'if the revolution begins, then we support you. "' the truth is that we've already started to support you for a long time with sil."
2022-03-23 12:31:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane at the stump, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use in the aircraft, or if you look at the
2022-03-23 12:31:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.871 | ppl 468.18 | bleu 31.46 | wps 4908.4 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.46
2022-03-23 12:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:31:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.46) (writing took 1.8399120438843966 seconds)
2022-03-23 12:31:06 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:31:06 | INFO | train | epoch 031 | loss 7.541 | ppl 186.24 | wps 40262.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.375 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3129
KL Stats: Epoch 31 Divergences: Uniform: 1.4190385652070485 Unigram: 1.0009589262791487
2022-03-23 12:31:07 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:21 | INFO | train_inner | epoch 032:     38 / 157 loss=7.562, ppl=189.03, wps=32478.1, ups=1.3, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.346, loss_scale=4, train_wall=37, gb_free=12.5, wall=3144
2022-03-23 12:31:59 | INFO | train_inner | epoch 032:    138 / 157 loss=7.452, ppl=175.15, wps=67454.8, ups=2.67, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.371, loss_scale=4, train_wall=37, gb_free=12.5, wall=3181
2022-03-23 12:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:32:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:32:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:32:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:32:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:32:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and ppepper.
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:32:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:32:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people responsibility for wildlife, the number of wildlife animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements are using energy, and that's how the superconducting disorder is.
2022-03-23 12:32:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restore the big constructions of the face and the basic shape, and through the one that refers the whole por-structure and all the fine.
2022-03-23 12:32:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when somebody said, "turn on the men on your table and tell them," when the revolution begins, we support you. "the truth is that we have already supported you."
2022-03-23 12:32:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the aircraft, or gosh, until you see, or if you see, to use a specifications, or if you look at a particular mechanism, until you see the air, until you see, you see, until you see, you see, until you see, you see, until you see, you see, you see, you see, and you see, you can see, you see, and you see, you can see, you can see, and you can see, and you can see, you can see, you can see, in the air, you can see, you can see, you can see, and you can see, and you can see, and you can see,
2022-03-23 12:32:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:43 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.883 | ppl 472.27 | bleu 31.32 | wps 4808.5 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.46
2022-03-23 12:32:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:32:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.32) (writing took 0.7534018871374428 seconds)
2022-03-23 12:32:44 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:32:44 | INFO | train | epoch 032 | loss 7.496 | ppl 180.57 | wps 40388.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.353 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3227
KL Stats: Epoch 32 Divergences: Uniform: 1.419173430722559 Unigram: 1.0066746994911302
2022-03-23 12:32:44 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:15 | INFO | train_inner | epoch 033:     81 / 157 loss=7.482, ppl=178.79, wps=32807.3, ups=1.31, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.355, loss_scale=4, train_wall=36, gb_free=12.1, wall=3258
2022-03-23 12:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks to create the two new pigs.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people have been responsibility for the wildlife, the number of wildlife grew back, and this has become a foundation for conservation in namibia.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle lines of magnetic field are caught inside, but the superconductor may not be able to move because their movements use energy, and so the superconductor disorders.
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and recover the basic shape, and recover it through the one of the information that refers the whole por-structure and all the fits.
2022-03-23 12:34:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time,"
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the go-and gosh, until you drive, or if you look at the promoting, you're going to do it, you're going to do it, you're going to do it, you're going to do it.
2022-03-23 12:34:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:23 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.814 | ppl 449.91 | bleu 32.46 | wps 4676.9 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.46
2022-03-23 12:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:34:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.46) (writing took 1.7433453118428588 seconds)
2022-03-23 12:34:25 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:34:25 | INFO | train | epoch 033 | loss 7.47 | ppl 177.32 | wps 39300.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.349 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3327
KL Stats: Epoch 33 Divergences: Uniform: 1.4190918491845077 Unigram: 1.0060189873003655
2022-03-23 12:34:25 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:34 | INFO | train_inner | epoch 034:     24 / 157 loss=7.495, ppl=180.34, wps=31775.3, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.355, loss_scale=4, train_wall=37, gb_free=12, wall=3337
2022-03-23 12:35:12 | INFO | train_inner | epoch 034:    124 / 157 loss=7.443, ppl=173.96, wps=66836.8, ups=2.66, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.336, loss_scale=4, train_wall=37, gb_free=11.8, wall=3374
2022-03-23 12:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:35:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:35:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend the two new pigs.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:35:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people's responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 12:35:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and the superconductor of the superconductor.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constraints of the face and restores the basic shape of the face, and by the one that refuses the whole porn structure and all the folds.
2022-03-23 12:35:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn you to your table and tell you, 'if the revolution begins, we support you.'" the truth is that we've already started supporting you for this topic for a long time with ra. "
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the most proud part of the design work that we are on our plane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable version of the design work, and a cooling system that allows us to stop using a liquid aircraft in the aircraft, or whether we're going to be able to be able to be able to use the most specialize in the case that we're going to be able to be able
2022-03-23 12:36:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:03 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.819 | ppl 451.55 | bleu 32.57 | wps 4612.2 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.57
2022-03-23 12:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:36:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:36:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.57) (writing took 1.7788609531708062 seconds)
2022-03-23 12:36:05 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:36:05 | INFO | train | epoch 034 | loss 7.446 | ppl 174.34 | wps 39331.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.363 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 3427
KL Stats: Epoch 34 Divergences: Uniform: 1.4183735374786512 Unigram: 1.0055766227851204
2022-03-23 12:36:05 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:36:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:30 | INFO | train_inner | epoch 035:     67 / 157 loss=7.39, ppl=167.74, wps=32018.6, ups=1.28, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.371, loss_scale=4, train_wall=36, gb_free=12.9, wall=3453
2022-03-23 12:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:37:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:37:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people know here.
2022-03-23 12:37:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks signs that are going to be transmitted by two new pigs.
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:37:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:37:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife regrew again, and that's become a basis for conservation in namibia.
2022-03-23 12:37:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconductor disorder.
2022-03-23 12:37:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can restore the big configurations of the face and the basic shape, and by the one of the information that refers the whole por-structure and all the fine folds.
2022-03-23 12:37:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men to your table and tell you," when the revolution begins, we support you. "the truth is that we've already been supporting you for this long time with raspring."
2022-03-23 12:37:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable distribution and a refrigerator system, that allows us to use an aircraft to go to the traffic until you get specially appropriate, or when you see the propelled in the air.
2022-03-23 12:37:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:42 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.781 | ppl 440.03 | bleu 32.58 | wps 4768 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.58
2022-03-23 12:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:37:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.58) (writing took 1.8335703639313579 seconds)
2022-03-23 12:37:44 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:37:44 | INFO | train | epoch 035 | loss 7.413 | ppl 170.44 | wps 39913.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.33 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3526
KL Stats: Epoch 35 Divergences: Uniform: 1.4195292423397772 Unigram: 1.0105686057088352
2022-03-23 12:37:44 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:48 | INFO | train_inner | epoch 036:     10 / 157 loss=7.5, ppl=181.07, wps=32050.4, ups=1.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.318, loss_scale=4, train_wall=37, gb_free=12.8, wall=3531
2022-03-23 12:38:26 | INFO | train_inner | epoch 036:    110 / 157 loss=7.378, ppl=166.33, wps=67240.8, ups=2.66, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.342, loss_scale=4, train_wall=37, gb_free=12.9, wall=3568
2022-03-23 12:38:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:47 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 12:38:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:39:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:39:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:39:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 12:39:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:39:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:39:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:15 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can start with a traditional face that restores the big constraints of the face, and through the one of the information that refers the entire por-structure and all the folds.
2022-03-23 12:39:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," 'if the revolution starts, we're supporting you.' "the truth is that we've been supporting you on this topic for a long time."
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our stumbling plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and a refrigerator system of refrigerator that allows us to use an aircraft in the traffic, until you're going to go to the traffic, or you're going to get rid of it, or if you're going to get rid of it, you're going to get rid of it, you're going to get rid of it, you're going to get rid of an aircraft that, you're going to get rid of it, or you're going to get rid of it, you're going to get rid of a steady or you're going to get rid of it, you're going to get rid of it, you're going to get rid of it, you know, you're going to get rid of the
2022-03-23 12:39:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:22 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.79 | ppl 442.63 | bleu 32.8 | wps 4655.2 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.8
2022-03-23 12:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.8) (writing took 1.8303677490912378 seconds)
2022-03-23 12:39:24 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:39:24 | INFO | train | epoch 036 | loss 7.394 | ppl 168.22 | wps 39559.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.345 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3626
KL Stats: Epoch 36 Divergences: Uniform: 1.4202152366088368 Unigram: 1.01125692006559
2022-03-23 12:39:24 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:44 | INFO | train_inner | epoch 037:     53 / 157 loss=7.251, ppl=152.29, wps=32624.3, ups=1.28, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.336, loss_scale=4, train_wall=36, gb_free=12.8, wall=3646
2022-03-23 12:40:21 | INFO | train_inner | epoch 037:    153 / 157 loss=7.489, ppl=179.62, wps=66703, ups=2.69, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=11.7, wall=3684
2022-03-23 12:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:26 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 12:40:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:40:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will transcend two new pigs.
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and ppepper.
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:40:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:40:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people are taking responsibility for wildlife, the number of wildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 12:40:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:40:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because they use their movements of energy, and so that's the superconductor.
2022-03-23 12:40:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructures of the face and restore the basic shape, and through the theft of information that refers the whole por-structure and all the fine folds.
2022-03-23 12:40:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men to your desk and tell them," 'when the revolution begins, we support you.' "'" the truth, women, love, is that we have supported you at this topic for a long time. "at the time," at the time, "at the time,"
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on the stump on our airplane was a result that we had to solve the unique problems that were connected to operate it on the ground -- all, from a continuously variable, and a refrigerator system with liquid fluid, that allows us to use an aircraft in the stumbellyfish traffic at the most stumber traffic, until you get to passing the most specific vehicle, to a vehicle, or when you can see it, you can see it's in the case that you can see it, to fly, to a mechanism, until you get rid of a mechanism, you can see it's in the same way that you can see it, you can see that you can see that you can see that you can see that you can see that you can see the way that you can see it in the way that you can see that you can see in the way that you can see in the
2022-03-23 12:41:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:02 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.777 | ppl 438.69 | bleu 33.44 | wps 4627 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.44
2022-03-23 12:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt
2022-03-23 12:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.44) (writing took 1.8689876799471676 seconds)
2022-03-23 12:41:04 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:41:04 | INFO | train | epoch 037 | loss 7.373 | ppl 165.75 | wps 39508.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.326 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3726
KL Stats: Epoch 37 Divergences: Uniform: 1.4215603429449466 Unigram: 1.0139628637466194
2022-03-23 12:41:04 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:40 | INFO | train_inner | epoch 038:     96 / 157 loss=7.528, ppl=184.62, wps=31190.6, ups=1.27, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.347, loss_scale=4, train_wall=37, gb_free=12.6, wall=3763
2022-03-23 12:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepses in the clinic.
2022-03-23 12:42:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:42:10 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most of you know here.
2022-03-23 12:42:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will transcend two new pigs.
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:42:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pepper.
2022-03-23 12:42:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:42:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 12:42:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:42:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people are responsible for wildlife, the number of wildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 12:42:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:42:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and restore the basic shape, and through the one that refers the whole por-structure and all the fine folds.
2022-03-23 12:42:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men to your desk and tell you," well, if the revolution begins, we support you, 'the truth is that we've already supported you in this topic for a long time with rachel carria's "] ["] ["]
2022-03-23 12:42:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our plane the most stumbling was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable system of refrigeration that allows us to use an aircraft in the go-traffic to a particular passage to a vehicle vehicle vehicle, or to a particular attack, to a vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to the fall, all the way to a mechanism, all the way to an aircraft that if you see the way that you see, all the aircraft that you see in the aircraft that you see, all the aircraft, all the aircraft, all the aircraft, all the way that you can see in the way that you can see in the aircraft that you see the aircraft, all the aircraft that you see, to the aircraft, all the aircraft, all the aircraft
2022-03-23 12:42:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:41 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.758 | ppl 432.88 | bleu 32.72 | wps 4737.8 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.44
2022-03-23 12:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.72) (writing took 0.7636008467525244 seconds)
2022-03-23 12:42:42 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:42:42 | INFO | train | epoch 038 | loss 7.359 | ppl 164.17 | wps 40247.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.339 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3824
KL Stats: Epoch 38 Divergences: Uniform: 1.4202208091379533 Unigram: 1.0144101475379335
2022-03-23 12:42:42 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:57 | INFO | train_inner | epoch 039:     39 / 157 loss=7.105, ppl=137.69, wps=33826.1, ups=1.3, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.299, loss_scale=4, train_wall=37, gb_free=11.8, wall=3840
2022-03-23 12:43:35 | INFO | train_inner | epoch 039:    139 / 157 loss=7.392, ppl=167.97, wps=66661.1, ups=2.68, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.358, loss_scale=4, train_wall=37, gb_free=12.8, wall=3877
2022-03-23 12:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:43:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:43:49 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most people know here.
2022-03-23 12:43:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:43:53 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that are going to overwrite two new pigs.
2022-03-23 12:43:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:43:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and peppepper.
2022-03-23 12:43:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:44:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:44:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:44:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again, and that's become a foundation for conservation in namibia.
2022-03-23 12:44:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:13 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and restores the basic shape, and then we add it through the theft of the information that pulls the whole por-structure and all the fine folds.
2022-03-23 12:44:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and interesting to be measured for me here at tedwomen is that... well, when i was striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," let's support you. "the truth, women, love, is that we've been supporting you in this topic for a long time."
2022-03-23 12:44:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of the design work that we're on our plane the stumbling toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable system of refrigeration and a refrigeration that allows us to use an aircraft in the go-and traffic aircraft, until a particular vehicle, or a vehicle, or a promoting machine, all the way to the most, to the most, to the engine that we could be able, to the most, to the most, to the most, to the promotable, to the progression, to the most, to the progressive, to the most, to the progressive, to the most, to the most, to the most, to the progressive, to the decrease, to the most, to the most, to the most, to the most, to the most, to the progressive
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:20 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.751 | ppl 430.79 | bleu 33.3 | wps 4679.2 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.44
2022-03-23 12:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:44:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 39 @ 6118 updates, score 33.3) (writing took 0.8313048169948161 seconds)
2022-03-23 12:44:21 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:44:21 | INFO | train | epoch 039 | loss 7.334 | ppl 161.29 | wps 40002.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.329 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3923
KL Stats: Epoch 39 Divergences: Uniform: 1.4208531093536767 Unigram: 1.01663831444694
2022-03-23 12:44:21 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:52 | INFO | train_inner | epoch 040:     82 / 157 loss=7.399, ppl=168.73, wps=32055.5, ups=1.29, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.304, loss_scale=4, train_wall=37, gb_free=12.2, wall=3954
2022-03-23 12:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:24 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepses in the clinic.
2022-03-23 12:45:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:27 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most people know here.
2022-03-23 12:45:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 12:45:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:45:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people are responsible for wildlife revenues, the number of wildlife grew again, and that's become a foundation for conservation in namibia.
2022-03-23 12:45:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:45:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like the superconductor if they move, because their movements use energy, and the superconductor disorders.
2022-03-23 12:45:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional face can that restores the big configurations of the face and restore the basic shape, and we add it through the one of the information that refers the whole por-structure and all the fine folds.
2022-03-23 12:45:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, the dinner was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. 'the truth is that we've been supporting you for this topic for a long time. "at carel sil
2022-03-23 12:45:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work we're on on on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable operating and a refrigerator system that allows us to use an aircraft in the go-traffic until a particular passage that is either the propelled to the ground, or if you're flying, it's the aircraft, to the aircraft, to be a mechanism, to the aircraft, to the aircraft, to the aircraft, until you're going to be the aircraft, to be the aircraft, to be the aircraft, to be the aircraft, until you're driving, until the aircraft, until you're going to be the aircraft, to be the aircraft, until the aircraft, until you're driving, until the aircraft, or if you're driving, until the aircraft, until you're going to be
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:58 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.751 | ppl 430.72 | bleu 33.38 | wps 4808.6 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.44
2022-03-23 12:45:58 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.38) (writing took 0.7754488582722843 seconds)
2022-03-23 12:45:58 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:45:58 | INFO | train | epoch 040 | loss 7.311 | ppl 158.77 | wps 40371.8 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.314 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4021
2022-03-23 12:45:58 | INFO | fairseq_cli.train | done training in 4020.5 seconds
