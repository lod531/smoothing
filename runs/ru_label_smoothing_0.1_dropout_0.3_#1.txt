Sender: LSF System <lsfadmin@eu-g2-07>
Subject: Job 208068417: <ru_label_smoothing_0.1_dropout_0.3_#1> in cluster <euler> Done

Job <ru_label_smoothing_0.1_dropout_0.3_#1> was submitted from host <eu-login-45> by user <andriusb> in cluster <euler> at Sun Mar 13 12:01:43 2022
Job was executed on host(s) <eu-g2-07>, in queue <gpu.120h>, as user <andriusb> in cluster <euler> at Sun Mar 13 12:02:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 13 12:02:15 2022
Terminated at Mon Mar 14 04:41:25 2022
Results reported at Mon Mar 14 04:41:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/ru --save-dir /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.3 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --patience 3 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   63486.37 sec.
    Max Memory :                                 3709 MB
    Average Memory :                             2806.35 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16291.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   59949 sec.
    Turnaround time :                            59982 sec.

The output (if any) follows:

2022-03-13 12:02:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.3, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ru', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-13 12:02:20 | INFO | fairseq.tasks.language_modeling | dictionary: 35920 types
2022-03-13 12:02:21 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=35920, bias=False)
  )
)
2022-03-13 12:02:21 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-13 12:02:21 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-13 12:02:21 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-13 12:02:21 | INFO | fairseq_cli.train | num. shared model params: 37,305,344 (num. trained: 37,305,344)
2022-03-13 12:02:21 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-13 12:02:21 | INFO | fairseq.data.data_utils | loaded 2,558 examples from: data-bin/ru/valid
2022-03-13 12:02:24 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-13 12:02:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:02:24 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-13 12:02:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:02:24 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-13 12:02:24 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-13 12:02:24 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:02:24 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:02:24 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-13 12:02:24 | INFO | fairseq.data.data_utils | loaded 53,136 examples from: data-bin/ru/train
2022-03-13 12:02:24 | INFO | fairseq.trainer | begin training epoch 1
2022-03-13 12:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:02:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-13 12:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:02:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 12:02:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 12:06:21 | INFO | train_inner | epoch 001:    104 / 407 loss=14.924, nll_loss=14.815, ppl=28833, wps=29760.3, ups=0.45, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=2.019, loss_scale=8, train_wall=212, gb_free=9.7, wall=237
2022-03-13 12:10:01 | INFO | train_inner | epoch 001:    204 / 407 loss=13.573, nll_loss=13.321, ppl=10231.9, wps=29830.7, ups=0.46, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=0.582, loss_scale=16, train_wall=196, gb_free=9.7, wall=456
2022-03-13 12:13:41 | INFO | train_inner | epoch 001:    304 / 407 loss=12.789, nll_loss=12.435, ppl=5538, wps=29730.5, ups=0.45, wpb=65536, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=0.362, loss_scale=32, train_wall=197, gb_free=9.7, wall=677
2022-03-13 12:17:24 | INFO | train_inner | epoch 001:    404 / 407 loss=12.416, nll_loss=11.981, ppl=4041.14, wps=29453.5, ups=0.45, wpb=65534.2, bsz=128, num_updates=400, lr=5.009e-05, gnorm=0.364, loss_scale=64, train_wall=199, gb_free=9.7, wall=899
2022-03-13 12:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:17:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.258 | nll_loss 11.782 | ppl 3521.39 | wps 51648.5 | wpb 511.9 | bsz 1 | num_updates 403
2022-03-13 12:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 403 updates
2022-03-13 12:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 1 @ 403 updates, score 12.258) (writing took 2.3398069979739375 seconds)
2022-03-13 12:17:58 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-13 12:17:58 | INFO | train | epoch 001 | loss 13.418 | nll_loss 13.13 | ppl 8961.46 | wps 28772.7 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 403 | lr 5.04649e-05 | gnorm 0.829 | loss_scale 64 | train_wall 810 | gb_free 9.7 | wall 934
2022-03-13 12:17:58 | INFO | fairseq.trainer | begin training epoch 2
2022-03-13 12:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:20:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:21:35 | INFO | train_inner | epoch 002:     98 / 407 loss=12.257, nll_loss=11.786, ppl=3530.64, wps=25984.3, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=500, lr=6.25875e-05, gnorm=0.376, loss_scale=32, train_wall=199, gb_free=9.7, wall=1151
2022-03-13 12:25:17 | INFO | train_inner | epoch 002:    198 / 407 loss=12.055, nll_loss=11.552, ppl=3002.32, wps=29480.3, ups=0.45, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.42, loss_scale=64, train_wall=199, gb_free=9.7, wall=1373
2022-03-13 12:26:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:29:01 | INFO | train_inner | epoch 002:    299 / 407 loss=11.794, nll_loss=11.251, ppl=2436.45, wps=29253.5, ups=0.45, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.442, loss_scale=32, train_wall=200, gb_free=9.7, wall=1597
2022-03-13 12:32:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:32:45 | INFO | train_inner | epoch 002:    400 / 407 loss=11.489, nll_loss=10.898, ppl=1908.05, wps=29330.7, ups=0.45, wpb=65536, bsz=128, num_updates=800, lr=0.00010008, gnorm=0.467, loss_scale=32, train_wall=200, gb_free=9.7, wall=1821
2022-03-13 12:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:33:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.13 | nll_loss 10.469 | ppl 1417.46 | wps 52033.2 | wpb 511.9 | bsz 1 | num_updates 807 | best_loss 11.13
2022-03-13 12:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 807 updates
2022-03-13 12:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 2 @ 807 updates, score 11.13) (writing took 2.2783278260030784 seconds)
2022-03-13 12:33:28 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-13 12:33:28 | INFO | train | epoch 002 | loss 11.886 | nll_loss 11.356 | ppl 2622.02 | wps 28463.9 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 807 | lr 0.000100955 | gnorm 0.427 | loss_scale 32 | train_wall 806 | gb_free 9.7 | wall 1863
2022-03-13 12:33:28 | INFO | fairseq.trainer | begin training epoch 3
2022-03-13 12:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:36:51 | INFO | train_inner | epoch 003:     93 / 407 loss=11.181, nll_loss=10.537, ppl=1485.76, wps=26540.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=900, lr=0.000112578, gnorm=0.49, loss_scale=32, train_wall=195, gb_free=9.7, wall=2067
2022-03-13 12:38:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:40:33 | INFO | train_inner | epoch 003:    194 / 407 loss=10.956, nll_loss=10.268, ppl=1233.03, wps=29479.4, ups=0.45, wpb=65536, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.466, loss_scale=32, train_wall=199, gb_free=9.7, wall=2289
2022-03-13 12:43:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:44:16 | INFO | train_inner | epoch 003:    295 / 407 loss=10.761, nll_loss=10.036, ppl=1049.61, wps=29403.1, ups=0.45, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.529, loss_scale=32, train_wall=199, gb_free=9.7, wall=2512
2022-03-13 12:47:57 | INFO | train_inner | epoch 003:    395 / 407 loss=10.58, nll_loss=9.821, ppl=904.29, wps=29700.3, ups=0.45, wpb=65536, bsz=128, num_updates=1200, lr=0.00015007, gnorm=0.548, loss_scale=32, train_wall=197, gb_free=9.7, wall=2733
2022-03-13 12:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:48:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.298 | nll_loss 9.466 | ppl 706.99 | wps 52101.6 | wpb 511.9 | bsz 1 | num_updates 1212 | best_loss 10.298
2022-03-13 12:48:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1212 updates
2022-03-13 12:48:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 3 @ 1212 updates, score 10.298) (writing took 2.6795185600058176 seconds)
2022-03-13 12:48:51 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-13 12:48:51 | INFO | train | epoch 003 | loss 10.85 | nll_loss 10.142 | ppl 1130.17 | wps 28710.3 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 1212 | lr 0.00015157 | gnorm 0.51 | loss_scale 64 | train_wall 800 | gb_free 9.7 | wall 2787
2022-03-13 12:48:51 | INFO | fairseq.trainer | begin training epoch 4
2022-03-13 12:48:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:48:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:52:08 | INFO | train_inner | epoch 004:     89 / 407 loss=10.398, nll_loss=9.606, ppl=779.28, wps=26036, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1300, lr=0.000162568, gnorm=0.572, loss_scale=32, train_wall=199, gb_free=9.7, wall=2984
2022-03-13 12:53:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:55:51 | INFO | train_inner | epoch 004:    190 / 407 loss=10.231, nll_loss=9.409, ppl=679.99, wps=29437.5, ups=0.45, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.627, loss_scale=32, train_wall=199, gb_free=9.7, wall=3206
2022-03-13 12:58:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:59:33 | INFO | train_inner | epoch 004:    291 / 407 loss=10.065, nll_loss=9.214, ppl=594.06, wps=29501.3, ups=0.45, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.606, loss_scale=32, train_wall=199, gb_free=9.7, wall=3429
2022-03-13 13:03:13 | INFO | train_inner | epoch 004:    391 / 407 loss=9.906, nll_loss=9.028, ppl=521.98, wps=29728.6, ups=0.45, wpb=65536, bsz=128, num_updates=1600, lr=0.00020006, gnorm=0.614, loss_scale=32, train_wall=197, gb_free=9.7, wall=3649
2022-03-13 13:03:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:04:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.62 | nll_loss 8.654 | ppl 402.93 | wps 52599.7 | wpb 511.9 | bsz 1 | num_updates 1615 | best_loss 9.62
2022-03-13 13:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1615 updates
2022-03-13 13:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 4 @ 1615 updates, score 9.62) (writing took 2.4051724540186115 seconds)
2022-03-13 13:04:16 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-13 13:04:16 | INFO | train | epoch 004 | loss 10.129 | nll_loss 9.289 | ppl 625.76 | wps 28534.3 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 1615 | lr 0.000201935 | gnorm 0.607 | loss_scale 32 | train_wall 802 | gb_free 9.7 | wall 3712
2022-03-13 13:04:16 | INFO | fairseq.trainer | begin training epoch 5
2022-03-13 13:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:07:24 | INFO | train_inner | epoch 005:     85 / 407 loss=9.751, nll_loss=8.845, ppl=459.91, wps=26110.3, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1700, lr=0.000212558, gnorm=0.619, loss_scale=32, train_wall=199, gb_free=9.7, wall=3899
2022-03-13 13:08:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:11:04 | INFO | train_inner | epoch 005:    186 / 407 loss=9.613, nll_loss=8.682, ppl=410.77, wps=29683.3, ups=0.45, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.65, loss_scale=32, train_wall=197, gb_free=9.7, wall=4120
2022-03-13 13:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:14:48 | INFO | train_inner | epoch 005:    287 / 407 loss=9.479, nll_loss=8.525, ppl=368.29, wps=29269.6, ups=0.45, wpb=65536, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.635, loss_scale=32, train_wall=200, gb_free=9.7, wall=4344
2022-03-13 13:18:28 | INFO | train_inner | epoch 005:    387 / 407 loss=9.37, nll_loss=8.396, ppl=336.81, wps=29777, ups=0.45, wpb=65536, bsz=128, num_updates=2000, lr=0.00025005, gnorm=0.641, loss_scale=32, train_wall=197, gb_free=9.7, wall=4564
2022-03-13 13:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:19:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.097 | nll_loss 8.026 | ppl 260.58 | wps 52902 | wpb 511.9 | bsz 1 | num_updates 2019 | best_loss 9.097
2022-03-13 13:19:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2019 updates
2022-03-13 13:19:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:19:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 5 @ 2019 updates, score 9.097) (writing took 2.4339395069982857 seconds)
2022-03-13 13:19:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-13 13:19:39 | INFO | train | epoch 005 | loss 9.531 | nll_loss 8.586 | ppl 384.17 | wps 28663.8 | ups 0.44 | wpb 65492.9 | bsz 127.9 | num_updates 2019 | lr 0.000252425 | gnorm 0.636 | loss_scale 32 | train_wall 800 | gb_free 9.7 | wall 4635
2022-03-13 13:19:40 | INFO | fairseq.trainer | begin training epoch 6
2022-03-13 13:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:22:37 | INFO | train_inner | epoch 006:     81 / 407 loss=9.236, nll_loss=8.239, ppl=302.2, wps=26280.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2100, lr=0.000262548, gnorm=0.625, loss_scale=32, train_wall=197, gb_free=9.7, wall=4813
2022-03-13 13:24:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:26:20 | INFO | train_inner | epoch 006:    182 / 407 loss=9.122, nll_loss=8.106, ppl=275.49, wps=29424.6, ups=0.45, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.635, loss_scale=32, train_wall=199, gb_free=9.7, wall=5036
2022-03-13 13:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:30:03 | INFO | train_inner | epoch 006:    283 / 407 loss=9.032, nll_loss=8, ppl=255.98, wps=29406.3, ups=0.45, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.627, loss_scale=32, train_wall=199, gb_free=9.7, wall=5258
2022-03-13 13:31:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:33:47 | INFO | train_inner | epoch 006:    384 / 407 loss=8.941, nll_loss=7.893, ppl=237.67, wps=29252.1, ups=0.45, wpb=65536, bsz=128, num_updates=2400, lr=0.00030004, gnorm=0.611, loss_scale=16, train_wall=200, gb_free=9.7, wall=5483
2022-03-13 13:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:35:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.701 | nll_loss 7.56 | ppl 188.7 | wps 51971.6 | wpb 511.9 | bsz 1 | num_updates 2423 | best_loss 8.701
2022-03-13 13:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2423 updates
2022-03-13 13:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:35:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 6 @ 2423 updates, score 8.701) (writing took 2.3398205879493617 seconds)
2022-03-13 13:35:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-13 13:35:06 | INFO | train | epoch 006 | loss 9.063 | nll_loss 8.036 | ppl 262.55 | wps 28566.1 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 2423 | lr 0.000302914 | gnorm 0.621 | loss_scale 16 | train_wall 803 | gb_free 9.7 | wall 5561
2022-03-13 13:35:06 | INFO | fairseq.trainer | begin training epoch 7
2022-03-13 13:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:37:55 | INFO | train_inner | epoch 007:     77 / 407 loss=8.83, nll_loss=7.764, ppl=217.41, wps=26301.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=2500, lr=0.000312538, gnorm=0.598, loss_scale=32, train_wall=197, gb_free=9.7, wall=5731
2022-03-13 13:40:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:41:39 | INFO | train_inner | epoch 007:    178 / 407 loss=8.765, nll_loss=7.688, ppl=206.15, wps=29346.3, ups=0.45, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.602, loss_scale=16, train_wall=200, gb_free=9.7, wall=5954
2022-03-13 13:45:21 | INFO | train_inner | epoch 007:    278 / 407 loss=8.696, nll_loss=7.608, ppl=195.04, wps=29474.5, ups=0.45, wpb=65536, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.577, loss_scale=32, train_wall=199, gb_free=9.7, wall=6177
2022-03-13 13:49:03 | INFO | train_inner | epoch 007:    378 / 407 loss=8.626, nll_loss=7.527, ppl=184.45, wps=29472, ups=0.45, wpb=65536, bsz=128, num_updates=2800, lr=0.00035003, gnorm=0.579, loss_scale=32, train_wall=199, gb_free=9.7, wall=6399
2022-03-13 13:50:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:50:32 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.417 | nll_loss 7.214 | ppl 148.49 | wps 51893.2 | wpb 511.9 | bsz 1 | num_updates 2828 | best_loss 8.417
2022-03-13 13:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2828 updates
2022-03-13 13:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 7 @ 2828 updates, score 8.417) (writing took 2.3513145339675248 seconds)
2022-03-13 13:50:35 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-13 13:50:35 | INFO | train | epoch 007 | loss 8.709 | nll_loss 7.623 | ppl 197.19 | wps 28547.9 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 2828 | lr 0.000353529 | gnorm 0.588 | loss_scale 32 | train_wall 806 | gb_free 9.7 | wall 6491
2022-03-13 13:50:35 | INFO | fairseq.trainer | begin training epoch 8
2022-03-13 13:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:50:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:53:16 | INFO | train_inner | epoch 008:     73 / 407 loss=8.53, nll_loss=7.416, ppl=170.74, wps=25905.9, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2900, lr=0.000362528, gnorm=0.571, loss_scale=16, train_wall=200, gb_free=9.7, wall=6651
2022-03-13 13:56:56 | INFO | train_inner | epoch 008:    173 / 407 loss=8.474, nll_loss=7.351, ppl=163.31, wps=29773.3, ups=0.45, wpb=65534.2, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.546, loss_scale=32, train_wall=197, gb_free=9.7, wall=6871
2022-03-13 14:00:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 14:00:38 | INFO | train_inner | epoch 008:    274 / 407 loss=8.428, nll_loss=7.297, ppl=157.31, wps=29424.3, ups=0.45, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.551, loss_scale=32, train_wall=199, gb_free=9.7, wall=7094
2022-03-13 14:00:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:04:20 | INFO | train_inner | epoch 008:    375 / 407 loss=8.377, nll_loss=7.239, ppl=151.03, wps=29553, ups=0.45, wpb=65536, bsz=128, num_updates=3200, lr=0.00040002, gnorm=0.527, loss_scale=16, train_wall=198, gb_free=9.7, wall=7316
2022-03-13 14:05:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:05:56 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.185 | nll_loss 6.947 | ppl 123.35 | wps 52949 | wpb 511.9 | bsz 1 | num_updates 3232 | best_loss 8.185
2022-03-13 14:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3232 updates
2022-03-13 14:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 8 @ 3232 updates, score 8.185) (writing took 2.6140634519979358 seconds)
2022-03-13 14:05:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-13 14:05:59 | INFO | train | epoch 008 | loss 8.434 | nll_loss 7.304 | ppl 158.06 | wps 28628.7 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 3232 | lr 0.000404019 | gnorm 0.549 | loss_scale 32 | train_wall 801 | gb_free 9.7 | wall 7415
2022-03-13 14:05:59 | INFO | fairseq.trainer | begin training epoch 9
2022-03-13 14:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:08:30 | INFO | train_inner | epoch 009:     68 / 407 loss=8.29, nll_loss=7.139, ppl=140.9, wps=26197, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=3300, lr=0.000412518, gnorm=0.546, loss_scale=32, train_wall=198, gb_free=9.7, wall=7565
2022-03-13 14:10:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:12:13 | INFO | train_inner | epoch 009:    169 / 407 loss=8.235, nll_loss=7.075, ppl=134.82, wps=29395.3, ups=0.45, wpb=65536, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.52, loss_scale=16, train_wall=199, gb_free=9.7, wall=7788
2022-03-13 14:15:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:15:55 | INFO | train_inner | epoch 009:    270 / 407 loss=8.193, nll_loss=7.026, ppl=130.36, wps=29525.1, ups=0.45, wpb=65536, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.516, loss_scale=16, train_wall=198, gb_free=9.7, wall=8010
2022-03-13 14:19:35 | INFO | train_inner | epoch 009:    370 / 407 loss=8.146, nll_loss=6.973, ppl=125.61, wps=29675.1, ups=0.45, wpb=65536, bsz=128, num_updates=3600, lr=0.00045001, gnorm=0.512, loss_scale=16, train_wall=197, gb_free=9.7, wall=8231
2022-03-13 14:20:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:21:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.952 | nll_loss 6.671 | ppl 101.88 | wps 52325.8 | wpb 511.9 | bsz 1 | num_updates 3636 | best_loss 7.952
2022-03-13 14:21:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3636 updates
2022-03-13 14:21:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 9 @ 3636 updates, score 7.952) (writing took 2.521768641017843 seconds)
2022-03-13 14:21:25 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-13 14:21:25 | INFO | train | epoch 009 | loss 8.197 | nll_loss 7.032 | ppl 130.85 | wps 28568.3 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 3636 | lr 0.000454509 | gnorm 0.519 | loss_scale 16 | train_wall 802 | gb_free 9.7 | wall 8341
2022-03-13 14:21:25 | INFO | fairseq.trainer | begin training epoch 10
2022-03-13 14:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:23:45 | INFO | train_inner | epoch 010:     64 / 407 loss=8.06, nll_loss=6.874, ppl=117.31, wps=26152.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=3700, lr=0.000462508, gnorm=0.506, loss_scale=16, train_wall=198, gb_free=9.7, wall=8481
2022-03-13 14:27:26 | INFO | train_inner | epoch 010:    164 / 407 loss=8.015, nll_loss=6.822, ppl=113.14, wps=29724, ups=0.45, wpb=65536, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.503, loss_scale=32, train_wall=197, gb_free=9.7, wall=8702
2022-03-13 14:27:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:31:10 | INFO | train_inner | epoch 010:    265 / 407 loss=7.98, nll_loss=6.782, ppl=110.05, wps=29266, ups=0.45, wpb=65536, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.491, loss_scale=16, train_wall=200, gb_free=9.7, wall=8926
2022-03-13 14:34:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:34:53 | INFO | train_inner | epoch 010:    366 / 407 loss=7.94, nll_loss=6.736, ppl=106.61, wps=29399.1, ups=0.45, wpb=65534.2, bsz=128, num_updates=4000, lr=0.0005, gnorm=0.488, loss_scale=16, train_wall=199, gb_free=9.7, wall=9148
2022-03-13 14:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:36:48 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.757 | nll_loss 6.444 | ppl 87.08 | wps 53597.7 | wpb 511.9 | bsz 1 | num_updates 4041 | best_loss 7.757
2022-03-13 14:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4041 updates
2022-03-13 14:36:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:36:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 10 @ 4041 updates, score 7.757) (writing took 2.66510087804636 seconds)
2022-03-13 14:36:51 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-13 14:36:51 | INFO | train | epoch 010 | loss 7.98 | nll_loss 6.783 | ppl 110.09 | wps 28659.1 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 4041 | lr 0.000497457 | gnorm 0.495 | loss_scale 16 | train_wall 802 | gb_free 9.7 | wall 9267
2022-03-13 14:36:51 | INFO | fairseq.trainer | begin training epoch 11
2022-03-13 14:36:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:39:00 | INFO | train_inner | epoch 011:     59 / 407 loss=7.862, nll_loss=6.647, ppl=100.25, wps=26399.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4100, lr=0.000493865, gnorm=0.491, loss_scale=16, train_wall=196, gb_free=9.7, wall=9396
2022-03-13 14:42:39 | INFO | train_inner | epoch 011:    159 / 407 loss=7.82, nll_loss=6.598, ppl=96.85, wps=29987.2, ups=0.46, wpb=65536, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.472, loss_scale=32, train_wall=195, gb_free=9.7, wall=9615
2022-03-13 14:43:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:46:22 | INFO | train_inner | epoch 011:    260 / 407 loss=7.779, nll_loss=6.551, ppl=93.77, wps=29408.9, ups=0.45, wpb=65536, bsz=128, num_updates=4300, lr=0.000482243, gnorm=0.463, loss_scale=16, train_wall=199, gb_free=9.7, wall=9837
2022-03-13 14:49:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:50:08 | INFO | train_inner | epoch 011:    361 / 407 loss=7.76, nll_loss=6.531, ppl=92.45, wps=28917.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.476, loss_scale=16, train_wall=203, gb_free=9.7, wall=10064
2022-03-13 14:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:52:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.604 | nll_loss 6.263 | ppl 76.81 | wps 52139.2 | wpb 511.9 | bsz 1 | num_updates 4446 | best_loss 7.604
2022-03-13 14:52:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4446 updates
2022-03-13 14:52:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:52:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 11 @ 4446 updates, score 7.604) (writing took 2.2034258379717357 seconds)
2022-03-13 14:52:18 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-13 14:52:18 | INFO | train | epoch 011 | loss 7.787 | nll_loss 6.561 | ppl 94.42 | wps 28589.3 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 4446 | lr 0.000474259 | gnorm 0.473 | loss_scale 16 | train_wall 804 | gb_free 9.7 | wall 10194
2022-03-13 14:52:19 | INFO | fairseq.trainer | begin training epoch 12
2022-03-13 14:52:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:54:17 | INFO | train_inner | epoch 012:     54 / 407 loss=7.693, nll_loss=6.453, ppl=87.61, wps=26325.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4500, lr=0.000471405, gnorm=0.454, loss_scale=32, train_wall=197, gb_free=9.7, wall=10312
2022-03-13 14:55:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:57:57 | INFO | train_inner | epoch 012:    155 / 407 loss=7.647, nll_loss=6.4, ppl=84.47, wps=29689.1, ups=0.45, wpb=65534.2, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.452, loss_scale=16, train_wall=197, gb_free=9.7, wall=10533
2022-03-13 15:01:37 | INFO | train_inner | epoch 012:    255 / 407 loss=7.642, nll_loss=6.395, ppl=84.16, wps=29815.8, ups=0.45, wpb=65536, bsz=128, num_updates=4700, lr=0.000461266, gnorm=0.454, loss_scale=32, train_wall=196, gb_free=9.7, wall=10753
2022-03-13 15:05:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:05:19 | INFO | train_inner | epoch 012:    356 / 407 loss=7.62, nll_loss=6.37, ppl=82.71, wps=29471.3, ups=0.45, wpb=65536, bsz=128, num_updates=4800, lr=0.000456435, gnorm=0.44, loss_scale=32, train_wall=199, gb_free=9.7, wall=10975
2022-03-13 15:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:07:35 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.503 | nll_loss 6.145 | ppl 70.74 | wps 52050.2 | wpb 511.9 | bsz 1 | num_updates 4851 | best_loss 7.503
2022-03-13 15:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4851 updates
2022-03-13 15:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:07:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 12 @ 4851 updates, score 7.503) (writing took 2.6702599250129424 seconds)
2022-03-13 15:07:38 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-13 15:07:38 | INFO | train | epoch 012 | loss 7.636 | nll_loss 6.388 | ppl 83.76 | wps 28841.6 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 4851 | lr 0.00045403 | gnorm 0.45 | loss_scale 32 | train_wall 796 | gb_free 9.7 | wall 11114
2022-03-13 15:07:38 | INFO | fairseq.trainer | begin training epoch 13
2022-03-13 15:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:09:26 | INFO | train_inner | epoch 013:     49 / 407 loss=7.573, nll_loss=6.317, ppl=79.71, wps=26499.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=4900, lr=0.000451754, gnorm=0.447, loss_scale=32, train_wall=195, gb_free=9.7, wall=11222
2022-03-13 15:10:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:13:08 | INFO | train_inner | epoch 013:    150 / 407 loss=7.529, nll_loss=6.265, ppl=76.91, wps=29528.5, ups=0.45, wpb=65534.2, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.438, loss_scale=32, train_wall=198, gb_free=9.7, wall=11444
2022-03-13 15:15:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:16:50 | INFO | train_inner | epoch 013:    251 / 407 loss=7.527, nll_loss=6.264, ppl=76.86, wps=29524, ups=0.45, wpb=65536, bsz=128, num_updates=5100, lr=0.000442807, gnorm=0.436, loss_scale=32, train_wall=198, gb_free=9.7, wall=11666
2022-03-13 15:20:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:20:32 | INFO | train_inner | epoch 013:    352 / 407 loss=7.512, nll_loss=6.247, ppl=75.97, wps=29497.2, ups=0.45, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.438, loss_scale=32, train_wall=199, gb_free=9.7, wall=11888
2022-03-13 15:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:22:59 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.416 | nll_loss 6.048 | ppl 66.15 | wps 53184.4 | wpb 511.9 | bsz 1 | num_updates 5255 | best_loss 7.416
2022-03-13 15:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5255 updates
2022-03-13 15:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 13 @ 5255 updates, score 7.416) (writing took 2.873506197996903 seconds)
2022-03-13 15:23:01 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-13 15:23:01 | INFO | train | epoch 013 | loss 7.521 | nll_loss 6.257 | ppl 76.48 | wps 28657.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 5255 | lr 0.000436228 | gnorm 0.438 | loss_scale 32 | train_wall 800 | gb_free 9.7 | wall 12037
2022-03-13 15:23:01 | INFO | fairseq.trainer | begin training epoch 14
2022-03-13 15:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:24:41 | INFO | train_inner | epoch 014:     45 / 407 loss=7.467, nll_loss=6.195, ppl=73.29, wps=26231.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=5300, lr=0.000434372, gnorm=0.437, loss_scale=32, train_wall=198, gb_free=9.7, wall=12137
2022-03-13 15:25:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:28:27 | INFO | train_inner | epoch 014:    146 / 407 loss=7.433, nll_loss=6.156, ppl=71.32, wps=29086, ups=0.44, wpb=65536, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.435, loss_scale=32, train_wall=202, gb_free=9.7, wall=12362
2022-03-13 15:30:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:32:09 | INFO | train_inner | epoch 014:    247 / 407 loss=7.434, nll_loss=6.157, ppl=71.36, wps=29470.6, ups=0.45, wpb=65536, bsz=128, num_updates=5500, lr=0.000426401, gnorm=0.432, loss_scale=32, train_wall=199, gb_free=9.7, wall=12585
2022-03-13 15:35:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:35:51 | INFO | train_inner | epoch 014:    348 / 407 loss=7.429, nll_loss=6.152, ppl=71.11, wps=29597.9, ups=0.45, wpb=65536, bsz=128, num_updates=5600, lr=0.000422577, gnorm=0.427, loss_scale=32, train_wall=198, gb_free=9.7, wall=12806
2022-03-13 15:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:38:25 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.354 | nll_loss 5.974 | ppl 62.84 | wps 52080.4 | wpb 511.9 | bsz 1 | num_updates 5659 | best_loss 7.354
2022-03-13 15:38:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5659 updates
2022-03-13 15:38:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 14 @ 5659 updates, score 7.354) (writing took 2.2200073320418596 seconds)
2022-03-13 15:38:28 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-13 15:38:28 | INFO | train | epoch 014 | loss 7.429 | nll_loss 6.152 | ppl 71.12 | wps 28565.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 5659 | lr 0.000420368 | gnorm 0.432 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 12963
2022-03-13 15:38:28 | INFO | fairseq.trainer | begin training epoch 15
2022-03-13 15:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:39:58 | INFO | train_inner | epoch 015:     41 / 407 loss=7.392, nll_loss=6.11, ppl=69.07, wps=26373.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=5700, lr=0.000418854, gnorm=0.429, loss_scale=32, train_wall=196, gb_free=9.7, wall=13054
2022-03-13 15:40:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:43:43 | INFO | train_inner | epoch 015:    142 / 407 loss=7.365, nll_loss=6.078, ppl=67.57, wps=29230.2, ups=0.45, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.429, loss_scale=32, train_wall=200, gb_free=9.7, wall=13278
2022-03-13 15:45:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:47:24 | INFO | train_inner | epoch 015:    243 / 407 loss=7.357, nll_loss=6.07, ppl=67.18, wps=29589.9, ups=0.45, wpb=65536, bsz=128, num_updates=5900, lr=0.000411693, gnorm=0.43, loss_scale=32, train_wall=198, gb_free=9.7, wall=13500
2022-03-13 15:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:51:05 | INFO | train_inner | epoch 015:    344 / 407 loss=7.35, nll_loss=6.063, ppl=66.85, wps=29593.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.426, loss_scale=32, train_wall=198, gb_free=9.7, wall=13721
2022-03-13 15:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:53:48 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 7.298 | nll_loss 5.909 | ppl 60.1 | wps 53445.1 | wpb 511.9 | bsz 1 | num_updates 6063 | best_loss 7.298
2022-03-13 15:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6063 updates
2022-03-13 15:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 15 @ 6063 updates, score 7.298) (writing took 2.4409026330104098 seconds)
2022-03-13 15:53:51 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-13 15:53:51 | INFO | train | epoch 015 | loss 7.354 | nll_loss 6.066 | ppl 67.02 | wps 28662.8 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6063 | lr 0.000406122 | gnorm 0.428 | loss_scale 32 | train_wall 800 | gb_free 9.7 | wall 13887
2022-03-13 15:53:51 | INFO | fairseq.trainer | begin training epoch 16
2022-03-13 15:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:55:12 | INFO | train_inner | epoch 016:     37 / 407 loss=7.316, nll_loss=6.023, ppl=65.01, wps=26555.8, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=6100, lr=0.000404888, gnorm=0.43, loss_scale=32, train_wall=195, gb_free=9.7, wall=13967
2022-03-13 15:55:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:58:54 | INFO | train_inner | epoch 016:    138 / 407 loss=7.292, nll_loss=5.995, ppl=63.78, wps=29531.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.427, loss_scale=32, train_wall=198, gb_free=9.7, wall=14189
2022-03-13 16:00:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:02:36 | INFO | train_inner | epoch 016:    239 / 407 loss=7.296, nll_loss=6, ppl=64.01, wps=29468.6, ups=0.45, wpb=65536, bsz=128, num_updates=6300, lr=0.00039841, gnorm=0.42, loss_scale=32, train_wall=199, gb_free=9.7, wall=14412
2022-03-13 16:04:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:06:16 | INFO | train_inner | epoch 016:    340 / 407 loss=7.286, nll_loss=5.989, ppl=63.53, wps=29740.5, ups=0.45, wpb=65536, bsz=128, num_updates=6400, lr=0.000395285, gnorm=0.428, loss_scale=32, train_wall=197, gb_free=9.7, wall=14632
2022-03-13 16:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:09:09 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.245 | nll_loss 5.851 | ppl 57.74 | wps 52032.8 | wpb 511.9 | bsz 1 | num_updates 6467 | best_loss 7.245
2022-03-13 16:09:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6467 updates
2022-03-13 16:09:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:09:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:09:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 16 @ 6467 updates, score 7.245) (writing took 2.8077084390097298 seconds)
2022-03-13 16:09:11 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-13 16:09:11 | INFO | train | epoch 016 | loss 7.29 | nll_loss 5.993 | ppl 63.68 | wps 28738.9 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6467 | lr 0.000393232 | gnorm 0.425 | loss_scale 32 | train_wall 797 | gb_free 9.7 | wall 14807
2022-03-13 16:09:12 | INFO | fairseq.trainer | begin training epoch 17
2022-03-13 16:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:10:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:10:26 | INFO | train_inner | epoch 017:     34 / 407 loss=7.27, nll_loss=5.97, ppl=62.7, wps=26175.1, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6500, lr=0.000392232, gnorm=0.422, loss_scale=32, train_wall=198, gb_free=9.7, wall=14882
2022-03-13 16:14:05 | INFO | train_inner | epoch 017:    134 / 407 loss=7.231, nll_loss=5.926, ppl=60.79, wps=29925.9, ups=0.46, wpb=65534.2, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.421, loss_scale=32, train_wall=196, gb_free=9.7, wall=15101
2022-03-13 16:14:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:17:47 | INFO | train_inner | epoch 017:    235 / 407 loss=7.235, nll_loss=5.931, ppl=60.99, wps=29525.7, ups=0.45, wpb=65536, bsz=128, num_updates=6700, lr=0.000386334, gnorm=0.424, loss_scale=32, train_wall=198, gb_free=9.7, wall=15323
2022-03-13 16:19:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:21:32 | INFO | train_inner | epoch 017:    336 / 407 loss=7.236, nll_loss=5.932, ppl=61.04, wps=29139.7, ups=0.44, wpb=65536, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.424, loss_scale=32, train_wall=201, gb_free=9.7, wall=15548
2022-03-13 16:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:24:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.205 | nll_loss 5.804 | ppl 55.86 | wps 52133.9 | wpb 511.9 | bsz 1 | num_updates 6871 | best_loss 7.205
2022-03-13 16:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6871 updates
2022-03-13 16:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 17 @ 6871 updates, score 7.205) (writing took 2.9233626059722155 seconds)
2022-03-13 16:24:36 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-13 16:24:36 | INFO | train | epoch 017 | loss 7.235 | nll_loss 5.931 | ppl 60.99 | wps 28603.7 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6871 | lr 0.000381496 | gnorm 0.424 | loss_scale 32 | train_wall 801 | gb_free 9.7 | wall 15732
2022-03-13 16:24:37 | INFO | fairseq.trainer | begin training epoch 18
2022-03-13 16:24:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:25:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:25:42 | INFO | train_inner | epoch 018:     30 / 407 loss=7.22, nll_loss=5.913, ppl=60.27, wps=26118.2, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6900, lr=0.000380693, gnorm=0.431, loss_scale=32, train_wall=198, gb_free=9.7, wall=15798
2022-03-13 16:29:21 | INFO | train_inner | epoch 018:    130 / 407 loss=7.179, nll_loss=5.866, ppl=58.31, wps=29979.5, ups=0.46, wpb=65534.2, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.421, loss_scale=32, train_wall=195, gb_free=9.7, wall=16016
2022-03-13 16:29:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:33:01 | INFO | train_inner | epoch 018:    231 / 407 loss=7.191, nll_loss=5.88, ppl=58.89, wps=29721.8, ups=0.45, wpb=65536, bsz=128, num_updates=7100, lr=0.000375293, gnorm=0.42, loss_scale=32, train_wall=197, gb_free=9.7, wall=16237
2022-03-13 16:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:36:46 | INFO | train_inner | epoch 018:    332 / 407 loss=7.189, nll_loss=5.879, ppl=58.83, wps=29161.3, ups=0.44, wpb=65536, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.426, loss_scale=32, train_wall=201, gb_free=9.7, wall=16462
2022-03-13 16:39:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:39:58 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.169 | nll_loss 5.766 | ppl 54.41 | wps 52144.8 | wpb 511.9 | bsz 1 | num_updates 7275 | best_loss 7.169
2022-03-13 16:39:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7275 updates
2022-03-13 16:39:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 18 @ 7275 updates, score 7.169) (writing took 2.720580350025557 seconds)
2022-03-13 16:40:01 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-13 16:40:01 | INFO | train | epoch 018 | loss 7.187 | nll_loss 5.876 | ppl 58.72 | wps 28621.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 7275 | lr 0.000370752 | gnorm 0.425 | loss_scale 64 | train_wall 801 | gb_free 9.7 | wall 16657
2022-03-13 16:40:01 | INFO | fairseq.trainer | begin training epoch 19
2022-03-13 16:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:40:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:40:59 | INFO | train_inner | epoch 019:     26 / 407 loss=7.183, nll_loss=5.871, ppl=58.52, wps=25834.8, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7300, lr=0.000370117, gnorm=0.428, loss_scale=32, train_wall=201, gb_free=9.7, wall=16715
2022-03-13 16:44:39 | INFO | train_inner | epoch 019:    126 / 407 loss=7.137, nll_loss=5.818, ppl=56.41, wps=29805.1, ups=0.45, wpb=65536, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.418, loss_scale=32, train_wall=196, gb_free=9.7, wall=16935
2022-03-13 16:44:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:48:20 | INFO | train_inner | epoch 019:    227 / 407 loss=7.14, nll_loss=5.822, ppl=56.56, wps=29623.7, ups=0.45, wpb=65534.2, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.422, loss_scale=32, train_wall=198, gb_free=9.7, wall=17156
2022-03-13 16:49:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:52:01 | INFO | train_inner | epoch 019:    328 / 407 loss=7.152, nll_loss=5.835, ppl=57.1, wps=29628.7, ups=0.45, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.422, loss_scale=32, train_wall=198, gb_free=9.7, wall=17377
2022-03-13 16:54:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:55:20 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.135 | nll_loss 5.729 | ppl 53.05 | wps 52542.8 | wpb 511.9 | bsz 1 | num_updates 7678 | best_loss 7.135
2022-03-13 16:55:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7678 updates
2022-03-13 16:55:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 19 @ 7678 updates, score 7.135) (writing took 2.469803334970493 seconds)
2022-03-13 16:55:22 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-13 16:55:22 | INFO | train | epoch 019 | loss 7.145 | nll_loss 5.827 | ppl 56.76 | wps 28649 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 7678 | lr 0.000360891 | gnorm 0.42 | loss_scale 32 | train_wall 798 | gb_free 9.7 | wall 17578
2022-03-13 16:55:22 | INFO | fairseq.trainer | begin training epoch 20
2022-03-13 16:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:56:11 | INFO | train_inner | epoch 020:     22 / 407 loss=7.14, nll_loss=5.822, ppl=56.56, wps=26126.7, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7700, lr=0.000360375, gnorm=0.421, loss_scale=32, train_wall=199, gb_free=9.7, wall=17627
2022-03-13 16:59:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:59:51 | INFO | train_inner | epoch 020:    123 / 407 loss=7.094, nll_loss=5.768, ppl=54.49, wps=29829, ups=0.46, wpb=65534.2, bsz=128, num_updates=7800, lr=0.000358057, gnorm=0.417, loss_scale=32, train_wall=196, gb_free=9.7, wall=17847
2022-03-13 17:03:30 | INFO | train_inner | epoch 020:    223 / 407 loss=7.112, nll_loss=5.79, ppl=55.31, wps=29895.6, ups=0.46, wpb=65536, bsz=128, num_updates=7900, lr=0.000355784, gnorm=0.425, loss_scale=32, train_wall=196, gb_free=9.7, wall=18066
2022-03-13 17:04:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:07:12 | INFO | train_inner | epoch 020:    324 / 407 loss=7.114, nll_loss=5.792, ppl=55.39, wps=29619.3, ups=0.45, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.418, loss_scale=32, train_wall=198, gb_free=9.7, wall=18287
2022-03-13 17:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:10:41 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.112 | nll_loss 5.703 | ppl 52.08 | wps 53069.9 | wpb 511.9 | bsz 1 | num_updates 8082 | best_loss 7.112
2022-03-13 17:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8082 updates
2022-03-13 17:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 20 @ 8082 updates, score 7.112) (writing took 2.247945951006841 seconds)
2022-03-13 17:10:43 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-13 17:10:43 | INFO | train | epoch 020 | loss 7.107 | nll_loss 5.784 | ppl 55.1 | wps 28729.8 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8082 | lr 0.000351755 | gnorm 0.421 | loss_scale 32 | train_wall 799 | gb_free 9.7 | wall 18499
2022-03-13 17:10:43 | INFO | fairseq.trainer | begin training epoch 21
2022-03-13 17:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:11:24 | INFO | train_inner | epoch 021:     18 / 407 loss=7.103, nll_loss=5.779, ppl=54.92, wps=25864.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=8100, lr=0.000351364, gnorm=0.424, loss_scale=32, train_wall=202, gb_free=9.7, wall=18540
2022-03-13 17:14:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:15:09 | INFO | train_inner | epoch 021:    119 / 407 loss=7.057, nll_loss=5.725, ppl=52.9, wps=29170, ups=0.45, wpb=65536, bsz=128, num_updates=8200, lr=0.000349215, gnorm=0.417, loss_scale=32, train_wall=201, gb_free=9.7, wall=18765
2022-03-13 17:18:48 | INFO | train_inner | epoch 021:    219 / 407 loss=7.079, nll_loss=5.752, ppl=53.88, wps=29877, ups=0.46, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.426, loss_scale=32, train_wall=196, gb_free=9.7, wall=18984
2022-03-13 17:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:22:26 | INFO | train_inner | epoch 021:    320 / 407 loss=7.076, nll_loss=5.748, ppl=53.75, wps=30136.1, ups=0.46, wpb=65536, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.418, loss_scale=32, train_wall=194, gb_free=9.7, wall=19202
2022-03-13 17:24:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:25:58 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.083 | nll_loss 5.673 | ppl 51.02 | wps 53952.9 | wpb 511.9 | bsz 1 | num_updates 8486 | best_loss 7.083
2022-03-13 17:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8486 updates
2022-03-13 17:25:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:25:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 21 @ 8486 updates, score 7.083) (writing took 2.4225302960257977 seconds)
2022-03-13 17:26:00 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-13 17:26:00 | INFO | train | epoch 021 | loss 7.073 | nll_loss 5.745 | ppl 53.63 | wps 28852.7 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8486 | lr 0.00034328 | gnorm 0.422 | loss_scale 32 | train_wall 795 | gb_free 9.7 | wall 19416
2022-03-13 17:26:00 | INFO | fairseq.trainer | begin training epoch 22
2022-03-13 17:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:26:30 | INFO | train_inner | epoch 022:     14 / 407 loss=7.079, nll_loss=5.752, ppl=53.89, wps=26710.6, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=8500, lr=0.000342997, gnorm=0.429, loss_scale=32, train_wall=194, gb_free=9.7, wall=19446
2022-03-13 17:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:30:08 | INFO | train_inner | epoch 022:    115 / 407 loss=7.03, nll_loss=5.694, ppl=51.78, wps=30166.4, ups=0.46, wpb=65536, bsz=128, num_updates=8600, lr=0.000340997, gnorm=0.425, loss_scale=32, train_wall=194, gb_free=9.7, wall=19663
2022-03-13 17:33:43 | INFO | train_inner | epoch 022:    215 / 407 loss=7.04, nll_loss=5.706, ppl=52.2, wps=30457.8, ups=0.46, wpb=65534.2, bsz=128, num_updates=8700, lr=0.000339032, gnorm=0.422, loss_scale=32, train_wall=192, gb_free=9.7, wall=19879
2022-03-13 17:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:37:21 | INFO | train_inner | epoch 022:    316 / 407 loss=7.051, nll_loss=5.719, ppl=52.69, wps=30067.1, ups=0.46, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.417, loss_scale=32, train_wall=195, gb_free=9.7, wall=20097
2022-03-13 17:38:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:40:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:41:02 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.067 | nll_loss 5.65 | ppl 50.2 | wps 52813.7 | wpb 511.9 | bsz 1 | num_updates 8890 | best_loss 7.067
2022-03-13 17:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 8890 updates
2022-03-13 17:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:41:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:41:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 22 @ 8890 updates, score 7.067) (writing took 2.313065971015021 seconds)
2022-03-13 17:41:05 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-13 17:41:05 | INFO | train | epoch 022 | loss 7.042 | nll_loss 5.709 | ppl 52.31 | wps 29253.7 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 8890 | lr 0.000335389 | gnorm 0.422 | loss_scale 32 | train_wall 782 | gb_free 9.7 | wall 20320
2022-03-13 17:41:05 | INFO | fairseq.trainer | begin training epoch 23
2022-03-13 17:41:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:41:27 | INFO | train_inner | epoch 023:     10 / 407 loss=7.046, nll_loss=5.715, ppl=52.51, wps=26600.1, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=8900, lr=0.000335201, gnorm=0.423, loss_scale=32, train_wall=195, gb_free=9.7, wall=20342
2022-03-13 17:44:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:45:05 | INFO | train_inner | epoch 023:    111 / 407 loss=6.999, nll_loss=5.659, ppl=50.54, wps=29995.2, ups=0.46, wpb=65536, bsz=128, num_updates=9000, lr=0.000333333, gnorm=0.423, loss_scale=32, train_wall=195, gb_free=9.7, wall=20561
2022-03-13 17:48:41 | INFO | train_inner | epoch 023:    211 / 407 loss=7.008, nll_loss=5.669, ppl=50.9, wps=30322.2, ups=0.46, wpb=65536, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.425, loss_scale=32, train_wall=193, gb_free=9.7, wall=20777
2022-03-13 17:48:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:52:20 | INFO | train_inner | epoch 023:    312 / 407 loss=7.034, nll_loss=5.7, ppl=51.99, wps=29930.7, ups=0.46, wpb=65534.2, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.422, loss_scale=32, train_wall=196, gb_free=9.7, wall=20996
2022-03-13 17:53:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:56:11 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.053 | nll_loss 5.631 | ppl 49.57 | wps 54005.2 | wpb 511.9 | bsz 1 | num_updates 9294 | best_loss 7.053
2022-03-13 17:56:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9294 updates
2022-03-13 17:56:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:56:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 23 @ 9294 updates, score 7.053) (writing took 2.299584088032134 seconds)
2022-03-13 17:56:13 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-13 17:56:13 | INFO | train | epoch 023 | loss 7.015 | nll_loss 5.678 | ppl 51.19 | wps 29133.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 9294 | lr 0.000328019 | gnorm 0.423 | loss_scale 32 | train_wall 787 | gb_free 9.7 | wall 21229
2022-03-13 17:56:13 | INFO | fairseq.trainer | begin training epoch 24
2022-03-13 17:56:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:56:26 | INFO | train_inner | epoch 024:      6 / 407 loss=7.017, nll_loss=5.682, ppl=51.33, wps=26614.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=9300, lr=0.000327913, gnorm=0.426, loss_scale=32, train_wall=195, gb_free=9.7, wall=21242
2022-03-13 17:58:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:00:03 | INFO | train_inner | epoch 024:    107 / 407 loss=6.97, nll_loss=5.626, ppl=49.38, wps=30184.8, ups=0.46, wpb=65534.2, bsz=128, num_updates=9400, lr=0.000326164, gnorm=0.433, loss_scale=32, train_wall=194, gb_free=9.7, wall=21459
2022-03-13 18:03:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:03:40 | INFO | train_inner | epoch 024:    208 / 407 loss=6.985, nll_loss=5.644, ppl=49.99, wps=30153.8, ups=0.46, wpb=65536, bsz=128, num_updates=9500, lr=0.000324443, gnorm=0.42, loss_scale=32, train_wall=194, gb_free=9.7, wall=21676
2022-03-13 18:07:17 | INFO | train_inner | epoch 024:    308 / 407 loss=6.996, nll_loss=5.656, ppl=50.42, wps=30177.9, ups=0.46, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.422, loss_scale=32, train_wall=194, gb_free=9.7, wall=21893
2022-03-13 18:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:11:15 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.03 | nll_loss 5.612 | ppl 48.91 | wps 54078.8 | wpb 511.9 | bsz 1 | num_updates 9698 | best_loss 7.03
2022-03-13 18:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9698 updates
2022-03-13 18:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 24 @ 9698 updates, score 7.03) (writing took 2.3280887239961885 seconds)
2022-03-13 18:11:18 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-13 18:11:18 | INFO | train | epoch 024 | loss 6.989 | nll_loss 5.648 | ppl 50.13 | wps 29243.9 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 9698 | lr 0.000321114 | gnorm 0.425 | loss_scale 32 | train_wall 783 | gb_free 9.7 | wall 22133
2022-03-13 18:11:18 | INFO | fairseq.trainer | begin training epoch 25
2022-03-13 18:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:11:22 | INFO | train_inner | epoch 025:      2 / 407 loss=7.005, nll_loss=5.667, ppl=50.81, wps=26705, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=9700, lr=0.000321081, gnorm=0.425, loss_scale=32, train_wall=194, gb_free=9.7, wall=22138
2022-03-13 18:13:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:15:11 | INFO | train_inner | epoch 025:    103 / 407 loss=6.944, nll_loss=5.596, ppl=48.36, wps=28682.3, ups=0.44, wpb=65534.2, bsz=128, num_updates=9800, lr=0.000319438, gnorm=0.427, loss_scale=32, train_wall=205, gb_free=9.7, wall=22366
2022-03-13 18:18:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:19:06 | INFO | train_inner | epoch 025:    204 / 407 loss=6.96, nll_loss=5.614, ppl=48.99, wps=27815.5, ups=0.42, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.427, loss_scale=32, train_wall=212, gb_free=9.7, wall=22602
2022-03-13 18:23:00 | INFO | train_inner | epoch 025:    304 / 407 loss=6.98, nll_loss=5.637, ppl=49.78, wps=28087.1, ups=0.43, wpb=65536, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.426, loss_scale=32, train_wall=210, gb_free=9.7, wall=22835
2022-03-13 18:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:26:58 | INFO | train_inner | epoch 025:    405 / 407 loss=6.977, nll_loss=5.635, ppl=49.69, wps=27529.6, ups=0.42, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.426, loss_scale=32, train_wall=215, gb_free=9.7, wall=23073
2022-03-13 18:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:27:27 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.017 | nll_loss 5.59 | ppl 48.17 | wps 51325 | wpb 511.9 | bsz 1 | num_updates 10102 | best_loss 7.017
2022-03-13 18:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10102 updates
2022-03-13 18:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:27:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 25 @ 10102 updates, score 7.017) (writing took 2.260714161035139 seconds)
2022-03-13 18:27:30 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-13 18:27:30 | INFO | train | epoch 025 | loss 6.965 | nll_loss 5.621 | ppl 49.21 | wps 27217.9 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 10102 | lr 0.000314627 | gnorm 0.427 | loss_scale 32 | train_wall 849 | gb_free 9.7 | wall 23106
2022-03-13 18:27:30 | INFO | fairseq.trainer | begin training epoch 26
2022-03-13 18:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:28:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:31:23 | INFO | train_inner | epoch 026:     99 / 407 loss=6.925, nll_loss=5.573, ppl=47.62, wps=24626.9, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=10200, lr=0.000313112, gnorm=0.427, loss_scale=32, train_wall=213, gb_free=9.7, wall=23339
2022-03-13 18:33:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:35:19 | INFO | train_inner | epoch 026:    200 / 407 loss=6.943, nll_loss=5.594, ppl=48.32, wps=27760, ups=0.42, wpb=65536, bsz=128, num_updates=10300, lr=0.000311588, gnorm=0.425, loss_scale=32, train_wall=213, gb_free=9.7, wall=23575
2022-03-13 18:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:39:17 | INFO | train_inner | epoch 026:    301 / 407 loss=6.943, nll_loss=5.595, ppl=48.33, wps=27493, ups=0.42, wpb=65534.2, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.418, loss_scale=32, train_wall=215, gb_free=9.7, wall=23813
2022-03-13 18:43:09 | INFO | train_inner | epoch 026:    401 / 407 loss=6.96, nll_loss=5.616, ppl=49.05, wps=28327, ups=0.43, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.424, loss_scale=32, train_wall=208, gb_free=9.7, wall=24045
2022-03-13 18:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:43:48 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.007 | nll_loss 5.581 | ppl 47.86 | wps 50204.3 | wpb 511.9 | bsz 1 | num_updates 10506 | best_loss 7.007
2022-03-13 18:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10506 updates
2022-03-13 18:43:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:43:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:43:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 26 @ 10506 updates, score 7.007) (writing took 2.2579219299950637 seconds)
2022-03-13 18:43:51 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-13 18:43:51 | INFO | train | epoch 026 | loss 6.943 | nll_loss 5.595 | ppl 48.33 | wps 26972.1 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 10506 | lr 0.000308519 | gnorm 0.424 | loss_scale 32 | train_wall 857 | gb_free 9.7 | wall 24086
2022-03-13 18:43:51 | INFO | fairseq.trainer | begin training epoch 27
2022-03-13 18:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:47:32 | INFO | train_inner | epoch 027:     95 / 407 loss=6.908, nll_loss=5.555, ppl=47, wps=24806.5, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=10600, lr=0.000307148, gnorm=0.434, loss_scale=32, train_wall=211, gb_free=9.7, wall=24308
2022-03-13 18:49:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:51:27 | INFO | train_inner | epoch 027:    196 / 407 loss=6.926, nll_loss=5.575, ppl=47.68, wps=27934.8, ups=0.43, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.425, loss_scale=32, train_wall=211, gb_free=9.7, wall=24543
2022-03-13 18:54:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:55:22 | INFO | train_inner | epoch 027:    297 / 407 loss=6.92, nll_loss=5.568, ppl=47.45, wps=27818.4, ups=0.42, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.428, loss_scale=32, train_wall=212, gb_free=9.7, wall=24778
2022-03-13 18:59:14 | INFO | train_inner | epoch 027:    397 / 407 loss=6.941, nll_loss=5.594, ppl=48.31, wps=28294.7, ups=0.43, wpb=65536, bsz=128, num_updates=10900, lr=0.000302891, gnorm=0.421, loss_scale=32, train_wall=208, gb_free=9.7, wall=25010
2022-03-13 18:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:00:04 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.981 | nll_loss 5.557 | ppl 47.07 | wps 50061.4 | wpb 511.9 | bsz 1 | num_updates 10910 | best_loss 6.981
2022-03-13 19:00:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 10910 updates
2022-03-13 19:00:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:00:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:00:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 27 @ 10910 updates, score 6.981) (writing took 2.33507864899002 seconds)
2022-03-13 19:00:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-13 19:00:06 | INFO | train | epoch 027 | loss 6.923 | nll_loss 5.572 | ppl 47.58 | wps 27132.4 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 10910 | lr 0.000302752 | gnorm 0.427 | loss_scale 64 | train_wall 851 | gb_free 9.7 | wall 25062
2022-03-13 19:00:06 | INFO | fairseq.trainer | begin training epoch 28
2022-03-13 19:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:00:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:03:38 | INFO | train_inner | epoch 028:     91 / 407 loss=6.883, nll_loss=5.525, ppl=46.06, wps=24803.8, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=11000, lr=0.000301511, gnorm=0.427, loss_scale=32, train_wall=211, gb_free=9.7, wall=25273
2022-03-13 19:05:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:07:34 | INFO | train_inner | epoch 028:    192 / 407 loss=6.896, nll_loss=5.541, ppl=46.57, wps=27723, ups=0.42, wpb=65536, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.424, loss_scale=32, train_wall=213, gb_free=9.7, wall=25510
2022-03-13 19:10:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:11:33 | INFO | train_inner | epoch 028:    293 / 407 loss=6.919, nll_loss=5.567, ppl=47.41, wps=27457.4, ups=0.42, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.429, loss_scale=32, train_wall=215, gb_free=9.7, wall=25748
2022-03-13 19:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:15:29 | INFO | train_inner | epoch 028:    394 / 407 loss=6.917, nll_loss=5.565, ppl=47.35, wps=27739.3, ups=0.42, wpb=65536, bsz=128, num_updates=11300, lr=0.000297482, gnorm=0.433, loss_scale=32, train_wall=213, gb_free=9.7, wall=25985
2022-03-13 19:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:16:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.974 | nll_loss 5.547 | ppl 46.75 | wps 50413.7 | wpb 511.9 | bsz 1 | num_updates 11313 | best_loss 6.974
2022-03-13 19:16:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11313 updates
2022-03-13 19:16:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:16:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:16:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 28 @ 11313 updates, score 6.974) (writing took 2.210252185992431 seconds)
2022-03-13 19:16:26 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-13 19:16:26 | INFO | train | epoch 028 | loss 6.904 | nll_loss 5.55 | ppl 46.86 | wps 26929 | ups 0.41 | wpb 65492.3 | bsz 127.9 | num_updates 11313 | lr 0.000297311 | gnorm 0.428 | loss_scale 32 | train_wall 856 | gb_free 9.7 | wall 26042
2022-03-13 19:16:26 | INFO | fairseq.trainer | begin training epoch 29
2022-03-13 19:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:19:52 | INFO | train_inner | epoch 029:     87 / 407 loss=6.877, nll_loss=5.518, ppl=45.83, wps=24862.1, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11400, lr=0.000296174, gnorm=0.428, loss_scale=32, train_wall=211, gb_free=9.7, wall=26248
2022-03-13 19:20:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:23:48 | INFO | train_inner | epoch 029:    188 / 407 loss=6.89, nll_loss=5.534, ppl=46.33, wps=27777.7, ups=0.42, wpb=65534.2, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.424, loss_scale=32, train_wall=212, gb_free=9.7, wall=26484
2022-03-13 19:26:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:27:48 | INFO | train_inner | epoch 029:    289 / 407 loss=6.88, nll_loss=5.523, ppl=45.97, wps=27315.6, ups=0.42, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.424, loss_scale=32, train_wall=216, gb_free=9.7, wall=26723
2022-03-13 19:31:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:31:44 | INFO | train_inner | epoch 029:    390 / 407 loss=6.903, nll_loss=5.549, ppl=46.82, wps=27674.6, ups=0.42, wpb=65536, bsz=128, num_updates=11700, lr=0.000292353, gnorm=0.427, loss_scale=32, train_wall=213, gb_free=9.7, wall=26960
2022-03-13 19:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:32:50 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.964 | nll_loss 5.531 | ppl 46.24 | wps 51277.1 | wpb 511.9 | bsz 1 | num_updates 11717 | best_loss 6.964
2022-03-13 19:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11717 updates
2022-03-13 19:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:32:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 29 @ 11717 updates, score 6.964) (writing took 2.21155476704007 seconds)
2022-03-13 19:32:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-13 19:32:52 | INFO | train | epoch 029 | loss 6.887 | nll_loss 5.53 | ppl 46.22 | wps 26823.3 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 11717 | lr 0.000292141 | gnorm 0.426 | loss_scale 32 | train_wall 863 | gb_free 9.7 | wall 27028
2022-03-13 19:32:52 | INFO | fairseq.trainer | begin training epoch 30
2022-03-13 19:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:36:08 | INFO | train_inner | epoch 030:     83 / 407 loss=6.863, nll_loss=5.503, ppl=45.35, wps=24811.7, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11800, lr=0.000291111, gnorm=0.427, loss_scale=32, train_wall=212, gb_free=9.7, wall=27224
2022-03-13 19:36:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:39:56 | INFO | train_inner | epoch 030:    184 / 407 loss=6.857, nll_loss=5.496, ppl=45.12, wps=28771.4, ups=0.44, wpb=65536, bsz=128, num_updates=11900, lr=0.000289886, gnorm=0.436, loss_scale=32, train_wall=204, gb_free=9.7, wall=27451
2022-03-13 19:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:43:56 | INFO | train_inner | epoch 030:    285 / 407 loss=6.876, nll_loss=5.518, ppl=45.84, wps=27304, ups=0.42, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.424, loss_scale=32, train_wall=216, gb_free=9.7, wall=27692
2022-03-13 19:46:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:47:54 | INFO | train_inner | epoch 030:    386 / 407 loss=6.885, nll_loss=5.529, ppl=46.16, wps=27515.2, ups=0.42, wpb=65534.2, bsz=128, num_updates=12100, lr=0.00028748, gnorm=0.435, loss_scale=32, train_wall=214, gb_free=9.7, wall=27930
2022-03-13 19:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:49:09 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.953 | nll_loss 5.521 | ppl 45.91 | wps 48473.4 | wpb 511.9 | bsz 1 | num_updates 12121 | best_loss 6.953
2022-03-13 19:49:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12121 updates
2022-03-13 19:49:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 30 @ 12121 updates, score 6.953) (writing took 3.0763244359986857 seconds)
2022-03-13 19:49:12 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-13 19:49:12 | INFO | train | epoch 030 | loss 6.87 | nll_loss 5.511 | ppl 45.6 | wps 27006.2 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 12121 | lr 0.000287231 | gnorm 0.43 | loss_scale 32 | train_wall 854 | gb_free 9.7 | wall 28008
2022-03-13 19:49:12 | INFO | fairseq.trainer | begin training epoch 31
2022-03-13 19:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:52:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:52:21 | INFO | train_inner | epoch 031:     80 / 407 loss=6.837, nll_loss=5.473, ppl=44.4, wps=24438.8, ups=0.37, wpb=65360.1, bsz=127.7, num_updates=12200, lr=0.000286299, gnorm=0.429, loss_scale=32, train_wall=213, gb_free=9.7, wall=28197
2022-03-13 19:56:18 | INFO | train_inner | epoch 031:    180 / 407 loss=6.848, nll_loss=5.485, ppl=44.79, wps=27675.7, ups=0.42, wpb=65536, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.432, loss_scale=32, train_wall=213, gb_free=9.7, wall=28434
2022-03-13 19:57:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:00:14 | INFO | train_inner | epoch 031:    281 / 407 loss=6.863, nll_loss=5.503, ppl=45.34, wps=27791.9, ups=0.42, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.432, loss_scale=32, train_wall=212, gb_free=9.7, wall=28670
2022-03-13 20:02:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:04:10 | INFO | train_inner | epoch 031:    382 / 407 loss=6.874, nll_loss=5.516, ppl=45.75, wps=27792.2, ups=0.42, wpb=65536, bsz=128, num_updates=12500, lr=0.000282843, gnorm=0.43, loss_scale=32, train_wall=212, gb_free=9.7, wall=28906
2022-03-13 20:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:05:35 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.944 | nll_loss 5.512 | ppl 45.64 | wps 49016.2 | wpb 511.9 | bsz 1 | num_updates 12525 | best_loss 6.944
2022-03-13 20:05:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12525 updates
2022-03-13 20:05:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:05:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 31 @ 12525 updates, score 6.944) (writing took 2.3882501519983634 seconds)
2022-03-13 20:05:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-13 20:05:37 | INFO | train | epoch 031 | loss 6.855 | nll_loss 5.493 | ppl 45.04 | wps 26857.5 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 12525 | lr 0.00028256 | gnorm 0.431 | loss_scale 32 | train_wall 860 | gb_free 9.7 | wall 28993
2022-03-13 20:05:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-13 20:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:08:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:08:37 | INFO | train_inner | epoch 032:     76 / 407 loss=6.829, nll_loss=5.463, ppl=44.11, wps=24497.8, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=12600, lr=0.000281718, gnorm=0.428, loss_scale=32, train_wall=213, gb_free=9.7, wall=29172
2022-03-13 20:12:32 | INFO | train_inner | epoch 032:    176 / 407 loss=6.831, nll_loss=5.465, ppl=44.17, wps=27842, ups=0.42, wpb=65536, bsz=128, num_updates=12700, lr=0.000280607, gnorm=0.43, loss_scale=32, train_wall=212, gb_free=9.7, wall=29408
2022-03-13 20:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:16:27 | INFO | train_inner | epoch 032:    277 / 407 loss=6.846, nll_loss=5.483, ppl=44.73, wps=27883.4, ups=0.43, wpb=65534.2, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.434, loss_scale=32, train_wall=211, gb_free=9.7, wall=29643
2022-03-13 20:17:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:20:14 | INFO | train_inner | epoch 032:    378 / 407 loss=6.858, nll_loss=5.498, ppl=45.2, wps=28925.8, ups=0.44, wpb=65536, bsz=128, num_updates=12900, lr=0.000278423, gnorm=0.431, loss_scale=32, train_wall=203, gb_free=9.7, wall=29869
2022-03-13 20:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:21:45 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.933 | nll_loss 5.498 | ppl 45.18 | wps 49547.5 | wpb 511.9 | bsz 1 | num_updates 12929 | best_loss 6.933
2022-03-13 20:21:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 12929 updates
2022-03-13 20:21:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:21:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 32 @ 12929 updates, score 6.933) (writing took 2.1592923930147663 seconds)
2022-03-13 20:21:48 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-13 20:21:48 | INFO | train | epoch 032 | loss 6.84 | nll_loss 5.476 | ppl 44.52 | wps 27270.9 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 12929 | lr 0.000278111 | gnorm 0.432 | loss_scale 32 | train_wall 846 | gb_free 9.7 | wall 29963
2022-03-13 20:21:48 | INFO | fairseq.trainer | begin training epoch 33
2022-03-13 20:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:23:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:24:33 | INFO | train_inner | epoch 033:     72 / 407 loss=6.816, nll_loss=5.449, ppl=43.67, wps=25213.3, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=13000, lr=0.00027735, gnorm=0.433, loss_scale=32, train_wall=206, gb_free=9.7, wall=30129
2022-03-13 20:28:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:28:24 | INFO | train_inner | epoch 033:    173 / 407 loss=6.819, nll_loss=5.451, ppl=43.75, wps=28357.1, ups=0.43, wpb=65534.2, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.431, loss_scale=32, train_wall=208, gb_free=9.7, wall=30360
2022-03-13 20:32:12 | INFO | train_inner | epoch 033:    273 / 407 loss=6.833, nll_loss=5.468, ppl=44.26, wps=28755.8, ups=0.44, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.431, loss_scale=32, train_wall=205, gb_free=9.7, wall=30588
2022-03-13 20:33:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:36:03 | INFO | train_inner | epoch 033:    374 / 407 loss=6.84, nll_loss=5.476, ppl=44.52, wps=28321, ups=0.43, wpb=65536, bsz=128, num_updates=13300, lr=0.000274204, gnorm=0.435, loss_scale=32, train_wall=208, gb_free=9.7, wall=30819
2022-03-13 20:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:37:45 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.928 | nll_loss 5.488 | ppl 44.89 | wps 51804.8 | wpb 511.9 | bsz 1 | num_updates 13333 | best_loss 6.928
2022-03-13 20:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13333 updates
2022-03-13 20:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:37:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 33 @ 13333 updates, score 6.928) (writing took 2.150473107001744 seconds)
2022-03-13 20:37:47 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-13 20:37:47 | INFO | train | epoch 033 | loss 6.826 | nll_loss 5.46 | ppl 44.03 | wps 27577.2 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 13333 | lr 0.000273865 | gnorm 0.432 | loss_scale 32 | train_wall 836 | gb_free 9.7 | wall 30923
2022-03-13 20:37:47 | INFO | fairseq.trainer | begin training epoch 34
2022-03-13 20:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:40:27 | INFO | train_inner | epoch 034:     68 / 407 loss=6.802, nll_loss=5.432, ppl=43.19, wps=24741.2, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13400, lr=0.000273179, gnorm=0.436, loss_scale=32, train_wall=212, gb_free=9.7, wall=31083
2022-03-13 20:43:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:44:24 | INFO | train_inner | epoch 034:    169 / 407 loss=6.799, nll_loss=5.429, ppl=43.08, wps=27716, ups=0.42, wpb=65534.2, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.431, loss_scale=32, train_wall=213, gb_free=9.7, wall=31320
2022-03-13 20:48:14 | INFO | train_inner | epoch 034:    269 / 407 loss=6.826, nll_loss=5.46, ppl=44.02, wps=28481.4, ups=0.43, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.431, loss_scale=32, train_wall=207, gb_free=9.7, wall=31550
2022-03-13 20:48:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:52:08 | INFO | train_inner | epoch 034:    370 / 407 loss=6.831, nll_loss=5.466, ppl=44.21, wps=28037.5, ups=0.43, wpb=65536, bsz=128, num_updates=13700, lr=0.000270172, gnorm=0.429, loss_scale=32, train_wall=210, gb_free=9.7, wall=31783
2022-03-13 20:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:54:01 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.922 | nll_loss 5.483 | ppl 44.74 | wps 51089.2 | wpb 511.9 | bsz 1 | num_updates 13737 | best_loss 6.922
2022-03-13 20:54:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13737 updates
2022-03-13 20:54:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:54:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 34 @ 13737 updates, score 6.922) (writing took 2.1596262119710445 seconds)
2022-03-13 20:54:03 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-13 20:54:03 | INFO | train | epoch 034 | loss 6.813 | nll_loss 5.445 | ppl 43.57 | wps 27113.5 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 13737 | lr 0.000269808 | gnorm 0.432 | loss_scale 32 | train_wall 852 | gb_free 9.7 | wall 31899
2022-03-13 20:54:03 | INFO | fairseq.trainer | begin training epoch 35
2022-03-13 20:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:54:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:56:33 | INFO | train_inner | epoch 035:     64 / 407 loss=6.79, nll_loss=5.419, ppl=42.78, wps=24654.4, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13800, lr=0.000269191, gnorm=0.43, loss_scale=32, train_wall=213, gb_free=9.7, wall=32049
2022-03-13 20:59:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:00:23 | INFO | train_inner | epoch 035:    165 / 407 loss=6.795, nll_loss=5.424, ppl=42.92, wps=28524.4, ups=0.44, wpb=65534.2, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.433, loss_scale=32, train_wall=206, gb_free=9.7, wall=32278
2022-03-13 21:04:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:04:16 | INFO | train_inner | epoch 035:    266 / 407 loss=6.808, nll_loss=5.44, ppl=43.4, wps=28070.2, ups=0.43, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.433, loss_scale=32, train_wall=210, gb_free=9.7, wall=32512
2022-03-13 21:08:01 | INFO | train_inner | epoch 035:    366 / 407 loss=6.819, nll_loss=5.452, ppl=43.77, wps=29150.5, ups=0.44, wpb=65536, bsz=128, num_updates=14100, lr=0.000266312, gnorm=0.433, loss_scale=32, train_wall=202, gb_free=9.7, wall=32737
2022-03-13 21:09:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:09:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:10:04 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.908 | nll_loss 5.47 | ppl 44.32 | wps 51779.4 | wpb 511.9 | bsz 1 | num_updates 14140 | best_loss 6.908
2022-03-13 21:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14140 updates
2022-03-13 21:10:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:10:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:10:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 35 @ 14140 updates, score 6.908) (writing took 2.3898718950222246 seconds)
2022-03-13 21:10:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-13 21:10:06 | INFO | train | epoch 035 | loss 6.802 | nll_loss 5.432 | ppl 43.16 | wps 27403.8 | ups 0.42 | wpb 65492.3 | bsz 127.9 | num_updates 14140 | lr 0.000265935 | gnorm 0.431 | loss_scale 32 | train_wall 840 | gb_free 9.7 | wall 32862
2022-03-13 21:10:06 | INFO | fairseq.trainer | begin training epoch 36
2022-03-13 21:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:12:19 | INFO | train_inner | epoch 036:     60 / 407 loss=6.787, nll_loss=5.415, ppl=42.67, wps=25359.2, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=14200, lr=0.000265372, gnorm=0.43, loss_scale=32, train_wall=206, gb_free=9.7, wall=32994
2022-03-13 21:14:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:16:09 | INFO | train_inner | epoch 036:    161 / 407 loss=6.781, nll_loss=5.407, ppl=42.44, wps=28450.2, ups=0.43, wpb=65534.2, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.436, loss_scale=32, train_wall=207, gb_free=9.7, wall=33225
2022-03-13 21:19:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:20:08 | INFO | train_inner | epoch 036:    262 / 407 loss=6.79, nll_loss=5.419, ppl=42.78, wps=27461.4, ups=0.42, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.433, loss_scale=32, train_wall=215, gb_free=9.7, wall=33463
2022-03-13 21:24:00 | INFO | train_inner | epoch 036:    362 / 407 loss=6.805, nll_loss=5.436, ppl=43.28, wps=28243.1, ups=0.43, wpb=65536, bsz=128, num_updates=14500, lr=0.000262613, gnorm=0.434, loss_scale=32, train_wall=209, gb_free=9.7, wall=33695
2022-03-13 21:24:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:26:07 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.901 | nll_loss 5.462 | ppl 44.07 | wps 51386.9 | wpb 511.9 | bsz 1 | num_updates 14544 | best_loss 6.901
2022-03-13 21:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14544 updates
2022-03-13 21:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:26:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:26:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 36 @ 14544 updates, score 6.901) (writing took 2.3116095759905875 seconds)
2022-03-13 21:26:10 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-13 21:26:10 | INFO | train | epoch 036 | loss 6.79 | nll_loss 5.418 | ppl 42.76 | wps 27454.7 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 14544 | lr 0.000262215 | gnorm 0.434 | loss_scale 32 | train_wall 840 | gb_free 9.7 | wall 33825
2022-03-13 21:26:10 | INFO | fairseq.trainer | begin training epoch 37
2022-03-13 21:26:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:28:22 | INFO | train_inner | epoch 037:     56 / 407 loss=6.767, nll_loss=5.392, ppl=41.98, wps=24940.1, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=14600, lr=0.000261712, gnorm=0.436, loss_scale=32, train_wall=210, gb_free=9.7, wall=33957
2022-03-13 21:30:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:32:17 | INFO | train_inner | epoch 037:    157 / 407 loss=6.77, nll_loss=5.395, ppl=42.07, wps=27902.9, ups=0.43, wpb=65536, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.432, loss_scale=32, train_wall=211, gb_free=9.7, wall=34192
2022-03-13 21:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:36:15 | INFO | train_inner | epoch 037:    258 / 407 loss=6.782, nll_loss=5.409, ppl=42.49, wps=27487.8, ups=0.42, wpb=65534.2, bsz=128, num_updates=14800, lr=0.000259938, gnorm=0.438, loss_scale=32, train_wall=215, gb_free=9.7, wall=34431
2022-03-13 21:40:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:40:07 | INFO | train_inner | epoch 037:    359 / 407 loss=6.795, nll_loss=5.424, ppl=42.93, wps=28289.1, ups=0.43, wpb=65536, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.432, loss_scale=32, train_wall=208, gb_free=9.7, wall=34662
2022-03-13 21:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:42:23 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.891 | nll_loss 5.449 | ppl 43.69 | wps 49706.5 | wpb 511.9 | bsz 1 | num_updates 14948 | best_loss 6.891
2022-03-13 21:42:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 14948 updates
2022-03-13 21:42:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:42:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 37 @ 14948 updates, score 6.891) (writing took 2.192156528006308 seconds)
2022-03-13 21:42:25 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-13 21:42:25 | INFO | train | epoch 037 | loss 6.779 | nll_loss 5.405 | ppl 42.38 | wps 27130.6 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 14948 | lr 0.000258648 | gnorm 0.434 | loss_scale 32 | train_wall 851 | gb_free 9.7 | wall 34801
2022-03-13 21:42:25 | INFO | fairseq.trainer | begin training epoch 38
2022-03-13 21:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:44:25 | INFO | train_inner | epoch 038:     52 / 407 loss=6.767, nll_loss=5.392, ppl=41.98, wps=25338.3, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=15000, lr=0.000258199, gnorm=0.435, loss_scale=32, train_wall=205, gb_free=9.7, wall=34920
2022-03-13 21:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:48:22 | INFO | train_inner | epoch 038:    153 / 407 loss=6.75, nll_loss=5.371, ppl=41.4, wps=27559.4, ups=0.42, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.435, loss_scale=32, train_wall=214, gb_free=9.7, wall=35158
2022-03-13 21:50:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:52:17 | INFO | train_inner | epoch 038:    254 / 407 loss=6.781, nll_loss=5.408, ppl=42.45, wps=27977.9, ups=0.43, wpb=65536, bsz=128, num_updates=15200, lr=0.000256495, gnorm=0.435, loss_scale=32, train_wall=211, gb_free=9.7, wall=35392
2022-03-13 21:55:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:56:08 | INFO | train_inner | epoch 038:    355 / 407 loss=6.779, nll_loss=5.406, ppl=42.39, wps=28330, ups=0.43, wpb=65534.2, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.434, loss_scale=32, train_wall=208, gb_free=9.7, wall=35624
2022-03-13 21:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:58:32 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.889 | nll_loss 5.446 | ppl 43.6 | wps 52023.6 | wpb 511.9 | bsz 1 | num_updates 15352 | best_loss 6.889
2022-03-13 21:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 15352 updates
2022-03-13 21:58:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 38 @ 15352 updates, score 6.889) (writing took 2.189159505011048 seconds)
2022-03-13 21:58:34 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-13 21:58:34 | INFO | train | epoch 038 | loss 6.768 | nll_loss 5.393 | ppl 42.03 | wps 27311.5 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 15352 | lr 0.000255222 | gnorm 0.435 | loss_scale 32 | train_wall 846 | gb_free 9.7 | wall 35770
2022-03-13 21:58:34 | INFO | fairseq.trainer | begin training epoch 39
2022-03-13 21:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:00:22 | INFO | train_inner | epoch 039:     48 / 407 loss=6.765, nll_loss=5.39, ppl=41.93, wps=25701.7, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=15400, lr=0.000254824, gnorm=0.438, loss_scale=32, train_wall=203, gb_free=9.7, wall=35878
2022-03-13 22:00:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:04:08 | INFO | train_inner | epoch 039:    149 / 407 loss=6.747, nll_loss=5.368, ppl=41.29, wps=29053.6, ups=0.44, wpb=65536, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.436, loss_scale=32, train_wall=202, gb_free=9.7, wall=36104
2022-03-13 22:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:07:51 | INFO | train_inner | epoch 039:    250 / 407 loss=6.76, nll_loss=5.384, ppl=41.75, wps=29428.3, ups=0.45, wpb=65536, bsz=128, num_updates=15600, lr=0.000253185, gnorm=0.442, loss_scale=32, train_wall=199, gb_free=9.7, wall=36326
2022-03-13 22:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:11:33 | INFO | train_inner | epoch 039:    351 / 407 loss=6.767, nll_loss=5.392, ppl=42, wps=29496.9, ups=0.45, wpb=65536, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.439, loss_scale=32, train_wall=199, gb_free=9.7, wall=36549
2022-03-13 22:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:14:00 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.886 | nll_loss 5.444 | ppl 43.52 | wps 53663.4 | wpb 511.9 | bsz 1 | num_updates 15756 | best_loss 6.886
2022-03-13 22:14:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 15756 updates
2022-03-13 22:14:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 39 @ 15756 updates, score 6.886) (writing took 2.1518284840276465 seconds)
2022-03-13 22:14:02 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-13 22:14:02 | INFO | train | epoch 039 | loss 6.758 | nll_loss 5.381 | ppl 41.67 | wps 28503.9 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 15756 | lr 0.000251928 | gnorm 0.439 | loss_scale 32 | train_wall 807 | gb_free 9.7 | wall 36698
2022-03-13 22:14:02 | INFO | fairseq.trainer | begin training epoch 40
2022-03-13 22:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:15:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:15:41 | INFO | train_inner | epoch 040:     45 / 407 loss=6.753, nll_loss=5.375, ppl=41.51, wps=26310.3, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=15800, lr=0.000251577, gnorm=0.435, loss_scale=32, train_wall=198, gb_free=9.7, wall=36797
2022-03-13 22:19:20 | INFO | train_inner | epoch 040:    145 / 407 loss=6.731, nll_loss=5.349, ppl=40.76, wps=29977.1, ups=0.46, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.44, loss_scale=32, train_wall=195, gb_free=9.7, wall=37016
2022-03-13 22:20:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:23:01 | INFO | train_inner | epoch 040:    246 / 407 loss=6.745, nll_loss=5.366, ppl=41.23, wps=29619.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=16000, lr=0.00025, gnorm=0.438, loss_scale=32, train_wall=198, gb_free=9.7, wall=37237
2022-03-13 22:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:26:41 | INFO | train_inner | epoch 040:    347 / 407 loss=6.769, nll_loss=5.394, ppl=42.06, wps=29819.1, ups=0.46, wpb=65536, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.435, loss_scale=32, train_wall=196, gb_free=9.7, wall=37457
2022-03-13 22:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:29:17 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.879 | nll_loss 5.434 | ppl 43.24 | wps 52464.1 | wpb 511.9 | bsz 1 | num_updates 16160 | best_loss 6.879
2022-03-13 22:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 16160 updates
2022-03-13 22:29:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 40 @ 16160 updates, score 6.879) (writing took 2.225913878006395 seconds)
2022-03-13 22:29:19 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-13 22:29:19 | INFO | train | epoch 040 | loss 6.749 | nll_loss 5.37 | ppl 41.36 | wps 28850.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16160 | lr 0.000248759 | gnorm 0.437 | loss_scale 32 | train_wall 795 | gb_free 9.7 | wall 37615
2022-03-13 22:29:19 | INFO | fairseq.trainer | begin training epoch 41
2022-03-13 22:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:30:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:30:50 | INFO | train_inner | epoch 041:     41 / 407 loss=6.742, nll_loss=5.363, ppl=41.16, wps=26260.1, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=16200, lr=0.000248452, gnorm=0.438, loss_scale=32, train_wall=198, gb_free=9.7, wall=37705
2022-03-13 22:34:28 | INFO | train_inner | epoch 041:    141 / 407 loss=6.733, nll_loss=5.352, ppl=40.83, wps=30060.4, ups=0.46, wpb=65536, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.438, loss_scale=32, train_wall=195, gb_free=9.7, wall=37924
2022-03-13 22:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:38:07 | INFO | train_inner | epoch 041:    242 / 407 loss=6.738, nll_loss=5.359, ppl=41.03, wps=29931.2, ups=0.46, wpb=65536, bsz=128, num_updates=16400, lr=0.000246932, gnorm=0.437, loss_scale=32, train_wall=195, gb_free=9.7, wall=38142
2022-03-13 22:39:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:41:47 | INFO | train_inner | epoch 041:    343 / 407 loss=6.753, nll_loss=5.376, ppl=41.51, wps=29698.7, ups=0.45, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.438, loss_scale=32, train_wall=197, gb_free=9.7, wall=38363
2022-03-13 22:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:44:31 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.876 | nll_loss 5.433 | ppl 43.19 | wps 53603.5 | wpb 511.9 | bsz 1 | num_updates 16564 | best_loss 6.876
2022-03-13 22:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 16564 updates
2022-03-13 22:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 41 @ 16564 updates, score 6.876) (writing took 2.2702699750079773 seconds)
2022-03-13 22:44:34 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-13 22:44:34 | INFO | train | epoch 041 | loss 6.74 | nll_loss 5.36 | ppl 41.07 | wps 28934.4 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16564 | lr 0.000245707 | gnorm 0.439 | loss_scale 32 | train_wall 793 | gb_free 9.7 | wall 38529
2022-03-13 22:44:34 | INFO | fairseq.trainer | begin training epoch 42
2022-03-13 22:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:44:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:45:54 | INFO | train_inner | epoch 042:     37 / 407 loss=6.733, nll_loss=5.352, ppl=40.85, wps=26525.4, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=16600, lr=0.00024544, gnorm=0.44, loss_scale=32, train_wall=196, gb_free=9.7, wall=38610
2022-03-13 22:49:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:49:34 | INFO | train_inner | epoch 042:    138 / 407 loss=6.72, nll_loss=5.336, ppl=40.4, wps=29737.7, ups=0.45, wpb=65536, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.435, loss_scale=32, train_wall=197, gb_free=9.7, wall=38830
2022-03-13 22:52:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:53:15 | INFO | train_inner | epoch 042:    239 / 407 loss=6.729, nll_loss=5.348, ppl=40.72, wps=29714.8, ups=0.45, wpb=65536, bsz=128, num_updates=16800, lr=0.000243975, gnorm=0.438, loss_scale=16, train_wall=197, gb_free=9.7, wall=39050
2022-03-13 22:56:53 | INFO | train_inner | epoch 042:    339 / 407 loss=6.744, nll_loss=5.365, ppl=41.22, wps=30009.6, ups=0.46, wpb=65534.2, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.44, loss_scale=16, train_wall=195, gb_free=9.7, wall=39269
2022-03-13 22:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:59:48 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.864 | nll_loss 5.423 | ppl 42.9 | wps 52185.8 | wpb 511.9 | bsz 1 | num_updates 16968 | best_loss 6.864
2022-03-13 22:59:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 16968 updates
2022-03-13 22:59:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:59:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 42 @ 16968 updates, score 6.864) (writing took 2.2762110219919123 seconds)
2022-03-13 22:59:50 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-13 22:59:50 | INFO | train | epoch 042 | loss 6.731 | nll_loss 5.349 | ppl 40.76 | wps 28871.9 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16968 | lr 0.000242764 | gnorm 0.438 | loss_scale 32 | train_wall 794 | gb_free 9.7 | wall 39446
2022-03-13 22:59:50 | INFO | fairseq.trainer | begin training epoch 43
2022-03-13 22:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:01:00 | INFO | train_inner | epoch 043:     32 / 407 loss=6.729, nll_loss=5.347, ppl=40.71, wps=26473, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=17000, lr=0.000242536, gnorm=0.439, loss_scale=32, train_wall=196, gb_free=9.7, wall=39516
2022-03-13 23:02:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:04:40 | INFO | train_inner | epoch 043:    133 / 407 loss=6.71, nll_loss=5.325, ppl=40.08, wps=29721.6, ups=0.45, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.437, loss_scale=32, train_wall=197, gb_free=9.7, wall=39736
2022-03-13 23:07:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:08:21 | INFO | train_inner | epoch 043:    234 / 407 loss=6.73, nll_loss=5.348, ppl=40.73, wps=29754.9, ups=0.45, wpb=65536, bsz=128, num_updates=17200, lr=0.000241121, gnorm=0.441, loss_scale=32, train_wall=197, gb_free=9.7, wall=39957
2022-03-13 23:11:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:12:02 | INFO | train_inner | epoch 043:    335 / 407 loss=6.727, nll_loss=5.346, ppl=40.66, wps=29605, ups=0.45, wpb=65534.2, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.445, loss_scale=32, train_wall=198, gb_free=9.7, wall=40178
2022-03-13 23:14:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:15:05 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.865 | nll_loss 5.419 | ppl 42.78 | wps 52900.6 | wpb 511.9 | bsz 1 | num_updates 17372 | best_loss 6.864
2022-03-13 23:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 17372 updates
2022-03-13 23:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:15:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:15:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 43 @ 17372 updates, score 6.865) (writing took 1.2313784320140257 seconds)
2022-03-13 23:15:06 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-13 23:15:06 | INFO | train | epoch 043 | loss 6.722 | nll_loss 5.34 | ppl 40.5 | wps 28886.3 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 17372 | lr 0.000239925 | gnorm 0.44 | loss_scale 32 | train_wall 795 | gb_free 9.7 | wall 40362
2022-03-13 23:15:06 | INFO | fairseq.trainer | begin training epoch 44
2022-03-13 23:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:16:07 | INFO | train_inner | epoch 044:     28 / 407 loss=6.723, nll_loss=5.341, ppl=40.52, wps=26695.2, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=17400, lr=0.000239732, gnorm=0.439, loss_scale=32, train_wall=195, gb_free=9.7, wall=40423
2022-03-13 23:16:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:19:48 | INFO | train_inner | epoch 044:    129 / 407 loss=6.698, nll_loss=5.311, ppl=39.69, wps=29693.6, ups=0.45, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.436, loss_scale=32, train_wall=197, gb_free=9.7, wall=40643
2022-03-13 23:21:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:23:27 | INFO | train_inner | epoch 044:    230 / 407 loss=6.717, nll_loss=5.333, ppl=40.32, wps=29812.4, ups=0.45, wpb=65536, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.446, loss_scale=32, train_wall=196, gb_free=9.7, wall=40863
2022-03-13 23:26:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:27:09 | INFO | train_inner | epoch 044:    331 / 407 loss=6.728, nll_loss=5.347, ppl=40.69, wps=29638.5, ups=0.45, wpb=65536, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.436, loss_scale=32, train_wall=198, gb_free=9.7, wall=41084
2022-03-13 23:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:30:18 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.855 | nll_loss 5.41 | ppl 42.5 | wps 53252.3 | wpb 511.9 | bsz 1 | num_updates 17776 | best_loss 6.855
2022-03-13 23:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 17776 updates
2022-03-13 23:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 44 @ 17776 updates, score 6.855) (writing took 2.202928486978635 seconds)
2022-03-13 23:30:20 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-13 23:30:20 | INFO | train | epoch 044 | loss 6.714 | nll_loss 5.33 | ppl 40.22 | wps 28934.4 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 17776 | lr 0.000237183 | gnorm 0.44 | loss_scale 32 | train_wall 793 | gb_free 9.7 | wall 41276
2022-03-13 23:30:20 | INFO | fairseq.trainer | begin training epoch 45
2022-03-13 23:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:31:16 | INFO | train_inner | epoch 045:     24 / 407 loss=6.71, nll_loss=5.326, ppl=40.11, wps=26413.2, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=17800, lr=0.000237023, gnorm=0.444, loss_scale=32, train_wall=197, gb_free=9.7, wall=41332
2022-03-13 23:31:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:35:09 | INFO | train_inner | epoch 045:    125 / 407 loss=6.681, nll_loss=5.292, ppl=39.17, wps=28109.3, ups=0.43, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.443, loss_scale=32, train_wall=209, gb_free=9.7, wall=41565
2022-03-13 23:36:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:39:01 | INFO | train_inner | epoch 045:    226 / 407 loss=6.701, nll_loss=5.315, ppl=39.8, wps=28295.4, ups=0.43, wpb=65536, bsz=128, num_updates=18000, lr=0.000235702, gnorm=0.438, loss_scale=32, train_wall=208, gb_free=9.7, wall=41797
2022-03-13 23:41:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:42:56 | INFO | train_inner | epoch 045:    327 / 407 loss=6.728, nll_loss=5.346, ppl=40.68, wps=27831.3, ups=0.42, wpb=65534.2, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.44, loss_scale=32, train_wall=212, gb_free=9.7, wall=42032
2022-03-13 23:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:46:31 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.856 | nll_loss 5.41 | ppl 42.51 | wps 49951 | wpb 511.9 | bsz 1 | num_updates 18180 | best_loss 6.855
2022-03-13 23:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 18180 updates
2022-03-13 23:46:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 45 @ 18180 updates, score 6.856) (writing took 1.2147049230406992 seconds)
2022-03-13 23:46:32 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-13 23:46:32 | INFO | train | epoch 045 | loss 6.706 | nll_loss 5.32 | ppl 39.96 | wps 27237.9 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 18180 | lr 0.000234533 | gnorm 0.442 | loss_scale 32 | train_wall 848 | gb_free 9.7 | wall 42248
2022-03-13 23:46:32 | INFO | fairseq.trainer | begin training epoch 46
2022-03-13 23:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:46:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:47:20 | INFO | train_inner | epoch 046:     21 / 407 loss=6.714, nll_loss=5.33, ppl=40.23, wps=24750.5, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18200, lr=0.000234404, gnorm=0.443, loss_scale=32, train_wall=212, gb_free=9.7, wall=42296
2022-03-13 23:51:08 | INFO | train_inner | epoch 046:    121 / 407 loss=6.68, nll_loss=5.291, ppl=39.14, wps=28769.3, ups=0.44, wpb=65534.2, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.446, loss_scale=32, train_wall=204, gb_free=9.7, wall=42524
2022-03-13 23:51:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:55:06 | INFO | train_inner | epoch 046:    222 / 407 loss=6.703, nll_loss=5.316, ppl=39.84, wps=27576.9, ups=0.42, wpb=65536, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.439, loss_scale=32, train_wall=214, gb_free=9.7, wall=42762
2022-03-13 23:56:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:59:00 | INFO | train_inner | epoch 046:    323 / 407 loss=6.705, nll_loss=5.319, ppl=39.93, wps=27933.7, ups=0.43, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.445, loss_scale=16, train_wall=211, gb_free=9.7, wall=42996
2022-03-14 00:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:02:44 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.845 | nll_loss 5.401 | ppl 42.26 | wps 49722 | wpb 511.9 | bsz 1 | num_updates 18584 | best_loss 6.845
2022-03-14 00:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 18584 updates
2022-03-14 00:02:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:02:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 46 @ 18584 updates, score 6.845) (writing took 2.202135053987149 seconds)
2022-03-14 00:02:46 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 00:02:46 | INFO | train | epoch 046 | loss 6.698 | nll_loss 5.312 | ppl 39.72 | wps 27167.7 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 18584 | lr 0.000231969 | gnorm 0.443 | loss_scale 32 | train_wall 850 | gb_free 9.7 | wall 43222
2022-03-14 00:02:46 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 00:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:03:22 | INFO | train_inner | epoch 047:     16 / 407 loss=6.709, nll_loss=5.325, ppl=40.08, wps=25010.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18600, lr=0.000231869, gnorm=0.441, loss_scale=32, train_wall=209, gb_free=9.7, wall=43258
2022-03-14 00:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:07:12 | INFO | train_inner | epoch 047:    117 / 407 loss=6.669, nll_loss=5.277, ppl=38.78, wps=28460.8, ups=0.43, wpb=65536, bsz=128, num_updates=18700, lr=0.000231249, gnorm=0.439, loss_scale=32, train_wall=207, gb_free=9.7, wall=43488
2022-03-14 00:11:06 | INFO | train_inner | epoch 047:    217 / 407 loss=6.679, nll_loss=5.29, ppl=39.11, wps=28067.7, ups=0.43, wpb=65534.2, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.443, loss_scale=32, train_wall=210, gb_free=9.7, wall=43721
2022-03-14 00:11:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:15:03 | INFO | train_inner | epoch 047:    318 / 407 loss=6.706, nll_loss=5.321, ppl=39.98, wps=27649.6, ups=0.42, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.442, loss_scale=32, train_wall=213, gb_free=9.7, wall=43958
2022-03-14 00:16:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:18:57 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.842 | nll_loss 5.392 | ppl 42 | wps 52233.9 | wpb 511.9 | bsz 1 | num_updates 18988 | best_loss 6.842
2022-03-14 00:18:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 18988 updates
2022-03-14 00:18:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:18:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 47 @ 18988 updates, score 6.842) (writing took 2.128567453008145 seconds)
2022-03-14 00:18:59 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 00:18:59 | INFO | train | epoch 047 | loss 6.691 | nll_loss 5.303 | ppl 39.47 | wps 27184.9 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 18988 | lr 0.000229488 | gnorm 0.441 | loss_scale 16 | train_wall 850 | gb_free 9.7 | wall 44195
2022-03-14 00:18:59 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 00:18:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:19:27 | INFO | train_inner | epoch 048:     12 / 407 loss=6.71, nll_loss=5.325, ppl=40.09, wps=24729.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19000, lr=0.000229416, gnorm=0.438, loss_scale=16, train_wall=213, gb_free=9.7, wall=44223
2022-03-14 00:23:19 | INFO | train_inner | epoch 048:    112 / 407 loss=6.665, nll_loss=5.272, ppl=38.64, wps=28281.4, ups=0.43, wpb=65534.2, bsz=128, num_updates=19100, lr=0.000228814, gnorm=0.438, loss_scale=32, train_wall=208, gb_free=9.7, wall=44454
2022-03-14 00:27:11 | INFO | train_inner | epoch 048:    212 / 407 loss=6.682, nll_loss=5.293, ppl=39.2, wps=28234.2, ups=0.43, wpb=65536, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.445, loss_scale=64, train_wall=209, gb_free=9.7, wall=44686
2022-03-14 00:27:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:31:05 | INFO | train_inner | epoch 048:    313 / 407 loss=6.693, nll_loss=5.306, ppl=39.56, wps=27963.6, ups=0.43, wpb=65536, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.441, loss_scale=32, train_wall=211, gb_free=9.7, wall=44921
2022-03-14 00:32:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:35:08 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.84 | nll_loss 5.392 | ppl 41.98 | wps 49864.5 | wpb 511.9 | bsz 1 | num_updates 19393 | best_loss 6.84
2022-03-14 00:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 19393 updates
2022-03-14 00:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 48 @ 19393 updates, score 6.84) (writing took 2.1316272690310143 seconds)
2022-03-14 00:35:10 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 00:35:10 | INFO | train | epoch 048 | loss 6.684 | nll_loss 5.296 | ppl 39.28 | wps 27327 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 19393 | lr 0.000227079 | gnorm 0.441 | loss_scale 32 | train_wall 846 | gb_free 9.7 | wall 45165
2022-03-14 00:35:10 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 00:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:35:26 | INFO | train_inner | epoch 049:      7 / 407 loss=6.696, nll_loss=5.31, ppl=39.67, wps=25010.1, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19400, lr=0.000227038, gnorm=0.441, loss_scale=32, train_wall=209, gb_free=9.7, wall=45182
2022-03-14 00:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:39:22 | INFO | train_inner | epoch 049:    108 / 407 loss=6.654, nll_loss=5.26, ppl=38.31, wps=27798, ups=0.42, wpb=65534.2, bsz=128, num_updates=19500, lr=0.000226455, gnorm=0.446, loss_scale=32, train_wall=212, gb_free=9.7, wall=45418
2022-03-14 00:42:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:43:09 | INFO | train_inner | epoch 049:    209 / 407 loss=6.683, nll_loss=5.294, ppl=39.23, wps=28950, ups=0.44, wpb=65536, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.44, loss_scale=32, train_wall=203, gb_free=9.7, wall=45644
2022-03-14 00:46:59 | INFO | train_inner | epoch 049:    309 / 407 loss=6.685, nll_loss=5.296, ppl=39.3, wps=28453.9, ups=0.43, wpb=65536, bsz=128, num_updates=19700, lr=0.000225303, gnorm=0.438, loss_scale=32, train_wall=207, gb_free=9.7, wall=45875
2022-03-14 00:47:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:50:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:51:12 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.839 | nll_loss 5.388 | ppl 41.89 | wps 49724.3 | wpb 511.9 | bsz 1 | num_updates 19797 | best_loss 6.839
2022-03-14 00:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 19797 updates
2022-03-14 00:51:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 49 @ 19797 updates, score 6.839) (writing took 2.1312499480554834 seconds)
2022-03-14 00:51:15 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 00:51:15 | INFO | train | epoch 049 | loss 6.677 | nll_loss 5.287 | ppl 39.04 | wps 27421.2 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 19797 | lr 0.00022475 | gnorm 0.442 | loss_scale 32 | train_wall 841 | gb_free 9.7 | wall 46130
2022-03-14 00:51:15 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 00:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:51:22 | INFO | train_inner | epoch 050:      3 / 407 loss=6.685, nll_loss=5.297, ppl=39.32, wps=24856.7, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19800, lr=0.000224733, gnorm=0.444, loss_scale=32, train_wall=210, gb_free=9.7, wall=46138
2022-03-14 00:53:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:55:15 | INFO | train_inner | epoch 050:    104 / 407 loss=6.645, nll_loss=5.25, ppl=38.05, wps=28086.9, ups=0.43, wpb=65536, bsz=128, num_updates=19900, lr=0.000224168, gnorm=0.441, loss_scale=32, train_wall=210, gb_free=9.7, wall=46371
2022-03-14 00:58:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:59:11 | INFO | train_inner | epoch 050:    205 / 407 loss=6.669, nll_loss=5.277, ppl=38.78, wps=27733.7, ups=0.42, wpb=65534.2, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.444, loss_scale=32, train_wall=213, gb_free=9.7, wall=46607
2022-03-14 01:02:57 | INFO | train_inner | epoch 050:    305 / 407 loss=6.676, nll_loss=5.286, ppl=39.03, wps=29028.4, ups=0.44, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.443, loss_scale=32, train_wall=202, gb_free=9.7, wall=46833
2022-03-14 01:03:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:06:51 | INFO | train_inner | epoch 050:    406 / 407 loss=6.694, nll_loss=5.307, ppl=39.58, wps=28008.3, ups=0.43, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.445, loss_scale=32, train_wall=210, gb_free=9.7, wall=47067
2022-03-14 01:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:07:18 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.831 | nll_loss 5.384 | ppl 41.77 | wps 52479.8 | wpb 511.9 | bsz 1 | num_updates 20201 | best_loss 6.831
2022-03-14 01:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 20201 updates
2022-03-14 01:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 50 @ 20201 updates, score 6.831) (writing took 2.1869210049626417 seconds)
2022-03-14 01:07:20 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 01:07:20 | INFO | train | epoch 050 | loss 6.671 | nll_loss 5.28 | ppl 38.85 | wps 27392.8 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 20201 | lr 0.000222492 | gnorm 0.443 | loss_scale 32 | train_wall 843 | gb_free 9.7 | wall 47096
2022-03-14 01:07:21 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 01:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:11:12 | INFO | train_inner | epoch 051:    100 / 407 loss=6.64, nll_loss=5.243, ppl=37.88, wps=25084.1, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=20300, lr=0.000221948, gnorm=0.443, loss_scale=32, train_wall=209, gb_free=9.7, wall=47328
2022-03-14 01:13:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:15:05 | INFO | train_inner | epoch 051:    201 / 407 loss=6.661, nll_loss=5.268, ppl=38.54, wps=28134.6, ups=0.43, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.444, loss_scale=32, train_wall=209, gb_free=9.7, wall=47560
2022-03-14 01:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:18:57 | INFO | train_inner | epoch 051:    302 / 407 loss=6.674, nll_loss=5.283, ppl=38.93, wps=28267, ups=0.43, wpb=65536, bsz=128, num_updates=20500, lr=0.000220863, gnorm=0.446, loss_scale=32, train_wall=208, gb_free=9.7, wall=47792
2022-03-14 01:22:51 | INFO | train_inner | epoch 051:    402 / 407 loss=6.682, nll_loss=5.293, ppl=39.2, wps=27943, ups=0.43, wpb=65534.2, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.446, loss_scale=32, train_wall=211, gb_free=9.7, wall=48027
2022-03-14 01:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:23:28 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.828 | nll_loss 5.38 | ppl 41.64 | wps 52885.3 | wpb 511.9 | bsz 1 | num_updates 20605 | best_loss 6.828
2022-03-14 01:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 20605 updates
2022-03-14 01:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 51 @ 20605 updates, score 6.828) (writing took 2.2022817849647254 seconds)
2022-03-14 01:23:30 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 01:23:30 | INFO | train | epoch 051 | loss 6.664 | nll_loss 5.272 | ppl 38.65 | wps 27297.4 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 20605 | lr 0.0002203 | gnorm 0.444 | loss_scale 32 | train_wall 847 | gb_free 9.7 | wall 48066
2022-03-14 01:23:30 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 01:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:23:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:27:07 | INFO | train_inner | epoch 052:     96 / 407 loss=6.647, nll_loss=5.251, ppl=38.09, wps=25496.1, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=20700, lr=0.000219793, gnorm=0.445, loss_scale=32, train_wall=205, gb_free=9.7, wall=48283
2022-03-14 01:29:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:31:27 | INFO | train_inner | epoch 052:    197 / 407 loss=6.655, nll_loss=5.261, ppl=38.36, wps=25208.4, ups=0.38, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.447, loss_scale=32, train_wall=236, gb_free=9.7, wall=48543
2022-03-14 01:31:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:35:49 | INFO | train_inner | epoch 052:    298 / 407 loss=6.665, nll_loss=5.273, ppl=38.67, wps=25039.9, ups=0.38, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.442, loss_scale=16, train_wall=237, gb_free=9.7, wall=48805
2022-03-14 01:40:08 | INFO | train_inner | epoch 052:    398 / 407 loss=6.665, nll_loss=5.273, ppl=38.68, wps=25291.4, ups=0.39, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.45, loss_scale=32, train_wall=235, gb_free=9.7, wall=49064
2022-03-14 01:40:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:41:00 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.829 | nll_loss 5.377 | ppl 41.57 | wps 46205.5 | wpb 511.9 | bsz 1 | num_updates 21009 | best_loss 6.828
2022-03-14 01:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 21009 updates
2022-03-14 01:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 52 @ 21009 updates, score 6.829) (writing took 1.292807660996914 seconds)
2022-03-14 01:41:01 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 01:41:01 | INFO | train | epoch 052 | loss 6.658 | nll_loss 5.265 | ppl 38.45 | wps 25163.3 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 21009 | lr 0.000218171 | gnorm 0.446 | loss_scale 32 | train_wall 923 | gb_free 9.7 | wall 49117
2022-03-14 01:41:01 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 01:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:43:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:45:01 | INFO | train_inner | epoch 053:     92 / 407 loss=6.631, nll_loss=5.233, ppl=37.62, wps=22292.6, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21100, lr=0.0002177, gnorm=0.45, loss_scale=32, train_wall=238, gb_free=9.7, wall=49357
2022-03-14 01:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:49:23 | INFO | train_inner | epoch 053:    193 / 407 loss=6.64, nll_loss=5.244, ppl=37.89, wps=25044.5, ups=0.38, wpb=65536, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.442, loss_scale=32, train_wall=237, gb_free=9.7, wall=49619
2022-03-14 01:53:40 | INFO | train_inner | epoch 053:    293 / 407 loss=6.673, nll_loss=5.282, ppl=38.92, wps=25481.8, ups=0.39, wpb=65534.2, bsz=128, num_updates=21300, lr=0.000216676, gnorm=0.449, loss_scale=32, train_wall=233, gb_free=9.7, wall=49876
2022-03-14 01:54:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:58:02 | INFO | train_inner | epoch 053:    394 / 407 loss=6.67, nll_loss=5.279, ppl=38.82, wps=25084.4, ups=0.38, wpb=65536, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.442, loss_scale=32, train_wall=237, gb_free=9.7, wall=50137
2022-03-14 01:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:59:04 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.824 | nll_loss 5.372 | ppl 41.43 | wps 46228.3 | wpb 511.9 | bsz 1 | num_updates 21413 | best_loss 6.824
2022-03-14 01:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 21413 updates
2022-03-14 01:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:59:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 53 @ 21413 updates, score 6.824) (writing took 2.274041083001066 seconds)
2022-03-14 01:59:06 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 01:59:06 | INFO | train | epoch 053 | loss 6.653 | nll_loss 5.259 | ppl 38.28 | wps 24392.1 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 21413 | lr 0.000216103 | gnorm 0.446 | loss_scale 32 | train_wall 955 | gb_free 9.7 | wall 50202
2022-03-14 01:59:06 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 01:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:00:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:02:55 | INFO | train_inner | epoch 054:     88 / 407 loss=6.613, nll_loss=5.212, ppl=37.07, wps=22301.2, ups=0.34, wpb=65360.1, bsz=127.7, num_updates=21500, lr=0.000215666, gnorm=0.448, loss_scale=32, train_wall=237, gb_free=9.7, wall=50430
2022-03-14 02:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:07:15 | INFO | train_inner | epoch 054:    189 / 407 loss=6.649, nll_loss=5.254, ppl=38.16, wps=25213.7, ups=0.38, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.448, loss_scale=32, train_wall=235, gb_free=9.7, wall=50690
2022-03-14 02:11:33 | INFO | train_inner | epoch 054:    289 / 407 loss=6.658, nll_loss=5.265, ppl=38.45, wps=25387.8, ups=0.39, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.439, loss_scale=32, train_wall=234, gb_free=9.7, wall=50949
2022-03-14 02:11:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:15:54 | INFO | train_inner | epoch 054:    390 / 407 loss=6.664, nll_loss=5.272, ppl=38.64, wps=25072.6, ups=0.38, wpb=65536, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.451, loss_scale=32, train_wall=237, gb_free=9.7, wall=51210
2022-03-14 02:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:17:06 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.823 | nll_loss 5.37 | ppl 41.36 | wps 46678.5 | wpb 511.9 | bsz 1 | num_updates 21817 | best_loss 6.823
2022-03-14 02:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 21817 updates
2022-03-14 02:17:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 54 @ 21817 updates, score 6.823) (writing took 2.2821019900147803 seconds)
2022-03-14 02:17:08 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 02:17:08 | INFO | train | epoch 054 | loss 6.646 | nll_loss 5.251 | ppl 38.09 | wps 24451.2 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 21817 | lr 0.000214093 | gnorm 0.446 | loss_scale 32 | train_wall 952 | gb_free 9.7 | wall 51284
2022-03-14 02:17:08 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 02:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:17:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:20:47 | INFO | train_inner | epoch 055:     84 / 407 loss=6.634, nll_loss=5.236, ppl=37.7, wps=22338.3, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21900, lr=0.000213687, gnorm=0.453, loss_scale=32, train_wall=237, gb_free=9.7, wall=51502
2022-03-14 02:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:25:07 | INFO | train_inner | epoch 055:    185 / 407 loss=6.634, nll_loss=5.237, ppl=37.71, wps=25157.4, ups=0.38, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.444, loss_scale=32, train_wall=236, gb_free=9.7, wall=51763
2022-03-14 02:29:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:29:28 | INFO | train_inner | epoch 055:    286 / 407 loss=6.638, nll_loss=5.242, ppl=37.83, wps=25145.2, ups=0.38, wpb=65536, bsz=128, num_updates=22100, lr=0.000212718, gnorm=0.448, loss_scale=32, train_wall=236, gb_free=9.7, wall=52024
2022-03-14 02:33:46 | INFO | train_inner | epoch 055:    386 / 407 loss=6.658, nll_loss=5.265, ppl=38.45, wps=25353.4, ups=0.39, wpb=65534.2, bsz=128, num_updates=22200, lr=0.000212238, gnorm=0.444, loss_scale=32, train_wall=234, gb_free=9.7, wall=52282
2022-03-14 02:34:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:35:09 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.816 | nll_loss 5.365 | ppl 41.21 | wps 46046.9 | wpb 511.9 | bsz 1 | num_updates 22220 | best_loss 6.816
2022-03-14 02:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 22220 updates
2022-03-14 02:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:35:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 55 @ 22220 updates, score 6.816) (writing took 2.331595264025964 seconds)
2022-03-14 02:35:11 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 02:35:11 | INFO | train | epoch 055 | loss 6.641 | nll_loss 5.245 | ppl 37.93 | wps 24372.3 | ups 0.37 | wpb 65492.3 | bsz 127.9 | num_updates 22220 | lr 0.000212143 | gnorm 0.448 | loss_scale 32 | train_wall 953 | gb_free 9.7 | wall 52367
2022-03-14 02:35:11 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 02:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:38:39 | INFO | train_inner | epoch 056:     80 / 407 loss=6.618, nll_loss=5.218, ppl=37.22, wps=22303, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22300, lr=0.000211762, gnorm=0.452, loss_scale=32, train_wall=237, gb_free=9.7, wall=52575
2022-03-14 02:40:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:43:00 | INFO | train_inner | epoch 056:    181 / 407 loss=6.631, nll_loss=5.233, ppl=37.6, wps=25133.8, ups=0.38, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.446, loss_scale=32, train_wall=236, gb_free=9.7, wall=52836
2022-03-14 02:46:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:47:21 | INFO | train_inner | epoch 056:    282 / 407 loss=6.644, nll_loss=5.248, ppl=38.01, wps=25084.7, ups=0.38, wpb=65536, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.449, loss_scale=32, train_wall=237, gb_free=9.7, wall=53097
2022-03-14 02:51:39 | INFO | train_inner | epoch 056:    382 / 407 loss=6.653, nll_loss=5.259, ppl=38.29, wps=25401.8, ups=0.39, wpb=65534.2, bsz=128, num_updates=22600, lr=0.000210352, gnorm=0.449, loss_scale=32, train_wall=234, gb_free=9.7, wall=53355
2022-03-14 02:51:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:53:12 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.811 | nll_loss 5.361 | ppl 41.1 | wps 46477.6 | wpb 511.9 | bsz 1 | num_updates 22624 | best_loss 6.811
2022-03-14 02:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 22624 updates
2022-03-14 02:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:53:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:53:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 56 @ 22624 updates, score 6.811) (writing took 2.2355851989705116 seconds)
2022-03-14 02:53:15 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 02:53:15 | INFO | train | epoch 056 | loss 6.636 | nll_loss 5.239 | ppl 37.77 | wps 24416.7 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 22624 | lr 0.00021024 | gnorm 0.448 | loss_scale 32 | train_wall 953 | gb_free 9.7 | wall 53450
2022-03-14 02:53:15 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 02:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:56:32 | INFO | train_inner | epoch 057:     76 / 407 loss=6.614, nll_loss=5.213, ppl=37.1, wps=22349.9, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22700, lr=0.000209888, gnorm=0.448, loss_scale=32, train_wall=237, gb_free=9.7, wall=53648
2022-03-14 02:57:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:00:54 | INFO | train_inner | epoch 057:    177 / 407 loss=6.626, nll_loss=5.227, ppl=37.45, wps=24963.1, ups=0.38, wpb=65536, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.444, loss_scale=32, train_wall=238, gb_free=9.7, wall=53910
2022-03-14 03:03:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:05:15 | INFO | train_inner | epoch 057:    278 / 407 loss=6.634, nll_loss=5.237, ppl=37.7, wps=25152.3, ups=0.38, wpb=65534.2, bsz=128, num_updates=22900, lr=0.000208969, gnorm=0.447, loss_scale=32, train_wall=236, gb_free=9.7, wall=54171
2022-03-14 03:09:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:09:36 | INFO | train_inner | epoch 057:    379 / 407 loss=6.648, nll_loss=5.253, ppl=38.14, wps=25124, ups=0.38, wpb=65536, bsz=128, num_updates=23000, lr=0.000208514, gnorm=0.45, loss_scale=32, train_wall=236, gb_free=9.7, wall=54432
2022-03-14 03:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:11:17 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 6.812 | nll_loss 5.356 | ppl 40.95 | wps 46035.9 | wpb 511.9 | bsz 1 | num_updates 23028 | best_loss 6.811
2022-03-14 03:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 23028 updates
2022-03-14 03:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:11:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 57 @ 23028 updates, score 6.812) (writing took 1.2538929739966989 seconds)
2022-03-14 03:11:18 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 03:11:18 | INFO | train | epoch 057 | loss 6.631 | nll_loss 5.233 | ppl 37.61 | wps 24419.7 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 23028 | lr 0.000208388 | gnorm 0.447 | loss_scale 32 | train_wall 954 | gb_free 9.7 | wall 54534
2022-03-14 03:11:18 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 03:11:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:14:25 | INFO | train_inner | epoch 058:     72 / 407 loss=6.617, nll_loss=5.217, ppl=37.2, wps=22598.5, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=23100, lr=0.000208063, gnorm=0.448, loss_scale=32, train_wall=234, gb_free=9.7, wall=54721
2022-03-14 03:15:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:18:47 | INFO | train_inner | epoch 058:    173 / 407 loss=6.612, nll_loss=5.211, ppl=37.03, wps=24970.2, ups=0.38, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.447, loss_scale=32, train_wall=238, gb_free=9.7, wall=54983
2022-03-14 03:20:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:23:07 | INFO | train_inner | epoch 058:    274 / 407 loss=6.629, nll_loss=5.231, ppl=37.56, wps=25228.6, ups=0.38, wpb=65534.2, bsz=128, num_updates=23300, lr=0.000207168, gnorm=0.452, loss_scale=32, train_wall=235, gb_free=9.7, wall=55243
2022-03-14 03:26:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:27:27 | INFO | train_inner | epoch 058:    375 / 407 loss=6.64, nll_loss=5.245, ppl=37.92, wps=25217.1, ups=0.38, wpb=65536, bsz=128, num_updates=23400, lr=0.000206725, gnorm=0.451, loss_scale=32, train_wall=235, gb_free=9.7, wall=55503
2022-03-14 03:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:29:17 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 6.812 | nll_loss 5.36 | ppl 41.08 | wps 46388 | wpb 511.9 | bsz 1 | num_updates 23432 | best_loss 6.811
2022-03-14 03:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 23432 updates
2022-03-14 03:29:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 03:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 58 @ 23432 updates, score 6.812) (writing took 1.3107272170018405 seconds)
2022-03-14 03:29:19 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 03:29:19 | INFO | train | epoch 058 | loss 6.625 | nll_loss 5.227 | ppl 37.45 | wps 24491.4 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 23432 | lr 0.000206583 | gnorm 0.45 | loss_scale 32 | train_wall 951 | gb_free 9.7 | wall 55614
2022-03-14 03:29:19 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 03:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:32:13 | INFO | train_inner | epoch 059:     68 / 407 loss=6.614, nll_loss=5.213, ppl=37.1, wps=22873.8, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=23500, lr=0.000206284, gnorm=0.445, loss_scale=64, train_wall=231, gb_free=9.7, wall=55789
2022-03-14 03:32:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:36:33 | INFO | train_inner | epoch 059:    169 / 407 loss=6.61, nll_loss=5.209, ppl=36.99, wps=25172.3, ups=0.38, wpb=65534.2, bsz=128, num_updates=23600, lr=0.000205847, gnorm=0.452, loss_scale=32, train_wall=236, gb_free=9.7, wall=56049
2022-03-14 03:37:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:40:53 | INFO | train_inner | epoch 059:    270 / 407 loss=6.625, nll_loss=5.226, ppl=37.44, wps=25222.3, ups=0.38, wpb=65536, bsz=128, num_updates=23700, lr=0.000205412, gnorm=0.447, loss_scale=32, train_wall=235, gb_free=9.7, wall=56309
2022-03-14 03:43:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:45:13 | INFO | train_inner | epoch 059:    371 / 407 loss=6.635, nll_loss=5.238, ppl=37.75, wps=25251.1, ups=0.39, wpb=65536, bsz=128, num_updates=23800, lr=0.00020498, gnorm=0.449, loss_scale=32, train_wall=235, gb_free=9.7, wall=56568
2022-03-14 03:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:47:14 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 6.802 | nll_loss 5.348 | ppl 40.74 | wps 46468.1 | wpb 511.9 | bsz 1 | num_updates 23836 | best_loss 6.802
2022-03-14 03:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 23836 updates
2022-03-14 03:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_best.pt (epoch 59 @ 23836 updates, score 6.802) (writing took 2.3112489319755696 seconds)
2022-03-14 03:47:16 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 03:47:16 | INFO | train | epoch 059 | loss 6.621 | nll_loss 5.222 | ppl 37.31 | wps 24556.2 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 23836 | lr 0.000204825 | gnorm 0.448 | loss_scale 32 | train_wall 948 | gb_free 9.7 | wall 56692
2022-03-14 03:47:16 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 03:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:49:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:50:05 | INFO | train_inner | epoch 060:     65 / 407 loss=6.612, nll_loss=5.211, ppl=37.04, wps=22333.3, ups=0.34, wpb=65360.1, bsz=127.7, num_updates=23900, lr=0.000204551, gnorm=0.451, loss_scale=32, train_wall=237, gb_free=9.7, wall=56861
2022-03-14 03:54:26 | INFO | train_inner | epoch 060:    165 / 407 loss=6.601, nll_loss=5.198, ppl=36.7, wps=25104.9, ups=0.38, wpb=65536, bsz=128, num_updates=24000, lr=0.000204124, gnorm=0.451, loss_scale=32, train_wall=237, gb_free=9.7, wall=57122
2022-03-14 03:55:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:58:48 | INFO | train_inner | epoch 060:    266 / 407 loss=6.616, nll_loss=5.216, ppl=37.17, wps=25088.2, ups=0.38, wpb=65536, bsz=128, num_updates=24100, lr=0.0002037, gnorm=0.447, loss_scale=32, train_wall=237, gb_free=9.7, wall=57383
2022-03-14 04:00:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:03:08 | INFO | train_inner | epoch 060:    367 / 407 loss=6.636, nll_loss=5.239, ppl=37.76, wps=25122.3, ups=0.38, wpb=65536, bsz=128, num_updates=24200, lr=0.000203279, gnorm=0.447, loss_scale=32, train_wall=236, gb_free=9.7, wall=57644
2022-03-14 04:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:05:21 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 6.806 | nll_loss 5.351 | ppl 40.8 | wps 45859.7 | wpb 511.9 | bsz 1 | num_updates 24240 | best_loss 6.802
2022-03-14 04:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 24240 updates
2022-03-14 04:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 60 @ 24240 updates, score 6.806) (writing took 1.3417549200239591 seconds)
2022-03-14 04:05:22 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 04:05:22 | INFO | train | epoch 060 | loss 6.616 | nll_loss 5.216 | ppl 37.17 | wps 24360.4 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 24240 | lr 0.000203111 | gnorm 0.45 | loss_scale 32 | train_wall 957 | gb_free 9.7 | wall 57778
2022-03-14 04:05:22 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 04:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:06:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:08:01 | INFO | train_inner | epoch 061:     61 / 407 loss=6.61, nll_loss=5.209, ppl=36.99, wps=22318.4, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=24300, lr=0.00020286, gnorm=0.455, loss_scale=32, train_wall=238, gb_free=9.7, wall=57937
2022-03-14 04:12:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:12:22 | INFO | train_inner | epoch 061:    162 / 407 loss=6.603, nll_loss=5.2, ppl=36.76, wps=25122.2, ups=0.38, wpb=65536, bsz=128, num_updates=24400, lr=0.000202444, gnorm=0.453, loss_scale=32, train_wall=236, gb_free=9.7, wall=58198
2022-03-14 04:16:40 | INFO | train_inner | epoch 061:    262 / 407 loss=6.611, nll_loss=5.21, ppl=37.01, wps=25410.3, ups=0.39, wpb=65534.2, bsz=128, num_updates=24500, lr=0.000202031, gnorm=0.449, loss_scale=32, train_wall=234, gb_free=9.7, wall=58456
2022-03-14 04:17:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:21:02 | INFO | train_inner | epoch 061:    363 / 407 loss=6.626, nll_loss=5.228, ppl=37.48, wps=25035.9, ups=0.38, wpb=65536, bsz=128, num_updates=24600, lr=0.000201619, gnorm=0.451, loss_scale=32, train_wall=237, gb_free=9.7, wall=58718
2022-03-14 04:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:23:23 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 6.803 | nll_loss 5.345 | ppl 40.65 | wps 46195.8 | wpb 511.9 | bsz 1 | num_updates 24644 | best_loss 6.802
2022-03-14 04:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 24644 updates
2022-03-14 04:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:23:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 61 @ 24644 updates, score 6.803) (writing took 1.2637827500002459 seconds)
2022-03-14 04:23:25 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 04:23:25 | INFO | train | epoch 061 | loss 6.612 | nll_loss 5.211 | ppl 37.03 | wps 24441.9 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 24644 | lr 0.000201439 | gnorm 0.452 | loss_scale 32 | train_wall 953 | gb_free 9.7 | wall 58860
2022-03-14 04:23:25 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 04:23:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:25:51 | INFO | train_inner | epoch 062:     57 / 407 loss=6.607, nll_loss=5.205, ppl=36.89, wps=22637.6, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=24700, lr=0.000201211, gnorm=0.449, loss_scale=32, train_wall=234, gb_free=9.7, wall=59006
2022-03-14 04:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:30:12 | INFO | train_inner | epoch 062:    158 / 407 loss=6.595, nll_loss=5.191, ppl=36.52, wps=25061.6, ups=0.38, wpb=65534.2, bsz=128, num_updates=24800, lr=0.000200805, gnorm=0.452, loss_scale=32, train_wall=237, gb_free=9.7, wall=59268
2022-03-14 04:34:30 | INFO | train_inner | epoch 062:    258 / 407 loss=6.609, nll_loss=5.207, ppl=36.94, wps=25389.7, ups=0.39, wpb=65536, bsz=128, num_updates=24900, lr=0.000200401, gnorm=0.453, loss_scale=32, train_wall=234, gb_free=9.7, wall=59526
2022-03-14 04:35:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:38:50 | INFO | train_inner | epoch 062:    359 / 407 loss=6.623, nll_loss=5.224, ppl=37.37, wps=25240, ups=0.39, wpb=65536, bsz=128, num_updates=25000, lr=0.0002, gnorm=0.454, loss_scale=32, train_wall=235, gb_free=9.7, wall=59786
2022-03-14 04:40:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:40:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:41:22 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 6.804 | nll_loss 5.345 | ppl 40.63 | wps 46068 | wpb 511.9 | bsz 1 | num_updates 25047 | best_loss 6.802
2022-03-14 04:41:22 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 04:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 25047 updates
2022-03-14 04:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.1_dropout_0.3_#1/checkpoint_last.pt (epoch 62 @ 25047 updates, score 6.804) (writing took 1.2784360200166702 seconds)
2022-03-14 04:41:23 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 04:41:23 | INFO | train | epoch 062 | loss 6.607 | nll_loss 5.205 | ppl 36.89 | wps 24471.6 | ups 0.37 | wpb 65492.3 | bsz 127.9 | num_updates 25047 | lr 0.000199812 | gnorm 0.452 | loss_scale 32 | train_wall 950 | gb_free 9.7 | wall 59939
2022-03-14 04:41:23 | INFO | fairseq_cli.train | done training in 59938.8 seconds
