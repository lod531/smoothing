Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 210580215: <iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:22:18 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:22:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:22:23 2022
Terminated at Wed Mar 23 10:13:50 2022
Results reported at Wed Mar 23 10:13:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.05 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3077.70 sec.
    Max Memory :                                 5175 MB
    Average Memory :                             3952.51 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14825.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3087 sec.
    Turnaround time :                            3092 sec.

The output (if any) follows:

2022-03-23 09:22:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.05, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.05, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:22:31 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:22:31 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:22:31 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:22:31 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:22:31 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:22:31 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:22:31 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:22:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:22:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:22:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:22:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:22:37 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:22:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:22:37 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:22:37 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:22:37 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:22:37 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:22:37 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:22:37 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:22:37 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:22:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:22:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:22:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:22:37 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:22:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:22:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:22:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:22:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:23:14 | INFO | train_inner | epoch 001:    104 / 157 loss=11.932, nll_loss=11.85, ppl=3691.06, wps=78408.1, ups=3.12, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.566, loss_scale=8, train_wall=36, gb_free=13.6, wall=37
2022-03-23 09:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:23:33 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:23:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:23:36 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 09:23:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:23:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,
2022-03-23 09:23:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:23:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 09:23:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:23:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:48 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:23:54 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:23:59 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:23:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:24:04 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:24:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:24:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.231 | nll_loss 10.05 | ppl 1059.95 | bleu 0.01 | wps 4011.2 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.676218728069216 seconds)
2022-03-23 09:24:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:24:16 | INFO | train | epoch 001 | loss 11.506 | nll_loss 11.4 | ppl 2702.38 | wps 40717.2 | ups 1.62 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.761 | loss_scale 8 | train_wall 52 | gb_free 13.9 | wall 99
2022-03-23 09:24:16 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:31 | INFO | train_inner | epoch 002:     47 / 157 loss=10.46, nll_loss=10.295, ppl=1256, wps=32397.6, ups=1.3, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.271, loss_scale=8, train_wall=30, gb_free=22.4, wall=114
2022-03-23 09:25:02 | INFO | train_inner | epoch 002:    147 / 157 loss=9.616, nll_loss=9.388, ppl=670.06, wps=79188.9, ups=3.16, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.398, loss_scale=8, train_wall=31, gb_free=13.9, wall=145
2022-03-23 09:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:25:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 09:25:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:25:15 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i i i.
2022-03-23 09:25:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:25:19 | INFO | fairseq.tasks.translation | example hypothesis: so,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 09:25:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:25:24 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 09:25:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:25:29 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:25:41 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:25:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:25:48 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:25:50 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:25:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:25:50 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.206 | nll_loss 8.919 | ppl 484.11 | bleu 0.02 | wps 3931.2 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:25:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:25:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7964706192724407 seconds)
2022-03-23 09:25:52 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:25:52 | INFO | train | epoch 002 | loss 9.765 | nll_loss 9.549 | ppl 749.23 | wps 40875.6 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.356 | loss_scale 8 | train_wall 49 | gb_free 14 | wall 195
2022-03-23 09:25:53 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:21 | INFO | train_inner | epoch 003:     90 / 157 loss=9.268, nll_loss=8.996, ppl=510.65, wps=31653.2, ups=1.27, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.304, loss_scale=8, train_wall=31, gb_free=13.9, wall=224
2022-03-23 09:26:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example hypothesis: it's's a.
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:26:50 | INFO | fairseq.tasks.translation | example hypothesis: he he he.
2022-03-23 09:26:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to to a a a a a a.
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was, he he was was was was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we, we, we we, we we, we we, we, we we, we we, we, we, we, we we, we, we, we, we, we
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we to we we we to we to we to we to to to to to to to to we we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:27:16 | INFO | fairseq.tasks.translation | example hypothesis: and if if if if if if if if if if if if if if if you you you you, you you you you you you you you the, you you you you you you you the, but the, but the, but the, but the, but the, but the, but the, but the, but but but but but but the,
2022-03-23 09:27:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we the, and we we the, and we we we the, we, we the, we, we we the, we, and we, and we the, we we, and we the, we, we, and we we we we we, we, and we the, and we we we we we we we we we we we we we to the, and we we we the, and we, and we we we we
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:29 | INFO | fairseq.tasks.translation | example hypothesis: and and and you, "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:27:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:32 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and the, the, and the, and the, and the, and the, and we we the, and the, and the, the, we we the, the, and the, the, and the, and the, we we we, and the, and the, we we we we we we the, and the, and the, and the, and the, and the, and we we we we we we the, and the, and the, and the, and the, and the, the, and the, the, and the, and the, and the, and the, and the, we we we we we we we that that that that that that that that that that that that the, we we we we we we we we we the, and the, and the, and the, and the, and the, and the, we we we we we we we we the, we we, and the, the, the, and the, we, we, we, we,
2022-03-23 09:27:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:32 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.918 | nll_loss 8.593 | ppl 386.22 | bleu 0.13 | wps 3568.1 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.13
2022-03-23 09:27:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:27:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.13) (writing took 1.7908396497368813 seconds)
2022-03-23 09:27:34 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:27:34 | INFO | train | epoch 003 | loss 9.16 | nll_loss 8.878 | ppl 470.4 | wps 38653.6 | ups 1.54 | wpb 25122.4 | bsz 1014.9 | num_updates 466 | lr 5.825e-05 | gnorm 1.373 | loss_scale 4 | train_wall 49 | gb_free 14.8 | wall 297
2022-03-23 09:27:34 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:45 | INFO | train_inner | epoch 004:     34 / 157 loss=9.005, nll_loss=8.708, ppl=418.17, wps=30468.7, ups=1.19, wpb=25511.1, bsz=1058.2, num_updates=500, lr=6.25e-05, gnorm=1.357, loss_scale=4, train_wall=31, gb_free=14.7, wall=308
2022-03-23 09:28:16 | INFO | train_inner | epoch 004:    134 / 157 loss=8.677, nll_loss=8.356, ppl=327.65, wps=79783, ups=3.16, wpb=25228.8, bsz=1092.2, num_updates=600, lr=7.5e-05, gnorm=1.604, loss_scale=4, train_wall=31, gb_free=14, wall=340
2022-03-23 09:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:28 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:28:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:28:34 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was the world of the world of the world of the world of the world, he can can can can can can can can can
2022-03-23 09:28:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:28:40 | INFO | fairseq.tasks.translation | example hypothesis: and i think a lot of this is a lot of a lot of a lot of a lot, i've've can can can can can can can can can can can can can
2022-03-23 09:28:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:28:45 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was was he was he was was he was was was was was he was was was was was was was was was was was he was was was was was he was was was was was was
2022-03-23 09:28:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:28:51 | INFO | fairseq.tasks.translation | example hypothesis: and so, what we know, what we know, what what what we're're're're're're're're're're're're going to do what what what what what what we're're're're're're're going to do do do
2022-03-23 09:28:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:28:57 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we can can can can can can can can can can can can can can can can can can see the or or or or or or or or or or or or or or or or or or or.
2022-03-23 09:28:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:29:03 | INFO | fairseq.tasks.translation | example hypothesis: but you have the way, but they're're're're're're have the world, but but they're're're have the world, and they're're have the world, but but they're're're're're're're're're're're're're're're're're're're have the world, but but they're the world, and they're
2022-03-23 09:29:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:09 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we can can can can can can can see the world of the world, and we can can can can can see the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world of the world of the world
2022-03-23 09:29:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's this is the way, and we've've've've've've've've've've've've've've've've've've've've've've've have to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be the world, "" "" "" "" "" the world, "" "" "" "" "" "" "" "" "" "" "" "" "" "" that's the world, and the world, and the world, and the world, and you can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be a
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:19 | INFO | fairseq.tasks.translation | example hypothesis: so, we have the world of the world of the world of the world, and we've've've've've've've've've've've've have the world of the world of the world, and the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we can can can can can can can see the world of the world, and the world of the world, and the world of the world of the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be be
2022-03-23 09:29:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:19 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.387 | nll_loss 8.03 | ppl 261.39 | bleu 0.79 | wps 3223.3 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.79
2022-03-23 09:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.79) (writing took 1.7607092401012778 seconds)
2022-03-23 09:29:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:29:21 | INFO | train | epoch 004 | loss 8.739 | nll_loss 8.423 | ppl 343.17 | wps 36760.3 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.477 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 404
2022-03-23 09:29:21 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:46 | INFO | train_inner | epoch 005:     77 / 157 loss=8.386, nll_loss=8.041, ppl=263.38, wps=28152.4, ups=1.12, wpb=25101.8, bsz=1058.5, num_updates=700, lr=8.75e-05, gnorm=1.77, loss_scale=4, train_wall=30, gb_free=14, wall=429
2022-03-23 09:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:15 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can can can can can can can can can can can can can can can can can.
2022-03-23 09:30:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:20 | INFO | fairseq.tasks.translation | example hypothesis: and he can can can can be in the time, he can can can can can can can can can can can can can can can can can can
2022-03-23 09:30:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example hypothesis: and i can can be a lot of a lot of a lot, i can can can can can be a lot of a lot of the world.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was his
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:30:37 | INFO | fairseq.tasks.translation | example hypothesis: and we have a lot of what we know, and we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we know, and we have to do
2022-03-23 09:30:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:30:43 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we have to do or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or we can can can can can can can can can see or or or or or or or
2022-03-23 09:30:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: but if if if if you're a lot of the world, but they are not not not not not not not not not not not not not not not, but they're the world, but they're the world, but they are the world, but they are the world, but they are the world, but they are not not not not not not not
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can can see the world, and we can can can can see the world, and we can see the world, and we can can see
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example hypothesis: and he said, "i said," i said, "" "" "we said," i said, "i said," "" "" "" "" we said, "i said," we said, "i said," we said, "we said," "" "i said," "" "" "we said," i said, "i said," i said, "i said," we said, "" "" "" "" "" "" "" "" "we said, and i said, and i said, and i said, and i said, and i said," "" "" "" "" we said, and i said, "i said," we said, "i said," "" we said, "i said," "we said," i said, "
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example hypothesis: and if if if we think, if if if if if if if if if if if if if if if if if if if we have the first first first, we have to see the world, and we have to see the world, it, and it, and it, and it's a first first first first first first first first first first first first first first first first first first first first first first first first first first first, and we have to be, and it, and it, and it, and it, and it, and it, and it's, and it, and it's, and it's a first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, and we think, and we think, and it's, and we think, and we think, and we think, and we think, and we think,
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:05 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.977 | nll_loss 7.578 | ppl 191.02 | bleu 1.1 | wps 3283.2 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.1
2022-03-23 09:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:31:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.1) (writing took 1.7855427339673042 seconds)
2022-03-23 09:31:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:31:07 | INFO | train | epoch 005 | loss 8.292 | nll_loss 7.938 | ppl 245.26 | wps 37400.1 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.732 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 510
2022-03-23 09:31:07 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:14 | INFO | train_inner | epoch 006:     20 / 157 loss=8.213, nll_loss=7.852, ppl=231.11, wps=28561.2, ups=1.14, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.557, loss_scale=4, train_wall=31, gb_free=14, wall=517
2022-03-23 09:31:45 | INFO | train_inner | epoch 006:    120 / 157 loss=7.975, nll_loss=7.592, ppl=193, wps=79603.9, ups=3.18, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.468, loss_scale=4, train_wall=31, gb_free=14, wall=548
2022-03-23 09:31:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example hypothesis: these are not not not just just just just just just just just just just.
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:05 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the world.
2022-03-23 09:32:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:32:09 | INFO | fairseq.tasks.translation | example hypothesis: now, i can can be a lot of the way of the way of the way of the way, because i can be a way.
2022-03-23 09:32:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:32:14 | INFO | fairseq.tasks.translation | example hypothesis: he said, because he was a few years, because he was been been been been been been been been been been been been been been been been been been been been been him.
2022-03-23 09:32:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do we're going to do, and we're going to do a little little bit of what we're going to do, and we're going to do, and we're going to do this is a bit
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:32:26 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about the world, or we're going to talk about the world, or the world, or the world, or the world, or our world, or we're going to talk about the world, or the world, or the world, or our world,
2022-03-23 09:32:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if you're going to have a lot of the way of the way of these people are not just just just just just just just just just just just just been been been been been been been been been been going to make the world, but they're going to make the world, but they're going to make the world, but they're going to
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the world, and we're going to see the world, and we're going to make the world, and we're going to see the world, and we're going to see the world, and we're going to see the world, and we're going to see the world of the world, and we can see the world, and we're going to see the world, and we're going to see the world of the world
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example hypothesis: so, if we said, "we're going to go to go to say," "" "we're going to go to go to go to the world," we're going to go to be the world, "that we're going to say," "we're going to go to do that we're going to go with the world," the world, "we're going to do the world," it's going to go to go to go to go to go with the world, "that we're going to go to go to go with the world," that we're going to go to go to be a first first first first first first first first first first first first first first first first first, "that we're going to say," there's going to do the world, "the world," there's going to be the world, "the world," the
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example hypothesis: so, there's a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to make the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which we're going to have a lot of the world, which is a lot of the world, which is that we're going to
2022-03-23 09:32:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:48 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.569 | nll_loss 7.138 | ppl 140.87 | bleu 1.58 | wps 3461.1 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.58
2022-03-23 09:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:32:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.58) (writing took 1.8164454908110201 seconds)
2022-03-23 09:32:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:32:50 | INFO | train | epoch 006 | loss 7.886 | nll_loss 7.498 | ppl 180.8 | wps 38340.8 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.491 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 613
2022-03-23 09:32:50 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:10 | INFO | train_inner | epoch 007:     63 / 157 loss=7.697, nll_loss=7.293, ppl=156.82, wps=29364.4, ups=1.18, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.43, loss_scale=4, train_wall=31, gb_free=13.8, wall=633
2022-03-23 09:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:43 | INFO | fairseq.tasks.translation | example hypothesis: these can't be no.
2022-03-23 09:33:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:33:47 | INFO | fairseq.tasks.translation | example hypothesis: and then, in the year.
2022-03-23 09:33:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example hypothesis: now, i can't have a lot of course.
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:33:55 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was his father, because he was his father.
2022-03-23 09:33:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:34:00 | INFO | fairseq.tasks.translation | example hypothesis: so, what we've got to do, and we have a lot of us, and we're going to do, and we're going to do what we're going to do?
2022-03-23 09:34:00 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:34:04 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to do our time, or or or or or or or our things, or we're going to do.
2022-03-23 09:34:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:34:09 | INFO | fairseq.tasks.translation | example hypothesis: now, there are some of the same, but you're not not not not not, but if you can see, but it, but it's not not not not the same, but you can see the way, but you can see the way.
2022-03-23 09:34:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to find the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world,
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example hypothesis: "well," "" "" "" "" "" "" "" "" "" "well," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to see that, if you're going to see the middle, and if we're going to see, if we're going to see the middle, and if we're going to see that we're going to see the world, and we're going to see the world, if we're going to get the world, and we're going to see the world, if we're going to be a, and we're going to see the middle of the world, if we're going to get to see the world, and if we're going to get to see the world, and we're going to get to see the middle of the world, and we're going to get to see the middle, and we're going to see the middle, and we're going to see the middle of the world, and we're going to see the world, if we're going to be a, and we're going to be a, and we're going to see the middle of the world, and we're going to see the middle of the
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.279 | nll_loss 6.815 | ppl 112.61 | bleu 2.73 | wps 3967.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.73
2022-03-23 09:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.73) (writing took 1.778723469004035 seconds)
2022-03-23 09:34:26 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:34:26 | INFO | train | epoch 007 | loss 7.61 | nll_loss 7.198 | ppl 146.87 | wps 40799.1 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.419 | loss_scale 4 | train_wall 49 | gb_free 13.8 | wall 709
2022-03-23 09:34:27 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:29 | INFO | train_inner | epoch 008:      6 / 157 loss=7.515, nll_loss=7.096, ppl=136.84, wps=32205.4, ups=1.27, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.452, loss_scale=4, train_wall=31, gb_free=15.3, wall=712
2022-03-23 09:35:00 | INFO | train_inner | epoch 008:    106 / 157 loss=7.318, nll_loss=6.883, ppl=118, wps=79365.7, ups=3.17, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=1.303, loss_scale=4, train_wall=31, gb_free=22.4, wall=743
2022-03-23 09:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:21 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to be able to use the brain.
2022-03-23 09:35:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the last year, he can have a year in the last year.
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:35:30 | INFO | fairseq.tasks.translation | example hypothesis: so, this can see, i can get a lot of course.
2022-03-23 09:35:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:35:34 | INFO | fairseq.tasks.translation | example hypothesis: he had his father had his father, because he had his father was his father.
2022-03-23 09:35:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:35:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a friend, and what we're going to do with what we're going to do, and what we're going to do?
2022-03-23 09:35:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:35:43 | INFO | fairseq.tasks.translation | example hypothesis: so we're doing our time that we're going to talk about how to talk about the world or or or or or or or or the other other other other or or or or or or or or or or or or or or or or about the other other other other or or or or or
2022-03-23 09:35:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example hypothesis: so some of some of some of the states, but if you don't look at the brain, but they don't have to get it, but if you're not not not not not the way, but they don't get it.
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get the way that we can see the brain, and we can see the world, and we can see that we can see the brain of the brain, and then we can make it.
2022-03-23 09:35:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:58 | INFO | fairseq.tasks.translation | example hypothesis: : one of the one of the one of the one of the one of the first one, and it's going to say, "and it's going to say that we're going to say," if you're going to say that we're going to say, "and then we're going to say," well, "and then we're going to say," well, "well," well, "well," well, "well," well, "if you're going to say," well, "well," well, "if you're going to say," well, "well," if you're going to say, and we're going to say, "well," if you're going to say, "if you're going to say," if you're going to say, "if you're going to say, you're going to say,"
2022-03-23 09:35:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: and the second thing is, if you're going to get the first time, and if we're going to get the first thing that we're going to get a little bit of the way that we're going to get to get the way that we're going to get to be a little bit of the way that we're going to get to get a little bit of the way that we're going to be a little bit of the way to get to get a little bit of the way that we're going to get to get to get to get to get to be a little bit of the way that we're going to get a lot of the way to get to get to get to get to get to get the way that we're going to get to be a little bit of the first time that we're going to get a little bit of the first time that we're going to get the way that we're going to get it, and that we're going to be a little bit of the way, or a little bit of the way that we're going
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:00 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.953 | nll_loss 6.459 | ppl 87.96 | bleu 4.14 | wps 4202.1 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 4.14
2022-03-23 09:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:36:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 4.14) (writing took 1.7855106047354639 seconds)
2022-03-23 09:36:02 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:36:02 | INFO | train | epoch 008 | loss 7.302 | nll_loss 6.865 | ppl 116.59 | wps 41445.6 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.316 | loss_scale 4 | train_wall 49 | gb_free 14.1 | wall 805
2022-03-23 09:36:02 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:17 | INFO | train_inner | epoch 009:     49 / 157 loss=7.19, nll_loss=6.743, ppl=107.12, wps=32665.5, ups=1.3, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.412, loss_scale=4, train_wall=31, gb_free=13.6, wall=821
2022-03-23 09:36:49 | INFO | train_inner | epoch 009:    149 / 157 loss=7.012, nll_loss=6.551, ppl=93.75, wps=80004, ups=3.16, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.281, loss_scale=4, train_wall=31, gb_free=14, wall=852
2022-03-23 09:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:36:59 | INFO | fairseq.tasks.translation | example hypothesis: so, he can be about about 100 percent.
2022-03-23 09:36:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:37:03 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, i can be a lot of course, and i can use a lot of course.
2022-03-23 09:37:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:37:08 | INFO | fairseq.tasks.translation | example hypothesis: he didn't never never never never never never seen his father because he had his father, because she had his father, she was his father.
2022-03-23 09:37:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:37:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i've got a friend, and we got a friend, so we're going to do what we're doing?
2022-03-23 09:37:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:37:17 | INFO | fairseq.tasks.translation | example hypothesis: so, we've got time to talk about things about things about things, and we don't talk about how to talk about the other things or or the other other other or or the other other other or or or the other other other other other or the other or or the other other or the
2022-03-23 09:37:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are in the water, but if you don't think it doesn't have the way, but if you don't use it, but they don't have the way, they don't use it, and they don't use it.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at this information, we can see this information, we can see this information, and we can see a little bit of the brain, and then we can see that we can see the environment, and then we can see the kind of the kind of the environment, and then we can see that we can see that we can see the environment, and then we can create a little bit of the kind of the environment, which is a kind of the
2022-03-23 09:37:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example hypothesis: "one of the reason, and it's the first thing, and it's going to say," and it's going to say, "and then we're going to say," if we're going to say, "if we're going to say," if we're going to say, "you're going to say," and then we're going to say, "if we're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," and then we're going to say, "" "" "and then we're going to say," if we're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to do
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example hypothesis: well, it's not a lot of the mother, and when we've got a lot of the first time, if we're going to see that we're going to get a lot of the way that we're going to see that we're going to see that we're going to get a lot of the brain, and then if we're going to see that we're going to see that we're going to see that we're going to see that we're going to get a lot of a lot of the brain, or a lot of the brain, and then we're going to see that if we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that if we're going to see that we're going to see in a lot of these are going to get a lot of the brain,
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.668 | nll_loss 6.141 | ppl 70.56 | bleu 5 | wps 3752.5 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5
2022-03-23 09:37:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:37:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:37:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.0) (writing took 1.7930513247847557 seconds)
2022-03-23 09:37:41 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:37:41 | INFO | train | epoch 009 | loss 7.03 | nll_loss 6.57 | ppl 95.01 | wps 39944.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.34 | loss_scale 4 | train_wall 49 | gb_free 14.1 | wall 904
2022-03-23 09:37:41 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:10 | INFO | train_inner | epoch 010:     92 / 157 loss=6.756, nll_loss=6.273, ppl=77.34, wps=31379.6, ups=1.23, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.511, loss_scale=4, train_wall=31, gb_free=12.6, wall=933
2022-03-23 09:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:34 | INFO | fairseq.tasks.translation | example hypothesis: these can't have no form.
2022-03-23 09:38:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:38:38 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about 770,000 dollars.
2022-03-23 09:38:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:38:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the course of course, i can do a lot of course, a lot of course.
2022-03-23 09:38:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father was his mother when she had his mother with his father.
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a lot of girls and a child, so we have a child, so we're doing what we do?
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example hypothesis: and so we have our time to do things about things, and we don't talk about the same time or 15 years or 15 years or every time.
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:38:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bbbbbbes, but if you don't have to do it, and if you don't need to do it, and so that's so that's so much.
2022-03-23 09:38:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can see this information, we can take a little bit of a lot of information, and then we can see a little bit of the environment.
2022-03-23 09:39:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example hypothesis: "one of the reasons that it's interesting, and it's interesting for me for me for me to say," and then we have to say, "you know," if you're going to say, "well," well, "if you're going to say," well, "you're going to say," well, "you're going to say," well, "well," well, "well," well, "well," well, "if we're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," for this is the first, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "
2022-03-23 09:39:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:08 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still still still the mother, and we have a lot of work that we had a lot of work, or if we had to see that we had to get a very important way to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it.
2022-03-23 09:39:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:08 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.31 | nll_loss 5.754 | ppl 53.95 | bleu 8.71 | wps 4786 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 8.71
2022-03-23 09:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:39:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 8.71) (writing took 1.8112237839959562 seconds)
2022-03-23 09:39:10 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:39:10 | INFO | train | epoch 010 | loss 6.762 | nll_loss 6.279 | ppl 77.63 | wps 44037.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.4 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 993
2022-03-23 09:39:11 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:22 | INFO | train_inner | epoch 011:     35 / 157 loss=6.716, nll_loss=6.228, ppl=74.97, wps=34833.9, ups=1.4, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=1.31, loss_scale=4, train_wall=31, gb_free=22.4, wall=1005
2022-03-23 09:39:53 | INFO | train_inner | epoch 011:    135 / 157 loss=6.462, nll_loss=5.954, ppl=61.99, wps=79851.4, ups=3.16, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=1.277, loss_scale=4, train_wall=31, gb_free=14.4, wall=1036
2022-03-23 09:40:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:04 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these cells.
2022-03-23 09:40:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:08 | INFO | fairseq.tasks.translation | example hypothesis: year, he can be about about 880,000 miles in the house.
2022-03-23 09:40:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:40:12 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course, of course, i can also also also have a lot of course of course.
2022-03-23 09:40:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:40:17 | INFO | fairseq.tasks.translation | example hypothesis: he had never seen his father because his father had his mother because his mother had his mother, she had his mother with his mother.
2022-03-23 09:40:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:40:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a lot of aids, and a child has got a child, so we asked us to do what we do?
2022-03-23 09:40:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:40:25 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time about time, how we're talking about things about the same time, and not talking about the cost of the world.
2022-03-23 09:40:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of you are some of the madddle in the size, but it doesn't have any energy, but if you need the energy, you need to need the energy.
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information that we can start from this information, we can start from one of one of one of the information, and then we can start through the information, and all of the information.
2022-03-23 09:40:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example hypothesis: second: one of the reasons that it's interesting, and it's interesting for me for me for me for me, "i'm going to say," you know, "you're going to say," you know, "you're going to say," the best. "
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's always always always always always the mother, and the great work of the work that we're working on our work, and we're going to see that we're going to see a new system, or to see that it's going to be able to be able to be able to make a whole system, or to see that we're going to be able to be able to see that we're going to see that it.
2022-03-23 09:40:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.049 | nll_loss 5.455 | ppl 43.87 | bleu 10.3 | wps 4523.6 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.3
2022-03-23 09:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.3) (writing took 1.8308674818836153 seconds)
2022-03-23 09:40:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:40:42 | INFO | train | epoch 011 | loss 6.449 | nll_loss 5.94 | ppl 61.41 | wps 42969.4 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.285 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1085
2022-03-23 09:40:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:07 | INFO | train_inner | epoch 012:     78 / 157 loss=6.099, nll_loss=5.564, ppl=47.3, wps=34600.4, ups=1.35, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=1.248, loss_scale=4, train_wall=31, gb_free=14.8, wall=1110
2022-03-23 09:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use any chemical chemical materials.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about about 88888880s in the restaurant.
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example hypothesis: so this pattern can also be able to be a lot of course, i can also be able to make a bibibibible.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example hypothesis: he had his father to never learned his father because his father had his mother, she had his father with him.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:41:53 | INFO | fairseq.tasks.translation | example hypothesis: and one of my grandgrandgrandgrandgrandgrandparents has been a child and a child, so we asked us, what do we do?
2022-03-23 09:41:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:41:57 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about how things about the time, and not talk about the time, or not about poverty or any of poverty or any of poverty or every time.
2022-03-23 09:41:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:42:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are some of the madddle in the field, but it doesn't like it, but if you don't need the energy, if you don't need your energy, if you need the energy, it's so the energy, you need to use the energy, you need to use the energy, you need to do
2022-03-23 09:42:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information, the information of this reflect, we can start with one of the traditional cness, we can start with a little bit of the structure, and we can start with the structure of the structure, and the structure of the structure, and the structure of the structure of the structure, and the structure, and the structure of the structure, and the information, and the structure of the information, and the structure of the structure, and
2022-03-23 09:42:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example hypothesis: fifth: one of the reasons, and it's interesting to be interesting for me, for me, for me, "yes," yes, "yes," yes, "yes," yes, "well," well, "if you say," oh, "oh," oh, "well," well, "well," well, "well," well, "if you've got the best," oh, "oh," oh, "oh," oh, "oh," oh, "well," oh, "oh," oh, "oh," well, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "the best," the best, "the best," the best, "the best," the best, "the best
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:15 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still the mother, and the media part of the work that we had a great work on our work on our work, we had to see that if we were able to use it, or to see that if we were able to use it, or to use it's all the same system, or to use it's all the same system, or to use it's going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to use the same system, or to see that if we were able to use it's all the same system, or to see that if we were able to use it, or to see that if we were able to use it's all of a whole system, or a whole whole whole whole whole whole system, or to take a
2022-03-23 09:42:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:15 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.718 | nll_loss 5.093 | ppl 34.12 | bleu 11.26 | wps 4221 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.26
2022-03-23 09:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:42:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:42:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.26) (writing took 1.7944012340158224 seconds)
2022-03-23 09:42:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:42:16 | INFO | train | epoch 012 | loss 6.162 | nll_loss 5.629 | ppl 49.5 | wps 41856.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.289 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1180
2022-03-23 09:42:17 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:24 | INFO | train_inner | epoch 013:     21 / 157 loss=6.161, nll_loss=5.627, ppl=49.42, wps=32251, ups=1.31, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=1.253, loss_scale=4, train_wall=31, gb_free=14.1, wall=1187
2022-03-23 09:42:55 | INFO | train_inner | epoch 013:    121 / 157 loss=5.91, nll_loss=5.355, ppl=40.94, wps=79444.8, ups=3.16, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=1.36, loss_scale=4, train_wall=31, gb_free=13.9, wall=1219
2022-03-23 09:43:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:10 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical chemical molecule.
2022-03-23 09:43:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8888888-restaurant.
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example hypothesis: these rrres can also be able to be able to be able to form a lot of forms.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:43:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had his mother.
2022-03-23 09:43:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:43:25 | INFO | fairseq.tasks.translation | example hypothesis: so one of my coups is a child and died of aids, so we asked us to do what do?
2022-03-23 09:43:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things that we don't talk about food, or not talk about the quality of poverty.
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:43:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are mamac lines, but it doesn't like it, but if you don't need it, if you don't need your energy, if you need your energy and so you need the energy.
2022-03-23 09:43:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information from this reflection that we can start with a traditional traditional network, we can start to start with a big form of the form of the form of the form of the form of the form of the information, and then the information that's going through it.
2022-03-23 09:43:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:41 | INFO | fairseq.tasks.translation | example hypothesis: th th: the reasons that it's interesting, and it's interesting for me to be here for me.
2022-03-23 09:43:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:43 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and the big work that we had to see the airplane on our airplane that we had to be able to be able to be able to be able to be able to be able to be able to make it.
2022-03-23 09:43:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:43 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.517 | nll_loss 4.879 | ppl 29.42 | bleu 10.84 | wps 4967.1 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.26
2022-03-23 09:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:43:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 10.84) (writing took 0.7826937800273299 seconds)
2022-03-23 09:43:44 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:43:44 | INFO | train | epoch 013 | loss 5.893 | nll_loss 5.337 | ppl 40.42 | wps 45070.3 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.297 | loss_scale 4 | train_wall 49 | gb_free 14 | wall 1267
2022-03-23 09:43:44 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:43:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:05 | INFO | train_inner | epoch 014:     64 / 157 loss=5.68, nll_loss=5.106, ppl=34.44, wps=36734.5, ups=1.44, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=1.217, loss_scale=4, train_wall=31, gb_free=13.9, wall=1288
2022-03-23 09:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:38 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical chemical chemical chemical chemical chemical chemical.
2022-03-23 09:44:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:44:42 | INFO | fairseq.tasks.translation | example hypothesis: and then, it can be about 8,000 dollars in the restaurant in the restaurant.
2022-03-23 09:44:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:44:47 | INFO | fairseq.tasks.translation | example hypothesis: this rrum can, of course, of course, i can also have a sense of course, of course, of course, of course, of course, of course,
2022-03-23 09:44:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:44:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, because she had learned his mother with him.
2022-03-23 09:44:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:44:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my coups has died in aids and died a child, so we asked us what do we do with aids?
2022-03-23 09:44:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:45:00 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things like gender, and not talking about how to talk about, or the nuclear weapons of poverty or poverty, or any other of poverty.
2022-03-23 09:45:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of magnetic magnetic field in the field, but it doesn't like that, if you don't need to move, you know, you don't need to move your energy, and you need the power of energy.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the reflection of this reflection, we can start with a traditional traditional face, and you can begin to start with the structure of the structure, and so if all the information of the information is all the information of the information, and the information, and so if you can use it all the information, the information, the information, the information, the information, the information, the information, the information of information
2022-03-23 09:45:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me for tedtedtalks to be here, "well, when we said," if you've got the best revolution, you know, you're going to say, "you know, you know, you know, you know," the first time, you've got to have a long time to have the first time to have a long time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to have a long time to have a long time to have a long time to have a long time to have a long time, "oh, you know, you know, you know, you know, you know, you know, you're going to have a long time to do it's going to
2022-03-23 09:45:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:19 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need still the mother, and the invention of the invention of design is a big design design that we had to use the aircraft, if we had to use it, it's all the way we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use that if you to use with a solar solar solar solar solar solar solar solar solar solar solar solar solar solar solar solar system, or the aircraft, or the aircraft, or the aircraft, or the air, or the air, or the air, or the bottom, or the bottom of the bottom, if you're still use that you're still able to use, if you're still able to use that you're still able to use, if you're still able to use it's still able to use it's still able to use,
2022-03-23 09:45:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.346 | nll_loss 4.681 | ppl 25.65 | bleu 12.37 | wps 3989.5 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.37
2022-03-23 09:45:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:45:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:45:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:45:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.37) (writing took 1.7846013023518026 seconds)
2022-03-23 09:45:21 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:45:21 | INFO | train | epoch 014 | loss 5.646 | nll_loss 5.066 | ppl 33.51 | wps 40787.6 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.25 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1364
2022-03-23 09:45:21 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:45:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:24 | INFO | train_inner | epoch 015:      7 / 157 loss=5.648, nll_loss=5.067, ppl=33.52, wps=31414.9, ups=1.27, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=1.243, loss_scale=4, train_wall=31, gb_free=14, wall=1367
2022-03-23 09:45:55 | INFO | train_inner | epoch 015:    107 / 157 loss=5.421, nll_loss=4.821, ppl=28.28, wps=79064.4, ups=3.17, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=1.161, loss_scale=4, train_wall=31, gb_free=13.8, wall=1399
2022-03-23 09:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:15 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical chemical rays.
2022-03-23 09:46:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8,000 places in the restaurant.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example hypothesis: and these magnets can also be able to be a lot of course, of course, of course, to form a very popular bible forms of forms.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his father when she was pregnant with him.
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:46:31 | INFO | fairseq.tasks.translation | example hypothesis: so, one of my couver is died in aids and died in aids, so we asked us, what do we do?
2022-03-23 09:46:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:46:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender and not talk about the weapons of nuclear weapons or nuclear weapons.
2022-03-23 09:46:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:46:40 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bl of magnetic magnetic field in the field, but it doesn't like the sususususues, if you don't need your movements, it doesn't need your energy, and so you need your energy.
2022-03-23 09:46:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection comes from this reflection, we can start with a traditional traditional factors, and start starting to start with a traditional view of the face of the face, and the instructions of the shape, and the shape of the information, and the information is the information, and the information, and the information, and the information that's what's going through it's going to put it through it
2022-03-23 09:46:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting and measure it, for me, for tedwomen, is that... yes, "yes, it was the best thing when someone said," well, it was the best thing that someone said, "somebody said," if you're going to help you're going to help you know, "and you're going to help you're going to have a long time," and you're going to have a long time, "and you're going to have a long time," and then you're going to have a long time, "
2022-03-23 09:46:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:53 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother that the invention of invention and a big design part of design that we were on our plane at our plane, and we had to solve a unique result that we had to solve a unique result that was able to solve, and if we had to solve the end of the bottom, it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:46:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:53 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.998 | nll_loss 4.29 | ppl 19.56 | bleu 16.69 | wps 4346.6 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.69
2022-03-23 09:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:46:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.69) (writing took 1.8616835456341505 seconds)
2022-03-23 09:46:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:46:54 | INFO | train | epoch 015 | loss 5.379 | nll_loss 4.775 | ppl 27.37 | wps 42199.9 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.108 | loss_scale 4 | train_wall 49 | gb_free 13.6 | wall 1458
2022-03-23 09:46:55 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:11 | INFO | train_inner | epoch 016:     50 / 157 loss=5.304, nll_loss=4.692, ppl=25.84, wps=33556, ups=1.33, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=1.042, loss_scale=4, train_wall=31, gb_free=14.4, wall=1474
2022-03-23 09:47:42 | INFO | train_inner | epoch 016:    150 / 157 loss=5.048, nll_loss=4.414, ppl=21.32, wps=80658.5, ups=3.22, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=1.076, loss_scale=4, train_wall=31, gb_free=13.7, wall=1505
2022-03-23 09:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:48 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical chemical rockets.
2022-03-23 09:47:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:47:52 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant in the restaurant.
2022-03-23 09:47:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:47:56 | INFO | fairseq.tasks.translation | example hypothesis: and this rank can also, of course, i can also be a popular bible to forms forms.
2022-03-23 09:47:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:48:00 | INFO | fairseq.tasks.translation | example hypothesis: he never learned his father because his father had his mother left his mother when she was pregpregnant.
2022-03-23 09:48:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:48:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a watha child asked us, so what do we do?
2022-03-23 09:48:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:48:07 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender and not talking about the nuclear weapons or nuclear weapons.
2022-03-23 09:48:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic lines in the field, but the sususususususus doesn't move their movements and so forth.
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection of reflection, we can start with a traditional face of the face of the face, and the real shape of the real information, and the whole structure of the whole structure, and the whole structure of this reflection of this reflect of this reflection, the reflect of this reflection, and the reflect of this reflect of this reflect of this reflection, we all the reflection
2022-03-23 09:48:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here in tedra, is that -- yes, when we came up to the best time '' '' '' '' '7th, and then we're going to help you're going to take it up with this great interesting, and then we're going to take it interesting, and you're going to be going to take it up the mimimimimimimimira, and you know,' '' '' '' '' '' '' '' '' '' '6ra ra ra ra ra ra ra ra ra ra ra ra son's a long long long long time, and you know, and you know, and you're going to take it's a long long long long time you know, and you're going to take it's a long time you know, and you know,
2022-03-23 09:48:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother's invention, and a big part of the design of design, we had to use the aircraft of our plane, which is a unique problem that we had to use the unique problems, so that it's all the way to use it was to be a refugegegegegegegegegegegegeous system, and that we're going to be able to use a little bit more sophisticated, and that if you're going to use the deep deep deep deep aircraft the sea sea sea sea sea, and that we're going to be able to see a giant giant giant giant sea sea sea sea sea sea sea, if you're going to use the sea sea sea, and that it's going to use a huge huge, if you're going to see the sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea sea, if you're going to see the deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep deep,
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.839 | nll_loss 4.117 | ppl 17.35 | bleu 18.11 | wps 4664.8 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 18.11
2022-03-23 09:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 18.11) (writing took 1.8040555189363658 seconds)
2022-03-23 09:48:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:48:25 | INFO | train | epoch 016 | loss 5.121 | nll_loss 4.494 | ppl 22.53 | wps 43691.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.079 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1548
2022-03-23 09:48:25 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:55 | INFO | train_inner | epoch 017:     93 / 157 loss=4.898, nll_loss=4.249, ppl=19.02, wps=35315.7, ups=1.36, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.972, loss_scale=4, train_wall=31, gb_free=13.9, wall=1578
2022-03-23 09:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8,000 places in the restaurant.
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:49:27 | INFO | fairseq.tasks.translation | example hypothesis: and i can also make these magnets of course, of course, of course, of course, i can also make a popular bible.
2022-03-23 09:49:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:49:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his father, because his father had his mother left his mother when she was pregnant with him pregnant.
2022-03-23 09:49:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:49:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup has died in aids and has died a waveline child, so we asked us good what do we do with them?
2022-03-23 09:49:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about the insect of nuclear weapons or any other topic.
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic magnetic lines in the inside the field, but the susususuing susususues don't move when you need your movements, your energy, and so the susususususulation of magnetic field.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional facial factors, which is the big facial shape of the factors and repeat it, and the information that gives it all the information, which is a whole structure of this whole structure, and the whole structure of this structure.
2022-03-23 09:49:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it's interesting and measure it for me here for tedwomen here in tedwomen, "well, that..." well, in the best time, somebody who said, "somebody who says," you know, "the men who starts to help you know," and then when you're going to help you say, "] ["] ["],"] ["],"] ["],"], "]," and then you know, "and then you know,"], if you know, "],"], "],"], "the men,"], "], you know, if you're going to support it's going to support it's going to support it's going to support it's going to do it's going to do it's interesting interesting interesting
2022-03-23 09:49:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother who is still the invention of invention, and a big part of design design design design design that we have to see is a result of a unique problems that we had to solve all the problems that we had to solve it -- all the way that it was to be linked from the ground, to the ground, and a decrease everything that it's all the way to the way that we have to see everything that we have to the ground, to use, to the ground, to use it, to use it, to the ground, and a reconstruct the ground, to the ground, to the ground, or to see everything that we have to see everything that it is that it's a decrease, or to the way that we have to see that we have to see it's a reconstructed by a reconstructed by a reconstructed by a reconstructed, to the ground, to the ground, to the ground, to the ground, or to the ground, to a reco
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:56 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.677 | nll_loss 3.93 | ppl 15.24 | bleu 19.38 | wps 4335.5 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.38
2022-03-23 09:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:49:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:49:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:49:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.38) (writing took 1.8577913269400597 seconds)
2022-03-23 09:49:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:49:58 | INFO | train | epoch 017 | loss 4.853 | nll_loss 4.201 | ppl 18.39 | wps 42357.6 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.979 | loss_scale 4 | train_wall 49 | gb_free 14.2 | wall 1641
2022-03-23 09:49:58 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:10 | INFO | train_inner | epoch 018:     36 / 157 loss=4.772, nll_loss=4.112, ppl=17.29, wps=32720.8, ups=1.34, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=1.056, loss_scale=4, train_wall=30, gb_free=14, wall=1653
2022-03-23 09:50:42 | INFO | train_inner | epoch 018:    136 / 157 loss=4.695, nll_loss=4.027, ppl=16.3, wps=80147.7, ups=3.14, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.949, loss_scale=4, train_wall=32, gb_free=13.6, wall=1685
2022-03-23 09:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:52 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:50:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:50:56 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:50:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:51:00 | INFO | fairseq.tasks.translation | example hypothesis: and this rough magnets, of course, i can also extend to form a very popular bible.
2022-03-23 09:51:00 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:51:04 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother, when she was pregnant.
2022-03-23 09:51:04 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples is died in aids, and we said, "well, what do we do with her?
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things like gender times and not talking about the overwheld of nuclear weapons or any other topics.
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example hypothesis: first, you know, some of the magnetic magnetic magnetic lines in the inside the inside, but the susususususuer doesn't like it, if you move your movements, your energy, and so the susususususucy.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information, the whole structure of this reflection, we can start with a traditional face, which is going to start with a traditional face, the big consequence of the face, and the information, all the structure.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you say, "well, for me, for you, you know, you know, you know,"
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, we had to solve all the problems of the soil, and it's a lot of the design system that we're going to use in our plane, if you're going to be able to be able to be able to be able to be able to use it all on the soil, you have to use it with a submermercy system, you need to use it, you're either in the way, you're going to use it.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:26 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.536 | nll_loss 3.778 | ppl 13.71 | bleu 20.08 | wps 4817.3 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.08
2022-03-23 09:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:51:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.08) (writing took 1.8249340178444982 seconds)
2022-03-23 09:51:28 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:51:28 | INFO | train | epoch 018 | loss 4.704 | nll_loss 4.036 | ppl 16.41 | wps 44103.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.033 | loss_scale 4 | train_wall 49 | gb_free 14.8 | wall 1731
2022-03-23 09:51:28 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:53 | INFO | train_inner | epoch 019:     79 / 157 loss=4.586, nll_loss=3.909, ppl=15.02, wps=34315.4, ups=1.4, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=1.004, loss_scale=4, train_wall=30, gb_free=13.6, wall=1756
2022-03-23 09:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:52:25 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:52:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:52:29 | INFO | fairseq.tasks.translation | example hypothesis: and i can also extend to form such a bible.
2022-03-23 09:52:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:52:32 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left him when she was pregnant.
2022-03-23 09:52:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:52:36 | INFO | fairseq.tasks.translation | example hypothesis: one of my coucousin has died in aids, so we asked, what do we do with?
2022-03-23 09:52:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:52:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not about weapons or poverty.
2022-03-23 09:52:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:52:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold rock lines in the inside, but the superconductor doesn't like it, if you need your movements, and so the superconductor.
2022-03-23 09:52:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big configuration of the face, and the real shape of the face and repeat it, and there's a real shape of the information, and then by the one of those tribes, and the tricky information, and the whole structure.
2022-03-23 09:52:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure for me to be here at tedwomen, is that -- yes, when it turned out to the best as somebody said, "and then somebody said," you know, "and then the men starts to support you."
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother still is the invention of invention, and a large part of design work that allowed us to see on the plane, and it was a result that we had to solve the unique problems so that we had to solve it to be connected to a refrigeration of the ground, and it's all the refrigered by a refrigered to a refrigeration, and to the refrifrigeration, and to the refrigered to the refrigeration of a refrigeration, and to the refrigeration, and to the refrigeration of a refrigered to the refrigered to the refrigeration, to a mechanism.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:54 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.392 | nll_loss 3.621 | ppl 12.3 | bleu 20.63 | wps 4919.8 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.63
2022-03-23 09:52:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:52:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:52:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 19 @ 2978 updates, score 20.63) (writing took 1.8023429149761796 seconds)
2022-03-23 09:52:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:52:56 | INFO | train | epoch 019 | loss 4.525 | nll_loss 3.841 | ppl 14.33 | wps 44558.9 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.935 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1819
2022-03-23 09:52:57 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:52:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:04 | INFO | train_inner | epoch 020:     22 / 157 loss=4.507, nll_loss=3.821, ppl=14.13, wps=35658.5, ups=1.42, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.904, loss_scale=4, train_wall=31, gb_free=14.6, wall=1827
2022-03-23 09:53:35 | INFO | train_inner | epoch 020:    122 / 157 loss=4.261, nll_loss=3.555, ppl=11.76, wps=81582, ups=3.15, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.812, loss_scale=4, train_wall=31, gb_free=22.4, wall=1858
2022-03-23 09:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:53:54 | INFO | fairseq.tasks.translation | example hypothesis: overyear, he can protect about 8,000 places in the restaurant.
2022-03-23 09:53:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:53:57 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand this tiny magnets to form a bike.
2022-03-23 09:53:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:54:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 09:54:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids and has a wawax child, so we asked, well, what do we do with your couples?
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:54:09 | INFO | fairseq.tasks.translation | example hypothesis: so we spend time talking about things like gender times and not talking about nuclear weapons or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 09:54:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field are caught in the inner lines, but the superconductor doesn't like if you move, because your energy needs, and so the superconductor disorders.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which can start the big constructures of face, and the real shape of the face, and the real shape, and the real form of information that can fold the whole structure and fold all the portion.
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that -- yes, when i think it was the best, when somebody said, "you know," listen to you to men and you say, "if you're in a table, we're supporting the truth," and then you know, the truth is that the truth is that you're supporting you know, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["], it's
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of design work that we're using on the plane, is a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- everything in the ground -- a continued by a continent of design system that allows us to use it into a production, and that allows us to be able to use the terror to use a production of a production system that allows us to make a production system, that allows us to use that allows us to create a production, and that allows us to create a production, if you to use it's a legal legal system, it's a legal system, if you're used to use it's used to use the terror to use it's used to use it's used to use it's a production, it's a production, it to use it's a production, it's a legal legal legal legal system, it's used to use it's used to use the production, that we're used
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:25 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.248 | nll_loss 3.457 | ppl 10.98 | bleu 23.37 | wps 4626.1 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.37
2022-03-23 09:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.37) (writing took 1.8654186059720814 seconds)
2022-03-23 09:54:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:54:27 | INFO | train | epoch 020 | loss 4.343 | nll_loss 3.644 | ppl 12.5 | wps 43590.5 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.87 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1910
2022-03-23 09:54:27 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:48 | INFO | train_inner | epoch 021:     65 / 157 loss=4.325, nll_loss=3.624, ppl=12.33, wps=33920.5, ups=1.38, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.87, loss_scale=4, train_wall=31, gb_free=14.7, wall=1931
2022-03-23 09:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:55:24 | INFO | fairseq.tasks.translation | example hypothesis: and over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 09:55:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:55:28 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand to form a popular equation.
2022-03-23 09:55:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:55:32 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his mother had left his mother when she was pregnant.
2022-03-23 09:55:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:55:36 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids and has a wais-child, so we asked us good what do we do with her?
2022-03-23 09:55:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:55:40 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:55:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnetic field are caught in the inner lines, but the superconductor doesn't like it when you move, your movements and so the superconducting disorder.
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, the big constructures of the face and the basic form, and through that information that makes the whole structure, the whole structure and fold all the structure.
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measuring me here at tedwomen, is that... yes, when it was the best, when someone said, "listen to men and say," look at a table and say, "if we're going to help you to help you," and then they start to support the truth, "and then we've already started to help you know that there's already started to help you know that there's a long time."
2022-03-23 09:55:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of design work that we were on our plane was a result of the unique problems that were connected to the soil, and it would be connected to the unique problems that were linked to the soil -- all sorts of variable, all sorts of refrigering, to be able to use the way that we're going to be able to use in the way that we're going to use it, or to use it would be able to use it, to use it would either when you could either be more sophisticated, or to use it would be more sophisticated in the way that we could either be refrigered to use the way that we could also be more sophisticated, to use the way that we could also be refrigered to use the way that we could either be more sophisticated, to use the way that we could either be more sophisticated in the way that we could either be able to use the way that we could be more sophisticated, to use
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:54 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.087 | nll_loss 3.282 | ppl 9.73 | bleu 24.8 | wps 4872.4 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.8
2022-03-23 09:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:55:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.8) (writing took 1.8269985411316156 seconds)
2022-03-23 09:55:56 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:55:56 | INFO | train | epoch 021 | loss 4.187 | nll_loss 3.474 | ppl 11.12 | wps 44348.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.788 | loss_scale 4 | train_wall 49 | gb_free 14.4 | wall 1999
2022-03-23 09:55:56 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:59 | INFO | train_inner | epoch 022:      8 / 157 loss=4.131, nll_loss=3.415, ppl=10.66, wps=35711.8, ups=1.41, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.782, loss_scale=4, train_wall=31, gb_free=14.3, wall=2002
2022-03-23 09:56:31 | INFO | train_inner | epoch 022:    108 / 157 loss=4.111, nll_loss=3.393, ppl=10.51, wps=80027.3, ups=3.17, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.82, loss_scale=4, train_wall=31, gb_free=13.9, wall=2034
2022-03-23 09:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:50 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 09:56:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:56:54 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 09:56:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these silly magnets.
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:57:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 09:57:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:57:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids and has a waisena child, so we asked us what do we do with her?
2022-03-23 09:57:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:57:09 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times and not talking about nuclear weapons or poverty.
2022-03-23 09:57:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are starting inside the inner inner field, but the superconductor doesn't like their movements, because their movements need energy, and so the superpower of magnetic magnetic field.
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that can be highly interesting and measured for men.
2022-03-23 09:57:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we were on the tozele, was a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- all sorts of things that we need to use a continuous operating system, either if we're going to use the propelled, it was a mechanism, or the propelled machine.
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:21 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.25 | nll_loss 3.458 | ppl 10.99 | bleu 18.05 | wps 5401 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.8
2022-03-23 09:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 09:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 18.05) (writing took 0.8071735501289368 seconds)
2022-03-23 09:57:21 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:57:21 | INFO | train | epoch 022 | loss 4.092 | nll_loss 3.372 | ppl 10.35 | wps 46239.6 | ups 1.84 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.816 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2084
2022-03-23 09:57:22 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:38 | INFO | train_inner | epoch 023:     51 / 157 loss=3.995, nll_loss=3.267, ppl=9.62, wps=37377.3, ups=1.49, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.81, loss_scale=4, train_wall=31, gb_free=14.7, wall=2101
2022-03-23 09:58:09 | INFO | train_inner | epoch 023:    151 / 157 loss=4.005, nll_loss=3.277, ppl=9.69, wps=78727.6, ups=3.17, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.742, loss_scale=4, train_wall=31, gb_free=13.9, wall=2132
2022-03-23 09:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example hypothesis: this sonian can't use chemical rockets.
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:58:19 | INFO | fairseq.tasks.translation | example hypothesis: there's about 8,000 places in the restaurant.
2022-03-23 09:58:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:58:23 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to form a very popular equation.
2022-03-23 09:58:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:58:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 09:58:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:58:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and i've got an orphanage, so we asked, well, what do we do with her?
2022-03-23 09:58:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times, and not about the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field lines are caught in the inner, but the superconductor doesn't like it, if you move, because your movements need, and so the superconductor disorders.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which is the big configuration of face and the basic form, and by the theft of information, the whole fabric structure and fold all the structure.
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that... tyes, when it was best summarized when somebody said, "turn you to the men on your table and say," if we're going to support the revolution, "then we're going to support women," in this case, we have a long time, "and then we have a silly," in this case for example, "and then we have a silly," by the honesty, "by the honesty," by the way, "by a long time," by the honesty, "and then," by a long term for example, "by a smillennity," and "and" you know, "by a few years," by the way, "you know,"
2022-03-23 09:58:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're at the plane of the poorest, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from continuing to a continuously variation, and that allows us to be a continuous, to be a refrigering system, to a refrigeration, to a prosperity, to a mechanism, to a mechanical, to a mechanism, to a mechanism, or to a mechanism, to a mechanism, to a mechanism that we're either see that it is to a mechanism that we're not to a mechanism that we need to a mechanism that we need to see that we need to be a mechanism that we need to see that we need to a mechanism that we need to a mechanism that we need to be more sophisticated, or to a mechanism that we need to be a mechanism, or to be a
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:51 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.852 | nll_loss 3.026 | ppl 8.14 | bleu 27.6 | wps 4606.7 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.6
2022-03-23 09:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 09:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 09:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.6) (writing took 1.8646465251222253 seconds)
2022-03-23 09:58:52 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:58:52 | INFO | train | epoch 023 | loss 3.974 | nll_loss 3.244 | ppl 9.47 | wps 43355.6 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.744 | loss_scale 4 | train_wall 49 | gb_free 14.3 | wall 2176
2022-03-23 09:58:53 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:23 | INFO | train_inner | epoch 024:     94 / 157 loss=3.829, nll_loss=3.088, ppl=8.5, wps=34320.3, ups=1.36, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.702, loss_scale=4, train_wall=31, gb_free=14, wall=2206
2022-03-23 09:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:59:54 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to form a popular equation.
2022-03-23 09:59:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:00:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and has an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:00:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble of magnetic fields are captured inside, but the superconductor doesn't like if you're moving, because your movements need, and so the superconducting disorder.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, the big constructures of the face, and the basic information that all the porter structure and all the folds.
2022-03-23 10:00:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be in tedwomen, is that... t.c., it's been the best thing when somebody said, "turn to men at a table and tell them," if we're going to support you. "we've been supporting you."
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're at the top of our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from continuously varied to a continually varied system and refrigering that allows us to use a refrigering machine.
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:19 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.826 | nll_loss 3.001 | ppl 8 | bleu 26.72 | wps 5057.6 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.6
2022-03-23 10:00:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:00:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:00:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:00:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 26.72) (writing took 0.79848249303177 seconds)
2022-03-23 10:00:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:00:19 | INFO | train | epoch 024 | loss 3.873 | nll_loss 3.135 | ppl 8.78 | wps 45432.8 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.733 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2262
2022-03-23 10:00:20 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:31 | INFO | train_inner | epoch 025:     37 / 157 loss=3.88, nll_loss=3.143, ppl=8.83, wps=36181.4, ups=1.46, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.734, loss_scale=4, train_wall=31, gb_free=14.7, wall=2274
2022-03-23 10:01:03 | INFO | train_inner | epoch 025:    137 / 157 loss=3.771, nll_loss=3.025, ppl=8.14, wps=80014.5, ups=3.15, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.705, loss_scale=4, train_wall=31, gb_free=13.8, wall=2306
2022-03-23 10:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:01:17 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:01:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:01:21 | INFO | fairseq.tasks.translation | example hypothesis: these tiny magnets, of course, i can also expand to form a very popular equality.
2022-03-23 10:01:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:01:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids, and has an orphanage, so we asked us, well what do we do with her?
2022-03-23 10:01:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:01:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weakness and not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:01:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:01:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like the supraleiter doesn't like it if you move, because your movements use, and so the superconductor disorders.
2022-03-23 10:01:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big configuration of the face and the basic form that the whole porter structure and all fold a fold.
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me to be here at tedwomen, is that... t.c., when it was the best summit when someone said to the men at dtable, and they say, "if the revolution begins to help you," well, the truth is that we've already supported you. "
2022-03-23 10:01:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:48 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our plane on the proud tooth, was a result that we had to solve the unique problems that were connected to the bottom -- all of which is a continuous variation, from a continual variation and refrigeration system that allows us to see that it to use a fluid, and that if you can either be able to use the ridge the rivers to see the ridge the rivers, or to see the decrease the most sophisticated, if you're either, if you have to use the rivers that they're going to use the most important problems that they're going to use the rivers that they're going to use the rivers that they're going to use the planet, and then you have to use the cryptification, and then you're either the more, if you have to use the rivers that they're going to use the crucial to use the crucial,
2022-03-23 10:01:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:48 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.758 | nll_loss 2.92 | ppl 7.57 | bleu 28.65 | wps 4777.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.65
2022-03-23 10:01:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:01:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:01:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.65) (writing took 1.7792350971139967 seconds)
2022-03-23 10:01:49 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:01:49 | INFO | train | epoch 025 | loss 3.768 | nll_loss 3.021 | ppl 8.12 | wps 43892.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.688 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2352
2022-03-23 10:01:50 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:01:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:15 | INFO | train_inner | epoch 026:     80 / 157 loss=3.706, nll_loss=2.955, ppl=7.75, wps=35263.3, ups=1.39, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.704, loss_scale=4, train_wall=31, gb_free=14, wall=2378
2022-03-23 10:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:43 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:02:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:02:47 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:02:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:02:51 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, i can expand these circles to form any kind of same equilibrium.
2022-03-23 10:02:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:02:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:02:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:02:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died of aids, and he left an orphanage, so we asked us, well what do we do with her?
2022-03-23 10:02:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:03:03 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:03:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:03:07 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are trapped inside the inner, but the superconductor doesn't like it if you move, because your movements need, and so the superconductor disorder.
2022-03-23 10:03:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, the big constructures of facial facial and the basic form, which is all the porting structure and all the folds.
2022-03-23 10:03:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured for me to be here at tedwomen, is that... tyes, when striking dinner was the best, when somebody said, "turn you to men at ddesk and tell them," if the revolution begins, we support you, "women love you, that we've already been supported for you."
2022-03-23 10:03:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessary, the mother of invention, and a large part of the design work that we are on our airplane on the stumb, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continual variation and a cooling system that allows us to use a system in the go-and-the system, if we see the system, if we're going to use the floody, or the system, if you can see the system, if you can see the system, if you can see the floodder, or the system, if you can see the system, if you're not a mechanism, if you're going to use the system, if you're going to use the system, if you can see the system, if you're going to use the system, if you're going to be a mechanism, if you're going to be a mechanism, or a mechanism, if you're going to be able to be able to use the
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:18 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.721 | nll_loss 2.886 | ppl 7.39 | bleu 28.99 | wps 4705.5 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.99
2022-03-23 10:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.99) (writing took 1.7842836580239236 seconds)
2022-03-23 10:03:20 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:03:20 | INFO | train | epoch 026 | loss 3.71 | nll_loss 2.959 | ppl 7.78 | wps 43732.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.7 | loss_scale 4 | train_wall 49 | gb_free 13.4 | wall 2443
2022-03-23 10:03:20 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:27 | INFO | train_inner | epoch 027:     23 / 157 loss=3.711, nll_loss=2.96, ppl=7.78, wps=34780.7, ups=1.38, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.687, loss_scale=4, train_wall=31, gb_free=13.7, wall=2450
2022-03-23 10:03:59 | INFO | train_inner | epoch 027:    123 / 157 loss=3.614, nll_loss=2.856, ppl=7.24, wps=79180.5, ups=3.17, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.628, loss_scale=4, train_wall=31, gb_free=14.1, wall=2482
2022-03-23 10:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:04:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:04:18 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 10:04:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:04:22 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these circular magnets, of course, to make a very popular same same equilibrium.
2022-03-23 10:04:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:04:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:04:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:04:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, so we asked ourselves, well what do we do with her?
2022-03-23 10:04:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:04:33 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals and not about genocide or distribution of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:04:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:04:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnet lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:04:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can begin with a traditional facial reflection that gives the big constructions of the face and the basic shape, and then recover it through the one that information that contains the whole porting structure and all the fits a fold.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen, is that... t.m., in the controversial dinner, it was best summarized when somebody said, "turn you to the men on your table and she says," if the revolution starts, "women are already supporting you."
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane was one result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continually varied system that allows us to stop using a machine in the air, or a cooling machine, to use a system, if we have a keyboard, it's either to use it to a little bit more fluid, it to a little bit of the propelled, it.
2022-03-23 10:04:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:47 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.649 | nll_loss 2.804 | ppl 6.99 | bleu 29.61 | wps 4856.9 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.61
2022-03-23 10:04:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:04:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:04:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.61) (writing took 1.8093652222305536 seconds)
2022-03-23 10:04:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:04:49 | INFO | train | epoch 027 | loss 3.601 | nll_loss 2.842 | ppl 7.17 | wps 44214.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.63 | loss_scale 4 | train_wall 49 | gb_free 13.4 | wall 2532
2022-03-23 10:04:49 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:04:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:11 | INFO | train_inner | epoch 028:     66 / 157 loss=3.567, nll_loss=2.806, ppl=6.99, wps=35243.8, ups=1.39, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.651, loss_scale=4, train_wall=31, gb_free=13.9, wall=2554
2022-03-23 10:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:43 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:05:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:05:47 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can discuss about 8,000 places in the restaurant.
2022-03-23 10:05:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:05:51 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form an arbitrary equation.
2022-03-23 10:05:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:05:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:05:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:05:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well what do we do with her?
2022-03-23 10:05:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:06:03 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talking issue.
2022-03-23 10:06:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some kind of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can begin with a traditional face, which gives the big constructures of the face and the basic shape, and recovery it through the one of the one information that pulls all the porter structure and all a fold.
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen is that... tyes, when striking dinner was the best together when someone said, "turn on the men at dtable and tell you," when the revolution starts, we support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still invention, and a big part of design work that we're on on our plane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and cooling system that allows us to use a refrigeration system, or to get rid of the propellment, to get rid of the propellment, or to get rid of the propellment system that we're going to be able to be able to be able to be able to be able to use, or to get rid of the progressed with the propelled in the crype for the system, or to get rid of the crussion.
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:17 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.585 | nll_loss 2.734 | ppl 6.66 | bleu 29.89 | wps 4788.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.89
2022-03-23 10:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:06:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:06:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:06:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.89) (writing took 1.8256408418528736 seconds)
2022-03-23 10:06:19 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:06:19 | INFO | train | epoch 028 | loss 3.548 | nll_loss 2.785 | ppl 6.89 | wps 43711.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.642 | loss_scale 4 | train_wall 49 | gb_free 13.4 | wall 2622
2022-03-23 10:06:20 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:23 | INFO | train_inner | epoch 029:      9 / 157 loss=3.504, nll_loss=2.738, ppl=6.67, wps=35044.4, ups=1.39, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.593, loss_scale=4, train_wall=31, gb_free=14.1, wall=2626
2022-03-23 10:06:54 | INFO | train_inner | epoch 029:    109 / 157 loss=3.475, nll_loss=2.707, ppl=6.53, wps=80115.8, ups=3.17, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.624, loss_scale=4, train_wall=31, gb_free=14.6, wall=2657
2022-03-23 10:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rocks to form any same glimpse.
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his mother had left his mother when she was pregnant.
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:07:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, so we asked ourselves, well, what do we do with her?
2022-03-23 10:07:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:07:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals and not about genocide or the spread of nuclear weapons or poverty, or any other promising topic.
2022-03-23 10:07:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic shape, and restorate it by the most porter structure and all a fold.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured for me here at tedwomen is that... well, when i dinner, it was best summarized, when somebody said, "if the men start on your table," and we say, "when the revolution begins, the truth is that we love you for this topic for a long time."
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on on our plane was a stumble, a result of that, we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a coolness system, that allows us to use a aircraft in the aircraft, or a panel, until a panel, and a plane machine, until a panel, and a computer, until a panel, until a particular machine, and the way, the way, the propelled, and the way, the propelled, until a panel, and it is, and it is, and it is, and it is that allows us to the wheel, until a panel, until a plane transport, until a plane transport, until a panel, and it, until a computer, and it's a plane transport, and it, and it, and it, until a plane plane machine, and it, until a
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:47 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.57 | nll_loss 2.724 | ppl 6.61 | bleu 29.61 | wps 4790 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.89
2022-03-23 10:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.61) (writing took 0.809224319178611 seconds)
2022-03-23 10:07:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:07:48 | INFO | train | epoch 029 | loss 3.458 | nll_loss 2.689 | ppl 6.45 | wps 44532.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.613 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2711
2022-03-23 10:07:48 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:05 | INFO | train_inner | epoch 030:     52 / 157 loss=3.399, nll_loss=2.626, ppl=6.17, wps=35313.2, ups=1.42, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.608, loss_scale=4, train_wall=31, gb_free=14.4, wall=2728
2022-03-23 10:08:36 | INFO | train_inner | epoch 030:    152 / 157 loss=3.42, nll_loss=2.647, ppl=6.26, wps=80476.2, ups=3.2, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.576, loss_scale=4, train_wall=31, gb_free=13.9, wall=2759
2022-03-23 10:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:08:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:08:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:08:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:08:50 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form a random equality.
2022-03-23 10:08:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:08:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:08:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:08:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:08:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:09:02 | INFO | fairseq.tasks.translation | example hypothesis: and that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talking topic.
2022-03-23 10:09:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:09:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 10:09:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, the big constructions of the face and the basic shape, and recovery it through the one of the same information that refers the whole porter structure and all the fits a fold.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's going to be highly interesting and appropriate for me to be here at tedwomen, is that... well, when strikes dinner dinner, it's been the best thing, when someone said, "turn you to the men at your table and tell you," if the revolution begins to support you. "the truth is that, women are already supporting you for this long time, we've been supporting you at this theme of sand-by-by-by-by-by-by-to-spring,"
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and it's a big part of the design work that we're at the stumpet, it was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system, that allows us to use an aircraft, or to use the wheels in the ground, if you're going to see the ground, all the way that you're going to use it's going to do is either the way that you're going to use the way that you're going to use it, you're going to have to operate at the wheels, you're going to use it, you're going to use it, you're going to use it, you're going to have to see it, you're going to use it, you're going to have to have to operate at the way that you know, you're going to run it, you're going to have to have to have to have to have to have to
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.483 | nll_loss 2.631 | ppl 6.19 | bleu 31.65 | wps 4752.4 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.65
2022-03-23 10:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt
2022-03-23 10:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.65) (writing took 1.8563725827261806 seconds)
2022-03-23 10:09:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:09:18 | INFO | train | epoch 030 | loss 3.4 | nll_loss 2.627 | ppl 6.18 | wps 43846 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.583 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2801
2022-03-23 10:09:18 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:49 | INFO | train_inner | epoch 031:     95 / 157 loss=3.331, nll_loss=2.552, ppl=5.87, wps=34465.6, ups=1.37, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.599, loss_scale=4, train_wall=31, gb_free=14.5, wall=2832
2022-03-23 10:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example hypothesis: this spacecraft can't use chemical rockets.
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form any single equation.
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:10:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his mother had left his mother when she was pregnant with him.
2022-03-23 10:10:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:10:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins had died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:10:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:10:33 | INFO | fairseq.tasks.translation | example hypothesis: and that's why we spend our time talking about things like equals wedding times and not about genocide or the spread of nuclear weapons or poverty or any other talking topic.
2022-03-23 10:10:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnet field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that gives the big constructions of the face and the basic shape, and then reconstruct it through the one of the most powerful information that comes from the whole porter structure and all the fits a fold.
2022-03-23 10:10:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and appropriate for me to be here at tedwomen is that... well, in a striking dinner, it's been the best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins, then we support you. "the truth is that we've already been supporting you at this theme for a long time," and then we've already started to encourage you, "
2022-03-23 10:10:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still invention, and a large part of the design work that we are at the stumbling edge of our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variables and a cooling system with liquid, that allows us to be able to be able to be able to use an aircraft, either, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:48 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.501 | nll_loss 2.653 | ppl 6.29 | bleu 31.33 | wps 4670.8 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.65
2022-03-23 10:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.33) (writing took 0.8096584072336555 seconds)
2022-03-23 10:10:49 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:10:49 | INFO | train | epoch 031 | loss 3.349 | nll_loss 2.572 | ppl 5.95 | wps 43482.9 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.62 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2892
2022-03-23 10:10:49 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:01 | INFO | train_inner | epoch 032:     38 / 157 loss=3.367, nll_loss=2.59, ppl=6.02, wps=34974.2, ups=1.38, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.644, loss_scale=4, train_wall=31, gb_free=14.9, wall=2904
2022-03-23 10:11:33 | INFO | train_inner | epoch 032:    138 / 157 loss=3.255, nll_loss=2.471, ppl=5.54, wps=80406.5, ups=3.18, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.519, loss_scale=4, train_wall=31, gb_free=14.1, wall=2936
2022-03-23 10:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:11:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:11:50 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form any kind of similar glimpse.
2022-03-23 10:11:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:11:54 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:11:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:11:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well what do we do with her?
2022-03-23 10:11:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:12:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:12:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because they use their movements, and so the superconducting disorder.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructures of the face and the basic shape, and then restore it through the one of the most porter texts, which includes all the porter structure and all wrinkling a fold.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... tja, the dinner dinner was the best summarized when someone said, "turn you to the men at your table and say," when the revolution begins, then we support you. "the truth, women is that we've already started supporting you for this theme for a long time."
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a big part of design work that we're on our airplane on the stest toe, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied operating operating and cooling system that allows us to use an aircraft in the air, to use it in particular, to the wheel, or to use it to the ground when you run it to the problem with a continuously, all the way that you get rid of a continuously variable machine, and you can use it, and you can use it to use it to the problem with a continuously, and you can use it to use it to the problem with a continuously, when you can use it to use it to use it to use it to use it to the problem with a continuously, and you can use it to the calm, and you can use it to the problem with a continuously, and you can use it to
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:17 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.442 | nll_loss 2.582 | ppl 5.99 | bleu 31.28 | wps 4770.4 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.65
2022-03-23 10:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.28) (writing took 0.8254145900718868 seconds)
2022-03-23 10:12:17 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:12:17 | INFO | train | epoch 032 | loss 3.28 | nll_loss 2.497 | ppl 5.64 | wps 44549.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.555 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2981
2022-03-23 10:12:18 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:44 | INFO | train_inner | epoch 033:     81 / 157 loss=3.253, nll_loss=2.468, ppl=5.53, wps=35278.2, ups=1.41, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.568, loss_scale=4, train_wall=31, gb_free=13.5, wall=3007
2022-03-23 10:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:11 | INFO | fairseq.tasks.translation | example hypothesis: these spacecraft can't use chemical rockets.
2022-03-23 10:13:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:13:19 | INFO | fairseq.tasks.translation | example hypothesis: and i can, of course, expand these roaches to form any kind of same glimpse.
2022-03-23 10:13:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:13:23 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant.
2022-03-23 10:13:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:13:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:13:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:13:36 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bundles of magnet field lines in the inner, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor.
2022-03-23 10:13:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructures of the face and the basic shape, and through the one of the same information that refits the entire porter structure and all the wrinkles a fold.
2022-03-23 10:13:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in fact, when i showed dinner, it became the best thing when someone said, "turn you to the men at your table and tell you," if the revolution begins, we'll support you. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still a mother of invention, and a big part of the design work that we're on on on our airplane on the stumbrest tozeste, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously varied version of the design work, and a cooling system that allows us to be able to use a more pervasive, until you're going to be able to be able to get rid of the logic of the cockroundings, or the logic of the logic of the logic of a digic of the wheel, all that's going on on on on on, the wheel, the wheel, which is the wheel, except for the wheel, except for the wheat at at at the wheel, except for the wheat at at at at at the stairs, except for the stairs, except for a more recently, except for the wheel, except for the
2022-03-23 10:13:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:47 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.419 | nll_loss 2.569 | ppl 5.93 | bleu 31.6 | wps 4566.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.65
2022-03-23 10:13:47 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:13:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:13:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:13:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt
2022-03-23 10:13:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.05_#4/checkpoint_last.pt (epoch 33 @ 5176 updates, score 31.6) (writing took 0.857673040125519 seconds)
2022-03-23 10:13:48 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:13:48 | INFO | train | epoch 033 | loss 3.235 | nll_loss 2.449 | ppl 5.46 | wps 43685.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.568 | loss_scale 4 | train_wall 49 | gb_free 13.9 | wall 3071
2022-03-23 10:13:48 | INFO | fairseq_cli.train | done training in 3070.6 seconds
