Sender: LSF System <lsfadmin@eu-g2-09>
Subject: Job 208027642: <ru_cross_entropy_dropout_0.4_#1> in cluster <euler> Done

Job <ru_cross_entropy_dropout_0.4_#1> was submitted from host <eu-login-12> by user <andriusb> in cluster <euler> at Sat Mar 12 10:22:35 2022
Job was executed on host(s) <eu-g2-09>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sat Mar 12 10:23:09 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar 12 10:23:09 2022
Terminated at Sun Mar 13 05:28:27 2022
Results reported at Sun Mar 13 05:28:27 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/ru --save-dir /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.4 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --patience 3 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   72980.30 sec.
    Max Memory :                                 3726 MB
    Average Memory :                             2950.50 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16274.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   68717 sec.
    Turnaround time :                            68752 sec.

The output (if any) follows:

2022-03-12 10:23:13 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.4, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ru', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-12 10:23:13 | INFO | fairseq.tasks.language_modeling | dictionary: 35920 types
2022-03-12 10:23:14 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=35920, bias=False)
  )
)
2022-03-12 10:23:14 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-12 10:23:14 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-12 10:23:14 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-12 10:23:14 | INFO | fairseq_cli.train | num. shared model params: 37,305,344 (num. trained: 37,305,344)
2022-03-12 10:23:14 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-12 10:23:14 | INFO | fairseq.data.data_utils | loaded 2,558 examples from: data-bin/ru/valid
2022-03-12 10:23:17 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-12 10:23:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-12 10:23:17 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-12 10:23:17 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-12 10:23:17 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-12 10:23:17 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-12 10:23:17 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-12 10:23:17 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-12 10:23:17 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-12 10:23:17 | INFO | fairseq.data.data_utils | loaded 53,136 examples from: data-bin/ru/train
2022-03-12 10:23:17 | INFO | fairseq.trainer | begin training epoch 1
2022-03-12 10:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 10:23:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-12 10:23:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 10:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 10:23:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-12 10:27:18 | INFO | train_inner | epoch 001:    104 / 407 loss=14.834, ppl=29213.1, wps=29385.9, ups=0.45, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=2.103, loss_scale=8, train_wall=216, gb_free=9.8, wall=241
2022-03-12 10:31:01 | INFO | train_inner | epoch 001:    204 / 407 loss=13.358, ppl=10502.8, wps=29386.3, ups=0.45, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=0.673, loss_scale=16, train_wall=199, gb_free=9.8, wall=464
2022-03-12 10:34:46 | INFO | train_inner | epoch 001:    304 / 407 loss=12.455, ppl=5616.01, wps=29139.9, ups=0.44, wpb=65536, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=9.8, wall=689
2022-03-12 10:38:30 | INFO | train_inner | epoch 001:    404 / 407 loss=12, ppl=4095.43, wps=29306.9, ups=0.45, wpb=65534.2, bsz=128, num_updates=400, lr=5.009e-05, gnorm=0.407, loss_scale=64, train_wall=200, gb_free=9.8, wall=913
2022-03-12 10:38:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 10:39:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.802 | ppl 3571.3 | wps 52026.4 | wpb 511.9 | bsz 1 | num_updates 403
2022-03-12 10:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 403 updates
2022-03-12 10:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 10:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 10:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 1 @ 403 updates, score 11.802) (writing took 2.1774539870093577 seconds)
2022-03-12 10:39:04 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-12 10:39:04 | INFO | train | epoch 001 | loss 13.154 | ppl 9111.9 | wps 28418.6 | ups 0.43 | wpb 65492.3 | bsz 127.9 | num_updates 403 | lr 5.04649e-05 | gnorm 0.899 | loss_scale 64 | train_wall 821 | gb_free 9.8 | wall 947
2022-03-12 10:39:04 | INFO | fairseq.trainer | begin training epoch 2
2022-03-12 10:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 10:41:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 10:42:44 | INFO | train_inner | epoch 002:     98 / 407 loss=11.823, ppl=3621.82, wps=25679.7, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=500, lr=6.25875e-05, gnorm=0.425, loss_scale=32, train_wall=202, gb_free=9.8, wall=1167
2022-03-12 10:46:27 | INFO | train_inner | epoch 002:    198 / 407 loss=11.631, ppl=3171.28, wps=29369.2, ups=0.45, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.442, loss_scale=64, train_wall=199, gb_free=9.8, wall=1390
2022-03-12 10:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 10:50:15 | INFO | train_inner | epoch 002:    299 / 407 loss=11.376, ppl=2657.41, wps=28727.5, ups=0.44, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.453, loss_scale=32, train_wall=204, gb_free=9.8, wall=1618
2022-03-12 10:53:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 10:54:03 | INFO | train_inner | epoch 002:    400 / 407 loss=11.073, ppl=2154.71, wps=28841.4, ups=0.44, wpb=65536, bsz=128, num_updates=800, lr=0.00010008, gnorm=0.488, loss_scale=32, train_wall=203, gb_free=9.8, wall=1846
2022-03-12 10:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 10:54:44 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.656 | ppl 1613.16 | wps 51180.9 | wpb 511.9 | bsz 1 | num_updates 807 | best_loss 10.656
2022-03-12 10:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 807 updates
2022-03-12 10:54:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 10:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 10:54:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 2 @ 807 updates, score 10.656) (writing took 2.311050550022628 seconds)
2022-03-12 10:54:47 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-12 10:54:47 | INFO | train | epoch 002 | loss 11.463 | ppl 2822.26 | wps 28062.5 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 807 | lr 0.000100955 | gnorm 0.454 | loss_scale 32 | train_wall 816 | gb_free 9.8 | wall 1890
2022-03-12 10:54:47 | INFO | fairseq.trainer | begin training epoch 3
2022-03-12 10:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 10:58:15 | INFO | train_inner | epoch 003:     93 / 407 loss=10.721, ppl=1688.36, wps=25936.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=900, lr=0.000112578, gnorm=0.509, loss_scale=32, train_wall=199, gb_free=9.8, wall=2098
2022-03-12 10:58:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:02:03 | INFO | train_inner | epoch 003:    194 / 407 loss=10.42, ppl=1369.61, wps=28751.5, ups=0.44, wpb=65536, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.497, loss_scale=32, train_wall=203, gb_free=9.8, wall=2326
2022-03-12 11:04:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:05:51 | INFO | train_inner | epoch 003:    295 / 407 loss=10.169, ppl=1151.57, wps=28719.9, ups=0.44, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.553, loss_scale=32, train_wall=204, gb_free=9.8, wall=2554
2022-03-12 11:09:34 | INFO | train_inner | epoch 003:    395 / 407 loss=9.951, ppl=989.55, wps=29371.2, ups=0.45, wpb=65536, bsz=128, num_updates=1200, lr=0.00015007, gnorm=0.529, loss_scale=32, train_wall=199, gb_free=9.8, wall=2777
2022-03-12 11:09:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 11:10:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.597 | ppl 774.41 | wps 51855.7 | wpb 511.9 | bsz 1 | num_updates 1211 | best_loss 9.597
2022-03-12 11:10:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1211 updates
2022-03-12 11:10:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:10:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:10:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 3 @ 1211 updates, score 9.597) (writing took 2.1909412370005157 seconds)
2022-03-12 11:10:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-12 11:10:28 | INFO | train | epoch 003 | loss 10.292 | ppl 1253.92 | wps 28100.8 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 1211 | lr 0.000151445 | gnorm 0.525 | loss_scale 32 | train_wall 815 | gb_free 9.8 | wall 2831
2022-03-12 11:10:28 | INFO | fairseq.trainer | begin training epoch 4
2022-03-12 11:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 11:13:49 | INFO | train_inner | epoch 004:     89 / 407 loss=9.74, ppl=855.35, wps=25588.2, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=1300, lr=0.000162568, gnorm=0.599, loss_scale=32, train_wall=203, gb_free=9.8, wall=3032
2022-03-12 11:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:17:35 | INFO | train_inner | epoch 004:    190 / 407 loss=9.554, ppl=751.46, wps=29016.1, ups=0.44, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.626, loss_scale=32, train_wall=201, gb_free=9.8, wall=3258
2022-03-12 11:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:21:23 | INFO | train_inner | epoch 004:    291 / 407 loss=9.369, ppl=661.27, wps=28772.6, ups=0.44, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.639, loss_scale=32, train_wall=203, gb_free=9.8, wall=3486
2022-03-12 11:25:07 | INFO | train_inner | epoch 004:    391 / 407 loss=9.189, ppl=583.61, wps=29258.2, ups=0.45, wpb=65536, bsz=128, num_updates=1600, lr=0.00020006, gnorm=0.633, loss_scale=32, train_wall=200, gb_free=9.8, wall=3710
2022-03-12 11:25:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 11:26:09 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.836 | ppl 457.11 | wps 50087.1 | wpb 511.9 | bsz 1 | num_updates 1615 | best_loss 8.836
2022-03-12 11:26:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1615 updates
2022-03-12 11:26:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:26:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:26:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 4 @ 1615 updates, score 8.836) (writing took 2.2349154780094977 seconds)
2022-03-12 11:26:11 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-12 11:26:11 | INFO | train | epoch 004 | loss 9.44 | ppl 694.53 | wps 28050 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 1615 | lr 0.000201935 | gnorm 0.624 | loss_scale 32 | train_wall 816 | gb_free 9.8 | wall 3774
2022-03-12 11:26:11 | INFO | fairseq.trainer | begin training epoch 5
2022-03-12 11:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 11:29:21 | INFO | train_inner | epoch 005:     85 / 407 loss=9.012, ppl=516.2, wps=25729, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=1700, lr=0.000212558, gnorm=0.658, loss_scale=32, train_wall=201, gb_free=9.8, wall=3964
2022-03-12 11:31:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:33:06 | INFO | train_inner | epoch 005:    186 / 407 loss=8.847, ppl=460.39, wps=29161.7, ups=0.44, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.692, loss_scale=32, train_wall=200, gb_free=9.8, wall=4189
2022-03-12 11:36:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:36:52 | INFO | train_inner | epoch 005:    287 / 407 loss=8.688, ppl=412.35, wps=29022.3, ups=0.44, wpb=65534.2, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.708, loss_scale=32, train_wall=202, gb_free=9.8, wall=4415
2022-03-12 11:40:35 | INFO | train_inner | epoch 005:    387 / 407 loss=8.555, ppl=376.12, wps=29375.9, ups=0.45, wpb=65536, bsz=128, num_updates=2000, lr=0.00025005, gnorm=0.685, loss_scale=32, train_wall=199, gb_free=9.8, wall=4638
2022-03-12 11:40:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 11:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 11:41:44 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.185 | ppl 291.01 | wps 52568.1 | wpb 511.9 | bsz 1 | num_updates 2019 | best_loss 8.185
2022-03-12 11:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2019 updates
2022-03-12 11:41:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:41:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 5 @ 2019 updates, score 8.185) (writing took 2.282328178989701 seconds)
2022-03-12 11:41:46 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-12 11:41:46 | INFO | train | epoch 005 | loss 8.749 | ppl 430.23 | wps 28295.7 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 2019 | lr 0.000252425 | gnorm 0.692 | loss_scale 16 | train_wall 809 | gb_free 9.8 | wall 4709
2022-03-12 11:41:47 | INFO | fairseq.trainer | begin training epoch 6
2022-03-12 11:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 11:44:50 | INFO | train_inner | epoch 006:     81 / 407 loss=8.399, ppl=337.66, wps=25633.7, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=2100, lr=0.000262548, gnorm=0.685, loss_scale=16, train_wall=203, gb_free=9.8, wall=4893
2022-03-12 11:48:34 | INFO | train_inner | epoch 006:    181 / 407 loss=8.262, ppl=307.08, wps=29257.8, ups=0.45, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.689, loss_scale=32, train_wall=200, gb_free=9.8, wall=5117
2022-03-12 11:51:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:52:21 | INFO | train_inner | epoch 006:    282 / 407 loss=8.152, ppl=284.48, wps=28839.9, ups=0.44, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.677, loss_scale=32, train_wall=203, gb_free=9.8, wall=5344
2022-03-12 11:56:05 | INFO | train_inner | epoch 006:    382 / 407 loss=8.043, ppl=263.68, wps=29233.6, ups=0.45, wpb=65536, bsz=128, num_updates=2400, lr=0.00030004, gnorm=0.698, loss_scale=32, train_wall=200, gb_free=9.8, wall=5568
2022-03-12 11:56:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 11:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 11:57:27 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.711 | ppl 209.59 | wps 51613.9 | wpb 511.9 | bsz 1 | num_updates 2424 | best_loss 7.711
2022-03-12 11:57:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2424 updates
2022-03-12 11:57:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:57:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 11:57:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 6 @ 2424 updates, score 7.711) (writing took 2.1797209059877787 seconds)
2022-03-12 11:57:29 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-12 11:57:29 | INFO | train | epoch 006 | loss 8.189 | ppl 291.92 | wps 28131.1 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 2424 | lr 0.000303039 | gnorm 0.682 | loss_scale 32 | train_wall 816 | gb_free 9.8 | wall 5652
2022-03-12 11:57:29 | INFO | fairseq.trainer | begin training epoch 7
2022-03-12 11:57:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 12:00:21 | INFO | train_inner | epoch 007:     76 / 407 loss=7.908, ppl=240.16, wps=25568.3, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=2500, lr=0.000312538, gnorm=0.667, loss_scale=32, train_wall=203, gb_free=9.8, wall=5824
2022-03-12 12:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:04:06 | INFO | train_inner | epoch 007:    177 / 407 loss=7.826, ppl=226.86, wps=29126.6, ups=0.44, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.671, loss_scale=32, train_wall=201, gb_free=9.8, wall=6049
2022-03-12 12:07:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:07:55 | INFO | train_inner | epoch 007:    278 / 407 loss=7.739, ppl=213.64, wps=28559.1, ups=0.44, wpb=65536, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.657, loss_scale=32, train_wall=205, gb_free=9.8, wall=6278
2022-03-12 12:11:40 | INFO | train_inner | epoch 007:    378 / 407 loss=7.654, ppl=201.37, wps=29180.5, ups=0.45, wpb=65536, bsz=128, num_updates=2800, lr=0.00035003, gnorm=0.657, loss_scale=32, train_wall=201, gb_free=9.8, wall=6503
2022-03-12 12:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 12:13:09 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.343 | ppl 162.33 | wps 52174.4 | wpb 511.9 | bsz 1 | num_updates 2828 | best_loss 7.343
2022-03-12 12:13:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2828 updates
2022-03-12 12:13:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:13:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:13:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 7 @ 2828 updates, score 7.343) (writing took 2.307355948985787 seconds)
2022-03-12 12:13:12 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-12 12:13:12 | INFO | train | epoch 007 | loss 7.757 | ppl 216.34 | wps 28082.4 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 2828 | lr 0.000353529 | gnorm 0.661 | loss_scale 32 | train_wall 816 | gb_free 9.8 | wall 6595
2022-03-12 12:13:12 | INFO | fairseq.trainer | begin training epoch 8
2022-03-12 12:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 12:15:52 | INFO | train_inner | epoch 008:     72 / 407 loss=7.545, ppl=186.72, wps=25880.7, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2900, lr=0.000362528, gnorm=0.638, loss_scale=32, train_wall=200, gb_free=9.8, wall=6755
2022-03-12 12:17:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:19:38 | INFO | train_inner | epoch 008:    173 / 407 loss=7.474, ppl=177.77, wps=29010.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.607, loss_scale=32, train_wall=202, gb_free=9.8, wall=6981
2022-03-12 12:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:23:26 | INFO | train_inner | epoch 008:    274 / 407 loss=7.42, ppl=171.3, wps=28831.6, ups=0.44, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.633, loss_scale=32, train_wall=203, gb_free=9.8, wall=7208
2022-03-12 12:27:09 | INFO | train_inner | epoch 008:    374 / 407 loss=7.357, ppl=163.89, wps=29340.7, ups=0.45, wpb=65536, bsz=128, num_updates=3200, lr=0.00040002, gnorm=0.605, loss_scale=32, train_wall=199, gb_free=9.8, wall=7432
2022-03-12 12:27:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 12:28:48 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.077 | ppl 134.99 | wps 51567.2 | wpb 511.9 | bsz 1 | num_updates 3232 | best_loss 7.077
2022-03-12 12:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3232 updates
2022-03-12 12:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 8 @ 3232 updates, score 7.077) (writing took 2.189149896003073 seconds)
2022-03-12 12:28:50 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-12 12:28:50 | INFO | train | epoch 008 | loss 7.427 | ppl 172.03 | wps 28200.1 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 3232 | lr 0.000404019 | gnorm 0.618 | loss_scale 32 | train_wall 812 | gb_free 9.8 | wall 7533
2022-03-12 12:28:50 | INFO | fairseq.trainer | begin training epoch 9
2022-03-12 12:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 12:31:22 | INFO | train_inner | epoch 009:     68 / 407 loss=7.263, ppl=153.62, wps=25849.3, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=3300, lr=0.000412518, gnorm=0.619, loss_scale=32, train_wall=200, gb_free=9.8, wall=7685
2022-03-12 12:33:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:35:08 | INFO | train_inner | epoch 009:    169 / 407 loss=7.2, ppl=146.99, wps=28997.1, ups=0.44, wpb=65536, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.595, loss_scale=32, train_wall=202, gb_free=9.8, wall=7911
2022-03-12 12:38:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:38:55 | INFO | train_inner | epoch 009:    270 / 407 loss=7.153, ppl=142.28, wps=28779, ups=0.44, wpb=65536, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.587, loss_scale=32, train_wall=203, gb_free=9.8, wall=8138
2022-03-12 12:42:39 | INFO | train_inner | epoch 009:    370 / 407 loss=7.102, ppl=137.38, wps=29338.6, ups=0.45, wpb=65536, bsz=128, num_updates=3600, lr=0.00045001, gnorm=0.581, loss_scale=32, train_wall=199, gb_free=9.8, wall=8362
2022-03-12 12:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 12:44:28 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.828 | ppl 113.64 | wps 52038.3 | wpb 511.9 | bsz 1 | num_updates 3636 | best_loss 6.828
2022-03-12 12:44:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3636 updates
2022-03-12 12:44:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 12:44:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 9 @ 3636 updates, score 6.828) (writing took 2.233784303010907 seconds)
2022-03-12 12:44:31 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-12 12:44:31 | INFO | train | epoch 009 | loss 7.159 | ppl 142.9 | wps 28121.7 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 3636 | lr 0.000454509 | gnorm 0.595 | loss_scale 32 | train_wall 815 | gb_free 9.8 | wall 8474
2022-03-12 12:44:31 | INFO | fairseq.trainer | begin training epoch 10
2022-03-12 12:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 12:46:53 | INFO | train_inner | epoch 010:     64 / 407 loss=7.011, ppl=128.97, wps=25683.8, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=3700, lr=0.000462508, gnorm=0.586, loss_scale=32, train_wall=202, gb_free=9.8, wall=8616
2022-03-12 12:48:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 12:48:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 12:50:42 | INFO | train_inner | epoch 010:    166 / 407 loss=6.962, ppl=124.7, wps=28616.5, ups=0.44, wpb=65536, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.567, loss_scale=16, train_wall=204, gb_free=9.8, wall=8845
2022-03-12 12:54:27 | INFO | train_inner | epoch 010:    266 / 407 loss=6.927, ppl=121.7, wps=29198.8, ups=0.45, wpb=65536, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.562, loss_scale=32, train_wall=200, gb_free=9.8, wall=9070
2022-03-12 12:57:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 12:58:13 | INFO | train_inner | epoch 010:    367 / 407 loss=6.879, ppl=117.71, wps=28925.6, ups=0.44, wpb=65534.2, bsz=128, num_updates=4000, lr=0.0005, gnorm=0.56, loss_scale=16, train_wall=202, gb_free=9.8, wall=9296
2022-03-12 12:59:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 13:00:11 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.615 | ppl 98 | wps 51203.5 | wpb 511.9 | bsz 1 | num_updates 4040 | best_loss 6.615
2022-03-12 13:00:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4040 updates
2022-03-12 13:00:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:00:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 10 @ 4040 updates, score 6.615) (writing took 2.203483344987035 seconds)
2022-03-12 13:00:13 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-12 13:00:13 | INFO | train | epoch 010 | loss 6.925 | ppl 121.54 | wps 28084.1 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 4040 | lr 0.000497519 | gnorm 0.568 | loss_scale 16 | train_wall 816 | gb_free 9.8 | wall 9416
2022-03-12 13:00:13 | INFO | fairseq.trainer | begin training epoch 11
2022-03-12 13:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 13:02:28 | INFO | train_inner | epoch 011:     60 / 407 loss=6.794, ppl=111, wps=25698.6, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=4100, lr=0.000493865, gnorm=0.568, loss_scale=16, train_wall=202, gb_free=9.8, wall=9551
2022-03-12 13:06:15 | INFO | train_inner | epoch 011:    160 / 407 loss=6.745, ppl=107.23, wps=28783.4, ups=0.44, wpb=65536, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.557, loss_scale=32, train_wall=203, gb_free=9.8, wall=9778
2022-03-12 13:07:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:10:02 | INFO | train_inner | epoch 011:    261 / 407 loss=6.69, ppl=103.26, wps=28894.9, ups=0.44, wpb=65536, bsz=128, num_updates=4300, lr=0.000482243, gnorm=0.55, loss_scale=32, train_wall=202, gb_free=9.8, wall=10005
2022-03-12 13:12:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:13:50 | INFO | train_inner | epoch 011:    362 / 407 loss=6.664, ppl=101.41, wps=28726.8, ups=0.44, wpb=65534.2, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.549, loss_scale=32, train_wall=204, gb_free=9.8, wall=10233
2022-03-12 13:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 13:15:58 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.398 | ppl 84.35 | wps 49636.2 | wpb 511.9 | bsz 1 | num_updates 4445 | best_loss 6.398
2022-03-12 13:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4445 updates
2022-03-12 13:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:15:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:16:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 11 @ 4445 updates, score 6.398) (writing took 2.2408665949769784 seconds)
2022-03-12 13:16:00 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-12 13:16:00 | INFO | train | epoch 011 | loss 6.702 | ppl 104.09 | wps 28006 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 4445 | lr 0.000474312 | gnorm 0.552 | loss_scale 32 | train_wall 819 | gb_free 9.8 | wall 10363
2022-03-12 13:16:00 | INFO | fairseq.trainer | begin training epoch 12
2022-03-12 13:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 13:18:03 | INFO | train_inner | epoch 012:     55 / 407 loss=6.583, ppl=95.89, wps=25854, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4500, lr=0.000471405, gnorm=0.536, loss_scale=64, train_wall=199, gb_free=9.8, wall=10486
2022-03-12 13:18:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:21:50 | INFO | train_inner | epoch 012:    156 / 407 loss=6.528, ppl=92.25, wps=28871.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.532, loss_scale=32, train_wall=203, gb_free=9.8, wall=10713
2022-03-12 13:23:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:25:37 | INFO | train_inner | epoch 012:    257 / 407 loss=6.514, ppl=91.39, wps=28863.7, ups=0.44, wpb=65536, bsz=128, num_updates=4700, lr=0.000461266, gnorm=0.525, loss_scale=32, train_wall=203, gb_free=9.8, wall=10940
2022-03-12 13:28:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:29:24 | INFO | train_inner | epoch 012:    358 / 407 loss=6.487, ppl=89.68, wps=28938.9, ups=0.44, wpb=65536, bsz=128, num_updates=4800, lr=0.000456435, gnorm=0.537, loss_scale=32, train_wall=202, gb_free=9.8, wall=11167
2022-03-12 13:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 13:31:40 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.252 | ppl 76.2 | wps 51516.6 | wpb 511.9 | bsz 1 | num_updates 4849 | best_loss 6.252
2022-03-12 13:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4849 updates
2022-03-12 13:31:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:31:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 12 @ 4849 updates, score 6.252) (writing took 2.2292492339911405 seconds)
2022-03-12 13:31:42 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-12 13:31:42 | INFO | train | epoch 012 | loss 6.51 | ppl 91.11 | wps 28093.1 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 4849 | lr 0.000454123 | gnorm 0.533 | loss_scale 32 | train_wall 815 | gb_free 9.8 | wall 11305
2022-03-12 13:31:42 | INFO | fairseq.trainer | begin training epoch 13
2022-03-12 13:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 13:33:37 | INFO | train_inner | epoch 013:     51 / 407 loss=6.427, ppl=86.04, wps=25826, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4900, lr=0.000451754, gnorm=0.532, loss_scale=32, train_wall=201, gb_free=9.8, wall=11420
2022-03-12 13:34:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:35:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 13:37:25 | INFO | train_inner | epoch 013:    153 / 407 loss=6.374, ppl=82.94, wps=28690.3, ups=0.44, wpb=65534.2, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.514, loss_scale=16, train_wall=204, gb_free=9.8, wall=11648
2022-03-12 13:41:10 | INFO | train_inner | epoch 013:    253 / 407 loss=6.372, ppl=82.85, wps=29173, ups=0.45, wpb=65536, bsz=128, num_updates=5100, lr=0.000442807, gnorm=0.525, loss_scale=32, train_wall=201, gb_free=9.8, wall=11873
2022-03-12 13:44:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:44:55 | INFO | train_inner | epoch 013:    354 / 407 loss=6.348, ppl=81.48, wps=29142.6, ups=0.44, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.525, loss_scale=32, train_wall=201, gb_free=9.8, wall=12098
2022-03-12 13:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 13:47:18 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.149 | ppl 70.95 | wps 52204.1 | wpb 511.9 | bsz 1 | num_updates 5253 | best_loss 6.149
2022-03-12 13:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5253 updates
2022-03-12 13:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:47:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 13:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 13 @ 5253 updates, score 6.149) (writing took 2.3148574780207127 seconds)
2022-03-12 13:47:20 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-12 13:47:20 | INFO | train | epoch 013 | loss 6.363 | ppl 82.33 | wps 28192.2 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 5253 | lr 0.000436311 | gnorm 0.521 | loss_scale 32 | train_wall 812 | gb_free 9.8 | wall 12243
2022-03-12 13:47:20 | INFO | fairseq.trainer | begin training epoch 14
2022-03-12 13:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 13:49:05 | INFO | train_inner | epoch 014:     47 / 407 loss=6.295, ppl=78.53, wps=26060.7, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=5300, lr=0.000434372, gnorm=0.516, loss_scale=32, train_wall=199, gb_free=9.8, wall=12348
2022-03-12 13:50:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:52:52 | INFO | train_inner | epoch 014:    148 / 407 loss=6.258, ppl=76.51, wps=28879, ups=0.44, wpb=65536, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.516, loss_scale=32, train_wall=203, gb_free=9.8, wall=12575
2022-03-12 13:55:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 13:56:39 | INFO | train_inner | epoch 014:    249 / 407 loss=6.252, ppl=76.22, wps=28974.3, ups=0.44, wpb=65536, bsz=128, num_updates=5500, lr=0.000426401, gnorm=0.511, loss_scale=32, train_wall=202, gb_free=9.8, wall=12802
2022-03-12 14:00:20 | INFO | train_inner | epoch 014:    349 / 407 loss=6.247, ppl=75.94, wps=29581.6, ups=0.45, wpb=65536, bsz=128, num_updates=5600, lr=0.000422577, gnorm=0.513, loss_scale=64, train_wall=198, gb_free=9.8, wall=13023
2022-03-12 14:00:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:01:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 14:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 14:02:57 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.07 | ppl 67.16 | wps 52032.1 | wpb 511.9 | bsz 1 | num_updates 5656 | best_loss 6.07
2022-03-12 14:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5656 updates
2022-03-12 14:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 14 @ 5656 updates, score 6.07) (writing took 2.2745199350174516 seconds)
2022-03-12 14:02:59 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-12 14:02:59 | INFO | train | epoch 014 | loss 6.249 | ppl 76.06 | wps 28121.9 | ups 0.43 | wpb 65492.3 | bsz 127.9 | num_updates 5656 | lr 0.00042048 | gnorm 0.513 | loss_scale 16 | train_wall 812 | gb_free 9.8 | wall 13182
2022-03-12 14:02:59 | INFO | fairseq.trainer | begin training epoch 15
2022-03-12 14:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 14:04:37 | INFO | train_inner | epoch 015:     44 / 407 loss=6.204, ppl=73.73, wps=25396.7, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=5700, lr=0.000418854, gnorm=0.514, loss_scale=16, train_wall=205, gb_free=9.8, wall=13280
2022-03-12 14:08:23 | INFO | train_inner | epoch 015:    144 / 407 loss=6.171, ppl=72.07, wps=29118.5, ups=0.44, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.518, loss_scale=32, train_wall=201, gb_free=9.8, wall=13506
2022-03-12 14:11:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:12:10 | INFO | train_inner | epoch 015:    245 / 407 loss=6.156, ppl=71.28, wps=28801.4, ups=0.44, wpb=65536, bsz=128, num_updates=5900, lr=0.000411693, gnorm=0.501, loss_scale=32, train_wall=203, gb_free=9.8, wall=13733
2022-03-12 14:15:55 | INFO | train_inner | epoch 015:    345 / 407 loss=6.15, ppl=71.03, wps=29186.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.509, loss_scale=32, train_wall=200, gb_free=9.8, wall=13958
2022-03-12 14:16:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 14:18:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6 | ppl 64.02 | wps 51010.6 | wpb 511.9 | bsz 1 | num_updates 6061 | best_loss 6
2022-03-12 14:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6061 updates
2022-03-12 14:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 15 @ 6061 updates, score 6.0) (writing took 2.2096615220070817 seconds)
2022-03-12 14:18:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-12 14:18:43 | INFO | train | epoch 015 | loss 6.156 | ppl 71.33 | wps 28085.2 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 6061 | lr 0.000406189 | gnorm 0.512 | loss_scale 32 | train_wall 818 | gb_free 9.8 | wall 14126
2022-03-12 14:18:43 | INFO | fairseq.trainer | begin training epoch 16
2022-03-12 14:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 14:20:12 | INFO | train_inner | epoch 016:     39 / 407 loss=6.108, ppl=68.99, wps=25423.7, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=6100, lr=0.000404888, gnorm=0.508, loss_scale=32, train_wall=204, gb_free=9.8, wall=14215
2022-03-12 14:21:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:23:55 | INFO | train_inner | epoch 016:    140 / 407 loss=6.085, ppl=67.88, wps=29361.9, ups=0.45, wpb=65534.2, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.507, loss_scale=32, train_wall=199, gb_free=9.8, wall=14438
2022-03-12 14:26:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:27:39 | INFO | train_inner | epoch 016:    241 / 407 loss=6.083, ppl=67.77, wps=29201.7, ups=0.45, wpb=65536, bsz=128, num_updates=6300, lr=0.00039841, gnorm=0.507, loss_scale=32, train_wall=200, gb_free=9.8, wall=14662
2022-03-12 14:31:22 | INFO | train_inner | epoch 016:    341 / 407 loss=6.069, ppl=67.14, wps=29426.6, ups=0.45, wpb=65536, bsz=128, num_updates=6400, lr=0.000395285, gnorm=0.507, loss_scale=64, train_wall=199, gb_free=9.8, wall=14885
2022-03-12 14:31:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 14:34:12 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.946 | ppl 61.66 | wps 52870 | wpb 511.9 | bsz 1 | num_updates 6465 | best_loss 5.946
2022-03-12 14:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6465 updates
2022-03-12 14:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:34:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 16 @ 6465 updates, score 5.946) (writing took 2.186611120996531 seconds)
2022-03-12 14:34:15 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-12 14:34:15 | INFO | train | epoch 016 | loss 6.076 | ppl 67.48 | wps 28409.1 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 6465 | lr 0.000393293 | gnorm 0.505 | loss_scale 32 | train_wall 806 | gb_free 9.8 | wall 15058
2022-03-12 14:34:15 | INFO | fairseq.trainer | begin training epoch 17
2022-03-12 14:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 14:35:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 14:35:34 | INFO | train_inner | epoch 017:     36 / 407 loss=6.049, ppl=66.22, wps=25920.4, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6500, lr=0.000392232, gnorm=0.504, loss_scale=16, train_wall=200, gb_free=9.8, wall=15137
2022-03-12 14:39:16 | INFO | train_inner | epoch 017:    136 / 407 loss=6.01, ppl=64.43, wps=29564.5, ups=0.45, wpb=65534.2, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.504, loss_scale=16, train_wall=198, gb_free=9.8, wall=15359
2022-03-12 14:43:02 | INFO | train_inner | epoch 017:    236 / 407 loss=6.008, ppl=64.37, wps=28968.5, ups=0.44, wpb=65536, bsz=128, num_updates=6700, lr=0.000386334, gnorm=0.508, loss_scale=32, train_wall=202, gb_free=9.8, wall=15585
2022-03-12 14:44:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 14:46:50 | INFO | train_inner | epoch 017:    337 / 407 loss=6.009, ppl=64.41, wps=28823.2, ups=0.44, wpb=65536, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.513, loss_scale=16, train_wall=203, gb_free=9.8, wall=15813
2022-03-12 14:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 14:49:54 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.887 | ppl 59.2 | wps 51982.9 | wpb 511.9 | bsz 1 | num_updates 6870 | best_loss 5.887
2022-03-12 14:49:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6870 updates
2022-03-12 14:49:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:49:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 14:49:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 17 @ 6870 updates, score 5.887) (writing took 2.3099078120139893 seconds)
2022-03-12 14:49:57 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-12 14:49:57 | INFO | train | epoch 017 | loss 6.01 | ppl 64.42 | wps 28158.6 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 6870 | lr 0.000381524 | gnorm 0.509 | loss_scale 16 | train_wall 816 | gb_free 9.8 | wall 16000
2022-03-12 14:49:57 | INFO | fairseq.trainer | begin training epoch 18
2022-03-12 14:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 14:51:04 | INFO | train_inner | epoch 018:     30 / 407 loss=5.986, ppl=63.4, wps=25690.7, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=6900, lr=0.000380693, gnorm=0.512, loss_scale=32, train_wall=202, gb_free=9.8, wall=16067
2022-03-12 14:54:49 | INFO | train_inner | epoch 018:    130 / 407 loss=5.945, ppl=61.59, wps=29053.9, ups=0.44, wpb=65534.2, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.505, loss_scale=32, train_wall=201, gb_free=9.8, wall=16292
2022-03-12 14:55:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 14:58:37 | INFO | train_inner | epoch 018:    231 / 407 loss=5.954, ppl=62.01, wps=28804.4, ups=0.44, wpb=65536, bsz=128, num_updates=7100, lr=0.000375293, gnorm=0.502, loss_scale=32, train_wall=203, gb_free=9.8, wall=16520
2022-03-12 15:00:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:01:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 15:02:27 | INFO | train_inner | epoch 018:    333 / 407 loss=5.949, ppl=61.78, wps=28507.9, ups=0.43, wpb=65536, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.505, loss_scale=16, train_wall=205, gb_free=9.8, wall=16750
2022-03-12 15:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 15:05:34 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.842 | ppl 57.36 | wps 52372.2 | wpb 511.9 | bsz 1 | num_updates 7274 | best_loss 5.842
2022-03-12 15:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7274 updates
2022-03-12 15:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:05:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:05:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 18 @ 7274 updates, score 5.842) (writing took 2.242269299022155 seconds)
2022-03-12 15:05:36 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-12 15:05:36 | INFO | train | epoch 018 | loss 5.95 | ppl 61.8 | wps 28171.3 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 7274 | lr 0.000370777 | gnorm 0.507 | loss_scale 16 | train_wall 813 | gb_free 9.8 | wall 16939
2022-03-12 15:05:36 | INFO | fairseq.trainer | begin training epoch 19
2022-03-12 15:05:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 15:06:35 | INFO | train_inner | epoch 019:     26 / 407 loss=5.942, ppl=61.48, wps=26341, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7300, lr=0.000370117, gnorm=0.513, loss_scale=32, train_wall=196, gb_free=9.8, wall=16998
2022-03-12 15:10:20 | INFO | train_inner | epoch 019:    126 / 407 loss=5.892, ppl=59.38, wps=29100, ups=0.44, wpb=65536, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.508, loss_scale=32, train_wall=201, gb_free=9.8, wall=17223
2022-03-12 15:11:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:14:10 | INFO | train_inner | epoch 019:    227 / 407 loss=5.893, ppl=59.43, wps=28526.2, ups=0.44, wpb=65534.2, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.504, loss_scale=32, train_wall=205, gb_free=9.8, wall=17453
2022-03-12 15:16:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:17:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 15:18:01 | INFO | train_inner | epoch 019:    329 / 407 loss=5.903, ppl=59.82, wps=28413.8, ups=0.43, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.504, loss_scale=16, train_wall=206, gb_free=9.8, wall=17684
2022-03-12 15:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 15:21:22 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.814 | ppl 56.27 | wps 51702 | wpb 511.9 | bsz 1 | num_updates 7678 | best_loss 5.814
2022-03-12 15:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7678 updates
2022-03-12 15:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 19 @ 7678 updates, score 5.814) (writing took 2.2758209699823055 seconds)
2022-03-12 15:21:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-12 15:21:25 | INFO | train | epoch 019 | loss 5.897 | ppl 59.6 | wps 27884 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 7678 | lr 0.000360891 | gnorm 0.506 | loss_scale 16 | train_wall 823 | gb_free 9.8 | wall 17888
2022-03-12 15:21:25 | INFO | fairseq.trainer | begin training epoch 20
2022-03-12 15:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 15:22:15 | INFO | train_inner | epoch 020:     22 / 407 loss=5.889, ppl=59.24, wps=25689, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=7700, lr=0.000360375, gnorm=0.506, loss_scale=16, train_wall=202, gb_free=9.8, wall=17938
2022-03-12 15:26:03 | INFO | train_inner | epoch 020:    122 / 407 loss=5.838, ppl=57.2, wps=28735.6, ups=0.44, wpb=65534.2, bsz=128, num_updates=7800, lr=0.000358057, gnorm=0.503, loss_scale=32, train_wall=204, gb_free=9.8, wall=18166
2022-03-12 15:27:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:29:52 | INFO | train_inner | epoch 020:    223 / 407 loss=5.858, ppl=57.98, wps=28634, ups=0.44, wpb=65536, bsz=128, num_updates=7900, lr=0.000355784, gnorm=0.508, loss_scale=32, train_wall=205, gb_free=9.8, wall=18395
2022-03-12 15:32:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:33:38 | INFO | train_inner | epoch 020:    324 / 407 loss=5.857, ppl=57.95, wps=29022, ups=0.44, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.505, loss_scale=32, train_wall=202, gb_free=9.8, wall=18621
2022-03-12 15:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 15:37:10 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.772 | ppl 54.63 | wps 51802.6 | wpb 511.9 | bsz 1 | num_updates 8083 | best_loss 5.772
2022-03-12 15:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8083 updates
2022-03-12 15:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:37:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 20 @ 8083 updates, score 5.772) (writing took 2.2124756910197902 seconds)
2022-03-12 15:37:12 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-12 15:37:12 | INFO | train | epoch 020 | loss 5.851 | ppl 57.71 | wps 28002.6 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 8083 | lr 0.000351733 | gnorm 0.505 | loss_scale 32 | train_wall 821 | gb_free 9.8 | wall 18835
2022-03-12 15:37:12 | INFO | fairseq.trainer | begin training epoch 21
2022-03-12 15:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 15:37:51 | INFO | train_inner | epoch 021:     17 / 407 loss=5.843, ppl=57.4, wps=25824.1, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=8100, lr=0.000351364, gnorm=0.507, loss_scale=32, train_wall=201, gb_free=9.8, wall=18874
2022-03-12 15:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:41:37 | INFO | train_inner | epoch 021:    118 / 407 loss=5.794, ppl=55.49, wps=28950.5, ups=0.44, wpb=65536, bsz=128, num_updates=8200, lr=0.000349215, gnorm=0.501, loss_scale=32, train_wall=202, gb_free=9.8, wall=19100
2022-03-12 15:42:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:45:24 | INFO | train_inner | epoch 021:    219 / 407 loss=5.816, ppl=56.34, wps=28945.1, ups=0.44, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.508, loss_scale=32, train_wall=202, gb_free=9.8, wall=19327
2022-03-12 15:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:49:13 | INFO | train_inner | epoch 021:    320 / 407 loss=5.811, ppl=56.12, wps=28643.9, ups=0.44, wpb=65536, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.507, loss_scale=32, train_wall=204, gb_free=9.8, wall=19556
2022-03-12 15:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 15:52:53 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.747 | ppl 53.71 | wps 51333 | wpb 511.9 | bsz 1 | num_updates 8487 | best_loss 5.747
2022-03-12 15:52:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8487 updates
2022-03-12 15:52:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 15:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 21 @ 8487 updates, score 5.747) (writing took 2.2378580429940484 seconds)
2022-03-12 15:52:55 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-12 15:52:55 | INFO | train | epoch 021 | loss 5.809 | ppl 56.06 | wps 28042.5 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 8487 | lr 0.00034326 | gnorm 0.506 | loss_scale 32 | train_wall 817 | gb_free 9.8 | wall 19778
2022-03-12 15:52:55 | INFO | fairseq.trainer | begin training epoch 22
2022-03-12 15:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 15:53:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 15:53:26 | INFO | train_inner | epoch 022:     14 / 407 loss=5.813, ppl=56.21, wps=25759.2, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=8500, lr=0.000342997, gnorm=0.509, loss_scale=32, train_wall=201, gb_free=9.8, wall=19809
2022-03-12 15:54:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 15:57:12 | INFO | train_inner | epoch 022:    115 / 407 loss=5.76, ppl=54.19, wps=28980.8, ups=0.44, wpb=65536, bsz=128, num_updates=8600, lr=0.000340997, gnorm=0.508, loss_scale=16, train_wall=202, gb_free=9.8, wall=20035
2022-03-12 16:00:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:01:00 | INFO | train_inner | epoch 022:    216 / 407 loss=5.769, ppl=54.51, wps=28808.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=8700, lr=0.000339032, gnorm=0.509, loss_scale=16, train_wall=203, gb_free=9.8, wall=20263
2022-03-12 16:04:44 | INFO | train_inner | epoch 022:    316 / 407 loss=5.78, ppl=54.95, wps=29187.7, ups=0.45, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.505, loss_scale=16, train_wall=200, gb_free=9.8, wall=20487
2022-03-12 16:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 16:08:36 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.721 | ppl 52.73 | wps 52120.1 | wpb 511.9 | bsz 1 | num_updates 8891 | best_loss 5.721
2022-03-12 16:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 8891 updates
2022-03-12 16:08:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:08:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 22 @ 8891 updates, score 5.721) (writing took 2.17347647601855 seconds)
2022-03-12 16:08:38 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-12 16:08:38 | INFO | train | epoch 022 | loss 5.771 | ppl 54.59 | wps 28077.8 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 8891 | lr 0.00033537 | gnorm 0.507 | loss_scale 32 | train_wall 816 | gb_free 9.8 | wall 20721
2022-03-12 16:08:38 | INFO | fairseq.trainer | begin training epoch 23
2022-03-12 16:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 16:08:58 | INFO | train_inner | epoch 023:      9 / 407 loss=5.772, ppl=54.66, wps=25775.4, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=8900, lr=0.000335201, gnorm=0.507, loss_scale=32, train_wall=202, gb_free=9.8, wall=20741
2022-03-12 16:09:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:12:45 | INFO | train_inner | epoch 023:    110 / 407 loss=5.721, ppl=52.75, wps=28916.5, ups=0.44, wpb=65536, bsz=128, num_updates=9000, lr=0.000333333, gnorm=0.506, loss_scale=16, train_wall=202, gb_free=9.8, wall=20968
2022-03-12 16:16:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:16:32 | INFO | train_inner | epoch 023:    211 / 407 loss=5.729, ppl=53.05, wps=28839.4, ups=0.44, wpb=65536, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.503, loss_scale=16, train_wall=203, gb_free=9.8, wall=21195
2022-03-12 16:20:17 | INFO | train_inner | epoch 023:    311 / 407 loss=5.757, ppl=54.06, wps=29165.5, ups=0.45, wpb=65534.2, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.508, loss_scale=16, train_wall=201, gb_free=9.8, wall=21420
2022-03-12 16:21:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 16:24:17 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.707 | ppl 52.25 | wps 52186.8 | wpb 511.9 | bsz 1 | num_updates 9295 | best_loss 5.707
2022-03-12 16:24:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9295 updates
2022-03-12 16:24:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:24:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 23 @ 9295 updates, score 5.707) (writing took 2.1883343220106326 seconds)
2022-03-12 16:24:19 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-12 16:24:19 | INFO | train | epoch 023 | loss 5.736 | ppl 53.3 | wps 28108.9 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 9295 | lr 0.000328001 | gnorm 0.509 | loss_scale 16 | train_wall 815 | gb_free 9.8 | wall 21662
2022-03-12 16:24:19 | INFO | fairseq.trainer | begin training epoch 24
2022-03-12 16:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 16:24:30 | INFO | train_inner | epoch 024:      5 / 407 loss=5.736, ppl=53.29, wps=25766.4, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=9300, lr=0.000327913, gnorm=0.516, loss_scale=16, train_wall=201, gb_free=9.8, wall=21673
2022-03-12 16:28:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:28:17 | INFO | train_inner | epoch 024:    106 / 407 loss=5.686, ppl=51.5, wps=28954.4, ups=0.44, wpb=65534.2, bsz=128, num_updates=9400, lr=0.000326164, gnorm=0.513, loss_scale=16, train_wall=202, gb_free=9.8, wall=21900
2022-03-12 16:32:01 | INFO | train_inner | epoch 024:    206 / 407 loss=5.701, ppl=52.02, wps=29194.4, ups=0.45, wpb=65536, bsz=128, num_updates=9500, lr=0.000324443, gnorm=0.511, loss_scale=16, train_wall=200, gb_free=9.8, wall=22124
2022-03-12 16:35:46 | INFO | train_inner | epoch 024:    306 / 407 loss=5.711, ppl=52.39, wps=29148.7, ups=0.44, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.509, loss_scale=32, train_wall=201, gb_free=9.8, wall=22349
2022-03-12 16:37:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 16:39:30 | INFO | train_inner | epoch 024:    407 / 407 loss=5.72, ppl=52.69, wps=29184.7, ups=0.45, wpb=65361.9, bsz=127.7, num_updates=9700, lr=0.000321081, gnorm=0.506, loss_scale=32, train_wall=200, gb_free=9.8, wall=22573
2022-03-12 16:39:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 16:39:56 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.681 | ppl 51.3 | wps 51810.3 | wpb 511.9 | bsz 1 | num_updates 9700 | best_loss 5.681
2022-03-12 16:39:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9700 updates
2022-03-12 16:39:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:39:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 24 @ 9700 updates, score 5.681) (writing took 2.29261264402885 seconds)
2022-03-12 16:39:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-12 16:39:58 | INFO | train | epoch 024 | loss 5.704 | ppl 52.13 | wps 28250.9 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 9700 | lr 0.000321081 | gnorm 0.51 | loss_scale 32 | train_wall 813 | gb_free 9.8 | wall 22601
2022-03-12 16:39:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-12 16:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 16:40:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:43:44 | INFO | train_inner | epoch 025:    101 / 407 loss=5.657, ppl=50.46, wps=25766.9, ups=0.39, wpb=65534.2, bsz=128, num_updates=9800, lr=0.000319438, gnorm=0.517, loss_scale=16, train_wall=202, gb_free=9.8, wall=22827
2022-03-12 16:46:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:47:30 | INFO | train_inner | epoch 025:    202 / 407 loss=5.666, ppl=50.77, wps=29069, ups=0.44, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.516, loss_scale=16, train_wall=201, gb_free=9.8, wall=23053
2022-03-12 16:51:13 | INFO | train_inner | epoch 025:    302 / 407 loss=5.69, ppl=51.62, wps=29291, ups=0.45, wpb=65536, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.509, loss_scale=16, train_wall=200, gb_free=9.8, wall=23276
2022-03-12 16:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:55:00 | INFO | train_inner | epoch 025:    403 / 407 loss=5.687, ppl=51.53, wps=28908.9, ups=0.44, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.513, loss_scale=16, train_wall=202, gb_free=9.8, wall=23503
2022-03-12 16:55:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 16:55:34 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.656 | ppl 50.42 | wps 52551.4 | wpb 511.9 | bsz 1 | num_updates 10104 | best_loss 5.656
2022-03-12 16:55:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10104 updates
2022-03-12 16:55:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 16:55:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 25 @ 10104 updates, score 5.656) (writing took 2.2214940980193205 seconds)
2022-03-12 16:55:36 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-12 16:55:36 | INFO | train | epoch 025 | loss 5.675 | ppl 51.09 | wps 28202 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 10104 | lr 0.000314596 | gnorm 0.514 | loss_scale 16 | train_wall 812 | gb_free 9.8 | wall 23539
2022-03-12 16:55:36 | INFO | fairseq.trainer | begin training epoch 26
2022-03-12 16:55:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 16:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 16:59:13 | INFO | train_inner | epoch 026:     97 / 407 loss=5.63, ppl=49.53, wps=25835.7, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=10200, lr=0.000313112, gnorm=0.515, loss_scale=16, train_wall=201, gb_free=9.8, wall=23756
2022-03-12 17:02:59 | INFO | train_inner | epoch 026:    197 / 407 loss=5.649, ppl=50.18, wps=29061.2, ups=0.44, wpb=65536, bsz=128, num_updates=10300, lr=0.000311588, gnorm=0.51, loss_scale=32, train_wall=201, gb_free=9.8, wall=23982
2022-03-12 17:06:43 | INFO | train_inner | epoch 026:    297 / 407 loss=5.643, ppl=49.98, wps=29136.6, ups=0.44, wpb=65534.2, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.511, loss_scale=32, train_wall=201, gb_free=9.8, wall=24206
2022-03-12 17:07:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 17:08:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:10:37 | INFO | train_inner | epoch 026:    399 / 407 loss=5.666, ppl=50.76, wps=28025.8, ups=0.43, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.515, loss_scale=16, train_wall=209, gb_free=9.8, wall=24440
2022-03-12 17:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 17:11:23 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.652 | ppl 50.29 | wps 47946.9 | wpb 511.9 | bsz 1 | num_updates 10508 | best_loss 5.652
2022-03-12 17:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10508 updates
2022-03-12 17:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:11:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 26 @ 10508 updates, score 5.652) (writing took 2.248836576996837 seconds)
2022-03-12 17:11:26 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-12 17:11:26 | INFO | train | epoch 026 | loss 5.648 | ppl 50.13 | wps 27869.6 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 10508 | lr 0.000308489 | gnorm 0.513 | loss_scale 16 | train_wall 821 | gb_free 9.8 | wall 24489
2022-03-12 17:11:26 | INFO | fairseq.trainer | begin training epoch 27
2022-03-12 17:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 17:14:58 | INFO | train_inner | epoch 027:     92 / 407 loss=5.614, ppl=48.97, wps=25116.7, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=10600, lr=0.000307148, gnorm=0.522, loss_scale=32, train_wall=206, gb_free=9.8, wall=24701
2022-03-12 17:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:18:51 | INFO | train_inner | epoch 027:    193 / 407 loss=5.622, ppl=49.25, wps=28059, ups=0.43, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.516, loss_scale=16, train_wall=209, gb_free=9.8, wall=24934
2022-03-12 17:21:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:22:42 | INFO | train_inner | epoch 027:    294 / 407 loss=5.616, ppl=49.06, wps=28335.4, ups=0.43, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.52, loss_scale=16, train_wall=207, gb_free=9.8, wall=25165
2022-03-12 17:26:34 | INFO | train_inner | epoch 027:    394 / 407 loss=5.646, ppl=50.07, wps=28275.7, ups=0.43, wpb=65536, bsz=128, num_updates=10900, lr=0.000302891, gnorm=0.508, loss_scale=32, train_wall=208, gb_free=9.8, wall=25397
2022-03-12 17:26:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 17:27:29 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.623 | ppl 49.28 | wps 51215 | wpb 511.9 | bsz 1 | num_updates 10912 | best_loss 5.623
2022-03-12 17:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 10912 updates
2022-03-12 17:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 27 @ 10912 updates, score 5.623) (writing took 2.313326667994261 seconds)
2022-03-12 17:27:32 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-12 17:27:32 | INFO | train | epoch 027 | loss 5.623 | ppl 49.27 | wps 27384.6 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 10912 | lr 0.000302725 | gnorm 0.517 | loss_scale 16 | train_wall 839 | gb_free 9.8 | wall 25455
2022-03-12 17:27:32 | INFO | fairseq.trainer | begin training epoch 28
2022-03-12 17:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 17:30:54 | INFO | train_inner | epoch 028:     88 / 407 loss=5.575, ppl=47.67, wps=25110.9, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=11000, lr=0.000301511, gnorm=0.524, loss_scale=16, train_wall=207, gb_free=9.8, wall=25657
2022-03-12 17:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:34:42 | INFO | train_inner | epoch 028:    189 / 407 loss=5.59, ppl=48.17, wps=28773.2, ups=0.44, wpb=65536, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.518, loss_scale=16, train_wall=203, gb_free=9.8, wall=25885
2022-03-12 17:38:27 | INFO | train_inner | epoch 028:    289 / 407 loss=5.616, ppl=49.03, wps=29223.6, ups=0.45, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.516, loss_scale=16, train_wall=200, gb_free=9.8, wall=26110
2022-03-12 17:42:11 | INFO | train_inner | epoch 028:    389 / 407 loss=5.612, ppl=48.92, wps=29223.8, ups=0.45, wpb=65536, bsz=128, num_updates=11300, lr=0.000297482, gnorm=0.516, loss_scale=32, train_wall=200, gb_free=9.8, wall=26334
2022-03-12 17:42:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 17:43:18 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.613 | ppl 48.93 | wps 50768.1 | wpb 511.9 | bsz 1 | num_updates 11317 | best_loss 5.613
2022-03-12 17:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11317 updates
2022-03-12 17:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:43:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 28 @ 11317 updates, score 5.613) (writing took 2.3084684180212207 seconds)
2022-03-12 17:43:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-12 17:43:20 | INFO | train | epoch 028 | loss 5.599 | ppl 48.48 | wps 27974.2 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 11317 | lr 0.000297259 | gnorm 0.518 | loss_scale 16 | train_wall 821 | gb_free 9.8 | wall 26403
2022-03-12 17:43:20 | INFO | fairseq.trainer | begin training epoch 29
2022-03-12 17:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 17:46:26 | INFO | train_inner | epoch 029:     83 / 407 loss=5.568, ppl=47.44, wps=25621.9, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=11400, lr=0.000296174, gnorm=0.514, loss_scale=16, train_wall=202, gb_free=9.8, wall=26589
2022-03-12 17:47:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:50:18 | INFO | train_inner | epoch 029:    184 / 407 loss=5.587, ppl=48.06, wps=28221.6, ups=0.43, wpb=65534.2, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.519, loss_scale=16, train_wall=208, gb_free=9.8, wall=26821
2022-03-12 17:52:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 17:54:12 | INFO | train_inner | epoch 029:    285 / 407 loss=5.567, ppl=47.41, wps=28034.2, ups=0.43, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.516, loss_scale=16, train_wall=209, gb_free=9.8, wall=27055
2022-03-12 17:58:00 | INFO | train_inner | epoch 029:    385 / 407 loss=5.591, ppl=48.21, wps=28724.8, ups=0.44, wpb=65536, bsz=128, num_updates=11700, lr=0.000292353, gnorm=0.52, loss_scale=32, train_wall=204, gb_free=9.8, wall=27283
2022-03-12 17:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 17:59:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.597 | ppl 48.4 | wps 52046.4 | wpb 511.9 | bsz 1 | num_updates 11722 | best_loss 5.597
2022-03-12 17:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11722 updates
2022-03-12 17:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 17:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 29 @ 11722 updates, score 5.597) (writing took 2.218859949032776 seconds)
2022-03-12 17:59:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-12 17:59:17 | INFO | train | epoch 029 | loss 5.578 | ppl 47.76 | wps 27714.2 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 11722 | lr 0.000292078 | gnorm 0.517 | loss_scale 32 | train_wall 831 | gb_free 9.8 | wall 27360
2022-03-12 17:59:17 | INFO | fairseq.trainer | begin training epoch 30
2022-03-12 17:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 18:02:15 | INFO | train_inner | epoch 030:     78 / 407 loss=5.555, ppl=47.02, wps=25632, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=11800, lr=0.000291111, gnorm=0.515, loss_scale=32, train_wall=203, gb_free=9.8, wall=27538
2022-03-12 18:03:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-12 18:03:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:06:08 | INFO | train_inner | epoch 030:    180 / 407 loss=5.544, ppl=46.65, wps=28088.3, ups=0.43, wpb=65536, bsz=128, num_updates=11900, lr=0.000289886, gnorm=0.524, loss_scale=16, train_wall=209, gb_free=9.8, wall=27771
2022-03-12 18:09:58 | INFO | train_inner | epoch 030:    280 / 407 loss=5.565, ppl=47.34, wps=28559.3, ups=0.44, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.52, loss_scale=32, train_wall=206, gb_free=9.8, wall=28001
2022-03-12 18:10:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:13:44 | INFO | train_inner | epoch 030:    381 / 407 loss=5.568, ppl=47.44, wps=28987.6, ups=0.44, wpb=65534.2, bsz=128, num_updates=12100, lr=0.00028748, gnorm=0.524, loss_scale=16, train_wall=202, gb_free=9.8, wall=28227
2022-03-12 18:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 18:15:06 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.588 | ppl 48.11 | wps 52748.2 | wpb 511.9 | bsz 1 | num_updates 12126 | best_loss 5.588
2022-03-12 18:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12126 updates
2022-03-12 18:15:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:15:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 30 @ 12126 updates, score 5.588) (writing took 2.2257652409607545 seconds)
2022-03-12 18:15:08 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-12 18:15:08 | INFO | train | epoch 030 | loss 5.557 | ppl 47.08 | wps 27809.6 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 12126 | lr 0.000287171 | gnorm 0.522 | loss_scale 16 | train_wall 826 | gb_free 9.8 | wall 28311
2022-03-12 18:15:08 | INFO | fairseq.trainer | begin training epoch 31
2022-03-12 18:15:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 18:16:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:17:56 | INFO | train_inner | epoch 031:     75 / 407 loss=5.52, ppl=45.88, wps=25876.6, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=12200, lr=0.000286299, gnorm=0.528, loss_scale=16, train_wall=201, gb_free=9.8, wall=28479
2022-03-12 18:21:43 | INFO | train_inner | epoch 031:    175 / 407 loss=5.531, ppl=46.25, wps=28902, ups=0.44, wpb=65536, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.528, loss_scale=32, train_wall=203, gb_free=9.8, wall=28706
2022-03-12 18:22:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:25:34 | INFO | train_inner | epoch 031:    276 / 407 loss=5.545, ppl=46.7, wps=28439.9, ups=0.43, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.517, loss_scale=16, train_wall=206, gb_free=9.8, wall=28937
2022-03-12 18:29:23 | INFO | train_inner | epoch 031:    376 / 407 loss=5.558, ppl=47.12, wps=28578.7, ups=0.44, wpb=65536, bsz=128, num_updates=12500, lr=0.000282843, gnorm=0.522, loss_scale=32, train_wall=205, gb_free=9.8, wall=29166
2022-03-12 18:30:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 18:30:59 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.577 | ppl 47.72 | wps 51020 | wpb 511.9 | bsz 1 | num_updates 12531 | best_loss 5.577
2022-03-12 18:30:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12531 updates
2022-03-12 18:30:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:31:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:31:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 31 @ 12531 updates, score 5.577) (writing took 2.2734579640091397 seconds)
2022-03-12 18:31:01 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-12 18:31:01 | INFO | train | epoch 031 | loss 5.538 | ppl 46.45 | wps 27847.7 | ups 0.43 | wpb 65493 | bsz 127.9 | num_updates 12531 | lr 0.000282493 | gnorm 0.524 | loss_scale 32 | train_wall 826 | gb_free 9.8 | wall 29264
2022-03-12 18:31:01 | INFO | fairseq.trainer | begin training epoch 32
2022-03-12 18:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 18:32:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:33:40 | INFO | train_inner | epoch 032:     70 / 407 loss=5.511, ppl=45.59, wps=25413.1, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=12600, lr=0.000281718, gnorm=0.524, loss_scale=16, train_wall=204, gb_free=9.8, wall=29423
2022-03-12 18:37:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:37:30 | INFO | train_inner | epoch 032:    171 / 407 loss=5.511, ppl=45.6, wps=28555, ups=0.44, wpb=65536, bsz=128, num_updates=12700, lr=0.000280607, gnorm=0.526, loss_scale=16, train_wall=205, gb_free=9.8, wall=29653
2022-03-12 18:41:18 | INFO | train_inner | epoch 032:    271 / 407 loss=5.526, ppl=46.08, wps=28659.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.526, loss_scale=16, train_wall=204, gb_free=9.8, wall=29881
2022-03-12 18:43:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:45:05 | INFO | train_inner | epoch 032:    372 / 407 loss=5.538, ppl=46.45, wps=28857.8, ups=0.44, wpb=65536, bsz=128, num_updates=12900, lr=0.000278423, gnorm=0.518, loss_scale=16, train_wall=203, gb_free=9.8, wall=30108
2022-03-12 18:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 18:46:48 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.553 | ppl 46.95 | wps 52378.6 | wpb 511.9 | bsz 1 | num_updates 12935 | best_loss 5.553
2022-03-12 18:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 12935 updates
2022-03-12 18:46:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:46:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 18:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 32 @ 12935 updates, score 5.553) (writing took 2.2092957890126854 seconds)
2022-03-12 18:46:50 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-12 18:46:50 | INFO | train | epoch 032 | loss 5.519 | ppl 45.87 | wps 27883.4 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 12935 | lr 0.000278046 | gnorm 0.523 | loss_scale 16 | train_wall 823 | gb_free 9.8 | wall 30213
2022-03-12 18:46:50 | INFO | fairseq.trainer | begin training epoch 33
2022-03-12 18:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 18:49:13 | INFO | train_inner | epoch 033:     65 / 407 loss=5.493, ppl=45.02, wps=26411.7, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=13000, lr=0.00027735, gnorm=0.525, loss_scale=32, train_wall=196, gb_free=9.8, wall=30356
2022-03-12 18:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:52:56 | INFO | train_inner | epoch 033:    166 / 407 loss=5.496, ppl=45.12, wps=29317.4, ups=0.45, wpb=65534.2, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.531, loss_scale=16, train_wall=199, gb_free=9.8, wall=30579
2022-03-12 18:55:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 18:56:42 | INFO | train_inner | epoch 033:    267 / 407 loss=5.508, ppl=45.51, wps=29102, ups=0.44, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.524, loss_scale=16, train_wall=201, gb_free=9.8, wall=30805
2022-03-12 19:00:23 | INFO | train_inner | epoch 033:    367 / 407 loss=5.514, ppl=45.69, wps=29543.3, ups=0.45, wpb=65536, bsz=128, num_updates=13300, lr=0.000274204, gnorm=0.522, loss_scale=32, train_wall=198, gb_free=9.8, wall=31026
2022-03-12 19:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 19:02:18 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.551 | ppl 46.88 | wps 52527.4 | wpb 511.9 | bsz 1 | num_updates 13340 | best_loss 5.551
2022-03-12 19:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13340 updates
2022-03-12 19:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 33 @ 13340 updates, score 5.551) (writing took 2.1823669410077855 seconds)
2022-03-12 19:02:20 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-12 19:02:20 | INFO | train | epoch 033 | loss 5.502 | ppl 45.32 | wps 28525.2 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 13340 | lr 0.000273793 | gnorm 0.525 | loss_scale 32 | train_wall 804 | gb_free 9.8 | wall 31143
2022-03-12 19:02:20 | INFO | fairseq.trainer | begin training epoch 34
2022-03-12 19:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 19:02:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:04:34 | INFO | train_inner | epoch 034:     61 / 407 loss=5.481, ppl=44.67, wps=26040.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=13400, lr=0.000273179, gnorm=0.527, loss_scale=16, train_wall=199, gb_free=9.8, wall=31277
2022-03-12 19:07:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:08:19 | INFO | train_inner | epoch 034:    162 / 407 loss=5.472, ppl=44.38, wps=29184.4, ups=0.45, wpb=65534.2, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.524, loss_scale=16, train_wall=200, gb_free=9.8, wall=31502
2022-03-12 19:12:00 | INFO | train_inner | epoch 034:    262 / 407 loss=5.497, ppl=45.16, wps=29711.8, ups=0.45, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.527, loss_scale=16, train_wall=197, gb_free=9.8, wall=31723
2022-03-12 19:14:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:15:49 | INFO | train_inner | epoch 034:    363 / 407 loss=5.503, ppl=45.34, wps=28609.4, ups=0.44, wpb=65536, bsz=128, num_updates=13700, lr=0.000270172, gnorm=0.526, loss_scale=16, train_wall=205, gb_free=9.8, wall=31952
2022-03-12 19:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 19:17:51 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.537 | ppl 46.44 | wps 53092.5 | wpb 511.9 | bsz 1 | num_updates 13744 | best_loss 5.537
2022-03-12 19:17:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13744 updates
2022-03-12 19:17:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:17:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 34 @ 13744 updates, score 5.537) (writing took 2.2679006989928894 seconds)
2022-03-12 19:17:53 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-12 19:17:53 | INFO | train | epoch 034 | loss 5.486 | ppl 44.82 | wps 28339.8 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 13744 | lr 0.000269739 | gnorm 0.527 | loss_scale 16 | train_wall 808 | gb_free 9.8 | wall 32076
2022-03-12 19:17:53 | INFO | fairseq.trainer | begin training epoch 35
2022-03-12 19:17:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 19:20:01 | INFO | train_inner | epoch 035:     56 / 407 loss=5.464, ppl=44.15, wps=25921.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=13800, lr=0.000269191, gnorm=0.528, loss_scale=32, train_wall=201, gb_free=9.8, wall=32204
2022-03-12 19:20:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:23:46 | INFO | train_inner | epoch 035:    157 / 407 loss=5.463, ppl=44.1, wps=29137.2, ups=0.44, wpb=65534.2, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.521, loss_scale=16, train_wall=201, gb_free=9.8, wall=32429
2022-03-12 19:24:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:27:32 | INFO | train_inner | epoch 035:    258 / 407 loss=5.478, ppl=44.57, wps=29027.4, ups=0.44, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.529, loss_scale=16, train_wall=202, gb_free=9.8, wall=32655
2022-03-12 19:30:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:31:18 | INFO | train_inner | epoch 035:    359 / 407 loss=5.488, ppl=44.89, wps=28972.5, ups=0.44, wpb=65536, bsz=128, num_updates=14100, lr=0.000266312, gnorm=0.538, loss_scale=16, train_wall=202, gb_free=9.8, wall=32881
2022-03-12 19:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 19:33:30 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.532 | ppl 46.26 | wps 52363.5 | wpb 511.9 | bsz 1 | num_updates 14148 | best_loss 5.532
2022-03-12 19:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14148 updates
2022-03-12 19:33:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 35 @ 14148 updates, score 5.532) (writing took 2.193324134044815 seconds)
2022-03-12 19:33:32 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-12 19:33:32 | INFO | train | epoch 035 | loss 5.471 | ppl 44.36 | wps 28181.5 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 14148 | lr 0.00026586 | gnorm 0.528 | loss_scale 16 | train_wall 813 | gb_free 9.8 | wall 33015
2022-03-12 19:33:32 | INFO | fairseq.trainer | begin training epoch 36
2022-03-12 19:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 19:35:28 | INFO | train_inner | epoch 036:     52 / 407 loss=5.462, ppl=44.08, wps=26075.6, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=14200, lr=0.000265372, gnorm=0.527, loss_scale=16, train_wall=199, gb_free=9.8, wall=33131
2022-03-12 19:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:38:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-12 19:39:15 | INFO | train_inner | epoch 036:    154 / 407 loss=5.45, ppl=43.73, wps=28971.7, ups=0.44, wpb=65536, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.533, loss_scale=8, train_wall=202, gb_free=9.8, wall=33358
2022-03-12 19:42:51 | INFO | train_inner | epoch 036:    254 / 407 loss=5.452, ppl=43.76, wps=30215.1, ups=0.46, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.529, loss_scale=8, train_wall=193, gb_free=9.8, wall=33574
2022-03-12 19:46:27 | INFO | train_inner | epoch 036:    354 / 407 loss=5.468, ppl=44.26, wps=30478, ups=0.47, wpb=65536, bsz=128, num_updates=14500, lr=0.000262613, gnorm=0.527, loss_scale=16, train_wall=191, gb_free=9.8, wall=33790
2022-03-12 19:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 19:48:42 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.52 | ppl 45.89 | wps 54495.7 | wpb 511.9 | bsz 1 | num_updates 14553 | best_loss 5.52
2022-03-12 19:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14553 updates
2022-03-12 19:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 19:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 36 @ 14553 updates, score 5.52) (writing took 2.3150593360187486 seconds)
2022-03-12 19:48:44 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-12 19:48:44 | INFO | train | epoch 036 | loss 5.456 | ppl 43.91 | wps 29085 | ups 0.44 | wpb 65493 | bsz 127.9 | num_updates 14553 | lr 0.000262134 | gnorm 0.53 | loss_scale 32 | train_wall 788 | gb_free 9.8 | wall 33927
2022-03-12 19:48:44 | INFO | fairseq.trainer | begin training epoch 37
2022-03-12 19:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 19:50:25 | INFO | train_inner | epoch 037:     47 / 407 loss=5.435, ppl=43.27, wps=27387.6, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=14600, lr=0.000261712, gnorm=0.527, loss_scale=32, train_wall=188, gb_free=9.8, wall=34028
2022-03-12 19:50:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:53:57 | INFO | train_inner | epoch 037:    148 / 407 loss=5.431, ppl=43.14, wps=30876.5, ups=0.47, wpb=65536, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.527, loss_scale=16, train_wall=188, gb_free=9.8, wall=34240
2022-03-12 19:55:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 19:57:31 | INFO | train_inner | epoch 037:    249 / 407 loss=5.444, ppl=43.52, wps=30715.3, ups=0.47, wpb=65536, bsz=128, num_updates=14800, lr=0.000259938, gnorm=0.526, loss_scale=16, train_wall=189, gb_free=9.8, wall=34454
2022-03-12 20:00:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:01:03 | INFO | train_inner | epoch 037:    350 / 407 loss=5.462, ppl=44.09, wps=30836.6, ups=0.47, wpb=65534.2, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.52, loss_scale=16, train_wall=188, gb_free=9.8, wall=34666
2022-03-12 20:03:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 20:03:28 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.514 | ppl 45.68 | wps 54572.4 | wpb 511.9 | bsz 1 | num_updates 14957 | best_loss 5.514
2022-03-12 20:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 14957 updates
2022-03-12 20:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 37 @ 14957 updates, score 5.514) (writing took 2.2090702049899846 seconds)
2022-03-12 20:03:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-12 20:03:31 | INFO | train | epoch 037 | loss 5.442 | ppl 43.46 | wps 29851.9 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 14957 | lr 0.00025857 | gnorm 0.525 | loss_scale 16 | train_wall 763 | gb_free 9.8 | wall 34814
2022-03-12 20:03:31 | INFO | fairseq.trainer | begin training epoch 38
2022-03-12 20:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 20:05:01 | INFO | train_inner | epoch 038:     43 / 407 loss=5.431, ppl=43.13, wps=27508.7, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=15000, lr=0.000258199, gnorm=0.529, loss_scale=16, train_wall=187, gb_free=9.8, wall=34904
2022-03-12 20:06:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:08:33 | INFO | train_inner | epoch 038:    144 / 407 loss=5.405, ppl=42.38, wps=30854.7, ups=0.47, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.528, loss_scale=16, train_wall=188, gb_free=9.8, wall=35116
2022-03-12 20:12:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:12:05 | INFO | train_inner | epoch 038:    245 / 407 loss=5.444, ppl=43.53, wps=30978.7, ups=0.47, wpb=65536, bsz=128, num_updates=15200, lr=0.000256495, gnorm=0.531, loss_scale=16, train_wall=187, gb_free=9.8, wall=35328
2022-03-12 20:15:35 | INFO | train_inner | epoch 038:    345 / 407 loss=5.441, ppl=43.43, wps=31117.5, ups=0.47, wpb=65534.2, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.532, loss_scale=16, train_wall=187, gb_free=9.8, wall=35538
2022-03-12 20:17:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 20:18:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.5 | ppl 45.26 | wps 54880.5 | wpb 511.9 | bsz 1 | num_updates 15361 | best_loss 5.5
2022-03-12 20:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 15361 updates
2022-03-12 20:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:18:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 38 @ 15361 updates, score 5.5) (writing took 2.2929572879802436 seconds)
2022-03-12 20:18:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-12 20:18:11 | INFO | train | epoch 038 | loss 5.429 | ppl 43.08 | wps 30042.7 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 15361 | lr 0.000255147 | gnorm 0.53 | loss_scale 16 | train_wall 757 | gb_free 9.8 | wall 35694
2022-03-12 20:18:11 | INFO | fairseq.trainer | begin training epoch 39
2022-03-12 20:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 20:19:33 | INFO | train_inner | epoch 039:     39 / 407 loss=5.427, ppl=43.03, wps=27557.3, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=15400, lr=0.000254824, gnorm=0.53, loss_scale=16, train_wall=186, gb_free=9.8, wall=35776
2022-03-12 20:22:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:23:05 | INFO | train_inner | epoch 039:    140 / 407 loss=5.404, ppl=42.35, wps=30816.9, ups=0.47, wpb=65536, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.54, loss_scale=16, train_wall=189, gb_free=9.8, wall=35988
2022-03-12 20:26:36 | INFO | train_inner | epoch 039:    240 / 407 loss=5.417, ppl=42.73, wps=31155.9, ups=0.48, wpb=65536, bsz=128, num_updates=15600, lr=0.000253185, gnorm=0.541, loss_scale=16, train_wall=187, gb_free=9.8, wall=36199
2022-03-12 20:27:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:30:10 | INFO | train_inner | epoch 039:    341 / 407 loss=5.428, ppl=43.05, wps=30620.7, ups=0.47, wpb=65536, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.534, loss_scale=16, train_wall=190, gb_free=9.8, wall=36413
2022-03-12 20:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 20:32:57 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.494 | ppl 45.07 | wps 53201.2 | wpb 511.9 | bsz 1 | num_updates 15766 | best_loss 5.494
2022-03-12 20:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 15766 updates
2022-03-12 20:32:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 39 @ 15766 updates, score 5.494) (writing took 2.1553187239915133 seconds)
2022-03-12 20:32:59 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-12 20:32:59 | INFO | train | epoch 039 | loss 5.417 | ppl 42.71 | wps 29887.4 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 15766 | lr 0.000251848 | gnorm 0.536 | loss_scale 32 | train_wall 763 | gb_free 9.8 | wall 36582
2022-03-12 20:32:59 | INFO | fairseq.trainer | begin training epoch 40
2022-03-12 20:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 20:33:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:34:15 | INFO | train_inner | epoch 040:     35 / 407 loss=5.416, ppl=42.7, wps=26677.8, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=15800, lr=0.000251577, gnorm=0.53, loss_scale=16, train_wall=193, gb_free=9.8, wall=36658
2022-03-12 20:37:54 | INFO | train_inner | epoch 040:    135 / 407 loss=5.382, ppl=41.69, wps=29875.8, ups=0.46, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.537, loss_scale=16, train_wall=195, gb_free=9.8, wall=36877
2022-03-12 20:38:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:41:33 | INFO | train_inner | epoch 040:    236 / 407 loss=5.398, ppl=42.17, wps=29917.8, ups=0.46, wpb=65534.2, bsz=128, num_updates=16000, lr=0.00025, gnorm=0.537, loss_scale=16, train_wall=195, gb_free=9.8, wall=37096
2022-03-12 20:43:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:45:14 | INFO | train_inner | epoch 040:    337 / 407 loss=5.424, ppl=42.92, wps=29630.6, ups=0.45, wpb=65536, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.531, loss_scale=16, train_wall=197, gb_free=9.8, wall=37317
2022-03-12 20:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 20:48:10 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.494 | ppl 45.06 | wps 53309.3 | wpb 511.9 | bsz 1 | num_updates 16170 | best_loss 5.494
2022-03-12 20:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 16170 updates
2022-03-12 20:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 20:48:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 40 @ 16170 updates, score 5.494) (writing took 2.1873950310400687 seconds)
2022-03-12 20:48:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-12 20:48:13 | INFO | train | epoch 040 | loss 5.404 | ppl 42.34 | wps 28952.6 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16170 | lr 0.000248682 | gnorm 0.536 | loss_scale 16 | train_wall 789 | gb_free 9.8 | wall 37496
2022-03-12 20:48:13 | INFO | fairseq.trainer | begin training epoch 41
2022-03-12 20:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 20:49:20 | INFO | train_inner | epoch 041:     30 / 407 loss=5.402, ppl=42.3, wps=26589.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=16200, lr=0.000248452, gnorm=0.545, loss_scale=32, train_wall=194, gb_free=9.8, wall=37563
2022-03-12 20:52:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 20:52:59 | INFO | train_inner | epoch 041:    131 / 407 loss=5.38, ppl=41.65, wps=30004, ups=0.46, wpb=65534.2, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.541, loss_scale=16, train_wall=194, gb_free=9.8, wall=37782
2022-03-12 20:56:34 | INFO | train_inner | epoch 041:    231 / 407 loss=5.394, ppl=42.05, wps=30458.3, ups=0.46, wpb=65536, bsz=128, num_updates=16400, lr=0.000246932, gnorm=0.537, loss_scale=16, train_wall=191, gb_free=9.8, wall=37997
2022-03-12 20:57:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:00:10 | INFO | train_inner | epoch 041:    332 / 407 loss=5.403, ppl=42.31, wps=30325.8, ups=0.46, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.54, loss_scale=16, train_wall=192, gb_free=9.8, wall=38213
2022-03-12 21:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 21:03:14 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.488 | ppl 44.88 | wps 53776.8 | wpb 511.9 | bsz 1 | num_updates 16574 | best_loss 5.488
2022-03-12 21:03:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 16574 updates
2022-03-12 21:03:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:03:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:03:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 41 @ 16574 updates, score 5.488) (writing took 2.1132761720218696 seconds)
2022-03-12 21:03:16 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-12 21:03:16 | INFO | train | epoch 041 | loss 5.392 | ppl 41.99 | wps 29286.2 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 16574 | lr 0.000245633 | gnorm 0.542 | loss_scale 16 | train_wall 779 | gb_free 9.8 | wall 38399
2022-03-12 21:03:16 | INFO | fairseq.trainer | begin training epoch 42
2022-03-12 21:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 21:04:12 | INFO | train_inner | epoch 042:     26 / 407 loss=5.394, ppl=42.04, wps=27005.4, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=16600, lr=0.00024544, gnorm=0.545, loss_scale=16, train_wall=191, gb_free=9.8, wall=38455
2022-03-12 21:07:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:07:48 | INFO | train_inner | epoch 042:    127 / 407 loss=5.365, ppl=41.2, wps=30330, ups=0.46, wpb=65536, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.538, loss_scale=16, train_wall=192, gb_free=9.8, wall=38671
2022-03-12 21:11:22 | INFO | train_inner | epoch 042:    227 / 407 loss=5.373, ppl=41.43, wps=30558.1, ups=0.47, wpb=65536, bsz=128, num_updates=16800, lr=0.000243975, gnorm=0.53, loss_scale=16, train_wall=191, gb_free=9.8, wall=38885
2022-03-12 21:13:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:14:59 | INFO | train_inner | epoch 042:    328 / 407 loss=5.4, ppl=42.22, wps=30316.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.539, loss_scale=16, train_wall=192, gb_free=9.8, wall=39102
2022-03-12 21:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 21:18:12 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.481 | ppl 44.65 | wps 53869.8 | wpb 511.9 | bsz 1 | num_updates 16979 | best_loss 5.481
2022-03-12 21:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 16979 updates
2022-03-12 21:18:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:18:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:18:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 42 @ 16979 updates, score 5.481) (writing took 2.1718515360262245 seconds)
2022-03-12 21:18:14 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-12 21:18:14 | INFO | train | epoch 042 | loss 5.381 | ppl 41.67 | wps 29545.2 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 16979 | lr 0.000242686 | gnorm 0.535 | loss_scale 16 | train_wall 774 | gb_free 9.8 | wall 39297
2022-03-12 21:18:14 | INFO | fairseq.trainer | begin training epoch 43
2022-03-12 21:18:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 21:18:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:19:01 | INFO | train_inner | epoch 043:     22 / 407 loss=5.384, ppl=41.75, wps=26969, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=17000, lr=0.000242536, gnorm=0.535, loss_scale=16, train_wall=191, gb_free=9.8, wall=39344
2022-03-12 21:22:35 | INFO | train_inner | epoch 043:    122 / 407 loss=5.353, ppl=40.88, wps=30618.5, ups=0.47, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.546, loss_scale=16, train_wall=190, gb_free=9.8, wall=39558
2022-03-12 21:23:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:26:11 | INFO | train_inner | epoch 043:    223 / 407 loss=5.377, ppl=41.55, wps=30288.6, ups=0.46, wpb=65536, bsz=128, num_updates=17200, lr=0.000241121, gnorm=0.536, loss_scale=16, train_wall=192, gb_free=9.8, wall=39774
2022-03-12 21:28:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:29:47 | INFO | train_inner | epoch 043:    324 / 407 loss=5.375, ppl=41.49, wps=30395, ups=0.46, wpb=65536, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.545, loss_scale=16, train_wall=192, gb_free=9.8, wall=39990
2022-03-12 21:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 21:33:08 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.475 | ppl 44.47 | wps 54108.2 | wpb 511.9 | bsz 1 | num_updates 17383 | best_loss 5.475
2022-03-12 21:33:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 17383 updates
2022-03-12 21:33:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 43 @ 17383 updates, score 5.475) (writing took 2.1255601560114883 seconds)
2022-03-12 21:33:10 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-12 21:33:10 | INFO | train | epoch 043 | loss 5.37 | ppl 41.34 | wps 29520.3 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 17383 | lr 0.000239849 | gnorm 0.541 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 40193
2022-03-12 21:33:10 | INFO | fairseq.trainer | begin training epoch 44
2022-03-12 21:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 21:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:33:49 | INFO | train_inner | epoch 044:     18 / 407 loss=5.373, ppl=41.43, wps=27057.8, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=17400, lr=0.000239732, gnorm=0.537, loss_scale=16, train_wall=191, gb_free=9.8, wall=40232
2022-03-12 21:37:22 | INFO | train_inner | epoch 044:    118 / 407 loss=5.343, ppl=40.58, wps=30665.7, ups=0.47, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.536, loss_scale=16, train_wall=190, gb_free=9.8, wall=40445
2022-03-12 21:38:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:40:58 | INFO | train_inner | epoch 044:    219 / 407 loss=5.358, ppl=41, wps=30361.1, ups=0.46, wpb=65536, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.543, loss_scale=16, train_wall=192, gb_free=9.8, wall=40661
2022-03-12 21:42:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:44:34 | INFO | train_inner | epoch 044:    320 / 407 loss=5.372, ppl=41.43, wps=30354.4, ups=0.46, wpb=65536, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.539, loss_scale=16, train_wall=192, gb_free=9.8, wall=40877
2022-03-12 21:47:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 21:48:04 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.464 | ppl 44.15 | wps 53969.6 | wpb 511.9 | bsz 1 | num_updates 17786 | best_loss 5.464
2022-03-12 21:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 17786 updates
2022-03-12 21:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 21:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 44 @ 17786 updates, score 5.464) (writing took 2.2188069359981455 seconds)
2022-03-12 21:48:06 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-12 21:48:06 | INFO | train | epoch 044 | loss 5.359 | ppl 41.05 | wps 29447.9 | ups 0.45 | wpb 65492.3 | bsz 127.9 | num_updates 17786 | lr 0.000237116 | gnorm 0.539 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 41089
2022-03-12 21:48:06 | INFO | fairseq.trainer | begin training epoch 45
2022-03-12 21:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 21:48:36 | INFO | train_inner | epoch 045:     14 / 407 loss=5.363, ppl=41.15, wps=26983.7, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=17800, lr=0.000237023, gnorm=0.54, loss_scale=16, train_wall=191, gb_free=9.8, wall=41119
2022-03-12 21:52:09 | INFO | train_inner | epoch 045:    114 / 407 loss=5.323, ppl=40.02, wps=30749.4, ups=0.47, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.542, loss_scale=16, train_wall=189, gb_free=9.8, wall=41332
2022-03-12 21:52:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:55:45 | INFO | train_inner | epoch 045:    215 / 407 loss=5.342, ppl=40.57, wps=30398, ups=0.46, wpb=65536, bsz=128, num_updates=18000, lr=0.000235702, gnorm=0.539, loss_scale=16, train_wall=192, gb_free=9.8, wall=41548
2022-03-12 21:58:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 21:59:21 | INFO | train_inner | epoch 045:    316 / 407 loss=5.372, ppl=41.42, wps=30315.1, ups=0.46, wpb=65534.2, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.54, loss_scale=16, train_wall=192, gb_free=9.8, wall=41764
2022-03-12 22:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 22:03:00 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.462 | ppl 44.07 | wps 53755.6 | wpb 511.9 | bsz 1 | num_updates 18191 | best_loss 5.462
2022-03-12 22:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 18191 updates
2022-03-12 22:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 45 @ 18191 updates, score 5.462) (writing took 2.171434150019195 seconds)
2022-03-12 22:03:02 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-12 22:03:02 | INFO | train | epoch 045 | loss 5.35 | ppl 40.78 | wps 29601.9 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 18191 | lr 0.000234462 | gnorm 0.541 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 41985
2022-03-12 22:03:02 | INFO | fairseq.trainer | begin training epoch 46
2022-03-12 22:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 22:03:22 | INFO | train_inner | epoch 046:      9 / 407 loss=5.365, ppl=41.2, wps=27160.4, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=18200, lr=0.000234404, gnorm=0.54, loss_scale=16, train_wall=190, gb_free=9.8, wall=42005
2022-03-12 22:04:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:06:58 | INFO | train_inner | epoch 046:    110 / 407 loss=5.319, ppl=39.93, wps=30383.4, ups=0.46, wpb=65534.2, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.547, loss_scale=16, train_wall=192, gb_free=9.8, wall=42221
2022-03-12 22:09:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:10:33 | INFO | train_inner | epoch 046:    211 / 407 loss=5.342, ppl=40.56, wps=30435.6, ups=0.46, wpb=65536, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.548, loss_scale=16, train_wall=191, gb_free=9.8, wall=42436
2022-03-12 22:14:06 | INFO | train_inner | epoch 046:    311 / 407 loss=5.349, ppl=40.75, wps=30716, ups=0.47, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.543, loss_scale=32, train_wall=190, gb_free=9.8, wall=42649
2022-03-12 22:14:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 22:17:55 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.453 | ppl 43.8 | wps 53974.2 | wpb 511.9 | bsz 1 | num_updates 18595 | best_loss 5.453
2022-03-12 22:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 18595 updates
2022-03-12 22:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:17:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 46 @ 18595 updates, score 5.453) (writing took 2.183248432993423 seconds)
2022-03-12 22:17:57 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-12 22:17:57 | INFO | train | epoch 046 | loss 5.341 | ppl 40.52 | wps 29580.7 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 18595 | lr 0.000231901 | gnorm 0.543 | loss_scale 16 | train_wall 770 | gb_free 9.8 | wall 42880
2022-03-12 22:17:57 | INFO | fairseq.trainer | begin training epoch 47
2022-03-12 22:17:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 22:18:08 | INFO | train_inner | epoch 047:      5 / 407 loss=5.354, ppl=40.91, wps=27068.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=18600, lr=0.000231869, gnorm=0.537, loss_scale=16, train_wall=190, gb_free=9.8, wall=42891
2022-03-12 22:19:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:21:43 | INFO | train_inner | epoch 047:    106 / 407 loss=5.308, ppl=39.61, wps=30427.1, ups=0.46, wpb=65536, bsz=128, num_updates=18700, lr=0.000231249, gnorm=0.541, loss_scale=16, train_wall=191, gb_free=9.8, wall=43106
2022-03-12 22:25:16 | INFO | train_inner | epoch 047:    206 / 407 loss=5.315, ppl=39.81, wps=30716.5, ups=0.47, wpb=65534.2, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.539, loss_scale=32, train_wall=189, gb_free=9.8, wall=43319
2022-03-12 22:25:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:28:52 | INFO | train_inner | epoch 047:    307 / 407 loss=5.349, ppl=40.75, wps=30407.3, ups=0.46, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.549, loss_scale=16, train_wall=191, gb_free=9.8, wall=43535
2022-03-12 22:32:25 | INFO | train_inner | epoch 047:    407 / 407 loss=5.355, ppl=40.92, wps=30693.7, ups=0.47, wpb=65361.9, bsz=127.7, num_updates=19000, lr=0.000229416, gnorm=0.542, loss_scale=32, train_wall=189, gb_free=9.8, wall=43748
2022-03-12 22:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 22:32:50 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 5.451 | ppl 43.75 | wps 53989.3 | wpb 511.9 | bsz 1 | num_updates 19000 | best_loss 5.451
2022-03-12 22:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 19000 updates
2022-03-12 22:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:32:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 47 @ 19000 updates, score 5.451) (writing took 2.159256719984114 seconds)
2022-03-12 22:32:52 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-12 22:32:52 | INFO | train | epoch 047 | loss 5.331 | ppl 40.26 | wps 29637.1 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 19000 | lr 0.000229416 | gnorm 0.543 | loss_scale 32 | train_wall 771 | gb_free 9.8 | wall 43775
2022-03-12 22:32:52 | INFO | fairseq.trainer | begin training epoch 48
2022-03-12 22:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 22:33:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:36:28 | INFO | train_inner | epoch 048:    101 / 407 loss=5.306, ppl=39.56, wps=27000.1, ups=0.41, wpb=65534.2, bsz=128, num_updates=19100, lr=0.000228814, gnorm=0.543, loss_scale=16, train_wall=191, gb_free=9.8, wall=43991
2022-03-12 22:39:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:40:03 | INFO | train_inner | epoch 048:    202 / 407 loss=5.315, ppl=39.82, wps=30376.5, ups=0.46, wpb=65536, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.541, loss_scale=16, train_wall=192, gb_free=9.8, wall=44206
2022-03-12 22:43:37 | INFO | train_inner | epoch 048:    302 / 407 loss=5.33, ppl=40.23, wps=30644, ups=0.47, wpb=65536, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.544, loss_scale=16, train_wall=190, gb_free=9.8, wall=44420
2022-03-12 22:44:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:47:13 | INFO | train_inner | epoch 048:    403 / 407 loss=5.338, ppl=40.45, wps=30323.2, ups=0.46, wpb=65536, bsz=128, num_updates=19400, lr=0.000227038, gnorm=0.541, loss_scale=16, train_wall=192, gb_free=9.8, wall=44636
2022-03-12 22:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 22:47:46 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 5.443 | ppl 43.5 | wps 53921.9 | wpb 511.9 | bsz 1 | num_updates 19404 | best_loss 5.443
2022-03-12 22:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 19404 updates
2022-03-12 22:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 22:47:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 48 @ 19404 updates, score 5.443) (writing took 2.1411982440040447 seconds)
2022-03-12 22:47:48 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-12 22:47:48 | INFO | train | epoch 048 | loss 5.322 | ppl 40.01 | wps 29515.3 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 19404 | lr 0.000227015 | gnorm 0.543 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 44671
2022-03-12 22:47:48 | INFO | fairseq.trainer | begin training epoch 49
2022-03-12 22:47:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 22:48:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-12 22:51:16 | INFO | train_inner | epoch 049:     97 / 407 loss=5.292, ppl=39.17, wps=26967.2, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=19500, lr=0.000226455, gnorm=0.546, loss_scale=8, train_wall=191, gb_free=9.8, wall=44879
2022-03-12 22:54:49 | INFO | train_inner | epoch 049:    197 / 407 loss=5.32, ppl=39.95, wps=30779.8, ups=0.47, wpb=65534.2, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.545, loss_scale=16, train_wall=189, gb_free=9.8, wall=45092
2022-03-12 22:58:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 22:58:25 | INFO | train_inner | epoch 049:    298 / 407 loss=5.321, ppl=39.96, wps=30362.8, ups=0.46, wpb=65536, bsz=128, num_updates=19700, lr=0.000225303, gnorm=0.546, loss_scale=16, train_wall=192, gb_free=9.8, wall=45308
2022-03-12 23:01:58 | INFO | train_inner | epoch 049:    398 / 407 loss=5.324, ppl=40.04, wps=30711.9, ups=0.47, wpb=65536, bsz=128, num_updates=19800, lr=0.000224733, gnorm=0.545, loss_scale=16, train_wall=190, gb_free=9.8, wall=45521
2022-03-12 23:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 23:02:41 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 5.441 | ppl 43.45 | wps 54012.1 | wpb 511.9 | bsz 1 | num_updates 19809 | best_loss 5.441
2022-03-12 23:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 19809 updates
2022-03-12 23:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:02:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 49 @ 19809 updates, score 5.441) (writing took 2.173830532003194 seconds)
2022-03-12 23:02:44 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-12 23:02:44 | INFO | train | epoch 049 | loss 5.314 | ppl 39.79 | wps 29629.4 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 19809 | lr 0.000224682 | gnorm 0.546 | loss_scale 16 | train_wall 771 | gb_free 9.8 | wall 45567
2022-03-12 23:02:44 | INFO | fairseq.trainer | begin training epoch 50
2022-03-12 23:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 23:03:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:06:00 | INFO | train_inner | epoch 050:     92 / 407 loss=5.286, ppl=39.02, wps=26998.8, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=19900, lr=0.000224168, gnorm=0.548, loss_scale=16, train_wall=191, gb_free=9.8, wall=45763
2022-03-12 23:07:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:09:36 | INFO | train_inner | epoch 050:    193 / 407 loss=5.305, ppl=39.53, wps=30401.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.548, loss_scale=16, train_wall=191, gb_free=9.8, wall=45979
2022-03-12 23:13:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:13:10 | INFO | train_inner | epoch 050:    294 / 407 loss=5.307, ppl=39.59, wps=30513.3, ups=0.47, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.546, loss_scale=16, train_wall=191, gb_free=9.8, wall=46193
2022-03-12 23:16:43 | INFO | train_inner | epoch 050:    394 / 407 loss=5.324, ppl=40.06, wps=30847.7, ups=0.47, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.544, loss_scale=16, train_wall=189, gb_free=9.8, wall=46406
2022-03-12 23:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 23:17:35 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 5.44 | ppl 43.41 | wps 53954.2 | wpb 511.9 | bsz 1 | num_updates 20213 | best_loss 5.44
2022-03-12 23:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 20213 updates
2022-03-12 23:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 50 @ 20213 updates, score 5.44) (writing took 2.1841013549710624 seconds)
2022-03-12 23:17:37 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-12 23:17:37 | INFO | train | epoch 050 | loss 5.306 | ppl 39.57 | wps 29617.2 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 20213 | lr 0.000222426 | gnorm 0.546 | loss_scale 16 | train_wall 769 | gb_free 9.8 | wall 46460
2022-03-12 23:17:37 | INFO | fairseq.trainer | begin training epoch 51
2022-03-12 23:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 23:18:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:20:44 | INFO | train_inner | epoch 051:     88 / 407 loss=5.278, ppl=38.81, wps=27088.7, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=20300, lr=0.000221948, gnorm=0.549, loss_scale=16, train_wall=190, gb_free=9.8, wall=46647
2022-03-12 23:24:17 | INFO | train_inner | epoch 051:    188 / 407 loss=5.293, ppl=39.21, wps=30737.5, ups=0.47, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.546, loss_scale=32, train_wall=189, gb_free=9.8, wall=46860
2022-03-12 23:24:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:27:53 | INFO | train_inner | epoch 051:    289 / 407 loss=5.305, ppl=39.54, wps=30350.8, ups=0.46, wpb=65536, bsz=128, num_updates=20500, lr=0.000220863, gnorm=0.553, loss_scale=16, train_wall=192, gb_free=9.8, wall=47076
2022-03-12 23:29:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:31:28 | INFO | train_inner | epoch 051:    390 / 407 loss=5.321, ppl=39.97, wps=30489.2, ups=0.47, wpb=65534.2, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.547, loss_scale=16, train_wall=191, gb_free=9.8, wall=47291
2022-03-12 23:32:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 23:32:29 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 5.432 | ppl 43.17 | wps 53718.9 | wpb 511.9 | bsz 1 | num_updates 20617 | best_loss 5.432
2022-03-12 23:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 20617 updates
2022-03-12 23:32:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:32:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:32:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 51 @ 20617 updates, score 5.432) (writing took 2.1837604150059633 seconds)
2022-03-12 23:32:31 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-12 23:32:31 | INFO | train | epoch 051 | loss 5.298 | ppl 39.35 | wps 29590.5 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 20617 | lr 0.000220235 | gnorm 0.548 | loss_scale 16 | train_wall 770 | gb_free 9.8 | wall 47354
2022-03-12 23:32:31 | INFO | fairseq.trainer | begin training epoch 52
2022-03-12 23:32:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 23:34:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:35:30 | INFO | train_inner | epoch 052:     84 / 407 loss=5.274, ppl=38.7, wps=27008.1, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=20700, lr=0.000219793, gnorm=0.546, loss_scale=16, train_wall=191, gb_free=9.8, wall=47533
2022-03-12 23:39:04 | INFO | train_inner | epoch 052:    184 / 407 loss=5.29, ppl=39.13, wps=30603.8, ups=0.47, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.553, loss_scale=32, train_wall=190, gb_free=9.8, wall=47747
2022-03-12 23:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:42:40 | INFO | train_inner | epoch 052:    285 / 407 loss=5.296, ppl=39.29, wps=30362.2, ups=0.46, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.548, loss_scale=16, train_wall=192, gb_free=9.8, wall=47963
2022-03-12 23:44:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:46:16 | INFO | train_inner | epoch 052:    386 / 407 loss=5.299, ppl=39.37, wps=30402.4, ups=0.46, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.555, loss_scale=16, train_wall=191, gb_free=9.8, wall=48179
2022-03-12 23:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-12 23:47:25 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 5.424 | ppl 42.94 | wps 53732.2 | wpb 511.9 | bsz 1 | num_updates 21021 | best_loss 5.424
2022-03-12 23:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 21021 updates
2022-03-12 23:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-12 23:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 52 @ 21021 updates, score 5.424) (writing took 2.1638388280407526 seconds)
2022-03-12 23:47:27 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-12 23:47:27 | INFO | train | epoch 052 | loss 5.29 | ppl 39.12 | wps 29531.3 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 21021 | lr 0.000218109 | gnorm 0.551 | loss_scale 16 | train_wall 771 | gb_free 9.8 | wall 48250
2022-03-12 23:47:27 | INFO | fairseq.trainer | begin training epoch 53
2022-03-12 23:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-12 23:50:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:50:18 | INFO | train_inner | epoch 053:     80 / 407 loss=5.263, ppl=38.39, wps=26978, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=21100, lr=0.0002177, gnorm=0.555, loss_scale=16, train_wall=191, gb_free=9.8, wall=48421
2022-03-12 23:53:52 | INFO | train_inner | epoch 053:    180 / 407 loss=5.27, ppl=38.58, wps=30693.1, ups=0.47, wpb=65536, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.552, loss_scale=16, train_wall=190, gb_free=9.8, wall=48635
2022-03-12 23:55:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-12 23:57:28 | INFO | train_inner | epoch 053:    281 / 407 loss=5.304, ppl=39.52, wps=30320.4, ups=0.46, wpb=65534.2, bsz=128, num_updates=21300, lr=0.000216676, gnorm=0.549, loss_scale=16, train_wall=192, gb_free=9.8, wall=48851
2022-03-12 23:59:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:01:03 | INFO | train_inner | epoch 053:    382 / 407 loss=5.302, ppl=39.44, wps=30427.8, ups=0.46, wpb=65536, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.554, loss_scale=16, train_wall=191, gb_free=9.8, wall=49066
2022-03-13 00:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 00:02:21 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 5.429 | ppl 43.09 | wps 53555.6 | wpb 511.9 | bsz 1 | num_updates 21425 | best_loss 5.424
2022-03-13 00:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 21425 updates
2022-03-13 00:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 00:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 00:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 53 @ 21425 updates, score 5.429) (writing took 1.230918244982604 seconds)
2022-03-13 00:02:22 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-13 00:02:22 | INFO | train | epoch 053 | loss 5.283 | ppl 38.94 | wps 29554.5 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 21425 | lr 0.000216043 | gnorm 0.552 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 49145
2022-03-13 00:02:22 | INFO | fairseq.trainer | begin training epoch 54
2022-03-13 00:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 00:05:03 | INFO | train_inner | epoch 054:     75 / 407 loss=5.244, ppl=37.9, wps=27239.8, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=21500, lr=0.000215666, gnorm=0.549, loss_scale=32, train_wall=190, gb_free=9.8, wall=49306
2022-03-13 00:07:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:08:40 | INFO | train_inner | epoch 054:    176 / 407 loss=5.273, ppl=38.68, wps=30243.4, ups=0.46, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.554, loss_scale=16, train_wall=193, gb_free=9.8, wall=49523
2022-03-13 00:11:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:12:16 | INFO | train_inner | epoch 054:    277 / 407 loss=5.284, ppl=38.97, wps=30251.3, ups=0.46, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.54, loss_scale=16, train_wall=192, gb_free=9.8, wall=49739
2022-03-13 00:15:50 | INFO | train_inner | epoch 054:    377 / 407 loss=5.297, ppl=39.32, wps=30641, ups=0.47, wpb=65536, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.55, loss_scale=16, train_wall=190, gb_free=9.8, wall=49953
2022-03-13 00:16:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 00:17:19 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 5.421 | ppl 42.84 | wps 53456.6 | wpb 511.9 | bsz 1 | num_updates 21829 | best_loss 5.421
2022-03-13 00:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 21829 updates
2022-03-13 00:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:17:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 54 @ 21829 updates, score 5.421) (writing took 2.1563119270140305 seconds)
2022-03-13 00:17:21 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-13 00:17:21 | INFO | train | epoch 054 | loss 5.276 | ppl 38.76 | wps 29435.5 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 21829 | lr 0.000214034 | gnorm 0.549 | loss_scale 16 | train_wall 774 | gb_free 9.8 | wall 50044
2022-03-13 00:17:21 | INFO | fairseq.trainer | begin training epoch 55
2022-03-13 00:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 00:19:53 | INFO | train_inner | epoch 055:     71 / 407 loss=5.267, ppl=38.51, wps=26889.7, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=21900, lr=0.000213687, gnorm=0.559, loss_scale=16, train_wall=192, gb_free=9.8, wall=50196
2022-03-13 00:21:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:23:30 | INFO | train_inner | epoch 055:    172 / 407 loss=5.264, ppl=38.42, wps=30268.9, ups=0.46, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.556, loss_scale=16, train_wall=192, gb_free=9.8, wall=50413
2022-03-13 00:27:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:27:06 | INFO | train_inner | epoch 055:    273 / 407 loss=5.262, ppl=38.37, wps=30288.3, ups=0.46, wpb=65536, bsz=128, num_updates=22100, lr=0.000212718, gnorm=0.549, loss_scale=16, train_wall=192, gb_free=9.8, wall=50629
2022-03-13 00:30:39 | INFO | train_inner | epoch 055:    373 / 407 loss=5.282, ppl=38.9, wps=30756.2, ups=0.47, wpb=65534.2, bsz=128, num_updates=22200, lr=0.000212238, gnorm=0.547, loss_scale=16, train_wall=189, gb_free=9.8, wall=50842
2022-03-13 00:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 00:32:16 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 5.419 | ppl 42.79 | wps 53710.2 | wpb 511.9 | bsz 1 | num_updates 22234 | best_loss 5.419
2022-03-13 00:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 22234 updates
2022-03-13 00:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 55 @ 22234 updates, score 5.419) (writing took 2.1704863340128213 seconds)
2022-03-13 00:32:18 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-13 00:32:18 | INFO | train | epoch 055 | loss 5.269 | ppl 38.57 | wps 29565.3 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 22234 | lr 0.000212076 | gnorm 0.553 | loss_scale 32 | train_wall 773 | gb_free 9.8 | wall 50941
2022-03-13 00:32:18 | INFO | fairseq.trainer | begin training epoch 56
2022-03-13 00:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 00:32:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:34:42 | INFO | train_inner | epoch 056:     67 / 407 loss=5.256, ppl=38.21, wps=26917.8, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=22300, lr=0.000211762, gnorm=0.556, loss_scale=16, train_wall=192, gb_free=9.8, wall=51085
2022-03-13 00:37:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:38:18 | INFO | train_inner | epoch 056:    168 / 407 loss=5.249, ppl=38.03, wps=30355, ups=0.46, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.556, loss_scale=16, train_wall=192, gb_free=9.8, wall=51301
2022-03-13 00:40:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 00:41:54 | INFO | train_inner | epoch 056:    269 / 407 loss=5.271, ppl=38.6, wps=30395.6, ups=0.46, wpb=65536, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.552, loss_scale=8, train_wall=191, gb_free=9.8, wall=51517
2022-03-13 00:45:27 | INFO | train_inner | epoch 056:    369 / 407 loss=5.279, ppl=38.83, wps=30674.6, ups=0.47, wpb=65534.2, bsz=128, num_updates=22600, lr=0.000210352, gnorm=0.561, loss_scale=16, train_wall=190, gb_free=9.8, wall=51730
2022-03-13 00:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 00:47:13 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 5.41 | ppl 42.5 | wps 53569.9 | wpb 511.9 | bsz 1 | num_updates 22638 | best_loss 5.41
2022-03-13 00:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 22638 updates
2022-03-13 00:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 00:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 56 @ 22638 updates, score 5.41) (writing took 2.2264440809958614 seconds)
2022-03-13 00:47:15 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-13 00:47:15 | INFO | train | epoch 056 | loss 5.262 | ppl 38.38 | wps 29508.4 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 22638 | lr 0.000210175 | gnorm 0.556 | loss_scale 16 | train_wall 772 | gb_free 9.8 | wall 51838
2022-03-13 00:47:15 | INFO | fairseq.trainer | begin training epoch 57
2022-03-13 00:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 00:49:28 | INFO | train_inner | epoch 057:     62 / 407 loss=5.247, ppl=37.97, wps=27191.1, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=22700, lr=0.000209888, gnorm=0.557, loss_scale=16, train_wall=189, gb_free=9.8, wall=51971
2022-03-13 00:50:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:53:04 | INFO | train_inner | epoch 057:    163 / 407 loss=5.248, ppl=38, wps=30273.2, ups=0.46, wpb=65536, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.555, loss_scale=16, train_wall=192, gb_free=9.8, wall=52187
2022-03-13 00:55:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 00:56:40 | INFO | train_inner | epoch 057:    264 / 407 loss=5.256, ppl=38.22, wps=30307.9, ups=0.46, wpb=65534.2, bsz=128, num_updates=22900, lr=0.000208969, gnorm=0.552, loss_scale=16, train_wall=192, gb_free=9.8, wall=52403
2022-03-13 01:00:14 | INFO | train_inner | epoch 057:    364 / 407 loss=5.276, ppl=38.76, wps=30606.4, ups=0.47, wpb=65536, bsz=128, num_updates=23000, lr=0.000208514, gnorm=0.564, loss_scale=32, train_wall=190, gb_free=9.8, wall=52617
2022-03-13 01:00:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:01:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 01:02:11 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 5.408 | ppl 42.47 | wps 53416.1 | wpb 511.9 | bsz 1 | num_updates 23042 | best_loss 5.408
2022-03-13 01:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 23042 updates
2022-03-13 01:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 57 @ 23042 updates, score 5.408) (writing took 2.1886280549806543 seconds)
2022-03-13 01:02:13 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-13 01:02:13 | INFO | train | epoch 057 | loss 5.257 | ppl 38.23 | wps 29455.5 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 23042 | lr 0.000208324 | gnorm 0.558 | loss_scale 16 | train_wall 773 | gb_free 9.8 | wall 52736
2022-03-13 01:02:13 | INFO | fairseq.trainer | begin training epoch 58
2022-03-13 01:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 01:04:17 | INFO | train_inner | epoch 058:     58 / 407 loss=5.247, ppl=37.97, wps=26895, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=23100, lr=0.000208063, gnorm=0.557, loss_scale=16, train_wall=192, gb_free=9.8, wall=52860
2022-03-13 01:06:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:07:53 | INFO | train_inner | epoch 058:    159 / 407 loss=5.237, ppl=37.72, wps=30342.8, ups=0.46, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.559, loss_scale=16, train_wall=192, gb_free=9.8, wall=53076
2022-03-13 01:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:11:30 | INFO | train_inner | epoch 058:    260 / 407 loss=5.249, ppl=38.03, wps=30292.5, ups=0.46, wpb=65534.2, bsz=128, num_updates=23300, lr=0.000207168, gnorm=0.554, loss_scale=16, train_wall=192, gb_free=9.8, wall=53293
2022-03-13 01:15:03 | INFO | train_inner | epoch 058:    360 / 407 loss=5.263, ppl=38.39, wps=30710.2, ups=0.47, wpb=65536, bsz=128, num_updates=23400, lr=0.000206725, gnorm=0.556, loss_scale=16, train_wall=190, gb_free=9.8, wall=53506
2022-03-13 01:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 01:17:08 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 5.416 | ppl 42.69 | wps 53605.6 | wpb 511.9 | bsz 1 | num_updates 23447 | best_loss 5.408
2022-03-13 01:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 23447 updates
2022-03-13 01:17:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 01:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 01:17:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 58 @ 23447 updates, score 5.416) (writing took 1.266381952969823 seconds)
2022-03-13 01:17:09 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-13 01:17:09 | INFO | train | epoch 058 | loss 5.25 | ppl 38.04 | wps 29599.4 | ups 0.45 | wpb 65492.6 | bsz 127.9 | num_updates 23447 | lr 0.000206517 | gnorm 0.555 | loss_scale 32 | train_wall 773 | gb_free 9.8 | wall 53632
2022-03-13 01:17:09 | INFO | fairseq.trainer | begin training epoch 59
2022-03-13 01:17:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 01:17:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:19:05 | INFO | train_inner | epoch 059:     54 / 407 loss=5.244, ppl=37.9, wps=27001.1, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=23500, lr=0.000206284, gnorm=0.552, loss_scale=16, train_wall=192, gb_free=9.8, wall=53748
2022-03-13 01:22:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:22:41 | INFO | train_inner | epoch 059:    155 / 407 loss=5.224, ppl=37.38, wps=30449.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=23600, lr=0.000205847, gnorm=0.558, loss_scale=16, train_wall=191, gb_free=9.8, wall=53964
2022-03-13 01:26:12 | INFO | train_inner | epoch 059:    255 / 407 loss=5.248, ppl=38, wps=30995.1, ups=0.47, wpb=65536, bsz=128, num_updates=23700, lr=0.000205412, gnorm=0.556, loss_scale=16, train_wall=188, gb_free=9.8, wall=54175
2022-03-13 01:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:29:45 | INFO | train_inner | epoch 059:    356 / 407 loss=5.256, ppl=38.21, wps=30734.4, ups=0.47, wpb=65536, bsz=128, num_updates=23800, lr=0.00020498, gnorm=0.551, loss_scale=16, train_wall=189, gb_free=9.8, wall=54388
2022-03-13 01:31:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 01:31:57 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 5.399 | ppl 42.18 | wps 53945.9 | wpb 511.9 | bsz 1 | num_updates 23850 | best_loss 5.399
2022-03-13 01:31:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 23850 updates
2022-03-13 01:31:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:31:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 59 @ 23850 updates, score 5.399) (writing took 2.2353260520030744 seconds)
2022-03-13 01:32:00 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-13 01:32:00 | INFO | train | epoch 059 | loss 5.243 | ppl 37.86 | wps 29643.4 | ups 0.45 | wpb 65492.3 | bsz 127.9 | num_updates 23850 | lr 0.000204765 | gnorm 0.554 | loss_scale 16 | train_wall 766 | gb_free 9.8 | wall 54523
2022-03-13 01:32:00 | INFO | fairseq.trainer | begin training epoch 60
2022-03-13 01:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 01:33:46 | INFO | train_inner | epoch 060:     50 / 407 loss=5.237, ppl=37.7, wps=27166.5, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=23900, lr=0.000204551, gnorm=0.552, loss_scale=16, train_wall=189, gb_free=9.8, wall=54629
2022-03-13 01:36:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:37:20 | INFO | train_inner | epoch 060:    151 / 407 loss=5.222, ppl=37.31, wps=30595.7, ups=0.47, wpb=65536, bsz=128, num_updates=24000, lr=0.000204124, gnorm=0.555, loss_scale=16, train_wall=190, gb_free=9.8, wall=54843
2022-03-13 01:40:52 | INFO | train_inner | epoch 060:    251 / 407 loss=5.236, ppl=37.67, wps=30967.4, ups=0.47, wpb=65536, bsz=128, num_updates=24100, lr=0.0002037, gnorm=0.553, loss_scale=16, train_wall=188, gb_free=9.8, wall=55055
2022-03-13 01:41:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:44:25 | INFO | train_inner | epoch 060:    352 / 407 loss=5.261, ppl=38.35, wps=30729, ups=0.47, wpb=65536, bsz=128, num_updates=24200, lr=0.000203279, gnorm=0.557, loss_scale=16, train_wall=189, gb_free=9.8, wall=55268
2022-03-13 01:45:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 01:46:46 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 5.399 | ppl 42.18 | wps 53926.6 | wpb 511.9 | bsz 1 | num_updates 24254 | best_loss 5.399
2022-03-13 01:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 24254 updates
2022-03-13 01:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:46:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 01:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 60 @ 24254 updates, score 5.399) (writing took 2.2638294649659656 seconds)
2022-03-13 01:46:48 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-13 01:46:48 | INFO | train | epoch 060 | loss 5.238 | ppl 37.73 | wps 29792.6 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 24254 | lr 0.000203052 | gnorm 0.554 | loss_scale 16 | train_wall 764 | gb_free 9.8 | wall 55411
2022-03-13 01:46:48 | INFO | fairseq.trainer | begin training epoch 61
2022-03-13 01:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 01:48:25 | INFO | train_inner | epoch 061:     46 / 407 loss=5.234, ppl=37.63, wps=27198.4, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=24300, lr=0.00020286, gnorm=0.552, loss_scale=16, train_wall=189, gb_free=9.8, wall=55508
2022-03-13 01:51:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:51:59 | INFO | train_inner | epoch 061:    147 / 407 loss=5.221, ppl=37.31, wps=30650.7, ups=0.47, wpb=65536, bsz=128, num_updates=24400, lr=0.000202444, gnorm=0.562, loss_scale=16, train_wall=190, gb_free=9.8, wall=55722
2022-03-13 01:55:31 | INFO | train_inner | epoch 061:    247 / 407 loss=5.225, ppl=37.39, wps=30916.8, ups=0.47, wpb=65534.2, bsz=128, num_updates=24500, lr=0.000202031, gnorm=0.561, loss_scale=16, train_wall=188, gb_free=9.8, wall=55934
2022-03-13 01:55:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 01:59:05 | INFO | train_inner | epoch 061:    348 / 407 loss=5.252, ppl=38.11, wps=30648.3, ups=0.47, wpb=65536, bsz=128, num_updates=24600, lr=0.000201619, gnorm=0.559, loss_scale=16, train_wall=190, gb_free=9.8, wall=56148
2022-03-13 02:00:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 02:01:34 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 5.402 | ppl 42.29 | wps 53928.4 | wpb 511.9 | bsz 1 | num_updates 24658 | best_loss 5.399
2022-03-13 02:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 24658 updates
2022-03-13 02:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 02:01:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 02:01:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 61 @ 24658 updates, score 5.402) (writing took 1.2544884060043842 seconds)
2022-03-13 02:01:36 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-13 02:01:36 | INFO | train | epoch 061 | loss 5.232 | ppl 37.59 | wps 29802.3 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 24658 | lr 0.000201382 | gnorm 0.559 | loss_scale 16 | train_wall 764 | gb_free 9.8 | wall 56299
2022-03-13 02:01:36 | INFO | fairseq.trainer | begin training epoch 62
2022-03-13 02:01:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 02:03:05 | INFO | train_inner | epoch 062:     42 / 407 loss=5.232, ppl=37.58, wps=27238.3, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=24700, lr=0.000201211, gnorm=0.555, loss_scale=16, train_wall=190, gb_free=9.8, wall=56388
2022-03-13 02:06:37 | INFO | train_inner | epoch 062:    142 / 407 loss=5.212, ppl=37.08, wps=30923.1, ups=0.47, wpb=65534.2, bsz=128, num_updates=24800, lr=0.000200805, gnorm=0.558, loss_scale=32, train_wall=188, gb_free=9.8, wall=56600
2022-03-13 02:06:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:10:11 | INFO | train_inner | epoch 062:    243 / 407 loss=5.227, ppl=37.45, wps=30637.2, ups=0.47, wpb=65536, bsz=128, num_updates=24900, lr=0.000200401, gnorm=0.561, loss_scale=16, train_wall=190, gb_free=9.8, wall=56814
2022-03-13 02:11:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:13:44 | INFO | train_inner | epoch 062:    344 / 407 loss=5.241, ppl=37.81, wps=30667.8, ups=0.47, wpb=65536, bsz=128, num_updates=25000, lr=0.0002, gnorm=0.555, loss_scale=16, train_wall=190, gb_free=9.8, wall=57027
2022-03-13 02:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 02:16:22 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 5.398 | ppl 42.16 | wps 53781.7 | wpb 511.9 | bsz 1 | num_updates 25063 | best_loss 5.398
2022-03-13 02:16:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 25063 updates
2022-03-13 02:16:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 62 @ 25063 updates, score 5.398) (writing took 2.192465108993929 seconds)
2022-03-13 02:16:24 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-13 02:16:24 | INFO | train | epoch 062 | loss 5.226 | ppl 37.44 | wps 29842.2 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 25063 | lr 0.000199748 | gnorm 0.56 | loss_scale 32 | train_wall 765 | gb_free 9.8 | wall 57187
2022-03-13 02:16:25 | INFO | fairseq.trainer | begin training epoch 63
2022-03-13 02:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 02:16:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:17:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 02:17:47 | INFO | train_inner | epoch 063:     39 / 407 loss=5.221, ppl=37.29, wps=26887.5, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=25100, lr=0.000199601, gnorm=0.564, loss_scale=8, train_wall=192, gb_free=9.8, wall=57270
2022-03-13 02:21:19 | INFO | train_inner | epoch 063:    139 / 407 loss=5.21, ppl=37.02, wps=30920.6, ups=0.47, wpb=65536, bsz=128, num_updates=25200, lr=0.000199205, gnorm=0.562, loss_scale=8, train_wall=188, gb_free=9.8, wall=57482
2022-03-13 02:24:51 | INFO | train_inner | epoch 063:    239 / 407 loss=5.22, ppl=37.26, wps=30964.1, ups=0.47, wpb=65534.2, bsz=128, num_updates=25300, lr=0.000198811, gnorm=0.57, loss_scale=16, train_wall=188, gb_free=9.8, wall=57694
2022-03-13 02:26:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:28:24 | INFO | train_inner | epoch 063:    340 / 407 loss=5.232, ppl=37.59, wps=30753.9, ups=0.47, wpb=65536, bsz=128, num_updates=25400, lr=0.000198419, gnorm=0.563, loss_scale=16, train_wall=189, gb_free=9.8, wall=57907
2022-03-13 02:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 02:31:10 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 5.396 | ppl 42.11 | wps 54085.1 | wpb 511.9 | bsz 1 | num_updates 25467 | best_loss 5.396
2022-03-13 02:31:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 25467 updates
2022-03-13 02:31:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 63 @ 25467 updates, score 5.396) (writing took 2.219009049993474 seconds)
2022-03-13 02:31:13 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-13 02:31:13 | INFO | train | epoch 063 | loss 5.221 | ppl 37.29 | wps 29788.8 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 25467 | lr 0.000198158 | gnorm 0.563 | loss_scale 16 | train_wall 764 | gb_free 9.8 | wall 58076
2022-03-13 02:31:13 | INFO | fairseq.trainer | begin training epoch 64
2022-03-13 02:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 02:32:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:32:25 | INFO | train_inner | epoch 064:     34 / 407 loss=5.221, ppl=37.29, wps=27166.8, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=25500, lr=0.00019803, gnorm=0.56, loss_scale=16, train_wall=189, gb_free=9.8, wall=58148
2022-03-13 02:35:57 | INFO | train_inner | epoch 064:    134 / 407 loss=5.202, ppl=36.82, wps=30894.8, ups=0.47, wpb=65536, bsz=128, num_updates=25600, lr=0.000197642, gnorm=0.568, loss_scale=16, train_wall=188, gb_free=9.8, wall=58360
2022-03-13 02:37:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:39:31 | INFO | train_inner | epoch 064:    235 / 407 loss=5.216, ppl=37.17, wps=30598.8, ups=0.47, wpb=65536, bsz=128, num_updates=25700, lr=0.000197257, gnorm=0.567, loss_scale=16, train_wall=190, gb_free=9.8, wall=58574
2022-03-13 02:42:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:43:05 | INFO | train_inner | epoch 064:    336 / 407 loss=5.222, ppl=37.31, wps=30688.5, ups=0.47, wpb=65536, bsz=128, num_updates=25800, lr=0.000196875, gnorm=0.567, loss_scale=16, train_wall=189, gb_free=9.8, wall=58788
2022-03-13 02:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 02:45:59 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 5.392 | ppl 41.99 | wps 54126 | wpb 511.9 | bsz 1 | num_updates 25871 | best_loss 5.392
2022-03-13 02:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 25871 updates
2022-03-13 02:45:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 02:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 64 @ 25871 updates, score 5.392) (writing took 2.226927039970178 seconds)
2022-03-13 02:46:01 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-13 02:46:01 | INFO | train | epoch 064 | loss 5.215 | ppl 37.15 | wps 29790.1 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 25871 | lr 0.000196604 | gnorm 0.566 | loss_scale 16 | train_wall 764 | gb_free 9.8 | wall 58964
2022-03-13 02:46:01 | INFO | fairseq.trainer | begin training epoch 65
2022-03-13 02:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 02:47:02 | INFO | train_inner | epoch 065:     29 / 407 loss=5.226, ppl=37.42, wps=27498.4, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=25900, lr=0.000196494, gnorm=0.559, loss_scale=16, train_wall=187, gb_free=9.8, wall=59025
2022-03-13 02:47:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:50:36 | INFO | train_inner | epoch 065:    130 / 407 loss=5.198, ppl=36.7, wps=30695.2, ups=0.47, wpb=65536, bsz=128, num_updates=26000, lr=0.000196116, gnorm=0.564, loss_scale=16, train_wall=189, gb_free=9.8, wall=59239
2022-03-13 02:52:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:54:09 | INFO | train_inner | epoch 065:    231 / 407 loss=5.213, ppl=37.09, wps=30686.8, ups=0.47, wpb=65536, bsz=128, num_updates=26100, lr=0.00019574, gnorm=0.563, loss_scale=16, train_wall=189, gb_free=9.8, wall=59452
2022-03-13 02:56:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 02:57:43 | INFO | train_inner | epoch 065:    332 / 407 loss=5.221, ppl=37.3, wps=30619.1, ups=0.47, wpb=65534.2, bsz=128, num_updates=26200, lr=0.000195366, gnorm=0.561, loss_scale=16, train_wall=190, gb_free=9.8, wall=59666
2022-03-13 03:00:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 03:00:47 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 5.39 | ppl 41.93 | wps 54049 | wpb 511.9 | bsz 1 | num_updates 26275 | best_loss 5.39
2022-03-13 03:00:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 26275 updates
2022-03-13 03:00:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 65 @ 26275 updates, score 5.39) (writing took 2.221231311035808 seconds)
2022-03-13 03:00:49 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-13 03:00:49 | INFO | train | epoch 065 | loss 5.21 | ppl 37.02 | wps 29797.6 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 26275 | lr 0.000195087 | gnorm 0.562 | loss_scale 16 | train_wall 764 | gb_free 9.8 | wall 59852
2022-03-13 03:00:49 | INFO | fairseq.trainer | begin training epoch 66
2022-03-13 03:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 03:01:42 | INFO | train_inner | epoch 066:     25 / 407 loss=5.209, ppl=36.98, wps=27421.1, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=26300, lr=0.000194994, gnorm=0.566, loss_scale=16, train_wall=187, gb_free=9.8, wall=59905
2022-03-13 03:02:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:05:15 | INFO | train_inner | epoch 066:    126 / 407 loss=5.187, ppl=36.42, wps=30756.3, ups=0.47, wpb=65536, bsz=128, num_updates=26400, lr=0.000194625, gnorm=0.561, loss_scale=16, train_wall=189, gb_free=9.8, wall=60118
2022-03-13 03:06:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:08:48 | INFO | train_inner | epoch 066:    227 / 407 loss=5.207, ppl=36.93, wps=30749, ups=0.47, wpb=65536, bsz=128, num_updates=26500, lr=0.000194257, gnorm=0.576, loss_scale=16, train_wall=189, gb_free=9.8, wall=60331
2022-03-13 03:10:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 03:12:20 | INFO | train_inner | epoch 066:    328 / 407 loss=5.213, ppl=37.09, wps=30871, ups=0.47, wpb=65536, bsz=128, num_updates=26600, lr=0.000193892, gnorm=0.566, loss_scale=8, train_wall=188, gb_free=9.8, wall=60543
2022-03-13 03:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 03:15:29 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 5.39 | ppl 41.92 | wps 54852.2 | wpb 511.9 | bsz 1 | num_updates 26679 | best_loss 5.39
2022-03-13 03:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 26679 updates
2022-03-13 03:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 66 @ 26679 updates, score 5.39) (writing took 2.2958838369813748 seconds)
2022-03-13 03:15:31 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-13 03:15:31 | INFO | train | epoch 066 | loss 5.206 | ppl 36.9 | wps 29976.1 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 26679 | lr 0.000193604 | gnorm 0.568 | loss_scale 16 | train_wall 759 | gb_free 9.8 | wall 60734
2022-03-13 03:15:32 | INFO | fairseq.trainer | begin training epoch 67
2022-03-13 03:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 03:16:16 | INFO | train_inner | epoch 067:     21 / 407 loss=5.215, ppl=37.15, wps=27738.2, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=26700, lr=0.000193528, gnorm=0.569, loss_scale=16, train_wall=185, gb_free=9.8, wall=60779
2022-03-13 03:19:46 | INFO | train_inner | epoch 067:    121 / 407 loss=5.176, ppl=36.15, wps=31209.6, ups=0.48, wpb=65536, bsz=128, num_updates=26800, lr=0.000193167, gnorm=0.563, loss_scale=32, train_wall=186, gb_free=9.8, wall=60989
2022-03-13 03:20:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:22:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 03:23:20 | INFO | train_inner | epoch 067:    223 / 407 loss=5.201, ppl=36.79, wps=30652.8, ups=0.47, wpb=65534.2, bsz=128, num_updates=26900, lr=0.000192807, gnorm=0.568, loss_scale=8, train_wall=189, gb_free=9.8, wall=61203
2022-03-13 03:26:49 | INFO | train_inner | epoch 067:    323 / 407 loss=5.211, ppl=37.04, wps=31281.4, ups=0.48, wpb=65536, bsz=128, num_updates=27000, lr=0.00019245, gnorm=0.571, loss_scale=8, train_wall=186, gb_free=9.8, wall=61412
2022-03-13 03:29:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 03:30:10 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 5.39 | ppl 41.93 | wps 54251.1 | wpb 511.9 | bsz 1 | num_updates 27084 | best_loss 5.39
2022-03-13 03:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 27084 updates
2022-03-13 03:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 67 @ 27084 updates, score 5.39) (writing took 2.213509568013251 seconds)
2022-03-13 03:30:12 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-13 03:30:12 | INFO | train | epoch 067 | loss 5.201 | ppl 36.78 | wps 30125.5 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 27084 | lr 0.000192151 | gnorm 0.567 | loss_scale 16 | train_wall 757 | gb_free 9.8 | wall 61615
2022-03-13 03:30:12 | INFO | fairseq.trainer | begin training epoch 68
2022-03-13 03:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 03:30:46 | INFO | train_inner | epoch 068:     16 / 407 loss=5.215, ppl=37.15, wps=27636, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=27100, lr=0.000192095, gnorm=0.564, loss_scale=16, train_wall=186, gb_free=9.8, wall=61649
2022-03-13 03:32:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:34:19 | INFO | train_inner | epoch 068:    117 / 407 loss=5.174, ppl=36.1, wps=30724.3, ups=0.47, wpb=65534.2, bsz=128, num_updates=27200, lr=0.000191741, gnorm=0.57, loss_scale=16, train_wall=189, gb_free=9.8, wall=61862
2022-03-13 03:37:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:37:52 | INFO | train_inner | epoch 068:    218 / 407 loss=5.191, ppl=36.53, wps=30774.8, ups=0.47, wpb=65536, bsz=128, num_updates=27300, lr=0.00019139, gnorm=0.566, loss_scale=16, train_wall=189, gb_free=9.8, wall=62075
2022-03-13 03:41:24 | INFO | train_inner | epoch 068:    318 / 407 loss=5.206, ppl=36.92, wps=30912.5, ups=0.47, wpb=65536, bsz=128, num_updates=27400, lr=0.00019104, gnorm=0.559, loss_scale=16, train_wall=188, gb_free=9.8, wall=62287
2022-03-13 03:41:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:41:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 03:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 03:44:57 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 5.382 | ppl 41.69 | wps 54126.8 | wpb 511.9 | bsz 1 | num_updates 27487 | best_loss 5.382
2022-03-13 03:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 27487 updates
2022-03-13 03:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 68 @ 27487 updates, score 5.382) (writing took 2.245981542975642 seconds)
2022-03-13 03:44:59 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-13 03:44:59 | INFO | train | epoch 068 | loss 5.196 | ppl 36.65 | wps 29754.7 | ups 0.45 | wpb 65492.3 | bsz 127.9 | num_updates 27487 | lr 0.000190738 | gnorm 0.567 | loss_scale 8 | train_wall 763 | gb_free 9.8 | wall 62502
2022-03-13 03:44:59 | INFO | fairseq.trainer | begin training epoch 69
2022-03-13 03:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 03:45:27 | INFO | train_inner | epoch 069:     13 / 407 loss=5.21, ppl=37.01, wps=26924.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=27500, lr=0.000190693, gnorm=0.574, loss_scale=8, train_wall=191, gb_free=9.8, wall=62530
2022-03-13 03:48:59 | INFO | train_inner | epoch 069:    113 / 407 loss=5.179, ppl=36.23, wps=30894, ups=0.47, wpb=65536, bsz=128, num_updates=27600, lr=0.000190347, gnorm=0.568, loss_scale=16, train_wall=188, gb_free=9.8, wall=62742
2022-03-13 03:52:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:52:33 | INFO | train_inner | epoch 069:    214 / 407 loss=5.182, ppl=36.31, wps=30628.2, ups=0.47, wpb=65536, bsz=128, num_updates=27700, lr=0.000190003, gnorm=0.57, loss_scale=16, train_wall=190, gb_free=9.8, wall=62956
2022-03-13 03:56:05 | INFO | train_inner | epoch 069:    314 / 407 loss=5.198, ppl=36.7, wps=30916.2, ups=0.47, wpb=65536, bsz=128, num_updates=27800, lr=0.000189661, gnorm=0.573, loss_scale=16, train_wall=188, gb_free=9.8, wall=63168
2022-03-13 03:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 03:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 03:59:46 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 5.379 | ppl 41.63 | wps 53798.1 | wpb 511.9 | bsz 1 | num_updates 27892 | best_loss 5.379
2022-03-13 03:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 27892 updates
2022-03-13 03:59:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:59:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 03:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 69 @ 27892 updates, score 5.379) (writing took 2.194635125983041 seconds)
2022-03-13 03:59:48 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-13 03:59:48 | INFO | train | epoch 069 | loss 5.191 | ppl 36.54 | wps 29832.7 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 27892 | lr 0.000189348 | gnorm 0.571 | loss_scale 16 | train_wall 765 | gb_free 9.8 | wall 63391
2022-03-13 03:59:48 | INFO | fairseq.trainer | begin training epoch 70
2022-03-13 03:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 04:00:05 | INFO | train_inner | epoch 070:      8 / 407 loss=5.211, ppl=37.03, wps=27197.9, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=27900, lr=0.000189321, gnorm=0.573, loss_scale=16, train_wall=189, gb_free=9.8, wall=63408
2022-03-13 04:03:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:03:38 | INFO | train_inner | epoch 070:    109 / 407 loss=5.162, ppl=35.79, wps=30754.2, ups=0.47, wpb=65536, bsz=128, num_updates=28000, lr=0.000188982, gnorm=0.567, loss_scale=16, train_wall=189, gb_free=9.8, wall=63621
2022-03-13 04:07:09 | INFO | train_inner | epoch 070:    209 / 407 loss=5.176, ppl=36.15, wps=31043.8, ups=0.47, wpb=65536, bsz=128, num_updates=28100, lr=0.000188646, gnorm=0.562, loss_scale=16, train_wall=187, gb_free=9.8, wall=63832
2022-03-13 04:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:10:42 | INFO | train_inner | epoch 070:    310 / 407 loss=5.205, ppl=36.88, wps=30759, ups=0.47, wpb=65534.2, bsz=128, num_updates=28200, lr=0.000188311, gnorm=0.567, loss_scale=16, train_wall=189, gb_free=9.8, wall=64045
2022-03-13 04:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 04:14:31 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 5.381 | ppl 41.68 | wps 54005 | wpb 511.9 | bsz 1 | num_updates 28297 | best_loss 5.379
2022-03-13 04:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 28297 updates
2022-03-13 04:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 04:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 04:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 70 @ 28297 updates, score 5.381) (writing took 1.252480885013938 seconds)
2022-03-13 04:14:33 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-13 04:14:33 | INFO | train | epoch 070 | loss 5.186 | ppl 36.4 | wps 29983.2 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 28297 | lr 0.000187988 | gnorm 0.566 | loss_scale 32 | train_wall 761 | gb_free 9.8 | wall 64276
2022-03-13 04:14:33 | INFO | fairseq.trainer | begin training epoch 71
2022-03-13 04:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 04:14:39 | INFO | train_inner | epoch 071:      3 / 407 loss=5.201, ppl=36.79, wps=27592.5, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=28300, lr=0.000187978, gnorm=0.568, loss_scale=32, train_wall=187, gb_free=9.8, wall=64282
2022-03-13 04:15:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:18:13 | INFO | train_inner | epoch 071:    104 / 407 loss=5.159, ppl=35.74, wps=30674.6, ups=0.47, wpb=65534.2, bsz=128, num_updates=28400, lr=0.000187647, gnorm=0.57, loss_scale=16, train_wall=189, gb_free=9.8, wall=64496
2022-03-13 04:19:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:21:46 | INFO | train_inner | epoch 071:    205 / 407 loss=5.177, ppl=36.17, wps=30712.5, ups=0.47, wpb=65536, bsz=128, num_updates=28500, lr=0.000187317, gnorm=0.567, loss_scale=16, train_wall=189, gb_free=9.8, wall=64709
2022-03-13 04:24:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:25:20 | INFO | train_inner | epoch 071:    306 / 407 loss=5.187, ppl=36.42, wps=30713.7, ups=0.47, wpb=65536, bsz=128, num_updates=28600, lr=0.000186989, gnorm=0.566, loss_scale=16, train_wall=189, gb_free=9.8, wall=64923
2022-03-13 04:28:51 | INFO | train_inner | epoch 071:    406 / 407 loss=5.207, ppl=36.94, wps=31038.9, ups=0.47, wpb=65536, bsz=128, num_updates=28700, lr=0.000186663, gnorm=0.566, loss_scale=32, train_wall=187, gb_free=9.8, wall=65134
2022-03-13 04:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 04:29:17 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 5.379 | ppl 41.61 | wps 53863.5 | wpb 511.9 | bsz 1 | num_updates 28701 | best_loss 5.379
2022-03-13 04:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 28701 updates
2022-03-13 04:29:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 04:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 04:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 71 @ 28701 updates, score 5.379) (writing took 2.278274510987103 seconds)
2022-03-13 04:29:20 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-13 04:29:20 | INFO | train | epoch 071 | loss 5.182 | ppl 36.3 | wps 29837.3 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 28701 | lr 0.00018666 | gnorm 0.567 | loss_scale 32 | train_wall 762 | gb_free 9.8 | wall 65163
2022-03-13 04:29:20 | INFO | fairseq.trainer | begin training epoch 72
2022-03-13 04:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 04:29:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:32:51 | INFO | train_inner | epoch 072:    100 / 407 loss=5.152, ppl=35.55, wps=27193.6, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=28800, lr=0.000186339, gnorm=0.574, loss_scale=16, train_wall=189, gb_free=9.8, wall=65374
2022-03-13 04:34:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:36:25 | INFO | train_inner | epoch 072:    201 / 407 loss=5.17, ppl=36, wps=30639.5, ups=0.47, wpb=65534.2, bsz=128, num_updates=28900, lr=0.000186016, gnorm=0.571, loss_scale=16, train_wall=190, gb_free=9.8, wall=65588
2022-03-13 04:38:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:39:59 | INFO | train_inner | epoch 072:    302 / 407 loss=5.193, ppl=36.57, wps=30658.6, ups=0.47, wpb=65536, bsz=128, num_updates=29000, lr=0.000185695, gnorm=0.571, loss_scale=16, train_wall=190, gb_free=9.8, wall=65802
2022-03-13 04:43:31 | INFO | train_inner | epoch 072:    402 / 407 loss=5.194, ppl=36.62, wps=30950.2, ups=0.47, wpb=65536, bsz=128, num_updates=29100, lr=0.000185376, gnorm=0.573, loss_scale=32, train_wall=188, gb_free=9.8, wall=66014
2022-03-13 04:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 04:44:05 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 5.369 | ppl 41.34 | wps 54035.9 | wpb 511.9 | bsz 1 | num_updates 29105 | best_loss 5.369
2022-03-13 04:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 29105 updates
2022-03-13 04:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 04:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt
2022-03-13 04:44:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_best.pt (epoch 72 @ 29105 updates, score 5.369) (writing took 2.2175531969987787 seconds)
2022-03-13 04:44:08 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-13 04:44:08 | INFO | train | epoch 072 | loss 5.178 | ppl 36.19 | wps 29795.6 | ups 0.45 | wpb 65492.5 | bsz 127.9 | num_updates 29105 | lr 0.00018536 | gnorm 0.572 | loss_scale 32 | train_wall 763 | gb_free 9.8 | wall 66051
2022-03-13 04:44:08 | INFO | fairseq.trainer | begin training epoch 73
2022-03-13 04:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 04:44:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:47:31 | INFO | train_inner | epoch 073:     96 / 407 loss=5.144, ppl=35.36, wps=27224.3, ups=0.42, wpb=65360.1, bsz=127.7, num_updates=29200, lr=0.000185058, gnorm=0.568, loss_scale=16, train_wall=189, gb_free=9.8, wall=66254
2022-03-13 04:51:02 | INFO | train_inner | epoch 073:    196 / 407 loss=5.178, ppl=36.2, wps=31029.7, ups=0.47, wpb=65536, bsz=128, num_updates=29300, lr=0.000184742, gnorm=0.568, loss_scale=32, train_wall=187, gb_free=9.8, wall=66465
2022-03-13 04:51:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:54:35 | INFO | train_inner | epoch 073:    297 / 407 loss=5.179, ppl=36.22, wps=30722.7, ups=0.47, wpb=65536, bsz=128, num_updates=29400, lr=0.000184428, gnorm=0.579, loss_scale=16, train_wall=189, gb_free=9.8, wall=66678
2022-03-13 04:55:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 04:58:08 | INFO | train_inner | epoch 073:    398 / 407 loss=5.188, ppl=36.46, wps=30763.2, ups=0.47, wpb=65536, bsz=128, num_updates=29500, lr=0.000184115, gnorm=0.574, loss_scale=16, train_wall=189, gb_free=9.8, wall=66891
2022-03-13 04:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 04:58:51 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 5.372 | ppl 41.41 | wps 54019.7 | wpb 511.9 | bsz 1 | num_updates 29509 | best_loss 5.369
2022-03-13 04:58:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 29509 updates
2022-03-13 04:58:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 04:58:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 04:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 73 @ 29509 updates, score 5.372) (writing took 1.2281737200100906 seconds)
2022-03-13 04:58:53 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-13 04:58:53 | INFO | train | epoch 073 | loss 5.173 | ppl 36.08 | wps 29893.7 | ups 0.46 | wpb 65492.5 | bsz 127.9 | num_updates 29509 | lr 0.000184087 | gnorm 0.572 | loss_scale 16 | train_wall 762 | gb_free 9.8 | wall 66936
2022-03-13 04:58:53 | INFO | fairseq.trainer | begin training epoch 74
2022-03-13 04:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 05:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 05:02:07 | INFO | train_inner | epoch 074:     92 / 407 loss=5.154, ppl=35.6, wps=27319.1, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=29600, lr=0.000183804, gnorm=0.572, loss_scale=16, train_wall=189, gb_free=9.8, wall=67130
2022-03-13 05:05:39 | INFO | train_inner | epoch 074:    192 / 407 loss=5.16, ppl=35.74, wps=30987.7, ups=0.47, wpb=65536, bsz=128, num_updates=29700, lr=0.000183494, gnorm=0.576, loss_scale=16, train_wall=188, gb_free=9.8, wall=67342
2022-03-13 05:06:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 05:09:13 | INFO | train_inner | epoch 074:    293 / 407 loss=5.188, ppl=36.45, wps=30666.9, ups=0.47, wpb=65534.2, bsz=128, num_updates=29800, lr=0.000183186, gnorm=0.573, loss_scale=16, train_wall=190, gb_free=9.8, wall=67556
2022-03-13 05:10:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 05:12:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 05:12:48 | INFO | train_inner | epoch 074:    395 / 407 loss=5.183, ppl=36.33, wps=30372.9, ups=0.46, wpb=65536, bsz=128, num_updates=29900, lr=0.000182879, gnorm=0.573, loss_scale=8, train_wall=191, gb_free=9.8, wall=67771
2022-03-13 05:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 05:13:38 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 5.375 | ppl 41.48 | wps 54098.3 | wpb 511.9 | bsz 1 | num_updates 29912 | best_loss 5.369
2022-03-13 05:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 29912 updates
2022-03-13 05:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 05:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 05:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 74 @ 29912 updates, score 5.375) (writing took 1.2254620870226063 seconds)
2022-03-13 05:13:39 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-13 05:13:39 | INFO | train | epoch 074 | loss 5.17 | ppl 36 | wps 29772.2 | ups 0.45 | wpb 65492.3 | bsz 127.9 | num_updates 29912 | lr 0.000182843 | gnorm 0.573 | loss_scale 8 | train_wall 763 | gb_free 9.8 | wall 67822
2022-03-13 05:13:39 | INFO | fairseq.trainer | begin training epoch 75
2022-03-13 05:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 05:16:45 | INFO | train_inner | epoch 075:     88 / 407 loss=5.139, ppl=35.23, wps=27592.5, ups=0.42, wpb=65361.9, bsz=127.7, num_updates=30000, lr=0.000182574, gnorm=0.575, loss_scale=8, train_wall=187, gb_free=9.8, wall=68008
2022-03-13 05:20:17 | INFO | train_inner | epoch 075:    188 / 407 loss=5.156, ppl=35.65, wps=30991.5, ups=0.47, wpb=65534.2, bsz=128, num_updates=30100, lr=0.000182271, gnorm=0.572, loss_scale=16, train_wall=188, gb_free=9.8, wall=68220
2022-03-13 05:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 05:23:51 | INFO | train_inner | epoch 075:    289 / 407 loss=5.172, ppl=36.06, wps=30647.1, ups=0.47, wpb=65536, bsz=128, num_updates=30200, lr=0.000181969, gnorm=0.575, loss_scale=16, train_wall=190, gb_free=9.8, wall=68434
2022-03-13 05:26:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 05:27:24 | INFO | train_inner | epoch 075:    390 / 407 loss=5.19, ppl=36.49, wps=30672.8, ups=0.47, wpb=65536, bsz=128, num_updates=30300, lr=0.000181668, gnorm=0.573, loss_scale=16, train_wall=190, gb_free=9.8, wall=68647
2022-03-13 05:28:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 05:28:25 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 5.374 | ppl 41.48 | wps 53931.2 | wpb 511.9 | bsz 1 | num_updates 30317 | best_loss 5.369
2022-03-13 05:28:25 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-13 05:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 30317 updates
2022-03-13 05:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 05:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt
2022-03-13 05:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_cross_entropy_dropout_0.4_#1/checkpoint_last.pt (epoch 75 @ 30317 updates, score 5.374) (writing took 1.2109574840287678 seconds)
2022-03-13 05:28:26 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-13 05:28:26 | INFO | train | epoch 075 | loss 5.165 | ppl 35.88 | wps 29916.5 | ups 0.46 | wpb 65492.6 | bsz 127.9 | num_updates 30317 | lr 0.000181617 | gnorm 0.573 | loss_scale 16 | train_wall 763 | gb_free 9.8 | wall 68709
2022-03-13 05:28:26 | INFO | fairseq_cli.train | done training in 68708.6 seconds
