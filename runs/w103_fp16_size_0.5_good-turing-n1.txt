Sender: LSF System <lsfadmin@eu-g3-005>
Subject: Job 206152257: <w103_fp16_size_0.5_good-turing-n1> in cluster <euler> Exited

Job <w103_fp16_size_0.5_good-turing-n1> was submitted from host <eu-login-47> by user <andriusb> in cluster <euler> at Wed Feb 23 10:06:16 2022
Job was executed on host(s) <eu-g3-005>, in queue <gpu.120h>, as user <andriusb> in cluster <euler> at Wed Feb 23 10:07:48 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb 23 10:07:48 2022
Terminated at Sun Feb 27 15:16:52 2022
Results reported at Sun Feb 27 15:16:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.5 --save-dir /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion good_turing_smoothing --good-turing-n 1 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --no-epoch-checkpoints --no-last-checkpoints --seed 1321672 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   363970.09 sec.
    Max Memory :                                 17772 MB
    Average Memory :                             5759.29 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               2228.00 MB
    Max Swap :                                   7848 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   364165 sec.
    Turnaround time :                            364236 sec.

The output (if any) follows:

2022-02-23 10:08:02 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321672, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.5', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321672, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'good_turing_smoothing', 'good_turing_n': 1, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-02-23 10:08:03 | INFO | fairseq.tasks.language_modeling | dictionary: 430640 types
2022-02-23 10:08:10 | INFO | fairseq.data.data_utils | loaded 900,675 examples from: data-bin/wikitext-103-raw-size-0.5/train
Calculating frequency stats:
  0%|          | 0/900675 [00:00<?, ?it/s]  0%|          | 680/900675 [00:00<02:12, 6796.75it/s]  0%|          | 1360/900675 [00:00<02:32, 5908.74it/s]  0%|          | 1959/900675 [00:00<02:39, 5644.89it/s]  0%|          | 2529/900675 [00:00<02:38, 5664.32it/s]  0%|          | 3229/900675 [00:00<02:26, 6115.68it/s]  0%|          | 3845/900675 [00:00<02:26, 6129.69it/s]  1%|          | 4539/900675 [00:00<02:20, 6388.02it/s]  1%|          | 5239/900675 [00:00<02:16, 6576.41it/s]  1%|          | 5926/900675 [00:00<02:14, 6661.45it/s]  1%|          | 6594/900675 [00:01<02:27, 6066.77it/s]  1%|          | 7212/900675 [00:01<02:27, 6060.14it/s]  1%|          | 7826/900675 [00:01<02:28, 6000.79it/s]  1%|          | 8432/900675 [00:01<02:33, 5808.03it/s]  1%|          | 9073/900675 [00:01<02:29, 5977.90it/s]  1%|          | 9675/900675 [00:01<02:32, 5854.42it/s]  1%|          | 10307/900675 [00:01<02:28, 5979.40it/s]  1%|          | 10908/900675 [00:01<02:32, 5822.93it/s]  1%|▏         | 11493/900675 [00:01<02:32, 5827.13it/s]  1%|▏         | 12133/900675 [00:02<02:28, 5989.94it/s]  1%|▏         | 12734/900675 [00:02<02:32, 5831.97it/s]  1%|▏         | 13362/900675 [00:02<02:29, 5951.55it/s]  2%|▏         | 14017/900675 [00:02<02:24, 6126.00it/s]  2%|▏         | 14632/900675 [00:02<02:24, 6120.02it/s]  2%|▏         | 15302/900675 [00:02<02:20, 6288.76it/s]  2%|▏         | 15932/900675 [00:02<02:28, 5967.47it/s]  2%|▏         | 16533/900675 [00:02<02:30, 5861.11it/s]  2%|▏         | 17147/900675 [00:02<02:28, 5936.07it/s]  2%|▏         | 17743/900675 [00:02<02:29, 5923.59it/s]  2%|▏         | 18337/900675 [00:03<02:30, 5873.76it/s]  2%|▏         | 19047/900675 [00:03<02:21, 6230.33it/s]  2%|▏         | 19709/900675 [00:03<02:18, 6339.93it/s]  2%|▏         | 20345/900675 [00:03<02:29, 5889.28it/s]  2%|▏         | 20971/900675 [00:03<02:26, 5991.86it/s]  2%|▏         | 21576/900675 [00:03<02:34, 5703.74it/s]  2%|▏         | 22203/900675 [00:03<02:29, 5861.06it/s]  3%|▎         | 22856/900675 [00:03<02:25, 6051.51it/s]  3%|▎         | 23502/900675 [00:03<02:22, 6169.50it/s]  3%|▎         | 24236/900675 [00:03<02:14, 6506.95it/s]  3%|▎         | 24943/900675 [00:04<02:11, 6672.67it/s]  3%|▎         | 25613/900675 [00:04<02:12, 6595.32it/s]  3%|▎         | 26275/900675 [00:04<02:20, 6205.04it/s]  3%|▎         | 26902/900675 [00:04<02:26, 5978.89it/s]  3%|▎         | 27505/900675 [00:04<02:31, 5750.05it/s]  3%|▎         | 28140/900675 [00:04<02:27, 5911.56it/s]  3%|▎         | 28823/900675 [00:04<02:21, 6163.71it/s]  3%|▎         | 29444/900675 [00:04<02:29, 5846.63it/s]  3%|▎         | 30113/900675 [00:04<02:23, 6082.55it/s]  3%|▎         | 30727/900675 [00:05<02:30, 5778.74it/s]  3%|▎         | 31311/900675 [00:05<02:32, 5698.96it/s]  4%|▎         | 31902/900675 [00:05<02:30, 5758.14it/s]  4%|▎         | 32481/900675 [00:05<02:31, 5747.92it/s]  4%|▎         | 33058/900675 [00:05<02:37, 5525.54it/s]  4%|▎         | 33650/900675 [00:05<02:33, 5637.18it/s]  4%|▍         | 34218/900675 [00:05<02:33, 5644.85it/s]  4%|▍         | 34923/900675 [00:05<02:22, 6054.96it/s]  4%|▍         | 35531/900675 [00:05<02:27, 5883.77it/s]  4%|▍         | 36126/900675 [00:06<02:26, 5902.61it/s]  4%|▍         | 36729/900675 [00:06<02:25, 5938.04it/s]  4%|▍         | 37325/900675 [00:06<02:32, 5666.37it/s]  4%|▍         | 37895/900675 [00:06<02:34, 5591.00it/s]  4%|▍         | 38457/900675 [00:06<02:35, 5529.91it/s]  4%|▍         | 39040/900675 [00:06<02:33, 5606.07it/s]  4%|▍         | 39623/900675 [00:06<02:31, 5668.81it/s]  4%|▍         | 40250/900675 [00:06<02:27, 5836.51it/s]  5%|▍         | 40904/900675 [00:06<02:22, 6043.71it/s]  5%|▍         | 41510/900675 [00:06<02:24, 5936.35it/s]  5%|▍         | 42105/900675 [00:07<02:32, 5615.21it/s]  5%|▍         | 42671/900675 [00:07<02:33, 5591.12it/s]  5%|▍         | 43233/900675 [00:07<02:34, 5535.47it/s]  5%|▍         | 43906/900675 [00:07<02:25, 5873.47it/s]  5%|▍         | 44521/900675 [00:07<02:24, 5945.48it/s]  5%|▌         | 45118/900675 [00:07<02:26, 5850.59it/s]  5%|▌         | 45734/900675 [00:07<02:24, 5936.96it/s]  5%|▌         | 46462/900675 [00:07<02:14, 6332.02it/s]  5%|▌         | 47097/900675 [00:07<02:17, 6211.31it/s]  5%|▌         | 48050/900675 [00:07<01:58, 7180.00it/s]  5%|▌         | 48772/900675 [00:08<02:02, 6958.14it/s]  5%|▌         | 49508/900675 [00:08<02:00, 7071.29it/s]  6%|▌         | 50219/900675 [00:08<02:10, 6504.42it/s]  6%|▌         | 50880/900675 [00:08<02:17, 6197.92it/s]  6%|▌         | 51509/900675 [00:08<02:18, 6117.61it/s]  6%|▌         | 52355/900675 [00:08<02:05, 6765.47it/s]  6%|▌         | 53041/900675 [00:08<02:09, 6558.13it/s]  6%|▌         | 53704/900675 [00:08<02:12, 6376.53it/s]  6%|▌         | 54347/900675 [00:09<02:21, 5972.13it/s]  6%|▌         | 54952/900675 [00:09<02:23, 5904.92it/s]  6%|▌         | 55595/900675 [00:09<02:19, 6047.04it/s]  6%|▌         | 56247/900675 [00:09<02:16, 6176.76it/s]  6%|▋         | 56869/900675 [00:09<02:24, 5854.98it/s]  6%|▋         | 57460/900675 [00:09<02:28, 5687.59it/s]  6%|▋         | 58064/900675 [00:09<02:25, 5780.71it/s]  7%|▋         | 58797/900675 [00:09<02:15, 6219.87it/s]  7%|▋         | 59424/900675 [00:09<02:22, 5895.09it/s]  7%|▋         | 60020/900675 [00:09<02:23, 5858.19it/s]  7%|▋         | 60627/900675 [00:10<02:22, 5912.36it/s]  7%|▋         | 61408/900675 [00:10<02:09, 6460.22it/s]  7%|▋         | 62059/900675 [00:10<02:17, 6109.11it/s]  7%|▋         | 62677/900675 [00:10<02:16, 6119.51it/s]  7%|▋         | 63294/900675 [00:10<02:19, 5986.82it/s]  7%|▋         | 63936/900675 [00:10<02:17, 6104.95it/s]  7%|▋         | 64550/900675 [00:10<02:21, 5908.56it/s]  7%|▋         | 65153/900675 [00:10<02:20, 5940.62it/s]  7%|▋         | 65751/900675 [00:10<02:20, 5951.64it/s]  7%|▋         | 66349/900675 [00:11<02:20, 5954.68it/s]  7%|▋         | 67007/900675 [00:11<02:15, 6134.85it/s]  8%|▊         | 67622/900675 [00:11<02:21, 5875.35it/s]  8%|▊         | 68213/900675 [00:11<02:26, 5693.22it/s]  8%|▊         | 68958/900675 [00:11<02:14, 6191.57it/s]  8%|▊         | 69582/900675 [00:11<02:14, 6194.91it/s]  8%|▊         | 70229/900675 [00:11<02:12, 6274.94it/s]  8%|▊         | 70859/900675 [00:11<02:19, 5944.50it/s]  8%|▊         | 71480/900675 [00:11<02:17, 6010.10it/s]  8%|▊         | 72113/900675 [00:11<02:15, 6096.81it/s]  8%|▊         | 72795/900675 [00:12<02:11, 6303.41it/s]  8%|▊         | 73519/900675 [00:12<02:05, 6570.55it/s]  8%|▊         | 74315/900675 [00:12<01:58, 6975.42it/s]  8%|▊         | 75015/900675 [00:12<02:02, 6712.94it/s]  8%|▊         | 75690/900675 [00:12<02:11, 6294.85it/s]  8%|▊         | 76372/900675 [00:12<02:08, 6437.29it/s]  9%|▊         | 77022/900675 [00:12<02:12, 6236.97it/s]  9%|▊         | 77665/900675 [00:12<02:11, 6281.91it/s]  9%|▊         | 78297/900675 [00:12<02:17, 5993.70it/s]  9%|▉         | 78901/900675 [00:13<02:23, 5712.59it/s]  9%|▉         | 79477/900675 [00:13<02:25, 5650.18it/s]  9%|▉         | 80045/900675 [00:13<02:25, 5633.78it/s]  9%|▉         | 80611/900675 [00:13<02:25, 5620.67it/s]  9%|▉         | 81330/900675 [00:13<02:15, 6069.04it/s]  9%|▉         | 81940/900675 [00:13<02:18, 5922.56it/s]  9%|▉         | 82546/900675 [00:13<02:17, 5955.71it/s]  9%|▉         | 83213/900675 [00:13<02:12, 6163.53it/s]  9%|▉         | 83832/900675 [00:13<02:13, 6106.06it/s]  9%|▉         | 84444/900675 [00:13<02:17, 5950.92it/s]  9%|▉         | 85063/900675 [00:14<02:15, 6016.30it/s] 10%|▉         | 85678/900675 [00:14<02:14, 6051.81it/s] 10%|▉         | 86285/900675 [00:14<02:17, 5924.68it/s] 10%|▉         | 86981/900675 [00:14<02:10, 6221.84it/s] 10%|▉         | 87621/900675 [00:14<02:09, 6270.53it/s] 10%|▉         | 88262/900675 [00:14<02:08, 6310.25it/s] 10%|▉         | 88894/900675 [00:14<02:20, 5759.77it/s] 10%|▉         | 89480/900675 [00:14<02:22, 5704.99it/s] 10%|▉         | 90058/900675 [00:14<02:24, 5609.40it/s] 10%|█         | 90647/900675 [00:15<02:22, 5688.61it/s] 10%|█         | 91299/900675 [00:15<02:16, 5913.24it/s] 10%|█         | 91898/900675 [00:15<02:16, 5929.45it/s] 10%|█         | 92587/900675 [00:15<02:10, 6205.54it/s] 10%|█         | 93210/900675 [00:15<02:17, 5884.03it/s] 10%|█         | 93804/900675 [00:15<02:16, 5895.28it/s] 10%|█         | 94397/900675 [00:15<02:17, 5883.89it/s] 11%|█         | 95075/900675 [00:15<02:11, 6144.67it/s] 11%|█         | 95692/900675 [00:15<02:16, 5888.33it/s] 11%|█         | 96359/900675 [00:15<02:11, 6112.16it/s] 11%|█         | 97132/900675 [00:16<02:02, 6579.05it/s] 11%|█         | 97794/900675 [00:16<02:10, 6149.96it/s] 11%|█         | 98419/900675 [00:16<02:09, 6177.78it/s] 11%|█         | 99043/900675 [00:16<02:12, 6060.58it/s] 11%|█         | 99654/900675 [00:16<02:17, 5812.00it/s] 11%|█         | 100240/900675 [00:16<02:20, 5712.52it/s] 11%|█         | 100833/900675 [00:16<02:18, 5771.65it/s] 11%|█▏        | 101413/900675 [00:16<02:19, 5716.44it/s] 11%|█▏        | 102108/900675 [00:16<02:11, 6071.92it/s] 11%|█▏        | 102718/900675 [00:17<02:14, 5944.63it/s] 11%|█▏        | 103315/900675 [00:17<02:16, 5861.61it/s] 12%|█▏        | 103903/900675 [00:17<02:18, 5735.87it/s] 12%|█▏        | 104520/900675 [00:17<02:15, 5860.52it/s] 12%|█▏        | 105108/900675 [00:17<02:18, 5727.04it/s] 12%|█▏        | 105768/900675 [00:17<02:17, 5764.64it/s] 12%|█▏        | 106346/900675 [00:17<02:21, 5627.92it/s] 12%|█▏        | 106910/900675 [00:17<02:21, 5625.54it/s] 12%|█▏        | 107473/900675 [00:17<02:22, 5573.36it/s] 12%|█▏        | 108124/900675 [00:17<02:15, 5842.34it/s] 12%|█▏        | 108710/900675 [00:18<02:24, 5498.69it/s] 12%|█▏        | 109284/900675 [00:18<02:22, 5566.70it/s] 12%|█▏        | 109907/900675 [00:18<02:17, 5753.03it/s] 12%|█▏        | 110528/900675 [00:18<02:14, 5878.92it/s] 12%|█▏        | 111193/900675 [00:18<02:09, 6099.35it/s] 12%|█▏        | 111806/900675 [00:18<02:12, 5964.74it/s] 12%|█▏        | 112405/900675 [00:18<02:11, 5971.95it/s] 13%|█▎        | 113014/900675 [00:18<02:11, 6004.55it/s] 13%|█▎        | 113616/900675 [00:18<02:18, 5678.33it/s] 13%|█▎        | 114278/900675 [00:19<02:12, 5942.79it/s] 13%|█▎        | 114877/900675 [00:19<02:14, 5855.53it/s] 13%|█▎        | 115466/900675 [00:19<02:15, 5808.08it/s] 13%|█▎        | 116049/900675 [00:19<02:18, 5679.63it/s] 13%|█▎        | 116619/900675 [00:19<02:19, 5630.72it/s] 13%|█▎        | 117184/900675 [00:19<02:20, 5588.71it/s] 13%|█▎        | 117744/900675 [00:19<02:21, 5546.33it/s] 13%|█▎        | 118430/900675 [00:19<02:11, 5928.95it/s] 13%|█▎        | 119025/900675 [00:19<02:14, 5832.47it/s] 13%|█▎        | 119610/900675 [00:19<02:15, 5773.99it/s] 13%|█▎        | 120354/900675 [00:20<02:04, 6257.07it/s] 13%|█▎        | 120982/900675 [00:20<02:06, 6162.00it/s] 14%|█▎        | 121600/900675 [00:20<02:12, 5886.94it/s] 14%|█▎        | 122205/900675 [00:20<02:11, 5927.08it/s] 14%|█▎        | 122817/900675 [00:20<02:10, 5979.65it/s] 14%|█▎        | 123417/900675 [00:20<02:15, 5730.01it/s] 14%|█▍        | 124036/900675 [00:20<02:12, 5855.52it/s] 14%|█▍        | 124625/900675 [00:20<02:13, 5812.62it/s] 14%|█▍        | 125209/900675 [00:20<02:14, 5766.02it/s] 14%|█▍        | 125858/900675 [00:21<02:09, 5976.49it/s] 14%|█▍        | 126460/900675 [00:21<02:09, 5988.13it/s] 14%|█▍        | 127118/900675 [00:21<02:05, 6162.90it/s] 14%|█▍        | 127736/900675 [00:21<02:11, 5880.44it/s] 14%|█▍        | 128348/900675 [00:21<02:09, 5941.01it/s] 14%|█▍        | 128945/900675 [00:21<02:10, 5898.34it/s] 14%|█▍        | 129590/900675 [00:21<02:07, 6051.99it/s] 14%|█▍        | 130197/900675 [00:21<02:15, 5704.41it/s] 15%|█▍        | 130773/900675 [00:21<02:15, 5686.45it/s] 15%|█▍        | 131372/900675 [00:21<02:13, 5772.85it/s] 15%|█▍        | 131952/900675 [00:22<02:27, 5211.32it/s] 15%|█▍        | 132628/900675 [00:22<02:16, 5627.03it/s] 15%|█▍        | 133313/900675 [00:22<02:08, 5964.56it/s] 15%|█▍        | 133921/900675 [00:22<02:08, 5981.79it/s] 15%|█▍        | 134616/900675 [00:22<02:02, 6254.55it/s] 15%|█▌        | 135325/900675 [00:22<01:57, 6496.15it/s] 15%|█▌        | 135980/900675 [00:22<02:02, 6259.31it/s] 15%|█▌        | 136708/900675 [00:22<01:56, 6549.03it/s] 15%|█▌        | 137396/900675 [00:22<01:54, 6645.33it/s] 15%|█▌        | 138065/900675 [00:23<02:00, 6344.17it/s] 15%|█▌        | 138705/900675 [00:23<02:01, 6260.96it/s] 15%|█▌        | 139335/900675 [00:23<02:05, 6076.62it/s] 16%|█▌        | 139946/900675 [00:23<02:05, 6074.97it/s] 16%|█▌        | 140556/900675 [00:23<02:07, 5939.43it/s] 16%|█▌        | 141175/900675 [00:23<02:06, 6011.04it/s] 16%|█▌        | 141778/900675 [00:23<02:10, 5822.93it/s] 16%|█▌        | 142363/900675 [00:23<02:10, 5806.80it/s] 16%|█▌        | 142945/900675 [00:23<02:13, 5695.20it/s] 16%|█▌        | 143681/900675 [00:23<02:02, 6173.58it/s] 16%|█▌        | 144301/900675 [00:24<02:04, 6084.85it/s] 16%|█▌        | 145003/900675 [00:24<01:59, 6349.19it/s] 16%|█▌        | 145645/900675 [00:24<01:58, 6369.67it/s] 16%|█▌        | 146284/900675 [00:24<02:00, 6279.10it/s] 16%|█▋        | 146914/900675 [00:24<02:07, 5891.64it/s] 16%|█▋        | 147509/900675 [00:24<02:13, 5641.59it/s] 16%|█▋        | 148098/900675 [00:24<02:11, 5707.20it/s] 17%|█▋        | 148677/900675 [00:24<02:11, 5724.44it/s] 17%|█▋        | 149284/900675 [00:24<02:09, 5822.51it/s] 17%|█▋        | 149869/900675 [00:25<02:09, 5790.88it/s] 17%|█▋        | 150450/900675 [00:25<02:11, 5704.57it/s] 17%|█▋        | 151022/900675 [00:25<02:13, 5616.20it/s] 17%|█▋        | 151638/900675 [00:25<02:09, 5772.94it/s] 17%|█▋        | 152217/900675 [00:25<02:22, 5257.97it/s] 17%|█▋        | 152863/900675 [00:25<02:13, 5586.32it/s] 17%|█▋        | 153551/900675 [00:25<02:05, 5945.72it/s] 17%|█▋        | 154155/900675 [00:25<02:12, 5635.68it/s] 17%|█▋        | 154728/900675 [00:25<02:12, 5644.27it/s] 17%|█▋        | 155369/900675 [00:26<02:07, 5861.40it/s] 17%|█▋        | 155961/900675 [00:26<02:07, 5844.18it/s] 17%|█▋        | 156620/900675 [00:26<02:02, 6054.86it/s] 17%|█▋        | 157265/900675 [00:26<02:00, 6167.81it/s] 18%|█▊        | 157907/900675 [00:26<01:59, 6232.48it/s] 18%|█▊        | 158533/900675 [00:26<01:59, 6232.27it/s] 18%|█▊        | 159158/900675 [00:26<02:07, 5817.86it/s] 18%|█▊        | 159847/900675 [00:26<02:01, 6120.88it/s] 18%|█▊        | 160466/900675 [00:26<02:01, 6070.37it/s] 18%|█▊        | 161140/900675 [00:26<01:58, 6263.85it/s] 18%|█▊        | 161771/900675 [00:27<02:06, 5835.79it/s] 18%|█▊        | 162430/900675 [00:27<02:02, 6036.15it/s] 18%|█▊        | 163129/900675 [00:27<01:57, 6294.94it/s] 18%|█▊        | 163765/900675 [00:27<02:05, 5889.95it/s] 18%|█▊        | 164407/900675 [00:27<02:02, 6024.46it/s] 18%|█▊        | 165060/900675 [00:27<01:59, 6164.35it/s] 18%|█▊        | 165761/900675 [00:27<01:54, 6404.56it/s] 18%|█▊        | 166407/900675 [00:27<01:58, 6206.80it/s] 19%|█▊        | 167086/900675 [00:27<01:55, 6368.84it/s] 19%|█▊        | 167727/900675 [00:28<01:56, 6272.30it/s] 19%|█▊        | 168357/900675 [00:28<02:03, 5931.80it/s] 19%|█▉        | 169005/900675 [00:28<02:00, 6081.92it/s] 19%|█▉        | 169618/900675 [00:28<02:02, 5987.41it/s] 19%|█▉        | 170220/900675 [00:28<02:06, 5771.29it/s] 19%|█▉        | 170801/900675 [00:28<02:08, 5686.42it/s] 19%|█▉        | 171396/900675 [00:28<02:06, 5758.78it/s] 19%|█▉        | 171982/900675 [00:28<02:06, 5783.01it/s] 19%|█▉        | 172576/900675 [00:28<02:05, 5819.54it/s] 19%|█▉        | 173159/900675 [00:28<02:06, 5762.58it/s] 19%|█▉        | 173780/900675 [00:29<02:03, 5883.95it/s] 19%|█▉        | 174370/900675 [00:29<02:06, 5745.59it/s] 19%|█▉        | 175070/900675 [00:29<01:58, 6106.67it/s] 20%|█▉        | 175683/900675 [00:29<02:04, 5801.36it/s] 20%|█▉        | 176295/900675 [00:29<02:03, 5886.04it/s] 20%|█▉        | 176887/900675 [00:29<02:06, 5702.73it/s] 20%|█▉        | 177461/900675 [00:29<02:11, 5498.27it/s] 20%|█▉        | 178014/900675 [00:29<02:13, 5429.43it/s] 20%|█▉        | 178676/900675 [00:29<02:05, 5766.71it/s] 20%|█▉        | 179266/900675 [00:30<02:04, 5802.49it/s] 20%|█▉        | 179849/900675 [00:30<02:05, 5744.17it/s] 20%|██        | 180487/900675 [00:30<02:01, 5928.98it/s] 20%|██        | 181082/900675 [00:30<02:09, 5566.71it/s] 20%|██        | 181644/900675 [00:30<02:09, 5531.25it/s] 20%|██        | 182248/900675 [00:30<02:06, 5675.15it/s] 20%|██        | 182831/900675 [00:30<02:05, 5715.91it/s] 20%|██        | 183411/900675 [00:30<02:04, 5740.36it/s] 20%|██        | 183987/900675 [00:30<02:13, 5374.97it/s] 20%|██        | 184545/900675 [00:30<02:11, 5425.95it/s] 21%|██        | 185159/900675 [00:31<02:07, 5625.42it/s] 21%|██        | 185726/900675 [00:31<02:11, 5446.59it/s] 21%|██        | 186286/900675 [00:31<02:10, 5487.09it/s] 21%|██        | 186859/900675 [00:31<02:08, 5555.12it/s] 21%|██        | 187510/900675 [00:31<02:02, 5829.49it/s] 21%|██        | 188095/900675 [00:31<02:03, 5769.10it/s] 21%|██        | 188781/900675 [00:31<01:56, 6089.67it/s] 21%|██        | 189392/900675 [00:31<02:00, 5923.24it/s] 21%|██        | 190016/900675 [00:31<01:58, 6007.54it/s] 21%|██        | 190647/900675 [00:31<01:56, 6090.54it/s] 21%|██        | 191258/900675 [00:32<01:57, 6055.20it/s] 21%|██▏       | 191865/900675 [00:32<01:58, 5998.51it/s] 21%|██▏       | 192478/900675 [00:32<01:57, 6035.62it/s] 21%|██▏       | 193083/900675 [00:32<01:57, 6024.67it/s] 22%|██▏       | 193693/900675 [00:32<01:57, 6041.90it/s] 22%|██▏       | 194298/900675 [00:32<01:57, 6012.53it/s] 22%|██▏       | 194901/900675 [00:32<01:57, 6016.28it/s] 22%|██▏       | 195522/900675 [00:32<01:56, 6070.53it/s] 22%|██▏       | 196130/900675 [00:32<01:59, 5916.95it/s] 22%|██▏       | 196723/900675 [00:33<02:01, 5805.44it/s] 22%|██▏       | 197685/900675 [00:33<01:41, 6916.39it/s] 22%|██▏       | 198381/900675 [00:33<01:51, 6284.70it/s] 22%|██▏       | 199023/900675 [00:33<01:55, 6055.91it/s] 22%|██▏       | 199639/900675 [00:33<01:58, 5924.93it/s] 22%|██▏       | 200238/900675 [00:33<01:58, 5889.72it/s] 22%|██▏       | 200832/900675 [00:33<02:02, 5692.52it/s] 22%|██▏       | 201405/900675 [00:33<02:03, 5673.55it/s] 22%|██▏       | 201999/900675 [00:33<02:01, 5743.98it/s] 22%|██▏       | 202622/900675 [00:34<01:58, 5883.44it/s] 23%|██▎       | 203240/900675 [00:34<01:56, 5969.38it/s] 23%|██▎       | 203939/900675 [00:34<01:51, 6261.15it/s] 23%|██▎       | 204567/900675 [00:34<01:58, 5887.60it/s] 23%|██▎       | 205162/900675 [00:34<01:59, 5819.43it/s] 23%|██▎       | 205748/900675 [00:34<02:00, 5752.84it/s] 23%|██▎       | 206418/900675 [00:34<01:55, 6015.40it/s] 23%|██▎       | 207023/900675 [00:34<01:59, 5789.67it/s] 23%|██▎       | 207606/900675 [00:34<02:00, 5762.20it/s] 23%|██▎       | 208185/900675 [00:34<02:01, 5683.09it/s] 23%|██▎       | 208755/900675 [00:35<02:05, 5508.99it/s] 23%|██▎       | 209315/900675 [00:35<02:04, 5533.12it/s] 23%|██▎       | 209963/900675 [00:35<01:58, 5805.42it/s] 23%|██▎       | 210592/900675 [00:35<01:56, 5944.24it/s] 23%|██▎       | 211233/900675 [00:35<01:53, 6080.22it/s] 24%|██▎       | 211843/900675 [00:35<01:55, 5974.26it/s] 24%|██▎       | 212442/900675 [00:35<01:55, 5951.39it/s] 24%|██▎       | 213148/900675 [00:35<01:49, 6273.24it/s] 24%|██▎       | 213777/900675 [00:35<01:58, 5789.18it/s] 24%|██▍       | 214364/900675 [00:36<01:58, 5785.72it/s] 24%|██▍       | 214949/900675 [00:36<02:09, 5293.77it/s] 24%|██▍       | 215507/900675 [00:36<02:07, 5365.34it/s] 24%|██▍       | 216108/900675 [00:36<02:03, 5544.82it/s] 24%|██▍       | 216670/900675 [00:36<02:03, 5539.71it/s] 24%|██▍       | 217234/900675 [00:36<02:02, 5567.70it/s] 24%|██▍       | 217896/900675 [00:36<01:56, 5869.33it/s] 24%|██▍       | 218512/900675 [00:36<01:54, 5954.10it/s] 24%|██▍       | 219136/900675 [00:36<01:52, 6036.59it/s] 24%|██▍       | 219742/900675 [00:36<01:56, 5821.65it/s] 24%|██▍       | 220361/900675 [00:37<01:54, 5925.50it/s] 25%|██▍       | 220956/900675 [00:37<01:57, 5801.24it/s] 25%|██▍       | 221575/900675 [00:37<01:54, 5910.48it/s] 25%|██▍       | 222168/900675 [00:37<01:58, 5720.29it/s] 25%|██▍       | 222743/900675 [00:37<02:00, 5616.63it/s] 25%|██▍       | 223307/900675 [00:37<02:03, 5492.81it/s] 25%|██▍       | 223858/900675 [00:37<02:03, 5482.24it/s] 25%|██▍       | 224545/900675 [00:37<01:54, 5884.06it/s] 25%|██▍       | 225140/900675 [00:37<01:54, 5900.94it/s] 25%|██▌       | 225872/900675 [00:37<01:46, 6318.54it/s] 25%|██▌       | 226506/900675 [00:38<01:47, 6279.95it/s] 25%|██▌       | 227136/900675 [00:38<01:49, 6125.33it/s] 25%|██▌       | 227751/900675 [00:38<01:55, 5840.82it/s] 25%|██▌       | 228365/900675 [00:38<01:53, 5918.58it/s] 25%|██▌       | 228960/900675 [00:38<01:56, 5741.47it/s] 25%|██▌       | 229537/900675 [00:38<01:59, 5610.63it/s] 26%|██▌       | 230100/900675 [00:38<02:01, 5519.02it/s] 26%|██▌       | 230739/900675 [00:38<01:56, 5763.35it/s] 26%|██▌       | 231318/900675 [00:38<01:57, 5719.15it/s] 26%|██▌       | 231892/900675 [00:39<02:00, 5569.66it/s] 26%|██▌       | 232464/900675 [00:39<01:59, 5612.32it/s] 26%|██▌       | 233213/900675 [00:39<01:48, 6158.03it/s] 26%|██▌       | 233840/900675 [00:39<01:47, 6180.79it/s] 26%|██▌       | 234544/900675 [00:39<01:43, 6430.75it/s] 26%|██▌       | 235207/900675 [00:39<01:42, 6489.43it/s] 26%|██▌       | 235858/900675 [00:39<01:45, 6315.76it/s] 26%|██▋       | 236492/900675 [00:39<01:53, 5856.45it/s] 26%|██▋       | 237098/900675 [00:39<01:52, 5909.65it/s] 26%|██▋       | 237714/900675 [00:39<01:50, 5979.23it/s] 26%|██▋       | 238317/900675 [00:40<01:51, 5961.45it/s] 27%|██▋       | 238971/900675 [00:40<01:48, 6121.71it/s] 27%|██▋       | 239586/900675 [00:40<01:48, 6071.03it/s] 27%|██▋       | 240195/900675 [00:40<01:54, 5789.80it/s] 27%|██▋       | 240975/900675 [00:40<01:43, 6359.69it/s] 27%|██▋       | 241622/900675 [00:40<01:43, 6390.73it/s] 27%|██▋       | 242265/900675 [00:40<01:43, 6368.95it/s] 27%|██▋       | 242905/900675 [00:40<01:45, 6218.78it/s] 27%|██▋       | 243561/900675 [00:40<01:44, 6314.06it/s] 27%|██▋       | 244195/900675 [00:41<01:48, 6024.51it/s] 27%|██▋       | 244811/900675 [00:41<01:48, 6056.49it/s] 27%|██▋       | 245420/900675 [00:41<01:50, 5916.33it/s] 27%|██▋       | 246103/900675 [00:41<01:46, 6170.96it/s] 27%|██▋       | 246855/900675 [00:41<01:39, 6560.09it/s] 27%|██▋       | 247515/900675 [00:41<01:43, 6325.64it/s] 28%|██▊       | 248152/900675 [00:41<01:45, 6171.43it/s] 28%|██▊       | 248787/900675 [00:41<01:44, 6221.24it/s] 28%|██▊       | 249460/900675 [00:41<01:42, 6367.23it/s] 28%|██▊       | 250099/900675 [00:41<01:42, 6365.21it/s] 28%|██▊       | 250737/900675 [00:42<01:43, 6262.71it/s] 28%|██▊       | 251385/900675 [00:42<01:42, 6326.18it/s] 28%|██▊       | 252019/900675 [00:42<01:44, 6185.27it/s] 28%|██▊       | 252640/900675 [00:42<01:44, 6187.99it/s] 28%|██▊       | 253260/900675 [00:42<01:49, 5925.32it/s] 28%|██▊       | 253980/900675 [00:42<01:42, 6289.09it/s] 28%|██▊       | 254613/900675 [00:42<01:47, 5982.30it/s] 28%|██▊       | 255220/900675 [00:42<01:47, 5999.58it/s] 28%|██▊       | 255941/900675 [00:42<01:41, 6337.96it/s] 28%|██▊       | 256579/900675 [00:43<01:44, 6172.45it/s] 29%|██▊       | 257230/900675 [00:43<01:42, 6268.48it/s] 29%|██▊       | 257878/900675 [00:43<01:41, 6325.00it/s] 29%|██▊       | 258513/900675 [00:43<01:54, 5630.32it/s] 29%|██▉       | 259091/900675 [00:43<01:54, 5582.95it/s] 29%|██▉       | 259682/900675 [00:43<01:53, 5667.56it/s] 29%|██▉       | 260300/900675 [00:43<01:50, 5808.33it/s] 29%|██▉       | 261039/900675 [00:43<01:42, 6259.99it/s] 29%|██▉       | 261672/900675 [00:43<01:43, 6179.27it/s] 29%|██▉       | 262295/900675 [00:44<01:49, 5839.97it/s] 29%|██▉       | 262886/900675 [00:44<01:49, 5838.54it/s] 29%|██▉       | 263475/900675 [00:44<01:52, 5688.63it/s] 29%|██▉       | 264061/900675 [00:44<01:50, 5736.86it/s] 29%|██▉       | 264649/900675 [00:44<01:50, 5773.13it/s] 29%|██▉       | 265229/900675 [00:44<01:50, 5773.19it/s] 30%|██▉       | 265808/900675 [00:44<01:51, 5699.09it/s] 30%|██▉       | 266405/900675 [00:44<01:49, 5772.63it/s] 30%|██▉       | 266984/900675 [00:44<01:52, 5628.38it/s] 30%|██▉       | 267567/900675 [00:44<01:51, 5681.35it/s] 30%|██▉       | 268142/900675 [00:45<01:51, 5690.50it/s] 30%|██▉       | 268764/900675 [00:45<01:48, 5844.08it/s] 30%|██▉       | 269416/900675 [00:45<01:44, 6043.17it/s] 30%|██▉       | 270022/900675 [00:45<01:47, 5866.23it/s] 30%|███       | 270645/900675 [00:45<01:45, 5970.42it/s] 30%|███       | 271244/900675 [00:45<01:46, 5891.55it/s] 30%|███       | 271893/900675 [00:45<01:43, 6062.63it/s] 30%|███       | 272628/900675 [00:45<01:37, 6437.55it/s] 30%|███       | 273281/900675 [00:45<01:37, 6459.07it/s] 30%|███       | 273928/900675 [00:45<01:37, 6431.89it/s] 30%|███       | 274572/900675 [00:46<01:40, 6225.77it/s] 31%|███       | 275197/900675 [00:46<01:46, 5892.32it/s] 31%|███       | 275791/900675 [00:46<01:46, 5859.14it/s] 31%|███       | 276380/900675 [00:46<01:52, 5536.59it/s] 31%|███       | 276984/900675 [00:46<01:49, 5675.92it/s] 31%|███       | 277556/900675 [00:46<01:50, 5638.49it/s] 31%|███       | 278186/900675 [00:46<01:47, 5816.86it/s] 31%|███       | 278877/900675 [00:46<01:41, 6134.16it/s] 31%|███       | 279494/900675 [00:46<01:44, 5957.26it/s] 31%|███       | 280113/900675 [00:47<01:43, 6022.39it/s] 31%|███       | 280718/900675 [00:47<01:45, 5900.77it/s] 31%|███       | 281334/900675 [00:47<01:43, 5971.53it/s] 31%|███▏      | 281933/900675 [00:47<01:44, 5894.69it/s] 31%|███▏      | 282524/900675 [00:47<01:48, 5720.86it/s] 31%|███▏      | 283159/900675 [00:47<01:44, 5898.45it/s] 32%|███▏      | 283769/900675 [00:47<01:43, 5956.80it/s] 32%|███▏      | 284371/900675 [00:47<01:43, 5969.07it/s] 32%|███▏      | 284969/900675 [00:47<01:45, 5852.59it/s] 32%|███▏      | 285564/900675 [00:47<01:44, 5879.55it/s] 32%|███▏      | 286170/900675 [00:48<01:43, 5927.10it/s] 32%|███▏      | 286764/900675 [00:48<01:44, 5867.91it/s] 32%|███▏      | 287352/900675 [00:48<01:46, 5749.66it/s] 32%|███▏      | 288051/900675 [00:48<01:40, 6110.67it/s] 32%|███▏      | 288681/900675 [00:48<01:39, 6163.83it/s] 32%|███▏      | 289299/900675 [00:48<01:41, 6030.45it/s] 32%|███▏      | 289904/900675 [00:48<01:45, 5779.82it/s] 32%|███▏      | 290485/900675 [00:48<01:46, 5717.09it/s] 32%|███▏      | 291059/900675 [00:48<01:48, 5622.96it/s] 32%|███▏      | 291685/900675 [00:49<01:45, 5797.93it/s] 32%|███▏      | 292267/900675 [00:49<01:46, 5704.62it/s] 33%|███▎      | 292856/900675 [00:49<01:45, 5750.96it/s] 33%|███▎      | 293442/900675 [00:49<01:45, 5781.87it/s] 33%|███▎      | 294021/900675 [00:49<01:45, 5766.92it/s] 33%|███▎      | 294690/900675 [00:49<01:40, 6032.82it/s] 33%|███▎      | 295378/900675 [00:49<01:36, 6272.25it/s] 33%|███▎      | 296006/900675 [00:49<01:40, 6002.69it/s] 33%|███▎      | 296609/900675 [00:49<01:41, 5967.42it/s] 33%|███▎      | 297214/900675 [00:49<01:40, 5987.38it/s] 33%|███▎      | 297872/900675 [00:50<01:37, 6157.33it/s] 33%|███▎      | 298490/900675 [00:50<01:40, 5985.52it/s] 33%|███▎      | 299091/900675 [00:50<01:41, 5905.20it/s] 33%|███▎      | 299805/900675 [00:50<01:36, 6256.87it/s] 33%|███▎      | 300433/900675 [00:50<01:38, 6074.50it/s] 33%|███▎      | 301043/900675 [00:50<01:40, 5944.83it/s] 33%|███▎      | 301640/900675 [00:50<01:41, 5874.84it/s] 34%|███▎      | 302229/900675 [00:50<01:44, 5724.06it/s] 34%|███▎      | 302887/900675 [00:50<01:40, 5968.56it/s] 34%|███▎      | 303520/900675 [00:50<01:38, 6070.52it/s] 34%|███▍      | 304149/900675 [00:51<01:37, 6132.52it/s] 34%|███▍      | 304764/900675 [00:51<01:39, 6013.36it/s] 34%|███▍      | 305367/900675 [00:51<01:39, 5998.73it/s] 34%|███▍      | 305968/900675 [00:51<01:40, 5934.43it/s] 34%|███▍      | 306563/900675 [00:51<01:42, 5809.31it/s] 34%|███▍      | 307161/900675 [00:51<01:41, 5858.80it/s] 34%|███▍      | 307811/900675 [00:51<01:38, 6044.15it/s] 34%|███▍      | 308417/900675 [00:51<01:49, 5404.87it/s] 34%|███▍      | 309187/900675 [00:51<01:38, 6032.78it/s] 34%|███▍      | 309925/900675 [00:52<01:32, 6404.01it/s] 34%|███▍      | 310579/900675 [00:52<01:35, 6196.28it/s] 35%|███▍      | 311209/900675 [00:52<01:36, 6093.43it/s] 35%|███▍      | 311830/900675 [00:52<01:36, 6111.92it/s] 35%|███▍      | 312447/900675 [00:52<01:36, 6070.15it/s] 35%|███▍      | 313097/900675 [00:52<01:34, 6190.85it/s] 35%|███▍      | 313796/900675 [00:52<01:31, 6419.30it/s] 35%|███▍      | 314445/900675 [00:52<01:31, 6427.02it/s] 35%|███▍      | 315090/900675 [00:52<01:39, 5857.06it/s] 35%|███▌      | 315732/900675 [00:53<01:37, 6005.33it/s] 35%|███▌      | 316342/900675 [00:53<01:41, 5743.16it/s] 35%|███▌      | 316968/900675 [00:53<01:39, 5886.92it/s] 35%|███▌      | 317564/900675 [00:53<01:42, 5697.72it/s] 35%|███▌      | 318139/900675 [00:53<01:43, 5631.95it/s] 35%|███▌      | 318706/900675 [00:53<01:43, 5638.94it/s] 35%|███▌      | 319370/900675 [00:53<01:38, 5926.31it/s] 36%|███▌      | 319966/900675 [00:53<01:40, 5793.49it/s] 36%|███▌      | 320548/900675 [00:53<01:42, 5638.65it/s] 36%|███▌      | 321320/900675 [00:53<01:33, 6229.52it/s] 36%|███▌      | 321948/900675 [00:54<01:38, 5891.71it/s] 36%|███▌      | 322544/900675 [00:54<01:40, 5744.23it/s] 36%|███▌      | 323155/900675 [00:54<01:38, 5846.35it/s] 36%|███▌      | 323744/900675 [00:54<01:38, 5842.77it/s] 36%|███▌      | 324356/900675 [00:54<01:37, 5921.76it/s] 36%|███▌      | 324972/900675 [00:54<01:36, 5985.61it/s] 36%|███▌      | 325573/900675 [00:54<01:44, 5522.22it/s] 36%|███▌      | 326178/900675 [00:54<01:41, 5669.59it/s] 36%|███▋      | 326884/900675 [00:54<01:34, 6066.15it/s] 36%|███▋      | 327530/900675 [00:55<01:32, 6179.27it/s] 36%|███▋      | 328313/900675 [00:55<01:25, 6660.80it/s] 37%|███▋      | 328984/900675 [00:55<01:26, 6592.30it/s] 37%|███▋      | 329647/900675 [00:55<01:33, 6130.92it/s] 37%|███▋      | 330269/900675 [00:55<01:38, 5785.18it/s] 37%|███▋      | 330856/900675 [00:55<01:39, 5751.36it/s] 37%|███▋      | 331437/900675 [00:55<01:40, 5663.46it/s] 37%|███▋      | 332054/900675 [00:55<01:38, 5801.97it/s] 37%|███▋      | 332649/900675 [00:55<01:37, 5844.13it/s] 37%|███▋      | 333237/900675 [00:55<01:37, 5842.58it/s] 37%|███▋      | 333875/900675 [00:56<01:34, 5997.73it/s] 37%|███▋      | 334477/900675 [00:56<01:35, 5938.00it/s] 37%|███▋      | 335078/900675 [00:56<01:34, 5958.56it/s] 37%|███▋      | 335695/900675 [00:56<01:33, 6014.67it/s] 37%|███▋      | 336298/900675 [00:56<01:33, 6010.37it/s] 37%|███▋      | 336925/900675 [00:56<01:32, 6086.66it/s] 37%|███▋      | 337535/900675 [00:56<01:34, 5945.27it/s] 38%|███▊      | 338161/900675 [00:56<01:33, 6034.76it/s] 38%|███▊      | 338798/900675 [00:56<01:31, 6133.63it/s] 38%|███▊      | 339417/900675 [00:56<01:31, 6150.10it/s] 38%|███▊      | 340033/900675 [00:57<01:41, 5534.43it/s] 38%|███▊      | 340633/900675 [00:57<01:38, 5658.06it/s] 38%|███▊      | 341278/900675 [00:57<01:35, 5868.02it/s] 38%|███▊      | 341873/900675 [00:57<01:35, 5828.13it/s] 38%|███▊      | 342559/900675 [00:57<01:31, 6123.31it/s] 38%|███▊      | 343177/900675 [00:57<01:33, 5964.58it/s] 38%|███▊      | 343889/900675 [00:57<01:28, 6291.92it/s] 38%|███▊      | 344523/900675 [00:57<01:35, 5826.89it/s] 38%|███▊      | 345217/900675 [00:57<01:30, 6130.70it/s] 38%|███▊      | 345839/900675 [00:58<01:39, 5569.14it/s] 38%|███▊      | 346540/900675 [00:58<01:33, 5951.74it/s] 39%|███▊      | 347150/900675 [00:58<01:34, 5886.20it/s] 39%|███▊      | 347751/900675 [00:58<01:33, 5916.94it/s] 39%|███▊      | 348350/900675 [00:58<01:35, 5758.51it/s] 39%|███▊      | 348967/900675 [00:58<01:33, 5874.93it/s] 39%|███▉      | 349580/900675 [00:58<01:32, 5947.59it/s] 39%|███▉      | 350406/900675 [00:58<01:23, 6615.33it/s] 39%|███▉      | 351072/900675 [00:58<01:29, 6158.10it/s] 39%|███▉      | 351697/900675 [00:59<01:29, 6164.73it/s] 39%|███▉      | 352320/900675 [00:59<01:35, 5719.83it/s] 39%|███▉      | 352902/900675 [00:59<01:38, 5554.36it/s] 39%|███▉      | 353542/900675 [00:59<01:34, 5782.86it/s] 39%|███▉      | 354127/900675 [00:59<01:37, 5581.50it/s] 39%|███▉      | 354830/900675 [00:59<01:31, 5981.60it/s] 39%|███▉      | 355435/900675 [00:59<01:35, 5717.85it/s] 40%|███▉      | 356097/900675 [00:59<01:31, 5969.53it/s] 40%|███▉      | 356701/900675 [00:59<01:32, 5873.29it/s] 40%|███▉      | 357293/900675 [01:00<01:40, 5418.12it/s] 40%|███▉      | 357943/900675 [01:00<01:35, 5712.63it/s] 40%|███▉      | 358524/900675 [01:00<01:34, 5734.49it/s] 40%|███▉      | 359114/900675 [01:00<01:33, 5781.31it/s] 40%|███▉      | 359730/900675 [01:00<01:31, 5888.58it/s] 40%|████      | 360367/900675 [01:00<01:29, 6029.15it/s] 40%|████      | 361012/900675 [01:00<01:27, 6148.80it/s] 40%|████      | 361641/900675 [01:00<01:27, 6188.45it/s] 40%|████      | 362331/900675 [01:00<01:24, 6395.78it/s] 40%|████      | 362984/900675 [01:00<01:23, 6431.00it/s] 40%|████      | 363629/900675 [01:01<01:24, 6359.04it/s] 40%|████      | 364296/900675 [01:01<01:23, 6447.76it/s] 41%|████      | 364942/900675 [01:01<01:23, 6437.81it/s] 41%|████      | 365602/900675 [01:01<01:22, 6479.41it/s] 41%|████      | 366251/900675 [01:01<01:22, 6470.00it/s] 41%|████      | 366899/900675 [01:01<01:28, 6045.82it/s] 41%|████      | 367536/900675 [01:01<01:26, 6134.52it/s] 41%|████      | 368154/900675 [01:01<01:34, 5665.09it/s] 41%|████      | 368823/900675 [01:01<01:29, 5937.57it/s] 41%|████      | 369426/900675 [01:02<01:29, 5941.27it/s] 41%|████      | 370065/900675 [01:02<01:27, 6069.16it/s] 41%|████      | 370677/900675 [01:02<01:30, 5868.36it/s] 41%|████      | 371269/900675 [01:02<01:30, 5837.89it/s] 41%|████▏     | 371856/900675 [01:02<01:32, 5725.84it/s] 41%|████▏     | 372431/900675 [01:02<01:32, 5695.93it/s] 41%|████▏     | 373065/900675 [01:02<01:29, 5882.11it/s] 41%|████▏     | 373655/900675 [01:02<01:29, 5858.10it/s] 42%|████▏     | 374306/900675 [01:02<01:27, 6049.20it/s] 42%|████▏     | 374946/900675 [01:02<01:25, 6143.17it/s] 42%|████▏     | 375562/900675 [01:03<01:32, 5692.08it/s] 42%|████▏     | 376166/900675 [01:03<01:30, 5785.53it/s] 42%|████▏     | 376751/900675 [01:03<01:34, 5554.93it/s] 42%|████▏     | 377351/900675 [01:03<01:32, 5678.38it/s] 42%|████▏     | 377965/900675 [01:03<01:29, 5808.91it/s] 42%|████▏     | 378566/900675 [01:03<01:29, 5860.96it/s] 42%|████▏     | 379202/900675 [01:03<01:26, 6001.06it/s] 42%|████▏     | 379888/900675 [01:03<01:23, 6254.22it/s] 42%|████▏     | 380516/900675 [01:03<01:24, 6153.24it/s] 42%|████▏     | 381224/900675 [01:04<01:20, 6421.28it/s] 42%|████▏     | 381868/900675 [01:04<01:23, 6192.63it/s] 42%|████▏     | 382490/900675 [01:04<01:29, 5814.61it/s] 43%|████▎     | 383078/900675 [01:04<01:31, 5686.45it/s] 43%|████▎     | 383651/900675 [01:04<01:30, 5692.99it/s] 43%|████▎     | 384333/900675 [01:04<01:25, 6011.24it/s] 43%|████▎     | 384966/900675 [01:04<01:24, 6103.47it/s] 43%|████▎     | 385580/900675 [01:04<01:25, 6000.02it/s] 43%|████▎     | 386183/900675 [01:04<01:28, 5823.56it/s] 43%|████▎     | 386768/900675 [01:04<01:28, 5819.15it/s] 43%|████▎     | 387520/900675 [01:05<01:21, 6308.29it/s] 43%|████▎     | 388154/900675 [01:05<01:22, 6243.05it/s] 43%|████▎     | 388781/900675 [01:05<01:24, 6047.51it/s] 43%|████▎     | 389425/900675 [01:05<01:23, 6155.56it/s] 43%|████▎     | 390051/900675 [01:05<01:22, 6179.11it/s] 43%|████▎     | 390682/900675 [01:05<01:22, 6212.11it/s] 43%|████▎     | 391305/900675 [01:05<01:26, 5904.89it/s] 44%|████▎     | 391900/900675 [01:05<01:29, 5706.81it/s] 44%|████▎     | 392524/900675 [01:05<01:26, 5847.97it/s] 44%|████▎     | 393112/900675 [01:06<01:28, 5766.36it/s] 44%|████▎     | 393691/900675 [01:06<01:30, 5598.40it/s] 44%|████▍     | 394343/900675 [01:06<01:26, 5846.95it/s] 44%|████▍     | 394931/900675 [01:06<01:28, 5726.37it/s] 44%|████▍     | 395558/900675 [01:06<01:25, 5877.06it/s] 44%|████▍     | 396168/900675 [01:06<01:24, 5940.17it/s] 44%|████▍     | 396764/900675 [01:06<01:27, 5771.21it/s] 44%|████▍     | 397344/900675 [01:06<01:31, 5506.12it/s] 44%|████▍     | 397970/900675 [01:06<01:27, 5718.75it/s] 44%|████▍     | 398679/900675 [01:06<01:22, 6111.04it/s] 44%|████▍     | 399295/900675 [01:07<01:22, 6070.85it/s] 44%|████▍     | 400032/900675 [01:07<01:17, 6441.96it/s] 44%|████▍     | 400680/900675 [01:07<01:19, 6304.69it/s] 45%|████▍     | 401313/900675 [01:07<01:21, 6157.89it/s] 45%|████▍     | 401931/900675 [01:07<01:26, 5758.68it/s] 45%|████▍     | 402513/900675 [01:07<01:32, 5366.09it/s] 45%|████▍     | 403110/900675 [01:07<01:29, 5528.77it/s] 45%|████▍     | 403730/900675 [01:07<01:27, 5706.43it/s] 45%|████▍     | 404307/900675 [01:07<01:28, 5625.10it/s] 45%|████▍     | 404969/900675 [01:08<01:23, 5903.37it/s] 45%|████▌     | 405564/900675 [01:08<01:29, 5559.82it/s] 45%|████▌     | 406132/900675 [01:08<01:28, 5590.28it/s] 45%|████▌     | 406696/900675 [01:08<01:30, 5431.65it/s] 45%|████▌     | 407354/900675 [01:08<01:25, 5755.05it/s] 45%|████▌     | 407934/900675 [01:08<01:29, 5494.68it/s] 45%|████▌     | 408549/900675 [01:08<01:26, 5674.87it/s] 45%|████▌     | 409180/900675 [01:08<01:24, 5846.86it/s] 45%|████▌     | 409769/900675 [01:08<01:25, 5753.16it/s] 46%|████▌     | 410348/900675 [01:09<01:26, 5690.01it/s] 46%|████▌     | 410983/900675 [01:09<01:23, 5875.90it/s] 46%|████▌     | 411573/900675 [01:09<01:25, 5688.12it/s] 46%|████▌     | 412145/900675 [01:09<01:26, 5638.75it/s] 46%|████▌     | 412711/900675 [01:09<01:35, 5122.78it/s] 46%|████▌     | 413247/900675 [01:09<01:33, 5186.08it/s] 46%|████▌     | 413846/900675 [01:09<01:30, 5403.02it/s] 46%|████▌     | 414393/900675 [01:09<01:34, 5135.84it/s] 46%|████▌     | 414913/900675 [01:09<01:36, 5036.68it/s] 46%|████▌     | 415515/900675 [01:09<01:31, 5308.12it/s] 46%|████▌     | 416084/900675 [01:10<01:29, 5416.16it/s] 46%|████▋     | 416636/900675 [01:10<01:28, 5441.61it/s] 46%|████▋     | 417184/900675 [01:10<01:29, 5431.03it/s] 46%|████▋     | 417758/900675 [01:10<01:27, 5520.32it/s] 46%|████▋     | 418312/900675 [01:10<01:28, 5471.90it/s] 47%|████▋     | 418887/900675 [01:10<01:26, 5549.28it/s] 47%|████▋     | 419466/900675 [01:10<01:25, 5616.57it/s] 47%|████▋     | 420066/900675 [01:10<01:23, 5729.86it/s] 47%|████▋     | 420640/900675 [01:10<01:23, 5725.52it/s] 47%|████▋     | 421213/900675 [01:11<01:28, 5406.03it/s] 47%|████▋     | 421767/900675 [01:11<01:27, 5442.61it/s] 47%|████▋     | 422317/900675 [01:11<01:27, 5458.87it/s] 47%|████▋     | 422986/900675 [01:11<01:22, 5819.94it/s] 47%|████▋     | 423573/900675 [01:11<01:21, 5834.41it/s] 47%|████▋     | 424159/900675 [01:11<01:24, 5660.02it/s] 47%|████▋     | 424728/900675 [01:11<01:24, 5610.39it/s] 47%|████▋     | 425291/900675 [01:11<01:26, 5514.62it/s] 47%|████▋     | 425924/900675 [01:11<01:22, 5747.27it/s] 47%|████▋     | 426674/900675 [01:11<01:15, 6249.52it/s] 47%|████▋     | 427302/900675 [01:12<01:19, 5985.08it/s] 48%|████▊     | 427905/900675 [01:12<01:20, 5886.83it/s] 48%|████▊     | 428650/900675 [01:12<01:14, 6330.30it/s] 48%|████▊     | 429287/900675 [01:12<01:16, 6150.14it/s] 48%|████▊     | 429906/900675 [01:12<01:17, 6079.80it/s] 48%|████▊     | 430517/900675 [01:12<01:19, 5933.86it/s] 48%|████▊     | 431113/900675 [01:12<01:22, 5666.97it/s] 48%|████▊     | 431683/900675 [01:12<01:24, 5565.36it/s] 48%|████▊     | 432267/900675 [01:12<01:23, 5641.15it/s] 48%|████▊     | 433110/900675 [01:13<01:12, 6441.23it/s] 48%|████▊     | 433759/900675 [01:13<01:16, 6092.81it/s] 48%|████▊     | 434375/900675 [01:13<01:21, 5704.24it/s] 48%|████▊     | 434954/900675 [01:13<01:23, 5577.03it/s] 48%|████▊     | 435606/900675 [01:13<01:19, 5833.27it/s] 48%|████▊     | 436196/900675 [01:13<01:22, 5648.34it/s] 48%|████▊     | 436807/900675 [01:13<01:20, 5777.50it/s] 49%|████▊     | 437412/900675 [01:13<01:19, 5853.88it/s] 49%|████▊     | 438001/900675 [01:13<01:19, 5805.27it/s] 49%|████▊     | 438584/900675 [01:13<01:20, 5746.86it/s] 49%|████▉     | 439161/900675 [01:14<01:22, 5612.21it/s] 49%|████▉     | 439724/900675 [01:14<01:23, 5496.27it/s] 49%|████▉     | 440275/900675 [01:14<01:24, 5448.88it/s] 49%|████▉     | 440878/900675 [01:14<01:21, 5616.01it/s] 49%|████▉     | 441502/900675 [01:14<01:19, 5795.40it/s] 49%|████▉     | 442092/900675 [01:14<01:18, 5823.53it/s] 49%|████▉     | 442676/900675 [01:14<01:19, 5773.77it/s] 49%|████▉     | 443334/900675 [01:14<01:16, 6009.50it/s] 49%|████▉     | 443977/900675 [01:14<01:14, 6133.98it/s] 49%|████▉     | 444592/900675 [01:15<01:19, 5709.65it/s] 49%|████▉     | 445170/900675 [01:15<01:22, 5510.27it/s] 49%|████▉     | 445756/900675 [01:15<01:21, 5607.53it/s] 50%|████▉     | 446321/900675 [01:15<01:22, 5519.32it/s] 50%|████▉     | 446928/900675 [01:15<01:19, 5676.26it/s] 50%|████▉     | 447541/900675 [01:15<01:18, 5806.54it/s] 50%|████▉     | 448126/900675 [01:15<01:17, 5816.01it/s] 50%|████▉     | 448794/900675 [01:15<01:14, 6070.39it/s] 50%|████▉     | 449403/900675 [01:15<01:17, 5845.41it/s] 50%|████▉     | 449991/900675 [01:15<01:18, 5715.48it/s] 50%|█████     | 450671/900675 [01:16<01:14, 6023.25it/s] 50%|█████     | 451277/900675 [01:16<01:14, 6008.89it/s] 50%|█████     | 451880/900675 [01:16<01:15, 5906.63it/s] 50%|█████     | 452473/900675 [01:16<01:18, 5691.92it/s] 50%|█████     | 453064/900675 [01:16<01:17, 5751.49it/s] 50%|█████     | 453662/900675 [01:16<01:16, 5812.80it/s] 50%|█████     | 454245/900675 [01:16<01:18, 5712.85it/s] 50%|█████     | 454818/900675 [01:16<01:19, 5642.52it/s] 51%|█████     | 455390/900675 [01:16<01:18, 5659.11it/s] 51%|█████     | 455971/900675 [01:17<01:18, 5697.35it/s] 51%|█████     | 456658/900675 [01:17<01:13, 6037.35it/s] 51%|█████     | 457364/900675 [01:17<01:09, 6337.79it/s] 51%|█████     | 457999/900675 [01:17<01:12, 6146.38it/s] 51%|█████     | 458616/900675 [01:17<01:17, 5693.38it/s] 51%|█████     | 459283/900675 [01:17<01:14, 5958.39it/s] 51%|█████     | 459886/900675 [01:17<01:14, 5899.48it/s] 51%|█████     | 460481/900675 [01:17<01:15, 5802.14it/s] 51%|█████     | 461065/900675 [01:17<01:17, 5676.15it/s] 51%|█████▏    | 461699/900675 [01:17<01:14, 5860.05it/s] 51%|█████▏    | 462288/900675 [01:18<01:17, 5664.73it/s] 51%|█████▏    | 462914/900675 [01:18<01:15, 5826.57it/s] 51%|█████▏    | 463515/900675 [01:18<01:14, 5879.50it/s] 52%|█████▏    | 464106/900675 [01:18<01:16, 5703.99it/s] 52%|█████▏    | 464708/900675 [01:18<01:15, 5790.62it/s] 52%|█████▏    | 465335/900675 [01:18<01:13, 5917.80it/s] 52%|█████▏    | 465954/900675 [01:18<01:12, 5990.54it/s] 52%|█████▏    | 466555/900675 [01:18<01:13, 5899.69it/s] 52%|█████▏    | 467147/900675 [01:18<01:14, 5826.94it/s] 52%|█████▏    | 467763/900675 [01:19<01:13, 5924.03it/s] 52%|█████▏    | 468357/900675 [01:19<01:12, 5926.92it/s] 52%|█████▏    | 468985/900675 [01:19<01:11, 6023.36it/s] 52%|█████▏    | 469588/900675 [01:19<01:13, 5870.99it/s] 52%|█████▏    | 470177/900675 [01:19<01:16, 5628.41it/s] 52%|█████▏    | 470894/900675 [01:19<01:10, 6066.58it/s] 52%|█████▏    | 471528/900675 [01:19<01:09, 6145.00it/s] 52%|█████▏    | 472146/900675 [01:19<01:14, 5761.11it/s] 52%|█████▏    | 472759/900675 [01:19<01:13, 5855.93it/s] 53%|█████▎    | 473393/900675 [01:19<01:11, 5992.47it/s] 53%|█████▎    | 473997/900675 [01:20<01:13, 5776.14it/s] 53%|█████▎    | 474580/900675 [01:20<01:13, 5789.41it/s] 53%|█████▎    | 475314/900675 [01:20<01:08, 6237.77it/s] 53%|█████▎    | 476055/900675 [01:20<01:04, 6580.24it/s] 53%|█████▎    | 476717/900675 [01:20<01:09, 6094.18it/s] 53%|█████▎    | 477336/900675 [01:20<01:11, 5953.69it/s] 53%|█████▎    | 477938/900675 [01:20<01:11, 5872.31it/s] 53%|█████▎    | 478624/900675 [01:20<01:08, 6148.99it/s] 53%|█████▎    | 479296/900675 [01:20<01:06, 6305.91it/s] 53%|█████▎    | 479931/900675 [01:21<01:09, 6093.04it/s] 53%|█████▎    | 480545/900675 [01:21<01:09, 6050.58it/s] 53%|█████▎    | 481178/900675 [01:21<01:08, 6126.75it/s] 53%|█████▎    | 481793/900675 [01:21<01:12, 5763.64it/s] 54%|█████▎    | 482375/900675 [01:21<01:13, 5707.73it/s] 54%|█████▎    | 483025/900675 [01:21<01:10, 5931.83it/s] 54%|█████▎    | 483622/900675 [01:21<01:13, 5701.05it/s] 54%|█████▍    | 484265/900675 [01:21<01:10, 5904.30it/s] 54%|█████▍    | 484959/900675 [01:21<01:07, 6201.11it/s] 54%|█████▍    | 485665/900675 [01:21<01:04, 6441.80it/s] 54%|█████▍    | 486313/900675 [01:22<01:08, 6019.63it/s] 54%|█████▍    | 486923/900675 [01:22<01:10, 5883.54it/s] 54%|█████▍    | 487565/900675 [01:22<01:08, 6025.46it/s] 54%|█████▍    | 488187/900675 [01:22<01:07, 6080.27it/s] 54%|█████▍    | 488799/900675 [01:22<01:08, 5990.62it/s] 54%|█████▍    | 489401/900675 [01:22<01:10, 5850.86it/s] 54%|█████▍    | 489989/900675 [01:22<01:12, 5658.68it/s] 54%|█████▍    | 490558/900675 [01:22<01:13, 5606.65it/s] 55%|█████▍    | 491121/900675 [01:22<01:13, 5599.56it/s] 55%|█████▍    | 491782/900675 [01:23<01:09, 5892.16it/s] 55%|█████▍    | 492392/900675 [01:23<01:08, 5948.62it/s] 55%|█████▍    | 492992/900675 [01:23<01:08, 5962.53it/s] 55%|█████▍    | 493590/900675 [01:23<01:10, 5812.27it/s] 55%|█████▍    | 494222/900675 [01:23<01:08, 5958.37it/s] 55%|█████▍    | 494919/900675 [01:23<01:04, 6255.64it/s] 55%|█████▌    | 495547/900675 [01:23<01:07, 6028.62it/s] 55%|█████▌    | 496174/900675 [01:23<01:06, 6093.33it/s] 55%|█████▌    | 496786/900675 [01:23<01:06, 6099.74it/s] 55%|█████▌    | 497398/900675 [01:23<01:06, 6094.31it/s] 55%|█████▌    | 498015/900675 [01:24<01:05, 6115.21it/s] 55%|█████▌    | 498628/900675 [01:24<01:06, 6082.69it/s] 55%|█████▌    | 499238/900675 [01:24<01:06, 6081.24it/s] 56%|█████▌    | 499918/900675 [01:24<01:03, 6291.22it/s] 56%|█████▌    | 500548/900675 [01:24<01:06, 6020.58it/s] 56%|█████▌    | 501153/900675 [01:24<01:06, 6028.65it/s] 56%|█████▌    | 501758/900675 [01:24<01:09, 5743.49it/s] 56%|█████▌    | 502336/900675 [01:24<01:09, 5724.88it/s] 56%|█████▌    | 502939/900675 [01:24<01:08, 5809.11it/s] 56%|█████▌    | 503530/900675 [01:25<01:08, 5838.18it/s] 56%|█████▌    | 504116/900675 [01:25<01:11, 5530.57it/s] 56%|█████▌    | 504709/900675 [01:25<01:10, 5643.76it/s] 56%|█████▌    | 505388/900675 [01:25<01:06, 5971.66it/s] 56%|█████▌    | 505994/900675 [01:25<01:05, 5995.01it/s] 56%|█████▋    | 506658/900675 [01:25<01:03, 6178.45it/s] 56%|█████▋    | 507278/900675 [01:25<01:05, 5983.35it/s] 56%|█████▋    | 507879/900675 [01:25<01:09, 5622.04it/s] 56%|█████▋    | 508447/900675 [01:25<01:09, 5614.61it/s] 57%|█████▋    | 509062/900675 [01:25<01:07, 5764.51it/s] 57%|█████▋    | 509731/900675 [01:26<01:04, 6032.02it/s] 57%|█████▋    | 510338/900675 [01:26<01:05, 5926.14it/s] 57%|█████▋    | 510934/900675 [01:26<01:05, 5926.26it/s] 57%|█████▋    | 511715/900675 [01:26<01:00, 6477.62it/s] 57%|█████▋    | 512366/900675 [01:26<01:04, 5994.77it/s] 57%|█████▋    | 513052/900675 [01:26<01:02, 6235.82it/s] 57%|█████▋    | 513684/900675 [01:26<01:03, 6125.63it/s] 57%|█████▋    | 514302/900675 [01:26<01:03, 6039.65it/s] 57%|█████▋    | 514910/900675 [01:26<01:04, 5942.98it/s] 57%|█████▋    | 515516/900675 [01:27<01:04, 5969.73it/s] 57%|█████▋    | 516153/900675 [01:27<01:03, 6075.54it/s] 57%|█████▋    | 516763/900675 [01:27<01:05, 5819.46it/s] 57%|█████▋    | 517348/900675 [01:27<01:07, 5707.85it/s] 58%|█████▊    | 518024/900675 [01:27<01:03, 6005.65it/s] 58%|█████▊    | 518654/900675 [01:27<01:02, 6087.98it/s] 58%|█████▊    | 519266/900675 [01:27<01:05, 5846.99it/s] 58%|█████▊    | 519916/900675 [01:27<01:03, 6029.36it/s] 58%|█████▊    | 520523/900675 [01:27<01:04, 5902.81it/s] 58%|█████▊    | 521207/900675 [01:27<01:01, 6172.78it/s] 58%|█████▊    | 521828/900675 [01:28<01:02, 6062.17it/s] 58%|█████▊    | 522440/900675 [01:28<01:02, 6075.94it/s] 58%|█████▊    | 523050/900675 [01:28<01:05, 5767.91it/s] 58%|█████▊    | 523642/900675 [01:28<01:04, 5805.12it/s] 58%|█████▊    | 524277/900675 [01:28<01:03, 5960.94it/s] 58%|█████▊    | 524876/900675 [01:28<01:03, 5940.79it/s] 58%|█████▊    | 525472/900675 [01:28<01:09, 5372.31it/s] 58%|█████▊    | 526219/900675 [01:28<01:02, 5945.00it/s] 58%|█████▊    | 526890/900675 [01:28<01:00, 6160.28it/s] 59%|█████▊    | 527517/900675 [01:29<01:01, 6056.98it/s] 59%|█████▊    | 528131/900675 [01:29<01:02, 5951.98it/s] 59%|█████▊    | 528779/900675 [01:29<01:00, 6102.18it/s] 59%|█████▉    | 529394/900675 [01:29<01:00, 6113.64it/s] 59%|█████▉    | 530009/900675 [01:29<01:02, 5889.17it/s] 59%|█████▉    | 530602/900675 [01:29<01:05, 5613.14it/s] 59%|█████▉    | 531224/900675 [01:29<01:03, 5782.58it/s] 59%|█████▉    | 531870/900675 [01:29<01:01, 5971.24it/s] 59%|█████▉    | 532471/900675 [01:29<01:03, 5802.15it/s] 59%|█████▉    | 533102/900675 [01:29<01:01, 5947.20it/s] 59%|█████▉    | 533700/900675 [01:30<01:03, 5743.30it/s] 59%|█████▉    | 534281/900675 [01:30<01:03, 5754.56it/s] 59%|█████▉    | 534870/900675 [01:30<01:03, 5787.42it/s] 59%|█████▉    | 535458/900675 [01:30<01:02, 5810.79it/s] 60%|█████▉    | 536041/900675 [01:30<01:03, 5732.46it/s] 60%|█████▉    | 536641/900675 [01:30<01:02, 5808.92it/s] 60%|█████▉    | 537254/900675 [01:30<01:01, 5903.35it/s] 60%|█████▉    | 537846/900675 [01:30<01:03, 5745.82it/s] 60%|█████▉    | 538491/900675 [01:30<01:00, 5948.81it/s] 60%|█████▉    | 539161/900675 [01:31<00:58, 6164.35it/s] 60%|█████▉    | 539779/900675 [01:31<01:01, 5856.36it/s] 60%|█████▉    | 540377/900675 [01:31<01:01, 5889.38it/s] 60%|██████    | 540969/900675 [01:31<01:01, 5830.08it/s] 60%|██████    | 541554/900675 [01:31<01:01, 5830.90it/s] 60%|██████    | 542139/900675 [01:31<01:04, 5529.19it/s] 60%|██████    | 542791/900675 [01:31<01:01, 5808.55it/s] 60%|██████    | 543440/900675 [01:31<00:59, 6001.20it/s] 60%|██████    | 544044/900675 [01:31<01:00, 5894.76it/s] 60%|██████    | 544637/900675 [01:31<01:02, 5689.09it/s] 61%|██████    | 545231/900675 [01:32<01:01, 5756.37it/s] 61%|██████    | 545813/900675 [01:32<01:01, 5767.88it/s] 61%|██████    | 546485/900675 [01:32<00:58, 6044.17it/s] 61%|██████    | 547092/900675 [01:32<01:01, 5728.87it/s] 61%|██████    | 547729/900675 [01:32<00:59, 5904.02it/s] 61%|██████    | 548410/900675 [01:32<00:57, 6165.55it/s] 61%|██████    | 549031/900675 [01:32<00:59, 5957.99it/s] 61%|██████    | 549631/900675 [01:32<00:58, 5961.18it/s] 61%|██████    | 550262/900675 [01:32<00:57, 6060.26it/s] 61%|██████    | 550884/900675 [01:33<00:57, 6104.91it/s] 61%|██████    | 551497/900675 [01:33<00:58, 6019.84it/s] 61%|██████▏   | 552101/900675 [01:33<00:58, 5993.89it/s] 61%|██████▏   | 552702/900675 [01:33<01:00, 5790.92it/s] 61%|██████▏   | 553298/900675 [01:33<00:59, 5833.88it/s] 61%|██████▏   | 553897/900675 [01:33<00:58, 5877.62it/s] 62%|██████▏   | 554486/900675 [01:33<01:00, 5753.30it/s] 62%|██████▏   | 555063/900675 [01:33<01:00, 5677.36it/s] 62%|██████▏   | 555725/900675 [01:33<00:57, 5950.72it/s] 62%|██████▏   | 556329/900675 [01:33<00:57, 5962.72it/s] 62%|██████▏   | 556941/900675 [01:34<00:57, 6001.12it/s] 62%|██████▏   | 557542/900675 [01:34<00:59, 5775.14it/s] 62%|██████▏   | 558122/900675 [01:34<00:59, 5755.21it/s] 62%|██████▏   | 558699/900675 [01:34<01:01, 5578.13it/s] 62%|██████▏   | 559259/900675 [01:34<01:02, 5455.15it/s] 62%|██████▏   | 559860/900675 [01:34<01:00, 5610.66it/s] 62%|██████▏   | 560423/900675 [01:34<01:00, 5601.28it/s] 62%|██████▏   | 561037/900675 [01:34<00:58, 5758.71it/s] 62%|██████▏   | 561716/900675 [01:34<00:55, 6057.24it/s] 62%|██████▏   | 562347/900675 [01:34<00:55, 6127.54it/s] 63%|██████▎   | 562981/900675 [01:35<00:54, 6187.35it/s] 63%|██████▎   | 563601/900675 [01:35<00:57, 5849.54it/s] 63%|██████▎   | 564254/900675 [01:35<00:55, 6037.89it/s] 63%|██████▎   | 564862/900675 [01:35<01:00, 5575.88it/s] 63%|██████▎   | 565530/900675 [01:35<00:57, 5877.23it/s] 63%|██████▎   | 566128/900675 [01:35<00:56, 5902.44it/s] 63%|██████▎   | 566725/900675 [01:35<01:00, 5550.62it/s] 63%|██████▎   | 567325/900675 [01:35<00:58, 5671.98it/s] 63%|██████▎   | 568031/900675 [01:35<00:54, 6064.01it/s] 63%|██████▎   | 568655/900675 [01:36<00:54, 6103.72it/s] 63%|██████▎   | 569288/900675 [01:36<00:53, 6169.09it/s] 63%|██████▎   | 569909/900675 [01:36<00:54, 6077.11it/s] 63%|██████▎   | 570570/900675 [01:36<00:52, 6232.20it/s] 63%|██████▎   | 571377/900675 [01:36<00:48, 6766.90it/s] 64%|██████▎   | 572057/900675 [01:36<00:50, 6457.49it/s] 64%|██████▎   | 572708/900675 [01:36<00:53, 6085.25it/s] 64%|██████▎   | 573324/900675 [01:36<00:54, 5954.00it/s] 64%|██████▎   | 573976/900675 [01:36<00:53, 6105.30it/s] 64%|██████▍   | 574591/900675 [01:37<00:56, 5805.28it/s] 64%|██████▍   | 575177/900675 [01:37<00:56, 5726.96it/s] 64%|██████▍   | 575786/900675 [01:37<00:55, 5829.05it/s] 64%|██████▍   | 576372/900675 [01:37<00:55, 5796.41it/s] 64%|██████▍   | 576989/900675 [01:37<00:54, 5902.04it/s] 64%|██████▍   | 577609/900675 [01:37<00:53, 5988.35it/s] 64%|██████▍   | 578210/900675 [01:37<00:57, 5574.78it/s] 64%|██████▍   | 578800/900675 [01:37<00:56, 5663.84it/s] 64%|██████▍   | 579421/900675 [01:37<00:55, 5818.20it/s] 64%|██████▍   | 580063/900675 [01:37<00:53, 5986.06it/s] 64%|██████▍   | 580696/900675 [01:38<00:52, 6083.18it/s] 65%|██████▍   | 581307/900675 [01:38<00:53, 5951.84it/s] 65%|██████▍   | 581925/900675 [01:38<00:52, 6017.88it/s] 65%|██████▍   | 582529/900675 [01:38<00:52, 6017.87it/s] 65%|██████▍   | 583189/900675 [01:38<00:51, 6186.64it/s] 65%|██████▍   | 583912/900675 [01:38<00:48, 6492.31it/s] 65%|██████▍   | 584563/900675 [01:38<00:48, 6491.75it/s] 65%|██████▍   | 585236/900675 [01:38<00:48, 6562.50it/s] 65%|██████▌   | 585893/900675 [01:38<00:50, 6282.29it/s] 65%|██████▌   | 586525/900675 [01:38<00:51, 6076.01it/s] 65%|██████▌   | 587136/900675 [01:39<00:55, 5647.62it/s] 65%|██████▌   | 587708/900675 [01:39<00:56, 5551.36it/s] 65%|██████▌   | 588321/900675 [01:39<00:54, 5711.92it/s] 65%|██████▌   | 588917/900675 [01:39<00:53, 5779.61it/s] 65%|██████▌   | 589516/900675 [01:39<00:53, 5838.07it/s] 66%|██████▌   | 590194/900675 [01:39<00:50, 6111.90it/s] 66%|██████▌   | 590832/900675 [01:39<00:50, 6186.32it/s] 66%|██████▌   | 591453/900675 [01:39<00:51, 5972.72it/s] 66%|██████▌   | 592092/900675 [01:39<00:50, 6091.65it/s] 66%|██████▌   | 592704/900675 [01:40<00:54, 5694.30it/s] 66%|██████▌   | 593280/900675 [01:40<00:54, 5638.12it/s] 66%|██████▌   | 593895/900675 [01:40<00:53, 5783.01it/s] 66%|██████▌   | 594503/900675 [01:40<00:52, 5868.51it/s] 66%|██████▌   | 595129/900675 [01:40<00:51, 5978.88it/s] 66%|██████▌   | 595730/900675 [01:40<00:53, 5679.86it/s] 66%|██████▌   | 596362/900675 [01:40<00:51, 5859.73it/s] 66%|██████▋   | 596992/900675 [01:40<00:50, 5986.45it/s] 66%|██████▋   | 597594/900675 [01:40<00:52, 5821.50it/s] 66%|██████▋   | 598183/900675 [01:41<00:51, 5832.24it/s] 66%|██████▋   | 598769/900675 [01:41<00:51, 5810.81it/s] 67%|██████▋   | 599399/900675 [01:41<00:50, 5953.84it/s] 67%|██████▋   | 600050/900675 [01:41<00:49, 6111.68it/s] 67%|██████▋   | 600663/900675 [01:41<00:49, 6042.17it/s] 67%|██████▋   | 601269/900675 [01:41<00:52, 5683.97it/s] 67%|██████▋   | 601843/900675 [01:41<00:54, 5484.13it/s] 67%|██████▋   | 602436/900675 [01:41<00:53, 5605.01it/s] 67%|██████▋   | 603024/900675 [01:41<00:52, 5675.82it/s] 67%|██████▋   | 603715/900675 [01:41<00:49, 6029.58it/s] 67%|██████▋   | 604322/900675 [01:42<00:50, 5917.94it/s] 67%|██████▋   | 604931/900675 [01:42<00:49, 5959.90it/s] 67%|██████▋   | 605529/900675 [01:42<00:52, 5671.14it/s] 67%|██████▋   | 606121/900675 [01:42<00:51, 5741.62it/s] 67%|██████▋   | 606796/900675 [01:42<00:48, 6027.73it/s] 67%|██████▋   | 607402/900675 [01:42<00:49, 5981.01it/s] 68%|██████▊   | 608003/900675 [01:42<00:49, 5928.13it/s] 68%|██████▊   | 608598/900675 [01:42<00:51, 5715.30it/s] 68%|██████▊   | 609172/900675 [01:42<00:51, 5624.56it/s] 68%|██████▊   | 609826/900675 [01:43<00:49, 5880.51it/s] 68%|██████▊   | 610553/900675 [01:43<00:46, 6272.66it/s] 68%|██████▊   | 611183/900675 [01:43<00:48, 6020.27it/s] 68%|██████▊   | 611824/900675 [01:43<00:47, 6128.82it/s] 68%|██████▊   | 612440/900675 [01:43<00:48, 5963.20it/s] 68%|██████▊   | 613054/900675 [01:43<00:47, 6013.54it/s] 68%|██████▊   | 613658/900675 [01:43<00:48, 5866.06it/s] 68%|██████▊   | 614247/900675 [01:43<00:50, 5657.99it/s] 68%|██████▊   | 614816/900675 [01:43<00:51, 5571.63it/s] 68%|██████▊   | 615448/900675 [01:43<00:49, 5779.86it/s] 68%|██████▊   | 616029/900675 [01:44<00:51, 5533.66it/s] 68%|██████▊   | 616793/900675 [01:44<00:46, 6128.24it/s] 69%|██████▊   | 617474/900675 [01:44<00:44, 6317.18it/s] 69%|██████▊   | 618151/900675 [01:44<00:43, 6436.30it/s] 69%|██████▊   | 618799/900675 [01:44<00:43, 6433.12it/s] 69%|██████▉   | 619541/900675 [01:44<00:41, 6722.39it/s] 69%|██████▉   | 620286/900675 [01:44<00:40, 6936.53it/s] 69%|██████▉   | 620982/900675 [01:44<00:40, 6859.37it/s] 69%|██████▉   | 621670/900675 [01:44<00:45, 6123.06it/s] 69%|██████▉   | 622298/900675 [01:45<00:45, 6059.59it/s] 69%|██████▉   | 623085/900675 [01:45<00:42, 6561.71it/s] 69%|██████▉   | 623753/900675 [01:45<00:44, 6281.02it/s] 69%|██████▉   | 624391/900675 [01:45<00:44, 6204.29it/s] 69%|██████▉   | 625018/900675 [01:45<00:44, 6152.14it/s] 69%|██████▉   | 625756/900675 [01:45<00:42, 6498.57it/s] 70%|██████▉   | 626411/900675 [01:45<00:43, 6376.70it/s] 70%|██████▉   | 627053/900675 [01:45<00:47, 5795.84it/s] 70%|██████▉   | 627678/900675 [01:45<00:46, 5916.52it/s] 70%|██████▉   | 628279/900675 [01:45<00:46, 5896.01it/s] 70%|██████▉   | 628885/900675 [01:46<00:45, 5939.29it/s] 70%|██████▉   | 629549/900675 [01:46<00:44, 6136.84it/s] 70%|██████▉   | 630167/900675 [01:46<00:46, 5765.09it/s] 70%|███████   | 630856/900675 [01:46<00:44, 6077.80it/s] 70%|███████   | 631583/900675 [01:46<00:41, 6416.01it/s] 70%|███████   | 632231/900675 [01:46<00:42, 6247.17it/s] 70%|███████   | 632915/900675 [01:46<00:41, 6414.14it/s] 70%|███████   | 633599/900675 [01:46<00:40, 6531.30it/s] 70%|███████   | 634256/900675 [01:46<00:41, 6403.19it/s] 70%|███████   | 634900/900675 [01:47<00:43, 6154.69it/s] 71%|███████   | 635542/900675 [01:47<00:42, 6226.99it/s] 71%|███████   | 636185/900675 [01:47<00:42, 6279.40it/s] 71%|███████   | 636816/900675 [01:47<00:45, 5857.78it/s] 71%|███████   | 637411/900675 [01:47<00:44, 5881.24it/s] 71%|███████   | 638123/900675 [01:47<00:42, 6231.17it/s] 71%|███████   | 638752/900675 [01:47<00:42, 6137.40it/s] 71%|███████   | 639370/900675 [01:47<00:43, 6036.62it/s] 71%|███████   | 639977/900675 [01:47<00:44, 5858.36it/s] 71%|███████   | 640637/900675 [01:48<00:42, 6069.13it/s] 71%|███████   | 641452/900675 [01:48<00:38, 6668.22it/s] 71%|███████▏  | 642123/900675 [01:48<00:40, 6314.42it/s] 71%|███████▏  | 642768/900675 [01:48<00:40, 6347.48it/s] 71%|███████▏  | 643408/900675 [01:48<00:44, 5829.73it/s] 72%|███████▏  | 644008/900675 [01:48<00:43, 5874.05it/s] 72%|███████▏  | 644603/900675 [01:48<00:44, 5778.61it/s] 72%|███████▏  | 645187/900675 [01:48<00:44, 5719.18it/s] 72%|███████▏  | 645934/900675 [01:48<00:40, 6217.38it/s] 72%|███████▏  | 646561/900675 [01:48<00:43, 5850.73it/s] 72%|███████▏  | 647154/900675 [01:49<00:44, 5752.18it/s] 72%|███████▏  | 647735/900675 [01:49<00:44, 5663.23it/s] 72%|███████▏  | 648305/900675 [01:49<00:48, 5248.44it/s] 72%|███████▏  | 648944/900675 [01:49<00:45, 5556.11it/s] 72%|███████▏  | 649508/900675 [01:49<00:47, 5334.35it/s] 72%|███████▏  | 650077/900675 [01:49<00:46, 5431.18it/s] 72%|███████▏  | 650626/900675 [01:49<00:46, 5413.50it/s] 72%|███████▏  | 651202/900675 [01:49<00:45, 5511.35it/s] 72%|███████▏  | 651905/900675 [01:49<00:41, 5949.23it/s] 72%|███████▏  | 652504/900675 [01:50<00:43, 5757.30it/s] 73%|███████▎  | 653218/900675 [01:50<00:40, 6152.99it/s] 73%|███████▎  | 653838/900675 [01:50<00:41, 5965.18it/s] 73%|███████▎  | 654523/900675 [01:50<00:39, 6214.52it/s] 73%|███████▎  | 655149/900675 [01:50<00:40, 6001.68it/s] 73%|███████▎  | 655783/900675 [01:50<00:40, 6096.06it/s] 73%|███████▎  | 656396/900675 [01:50<00:41, 5863.37it/s] 73%|███████▎  | 657015/900675 [01:50<00:40, 5955.84it/s] 73%|███████▎  | 657718/900675 [01:50<00:38, 6261.49it/s] 73%|███████▎  | 658348/900675 [01:51<00:40, 5941.93it/s] 73%|███████▎  | 658981/900675 [01:51<00:39, 6051.42it/s] 73%|███████▎  | 659594/900675 [01:51<00:39, 6064.53it/s] 73%|███████▎  | 660215/900675 [01:51<00:39, 6104.50it/s] 73%|███████▎  | 660828/900675 [01:51<00:39, 6044.50it/s] 73%|███████▎  | 661435/900675 [01:51<00:40, 5893.39it/s] 74%|███████▎  | 662091/900675 [01:51<00:39, 6084.06it/s] 74%|███████▎  | 662702/900675 [01:51<00:39, 6037.72it/s] 74%|███████▎  | 663308/900675 [01:51<00:40, 5870.90it/s] 74%|███████▎  | 663901/900675 [01:51<00:40, 5887.73it/s] 74%|███████▍  | 664544/900675 [01:52<00:39, 6046.09it/s] 74%|███████▍  | 665150/900675 [01:52<00:39, 6022.46it/s] 74%|███████▍  | 665802/900675 [01:52<00:38, 6162.66it/s] 74%|███████▍  | 666430/900675 [01:52<00:37, 6196.55it/s] 74%|███████▍  | 667051/900675 [01:52<00:38, 6006.94it/s] 74%|███████▍  | 667654/900675 [01:52<00:39, 5929.20it/s] 74%|███████▍  | 668278/900675 [01:52<00:38, 6018.42it/s] 74%|███████▍  | 668881/900675 [01:52<00:38, 5959.35it/s] 74%|███████▍  | 669552/900675 [01:52<00:37, 6179.47it/s] 74%|███████▍  | 670171/900675 [01:52<00:37, 6070.85it/s] 74%|███████▍  | 670785/900675 [01:53<00:37, 6085.10it/s] 75%|███████▍  | 671445/900675 [01:53<00:36, 6230.98it/s] 75%|███████▍  | 672069/900675 [01:53<00:37, 6120.68it/s] 75%|███████▍  | 672696/900675 [01:53<00:36, 6162.16it/s] 75%|███████▍  | 673313/900675 [01:53<00:36, 6164.32it/s] 75%|███████▍  | 673930/900675 [01:53<00:37, 6014.95it/s] 75%|███████▍  | 674533/900675 [01:53<00:37, 5991.59it/s] 75%|███████▍  | 675177/900675 [01:53<00:36, 6123.07it/s] 75%|███████▌  | 675842/900675 [01:53<00:35, 6276.78it/s] 75%|███████▌  | 676471/900675 [01:54<00:37, 5912.34it/s] 75%|███████▌  | 677067/900675 [01:54<00:38, 5870.38it/s] 75%|███████▌  | 677660/900675 [01:54<00:37, 5886.52it/s] 75%|███████▌  | 678251/900675 [01:54<00:37, 5887.14it/s] 75%|███████▌  | 678856/900675 [01:54<00:37, 5924.83it/s] 75%|███████▌  | 679450/900675 [01:54<00:38, 5721.54it/s] 76%|███████▌  | 680187/900675 [01:54<00:35, 6197.15it/s] 76%|███████▌  | 680810/900675 [01:54<00:36, 6105.76it/s] 76%|███████▌  | 681423/900675 [01:54<00:36, 5980.68it/s] 76%|███████▌  | 682023/900675 [01:54<00:37, 5907.23it/s] 76%|███████▌  | 682616/900675 [01:55<00:37, 5768.78it/s] 76%|███████▌  | 683271/900675 [01:55<00:36, 5992.10it/s] 76%|███████▌  | 683909/900675 [01:55<00:35, 6104.64it/s] 76%|███████▌  | 684602/900675 [01:55<00:34, 6345.80it/s] 76%|███████▌  | 685239/900675 [01:55<00:35, 6077.55it/s] 76%|███████▌  | 685851/900675 [01:55<00:35, 5994.53it/s] 76%|███████▌  | 686497/900675 [01:55<00:34, 6120.91it/s] 76%|███████▋  | 687112/900675 [01:55<00:37, 5693.34it/s] 76%|███████▋  | 687779/900675 [01:55<00:35, 5965.12it/s] 76%|███████▋  | 688383/900675 [01:56<00:35, 5956.04it/s] 76%|███████▋  | 688984/900675 [01:56<00:36, 5773.61it/s] 77%|███████▋  | 689579/900675 [01:56<00:36, 5821.87it/s] 77%|███████▋  | 690165/900675 [01:56<00:36, 5790.95it/s] 77%|███████▋  | 690747/900675 [01:56<00:36, 5693.27it/s] 77%|███████▋  | 691318/900675 [01:56<00:37, 5601.62it/s] 77%|███████▋  | 691880/900675 [01:56<00:37, 5517.78it/s] 77%|███████▋  | 692433/900675 [01:56<00:37, 5491.06it/s] 77%|███████▋  | 692986/900675 [01:56<00:37, 5496.11it/s] 77%|███████▋  | 693578/900675 [01:56<00:36, 5615.80it/s] 77%|███████▋  | 694167/900675 [01:57<00:36, 5696.60it/s] 77%|███████▋  | 694764/900675 [01:57<00:35, 5773.24it/s] 77%|███████▋  | 695342/900675 [01:57<00:36, 5597.57it/s] 77%|███████▋  | 695962/900675 [01:57<00:35, 5768.08it/s] 77%|███████▋  | 696541/900675 [01:57<00:35, 5680.88it/s] 77%|███████▋  | 697120/900675 [01:57<00:35, 5708.87it/s] 77%|███████▋  | 697781/900675 [01:57<00:33, 5969.31it/s] 78%|███████▊  | 698399/900675 [01:57<00:33, 6013.56it/s] 78%|███████▊  | 699002/900675 [01:57<00:35, 5640.23it/s] 78%|███████▊  | 699627/900675 [01:57<00:34, 5807.27it/s] 78%|███████▊  | 700213/900675 [01:58<00:34, 5794.11it/s] 78%|███████▊  | 700829/900675 [01:58<00:33, 5897.44it/s] 78%|███████▊  | 701458/900675 [01:58<00:33, 6012.42it/s] 78%|███████▊  | 702182/900675 [01:58<00:31, 6370.89it/s] 78%|███████▊  | 702821/900675 [01:58<00:31, 6235.79it/s] 78%|███████▊  | 703447/900675 [01:58<00:32, 6018.51it/s] 78%|███████▊  | 704078/900675 [01:58<00:32, 6102.12it/s] 78%|███████▊  | 704691/900675 [01:58<00:32, 6021.05it/s] 78%|███████▊  | 705295/900675 [01:58<00:34, 5718.30it/s] 78%|███████▊  | 705871/900675 [01:59<00:35, 5485.41it/s] 78%|███████▊  | 706436/900675 [01:59<00:35, 5530.63it/s] 78%|███████▊  | 707018/900675 [01:59<00:34, 5608.76it/s] 79%|███████▊  | 707586/900675 [01:59<00:34, 5626.66it/s] 79%|███████▊  | 708175/900675 [01:59<00:33, 5703.38it/s] 79%|███████▊  | 708826/900675 [01:59<00:32, 5935.23it/s] 79%|███████▉  | 709538/900675 [01:59<00:30, 6281.01it/s] 79%|███████▉  | 710168/900675 [01:59<00:30, 6166.22it/s] 79%|███████▉  | 710786/900675 [01:59<00:33, 5723.03it/s] 79%|███████▉  | 711480/900675 [01:59<00:31, 6060.35it/s] 79%|███████▉  | 712094/900675 [02:00<00:31, 5901.68it/s] 79%|███████▉  | 712758/900675 [02:00<00:30, 6110.97it/s] 79%|███████▉  | 713374/900675 [02:00<00:30, 6057.23it/s] 79%|███████▉  | 713984/900675 [02:00<00:31, 6022.08it/s] 79%|███████▉  | 714589/900675 [02:00<00:31, 5931.39it/s] 79%|███████▉  | 715212/900675 [02:00<00:30, 6013.22it/s] 79%|███████▉  | 715825/900675 [02:00<00:30, 6045.10it/s] 80%|███████▉  | 716445/900675 [02:00<00:30, 6085.11it/s] 80%|███████▉  | 717062/900675 [02:00<00:30, 6106.03it/s] 80%|███████▉  | 717674/900675 [02:01<00:30, 5941.35it/s] 80%|███████▉  | 718270/900675 [02:01<00:32, 5642.77it/s] 80%|███████▉  | 718899/900675 [02:01<00:31, 5822.09it/s] 80%|███████▉  | 719485/900675 [02:01<00:32, 5571.47it/s] 80%|███████▉  | 720047/900675 [02:01<00:32, 5521.78it/s] 80%|████████  | 720602/900675 [02:01<00:32, 5518.35it/s] 80%|████████  | 721228/900675 [02:01<00:31, 5729.67it/s] 80%|████████  | 721821/900675 [02:01<00:30, 5783.49it/s] 80%|████████  | 722463/900675 [02:01<00:29, 5967.43it/s] 80%|████████  | 723062/900675 [02:01<00:30, 5868.28it/s] 80%|████████  | 723670/900675 [02:02<00:29, 5930.22it/s] 80%|████████  | 724265/900675 [02:02<00:30, 5845.60it/s] 80%|████████  | 724851/900675 [02:02<00:30, 5806.59it/s] 81%|████████  | 725433/900675 [02:02<00:31, 5620.32it/s] 81%|████████  | 726025/900675 [02:02<00:30, 5701.30it/s] 81%|████████  | 726597/900675 [02:02<00:31, 5564.50it/s] 81%|████████  | 727266/900675 [02:02<00:29, 5885.23it/s] 81%|████████  | 727883/900675 [02:02<00:28, 5966.23it/s] 81%|████████  | 728482/900675 [02:02<00:30, 5709.27it/s] 81%|████████  | 729057/900675 [02:03<00:30, 5710.66it/s] 81%|████████  | 729631/900675 [02:03<00:30, 5613.51it/s] 81%|████████  | 730195/900675 [02:03<00:30, 5559.80it/s] 81%|████████  | 730788/900675 [02:03<00:30, 5660.47it/s] 81%|████████  | 731356/900675 [02:03<00:30, 5637.18it/s] 81%|████████▏ | 731944/900675 [02:03<00:29, 5708.45it/s] 81%|████████▏ | 732557/900675 [02:03<00:28, 5832.94it/s] 81%|████████▏ | 733141/900675 [02:03<00:28, 5779.63it/s] 81%|████████▏ | 733919/900675 [02:03<00:26, 6369.89it/s] 82%|████████▏ | 734558/900675 [02:03<00:26, 6251.60it/s] 82%|████████▏ | 735185/900675 [02:04<00:27, 5999.66it/s] 82%|████████▏ | 735788/900675 [02:04<00:28, 5760.04it/s] 82%|████████▏ | 736413/900675 [02:04<00:27, 5895.36it/s] 82%|████████▏ | 737257/900675 [02:04<00:24, 6621.91it/s] 82%|████████▏ | 737925/900675 [02:04<00:25, 6293.35it/s] 82%|████████▏ | 738561/900675 [02:04<00:26, 6179.47it/s] 82%|████████▏ | 739186/900675 [02:04<00:26, 6196.34it/s] 82%|████████▏ | 739809/900675 [02:04<00:26, 5969.39it/s] 82%|████████▏ | 740410/900675 [02:04<00:27, 5884.65it/s] 82%|████████▏ | 741058/900675 [02:05<00:26, 6053.76it/s] 82%|████████▏ | 741666/900675 [02:05<00:27, 5764.68it/s] 82%|████████▏ | 742247/900675 [02:05<00:28, 5623.50it/s] 82%|████████▏ | 742875/900675 [02:05<00:27, 5799.67it/s] 83%|████████▎ | 743512/900675 [02:05<00:26, 5961.23it/s] 83%|████████▎ | 744111/900675 [02:05<00:27, 5615.88it/s] 83%|████████▎ | 744696/900675 [02:05<00:27, 5678.97it/s] 83%|████████▎ | 745301/900675 [02:05<00:26, 5784.95it/s] 83%|████████▎ | 745883/900675 [02:05<00:28, 5527.08it/s] 83%|████████▎ | 746579/900675 [02:05<00:25, 5931.53it/s] 83%|████████▎ | 747178/900675 [02:06<00:26, 5821.15it/s] 83%|████████▎ | 747764/900675 [02:06<00:27, 5549.08it/s] 83%|████████▎ | 748328/900675 [02:06<00:27, 5573.75it/s] 83%|████████▎ | 748892/900675 [02:06<00:27, 5588.53it/s] 83%|████████▎ | 749548/900675 [02:06<00:25, 5865.87it/s] 83%|████████▎ | 750141/900675 [02:06<00:25, 5883.11it/s] 83%|████████▎ | 750749/900675 [02:06<00:25, 5933.69it/s] 83%|████████▎ | 751344/900675 [02:06<00:26, 5717.55it/s] 83%|████████▎ | 751919/900675 [02:06<00:26, 5596.63it/s] 84%|████████▎ | 752481/900675 [02:07<00:27, 5456.77it/s] 84%|████████▎ | 753103/900675 [02:07<00:26, 5665.26it/s] 84%|████████▎ | 753745/900675 [02:07<00:24, 5881.53it/s] 84%|████████▍ | 754336/900675 [02:07<00:25, 5748.47it/s] 84%|████████▍ | 754913/900675 [02:07<00:26, 5549.72it/s] 84%|████████▍ | 755471/900675 [02:07<00:26, 5433.31it/s] 84%|████████▍ | 756017/900675 [02:07<00:27, 5311.23it/s] 84%|████████▍ | 756623/900675 [02:07<00:26, 5521.55it/s] 84%|████████▍ | 757178/900675 [02:07<00:26, 5508.49it/s] 84%|████████▍ | 757811/900675 [02:07<00:24, 5747.02it/s] 84%|████████▍ | 758446/900675 [02:08<00:24, 5918.81it/s] 84%|████████▍ | 759040/900675 [02:08<00:24, 5736.37it/s] 84%|████████▍ | 759735/900675 [02:08<00:23, 6087.00it/s] 84%|████████▍ | 760365/900675 [02:08<00:22, 6145.47it/s] 84%|████████▍ | 761008/900675 [02:08<00:22, 6224.88it/s] 85%|████████▍ | 761633/900675 [02:08<00:22, 6227.49it/s] 85%|████████▍ | 762257/900675 [02:08<00:22, 6063.32it/s] 85%|████████▍ | 762865/900675 [02:08<00:23, 5787.91it/s] 85%|████████▍ | 763448/900675 [02:08<00:24, 5674.52it/s] 85%|████████▍ | 764024/900675 [02:09<00:23, 5698.35it/s] 85%|████████▍ | 764624/900675 [02:09<00:23, 5785.44it/s] 85%|████████▍ | 765206/900675 [02:09<00:23, 5792.30it/s] 85%|████████▌ | 765787/900675 [02:09<00:23, 5626.75it/s] 85%|████████▌ | 766483/900675 [02:09<00:22, 6011.74it/s] 85%|████████▌ | 767136/900675 [02:09<00:21, 6151.65it/s] 85%|████████▌ | 767754/900675 [02:09<00:21, 6086.44it/s] 85%|████████▌ | 768365/900675 [02:09<00:22, 5940.43it/s] 85%|████████▌ | 768961/900675 [02:09<00:23, 5618.79it/s] 85%|████████▌ | 769527/900675 [02:09<00:23, 5585.58it/s] 86%|████████▌ | 770089/900675 [02:10<00:23, 5501.96it/s] 86%|████████▌ | 770680/900675 [02:10<00:23, 5615.49it/s] 86%|████████▌ | 771244/900675 [02:10<00:23, 5604.76it/s] 86%|████████▌ | 771909/900675 [02:10<00:21, 5909.56it/s] 86%|████████▌ | 772502/900675 [02:10<00:22, 5724.51it/s] 86%|████████▌ | 773180/900675 [02:10<00:21, 6024.26it/s] 86%|████████▌ | 773801/900675 [02:10<00:20, 6075.22it/s] 86%|████████▌ | 774448/900675 [02:10<00:20, 6190.52it/s] 86%|████████▌ | 775069/900675 [02:10<00:21, 5805.14it/s] 86%|████████▌ | 775656/900675 [02:11<00:21, 5785.40it/s] 86%|████████▌ | 776239/900675 [02:11<00:21, 5710.00it/s] 86%|████████▌ | 776813/900675 [02:11<00:22, 5464.00it/s] 86%|████████▋ | 777459/900675 [02:11<00:21, 5739.55it/s] 86%|████████▋ | 778075/900675 [02:11<00:20, 5845.41it/s] 86%|████████▋ | 778713/900675 [02:11<00:20, 5995.88it/s] 87%|████████▋ | 779316/900675 [02:11<00:20, 5809.43it/s] 87%|████████▋ | 779941/900675 [02:11<00:20, 5930.86it/s] 87%|████████▋ | 780537/900675 [02:11<00:21, 5506.82it/s] 87%|████████▋ | 781155/900675 [02:11<00:20, 5692.33it/s] 87%|████████▋ | 781927/900675 [02:12<00:18, 6267.71it/s] 87%|████████▋ | 782562/900675 [02:12<00:19, 5941.17it/s] 87%|████████▋ | 783165/900675 [02:12<00:21, 5570.36it/s] 87%|████████▋ | 783734/900675 [02:12<00:20, 5602.73it/s] 87%|████████▋ | 784301/900675 [02:12<00:20, 5543.12it/s] 87%|████████▋ | 784860/900675 [02:12<00:20, 5549.87it/s] 87%|████████▋ | 785485/900675 [02:12<00:20, 5743.33it/s] 87%|████████▋ | 786164/900675 [02:12<00:18, 6043.90it/s] 87%|████████▋ | 786772/900675 [02:12<00:19, 5979.29it/s] 87%|████████▋ | 787373/900675 [02:13<00:19, 5902.52it/s] 87%|████████▋ | 788021/900675 [02:13<00:18, 6068.02it/s] 88%|████████▊ | 788630/900675 [02:13<00:19, 5813.22it/s] 88%|████████▊ | 789215/900675 [02:13<00:19, 5796.94it/s] 88%|████████▊ | 789825/900675 [02:13<00:18, 5879.42it/s] 88%|████████▊ | 790477/900675 [02:13<00:18, 6065.67it/s] 88%|████████▊ | 791086/900675 [02:13<00:18, 5966.70it/s] 88%|████████▊ | 791685/900675 [02:13<00:19, 5692.79it/s] 88%|████████▊ | 792258/900675 [02:13<00:19, 5541.24it/s] 88%|████████▊ | 792963/900675 [02:13<00:18, 5965.63it/s] 88%|████████▊ | 793564/900675 [02:14<00:18, 5919.20it/s] 88%|████████▊ | 794159/900675 [02:14<00:19, 5445.20it/s] 88%|████████▊ | 794817/900675 [02:14<00:18, 5755.98it/s] 88%|████████▊ | 795422/900675 [02:14<00:18, 5838.47it/s] 88%|████████▊ | 796038/900675 [02:14<00:17, 5930.58it/s] 88%|████████▊ | 796637/900675 [02:14<00:17, 5913.18it/s] 89%|████████▊ | 797259/900675 [02:14<00:17, 5996.50it/s] 89%|████████▊ | 797862/900675 [02:14<00:17, 5833.99it/s] 89%|████████▊ | 798479/900675 [02:14<00:17, 5930.30it/s] 89%|████████▊ | 799075/900675 [02:15<00:17, 5936.78it/s] 89%|████████▉ | 799671/900675 [02:15<00:17, 5897.09it/s] 89%|████████▉ | 800292/900675 [02:15<00:16, 5988.96it/s] 89%|████████▉ | 800892/900675 [02:15<00:17, 5864.32it/s] 89%|████████▉ | 801480/900675 [02:15<00:17, 5750.75it/s] 89%|████████▉ | 802140/900675 [02:15<00:16, 5994.93it/s] 89%|████████▉ | 802741/900675 [02:15<00:17, 5512.97it/s] 89%|████████▉ | 803425/900675 [02:15<00:16, 5880.77it/s] 89%|████████▉ | 804022/900675 [02:15<00:16, 5715.67it/s] 89%|████████▉ | 804674/900675 [02:15<00:16, 5937.00it/s] 89%|████████▉ | 805289/900675 [02:16<00:15, 5996.79it/s] 89%|████████▉ | 805893/900675 [02:16<00:16, 5772.97it/s] 90%|████████▉ | 806492/900675 [02:16<00:16, 5834.31it/s] 90%|████████▉ | 807101/900675 [02:16<00:15, 5901.90it/s] 90%|████████▉ | 807694/900675 [02:16<00:16, 5761.55it/s] 90%|████████▉ | 808273/900675 [02:16<00:17, 5328.58it/s] 90%|████████▉ | 808905/900675 [02:16<00:16, 5596.17it/s] 90%|████████▉ | 809488/900675 [02:16<00:16, 5660.94it/s] 90%|████████▉ | 810102/900675 [02:16<00:15, 5797.89it/s] 90%|█████████ | 810687/900675 [02:17<00:16, 5372.02it/s] 90%|█████████ | 811233/900675 [02:17<00:16, 5363.21it/s] 90%|█████████ | 811926/900675 [02:17<00:15, 5806.00it/s] 90%|█████████ | 812514/900675 [02:17<00:15, 5522.00it/s] 90%|█████████ | 813189/900675 [02:17<00:14, 5862.23it/s] 90%|█████████ | 813887/900675 [02:17<00:14, 6181.47it/s] 90%|█████████ | 814512/900675 [02:17<00:13, 6196.46it/s] 91%|█████████ | 815193/900675 [02:17<00:13, 6373.57it/s] 91%|█████████ | 815840/900675 [02:17<00:13, 6398.03it/s] 91%|█████████ | 816549/900675 [02:17<00:12, 6596.40it/s] 91%|█████████ | 817235/900675 [02:18<00:12, 6674.55it/s] 91%|█████████ | 817963/900675 [02:18<00:12, 6854.59it/s] 91%|█████████ | 818650/900675 [02:18<00:12, 6346.20it/s] 91%|█████████ | 819293/900675 [02:18<00:13, 6161.22it/s] 91%|█████████ | 819960/900675 [02:18<00:12, 6301.91it/s] 91%|█████████ | 820596/900675 [02:18<00:12, 6276.33it/s] 91%|█████████ | 821295/900675 [02:18<00:12, 6475.48it/s] 91%|█████████▏| 821946/900675 [02:18<00:13, 5847.79it/s] 91%|█████████▏| 822544/900675 [02:18<00:13, 5835.79it/s] 91%|█████████▏| 823201/900675 [02:19<00:12, 6035.11it/s] 91%|█████████▏| 823813/900675 [02:19<00:12, 6032.56it/s] 92%|█████████▏| 824422/900675 [02:19<00:12, 5977.68it/s] 92%|█████████▏| 825024/900675 [02:19<00:13, 5654.56it/s] 92%|█████████▏| 825595/900675 [02:19<00:13, 5402.14it/s] 92%|█████████▏| 826185/900675 [02:19<00:13, 5539.45it/s] 92%|█████████▏| 826784/900675 [02:19<00:13, 5663.15it/s] 92%|█████████▏| 827433/900675 [02:19<00:12, 5899.06it/s] 92%|█████████▏| 828064/900675 [02:19<00:12, 6012.63it/s] 92%|█████████▏| 828669/900675 [02:20<00:12, 5812.07it/s] 92%|█████████▏| 829254/900675 [02:20<00:13, 5217.50it/s] 92%|█████████▏| 829894/900675 [02:20<00:12, 5532.65it/s] 92%|█████████▏| 830460/900675 [02:20<00:12, 5543.46it/s] 92%|█████████▏| 831023/900675 [02:20<00:12, 5467.34it/s] 92%|█████████▏| 831670/900675 [02:20<00:12, 5749.76it/s] 92%|█████████▏| 832251/900675 [02:20<00:12, 5605.84it/s] 92%|█████████▏| 832905/900675 [02:20<00:11, 5871.66it/s] 93%|█████████▎| 833497/900675 [02:20<00:11, 5777.73it/s] 93%|█████████▎| 834081/900675 [02:20<00:11, 5794.69it/s] 93%|█████████▎| 834663/900675 [02:21<00:11, 5730.05it/s] 93%|█████████▎| 835292/900675 [02:21<00:11, 5888.34it/s] 93%|█████████▎| 835903/900675 [02:21<00:10, 5950.97it/s] 93%|█████████▎| 836544/900675 [02:21<00:10, 6082.82it/s] 93%|█████████▎| 837154/900675 [02:21<00:10, 5991.30it/s] 93%|█████████▎| 837807/900675 [02:21<00:10, 6146.85it/s] 93%|█████████▎| 838423/900675 [02:21<00:10, 6041.48it/s] 93%|█████████▎| 839029/900675 [02:21<00:10, 5870.66it/s] 93%|█████████▎| 839618/900675 [02:21<00:10, 5778.47it/s] 93%|█████████▎| 840223/900675 [02:22<00:10, 5856.43it/s] 93%|█████████▎| 840901/900675 [02:22<00:09, 6124.41it/s] 93%|█████████▎| 841515/900675 [02:22<00:09, 6080.97it/s] 93%|█████████▎| 842127/900675 [02:22<00:09, 6086.51it/s] 94%|█████████▎| 842737/900675 [02:22<00:10, 5721.11it/s] 94%|█████████▎| 843314/900675 [02:22<00:10, 5319.21it/s] 94%|█████████▎| 843854/900675 [02:22<00:10, 5299.82it/s] 94%|█████████▍| 844390/900675 [02:22<00:11, 5104.82it/s] 94%|█████████▍| 844964/900675 [02:22<00:10, 5274.98it/s] 94%|█████████▍| 845535/900675 [02:23<00:10, 5397.24it/s] 94%|█████████▍| 846099/900675 [02:23<00:09, 5463.83it/s] 94%|█████████▍| 846663/900675 [02:23<00:09, 5514.87it/s] 94%|█████████▍| 847288/900675 [02:23<00:09, 5725.09it/s] 94%|█████████▍| 847918/900675 [02:23<00:08, 5885.61it/s] 94%|█████████▍| 848509/900675 [02:23<00:09, 5782.99it/s] 94%|█████████▍| 849095/900675 [02:23<00:08, 5777.60it/s] 94%|█████████▍| 849674/900675 [02:23<00:08, 5770.41it/s] 94%|█████████▍| 850306/900675 [02:23<00:08, 5923.87it/s] 94%|█████████▍| 850900/900675 [02:23<00:08, 5571.37it/s] 95%|█████████▍| 851514/900675 [02:24<00:08, 5731.67it/s] 95%|█████████▍| 852092/900675 [02:24<00:08, 5730.99it/s] 95%|█████████▍| 852668/900675 [02:24<00:08, 5449.35it/s] 95%|█████████▍| 853277/900675 [02:24<00:08, 5627.24it/s] 95%|█████████▍| 853844/900675 [02:24<00:08, 5636.92it/s] 95%|█████████▍| 854472/900675 [02:24<00:07, 5822.77it/s] 95%|█████████▍| 855057/900675 [02:24<00:08, 5694.84it/s] 95%|█████████▌| 855659/900675 [02:24<00:07, 5781.16it/s] 95%|█████████▌| 856252/900675 [02:24<00:07, 5818.71it/s] 95%|█████████▌| 856861/900675 [02:24<00:07, 5898.64it/s] 95%|█████████▌| 857465/900675 [02:25<00:07, 5935.46it/s] 95%|█████████▌| 858075/900675 [02:25<00:07, 5983.24it/s] 95%|█████████▌| 858674/900675 [02:25<00:07, 5748.66it/s] 95%|█████████▌| 859252/900675 [02:25<00:07, 5727.67it/s] 95%|█████████▌| 859851/900675 [02:25<00:07, 5795.36it/s] 96%|█████████▌| 860623/900675 [02:25<00:06, 6356.83it/s] 96%|█████████▌| 861274/900675 [02:25<00:06, 6396.73it/s] 96%|█████████▌| 861916/900675 [02:25<00:06, 6046.29it/s] 96%|█████████▌| 862570/900675 [02:25<00:06, 6179.30it/s] 96%|█████████▌| 863213/900675 [02:25<00:05, 6248.38it/s] 96%|█████████▌| 863841/900675 [02:26<00:06, 6068.55it/s] 96%|█████████▌| 864451/900675 [02:26<00:06, 5958.43it/s] 96%|█████████▌| 865049/900675 [02:26<00:06, 5894.75it/s] 96%|█████████▌| 865640/900675 [02:26<00:06, 5684.15it/s] 96%|█████████▌| 866246/900675 [02:26<00:05, 5785.11it/s] 96%|█████████▌| 866866/900675 [02:26<00:05, 5900.19it/s] 96%|█████████▋| 867458/900675 [02:26<00:05, 5857.67it/s] 96%|█████████▋| 868045/900675 [02:26<00:05, 5805.96it/s] 96%|█████████▋| 868627/900675 [02:26<00:05, 5756.88it/s] 97%|█████████▋| 869230/900675 [02:27<00:05, 5834.49it/s] 97%|█████████▋| 869849/900675 [02:27<00:05, 5938.96it/s] 97%|█████████▋| 870484/900675 [02:27<00:04, 6060.34it/s] 97%|█████████▋| 871210/900675 [02:27<00:04, 6408.86it/s] 97%|█████████▋| 871852/900675 [02:27<00:04, 6214.96it/s] 97%|█████████▋| 872476/900675 [02:27<00:04, 5794.78it/s] 97%|█████████▋| 873178/900675 [02:27<00:04, 6133.01it/s] 97%|█████████▋| 873798/900675 [02:27<00:04, 5946.35it/s] 97%|█████████▋| 874415/900675 [02:27<00:04, 6005.26it/s] 97%|█████████▋| 875020/900675 [02:28<00:04, 5831.40it/s] 97%|█████████▋| 875633/900675 [02:28<00:04, 5912.93it/s] 97%|█████████▋| 876278/900675 [02:28<00:04, 6066.92it/s] 97%|█████████▋| 876888/900675 [02:28<00:04, 5817.77it/s] 97%|█████████▋| 877474/900675 [02:28<00:03, 5819.25it/s] 97%|█████████▋| 878059/900675 [02:28<00:03, 5756.47it/s] 98%|█████████▊| 878648/900675 [02:28<00:03, 5794.86it/s] 98%|█████████▊| 879257/900675 [02:28<00:03, 5880.44it/s] 98%|█████████▊| 879847/900675 [02:28<00:03, 5607.74it/s] 98%|█████████▊| 880433/900675 [02:28<00:03, 5675.60it/s] 98%|█████████▊| 881004/900675 [02:29<00:03, 5590.13it/s] 98%|█████████▊| 881565/900675 [02:29<00:03, 5504.71it/s] 98%|█████████▊| 882117/900675 [02:29<00:03, 5204.91it/s] 98%|█████████▊| 882738/900675 [02:29<00:03, 5485.30it/s] 98%|█████████▊| 883393/900675 [02:29<00:02, 5787.27it/s] 98%|█████████▊| 883977/900675 [02:29<00:02, 5760.93it/s] 98%|█████████▊| 884557/900675 [02:29<00:02, 5691.57it/s] 98%|█████████▊| 885184/900675 [02:29<00:02, 5854.91it/s] 98%|█████████▊| 885808/900675 [02:29<00:02, 5963.74it/s] 98%|█████████▊| 886530/900675 [02:29<00:02, 6331.23it/s] 99%|█████████▊| 887165/900675 [02:30<00:02, 6125.06it/s] 99%|█████████▊| 887780/900675 [02:30<00:02, 5782.20it/s] 99%|█████████▊| 888404/900675 [02:30<00:02, 5905.07it/s] 99%|█████████▊| 888999/900675 [02:30<00:02, 5752.82it/s] 99%|█████████▉| 889646/900675 [02:30<00:01, 5951.81it/s] 99%|█████████▉| 890245/900675 [02:30<00:01, 5861.82it/s] 99%|█████████▉| 890922/900675 [02:30<00:01, 6123.13it/s] 99%|█████████▉| 891537/900675 [02:30<00:01, 5899.99it/s] 99%|█████████▉| 892131/900675 [02:30<00:01, 5802.65it/s] 99%|█████████▉| 892730/900675 [02:31<00:01, 5853.33it/s] 99%|█████████▉| 893318/900675 [02:31<00:01, 5578.94it/s] 99%|█████████▉| 893880/900675 [02:31<00:01, 5411.62it/s] 99%|█████████▉| 894429/900675 [02:31<00:01, 5428.00it/s] 99%|█████████▉| 894978/900675 [02:31<00:01, 5441.06it/s] 99%|█████████▉| 895582/900675 [02:31<00:00, 5610.80it/s]100%|█████████▉| 896266/900675 [02:31<00:00, 5965.62it/s]100%|█████████▉| 896865/900675 [02:31<00:00, 5805.18it/s]100%|█████████▉| 897484/900675 [02:31<00:00, 5916.53it/s]100%|█████████▉| 898153/900675 [02:31<00:00, 6136.49it/s]100%|█████████▉| 898780/900675 [02:32<00:00, 6174.85it/s]100%|█████████▉| 899417/900675 [02:32<00:00, 6229.11it/s]100%|█████████▉| 900041/900675 [02:32<00:00, 6126.07it/s]100%|█████████▉| 900655/900675 [02:32<00:00, 6031.41it/s]100%|██████████| 900675/900675 [02:32<00:00, 5909.70it/s]

gathering stats for n=1
  0%|          | 0/900675 [00:00<?, ?it/s]  0%|          | 1891/900675 [00:00<00:47, 18866.75it/s]  0%|          | 3917/900675 [00:00<00:45, 19683.86it/s]  1%|          | 6131/900675 [00:00<00:43, 20799.68it/s]  1%|          | 8212/900675 [00:00<00:45, 19715.87it/s]  1%|          | 10192/900675 [00:00<00:45, 19736.09it/s]  1%|▏         | 12171/900675 [00:00<00:45, 19578.49it/s]  2%|▏         | 14133/900675 [00:00<00:45, 19523.68it/s]  2%|▏         | 16088/900675 [00:00<00:45, 19264.47it/s]  2%|▏         | 18045/900675 [00:00<00:45, 19352.49it/s]  2%|▏         | 20095/900675 [00:01<00:44, 19695.75it/s]  2%|▏         | 22067/900675 [00:01<00:45, 19364.78it/s]  3%|▎         | 24226/900675 [00:01<00:43, 20028.06it/s]  3%|▎         | 26267/900675 [00:01<00:43, 20139.35it/s]  3%|▎         | 28283/900675 [00:01<00:44, 19722.32it/s]  3%|▎         | 30277/900675 [00:01<00:43, 19784.49it/s]  4%|▎         | 32258/900675 [00:01<00:45, 19064.25it/s]  4%|▍         | 34171/900675 [00:01<00:45, 19026.32it/s]  4%|▍         | 36198/900675 [00:01<00:44, 19387.77it/s]  4%|▍         | 38141/900675 [00:01<00:45, 18977.78it/s]  4%|▍         | 40070/900675 [00:02<00:45, 19066.05it/s]  5%|▍         | 41980/900675 [00:02<00:45, 19035.04it/s]  5%|▍         | 43886/900675 [00:02<00:45, 18896.36it/s]  5%|▌         | 45888/900675 [00:02<00:44, 19225.44it/s]  5%|▌         | 48263/900675 [00:02<00:41, 20566.34it/s]  6%|▌         | 50323/900675 [00:02<00:41, 20385.91it/s]  6%|▌         | 52473/900675 [00:02<00:40, 20709.92it/s]  6%|▌         | 54546/900675 [00:02<00:42, 19928.20it/s]  6%|▋         | 56559/900675 [00:02<00:42, 19985.78it/s]  7%|▋         | 58563/900675 [00:02<00:42, 19735.31it/s]  7%|▋         | 60541/900675 [00:03<00:43, 19400.34it/s]  7%|▋         | 62613/900675 [00:03<00:42, 19783.91it/s]  7%|▋         | 64595/900675 [00:03<00:42, 19619.96it/s]  7%|▋         | 66590/900675 [00:03<00:42, 19715.93it/s]  8%|▊         | 68564/900675 [00:03<00:42, 19455.98it/s]  8%|▊         | 70629/900675 [00:03<00:41, 19803.04it/s]  8%|▊         | 72681/900675 [00:03<00:41, 20014.60it/s]  8%|▊         | 74965/900675 [00:03<00:39, 20851.32it/s]  9%|▊         | 77053/900675 [00:03<00:40, 20448.82it/s]  9%|▉         | 79101/900675 [00:04<00:42, 19535.18it/s]  9%|▉         | 81064/900675 [00:04<00:42, 19223.92it/s]  9%|▉         | 83017/900675 [00:04<00:42, 19308.01it/s]  9%|▉         | 84961/900675 [00:04<00:42, 19345.41it/s] 10%|▉         | 86900/900675 [00:04<00:42, 19326.11it/s] 10%|▉         | 88836/900675 [00:04<00:42, 19143.51it/s] 10%|█         | 90753/900675 [00:04<00:43, 18673.10it/s] 10%|█         | 92811/900675 [00:04<00:42, 19222.49it/s] 11%|█         | 94745/900675 [00:04<00:41, 19256.28it/s] 11%|█         | 96847/900675 [00:04<00:40, 19775.20it/s] 11%|█         | 98828/900675 [00:05<00:42, 18956.28it/s] 11%|█         | 100733/900675 [00:05<00:42, 18614.74it/s] 11%|█▏        | 102716/900675 [00:05<00:42, 18964.07it/s] 12%|█▏        | 104619/900675 [00:05<00:42, 18792.12it/s] 12%|█▏        | 106518/900675 [00:05<00:42, 18849.34it/s] 12%|█▏        | 108406/900675 [00:05<00:42, 18740.13it/s] 12%|█▏        | 110283/900675 [00:05<00:42, 18607.26it/s] 12%|█▏        | 112252/900675 [00:05<00:41, 18925.56it/s] 13%|█▎        | 114174/900675 [00:05<00:41, 19012.29it/s] 13%|█▎        | 116077/900675 [00:05<00:41, 18695.67it/s] 13%|█▎        | 117949/900675 [00:06<00:42, 18505.62it/s] 13%|█▎        | 119813/900675 [00:06<00:42, 18543.69it/s] 14%|█▎        | 121818/900675 [00:06<00:41, 18982.21it/s] 14%|█▎        | 123718/900675 [00:06<00:41, 18893.01it/s] 14%|█▍        | 125659/900675 [00:06<00:40, 19045.64it/s] 14%|█▍        | 127565/900675 [00:06<00:40, 19021.09it/s] 14%|█▍        | 129502/900675 [00:06<00:40, 19124.54it/s] 15%|█▍        | 131415/900675 [00:06<00:41, 18687.31it/s] 15%|█▍        | 133287/900675 [00:06<00:41, 18584.76it/s] 15%|█▌        | 135389/900675 [00:06<00:39, 19293.47it/s] 15%|█▌        | 137475/900675 [00:07<00:38, 19756.58it/s] 15%|█▌        | 139453/900675 [00:07<00:39, 19381.01it/s] 16%|█▌        | 141394/900675 [00:07<00:39, 19064.30it/s] 16%|█▌        | 143304/900675 [00:07<00:40, 18862.94it/s] 16%|█▌        | 145428/900675 [00:07<00:38, 19549.94it/s] 16%|█▋        | 147387/900675 [00:07<00:39, 19102.50it/s] 17%|█▋        | 149301/900675 [00:07<00:39, 18973.95it/s] 17%|█▋        | 151201/900675 [00:07<00:40, 18603.50it/s] 17%|█▋        | 153132/900675 [00:07<00:39, 18803.23it/s] 17%|█▋        | 155015/900675 [00:08<00:39, 18778.03it/s] 17%|█▋        | 156921/900675 [00:08<00:39, 18860.37it/s] 18%|█▊        | 158931/900675 [00:08<00:38, 19225.93it/s] 18%|█▊        | 160879/900675 [00:08<00:38, 19300.76it/s] 18%|█▊        | 162847/900675 [00:08<00:38, 19410.61it/s] 18%|█▊        | 164789/900675 [00:08<00:38, 19226.30it/s] 19%|█▊        | 166870/900675 [00:08<00:37, 19693.45it/s] 19%|█▊        | 168841/900675 [00:08<00:37, 19426.37it/s] 19%|█▉        | 170786/900675 [00:08<00:38, 18886.98it/s] 19%|█▉        | 172679/900675 [00:08<00:38, 18898.37it/s] 19%|█▉        | 174603/900675 [00:09<00:38, 18998.25it/s] 20%|█▉        | 176505/900675 [00:09<00:39, 18533.39it/s] 20%|█▉        | 178362/900675 [00:09<00:39, 18126.35it/s] 20%|██        | 180248/900675 [00:09<00:39, 18337.22it/s] 20%|██        | 182085/900675 [00:09<00:39, 18209.39it/s] 20%|██        | 183909/900675 [00:09<00:39, 17928.21it/s] 21%|██        | 185737/900675 [00:09<00:39, 18029.31it/s] 21%|██        | 187664/900675 [00:09<00:38, 18388.45it/s] 21%|██        | 189657/900675 [00:09<00:37, 18844.20it/s] 21%|██▏       | 191592/900675 [00:09<00:37, 18993.86it/s] 21%|██▏       | 193616/900675 [00:10<00:36, 19363.99it/s] 22%|██▏       | 195554/900675 [00:10<00:36, 19362.20it/s] 22%|██▏       | 197735/900675 [00:10<00:34, 20092.42it/s] 22%|██▏       | 199746/900675 [00:10<00:35, 19478.74it/s] 22%|██▏       | 201699/900675 [00:10<00:36, 19221.66it/s] 23%|██▎       | 203731/900675 [00:10<00:35, 19540.56it/s] 23%|██▎       | 205689/900675 [00:10<00:35, 19384.72it/s] 23%|██▎       | 207630/900675 [00:10<00:36, 19191.46it/s] 23%|██▎       | 209551/900675 [00:10<00:36, 18705.45it/s] 23%|██▎       | 211593/900675 [00:10<00:35, 19201.15it/s] 24%|██▎       | 213561/900675 [00:11<00:35, 19339.88it/s] 24%|██▍       | 215498/900675 [00:11<00:36, 18972.69it/s] 24%|██▍       | 217407/900675 [00:11<00:35, 19002.45it/s] 24%|██▍       | 219447/900675 [00:11<00:35, 19411.46it/s] 25%|██▍       | 221391/900675 [00:11<00:35, 19249.69it/s] 25%|██▍       | 223318/900675 [00:11<00:36, 18607.67it/s] 25%|██▌       | 225368/900675 [00:11<00:35, 19154.32it/s] 25%|██▌       | 227351/900675 [00:11<00:34, 19349.05it/s] 25%|██▌       | 229291/900675 [00:11<00:35, 18962.45it/s] 26%|██▌       | 231192/900675 [00:12<00:35, 18771.08it/s] 26%|██▌       | 233189/900675 [00:12<00:34, 19114.94it/s] 26%|██▌       | 235309/900675 [00:12<00:33, 19724.30it/s] 26%|██▋       | 237285/900675 [00:12<00:34, 19168.03it/s] 27%|██▋       | 239356/900675 [00:12<00:33, 19612.59it/s] 27%|██▋       | 241422/900675 [00:12<00:33, 19919.86it/s] 27%|██▋       | 243419/900675 [00:12<00:33, 19847.09it/s] 27%|██▋       | 245407/900675 [00:12<00:33, 19852.23it/s] 27%|██▋       | 247593/900675 [00:12<00:31, 20443.34it/s] 28%|██▊       | 249696/900675 [00:12<00:31, 20617.36it/s] 28%|██▊       | 251760/900675 [00:13<00:31, 20491.72it/s] 28%|██▊       | 253811/900675 [00:13<00:31, 20255.64it/s] 28%|██▊       | 255838/900675 [00:13<00:32, 20079.79it/s] 29%|██▊       | 257847/900675 [00:13<00:32, 20078.10it/s] 29%|██▉       | 259856/900675 [00:13<00:33, 19102.01it/s] 29%|██▉       | 261940/900675 [00:13<00:32, 19600.15it/s] 29%|██▉       | 263909/900675 [00:13<00:33, 19190.52it/s] 30%|██▉       | 265836/900675 [00:13<00:33, 19001.04it/s] 30%|██▉       | 267741/900675 [00:13<00:33, 18868.51it/s] 30%|██▉       | 269680/900675 [00:13<00:33, 19019.16it/s] 30%|███       | 271632/900675 [00:14<00:32, 19165.19it/s] 30%|███       | 273870/900675 [00:14<00:31, 20114.97it/s] 31%|███       | 275885/900675 [00:14<00:31, 19558.38it/s] 31%|███       | 277846/900675 [00:14<00:32, 19238.19it/s] 31%|███       | 279774/900675 [00:14<00:32, 19195.51it/s] 31%|███▏      | 281738/900675 [00:14<00:32, 19323.59it/s] 31%|███▏      | 283684/900675 [00:14<00:31, 19352.72it/s] 32%|███▏      | 285621/900675 [00:14<00:31, 19265.07it/s] 32%|███▏      | 287549/900675 [00:14<00:32, 19151.98it/s] 32%|███▏      | 289565/900675 [00:15<00:31, 19439.27it/s] 32%|███▏      | 291510/900675 [00:15<00:31, 19337.45it/s] 33%|███▎      | 293445/900675 [00:15<00:31, 19117.63it/s] 33%|███▎      | 295450/900675 [00:15<00:31, 19390.25it/s] 33%|███▎      | 297391/900675 [00:15<00:31, 19304.42it/s] 33%|███▎      | 299410/900675 [00:15<00:30, 19565.13it/s] 33%|███▎      | 301368/900675 [00:15<00:30, 19364.88it/s] 34%|███▎      | 303368/900675 [00:15<00:30, 19551.10it/s] 34%|███▍      | 305325/900675 [00:15<00:30, 19555.19it/s] 34%|███▍      | 307282/900675 [00:15<00:30, 19419.22it/s] 34%|███▍      | 309241/900675 [00:16<00:30, 19469.44it/s] 35%|███▍      | 311255/900675 [00:16<00:29, 19666.29it/s] 35%|███▍      | 313325/900675 [00:16<00:29, 19973.51it/s] 35%|███▌      | 315323/900675 [00:16<00:29, 19760.61it/s] 35%|███▌      | 317300/900675 [00:16<00:29, 19525.89it/s] 35%|███▌      | 319254/900675 [00:16<00:29, 19403.20it/s] 36%|███▌      | 321195/900675 [00:16<00:29, 19356.37it/s] 36%|███▌      | 323132/900675 [00:16<00:30, 19069.46it/s] 36%|███▌      | 325066/900675 [00:16<00:30, 19148.26it/s] 36%|███▋      | 326992/900675 [00:16<00:29, 19175.76it/s] 37%|███▋      | 329143/900675 [00:17<00:28, 19865.67it/s] 37%|███▋      | 331131/900675 [00:17<00:29, 19226.14it/s] 37%|███▋      | 333059/900675 [00:17<00:29, 19026.13it/s] 37%|███▋      | 335038/900675 [00:17<00:29, 19238.85it/s] 37%|███▋      | 337016/900675 [00:17<00:29, 19397.49it/s] 38%|███▊      | 339058/900675 [00:17<00:28, 19696.32it/s] 38%|███▊      | 341030/900675 [00:17<00:29, 19099.32it/s] 38%|███▊      | 343034/900675 [00:17<00:28, 19369.78it/s] 38%|███▊      | 345010/900675 [00:17<00:28, 19479.42it/s] 39%|███▊      | 346962/900675 [00:17<00:28, 19219.66it/s] 39%|███▊      | 348894/900675 [00:18<00:28, 19241.26it/s] 39%|███▉      | 351020/900675 [00:18<00:27, 19834.62it/s] 39%|███▉      | 353006/900675 [00:18<00:28, 19271.23it/s] 39%|███▉      | 354965/900675 [00:18<00:28, 19356.28it/s] 40%|███▉      | 356905/900675 [00:18<00:28, 18972.14it/s] 40%|███▉      | 358824/900675 [00:18<00:28, 19035.20it/s] 40%|████      | 360826/900675 [00:18<00:27, 19321.40it/s] 40%|████      | 362973/900675 [00:18<00:26, 19954.48it/s] 41%|████      | 365069/900675 [00:18<00:26, 20251.95it/s] 41%|████      | 367097/900675 [00:18<00:26, 20157.99it/s] 41%|████      | 369115/900675 [00:19<00:27, 19678.37it/s] 41%|████      | 371087/900675 [00:19<00:27, 19551.66it/s] 41%|████▏     | 373045/900675 [00:19<00:27, 19451.94it/s] 42%|████▏     | 375052/900675 [00:19<00:26, 19627.81it/s] 42%|████▏     | 377017/900675 [00:19<00:27, 19021.07it/s] 42%|████▏     | 379044/900675 [00:19<00:26, 19383.31it/s] 42%|████▏     | 381121/900675 [00:19<00:26, 19789.58it/s] 43%|████▎     | 383104/900675 [00:19<00:26, 19249.49it/s] 43%|████▎     | 385130/900675 [00:19<00:26, 19528.70it/s] 43%|████▎     | 387097/900675 [00:20<00:26, 19568.23it/s] 43%|████▎     | 389094/900675 [00:20<00:25, 19685.44it/s] 43%|████▎     | 391066/900675 [00:20<00:26, 19578.79it/s] 44%|████▎     | 393026/900675 [00:20<00:27, 18717.43it/s] 44%|████▍     | 394907/900675 [00:20<00:27, 18615.85it/s] 44%|████▍     | 396775/900675 [00:20<00:27, 18625.71it/s] 44%|████▍     | 398680/900675 [00:20<00:26, 18747.52it/s] 44%|████▍     | 400704/900675 [00:20<00:26, 19182.10it/s] 45%|████▍     | 402626/900675 [00:20<00:27, 18304.77it/s] 45%|████▍     | 404525/900675 [00:20<00:26, 18501.03it/s] 45%|████▌     | 406383/900675 [00:21<00:27, 18215.21it/s] 45%|████▌     | 408211/900675 [00:21<00:27, 18160.76it/s] 46%|████▌     | 410109/900675 [00:21<00:26, 18395.27it/s] 46%|████▌     | 412002/900675 [00:21<00:26, 18549.04it/s] 46%|████▌     | 413860/900675 [00:21<00:27, 18003.06it/s] 46%|████▌     | 415666/900675 [00:21<00:27, 17741.48it/s] 46%|████▋     | 417470/900675 [00:21<00:27, 17818.78it/s] 47%|████▋     | 419403/900675 [00:21<00:26, 18260.78it/s] 47%|████▋     | 421232/900675 [00:21<00:26, 18073.85it/s] 47%|████▋     | 423205/900675 [00:21<00:25, 18559.44it/s] 47%|████▋     | 425064/900675 [00:22<00:25, 18380.26it/s] 47%|████▋     | 427047/900675 [00:22<00:25, 18804.34it/s] 48%|████▊     | 428946/900675 [00:22<00:25, 18850.92it/s] 48%|████▊     | 430867/900675 [00:22<00:24, 18950.18it/s] 48%|████▊     | 432928/900675 [00:22<00:24, 19444.42it/s] 48%|████▊     | 434874/900675 [00:22<00:24, 18660.85it/s] 48%|████▊     | 436770/900675 [00:22<00:24, 18744.45it/s] 49%|████▊     | 438650/900675 [00:22<00:24, 18664.78it/s] 49%|████▉     | 440521/900675 [00:22<00:25, 18286.10it/s] 49%|████▉     | 442420/900675 [00:23<00:24, 18488.18it/s] 49%|████▉     | 444344/900675 [00:23<00:24, 18703.86it/s] 50%|████▉     | 446218/900675 [00:23<00:25, 18141.27it/s] 50%|████▉     | 448140/900675 [00:23<00:24, 18451.02it/s] 50%|████▉     | 450006/900675 [00:23<00:24, 18508.26it/s] 50%|█████     | 451937/900675 [00:23<00:23, 18740.26it/s] 50%|█████     | 453814/900675 [00:23<00:24, 18428.35it/s] 51%|█████     | 455660/900675 [00:23<00:24, 18356.93it/s] 51%|█████     | 457716/900675 [00:23<00:23, 19003.68it/s] 51%|█████     | 459686/900675 [00:23<00:22, 19207.50it/s] 51%|█████▏    | 461609/900675 [00:24<00:23, 18831.60it/s] 51%|█████▏    | 463495/900675 [00:24<00:23, 18805.63it/s] 52%|█████▏    | 465378/900675 [00:24<00:23, 18675.39it/s] 52%|█████▏    | 467272/900675 [00:24<00:23, 18746.87it/s] 52%|█████▏    | 469176/900675 [00:24<00:22, 18832.54it/s] 52%|█████▏    | 471093/900675 [00:24<00:22, 18924.33it/s] 53%|█████▎    | 472987/900675 [00:24<00:22, 18615.24it/s] 53%|█████▎    | 474931/900675 [00:24<00:22, 18856.13it/s] 53%|█████▎    | 476818/900675 [00:24<00:22, 18743.83it/s] 53%|█████▎    | 478850/900675 [00:24<00:21, 19205.25it/s] 53%|█████▎    | 480772/900675 [00:25<00:22, 19026.21it/s] 54%|█████▎    | 482676/900675 [00:25<00:22, 18763.01it/s] 54%|█████▍    | 484554/900675 [00:25<00:22, 18716.55it/s] 54%|█████▍    | 486528/900675 [00:25<00:21, 19015.48it/s] 54%|█████▍    | 488431/900675 [00:25<00:21, 18987.60it/s] 54%|█████▍    | 490331/900675 [00:25<00:22, 18563.19it/s] 55%|█████▍    | 492278/900675 [00:25<00:21, 18829.02it/s] 55%|█████▍    | 494164/900675 [00:25<00:21, 18746.52it/s] 55%|█████▌    | 496176/900675 [00:25<00:21, 19149.72it/s] 55%|█████▌    | 498093/900675 [00:25<00:21, 19023.72it/s] 56%|█████▌    | 500183/900675 [00:26<00:20, 19577.77it/s] 56%|█████▌    | 502143/900675 [00:26<00:20, 19222.99it/s] 56%|█████▌    | 504068/900675 [00:26<00:20, 19031.83it/s] 56%|█████▌    | 506087/900675 [00:26<00:20, 19370.75it/s] 56%|█████▋    | 508026/900675 [00:26<00:20, 19143.85it/s] 57%|█████▋    | 510064/900675 [00:26<00:20, 19499.19it/s] 57%|█████▋    | 512042/900675 [00:26<00:19, 19577.56it/s] 57%|█████▋    | 514097/900675 [00:26<00:19, 19864.91it/s] 57%|█████▋    | 516085/900675 [00:26<00:19, 19744.06it/s] 58%|█████▊    | 518061/900675 [00:26<00:19, 19512.64it/s] 58%|█████▊    | 520031/900675 [00:27<00:19, 19567.12it/s] 58%|█████▊    | 522085/900675 [00:27<00:19, 19852.62it/s] 58%|█████▊    | 524072/900675 [00:27<00:19, 19407.21it/s] 58%|█████▊    | 526016/900675 [00:27<00:19, 19204.50it/s] 59%|█████▊    | 527952/900675 [00:27<00:19, 19247.56it/s] 59%|█████▉    | 529965/900675 [00:27<00:19, 19505.00it/s] 59%|█████▉    | 531917/900675 [00:27<00:19, 19284.79it/s] 59%|█████▉    | 533847/900675 [00:27<00:19, 18863.26it/s] 59%|█████▉    | 535736/900675 [00:27<00:19, 18744.62it/s] 60%|█████▉    | 537612/900675 [00:28<00:19, 18680.93it/s] 60%|█████▉    | 539576/900675 [00:28<00:19, 18960.38it/s] 60%|██████    | 541474/900675 [00:28<00:19, 18746.94it/s] 60%|██████    | 543523/900675 [00:28<00:18, 19257.82it/s] 61%|██████    | 545451/900675 [00:28<00:18, 19134.46it/s] 61%|██████    | 547366/900675 [00:28<00:18, 19041.04it/s] 61%|██████    | 549377/900675 [00:28<00:18, 19353.38it/s] 61%|██████    | 551320/900675 [00:28<00:18, 19374.00it/s] 61%|██████▏   | 553259/900675 [00:28<00:18, 19277.85it/s] 62%|██████▏   | 555188/900675 [00:28<00:18, 19064.55it/s] 62%|██████▏   | 557138/900675 [00:29<00:17, 19191.28it/s] 62%|██████▏   | 559058/900675 [00:29<00:18, 18891.62it/s] 62%|██████▏   | 560972/900675 [00:29<00:17, 18964.21it/s] 63%|██████▎   | 563087/900675 [00:29<00:17, 19606.23it/s] 63%|██████▎   | 565050/900675 [00:29<00:17, 19008.38it/s] 63%|██████▎   | 566956/900675 [00:29<00:17, 18815.91it/s] 63%|██████▎   | 569037/900675 [00:29<00:17, 19393.44it/s] 63%|██████▎   | 571170/900675 [00:29<00:16, 19961.89it/s] 64%|██████▎   | 573170/900675 [00:29<00:16, 19615.18it/s] 64%|██████▍   | 575136/900675 [00:29<00:17, 18968.68it/s] 64%|██████▍   | 577039/900675 [00:30<00:17, 18949.45it/s] 64%|██████▍   | 578939/900675 [00:30<00:17, 18624.81it/s] 64%|██████▍   | 580927/900675 [00:30<00:16, 18988.65it/s] 65%|██████▍   | 582944/900675 [00:30<00:16, 19328.97it/s] 65%|██████▍   | 585098/900675 [00:30<00:15, 19980.87it/s] 65%|██████▌   | 587100/900675 [00:30<00:16, 19379.42it/s] 65%|██████▌   | 589044/900675 [00:30<00:16, 19252.01it/s] 66%|██████▌   | 591024/900675 [00:30<00:15, 19407.48it/s] 66%|██████▌   | 592968/900675 [00:30<00:16, 18995.93it/s] 66%|██████▌   | 594952/900675 [00:30<00:15, 19241.06it/s] 66%|██████▋   | 596880/900675 [00:31<00:15, 19134.53it/s] 66%|██████▋   | 598796/900675 [00:31<00:15, 19053.39it/s] 67%|██████▋   | 600767/900675 [00:31<00:15, 19246.61it/s] 67%|██████▋   | 602693/900675 [00:31<00:15, 18707.80it/s] 67%|██████▋   | 604666/900675 [00:31<00:15, 19005.58it/s] 67%|██████▋   | 606603/900675 [00:31<00:15, 19105.37it/s] 68%|██████▊   | 608517/900675 [00:31<00:15, 18920.87it/s] 68%|██████▊   | 610554/900675 [00:31<00:15, 19339.81it/s] 68%|██████▊   | 612491/900675 [00:31<00:14, 19237.93it/s] 68%|██████▊   | 614417/900675 [00:32<00:15, 18629.78it/s] 68%|██████▊   | 616285/900675 [00:32<00:15, 18522.94it/s] 69%|██████▊   | 618555/900675 [00:32<00:14, 19742.31it/s] 69%|██████▉   | 620741/900675 [00:32<00:13, 20364.01it/s] 69%|██████▉   | 622783/900675 [00:32<00:13, 20237.42it/s] 69%|██████▉   | 624811/900675 [00:32<00:14, 19352.78it/s] 70%|██████▉   | 626873/900675 [00:32<00:13, 19714.22it/s] 70%|██████▉   | 628853/900675 [00:32<00:13, 19625.97it/s] 70%|███████   | 630822/900675 [00:32<00:13, 19436.92it/s] 70%|███████   | 632956/900675 [00:32<00:13, 19993.31it/s] 70%|███████   | 634960/900675 [00:33<00:13, 19973.04it/s] 71%|███████   | 636961/900675 [00:33<00:13, 19639.41it/s] 71%|███████   | 639010/900675 [00:33<00:13, 19884.03it/s] 71%|███████   | 641032/900675 [00:33<00:12, 19982.56it/s] 71%|███████▏  | 643033/900675 [00:33<00:12, 19822.94it/s] 72%|███████▏  | 645017/900675 [00:33<00:13, 19266.88it/s] 72%|███████▏  | 646989/900675 [00:33<00:13, 19396.79it/s] 72%|███████▏  | 648932/900675 [00:33<00:13, 18810.34it/s] 72%|███████▏  | 650819/900675 [00:33<00:13, 18548.77it/s] 72%|███████▏  | 652789/900675 [00:33<00:13, 18881.28it/s] 73%|███████▎  | 654809/900675 [00:34<00:12, 19266.43it/s] 73%|███████▎  | 656756/900675 [00:34<00:12, 19323.51it/s] 73%|███████▎  | 658708/900675 [00:34<00:12, 19377.67it/s] 73%|███████▎  | 660710/900675 [00:34<00:12, 19563.30it/s] 74%|███████▎  | 662683/900675 [00:34<00:12, 19598.62it/s] 74%|███████▍  | 664644/900675 [00:34<00:12, 19599.16it/s] 74%|███████▍  | 666605/900675 [00:34<00:11, 19588.07it/s] 74%|███████▍  | 668565/900675 [00:34<00:11, 19384.32it/s] 74%|███████▍  | 670667/900675 [00:34<00:11, 19862.67it/s] 75%|███████▍  | 672681/900675 [00:34<00:11, 19943.49it/s] 75%|███████▍  | 674677/900675 [00:35<00:11, 19817.90it/s] 75%|███████▌  | 676660/900675 [00:35<00:11, 19699.42it/s] 75%|███████▌  | 678631/900675 [00:35<00:11, 19505.06it/s] 76%|███████▌  | 680607/900675 [00:35<00:11, 19579.85it/s] 76%|███████▌  | 682566/900675 [00:35<00:11, 19269.71it/s] 76%|███████▌  | 684689/900675 [00:35<00:10, 19846.27it/s] 76%|███████▌  | 686676/900675 [00:35<00:10, 19679.10it/s] 76%|███████▋  | 688646/900675 [00:35<00:10, 19556.88it/s] 77%|███████▋  | 690603/900675 [00:35<00:10, 19144.39it/s] 77%|███████▋  | 692520/900675 [00:36<00:11, 18829.37it/s] 77%|███████▋  | 694462/900675 [00:36<00:10, 18995.02it/s] 77%|███████▋  | 696364/900675 [00:36<00:10, 18777.61it/s] 78%|███████▊  | 698394/900675 [00:36<00:10, 19221.25it/s] 78%|███████▊  | 700319/900675 [00:36<00:10, 19084.25it/s] 78%|███████▊  | 702396/900675 [00:36<00:10, 19578.29it/s] 78%|███████▊  | 704356/900675 [00:36<00:10, 19444.04it/s] 78%|███████▊  | 706302/900675 [00:36<00:10, 18740.37it/s] 79%|███████▊  | 708227/900675 [00:36<00:10, 18882.21it/s] 79%|███████▉  | 710310/900675 [00:36<00:09, 19449.33it/s] 79%|███████▉  | 712311/900675 [00:37<00:09, 19611.73it/s] 79%|███████▉  | 714331/900675 [00:37<00:09, 19781.08it/s] 80%|███████▉  | 716312/900675 [00:37<00:09, 19748.21it/s] 80%|███████▉  | 718289/900675 [00:37<00:09, 19366.46it/s] 80%|███████▉  | 720229/900675 [00:37<00:09, 19022.08it/s] 80%|████████  | 722296/900675 [00:37<00:09, 19497.68it/s] 80%|████████  | 724249/900675 [00:37<00:09, 19213.68it/s] 81%|████████  | 726174/900675 [00:37<00:09, 19007.16it/s] 81%|████████  | 728168/900675 [00:37<00:08, 19270.46it/s] 81%|████████  | 730098/900675 [00:37<00:09, 18790.33it/s] 81%|████████▏ | 732003/900675 [00:38<00:08, 18860.13it/s] 82%|████████▏ | 734143/900675 [00:38<00:08, 19605.20it/s] 82%|████████▏ | 736107/900675 [00:38<00:08, 19245.79it/s] 82%|████████▏ | 738274/900675 [00:38<00:08, 19951.80it/s] 82%|████████▏ | 740274/900675 [00:38<00:08, 19430.07it/s] 82%|████████▏ | 742223/900675 [00:38<00:08, 19154.04it/s] 83%|████████▎ | 744143/900675 [00:38<00:08, 18863.28it/s] 83%|████████▎ | 746039/900675 [00:38<00:08, 18889.50it/s] 83%|████████▎ | 747930/900675 [00:38<00:08, 18812.52it/s] 83%|████████▎ | 749864/900675 [00:39<00:07, 18966.56it/s] 83%|████████▎ | 751773/900675 [00:39<00:07, 18999.14it/s] 84%|████████▎ | 753757/900675 [00:39<00:07, 19244.36it/s] 84%|████████▍ | 755683/900675 [00:39<00:07, 18800.72it/s] 84%|████████▍ | 757593/900675 [00:39<00:07, 18881.49it/s] 84%|████████▍ | 759613/900675 [00:39<00:07, 19268.72it/s] 85%|████████▍ | 761661/900675 [00:39<00:07, 19624.17it/s] 85%|████████▍ | 763626/900675 [00:39<00:07, 19102.35it/s] 85%|████████▍ | 765541/900675 [00:39<00:07, 18963.61it/s] 85%|████████▌ | 767605/900675 [00:39<00:06, 19450.02it/s] 85%|████████▌ | 769553/900675 [00:40<00:06, 18782.11it/s] 86%|████████▌ | 771438/900675 [00:40<00:06, 18636.77it/s] 86%|████████▌ | 773421/900675 [00:40<00:06, 18981.66it/s] 86%|████████▌ | 775324/900675 [00:40<00:06, 18972.44it/s] 86%|████████▋ | 777225/900675 [00:40<00:06, 18893.17it/s] 87%|████████▋ | 779142/900675 [00:40<00:06, 18974.23it/s] 87%|████████▋ | 781041/900675 [00:40<00:06, 18642.08it/s] 87%|████████▋ | 782914/900675 [00:40<00:06, 18664.33it/s] 87%|████████▋ | 784782/900675 [00:40<00:06, 18598.57it/s] 87%|████████▋ | 786782/900675 [00:40<00:05, 19010.81it/s] 88%|████████▊ | 788685/900675 [00:41<00:05, 18941.63it/s] 88%|████████▊ | 790677/900675 [00:41<00:05, 19228.03it/s] 88%|████████▊ | 792601/900675 [00:41<00:05, 18878.38it/s] 88%|████████▊ | 794491/900675 [00:41<00:05, 18788.96it/s] 88%|████████▊ | 796509/900675 [00:41<00:05, 19196.79it/s] 89%|████████▊ | 798431/900675 [00:41<00:05, 19199.88it/s] 89%|████████▉ | 800353/900675 [00:41<00:05, 19149.05it/s] 89%|████████▉ | 802269/900675 [00:41<00:05, 19052.25it/s] 89%|████████▉ | 804175/900675 [00:41<00:05, 18905.50it/s] 90%|████████▉ | 806135/900675 [00:41<00:04, 19111.00it/s] 90%|████████▉ | 808047/900675 [00:42<00:04, 18539.88it/s] 90%|████████▉ | 809970/900675 [00:42<00:04, 18734.75it/s] 90%|█████████ | 811847/900675 [00:42<00:04, 18327.80it/s] 90%|█████████ | 813811/900675 [00:42<00:04, 18707.08it/s] 91%|█████████ | 815899/900675 [00:42<00:04, 19340.73it/s] 91%|█████████ | 818166/900675 [00:42<00:04, 20322.53it/s] 91%|█████████ | 820203/900675 [00:42<00:03, 20135.64it/s] 91%|█████████▏| 822220/900675 [00:42<00:04, 19471.35it/s] 92%|█████████▏| 824261/900675 [00:42<00:03, 19738.15it/s] 92%|█████████▏| 826241/900675 [00:43<00:03, 18932.10it/s] 92%|█████████▏| 828248/900675 [00:43<00:03, 19256.49it/s] 92%|█████████▏| 830182/900675 [00:43<00:03, 18670.65it/s] 92%|█████████▏| 832058/900675 [00:43<00:03, 18635.69it/s] 93%|█████████▎| 834004/900675 [00:43<00:03, 18871.13it/s] 93%|█████████▎| 835916/900675 [00:43<00:03, 18939.81it/s] 93%|█████████▎| 837901/900675 [00:43<00:03, 19206.97it/s] 93%|█████████▎| 839825/900675 [00:43<00:03, 19028.27it/s] 93%|█████████▎| 841819/900675 [00:43<00:03, 19297.16it/s] 94%|█████████▎| 843751/900675 [00:43<00:03, 18519.30it/s] 94%|█████████▍| 845611/900675 [00:44<00:03, 18289.51it/s] 94%|█████████▍| 847497/900675 [00:44<00:02, 18446.44it/s] 94%|█████████▍| 849396/900675 [00:44<00:02, 18597.16it/s] 95%|█████████▍| 851259/900675 [00:44<00:02, 18508.34it/s] 95%|█████████▍| 853113/900675 [00:44<00:02, 18507.73it/s] 95%|█████████▍| 855019/900675 [00:44<00:02, 18668.00it/s] 95%|█████████▌| 857005/900675 [00:44<00:02, 19022.19it/s] 95%|█████████▌| 858909/900675 [00:44<00:02, 18790.48it/s] 96%|█████████▌| 861033/900675 [00:44<00:02, 19495.82it/s] 96%|█████████▌| 863034/900675 [00:44<00:01, 19647.77it/s] 96%|█████████▌| 865001/900675 [00:45<00:01, 19411.07it/s] 96%|█████████▋| 866944/900675 [00:45<00:01, 19270.79it/s] 96%|█████████▋| 868873/900675 [00:45<00:01, 19008.25it/s] 97%|█████████▋| 870835/900675 [00:45<00:01, 19186.77it/s] 97%|█████████▋| 872755/900675 [00:45<00:01, 18912.85it/s] 97%|█████████▋| 874794/900675 [00:45<00:01, 19338.42it/s] 97%|█████████▋| 876798/900675 [00:45<00:01, 19541.58it/s] 98%|█████████▊| 878754/900675 [00:45<00:01, 19221.50it/s] 98%|█████████▊| 880679/900675 [00:45<00:01, 18859.28it/s] 98%|█████████▊| 882568/900675 [00:45<00:00, 18485.67it/s] 98%|█████████▊| 884504/900675 [00:46<00:00, 18735.92it/s] 98%|█████████▊| 886572/900675 [00:46<00:00, 19304.96it/s] 99%|█████████▊| 888506/900675 [00:46<00:00, 19083.20it/s] 99%|█████████▉| 890429/900675 [00:46<00:00, 19122.60it/s] 99%|█████████▉| 892344/900675 [00:46<00:00, 19041.41it/s] 99%|█████████▉| 894250/900675 [00:46<00:00, 18511.39it/s]100%|█████████▉| 896246/900675 [00:46<00:00, 18932.88it/s]100%|█████████▉| 898236/900675 [00:46<00:00, 19215.25it/s]100%|█████████▉| 900217/900675 [00:46<00:00, 19384.23it/s]100%|██████████| 900675/900675 [00:46<00:00, 19191.25it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]100%|██████████| 1/1 [00:00<00:00,  2.79it/s]SMOOTHED CONTEXTS
0
TOTAL CONTEXTS
1
2022-02-23 10:12:58 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(430640, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=430640, bias=False)
  )
)
2022-02-23 10:12:58 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-23 10:12:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-23 10:12:58 | INFO | fairseq_cli.train | criterion: GoodTuringSmoothingCriterion
2022-02-23 10:12:58 | INFO | fairseq_cli.train | num. shared model params: 239,401,984 (num. trained: 239,401,984)
2022-02-23 10:12:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-23 10:12:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.5/valid
2022-02-23 10:13:07 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-23 10:13:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-23 10:13:07 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-23 10:13:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-23 10:13:07 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-23 10:13:07 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-02-23 10:13:07 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_last.pt
2022-02-23 10:13:07 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_last.pt
2022-02-23 10:13:07 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-23 10:13:07 | INFO | fairseq.data.data_utils | loaded 900,675 examples from: data-bin/wikitext-103-raw-size-0.5/train
2022-02-23 10:13:08 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-23 10:13:08 | INFO | fairseq.trainer | begin training epoch 1
2022-02-23 10:13:08 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-23 10:39:20 | INFO | train_inner | epoch 001:    100 / 788 loss=17.516, ppl=187392, wps=4194.1, ups=0.06, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=3.434, train_wall=1549, gb_free=3.3, wall=1573
2022-02-23 11:05:22 | INFO | train_inner | epoch 001:    200 / 788 loss=14.985, ppl=32422.5, wps=4195.4, ups=0.06, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.725, train_wall=1539, gb_free=3.3, wall=3135
2022-02-23 11:31:23 | INFO | train_inner | epoch 001:    300 / 788 loss=12.66, ppl=6471.4, wps=4199.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=1.212, train_wall=1538, gb_free=3.3, wall=4695
2022-02-23 11:57:21 | INFO | train_inner | epoch 001:    400 / 788 loss=10.916, ppl=1932.03, wps=4205.4, ups=0.06, wpb=65536, bsz=128, num_updates=400, lr=5.009e-05, gnorm=0.703, train_wall=1536, gb_free=3.3, wall=6254
2022-02-23 12:23:18 | INFO | train_inner | epoch 001:    500 / 788 loss=10.177, ppl=1157.53, wps=4210.5, ups=0.06, wpb=65536, bsz=128, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=1534, gb_free=3.3, wall=7810
2022-02-23 12:49:15 | INFO | train_inner | epoch 001:    600 / 788 loss=9.808, ppl=896.31, wps=4208.9, ups=0.06, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.605, train_wall=1535, gb_free=3.3, wall=9367
2022-02-23 13:15:13 | INFO | train_inner | epoch 001:    700 / 788 loss=9.52, ppl=734.04, wps=4206.4, ups=0.06, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.644, train_wall=1536, gb_free=3.3, wall=10925
2022-02-23 13:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-23 13:38:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.078 | ppl 540.52 | wps 9159.6 | wpb 510.9 | bsz 1 | num_updates 788
2022-02-23 13:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 788 updates
2022-02-23 13:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 13:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 13:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 1 @ 788 updates, score 9.078) (writing took 7.022734976373613 seconds)
2022-02-23 13:38:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-23 13:38:24 | INFO | train | epoch 001 | loss 11.899 | ppl 3819.89 | wps 4193.9 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 788 | lr 9.85803e-05 | gnorm 1.204 | train_wall 12107 | gb_free 3.3 | wall 12317
2022-02-23 13:38:24 | INFO | fairseq.trainer | begin training epoch 2
2022-02-23 13:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-23 13:41:30 | INFO | train_inner | epoch 002:     12 / 788 loss=9.271, ppl=617.82, wps=4135.7, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=800, lr=0.00010008, gnorm=0.749, train_wall=1524, gb_free=3.3, wall=12503
2022-02-23 14:07:22 | INFO | train_inner | epoch 002:    112 / 788 loss=9.018, ppl=518.48, wps=4224.2, ups=0.06, wpb=65536, bsz=128, num_updates=900, lr=0.000112578, gnorm=0.823, train_wall=1529, gb_free=3.3, wall=14054
2022-02-23 14:33:15 | INFO | train_inner | epoch 002:    212 / 788 loss=8.815, ppl=450.37, wps=4219.3, ups=0.06, wpb=65534.7, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.923, train_wall=1531, gb_free=3.3, wall=15607
2022-02-23 14:59:19 | INFO | train_inner | epoch 002:    312 / 788 loss=8.63, ppl=396.3, wps=4188.5, ups=0.06, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.904, train_wall=1542, gb_free=3.3, wall=17172
2022-02-23 15:25:25 | INFO | train_inner | epoch 002:    412 / 788 loss=8.463, ppl=352.77, wps=4185, ups=0.06, wpb=65536, bsz=128, num_updates=1200, lr=0.00015007, gnorm=0.924, train_wall=1543, gb_free=3.3, wall=18738
2022-02-23 15:51:31 | INFO | train_inner | epoch 002:    512 / 788 loss=8.319, ppl=319.3, wps=4186.6, ups=0.06, wpb=65536, bsz=128, num_updates=1300, lr=0.000162568, gnorm=0.958, train_wall=1543, gb_free=3.3, wall=20303
2022-02-23 16:17:36 | INFO | train_inner | epoch 002:    612 / 788 loss=8.173, ppl=288.71, wps=4186.3, ups=0.06, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.97, train_wall=1543, gb_free=3.3, wall=21869
2022-02-23 16:43:42 | INFO | train_inner | epoch 002:    712 / 788 loss=8.033, ppl=261.98, wps=4186.7, ups=0.06, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.98, train_wall=1543, gb_free=3.3, wall=23434
2022-02-23 17:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-23 17:03:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.738 | ppl 213.42 | wps 8970.3 | wpb 510.9 | bsz 1 | num_updates 1576 | best_loss 7.738
2022-02-23 17:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 1576 updates
2022-02-23 17:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 17:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 17:03:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 2 @ 1576 updates, score 7.738) (writing took 7.204366682097316 seconds)
2022-02-23 17:03:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-23 17:03:56 | INFO | train | epoch 002 | loss 8.449 | ppl 349.45 | wps 4185.2 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 1576 | lr 0.000197061 | gnorm 0.93 | train_wall 12123 | gb_free 3.3 | wall 24648
2022-02-23 17:03:56 | INFO | fairseq.trainer | begin training epoch 3
2022-02-23 17:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-23 17:10:11 | INFO | train_inner | epoch 003:     24 / 788 loss=7.899, ppl=238.71, wps=4103.7, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=1600, lr=0.00020006, gnorm=0.985, train_wall=1535, gb_free=3.3, wall=25024
2022-02-23 17:36:17 | INFO | train_inner | epoch 003:    124 / 788 loss=7.736, ppl=213.14, wps=4186.4, ups=0.06, wpb=65536, bsz=128, num_updates=1700, lr=0.000212558, gnorm=0.976, train_wall=1543, gb_free=3.3, wall=26589
2022-02-23 18:02:22 | INFO | train_inner | epoch 003:    224 / 788 loss=7.633, ppl=198.54, wps=4186.5, ups=0.06, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.946, train_wall=1543, gb_free=3.3, wall=28155
2022-02-23 18:28:30 | INFO | train_inner | epoch 003:    324 / 788 loss=7.553, ppl=187.74, wps=4181.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.956, train_wall=1544, gb_free=3.3, wall=29722
2022-02-23 18:54:36 | INFO | train_inner | epoch 003:    424 / 788 loss=7.448, ppl=174.6, wps=4182.9, ups=0.06, wpb=65536, bsz=128, num_updates=2000, lr=0.00025005, gnorm=0.929, train_wall=1544, gb_free=3.3, wall=31289
2022-02-23 19:20:44 | INFO | train_inner | epoch 003:    524 / 788 loss=7.362, ppl=164.55, wps=4181, ups=0.06, wpb=65536, bsz=128, num_updates=2100, lr=0.000262548, gnorm=0.929, train_wall=1544, gb_free=3.3, wall=32856
2022-02-23 19:46:50 | INFO | train_inner | epoch 003:    624 / 788 loss=7.289, ppl=156.35, wps=4184.7, ups=0.06, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.909, train_wall=1543, gb_free=3.3, wall=34423
2022-02-23 20:12:56 | INFO | train_inner | epoch 003:    724 / 788 loss=7.2, ppl=147.05, wps=4185.6, ups=0.06, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.873, train_wall=1543, gb_free=3.3, wall=35988
2022-02-23 20:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-23 20:29:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.984 | ppl 126.62 | wps 8955.2 | wpb 510.9 | bsz 1 | num_updates 2364 | best_loss 6.984
2022-02-23 20:29:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 2364 updates
2022-02-23 20:29:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 20:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 20:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 3 @ 2364 updates, score 6.984) (writing took 7.571339322254062 seconds)
2022-02-23 20:30:02 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-23 20:30:02 | INFO | train | epoch 003 | loss 7.445 | ppl 174.22 | wps 4173.5 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 2364 | lr 0.000295541 | gnorm 0.93 | train_wall 12154 | gb_free 3.3 | wall 37015
2022-02-23 20:30:03 | INFO | fairseq.trainer | begin training epoch 4
2022-02-23 20:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-23 20:39:26 | INFO | train_inner | epoch 004:     36 / 788 loss=7.091, ppl=136.3, wps=4101.8, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=2400, lr=0.00030004, gnorm=0.874, train_wall=1536, gb_free=3.3, wall=37579
2022-02-23 21:05:33 | INFO | train_inner | epoch 004:    136 / 788 loss=6.966, ppl=125, wps=4183.3, ups=0.06, wpb=65536, bsz=128, num_updates=2500, lr=0.000312538, gnorm=0.861, train_wall=1544, gb_free=3.3, wall=39145
2022-02-23 21:31:40 | INFO | train_inner | epoch 004:    236 / 788 loss=6.914, ppl=120.62, wps=4182.5, ups=0.06, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.874, train_wall=1544, gb_free=3.3, wall=40712
2022-02-23 21:57:46 | INFO | train_inner | epoch 004:    336 / 788 loss=6.853, ppl=115.59, wps=4183.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.812, train_wall=1543, gb_free=3.3, wall=42279
2022-02-23 22:23:52 | INFO | train_inner | epoch 004:    436 / 788 loss=6.803, ppl=111.67, wps=4185.8, ups=0.06, wpb=65536, bsz=128, num_updates=2800, lr=0.00035003, gnorm=0.812, train_wall=1543, gb_free=3.3, wall=43845
2022-02-23 22:50:00 | INFO | train_inner | epoch 004:    536 / 788 loss=6.758, ppl=108.21, wps=4180, ups=0.06, wpb=65536, bsz=128, num_updates=2900, lr=0.000362528, gnorm=0.82, train_wall=1544, gb_free=3.3, wall=45412
2022-02-23 23:16:01 | INFO | train_inner | epoch 004:    636 / 788 loss=6.703, ppl=104.16, wps=4196.9, ups=0.06, wpb=65536, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.813, train_wall=1539, gb_free=3.3, wall=46974
2022-02-23 23:41:54 | INFO | train_inner | epoch 004:    736 / 788 loss=6.653, ppl=100.67, wps=4220, ups=0.06, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.775, train_wall=1531, gb_free=3.3, wall=48527
2022-02-23 23:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-23 23:55:41 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.494 | ppl 90.15 | wps 8958.4 | wpb 510.9 | bsz 1 | num_updates 3152 | best_loss 6.494
2022-02-23 23:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 3152 updates
2022-02-23 23:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 23:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-23 23:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 4 @ 3152 updates, score 6.494) (writing took 7.021151024848223 seconds)
2022-02-23 23:55:48 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-23 23:55:48 | INFO | train | epoch 004 | loss 6.802 | ppl 111.6 | wps 4180.6 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 3152 | lr 0.000394021 | gnorm 0.823 | train_wall 12133 | gb_free 3.3 | wall 49361
2022-02-23 23:55:48 | INFO | fairseq.trainer | begin training epoch 5
2022-02-23 23:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 00:08:19 | INFO | train_inner | epoch 005:     48 / 788 loss=6.534, ppl=92.7, wps=4116.3, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=3200, lr=0.00040002, gnorm=0.774, train_wall=1530, gb_free=3.3, wall=50112
2022-02-24 00:34:15 | INFO | train_inner | epoch 005:    148 / 788 loss=6.445, ppl=87.12, wps=4212.9, ups=0.06, wpb=65536, bsz=128, num_updates=3300, lr=0.000412518, gnorm=0.798, train_wall=1533, gb_free=3.3, wall=51667
2022-02-24 01:00:08 | INFO | train_inner | epoch 005:    248 / 788 loss=6.415, ppl=85.31, wps=4219.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.776, train_wall=1531, gb_free=3.3, wall=53221
2022-02-24 01:26:03 | INFO | train_inner | epoch 005:    348 / 788 loss=6.388, ppl=83.72, wps=4214.5, ups=0.06, wpb=65536, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.768, train_wall=1533, gb_free=3.3, wall=54776
2022-02-24 01:52:04 | INFO | train_inner | epoch 005:    448 / 788 loss=6.355, ppl=81.88, wps=4197.6, ups=0.06, wpb=65536, bsz=128, num_updates=3600, lr=0.00045001, gnorm=0.756, train_wall=1539, gb_free=3.3, wall=56337
2022-02-24 02:17:58 | INFO | train_inner | epoch 005:    548 / 788 loss=6.326, ppl=80.24, wps=4219, ups=0.06, wpb=65536, bsz=128, num_updates=3700, lr=0.000462508, gnorm=0.76, train_wall=1531, gb_free=3.3, wall=57890
2022-02-24 02:43:56 | INFO | train_inner | epoch 005:    648 / 788 loss=6.295, ppl=78.54, wps=4205.3, ups=0.06, wpb=65536, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.725, train_wall=1536, gb_free=3.3, wall=59449
2022-02-24 03:09:53 | INFO | train_inner | epoch 005:    748 / 788 loss=6.266, ppl=76.96, wps=4209.9, ups=0.06, wpb=65536, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.734, train_wall=1534, gb_free=3.3, wall=61005
2022-02-24 03:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 03:20:32 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.183 | ppl 72.63 | wps 9064 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 6.183
2022-02-24 03:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 3940 updates
2022-02-24 03:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 03:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 03:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 5 @ 3940 updates, score 6.183) (writing took 6.991743518039584 seconds)
2022-02-24 03:20:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-24 03:20:39 | INFO | train | epoch 005 | loss 6.358 | ppl 82 | wps 4199 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 3940 | lr 0.000492502 | gnorm 0.757 | train_wall 12083 | gb_free 3.3 | wall 61652
2022-02-24 03:20:40 | INFO | fairseq.trainer | begin training epoch 6
2022-02-24 03:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 03:36:15 | INFO | train_inner | epoch 006:     60 / 788 loss=6.159, ppl=71.48, wps=4122.3, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=4000, lr=0.0005, gnorm=0.71, train_wall=1529, gb_free=3.3, wall=62588
2022-02-24 04:02:22 | INFO | train_inner | epoch 006:    160 / 788 loss=6.09, ppl=68.14, wps=4183.2, ups=0.06, wpb=65536, bsz=128, num_updates=4100, lr=0.000493865, gnorm=0.715, train_wall=1543, gb_free=3.3, wall=64154
2022-02-24 04:28:18 | INFO | train_inner | epoch 006:    260 / 788 loss=6.069, ppl=67.15, wps=4212.5, ups=0.06, wpb=65536, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.697, train_wall=1533, gb_free=3.3, wall=65710
2022-02-24 04:54:12 | INFO | train_inner | epoch 006:    360 / 788 loss=6.04, ppl=65.81, wps=4215.1, ups=0.06, wpb=65536, bsz=128, num_updates=4300, lr=0.000482243, gnorm=0.656, train_wall=1532, gb_free=3.3, wall=67265
2022-02-24 05:20:10 | INFO | train_inner | epoch 006:    460 / 788 loss=6.018, ppl=64.82, wps=4206.6, ups=0.06, wpb=65536, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.676, train_wall=1535, gb_free=3.3, wall=68823
2022-02-24 05:46:12 | INFO | train_inner | epoch 006:    560 / 788 loss=6.005, ppl=64.2, wps=4196, ups=0.06, wpb=65536, bsz=128, num_updates=4500, lr=0.000471405, gnorm=0.644, train_wall=1539, gb_free=3.3, wall=70385
2022-02-24 06:12:07 | INFO | train_inner | epoch 006:    660 / 788 loss=5.993, ppl=63.68, wps=4215.6, ups=0.06, wpb=65536, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.627, train_wall=1532, gb_free=3.3, wall=71939
2022-02-24 06:38:02 | INFO | train_inner | epoch 006:    760 / 788 loss=5.981, ppl=63.15, wps=4213.3, ups=0.06, wpb=65536, bsz=128, num_updates=4700, lr=0.000461266, gnorm=0.655, train_wall=1533, gb_free=3.3, wall=73495
2022-02-24 06:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 06:45:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 5.969 | ppl 62.65 | wps 9162.8 | wpb 510.9 | bsz 1 | num_updates 4728 | best_loss 5.969
2022-02-24 06:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 4728 updates
2022-02-24 06:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 06:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 06:45:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 6 @ 4728 updates, score 5.969) (writing took 7.378283857367933 seconds)
2022-02-24 06:45:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-24 06:45:41 | INFO | train | epoch 006 | loss 6.031 | ppl 65.39 | wps 4195.5 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 4728 | lr 0.000459898 | gnorm 0.668 | train_wall 12092 | gb_free 3.3 | wall 73954
2022-02-24 06:45:41 | INFO | fairseq.trainer | begin training epoch 7
2022-02-24 06:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 07:04:20 | INFO | train_inner | epoch 007:     72 / 788 loss=5.841, ppl=57.31, wps=4135, ups=0.06, wpb=65232.6, bsz=127.4, num_updates=4800, lr=0.000456435, gnorm=0.618, train_wall=1524, gb_free=3.3, wall=75072
2022-02-24 07:30:22 | INFO | train_inner | epoch 007:    172 / 788 loss=5.788, ppl=55.26, wps=4195.9, ups=0.06, wpb=65536, bsz=128, num_updates=4900, lr=0.000451754, gnorm=0.636, train_wall=1539, gb_free=3.3, wall=76634
2022-02-24 07:56:20 | INFO | train_inner | epoch 007:    272 / 788 loss=5.777, ppl=54.83, wps=4204.8, ups=0.06, wpb=65536, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.592, train_wall=1536, gb_free=3.3, wall=78193
2022-02-24 08:22:20 | INFO | train_inner | epoch 007:    372 / 788 loss=5.788, ppl=55.27, wps=4202.9, ups=0.06, wpb=65536, bsz=128, num_updates=5100, lr=0.000442807, gnorm=0.611, train_wall=1537, gb_free=3.3, wall=79752
2022-02-24 08:48:18 | INFO | train_inner | epoch 007:    472 / 788 loss=5.783, ppl=55.07, wps=4204.3, ups=0.06, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.606, train_wall=1536, gb_free=3.3, wall=81311
2022-02-24 09:14:18 | INFO | train_inner | epoch 007:    572 / 788 loss=5.778, ppl=54.86, wps=4202.3, ups=0.06, wpb=65536, bsz=128, num_updates=5300, lr=0.000434372, gnorm=0.585, train_wall=1537, gb_free=3.3, wall=82871
2022-02-24 09:40:17 | INFO | train_inner | epoch 007:    672 / 788 loss=5.783, ppl=55.06, wps=4203.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.612, train_wall=1537, gb_free=3.3, wall=84430
2022-02-24 10:06:17 | INFO | train_inner | epoch 007:    772 / 788 loss=5.772, ppl=54.64, wps=4201.8, ups=0.06, wpb=65536, bsz=128, num_updates=5500, lr=0.000426401, gnorm=0.594, train_wall=1537, gb_free=3.3, wall=85989
2022-02-24 10:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 10:10:43 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.824 | ppl 56.66 | wps 9071.1 | wpb 510.9 | bsz 1 | num_updates 5516 | best_loss 5.824
2022-02-24 10:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 5516 updates
2022-02-24 10:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 10:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 10:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 7 @ 5516 updates, score 5.824) (writing took 6.747129964642227 seconds)
2022-02-24 10:10:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-24 10:10:50 | INFO | train | epoch 007 | loss 5.782 | ppl 55.01 | wps 4193.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 5516 | lr 0.000425783 | gnorm 0.607 | train_wall 12101 | gb_free 3.3 | wall 86263
2022-02-24 10:10:50 | INFO | fairseq.trainer | begin training epoch 8
2022-02-24 10:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 10:32:40 | INFO | train_inner | epoch 008:     84 / 788 loss=5.606, ppl=48.69, wps=4120.2, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=5600, lr=0.000422577, gnorm=0.594, train_wall=1530, gb_free=3.3, wall=87573
2022-02-24 10:58:40 | INFO | train_inner | epoch 008:    184 / 788 loss=5.598, ppl=48.45, wps=4200.3, ups=0.06, wpb=65536, bsz=128, num_updates=5700, lr=0.000418854, gnorm=0.614, train_wall=1537, gb_free=3.3, wall=89133
2022-02-24 11:24:39 | INFO | train_inner | epoch 008:    284 / 788 loss=5.593, ppl=48.26, wps=4204.4, ups=0.06, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.575, train_wall=1536, gb_free=3.3, wall=90692
2022-02-24 11:50:37 | INFO | train_inner | epoch 008:    384 / 788 loss=5.611, ppl=48.87, wps=4206.8, ups=0.06, wpb=65536, bsz=128, num_updates=5900, lr=0.000411693, gnorm=0.599, train_wall=1535, gb_free=3.3, wall=92250
2022-02-24 12:16:35 | INFO | train_inner | epoch 008:    484 / 788 loss=5.608, ppl=48.78, wps=4205.6, ups=0.06, wpb=65534.7, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.595, train_wall=1536, gb_free=3.3, wall=93808
2022-02-24 12:42:33 | INFO | train_inner | epoch 008:    584 / 788 loss=5.617, ppl=49.07, wps=4206.4, ups=0.06, wpb=65536, bsz=128, num_updates=6100, lr=0.000404888, gnorm=0.584, train_wall=1536, gb_free=3.3, wall=95366
2022-02-24 13:08:32 | INFO | train_inner | epoch 008:    684 / 788 loss=5.614, ppl=48.98, wps=4205.3, ups=0.06, wpb=65536, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.571, train_wall=1536, gb_free=3.3, wall=96924
2022-02-24 13:34:28 | INFO | train_inner | epoch 008:    784 / 788 loss=5.611, ppl=48.86, wps=4209.5, ups=0.06, wpb=65536, bsz=128, num_updates=6300, lr=0.00039841, gnorm=0.569, train_wall=1534, gb_free=3.3, wall=98481
2022-02-24 13:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 13:35:48 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.723 | ppl 52.83 | wps 9104.4 | wpb 510.9 | bsz 1 | num_updates 6304 | best_loss 5.723
2022-02-24 13:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 6304 updates
2022-02-24 13:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 13:35:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 13:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 8 @ 6304 updates, score 5.723) (writing took 7.690550968050957 seconds)
2022-02-24 13:35:55 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-24 13:35:55 | INFO | train | epoch 008 | loss 5.604 | ppl 48.65 | wps 4194.3 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 6304 | lr 0.000398283 | gnorm 0.587 | train_wall 12096 | gb_free 3.3 | wall 98568
2022-02-24 13:35:55 | INFO | fairseq.trainer | begin training epoch 9
2022-02-24 13:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 14:00:50 | INFO | train_inner | epoch 009:     96 / 788 loss=5.44, ppl=43.41, wps=4124.4, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=6400, lr=0.000395285, gnorm=0.573, train_wall=1527, gb_free=3.3, wall=100063
2022-02-24 14:26:46 | INFO | train_inner | epoch 009:    196 / 788 loss=5.449, ppl=43.67, wps=4213.2, ups=0.06, wpb=65536, bsz=128, num_updates=6500, lr=0.000392232, gnorm=0.584, train_wall=1533, gb_free=3.3, wall=101618
2022-02-24 14:52:41 | INFO | train_inner | epoch 009:    296 / 788 loss=5.457, ppl=43.94, wps=4212.1, ups=0.06, wpb=65536, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.559, train_wall=1534, gb_free=3.3, wall=103174
2022-02-24 15:18:38 | INFO | train_inner | epoch 009:    396 / 788 loss=5.49, ppl=44.94, wps=4211.2, ups=0.06, wpb=65536, bsz=128, num_updates=6700, lr=0.000386334, gnorm=0.584, train_wall=1534, gb_free=3.3, wall=104730
2022-02-24 15:44:33 | INFO | train_inner | epoch 009:    496 / 788 loss=5.484, ppl=44.75, wps=4212.6, ups=0.06, wpb=65536, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.573, train_wall=1533, gb_free=3.3, wall=106286
2022-02-24 16:10:27 | INFO | train_inner | epoch 009:    596 / 788 loss=5.488, ppl=44.88, wps=4218.8, ups=0.06, wpb=65534.7, bsz=128, num_updates=6900, lr=0.000380693, gnorm=0.562, train_wall=1531, gb_free=3.3, wall=107839
2022-02-24 16:36:21 | INFO | train_inner | epoch 009:    696 / 788 loss=5.481, ppl=44.67, wps=4217.9, ups=0.06, wpb=65536, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.593, train_wall=1532, gb_free=3.3, wall=109393
2022-02-24 17:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 17:00:27 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.656 | ppl 50.44 | wps 9118.5 | wpb 510.9 | bsz 1 | num_updates 7092 | best_loss 5.656
2022-02-24 17:00:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 7092 updates
2022-02-24 17:00:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 17:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 17:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 9 @ 7092 updates, score 5.656) (writing took 6.823846790008247 seconds)
2022-02-24 17:00:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-24 17:00:34 | INFO | train | epoch 009 | loss 5.47 | ppl 44.33 | wps 4203.3 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 7092 | lr 0.000375505 | gnorm 0.573 | train_wall 12072 | gb_free 3.3 | wall 110847
2022-02-24 17:00:34 | INFO | fairseq.trainer | begin training epoch 10
2022-02-24 17:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 17:02:39 | INFO | train_inner | epoch 010:      8 / 788 loss=5.463, ppl=44.1, wps=4134, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=7100, lr=0.000375293, gnorm=0.553, train_wall=1525, gb_free=3.3, wall=110971
2022-02-24 17:28:33 | INFO | train_inner | epoch 010:    108 / 788 loss=5.311, ppl=39.7, wps=4216.3, ups=0.06, wpb=65536, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.563, train_wall=1532, gb_free=3.3, wall=112526
2022-02-24 17:54:27 | INFO | train_inner | epoch 010:    208 / 788 loss=5.343, ppl=40.58, wps=4217.2, ups=0.06, wpb=65536, bsz=128, num_updates=7300, lr=0.000370117, gnorm=0.584, train_wall=1532, gb_free=3.3, wall=114080
2022-02-24 18:20:21 | INFO | train_inner | epoch 010:    308 / 788 loss=5.353, ppl=40.86, wps=4218.1, ups=0.06, wpb=65536, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.574, train_wall=1531, gb_free=3.3, wall=115633
2022-02-24 18:46:14 | INFO | train_inner | epoch 010:    408 / 788 loss=5.373, ppl=41.43, wps=4218, ups=0.06, wpb=65536, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.569, train_wall=1532, gb_free=3.3, wall=117187
2022-02-24 19:12:08 | INFO | train_inner | epoch 010:    508 / 788 loss=5.38, ppl=41.64, wps=4217.6, ups=0.06, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.578, train_wall=1532, gb_free=3.3, wall=118741
2022-02-24 19:38:02 | INFO | train_inner | epoch 010:    608 / 788 loss=5.385, ppl=41.78, wps=4216.5, ups=0.06, wpb=65536, bsz=128, num_updates=7700, lr=0.000360375, gnorm=0.575, train_wall=1532, gb_free=3.3, wall=120295
2022-02-24 20:03:56 | INFO | train_inner | epoch 010:    708 / 788 loss=5.384, ppl=41.76, wps=4217.6, ups=0.06, wpb=65536, bsz=128, num_updates=7800, lr=0.000358057, gnorm=0.563, train_wall=1532, gb_free=3.3, wall=121849
2022-02-24 20:24:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 20:24:56 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.614 | ppl 48.97 | wps 9161.1 | wpb 510.9 | bsz 1 | num_updates 7880 | best_loss 5.614
2022-02-24 20:24:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 7880 updates
2022-02-24 20:24:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 20:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 20:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 10 @ 7880 updates, score 5.614) (writing took 6.095101960003376 seconds)
2022-02-24 20:25:02 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-24 20:25:02 | INFO | train | epoch 010 | loss 5.363 | ppl 41.14 | wps 4207.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 7880 | lr 0.000356235 | gnorm 0.572 | train_wall 12063 | gb_free 3.3 | wall 123115
2022-02-24 20:25:02 | INFO | fairseq.trainer | begin training epoch 11
2022-02-24 20:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 20:30:13 | INFO | train_inner | epoch 011:     20 / 788 loss=5.346, ppl=40.67, wps=4137.3, ups=0.06, wpb=65232.6, bsz=127.4, num_updates=7900, lr=0.000355784, gnorm=0.561, train_wall=1524, gb_free=3.3, wall=123426
2022-02-24 20:56:08 | INFO | train_inner | epoch 011:    120 / 788 loss=5.223, ppl=37.35, wps=4215.3, ups=0.06, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.561, train_wall=1532, gb_free=3.3, wall=124980
2022-02-24 21:22:02 | INFO | train_inner | epoch 011:    220 / 788 loss=5.245, ppl=37.91, wps=4216.4, ups=0.06, wpb=65536, bsz=128, num_updates=8100, lr=0.000351364, gnorm=0.566, train_wall=1532, gb_free=3.3, wall=126535
2022-02-24 21:47:57 | INFO | train_inner | epoch 011:    320 / 788 loss=5.265, ppl=38.44, wps=4215.8, ups=0.06, wpb=65536, bsz=128, num_updates=8200, lr=0.000349215, gnorm=0.572, train_wall=1532, gb_free=3.3, wall=128089
2022-02-24 22:13:51 | INFO | train_inner | epoch 011:    420 / 788 loss=5.275, ppl=38.72, wps=4216.7, ups=0.06, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.582, train_wall=1532, gb_free=3.3, wall=129643
2022-02-24 22:39:44 | INFO | train_inner | epoch 011:    520 / 788 loss=5.292, ppl=39.19, wps=4217.9, ups=0.06, wpb=65534.7, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.581, train_wall=1532, gb_free=3.3, wall=131197
2022-02-24 23:05:39 | INFO | train_inner | epoch 011:    620 / 788 loss=5.306, ppl=39.55, wps=4217.2, ups=0.06, wpb=65536, bsz=128, num_updates=8500, lr=0.000342997, gnorm=0.557, train_wall=1532, gb_free=3.3, wall=132751
2022-02-24 23:31:32 | INFO | train_inner | epoch 011:    720 / 788 loss=5.305, ppl=39.54, wps=4217.3, ups=0.06, wpb=65536, bsz=128, num_updates=8600, lr=0.000340997, gnorm=0.565, train_wall=1532, gb_free=3.3, wall=134305
2022-02-24 23:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-24 23:49:27 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.585 | ppl 48.01 | wps 9160.5 | wpb 510.9 | bsz 1 | num_updates 8668 | best_loss 5.585
2022-02-24 23:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 8668 updates
2022-02-24 23:49:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 23:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-24 23:49:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 11 @ 8668 updates, score 5.585) (writing took 6.0574505580589175 seconds)
2022-02-24 23:49:33 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-24 23:49:33 | INFO | train | epoch 011 | loss 5.274 | ppl 38.69 | wps 4206.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 8668 | lr 0.000339657 | gnorm 0.569 | train_wall 12066 | gb_free 3.3 | wall 135385
2022-02-24 23:49:33 | INFO | fairseq.trainer | begin training epoch 12
2022-02-24 23:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-24 23:57:50 | INFO | train_inner | epoch 012:     32 / 788 loss=5.247, ppl=37.98, wps=4134.3, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=8700, lr=0.000339032, gnorm=0.573, train_wall=1526, gb_free=3.3, wall=135883
2022-02-25 00:23:46 | INFO | train_inner | epoch 012:    132 / 788 loss=5.147, ppl=35.43, wps=4214, ups=0.06, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.555, train_wall=1533, gb_free=3.3, wall=137438
2022-02-25 00:49:40 | INFO | train_inner | epoch 012:    232 / 788 loss=5.173, ppl=36.07, wps=4215.1, ups=0.06, wpb=65536, bsz=128, num_updates=8900, lr=0.000335201, gnorm=0.578, train_wall=1533, gb_free=3.3, wall=138993
2022-02-25 01:15:39 | INFO | train_inner | epoch 012:    332 / 788 loss=5.192, ppl=36.56, wps=4204.3, ups=0.06, wpb=65536, bsz=128, num_updates=9000, lr=0.000333333, gnorm=0.569, train_wall=1537, gb_free=3.3, wall=140552
2022-02-25 01:41:44 | INFO | train_inner | epoch 012:    432 / 788 loss=5.194, ppl=36.61, wps=4187.5, ups=0.06, wpb=65536, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.566, train_wall=1543, gb_free=3.3, wall=142117
2022-02-25 02:07:49 | INFO | train_inner | epoch 012:    532 / 788 loss=5.219, ppl=37.25, wps=4186.9, ups=0.06, wpb=65534.7, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.555, train_wall=1543, gb_free=3.3, wall=143682
2022-02-25 02:33:52 | INFO | train_inner | epoch 012:    632 / 788 loss=5.224, ppl=37.36, wps=4193.1, ups=0.06, wpb=65536, bsz=128, num_updates=9300, lr=0.000327913, gnorm=0.566, train_wall=1541, gb_free=3.3, wall=145245
2022-02-25 02:59:57 | INFO | train_inner | epoch 012:    732 / 788 loss=5.235, ppl=37.65, wps=4187.7, ups=0.06, wpb=65536, bsz=128, num_updates=9400, lr=0.000326164, gnorm=0.591, train_wall=1543, gb_free=3.3, wall=146810
2022-02-25 03:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 03:14:51 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.555 | ppl 47 | wps 9036.9 | wpb 510.9 | bsz 1 | num_updates 9456 | best_loss 5.555
2022-02-25 03:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 9456 updates
2022-02-25 03:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 03:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 03:14:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 12 @ 9456 updates, score 5.555) (writing took 5.923054086975753 seconds)
2022-02-25 03:14:57 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-25 03:14:57 | INFO | train | epoch 012 | loss 5.199 | ppl 36.73 | wps 4187.9 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 9456 | lr 0.000325197 | gnorm 0.567 | train_wall 12118 | gb_free 3.3 | wall 147709
2022-02-25 03:14:57 | INFO | fairseq.trainer | begin training epoch 13
2022-02-25 03:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 03:26:23 | INFO | train_inner | epoch 013:     44 / 788 loss=5.161, ppl=35.79, wps=4113.7, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=9500, lr=0.000324443, gnorm=0.564, train_wall=1533, gb_free=3.3, wall=148396
2022-02-25 03:52:28 | INFO | train_inner | epoch 013:    144 / 788 loss=5.082, ppl=33.86, wps=4187.9, ups=0.06, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.557, train_wall=1542, gb_free=3.3, wall=149961
2022-02-25 04:18:35 | INFO | train_inner | epoch 013:    244 / 788 loss=5.111, ppl=34.56, wps=4182.5, ups=0.06, wpb=65536, bsz=128, num_updates=9700, lr=0.000321081, gnorm=0.584, train_wall=1544, gb_free=3.3, wall=151528
2022-02-25 04:44:37 | INFO | train_inner | epoch 013:    344 / 788 loss=5.127, ppl=34.96, wps=4195, ups=0.06, wpb=65534.7, bsz=128, num_updates=9800, lr=0.000319438, gnorm=0.563, train_wall=1540, gb_free=3.3, wall=153090
2022-02-25 05:10:42 | INFO | train_inner | epoch 013:    444 / 788 loss=5.15, ppl=35.5, wps=4187.1, ups=0.06, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.592, train_wall=1543, gb_free=3.3, wall=154655
2022-02-25 05:36:49 | INFO | train_inner | epoch 013:    544 / 788 loss=5.153, ppl=35.57, wps=4182.6, ups=0.06, wpb=65536, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.567, train_wall=1544, gb_free=3.3, wall=156222
2022-02-25 06:02:56 | INFO | train_inner | epoch 013:    644 / 788 loss=5.162, ppl=35.8, wps=4182.3, ups=0.06, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.581, train_wall=1544, gb_free=3.3, wall=157789
2022-02-25 06:29:00 | INFO | train_inner | epoch 013:    744 / 788 loss=5.171, ppl=36.03, wps=4190.8, ups=0.06, wpb=65536, bsz=128, num_updates=10200, lr=0.000313112, gnorm=0.591, train_wall=1541, gb_free=3.3, wall=159353
2022-02-25 06:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 06:40:45 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.541 | ppl 46.56 | wps 9002.9 | wpb 510.9 | bsz 1 | num_updates 10244 | best_loss 5.541
2022-02-25 06:40:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 10244 updates
2022-02-25 06:40:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 06:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 06:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 13 @ 10244 updates, score 5.541) (writing took 6.232390968129039 seconds)
2022-02-25 06:40:52 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-25 06:40:52 | INFO | train | epoch 013 | loss 5.134 | ppl 35.12 | wps 4177.4 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 10244 | lr 0.000312439 | gnorm 0.576 | train_wall 12146 | gb_free 3.3 | wall 160064
2022-02-25 06:40:52 | INFO | fairseq.trainer | begin training epoch 14
2022-02-25 06:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 06:55:28 | INFO | train_inner | epoch 014:     56 / 788 loss=5.085, ppl=33.94, wps=4108.9, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=10300, lr=0.000311588, gnorm=0.583, train_wall=1534, gb_free=3.3, wall=160940
2022-02-25 07:21:28 | INFO | train_inner | epoch 014:    156 / 788 loss=5.03, ppl=32.67, wps=4199.5, ups=0.06, wpb=65534.7, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.569, train_wall=1538, gb_free=3.3, wall=162501
2022-02-25 07:47:24 | INFO | train_inner | epoch 014:    256 / 788 loss=5.05, ppl=33.13, wps=4213, ups=0.06, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.587, train_wall=1533, gb_free=3.3, wall=164056
2022-02-25 08:13:23 | INFO | train_inner | epoch 014:    356 / 788 loss=5.059, ppl=33.34, wps=4203.9, ups=0.06, wpb=65536, bsz=128, num_updates=10600, lr=0.000307148, gnorm=0.57, train_wall=1537, gb_free=3.3, wall=165615
2022-02-25 08:39:21 | INFO | train_inner | epoch 014:    456 / 788 loss=5.087, ppl=34, wps=4206.2, ups=0.06, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.576, train_wall=1536, gb_free=3.3, wall=167173
2022-02-25 09:05:20 | INFO | train_inner | epoch 014:    556 / 788 loss=5.108, ppl=34.48, wps=4202.5, ups=0.06, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.56, train_wall=1537, gb_free=3.3, wall=168733
2022-02-25 09:31:22 | INFO | train_inner | epoch 014:    656 / 788 loss=5.116, ppl=34.68, wps=4197.5, ups=0.06, wpb=65536, bsz=128, num_updates=10900, lr=0.000302891, gnorm=0.591, train_wall=1539, gb_free=3.3, wall=170294
2022-02-25 09:57:23 | INFO | train_inner | epoch 014:    756 / 788 loss=5.116, ppl=34.68, wps=4196.4, ups=0.06, wpb=65536, bsz=128, num_updates=11000, lr=0.000301511, gnorm=0.605, train_wall=1539, gb_free=3.3, wall=171856
2022-02-25 10:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 10:06:00 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.525 | ppl 46.06 | wps 9029.1 | wpb 510.9 | bsz 1 | num_updates 11032 | best_loss 5.525
2022-02-25 10:06:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 11032 updates
2022-02-25 10:06:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 10:06:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 10:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 14 @ 11032 updates, score 5.525) (writing took 6.392363462597132 seconds)
2022-02-25 10:06:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-25 10:06:06 | INFO | train | epoch 014 | loss 5.078 | ppl 33.77 | wps 4191.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 11032 | lr 0.000301074 | gnorm 0.581 | train_wall 12107 | gb_free 3.3 | wall 172379
2022-02-25 10:06:07 | INFO | fairseq.trainer | begin training epoch 15
2022-02-25 10:06:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 10:23:49 | INFO | train_inner | epoch 015:     68 / 788 loss=5.013, ppl=32.29, wps=4115, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=11100, lr=0.00030015, gnorm=0.582, train_wall=1532, gb_free=3.3, wall=173441
2022-02-25 10:49:50 | INFO | train_inner | epoch 015:    168 / 788 loss=4.978, ppl=31.52, wps=4196.8, ups=0.06, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.583, train_wall=1539, gb_free=3.3, wall=175003
2022-02-25 11:16:27 | INFO | train_inner | epoch 015:    268 / 788 loss=4.992, ppl=31.83, wps=4104.7, ups=0.06, wpb=65536, bsz=128, num_updates=11300, lr=0.000297482, gnorm=0.586, train_wall=1574, gb_free=3.3, wall=176599
2022-02-25 11:42:26 | INFO | train_inner | epoch 015:    368 / 788 loss=5.026, ppl=32.58, wps=4201.8, ups=0.06, wpb=65534.7, bsz=128, num_updates=11400, lr=0.000296174, gnorm=0.577, train_wall=1537, gb_free=3.3, wall=178159
2022-02-25 12:08:25 | INFO | train_inner | epoch 015:    468 / 788 loss=5.045, ppl=33.02, wps=4205.8, ups=0.06, wpb=65536, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.619, train_wall=1536, gb_free=3.3, wall=179717
2022-02-25 12:34:23 | INFO | train_inner | epoch 015:    568 / 788 loss=5.05, ppl=33.14, wps=4205, ups=0.06, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.565, train_wall=1536, gb_free=3.3, wall=181276
2022-02-25 13:00:23 | INFO | train_inner | epoch 015:    668 / 788 loss=5.064, ppl=33.45, wps=4201.8, ups=0.06, wpb=65536, bsz=128, num_updates=11700, lr=0.000292353, gnorm=0.577, train_wall=1537, gb_free=3.3, wall=182836
2022-02-25 13:26:24 | INFO | train_inner | epoch 015:    768 / 788 loss=5.074, ppl=33.69, wps=4196.8, ups=0.06, wpb=65536, bsz=128, num_updates=11800, lr=0.000291111, gnorm=0.58, train_wall=1539, gb_free=3.3, wall=184397
2022-02-25 13:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 13:31:53 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.514 | ppl 45.71 | wps 9099.2 | wpb 510.9 | bsz 1 | num_updates 11820 | best_loss 5.514
2022-02-25 13:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 11820 updates
2022-02-25 13:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 13:31:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 13:31:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 15 @ 11820 updates, score 5.514) (writing took 6.549965965561569 seconds)
2022-02-25 13:31:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-25 13:31:59 | INFO | train | epoch 015 | loss 5.027 | ppl 32.62 | wps 4178.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 11820 | lr 0.000290865 | gnorm 0.581 | train_wall 12145 | gb_free 3.3 | wall 184732
2022-02-25 13:32:00 | INFO | fairseq.trainer | begin training epoch 16
2022-02-25 13:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 13:52:48 | INFO | train_inner | epoch 016:     80 / 788 loss=4.935, ppl=30.6, wps=4118.2, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=11900, lr=0.000289886, gnorm=0.575, train_wall=1531, gb_free=3.3, wall=185981
2022-02-25 14:18:51 | INFO | train_inner | epoch 016:    180 / 788 loss=4.932, ppl=30.53, wps=4194.9, ups=0.06, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.591, train_wall=1540, gb_free=3.3, wall=187543
2022-02-25 14:44:57 | INFO | train_inner | epoch 016:    280 / 788 loss=4.957, ppl=31.05, wps=4184.9, ups=0.06, wpb=65536, bsz=128, num_updates=12100, lr=0.00028748, gnorm=0.578, train_wall=1543, gb_free=3.3, wall=189109
2022-02-25 15:11:00 | INFO | train_inner | epoch 016:    380 / 788 loss=4.988, ppl=31.73, wps=4191.6, ups=0.06, wpb=65536, bsz=128, num_updates=12200, lr=0.000286299, gnorm=0.579, train_wall=1541, gb_free=3.3, wall=190673
2022-02-25 15:37:03 | INFO | train_inner | epoch 016:    480 / 788 loss=4.997, ppl=31.92, wps=4192.9, ups=0.06, wpb=65534.7, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.59, train_wall=1540, gb_free=3.3, wall=192236
2022-02-25 16:03:05 | INFO | train_inner | epoch 016:    580 / 788 loss=5.015, ppl=32.33, wps=4197.4, ups=0.06, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.588, train_wall=1539, gb_free=3.3, wall=193797
2022-02-25 16:29:05 | INFO | train_inner | epoch 016:    680 / 788 loss=5.026, ppl=32.57, wps=4199.6, ups=0.06, wpb=65536, bsz=128, num_updates=12500, lr=0.000282843, gnorm=0.588, train_wall=1538, gb_free=3.3, wall=195358
2022-02-25 16:55:06 | INFO | train_inner | epoch 016:    780 / 788 loss=5.026, ppl=32.59, wps=4199.5, ups=0.06, wpb=65536, bsz=128, num_updates=12600, lr=0.000281718, gnorm=0.592, train_wall=1538, gb_free=3.3, wall=196918
2022-02-25 16:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 16:57:27 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.5 | ppl 45.26 | wps 9127.8 | wpb 510.9 | bsz 1 | num_updates 12608 | best_loss 5.5
2022-02-25 16:57:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 12608 updates
2022-02-25 16:57:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 16:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 16:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 16 @ 12608 updates, score 5.5) (writing took 5.969380820170045 seconds)
2022-02-25 16:57:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-25 16:57:33 | INFO | train | epoch 016 | loss 4.983 | ppl 31.62 | wps 4184.7 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 12608 | lr 0.000281629 | gnorm 0.586 | train_wall 12126 | gb_free 3.3 | wall 197066
2022-02-25 16:57:33 | INFO | fairseq.trainer | begin training epoch 17
2022-02-25 16:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 17:21:27 | INFO | train_inner | epoch 017:     92 / 788 loss=4.889, ppl=29.63, wps=4125.5, ups=0.06, wpb=65232.6, bsz=127.4, num_updates=12700, lr=0.000280607, gnorm=0.604, train_wall=1529, gb_free=3.3, wall=198500
2022-02-25 17:47:25 | INFO | train_inner | epoch 017:    192 / 788 loss=4.896, ppl=29.78, wps=4205.8, ups=0.06, wpb=65536, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.594, train_wall=1535, gb_free=3.3, wall=200058
2022-02-25 18:13:22 | INFO | train_inner | epoch 017:    292 / 788 loss=4.923, ppl=30.34, wps=4208.6, ups=0.06, wpb=65536, bsz=128, num_updates=12900, lr=0.000278423, gnorm=0.578, train_wall=1535, gb_free=3.3, wall=201615
2022-02-25 18:39:23 | INFO | train_inner | epoch 017:    392 / 788 loss=4.935, ppl=30.59, wps=4200.1, ups=0.06, wpb=65536, bsz=128, num_updates=13000, lr=0.00027735, gnorm=0.629, train_wall=1538, gb_free=3.3, wall=203175
2022-02-25 19:05:26 | INFO | train_inner | epoch 017:    492 / 788 loss=4.945, ppl=30.81, wps=4191.3, ups=0.06, wpb=65536, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.575, train_wall=1541, gb_free=3.3, wall=204739
2022-02-25 19:31:30 | INFO | train_inner | epoch 017:    592 / 788 loss=4.968, ppl=31.29, wps=4192, ups=0.06, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.585, train_wall=1541, gb_free=3.3, wall=206302
2022-02-25 19:57:33 | INFO | train_inner | epoch 017:    692 / 788 loss=4.991, ppl=31.79, wps=4193, ups=0.06, wpb=65536, bsz=128, num_updates=13300, lr=0.000274204, gnorm=0.61, train_wall=1540, gb_free=3.3, wall=207865
2022-02-25 20:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 20:22:50 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.502 | ppl 45.31 | wps 9006.4 | wpb 510.9 | bsz 1 | num_updates 13396 | best_loss 5.5
2022-02-25 20:22:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 13396 updates
2022-02-25 20:22:50 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-25 20:22:50 | INFO | train | epoch 017 | loss 4.942 | ppl 30.74 | wps 4190.2 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 13396 | lr 0.00027322 | gnorm 0.598 | train_wall 12114 | gb_free 3.3 | wall 209383
2022-02-25 20:22:51 | INFO | fairseq.trainer | begin training epoch 18
2022-02-25 20:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 20:23:53 | INFO | train_inner | epoch 018:      4 / 788 loss=4.992, ppl=31.81, wps=4127.4, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=13400, lr=0.000273179, gnorm=0.604, train_wall=1533, gb_free=3.3, wall=209446
2022-02-25 20:49:57 | INFO | train_inner | epoch 018:    104 / 788 loss=4.831, ppl=28.47, wps=4189.8, ups=0.06, wpb=65536, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.582, train_wall=1541, gb_free=3.3, wall=211010
2022-02-25 21:16:02 | INFO | train_inner | epoch 018:    204 / 788 loss=4.849, ppl=28.83, wps=4189, ups=0.06, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.62, train_wall=1541, gb_free=3.3, wall=212574
2022-02-25 21:42:06 | INFO | train_inner | epoch 018:    304 / 788 loss=4.89, ppl=29.65, wps=4189.9, ups=0.06, wpb=65536, bsz=128, num_updates=13700, lr=0.000270172, gnorm=0.58, train_wall=1541, gb_free=3.3, wall=214139
2022-02-25 22:08:10 | INFO | train_inner | epoch 018:    404 / 788 loss=4.902, ppl=29.91, wps=4189.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=13800, lr=0.000269191, gnorm=0.596, train_wall=1542, gb_free=3.3, wall=215703
2022-02-25 22:34:14 | INFO | train_inner | epoch 018:    504 / 788 loss=4.933, ppl=30.55, wps=4191.6, ups=0.06, wpb=65536, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.592, train_wall=1541, gb_free=3.3, wall=217267
2022-02-25 23:00:17 | INFO | train_inner | epoch 018:    604 / 788 loss=4.935, ppl=30.58, wps=4191.7, ups=0.06, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.608, train_wall=1541, gb_free=3.3, wall=218830
2022-02-25 23:26:22 | INFO | train_inner | epoch 018:    704 / 788 loss=4.946, ppl=30.82, wps=4189.9, ups=0.06, wpb=65536, bsz=128, num_updates=14100, lr=0.000266312, gnorm=0.588, train_wall=1541, gb_free=3.3, wall=220394
2022-02-25 23:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-25 23:48:35 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.497 | ppl 45.17 | wps 8917.9 | wpb 510.9 | bsz 1 | num_updates 14184 | best_loss 5.497
2022-02-25 23:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 14184 updates
2022-02-25 23:48:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 23:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-25 23:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 18 @ 14184 updates, score 5.497) (writing took 8.219425914809108 seconds)
2022-02-25 23:48:43 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-25 23:48:43 | INFO | train | epoch 018 | loss 4.905 | ppl 29.96 | wps 4178.3 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 14184 | lr 0.000265522 | gnorm 0.597 | train_wall 12139 | gb_free 3.3 | wall 221736
2022-02-25 23:48:43 | INFO | fairseq.trainer | begin training epoch 19
2022-02-25 23:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-25 23:52:54 | INFO | train_inner | epoch 019:     16 / 788 loss=4.939, ppl=30.68, wps=4097, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=14200, lr=0.000265372, gnorm=0.599, train_wall=1536, gb_free=3.3, wall=221986
2022-02-26 00:19:00 | INFO | train_inner | epoch 019:    116 / 788 loss=4.805, ppl=27.96, wps=4185.3, ups=0.06, wpb=65536, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.608, train_wall=1542, gb_free=3.3, wall=223552
2022-02-26 00:45:03 | INFO | train_inner | epoch 019:    216 / 788 loss=4.822, ppl=28.28, wps=4193, ups=0.06, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.582, train_wall=1540, gb_free=3.3, wall=225115
2022-02-26 01:10:58 | INFO | train_inner | epoch 019:    316 / 788 loss=4.851, ppl=28.87, wps=4213.6, ups=0.06, wpb=65536, bsz=128, num_updates=14500, lr=0.000262613, gnorm=0.594, train_wall=1533, gb_free=3.3, wall=226671
2022-02-26 01:36:54 | INFO | train_inner | epoch 019:    416 / 788 loss=4.871, ppl=29.27, wps=4211.6, ups=0.06, wpb=65536, bsz=128, num_updates=14600, lr=0.000261712, gnorm=0.594, train_wall=1534, gb_free=3.3, wall=228227
2022-02-26 02:02:49 | INFO | train_inner | epoch 019:    516 / 788 loss=4.898, ppl=29.81, wps=4214.2, ups=0.06, wpb=65534.7, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.604, train_wall=1533, gb_free=3.3, wall=229782
2022-02-26 02:28:45 | INFO | train_inner | epoch 019:    616 / 788 loss=4.913, ppl=30.13, wps=4212.7, ups=0.06, wpb=65536, bsz=128, num_updates=14800, lr=0.000259938, gnorm=0.612, train_wall=1533, gb_free=3.3, wall=231337
2022-02-26 02:54:39 | INFO | train_inner | epoch 019:    716 / 788 loss=4.915, ppl=30.18, wps=4216.3, ups=0.06, wpb=65536, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.626, train_wall=1532, gb_free=3.3, wall=232892
2022-02-26 03:13:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 03:13:36 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.489 | ppl 44.9 | wps 9127.3 | wpb 510.9 | bsz 1 | num_updates 14972 | best_loss 5.489
2022-02-26 03:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 14972 updates
2022-02-26 03:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-26 03:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-26 03:13:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 19 @ 14972 updates, score 5.489) (writing took 6.77496107108891 seconds)
2022-02-26 03:13:43 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-26 03:13:43 | INFO | train | epoch 019 | loss 4.872 | ppl 29.28 | wps 4196.1 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 14972 | lr 0.00025844 | gnorm 0.602 | train_wall 12091 | gb_free 3.3 | wall 234036
2022-02-26 03:13:43 | INFO | fairseq.trainer | begin training epoch 20
2022-02-26 03:13:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 03:20:58 | INFO | train_inner | epoch 020:     28 / 788 loss=4.876, ppl=29.36, wps=4131.2, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=15000, lr=0.000258199, gnorm=0.618, train_wall=1526, gb_free=3.3, wall=234471
2022-02-26 03:46:54 | INFO | train_inner | epoch 020:    128 / 788 loss=4.769, ppl=27.26, wps=4212.3, ups=0.06, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.59, train_wall=1533, gb_free=3.3, wall=236027
2022-02-26 04:12:50 | INFO | train_inner | epoch 020:    228 / 788 loss=4.792, ppl=27.71, wps=4212.9, ups=0.06, wpb=65536, bsz=128, num_updates=15200, lr=0.000256495, gnorm=0.613, train_wall=1533, gb_free=3.3, wall=237582
2022-02-26 04:38:45 | INFO | train_inner | epoch 020:    328 / 788 loss=4.836, ppl=28.57, wps=4214.2, ups=0.06, wpb=65536, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.6, train_wall=1533, gb_free=3.3, wall=239137
2022-02-26 05:04:40 | INFO | train_inner | epoch 020:    428 / 788 loss=4.84, ppl=28.64, wps=4214.9, ups=0.06, wpb=65536, bsz=128, num_updates=15400, lr=0.000254824, gnorm=0.616, train_wall=1533, gb_free=3.3, wall=240692
2022-02-26 05:30:35 | INFO | train_inner | epoch 020:    528 / 788 loss=4.865, ppl=29.14, wps=4214.6, ups=0.06, wpb=65536, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.624, train_wall=1533, gb_free=3.3, wall=242247
2022-02-26 05:56:30 | INFO | train_inner | epoch 020:    628 / 788 loss=4.878, ppl=29.41, wps=4213.8, ups=0.06, wpb=65536, bsz=128, num_updates=15600, lr=0.000253185, gnorm=0.619, train_wall=1533, gb_free=3.3, wall=243802
2022-02-26 06:22:25 | INFO | train_inner | epoch 020:    728 / 788 loss=4.892, ppl=29.7, wps=4213.5, ups=0.06, wpb=65534.7, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.598, train_wall=1533, gb_free=3.3, wall=245358
2022-02-26 06:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 06:38:16 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.491 | ppl 44.96 | wps 9127.7 | wpb 510.9 | bsz 1 | num_updates 15760 | best_loss 5.489
2022-02-26 06:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 15760 updates
2022-02-26 06:38:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-26 06:38:16 | INFO | train | epoch 020 | loss 4.841 | ppl 28.65 | wps 4205.3 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 15760 | lr 0.000251896 | gnorm 0.61 | train_wall 12073 | gb_free 3.3 | wall 246309
2022-02-26 06:38:16 | INFO | fairseq.trainer | begin training epoch 21
2022-02-26 06:38:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 06:48:38 | INFO | train_inner | epoch 021:     40 / 788 loss=4.833, ppl=28.5, wps=4148.4, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=15800, lr=0.000251577, gnorm=0.609, train_wall=1526, gb_free=3.3, wall=246930
2022-02-26 07:14:33 | INFO | train_inner | epoch 021:    140 / 788 loss=4.746, ppl=26.83, wps=4213.8, ups=0.06, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.605, train_wall=1533, gb_free=3.3, wall=248486
2022-02-26 07:40:28 | INFO | train_inner | epoch 021:    240 / 788 loss=4.775, ppl=27.38, wps=4215.5, ups=0.06, wpb=65536, bsz=128, num_updates=16000, lr=0.00025, gnorm=0.599, train_wall=1532, gb_free=3.3, wall=250040
2022-02-26 08:06:22 | INFO | train_inner | epoch 021:    340 / 788 loss=4.794, ppl=27.74, wps=4216.2, ups=0.06, wpb=65534.7, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.614, train_wall=1532, gb_free=3.3, wall=251595
2022-02-26 08:32:17 | INFO | train_inner | epoch 021:    440 / 788 loss=4.818, ppl=28.2, wps=4213.3, ups=0.06, wpb=65536, bsz=128, num_updates=16200, lr=0.000248452, gnorm=0.623, train_wall=1533, gb_free=3.3, wall=253150
2022-02-26 08:58:12 | INFO | train_inner | epoch 021:    540 / 788 loss=4.837, ppl=28.57, wps=4215, ups=0.06, wpb=65536, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.622, train_wall=1532, gb_free=3.3, wall=254705
2022-02-26 09:24:08 | INFO | train_inner | epoch 021:    640 / 788 loss=4.855, ppl=28.94, wps=4212.5, ups=0.06, wpb=65536, bsz=128, num_updates=16400, lr=0.000246932, gnorm=0.604, train_wall=1533, gb_free=3.3, wall=256261
2022-02-26 09:50:03 | INFO | train_inner | epoch 021:    740 / 788 loss=4.868, ppl=29.2, wps=4213.5, ups=0.06, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.61, train_wall=1533, gb_free=3.3, wall=257816
2022-02-26 10:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 10:02:47 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.488 | ppl 44.89 | wps 9145.9 | wpb 510.9 | bsz 1 | num_updates 16548 | best_loss 5.488
2022-02-26 10:02:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 16548 updates
2022-02-26 10:02:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-26 10:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt
2022-02-26 10:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_fp16_size_0.5-good-turing-n1/checkpoint_best.pt (epoch 21 @ 16548 updates, score 5.488) (writing took 6.77592905331403 seconds)
2022-02-26 10:02:53 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-26 10:02:53 | INFO | train | epoch 021 | loss 4.812 | ppl 28.09 | wps 4203.8 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 16548 | lr 0.000245826 | gnorm 0.613 | train_wall 12070 | gb_free 3.3 | wall 258586
2022-02-26 10:02:53 | INFO | fairseq.trainer | begin training epoch 22
2022-02-26 10:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 10:16:22 | INFO | train_inner | epoch 022:     52 / 788 loss=4.782, ppl=27.52, wps=4133, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=16600, lr=0.00024544, gnorm=0.614, train_wall=1525, gb_free=3.3, wall=259394
2022-02-26 10:42:18 | INFO | train_inner | epoch 022:    152 / 788 loss=4.729, ppl=26.52, wps=4210.1, ups=0.06, wpb=65536, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.632, train_wall=1534, gb_free=3.3, wall=260951
2022-02-26 11:08:16 | INFO | train_inner | epoch 022:    252 / 788 loss=4.753, ppl=26.97, wps=4207.5, ups=0.06, wpb=65536, bsz=128, num_updates=16800, lr=0.000243975, gnorm=0.608, train_wall=1535, gb_free=3.3, wall=262509
2022-02-26 11:34:13 | INFO | train_inner | epoch 022:    352 / 788 loss=4.771, ppl=27.31, wps=4209, ups=0.06, wpb=65536, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.64, train_wall=1535, gb_free=3.3, wall=264066
2022-02-26 12:00:10 | INFO | train_inner | epoch 022:    452 / 788 loss=4.786, ppl=27.59, wps=4208.6, ups=0.06, wpb=65536, bsz=128, num_updates=17000, lr=0.000242536, gnorm=0.612, train_wall=1535, gb_free=3.3, wall=265623
2022-02-26 12:26:07 | INFO | train_inner | epoch 022:    552 / 788 loss=4.808, ppl=28.02, wps=4209, ups=0.06, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.64, train_wall=1535, gb_free=3.3, wall=267180
2022-02-26 12:52:05 | INFO | train_inner | epoch 022:    652 / 788 loss=4.824, ppl=28.33, wps=4207.3, ups=0.06, wpb=65534.7, bsz=128, num_updates=17200, lr=0.000241121, gnorm=0.612, train_wall=1535, gb_free=3.3, wall=268738
2022-02-26 13:18:02 | INFO | train_inner | epoch 022:    752 / 788 loss=4.84, ppl=28.65, wps=4208.1, ups=0.06, wpb=65536, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.608, train_wall=1535, gb_free=3.3, wall=270295
2022-02-26 13:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 13:27:41 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.495 | ppl 45.1 | wps 9065.1 | wpb 510.9 | bsz 1 | num_updates 17336 | best_loss 5.488
2022-02-26 13:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 17336 updates
2022-02-26 13:27:41 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-26 13:27:41 | INFO | train | epoch 022 | loss 4.785 | ppl 27.56 | wps 4200.4 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 17336 | lr 0.000240174 | gnorm 0.619 | train_wall 12086 | gb_free 3.3 | wall 270873
2022-02-26 13:27:41 | INFO | fairseq.trainer | begin training epoch 23
2022-02-26 13:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 13:44:22 | INFO | train_inner | epoch 023:     64 / 788 loss=4.743, ppl=26.77, wps=4128.9, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=17400, lr=0.000239732, gnorm=0.621, train_wall=1532, gb_free=3.3, wall=271875
2022-02-26 14:10:33 | INFO | train_inner | epoch 023:    164 / 788 loss=4.708, ppl=26.13, wps=4172.7, ups=0.06, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.64, train_wall=1546, gb_free=3.3, wall=273446
2022-02-26 14:36:33 | INFO | train_inner | epoch 023:    264 / 788 loss=4.722, ppl=26.38, wps=4200.5, ups=0.06, wpb=65536, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.63, train_wall=1537, gb_free=3.3, wall=275006
2022-02-26 15:02:32 | INFO | train_inner | epoch 023:    364 / 788 loss=4.763, ppl=27.15, wps=4205.1, ups=0.06, wpb=65534.7, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.621, train_wall=1536, gb_free=3.3, wall=276564
2022-02-26 15:28:29 | INFO | train_inner | epoch 023:    464 / 788 loss=4.757, ppl=27.04, wps=4207.6, ups=0.06, wpb=65536, bsz=128, num_updates=17800, lr=0.000237023, gnorm=0.62, train_wall=1535, gb_free=3.3, wall=278122
2022-02-26 15:54:27 | INFO | train_inner | epoch 023:    564 / 788 loss=4.786, ppl=27.59, wps=4207.6, ups=0.06, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.619, train_wall=1535, gb_free=3.3, wall=279679
2022-02-26 16:20:32 | INFO | train_inner | epoch 023:    664 / 788 loss=4.808, ppl=28.01, wps=4187, ups=0.06, wpb=65536, bsz=128, num_updates=18000, lr=0.000235702, gnorm=0.613, train_wall=1542, gb_free=3.3, wall=281245
2022-02-26 16:46:38 | INFO | train_inner | epoch 023:    764 / 788 loss=4.812, ppl=28.1, wps=4185.8, ups=0.06, wpb=65536, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.615, train_wall=1542, gb_free=3.3, wall=282810
2022-02-26 16:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 16:53:11 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.501 | ppl 45.3 | wps 8828.5 | wpb 510.9 | bsz 1 | num_updates 18124 | best_loss 5.488
2022-02-26 16:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 18124 updates
2022-02-26 16:53:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-26 16:53:11 | INFO | train | epoch 023 | loss 4.76 | ppl 27.1 | wps 4185.9 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 18124 | lr 0.000234895 | gnorm 0.622 | train_wall 12124 | gb_free 3.3 | wall 283203
2022-02-26 16:53:11 | INFO | fairseq.trainer | begin training epoch 24
2022-02-26 16:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 17:13:02 | INFO | train_inner | epoch 024:     76 / 788 loss=4.686, ppl=25.74, wps=4117.6, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=18200, lr=0.000234404, gnorm=0.645, train_wall=1536, gb_free=3.3, wall=284394
2022-02-26 17:39:10 | INFO | train_inner | epoch 024:    176 / 788 loss=4.687, ppl=25.76, wps=4179.9, ups=0.06, wpb=65536, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.651, train_wall=1544, gb_free=3.3, wall=285962
2022-02-26 18:05:15 | INFO | train_inner | epoch 024:    276 / 788 loss=4.708, ppl=26.13, wps=4187.4, ups=0.06, wpb=65536, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.625, train_wall=1542, gb_free=3.3, wall=287527
2022-02-26 18:31:20 | INFO | train_inner | epoch 024:    376 / 788 loss=4.739, ppl=26.7, wps=4186.6, ups=0.06, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.633, train_wall=1542, gb_free=3.3, wall=289093
2022-02-26 18:57:26 | INFO | train_inner | epoch 024:    476 / 788 loss=4.746, ppl=26.84, wps=4184.2, ups=0.06, wpb=65536, bsz=128, num_updates=18600, lr=0.000231869, gnorm=0.622, train_wall=1543, gb_free=3.3, wall=290659
2022-02-26 19:23:34 | INFO | train_inner | epoch 024:    576 / 788 loss=4.764, ppl=27.18, wps=4182, ups=0.06, wpb=65536, bsz=128, num_updates=18700, lr=0.000231249, gnorm=0.644, train_wall=1543, gb_free=3.3, wall=292226
2022-02-26 19:49:39 | INFO | train_inner | epoch 024:    676 / 788 loss=4.78, ppl=27.48, wps=4185.3, ups=0.06, wpb=65534.7, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.618, train_wall=1543, gb_free=3.3, wall=293792
2022-02-26 20:15:45 | INFO | train_inner | epoch 024:    776 / 788 loss=4.798, ppl=27.81, wps=4186.9, ups=0.06, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.62, train_wall=1542, gb_free=3.3, wall=295357
2022-02-26 20:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 20:19:11 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.506 | ppl 45.46 | wps 8832.6 | wpb 510.9 | bsz 1 | num_updates 18912 | best_loss 5.488
2022-02-26 20:19:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 18912 updates
2022-02-26 20:19:11 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-26 20:19:11 | INFO | train | epoch 024 | loss 4.737 | ppl 26.66 | wps 4175.7 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 18912 | lr 0.000229949 | gnorm 0.633 | train_wall 12149 | gb_free 3.3 | wall 295563
2022-02-26 20:19:11 | INFO | fairseq.trainer | begin training epoch 25
2022-02-26 20:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-26 20:42:10 | INFO | train_inner | epoch 025:     88 / 788 loss=4.655, ppl=25.19, wps=4114.2, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=19000, lr=0.000229416, gnorm=0.607, train_wall=1536, gb_free=3.3, wall=296943
2022-02-26 21:08:17 | INFO | train_inner | epoch 025:    188 / 788 loss=4.67, ppl=25.45, wps=4184.2, ups=0.06, wpb=65536, bsz=128, num_updates=19100, lr=0.000228814, gnorm=0.635, train_wall=1543, gb_free=3.3, wall=298509
2022-02-26 21:34:22 | INFO | train_inner | epoch 025:    288 / 788 loss=4.692, ppl=25.84, wps=4186.3, ups=0.06, wpb=65536, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.644, train_wall=1542, gb_free=3.3, wall=300075
2022-02-26 22:00:29 | INFO | train_inner | epoch 025:    388 / 788 loss=4.706, ppl=26.09, wps=4183.5, ups=0.06, wpb=65536, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.642, train_wall=1543, gb_free=3.3, wall=301641
2022-02-26 22:26:35 | INFO | train_inner | epoch 025:    488 / 788 loss=4.733, ppl=26.59, wps=4182.6, ups=0.06, wpb=65536, bsz=128, num_updates=19400, lr=0.000227038, gnorm=0.645, train_wall=1543, gb_free=3.3, wall=303208
2022-02-26 22:52:41 | INFO | train_inner | epoch 025:    588 / 788 loss=4.741, ppl=26.74, wps=4187.3, ups=0.06, wpb=65534.7, bsz=128, num_updates=19500, lr=0.000226455, gnorm=0.646, train_wall=1542, gb_free=3.3, wall=304773
2022-02-26 23:18:46 | INFO | train_inner | epoch 025:    688 / 788 loss=4.757, ppl=27.03, wps=4186.6, ups=0.06, wpb=65536, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.62, train_wall=1542, gb_free=3.3, wall=306339
2022-02-26 23:44:46 | INFO | train_inner | epoch 025:    788 / 788 loss=4.781, ppl=27.49, wps=4181.4, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=19700, lr=0.000225303, gnorm=0.641, train_wall=1537, gb_free=3.3, wall=307899
2022-02-26 23:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-26 23:45:10 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.502 | ppl 45.31 | wps 8997.9 | wpb 510.9 | bsz 1 | num_updates 19700 | best_loss 5.488
2022-02-26 23:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 19700 updates
2022-02-26 23:45:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-26 23:45:10 | INFO | train | epoch 025 | loss 4.716 | ppl 26.27 | wps 4175.9 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 19700 | lr 0.000225303 | gnorm 0.635 | train_wall 12149 | gb_free 3.3 | wall 307923
2022-02-26 23:45:10 | INFO | fairseq.trainer | begin training epoch 26
2022-02-26 23:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-27 00:11:15 | INFO | train_inner | epoch 026:    100 / 788 loss=4.615, ppl=24.51, wps=4123, ups=0.06, wpb=65534.7, bsz=128, num_updates=19800, lr=0.000224733, gnorm=0.643, train_wall=1542, gb_free=3.3, wall=309488
2022-02-27 00:37:20 | INFO | train_inner | epoch 026:    200 / 788 loss=4.652, ppl=25.14, wps=4188.5, ups=0.06, wpb=65536, bsz=128, num_updates=19900, lr=0.000224168, gnorm=0.651, train_wall=1541, gb_free=3.3, wall=311053
2022-02-27 01:03:27 | INFO | train_inner | epoch 026:    300 / 788 loss=4.663, ppl=25.34, wps=4182.2, ups=0.06, wpb=65536, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.634, train_wall=1543, gb_free=3.3, wall=312620
2022-02-27 01:29:32 | INFO | train_inner | epoch 026:    400 / 788 loss=4.691, ppl=25.83, wps=4187.2, ups=0.06, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.656, train_wall=1542, gb_free=3.3, wall=314185
2022-02-27 01:55:37 | INFO | train_inner | epoch 026:    500 / 788 loss=4.706, ppl=26.1, wps=4188.5, ups=0.06, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.634, train_wall=1541, gb_free=3.3, wall=315750
2022-02-27 02:21:43 | INFO | train_inner | epoch 026:    600 / 788 loss=4.728, ppl=26.5, wps=4185.5, ups=0.06, wpb=65536, bsz=128, num_updates=20300, lr=0.000221948, gnorm=0.659, train_wall=1542, gb_free=3.3, wall=317315
2022-02-27 02:47:48 | INFO | train_inner | epoch 026:    700 / 788 loss=4.743, ppl=26.79, wps=4186, ups=0.06, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.651, train_wall=1542, gb_free=3.3, wall=318881
2022-02-27 03:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-27 03:11:02 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.526 | ppl 46.07 | wps 9010.1 | wpb 510.9 | bsz 1 | num_updates 20488 | best_loss 5.488
2022-02-27 03:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 20488 updates
2022-02-27 03:11:02 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-27 03:11:02 | INFO | train | epoch 026 | loss 4.695 | ppl 25.9 | wps 4178.4 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 20488 | lr 0.000220928 | gnorm 0.644 | train_wall 12144 | gb_free 3.3 | wall 320275
2022-02-27 03:11:02 | INFO | fairseq.trainer | begin training epoch 27
2022-02-27 03:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-27 03:14:10 | INFO | train_inner | epoch 027:     12 / 788 loss=4.746, ppl=26.83, wps=4124.5, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=20500, lr=0.000220863, gnorm=0.642, train_wall=1534, gb_free=3.3, wall=320463
2022-02-27 03:40:16 | INFO | train_inner | epoch 027:    112 / 788 loss=4.6, ppl=24.25, wps=4185.6, ups=0.06, wpb=65536, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.618, train_wall=1542, gb_free=3.3, wall=322028
2022-02-27 04:06:22 | INFO | train_inner | epoch 027:    212 / 788 loss=4.632, ppl=24.79, wps=4184.4, ups=0.06, wpb=65536, bsz=128, num_updates=20700, lr=0.000219793, gnorm=0.688, train_wall=1543, gb_free=3.3, wall=323595
2022-02-27 04:32:26 | INFO | train_inner | epoch 027:    312 / 788 loss=4.648, ppl=25.08, wps=4188.7, ups=0.06, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.643, train_wall=1541, gb_free=3.3, wall=325159
2022-02-27 04:58:31 | INFO | train_inner | epoch 027:    412 / 788 loss=4.667, ppl=25.4, wps=4187.8, ups=0.06, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.637, train_wall=1541, gb_free=3.3, wall=326724
2022-02-27 05:24:38 | INFO | train_inner | epoch 027:    512 / 788 loss=4.701, ppl=26.01, wps=4182.1, ups=0.06, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.649, train_wall=1543, gb_free=3.3, wall=328291
2022-02-27 05:50:43 | INFO | train_inner | epoch 027:    612 / 788 loss=4.714, ppl=26.24, wps=4188.2, ups=0.06, wpb=65536, bsz=128, num_updates=21100, lr=0.0002177, gnorm=0.632, train_wall=1542, gb_free=3.3, wall=329856
2022-02-27 06:16:48 | INFO | train_inner | epoch 027:    712 / 788 loss=4.729, ppl=26.52, wps=4187.8, ups=0.06, wpb=65534.7, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.646, train_wall=1542, gb_free=3.3, wall=331421
2022-02-27 06:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-27 06:36:55 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.509 | ppl 45.53 | wps 9033.8 | wpb 510.9 | bsz 1 | num_updates 21276 | best_loss 5.488
2022-02-27 06:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 21276 updates
2022-02-27 06:36:56 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-27 06:36:56 | INFO | train | epoch 027 | loss 4.675 | ppl 25.55 | wps 4178 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 21276 | lr 0.000216798 | gnorm 0.646 | train_wall 12144 | gb_free 3.3 | wall 332628
2022-02-27 06:36:56 | INFO | fairseq.trainer | begin training epoch 28
2022-02-27 06:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-27 06:43:13 | INFO | train_inner | epoch 028:     24 / 788 loss=4.694, ppl=25.88, wps=4116, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=21300, lr=0.000216676, gnorm=0.632, train_wall=1537, gb_free=3.3, wall=333006
2022-02-27 07:09:18 | INFO | train_inner | epoch 028:    124 / 788 loss=4.584, ppl=23.98, wps=4188.8, ups=0.06, wpb=65534.7, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.667, train_wall=1541, gb_free=3.3, wall=334570
2022-02-27 07:35:22 | INFO | train_inner | epoch 028:    224 / 788 loss=4.614, ppl=24.49, wps=4190.4, ups=0.06, wpb=65536, bsz=128, num_updates=21500, lr=0.000215666, gnorm=0.646, train_wall=1541, gb_free=3.3, wall=336134
2022-02-27 08:01:28 | INFO | train_inner | epoch 028:    324 / 788 loss=4.635, ppl=24.85, wps=4184.7, ups=0.06, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.645, train_wall=1543, gb_free=3.3, wall=337700
2022-02-27 08:27:32 | INFO | train_inner | epoch 028:    424 / 788 loss=4.646, ppl=25.05, wps=4188.4, ups=0.06, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.659, train_wall=1541, gb_free=3.3, wall=339265
2022-02-27 08:53:36 | INFO | train_inner | epoch 028:    524 / 788 loss=4.67, ppl=25.46, wps=4190.6, ups=0.06, wpb=65536, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.649, train_wall=1541, gb_free=3.3, wall=340829
2022-02-27 09:19:41 | INFO | train_inner | epoch 028:    624 / 788 loss=4.712, ppl=26.2, wps=4189.1, ups=0.06, wpb=65536, bsz=128, num_updates=21900, lr=0.000213687, gnorm=0.667, train_wall=1541, gb_free=3.3, wall=342393
2022-02-27 09:45:43 | INFO | train_inner | epoch 028:    724 / 788 loss=4.708, ppl=26.14, wps=4193.9, ups=0.06, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.656, train_wall=1539, gb_free=3.3, wall=343956
2022-02-27 10:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-27 10:02:41 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.511 | ppl 45.61 | wps 9051.4 | wpb 510.9 | bsz 1 | num_updates 22064 | best_loss 5.488
2022-02-27 10:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 22064 updates
2022-02-27 10:02:41 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-27 10:02:41 | INFO | train | epoch 028 | loss 4.657 | ppl 25.22 | wps 4180.7 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 22064 | lr 0.000212891 | gnorm 0.654 | train_wall 12137 | gb_free 3.3 | wall 344973
2022-02-27 10:02:41 | INFO | fairseq.trainer | begin training epoch 29
2022-02-27 10:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-27 10:12:03 | INFO | train_inner | epoch 029:     36 / 788 loss=4.667, ppl=25.4, wps=4130.7, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=22100, lr=0.000212718, gnorm=0.642, train_wall=1532, gb_free=3.3, wall=345535
2022-02-27 10:38:06 | INFO | train_inner | epoch 029:    136 / 788 loss=4.57, ppl=23.75, wps=4191.1, ups=0.06, wpb=65536, bsz=128, num_updates=22200, lr=0.000212238, gnorm=0.641, train_wall=1540, gb_free=3.3, wall=347099
2022-02-27 11:04:10 | INFO | train_inner | epoch 029:    236 / 788 loss=4.59, ppl=24.08, wps=4189.9, ups=0.06, wpb=65534.7, bsz=128, num_updates=22300, lr=0.000211762, gnorm=0.656, train_wall=1541, gb_free=3.3, wall=348663
2022-02-27 11:30:13 | INFO | train_inner | epoch 029:    336 / 788 loss=4.616, ppl=24.53, wps=4193.5, ups=0.06, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.675, train_wall=1540, gb_free=3.3, wall=350226
2022-02-27 11:56:16 | INFO | train_inner | epoch 029:    436 / 788 loss=4.653, ppl=25.16, wps=4193.2, ups=0.06, wpb=65536, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.646, train_wall=1540, gb_free=3.3, wall=351789
2022-02-27 12:22:20 | INFO | train_inner | epoch 029:    536 / 788 loss=4.67, ppl=25.46, wps=4191.3, ups=0.06, wpb=65536, bsz=128, num_updates=22600, lr=0.000210352, gnorm=0.651, train_wall=1540, gb_free=3.3, wall=353352
2022-02-27 12:48:21 | INFO | train_inner | epoch 029:    636 / 788 loss=4.695, ppl=25.91, wps=4196.4, ups=0.06, wpb=65536, bsz=128, num_updates=22700, lr=0.000209888, gnorm=0.671, train_wall=1539, gb_free=3.3, wall=354914
2022-02-27 13:14:24 | INFO | train_inner | epoch 029:    736 / 788 loss=4.686, ppl=25.75, wps=4195.3, ups=0.06, wpb=65536, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.651, train_wall=1539, gb_free=3.3, wall=356476
2022-02-27 13:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-27 13:28:14 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.523 | ppl 45.97 | wps 9048.7 | wpb 510.9 | bsz 1 | num_updates 22852 | best_loss 5.488
2022-02-27 13:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 22852 updates
2022-02-27 13:28:14 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-27 13:28:14 | INFO | train | epoch 029 | loss 4.639 | ppl 24.92 | wps 4184.9 | ups 0.06 | wpb 65497.5 | bsz 127.9 | num_updates 22852 | lr 0.000209189 | gnorm 0.655 | train_wall 12126 | gb_free 3.3 | wall 357306
2022-02-27 13:28:14 | INFO | fairseq.trainer | begin training epoch 30
2022-02-27 13:28:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-27 13:40:45 | INFO | train_inner | epoch 030:     48 / 788 loss=4.616, ppl=24.52, wps=4125.2, ups=0.06, wpb=65233.9, bsz=127.4, num_updates=22900, lr=0.000208969, gnorm=0.665, train_wall=1534, gb_free=3.3, wall=358058
2022-02-27 14:06:48 | INFO | train_inner | epoch 030:    148 / 788 loss=4.559, ppl=23.57, wps=4194, ups=0.06, wpb=65534.7, bsz=128, num_updates=23000, lr=0.000208514, gnorm=0.643, train_wall=1539, gb_free=3.3, wall=359620
2022-02-27 14:32:50 | INFO | train_inner | epoch 030:    248 / 788 loss=4.585, ppl=24, wps=4193.2, ups=0.06, wpb=65536, bsz=128, num_updates=23100, lr=0.000208063, gnorm=0.664, train_wall=1540, gb_free=3.3, wall=361183
2022-02-27 14:58:55 | INFO | train_inner | epoch 030:    348 / 788 loss=4.608, ppl=24.38, wps=4189.8, ups=0.06, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.679, train_wall=1541, gb_free=3.3, wall=362747
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fairseq_optimizer.py", line 95, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
Terminated
