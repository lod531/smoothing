Sender: LSF System <lsfadmin@eu-g2-11>
Subject: Job 202286073: <w2_jelinek_0.05_0.05_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.05_0.05_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 06:54:54 2022
Job was executed on host(s) <eu-g2-11>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 07:03:17 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 07:03:17 2022
Terminated at Sat Jan 29 03:03:28 2022
Results reported at Sat Jan 29 03:03:28 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.05, 0.05, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72882.00 sec.
    Max Memory :                                 6064 MB
    Average Memory :                             3602.99 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13936.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72010 sec.
    Turnaround time :                            72514 sec.

The output (if any) follows:

2022-01-28 07:03:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.05, 0.05, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 07:03:25 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 07:03:26 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1445/36718 [00:00<00:02, 14416.54it/s]  8%|▊         | 2887/36718 [00:00<00:02, 13946.48it/s] 12%|█▏        | 4490/36718 [00:00<00:02, 14871.75it/s] 17%|█▋        | 6131/36718 [00:00<00:01, 15466.49it/s] 21%|██        | 7680/36718 [00:00<00:01, 14640.98it/s] 25%|██▍       | 9153/36718 [00:00<00:01, 14458.69it/s] 29%|██▉       | 10604/36718 [00:00<00:01, 14334.29it/s] 33%|███▎      | 12105/36718 [00:00<00:01, 14541.65it/s] 37%|███▋      | 13586/36718 [00:00<00:01, 14620.08it/s] 41%|████      | 15058/36718 [00:01<00:01, 14647.30it/s] 45%|████▌     | 16525/36718 [00:01<00:01, 14272.65it/s] 49%|████▉     | 17997/36718 [00:01<00:01, 14402.86it/s] 53%|█████▎    | 19595/36718 [00:01<00:01, 14870.79it/s] 57%|█████▋    | 21085/36718 [00:01<00:01, 14523.78it/s] 61%|██████▏   | 22541/36718 [00:01<00:00, 14449.84it/s] 66%|██████▌   | 24181/36718 [00:01<00:00, 15022.00it/s] 70%|███████   | 25767/36718 [00:01<00:00, 15268.48it/s] 74%|███████▍  | 27297/36718 [00:01<00:00, 14584.15it/s] 78%|███████▊  | 28823/36718 [00:01<00:00, 14767.17it/s] 83%|████████▎ | 30306/36718 [00:02<00:00, 14486.24it/s] 86%|████████▋ | 31760/36718 [00:02<00:00, 14236.48it/s] 90%|█████████ | 33188/36718 [00:02<00:00, 13697.07it/s] 95%|█████████▍| 34701/36718 [00:02<00:00, 14101.72it/s] 98%|█████████▊| 36118/36718 [00:02<00:00, 14035.06it/s]100%|██████████| 36718/36718 [00:02<00:00, 14475.59it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2793/36718 [00:00<00:01, 27911.26it/s] 16%|█▋        | 6051/36718 [00:00<00:01, 30654.64it/s] 25%|██▍       | 9117/36718 [00:00<00:00, 29185.51it/s] 33%|███▎      | 12049/36718 [00:00<00:00, 29235.62it/s] 41%|████      | 14992/36718 [00:00<00:00, 29302.57it/s] 49%|████▉     | 17926/36718 [00:00<00:00, 28909.17it/s] 57%|█████▋    | 20894/36718 [00:00<00:00, 29151.40it/s] 65%|██████▌   | 23890/36718 [00:00<00:00, 29398.55it/s] 73%|███████▎  | 26849/36718 [00:00<00:00, 29457.12it/s] 81%|████████  | 29797/36718 [00:01<00:00, 29328.68it/s] 89%|████████▉ | 32731/36718 [00:01<00:00, 28615.81it/s] 97%|█████████▋| 35597/36718 [00:01<00:00, 28534.46it/s]100%|██████████| 36718/36718 [00:01<00:00, 29013.19it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 71.04it/s]2022-01-28 07:03:39 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 07:03:39 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 07:03:39 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 07:03:39 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 07:03:39 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 07:03:39 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 07:03:39 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 07:03:39 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 07:03:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:03:39 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-28 07:03:39 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:03:39 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 07:03:39 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 07:03:39 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint_last.pt
2022-01-28 07:03:39 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint_last.pt
2022-01-28 07:03:39 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 07:03:39 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 07:03:39 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 07:03:39 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 07:03:39 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 07:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 07:09:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.548 | ppl 23956.2 | wps 8202.8 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 07:09:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 07:09:24 | INFO | train | epoch 001 | loss 16.071 | ppl 68865.7 | wps 6086.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.415 | train_wall 316 | gb_free 6.1 | wall 344
KL Stats: Epoch 1 Divergences: Uniform: 0.5176707649834147 Unigram: 3.684307777982154
2022-01-28 07:09:24 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 07:09:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:12:22 | INFO | train_inner | epoch 002:     36 / 64 loss=15.5, ppl=46342.2, wps=6266.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.8, train_wall=494, gb_free=6.1, wall=523
2022-01-28 07:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:15:06 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.492 | ppl 11517.5 | wps 8218.4 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:15:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:15:06 | INFO | train | epoch 002 | loss 14.263 | ppl 19654.1 | wps 6093.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.583 | train_wall 315 | gb_free 6.1 | wall 687
KL Stats: Epoch 2 Divergences: Uniform: 0.5394583452134147 Unigram: 2.4117108355402364
2022-01-28 07:15:06 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:20:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.623 | ppl 6307.4 | wps 8206 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:20:49 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:20:49 | INFO | train | epoch 003 | loss 13.306 | ppl 10126.6 | wps 6096 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.279 | train_wall 315 | gb_free 6.1 | wall 1030
KL Stats: Epoch 3 Divergences: Uniform: 0.5331255585365279 Unigram: 1.72327423518994
2022-01-28 07:20:49 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:21:29 | INFO | train_inner | epoch 004:      8 / 64 loss=13.447, ppl=11165, wps=5963.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.309, train_wall=492, gb_free=6.1, wall=1070
2022-01-28 07:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:26:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.717 | ppl 3365.48 | wps 8193.6 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 07:26:32 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 07:26:32 | INFO | train | epoch 004 | loss 12.308 | ppl 5069.31 | wps 6096.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 1.024 | train_wall 315 | gb_free 6.1 | wall 1372
KL Stats: Epoch 4 Divergences: Uniform: 0.6294233488391041 Unigram: 1.0920674883943635
2022-01-28 07:26:32 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 07:26:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:30:10 | INFO | train_inner | epoch 005:     44 / 64 loss=11.934, ppl=3912.62, wps=6270.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.895, train_wall=493, gb_free=6.1, wall=1591
2022-01-28 07:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:32:14 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.164 | ppl 2294.68 | wps 8202.7 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 07:32:14 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 07:32:14 | INFO | train | epoch 005 | loss 11.453 | ppl 2802.87 | wps 6093.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.721 | train_wall 315 | gb_free 6.1 | wall 1715
KL Stats: Epoch 5 Divergences: Uniform: 0.9005184205859913 Unigram: 0.6222925820299852
2022-01-28 07:32:14 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 07:32:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:37:57 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.911 | ppl 1925.94 | wps 8214.3 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 07:37:57 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 07:37:57 | INFO | train | epoch 006 | loss 10.987 | ppl 2030.04 | wps 6101.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.603 | train_wall 315 | gb_free 6.1 | wall 2057
KL Stats: Epoch 6 Divergences: Uniform: 1.247919908323343 Unigram: 0.4004072997499137
2022-01-28 07:37:57 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 07:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:39:16 | INFO | train_inner | epoch 007:     16 / 64 loss=11.012, ppl=2064.7, wps=5966.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.602, train_wall=492, gb_free=6.1, wall=2137
2022-01-28 07:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:43:40 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.777 | ppl 1754.6 | wps 8164.6 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 07:43:40 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 07:43:40 | INFO | train | epoch 007 | loss 10.775 | ppl 1751.71 | wps 6079.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.531 | train_wall 316 | gb_free 6.1 | wall 2401
KL Stats: Epoch 7 Divergences: Uniform: 1.5315191675915063 Unigram: 0.38976558290266533
2022-01-28 07:43:40 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 07:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:47:59 | INFO | train_inner | epoch 008:     52 / 64 loss=10.713, ppl=1678.3, wps=6253.3, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.522, train_wall=495, gb_free=6.1, wall=2660
2022-01-28 07:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:49:24 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.682 | ppl 1642.81 | wps 8162.6 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 07:49:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 07:49:24 | INFO | train | epoch 008 | loss 10.662 | ppl 1619.72 | wps 6074.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.516 | train_wall 316 | gb_free 6.1 | wall 2745
KL Stats: Epoch 8 Divergences: Uniform: 1.6961663570395586 Unigram: 0.4426154999853609
2022-01-28 07:49:24 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 07:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:54:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:55:08 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.571 | ppl 1520.85 | wps 8172.6 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 07:55:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 07:55:08 | INFO | train | epoch 009 | loss 10.562 | ppl 1511.94 | wps 6073 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.491 | train_wall 316 | gb_free 6.1 | wall 3089
KL Stats: Epoch 9 Divergences: Uniform: 1.7741669057159493 Unigram: 0.5155825793505032
2022-01-28 07:55:08 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 07:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:57:07 | INFO | train_inner | epoch 010:     24 / 64 loss=10.554, ppl=1503.24, wps=5944.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.493, train_wall=493, gb_free=6.1, wall=3208
2022-01-28 08:00:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:00:52 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.472 | ppl 1420.52 | wps 8172.5 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 08:00:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 08:00:52 | INFO | train | epoch 010 | loss 10.46 | ppl 1408.82 | wps 6077.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 316 | gb_free 6.1 | wall 3432
KL Stats: Epoch 10 Divergences: Uniform: 1.817721311431221 Unigram: 0.5960187055616976
2022-01-28 08:00:52 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 08:00:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:05:50 | INFO | train_inner | epoch 011:     60 / 64 loss=10.388, ppl=1340.43, wps=6248.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.495, train_wall=495, gb_free=6.1, wall=3731
2022-01-28 08:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:06:36 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.368 | ppl 1321.97 | wps 8164.7 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:06:36 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:06:36 | INFO | train | epoch 011 | loss 10.351 | ppl 1306.07 | wps 6070 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.504 | train_wall 316 | gb_free 6.1 | wall 3776
KL Stats: Epoch 11 Divergences: Uniform: 1.8457679501968227 Unigram: 0.6752372912920374
2022-01-28 08:06:36 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:12:20 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.265 | ppl 1230.82 | wps 8178.3 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:12:20 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:12:20 | INFO | train | epoch 012 | loss 10.238 | ppl 1207.93 | wps 6075.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.472 | train_wall 316 | gb_free 6.1 | wall 4120
KL Stats: Epoch 12 Divergences: Uniform: 1.86201671076731 Unigram: 0.7553040216194488
2022-01-28 08:12:20 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:14:59 | INFO | train_inner | epoch 013:     32 / 64 loss=10.215, ppl=1188.56, wps=5944.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.487, train_wall=493, gb_free=6.1, wall=4279
2022-01-28 08:17:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:18:03 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.176 | ppl 1157.1 | wps 8161 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:18:03 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:18:03 | INFO | train | epoch 013 | loss 10.127 | ppl 1118.21 | wps 6076.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.516 | train_wall 316 | gb_free 6.1 | wall 4464
KL Stats: Epoch 13 Divergences: Uniform: 1.894921378141184 Unigram: 0.825692762759226
2022-01-28 08:18:03 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:18:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:23:47 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.086 | ppl 1086.66 | wps 8194.5 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 08:23:47 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 08:23:47 | INFO | train | epoch 014 | loss 10.017 | ppl 1036.31 | wps 6072.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.544 | train_wall 316 | gb_free 6.1 | wall 4808
KL Stats: Epoch 14 Divergences: Uniform: 1.9250484433536046 Unigram: 0.8932782832749727
2022-01-28 08:23:47 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 08:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:24:07 | INFO | train_inner | epoch 015:      4 / 64 loss=10.04, ppl=1052.59, wps=5943.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.529, train_wall=494, gb_free=6.1, wall=4828
2022-01-28 08:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:29:31 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.018 | ppl 1036.72 | wps 8192.1 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 08:29:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 08:29:31 | INFO | train | epoch 015 | loss 9.906 | ppl 959.68 | wps 6075.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.53 | train_wall 316 | gb_free 6.1 | wall 5152
KL Stats: Epoch 15 Divergences: Uniform: 1.9583422123883176 Unigram: 0.9542269132108726
2022-01-28 08:29:31 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 08:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:32:50 | INFO | train_inner | epoch 016:     40 / 64 loss=9.865, ppl=932.76, wps=6250.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.55, train_wall=495, gb_free=6.1, wall=5351
2022-01-28 08:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:35:15 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.941 | ppl 982.68 | wps 8171.3 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 08:35:15 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 08:35:15 | INFO | train | epoch 016 | loss 9.8 | ppl 891.48 | wps 6071.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.547 | train_wall 316 | gb_free 6.1 | wall 5496
KL Stats: Epoch 16 Divergences: Uniform: 1.9942174643555906 Unigram: 1.0157685912666032
2022-01-28 08:35:15 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 08:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:40:59 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.847 | ppl 921.04 | wps 8160.1 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 08:40:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 08:40:59 | INFO | train | epoch 017 | loss 9.693 | ppl 827.76 | wps 6070.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.533 | train_wall 316 | gb_free 6.1 | wall 5840
KL Stats: Epoch 17 Divergences: Uniform: 2.0355958372447103 Unigram: 1.0683623637509674
2022-01-28 08:40:59 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 08:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:41:59 | INFO | train_inner | epoch 018:     12 / 64 loss=9.707, ppl=835.87, wps=5939.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.536, train_wall=494, gb_free=6.1, wall=5900
2022-01-28 08:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:46:43 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.776 | ppl 877.03 | wps 8175 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 08:46:43 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 08:46:43 | INFO | train | epoch 018 | loss 9.593 | ppl 772.07 | wps 6071.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.564 | train_wall 316 | gb_free 6.1 | wall 6184
KL Stats: Epoch 18 Divergences: Uniform: 2.0793680903438565 Unigram: 1.1211601870884327
2022-01-28 08:46:43 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 08:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:50:42 | INFO | train_inner | epoch 019:     48 / 64 loss=9.543, ppl=745.75, wps=6248, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.526, train_wall=495, gb_free=6.1, wall=6423
2022-01-28 08:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:52:27 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.707 | ppl 835.74 | wps 8186.5 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 08:52:27 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 08:52:27 | INFO | train | epoch 019 | loss 9.489 | ppl 718.34 | wps 6072.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.509 | train_wall 316 | gb_free 6.1 | wall 6528
KL Stats: Epoch 19 Divergences: Uniform: 2.119304737407686 Unigram: 1.1746788178345282
2022-01-28 08:52:27 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 08:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:58:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.621 | ppl 787.32 | wps 8160.9 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 08:58:11 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 08:58:11 | INFO | train | epoch 020 | loss 9.39 | ppl 671.02 | wps 6069.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.527 | train_wall 316 | gb_free 6.1 | wall 6872
KL Stats: Epoch 20 Divergences: Uniform: 2.1594186681035463 Unigram: 1.224249679143832
2022-01-28 08:58:11 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 08:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:59:51 | INFO | train_inner | epoch 021:     20 / 64 loss=9.386, ppl=669.05, wps=5939.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.537, train_wall=494, gb_free=6.1, wall=6972
2022-01-28 09:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:03:55 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.568 | ppl 758.85 | wps 8164.6 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 09:03:55 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 09:03:55 | INFO | train | epoch 021 | loss 9.297 | ppl 629.07 | wps 6068.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.541 | train_wall 317 | gb_free 6.1 | wall 7216
KL Stats: Epoch 21 Divergences: Uniform: 2.1949015801290486 Unigram: 1.2718624906755795
2022-01-28 09:03:55 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 09:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:08:35 | INFO | train_inner | epoch 022:     56 / 64 loss=9.244, ppl=606.27, wps=6234.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.53, train_wall=496, gb_free=6.1, wall=7496
2022-01-28 09:09:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:09:40 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.514 | ppl 731.19 | wps 8133 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:09:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:09:40 | INFO | train | epoch 022 | loss 9.207 | ppl 590.91 | wps 6050 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.53 | train_wall 317 | gb_free 6.1 | wall 7561
KL Stats: Epoch 22 Divergences: Uniform: 2.228719959352157 Unigram: 1.3170625793632273
2022-01-28 09:09:41 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:14:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:15:25 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.452 | ppl 700.15 | wps 8170.1 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:15:25 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:15:25 | INFO | train | epoch 023 | loss 9.121 | ppl 556.73 | wps 6059.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.518 | train_wall 317 | gb_free 6.1 | wall 7906
KL Stats: Epoch 23 Divergences: Uniform: 2.2604290166009124 Unigram: 1.357239971465658
2022-01-28 09:15:25 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:17:45 | INFO | train_inner | epoch 024:     28 / 64 loss=9.105, ppl=550.67, wps=5927.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.52, train_wall=495, gb_free=6.1, wall=8046
2022-01-28 09:20:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:21:10 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.403 | ppl 676.93 | wps 8137.6 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:21:10 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:21:10 | INFO | train | epoch 024 | loss 9.036 | ppl 525.01 | wps 6059.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.529 | train_wall 317 | gb_free 6.1 | wall 8251
KL Stats: Epoch 24 Divergences: Uniform: 2.2904278200253665 Unigram: 1.3957430530112953
2022-01-28 09:21:10 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:26:28 | INFO | train_inner | epoch 025:     64 / 64 loss=8.982, ppl=505.78, wps=6234.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.521, train_wall=495, gb_free=6.1, wall=8568
2022-01-28 09:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:26:55 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.372 | ppl 662.72 | wps 8145.2 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 09:26:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 09:26:55 | INFO | train | epoch 025 | loss 8.954 | ppl 496.06 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.513 | train_wall 317 | gb_free 6.1 | wall 8595
KL Stats: Epoch 25 Divergences: Uniform: 2.326108945617134 Unigram: 1.4329322643720253
2022-01-28 09:26:55 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 09:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:32:39 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.328 | ppl 642.89 | wps 8174.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 09:32:39 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 09:32:39 | INFO | train | epoch 026 | loss 8.874 | ppl 469.06 | wps 6061 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.533 | train_wall 317 | gb_free 6.1 | wall 8940
KL Stats: Epoch 26 Divergences: Uniform: 2.344301141001519 Unigram: 1.4669823172459642
2022-01-28 09:32:39 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 09:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:35:39 | INFO | train_inner | epoch 027:     36 / 64 loss=8.845, ppl=459.99, wps=5931.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.521, train_wall=496, gb_free=6.1, wall=9119
2022-01-28 09:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:38:24 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.29 | ppl 625.88 | wps 8141.9 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 09:38:24 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 09:38:24 | INFO | train | epoch 027 | loss 8.793 | ppl 443.6 | wps 6056 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.511 | train_wall 317 | gb_free 6.1 | wall 9285
KL Stats: Epoch 27 Divergences: Uniform: 2.3734188790962634 Unigram: 1.5003957115593245
2022-01-28 09:38:24 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 09:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:44:09 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.26 | ppl 613.13 | wps 8123.5 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 09:44:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 09:44:09 | INFO | train | epoch 028 | loss 8.713 | ppl 419.64 | wps 6053.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.508 | train_wall 317 | gb_free 6.1 | wall 9630
KL Stats: Epoch 28 Divergences: Uniform: 2.4082056251674877 Unigram: 1.531423714178909
2022-01-28 09:44:09 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 09:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:44:49 | INFO | train_inner | epoch 029:      8 / 64 loss=8.729, ppl=424.45, wps=5921.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.516, train_wall=495, gb_free=6.1, wall=9670
2022-01-28 09:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:49:54 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.229 | ppl 600.25 | wps 8132 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 09:49:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 09:49:54 | INFO | train | epoch 029 | loss 8.634 | ppl 397.37 | wps 6050 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.517 | train_wall 317 | gb_free 6.1 | wall 9975
KL Stats: Epoch 29 Divergences: Uniform: 2.4375981033721397 Unigram: 1.5627348485439554
2022-01-28 09:49:54 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 09:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:53:34 | INFO | train_inner | epoch 030:     44 / 64 loss=8.601, ppl=388.17, wps=6224.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.507, train_wall=497, gb_free=6.1, wall=10195
2022-01-28 09:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:55:40 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.213 | ppl 593.54 | wps 8077.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 09:55:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 09:55:40 | INFO | train | epoch 030 | loss 8.555 | ppl 376.22 | wps 6035.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.511 | train_wall 318 | gb_free 6.1 | wall 10321
KL Stats: Epoch 30 Divergences: Uniform: 2.461237971114943 Unigram: 1.5951743703707557
2022-01-28 09:55:40 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 09:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:01:27 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.165 | ppl 573.96 | wps 8059.1 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 10:01:27 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 10:01:27 | INFO | train | epoch 031 | loss 8.476 | ppl 356.11 | wps 6018.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.488 | train_wall 319 | gb_free 6.1 | wall 10668
KL Stats: Epoch 31 Divergences: Uniform: 2.4873747192802718 Unigram: 1.6237822840386267
2022-01-28 10:01:27 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 10:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:02:48 | INFO | train_inner | epoch 032:     16 / 64 loss=8.478, ppl=356.46, wps=5891.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.496, train_wall=498, gb_free=6.1, wall=10748
2022-01-28 10:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:07:14 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.129 | ppl 560.02 | wps 8113.9 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 10:07:14 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 10:07:14 | INFO | train | epoch 032 | loss 8.401 | ppl 338.09 | wps 6031 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.497 | train_wall 319 | gb_free 6.1 | wall 11014
KL Stats: Epoch 32 Divergences: Uniform: 2.516317742801062 Unigram: 1.6533823990049332
2022-01-28 10:07:14 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 10:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:11:34 | INFO | train_inner | epoch 033:     52 / 64 loss=8.364, ppl=329.49, wps=6207, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.499, train_wall=498, gb_free=6.1, wall=11275
2022-01-28 10:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:13:00 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.114 | ppl 554 | wps 8102.6 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 10:13:00 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 10:13:00 | INFO | train | epoch 033 | loss 8.327 | ppl 321.03 | wps 6033.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.494 | train_wall 318 | gb_free 6.1 | wall 11361
KL Stats: Epoch 33 Divergences: Uniform: 2.545334768358782 Unigram: 1.6808045087154844
2022-01-28 10:13:00 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 10:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:18:46 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.098 | ppl 547.96 | wps 8176.5 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:18:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:18:46 | INFO | train | epoch 034 | loss 8.251 | ppl 304.61 | wps 6041.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.503 | train_wall 318 | gb_free 6.1 | wall 11706
KL Stats: Epoch 34 Divergences: Uniform: 2.5711798802302566 Unigram: 1.7099434912495755
2022-01-28 10:18:46 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:20:45 | INFO | train_inner | epoch 035:     24 / 64 loss=8.238, ppl=301.9, wps=5913.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.497, train_wall=496, gb_free=6.1, wall=11826
2022-01-28 10:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:24:31 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.075 | ppl 539.18 | wps 8123.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 10:24:31 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 10:24:31 | INFO | train | epoch 035 | loss 8.179 | ppl 289.78 | wps 6054.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.498 | train_wall 317 | gb_free 6.1 | wall 12051
KL Stats: Epoch 35 Divergences: Uniform: 2.601064059028507 Unigram: 1.7335640397857044
2022-01-28 10:24:31 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 10:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:29:30 | INFO | train_inner | epoch 036:     60 / 64 loss=8.135, ppl=281.03, wps=6227.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.493, train_wall=497, gb_free=6.1, wall=12351
2022-01-28 10:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:30:16 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.05 | ppl 530.03 | wps 8128.8 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 10:30:16 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 10:30:16 | INFO | train | epoch 036 | loss 8.104 | ppl 275.2 | wps 6051 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.486 | train_wall 317 | gb_free 6.1 | wall 12397
KL Stats: Epoch 36 Divergences: Uniform: 2.627221646543825 Unigram: 1.7617580118149692
2022-01-28 10:30:16 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 10:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:35:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:36:01 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.057 | ppl 532.79 | wps 8119.7 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 10:36:01 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 10:36:01 | INFO | train | epoch 037 | loss 8.035 | ppl 262.2 | wps 6054.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.493 | train_wall 317 | gb_free 6.1 | wall 12741
KL Stats: Epoch 37 Divergences: Uniform: 2.653174660018535 Unigram: 1.7896088403540085
2022-01-28 10:36:01 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 10:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:38:40 | INFO | train_inner | epoch 038:     32 / 64 loss=8.013, ppl=258.3, wps=5924.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.491, train_wall=495, gb_free=6.1, wall=12901
2022-01-28 10:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:41:45 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.046 | ppl 528.45 | wps 8129.2 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 10:41:45 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 10:41:45 | INFO | train | epoch 038 | loss 7.966 | ppl 250.05 | wps 6060.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.499 | train_wall 317 | gb_free 6.1 | wall 13086
KL Stats: Epoch 38 Divergences: Uniform: 2.6907567353551247 Unigram: 1.8107415091128969
2022-01-28 10:41:45 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 10:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:47:30 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.013 | ppl 516.68 | wps 8112.4 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 10:47:30 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 10:47:30 | INFO | train | epoch 039 | loss 7.896 | ppl 238.21 | wps 6055.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.48 | train_wall 317 | gb_free 6.1 | wall 13431
KL Stats: Epoch 39 Divergences: Uniform: 2.701924318532863 Unigram: 1.8391263004519705
2022-01-28 10:47:30 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 10:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:47:50 | INFO | train_inner | epoch 040:      4 / 64 loss=7.918, ppl=241.93, wps=5927.6, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.491, train_wall=495, gb_free=6.1, wall=13451
2022-01-28 10:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:53:15 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.009 | ppl 515.37 | wps 8129.9 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 10:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 10:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint40.pt
2022-01-28 10:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint40.pt
2022-01-28 10:53:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.009) (writing took 4.770516112446785 seconds)
2022-01-28 10:53:20 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 10:53:20 | INFO | train | epoch 040 | loss 7.827 | ppl 227.12 | wps 5976.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.483 | train_wall 317 | gb_free 6.1 | wall 13781
KL Stats: Epoch 40 Divergences: Uniform: 2.737847995292437 Unigram: 1.8618538892909362
2022-01-28 10:53:20 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 10:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:56:39 | INFO | train_inner | epoch 041:     40 / 64 loss=7.804, ppl=223.44, wps=6178.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.48, train_wall=496, gb_free=6.1, wall=13980
2022-01-28 10:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:59:05 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.004 | ppl 513.5 | wps 8157.7 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.004
2022-01-28 10:59:05 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 10:59:05 | INFO | train | epoch 041 | loss 7.763 | ppl 217.24 | wps 6056.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.482 | train_wall 317 | gb_free 6.1 | wall 14125
KL Stats: Epoch 41 Divergences: Uniform: 2.753180655806635 Unigram: 1.8828100295686954
2022-01-28 10:59:05 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 10:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:04:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:04:49 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.969 | ppl 501.1 | wps 8150.8 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 8.969
2022-01-28 11:04:49 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 11:04:49 | INFO | train | epoch 042 | loss 7.699 | ppl 207.83 | wps 6058.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.501 | train_wall 317 | gb_free 6.1 | wall 14470
KL Stats: Epoch 42 Divergences: Uniform: 2.7766883799726045 Unigram: 1.9084547824241616
2022-01-28 11:04:49 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 11:04:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:05:49 | INFO | train_inner | epoch 043:     12 / 64 loss=7.706, ppl=208.74, wps=5926, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.496, train_wall=495, gb_free=6.1, wall=14530
2022-01-28 11:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:10:35 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.978 | ppl 504.4 | wps 8099.1 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 8.978
2022-01-28 11:10:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 11:10:35 | INFO | train | epoch 043 | loss 7.633 | ppl 198.52 | wps 6051.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.481 | train_wall 317 | gb_free 6.1 | wall 14815
KL Stats: Epoch 43 Divergences: Uniform: 2.806148294020482 Unigram: 1.9292602929548321
2022-01-28 11:10:35 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 11:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:14:34 | INFO | train_inner | epoch 044:     48 / 64 loss=7.599, ppl=193.89, wps=6230.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.488, train_wall=496, gb_free=6.1, wall=15055
2022-01-28 11:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:16:20 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.991 | ppl 508.73 | wps 8091.9 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 8.991
2022-01-28 11:16:20 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 11:16:20 | INFO | train | epoch 044 | loss 7.574 | ppl 190.55 | wps 6054.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 15160
KL Stats: Epoch 44 Divergences: Uniform: 2.8291245402096115 Unigram: 1.9491977841918646
2022-01-28 11:16:20 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 11:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:22:04 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.999 | ppl 511.62 | wps 8128.1 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 8.999
2022-01-28 11:22:04 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 11:22:04 | INFO | train | epoch 045 | loss 7.51 | ppl 182.3 | wps 6054.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.494 | train_wall 317 | gb_free 6.1 | wall 15505
KL Stats: Epoch 45 Divergences: Uniform: 2.8467301602793227 Unigram: 1.9765027342930508
2022-01-28 11:22:04 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 11:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:23:44 | INFO | train_inner | epoch 046:     20 / 64 loss=7.51, ppl=182.24, wps=5922.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.492, train_wall=495, gb_free=6.1, wall=15605
2022-01-28 11:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:27:50 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.972 | ppl 502.08 | wps 8108.6 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 8.972
2022-01-28 11:27:50 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 11:27:50 | INFO | train | epoch 046 | loss 7.45 | ppl 174.88 | wps 6050.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.49 | train_wall 317 | gb_free 6.1 | wall 15850
KL Stats: Epoch 46 Divergences: Uniform: 2.8680473508381916 Unigram: 1.9917094472562584
2022-01-28 11:27:50 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 11:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:32:29 | INFO | train_inner | epoch 047:     56 / 64 loss=7.419, ppl=171.16, wps=6227.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.486, train_wall=496, gb_free=6.1, wall=16130
2022-01-28 11:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:33:35 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.971 | ppl 501.88 | wps 8148.8 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 8.971
2022-01-28 11:33:35 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 11:33:35 | INFO | train | epoch 047 | loss 7.391 | ppl 167.84 | wps 6055.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.481 | train_wall 317 | gb_free 6.1 | wall 16195
KL Stats: Epoch 47 Divergences: Uniform: 2.897262869334147 Unigram: 2.0114001537819095
2022-01-28 11:33:35 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 11:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:39:20 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.971 | ppl 501.64 | wps 8145.3 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 8.971
2022-01-28 11:39:20 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 11:39:20 | INFO | train | epoch 048 | loss 7.333 | ppl 161.23 | wps 6051.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.494 | train_wall 317 | gb_free 6.1 | wall 16541
KL Stats: Epoch 48 Divergences: Uniform: 2.919745115931173 Unigram: 2.0372191335802547
2022-01-28 11:39:20 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 11:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:41:40 | INFO | train_inner | epoch 049:     28 / 64 loss=7.316, ppl=159.3, wps=5923.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.491, train_wall=495, gb_free=6.1, wall=16680
2022-01-28 11:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:45:05 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.974 | ppl 502.76 | wps 8114.8 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 8.974
2022-01-28 11:45:05 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 11:45:05 | INFO | train | epoch 049 | loss 7.276 | ppl 155.03 | wps 6052.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.497 | train_wall 317 | gb_free 6.1 | wall 16886
KL Stats: Epoch 49 Divergences: Uniform: 2.9304952616168825 Unigram: 2.0521912407568177
2022-01-28 11:45:05 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 11:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:50:23 | INFO | train_inner | epoch 050:     64 / 64 loss=7.251, ppl=152.29, wps=6226.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.505, train_wall=495, gb_free=6.1, wall=17204
2022-01-28 11:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:50:50 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.004 | ppl 513.45 | wps 8164.7 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.004
2022-01-28 11:50:50 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 11:50:50 | INFO | train | epoch 050 | loss 7.223 | ppl 149.44 | wps 6054.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.506 | train_wall 317 | gb_free 6.1 | wall 17231
KL Stats: Epoch 50 Divergences: Uniform: 2.952408886675405 Unigram: 2.063095420083098
2022-01-28 11:50:50 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 11:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:56:35 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.982 | ppl 505.53 | wps 8111.4 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 8.982
2022-01-28 11:56:35 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 11:56:35 | INFO | train | epoch 051 | loss 7.168 | ppl 143.76 | wps 6051.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.495 | train_wall 317 | gb_free 6.1 | wall 17576
KL Stats: Epoch 51 Divergences: Uniform: 2.9911014144811108 Unigram: 2.0848178377799123
2022-01-28 11:56:35 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 11:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:59:35 | INFO | train_inner | epoch 052:     36 / 64 loss=7.144, ppl=141.39, wps=5925, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.494, train_wall=496, gb_free=6.1, wall=17755
2022-01-28 12:01:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:02:20 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.949 | ppl 494.29 | wps 8156.7 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 8.949
2022-01-28 12:02:20 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 12:02:20 | INFO | train | epoch 052 | loss 7.114 | ppl 138.54 | wps 6058.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.495 | train_wall 317 | gb_free 6.1 | wall 17921
KL Stats: Epoch 52 Divergences: Uniform: 2.999491295389107 Unigram: 2.104438037063829
2022-01-28 12:02:20 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 12:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:08:05 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.965 | ppl 499.58 | wps 8121.2 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 8.965
2022-01-28 12:08:05 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 12:08:05 | INFO | train | epoch 053 | loss 7.062 | ppl 133.66 | wps 6053.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.489 | train_wall 317 | gb_free 6.1 | wall 18266
KL Stats: Epoch 53 Divergences: Uniform: 3.0262221011700654 Unigram: 2.1197227242254333
2022-01-28 12:08:05 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 12:08:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:08:45 | INFO | train_inner | epoch 054:      8 / 64 loss=7.075, ppl=134.85, wps=5925.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.496, train_wall=495, gb_free=6.1, wall=18306
2022-01-28 12:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:13:50 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.978 | ppl 504.41 | wps 8123.8 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 8.978
2022-01-28 12:13:50 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 12:13:50 | INFO | train | epoch 054 | loss 7.013 | ppl 129.18 | wps 6056 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.514 | train_wall 317 | gb_free 6.1 | wall 18610
KL Stats: Epoch 54 Divergences: Uniform: 3.0331763328047683 Unigram: 2.1358477675644916
2022-01-28 12:13:50 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 12:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:17:29 | INFO | train_inner | epoch 055:     44 / 64 loss=6.985, ppl=126.67, wps=6231.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.506, train_wall=496, gb_free=6.1, wall=18830
2022-01-28 12:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:19:35 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.964 | ppl 499.42 | wps 8139.5 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 8.964
2022-01-28 12:19:35 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 12:19:35 | INFO | train | epoch 055 | loss 6.964 | ppl 124.88 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.512 | train_wall 317 | gb_free 6.1 | wall 18955
KL Stats: Epoch 55 Divergences: Uniform: 3.0580563459510652 Unigram: 2.1550038161406873
2022-01-28 12:19:35 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 12:19:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:25:20 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.051 | ppl 530.38 | wps 8159.8 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.009
2022-01-28 12:25:20 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 12:25:20 | INFO | train | epoch 056 | loss 6.914 | ppl 120.62 | wps 6054.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.506 | train_wall 317 | gb_free 6.1 | wall 19300
KL Stats: Epoch 56 Divergences: Uniform: 3.058823775462029 Unigram: 2.166614386435355
2022-01-28 12:25:20 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 12:25:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:26:39 | INFO | train_inner | epoch 057:     16 / 64 loss=6.919, ppl=120.99, wps=5925.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.512, train_wall=495, gb_free=6.1, wall=19380
2022-01-28 12:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:31:05 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.056 | ppl 532.17 | wps 8112.9 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.009
2022-01-28 12:31:05 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 12:31:05 | INFO | train | epoch 057 | loss 6.867 | ppl 116.69 | wps 6051.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.507 | train_wall 317 | gb_free 6.1 | wall 19645
KL Stats: Epoch 57 Divergences: Uniform: 3.0916384477060848 Unigram: 2.1874405134533754
2022-01-28 12:31:05 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 12:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:35:24 | INFO | train_inner | epoch 058:     52 / 64 loss=6.843, ppl=114.8, wps=6226.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.511, train_wall=497, gb_free=6.1, wall=19905
2022-01-28 12:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:36:50 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.049 | ppl 529.86 | wps 8135.6 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.009
2022-01-28 12:36:50 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 12:36:50 | INFO | train | epoch 058 | loss 6.824 | ppl 113.27 | wps 6053.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.521 | train_wall 317 | gb_free 6.1 | wall 19990
KL Stats: Epoch 58 Divergences: Uniform: 3.104350843907884 Unigram: 2.199917902377146
2022-01-28 12:36:50 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 12:36:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:42:35 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.101 | ppl 549.05 | wps 8127.7 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.009
2022-01-28 12:42:35 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 12:42:35 | INFO | train | epoch 059 | loss 6.776 | ppl 109.6 | wps 6056.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.51 | train_wall 317 | gb_free 6.1 | wall 20335
KL Stats: Epoch 59 Divergences: Uniform: 3.1314579957969655 Unigram: 2.2133039924445495
2022-01-28 12:42:35 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 12:42:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:44:34 | INFO | train_inner | epoch 060:     24 / 64 loss=6.771, ppl=109.18, wps=5926.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.515, train_wall=495, gb_free=6.1, wall=20455
2022-01-28 12:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:48:20 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.049 | ppl 529.77 | wps 8137 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.009
2022-01-28 12:48:20 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 12:48:20 | INFO | train | epoch 060 | loss 6.732 | ppl 106.28 | wps 6050.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.521 | train_wall 317 | gb_free 6.1 | wall 20680
KL Stats: Epoch 60 Divergences: Uniform: 3.143418032594961 Unigram: 2.2323062962761893
2022-01-28 12:48:20 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 12:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:53:19 | INFO | train_inner | epoch 061:     60 / 64 loss=6.712, ppl=104.85, wps=6231, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.527, train_wall=496, gb_free=6.1, wall=20980
2022-01-28 12:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:54:04 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.09 | ppl 545.07 | wps 8104.7 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.009
2022-01-28 12:54:04 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 12:54:04 | INFO | train | epoch 061 | loss 6.689 | ppl 103.19 | wps 6059.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.532 | train_wall 317 | gb_free 6.1 | wall 21025
KL Stats: Epoch 61 Divergences: Uniform: 3.171432341674249 Unigram: 2.2459784009114827
2022-01-28 12:54:04 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 12:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:59:49 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.085 | ppl 543.19 | wps 8147.5 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.009
2022-01-28 12:59:49 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 12:59:49 | INFO | train | epoch 062 | loss 6.647 | ppl 100.19 | wps 6056.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.524 | train_wall 317 | gb_free 6.1 | wall 21370
KL Stats: Epoch 62 Divergences: Uniform: 3.1808307150761603 Unigram: 2.261123598600778
2022-01-28 12:59:49 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 12:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:02:29 | INFO | train_inner | epoch 063:     32 / 64 loss=6.622, ppl=98.51, wps=5921.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.533, train_wall=495, gb_free=6.1, wall=21530
2022-01-28 13:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:05:35 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.096 | ppl 547.15 | wps 8130.6 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.009
2022-01-28 13:05:35 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 13:05:35 | INFO | train | epoch 063 | loss 6.606 | ppl 97.39 | wps 6048.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.539 | train_wall 318 | gb_free 6.1 | wall 21715
KL Stats: Epoch 63 Divergences: Uniform: 3.200481563793306 Unigram: 2.2735106240258554
2022-01-28 13:05:35 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 13:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:11:19 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.15 | ppl 567.97 | wps 8154.1 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.009
2022-01-28 13:11:19 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 13:11:19 | INFO | train | epoch 064 | loss 6.56 | ppl 94.36 | wps 6061.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.534 | train_wall 317 | gb_free 6.1 | wall 22060
KL Stats: Epoch 64 Divergences: Uniform: 3.2083738992016313 Unigram: 2.2875530881665838
2022-01-28 13:11:19 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 13:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:11:39 | INFO | train_inner | epoch 065:      4 / 64 loss=6.587, ppl=96.16, wps=5928.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.533, train_wall=495, gb_free=6.1, wall=22080
2022-01-28 13:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:17:04 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.056 | ppl 532.27 | wps 8153.8 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.009
2022-01-28 13:17:04 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 13:17:04 | INFO | train | epoch 065 | loss 6.519 | ppl 91.7 | wps 6058.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.536 | train_wall 317 | gb_free 6.1 | wall 22405
KL Stats: Epoch 65 Divergences: Uniform: 3.2289370439658946 Unigram: 2.3034690422213875
2022-01-28 13:17:04 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 13:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:20:23 | INFO | train_inner | epoch 066:     40 / 64 loss=6.494, ppl=90.11, wps=6234.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.531, train_wall=496, gb_free=6.1, wall=22604
2022-01-28 13:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:22:48 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.097 | ppl 547.61 | wps 8174 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.009
2022-01-28 13:22:48 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 13:22:48 | INFO | train | epoch 066 | loss 6.477 | ppl 89.1 | wps 6061.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.526 | train_wall 317 | gb_free 6.1 | wall 22749
KL Stats: Epoch 66 Divergences: Uniform: 3.242511054858916 Unigram: 2.3172734233468466
2022-01-28 13:22:48 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 13:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:28:34 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.087 | ppl 543.78 | wps 8119.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.009
2022-01-28 13:28:34 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 13:28:34 | INFO | train | epoch 067 | loss 6.439 | ppl 86.73 | wps 6050.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.538 | train_wall 317 | gb_free 6.1 | wall 23094
KL Stats: Epoch 67 Divergences: Uniform: 3.271401418668135 Unigram: 2.3348384337376555
2022-01-28 13:28:34 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 13:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:29:34 | INFO | train_inner | epoch 068:     12 / 64 loss=6.447, ppl=87.24, wps=5925.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.533, train_wall=495, gb_free=6.1, wall=23154
2022-01-28 13:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:34:18 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.172 | ppl 576.73 | wps 8133.1 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.009
2022-01-28 13:34:18 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 13:34:18 | INFO | train | epoch 068 | loss 6.4 | ppl 84.43 | wps 6058.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.546 | train_wall 317 | gb_free 6.1 | wall 23439
KL Stats: Epoch 68 Divergences: Uniform: 3.278031240290554 Unigram: 2.3464710529359563
2022-01-28 13:34:18 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 13:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:38:19 | INFO | train_inner | epoch 069:     48 / 64 loss=6.382, ppl=83.4, wps=6222.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.543, train_wall=497, gb_free=6.1, wall=23679
2022-01-28 13:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:40:05 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.203 | ppl 589.43 | wps 8106 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.009
2022-01-28 13:40:05 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 13:40:05 | INFO | train | epoch 069 | loss 6.362 | ppl 82.27 | wps 6029.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.542 | train_wall 319 | gb_free 6.1 | wall 23786
KL Stats: Epoch 69 Divergences: Uniform: 3.298100057200649 Unigram: 2.3583776989990586
2022-01-28 13:40:05 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 13:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:45:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:45:52 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.203 | ppl 589.19 | wps 8083 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.009
2022-01-28 13:45:52 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 13:45:52 | INFO | train | epoch 070 | loss 6.327 | ppl 80.3 | wps 6024.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.537 | train_wall 319 | gb_free 6.1 | wall 24132
KL Stats: Epoch 70 Divergences: Uniform: 3.3143658273970344 Unigram: 2.3710917083623406
2022-01-28 13:45:52 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 13:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:47:32 | INFO | train_inner | epoch 071:     20 / 64 loss=6.322, ppl=80.02, wps=5894.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.544, train_wall=498, gb_free=6.1, wall=24232
2022-01-28 13:51:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:51:38 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.162 | ppl 572.77 | wps 8115.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.009
2022-01-28 13:51:38 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 13:51:38 | INFO | train | epoch 071 | loss 6.295 | ppl 78.5 | wps 6033.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.561 | train_wall 318 | gb_free 6.1 | wall 24478
KL Stats: Epoch 71 Divergences: Uniform: 3.324081634660324 Unigram: 2.3851994201441737
2022-01-28 13:51:38 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 13:51:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:56:19 | INFO | train_inner | epoch 072:     56 / 64 loss=6.279, ppl=77.65, wps=6201.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.559, train_wall=499, gb_free=6.1, wall=24759
2022-01-28 13:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:57:25 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.148 | ppl 567.16 | wps 8101.3 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.009
2022-01-28 13:57:25 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 13:57:25 | INFO | train | epoch 072 | loss 6.259 | ppl 76.57 | wps 6021.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.55 | train_wall 319 | gb_free 6.1 | wall 24825
KL Stats: Epoch 72 Divergences: Uniform: 3.3445219276113294 Unigram: 2.3981410049619645
2022-01-28 13:57:25 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 13:57:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:03:10 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.243 | ppl 605.87 | wps 8146.1 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.009
2022-01-28 14:03:10 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 14:03:10 | INFO | train | epoch 073 | loss 6.227 | ppl 74.92 | wps 6055 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.555 | train_wall 317 | gb_free 6.1 | wall 25170
KL Stats: Epoch 73 Divergences: Uniform: 3.343644107864319 Unigram: 2.406806975325319
2022-01-28 14:03:10 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 14:03:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:05:29 | INFO | train_inner | epoch 074:     28 / 64 loss=6.216, ppl=74.35, wps=5921.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.553, train_wall=495, gb_free=6.1, wall=25310
2022-01-28 14:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:08:54 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.171 | ppl 576.5 | wps 8138.1 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.009
2022-01-28 14:08:54 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 14:08:54 | INFO | train | epoch 074 | loss 6.195 | ppl 73.25 | wps 6056.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.551 | train_wall 317 | gb_free 6.1 | wall 25515
KL Stats: Epoch 74 Divergences: Uniform: 3.3655043019753164 Unigram: 2.4251046972279013
2022-01-28 14:08:54 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 14:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:14:12 | INFO | train_inner | epoch 075:     64 / 64 loss=6.185, ppl=72.75, wps=6232.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.55, train_wall=495, gb_free=6.1, wall=25833
2022-01-28 14:14:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:14:39 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.31 | ppl 634.89 | wps 8137.6 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.009
2022-01-28 14:14:39 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 14:14:39 | INFO | train | epoch 075 | loss 6.165 | ppl 71.74 | wps 6057.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.548 | train_wall 317 | gb_free 6.1 | wall 25860
KL Stats: Epoch 75 Divergences: Uniform: 3.3665383066328904 Unigram: 2.4331673290059666
2022-01-28 14:14:39 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 14:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:20:24 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.254 | ppl 610.36 | wps 8136.4 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.009
2022-01-28 14:20:24 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 14:20:24 | INFO | train | epoch 076 | loss 6.137 | ppl 70.37 | wps 6059 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.572 | train_wall 317 | gb_free 6.1 | wall 26205
KL Stats: Epoch 76 Divergences: Uniform: 3.3752264820942073 Unigram: 2.44799484489126
2022-01-28 14:20:24 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 14:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:23:23 | INFO | train_inner | epoch 077:     36 / 64 loss=6.112, ppl=69.18, wps=5931.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.569, train_wall=496, gb_free=6.1, wall=26384
2022-01-28 14:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:26:09 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.263 | ppl 614.33 | wps 8115.3 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.009
2022-01-28 14:26:09 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 14:26:09 | INFO | train | epoch 077 | loss 6.107 | ppl 68.92 | wps 6058.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.568 | train_wall 317 | gb_free 6.1 | wall 26549
KL Stats: Epoch 77 Divergences: Uniform: 3.3812183209964024 Unigram: 2.462989228913586
2022-01-28 14:26:09 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 14:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:31:54 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.256 | ppl 611.31 | wps 8149.2 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.009
2022-01-28 14:31:54 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 14:31:54 | INFO | train | epoch 078 | loss 6.079 | ppl 67.61 | wps 6054.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.563 | train_wall 317 | gb_free 6.1 | wall 26894
KL Stats: Epoch 78 Divergences: Uniform: 3.3972048321354404 Unigram: 2.4691752577907393
2022-01-28 14:31:54 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 14:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:32:34 | INFO | train_inner | epoch 079:      8 / 64 loss=6.093, ppl=68.28, wps=5924.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.566, train_wall=495, gb_free=6.1, wall=26934
2022-01-28 14:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:37:38 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.291 | ppl 626.47 | wps 8144.5 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.009
2022-01-28 14:37:38 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 14:37:38 | INFO | train | epoch 079 | loss 6.05 | ppl 66.24 | wps 6057.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.559 | train_wall 317 | gb_free 6.1 | wall 27239
KL Stats: Epoch 79 Divergences: Uniform: 3.4101566346655727 Unigram: 2.4789490535742855
2022-01-28 14:37:38 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 14:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:41:18 | INFO | train_inner | epoch 080:     44 / 64 loss=6.034, ppl=65.53, wps=6229.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.563, train_wall=496, gb_free=6.1, wall=27459
2022-01-28 14:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:43:23 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.247 | ppl 607.6 | wps 8176.9 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.009
2022-01-28 14:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 14:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint80.pt
2022-01-28 14:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint80.pt
2022-01-28 14:43:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.247) (writing took 3.2372304275631905 seconds)
2022-01-28 14:43:27 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 14:43:27 | INFO | train | epoch 080 | loss 6.025 | ppl 65.12 | wps 5994.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.572 | train_wall 317 | gb_free 6.1 | wall 27588
KL Stats: Epoch 80 Divergences: Uniform: 3.414108208005713 Unigram: 2.491517820730772
2022-01-28 14:43:27 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 14:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:49:12 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.287 | ppl 624.75 | wps 8130.1 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.009
2022-01-28 14:49:12 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 14:49:12 | INFO | train | epoch 081 | loss 5.998 | ppl 63.93 | wps 6056.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.583 | train_wall 317 | gb_free 6.1 | wall 27932
KL Stats: Epoch 81 Divergences: Uniform: 3.4325940875651515 Unigram: 2.505752413843242
2022-01-28 14:49:12 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 14:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:50:32 | INFO | train_inner | epoch 082:     16 / 64 loss=6.005, ppl=64.21, wps=5888.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.58, train_wall=495, gb_free=6.1, wall=28013
2022-01-28 14:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:54:57 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.292 | ppl 626.88 | wps 8112.5 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.009
2022-01-28 14:54:57 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 14:54:57 | INFO | train | epoch 082 | loss 5.974 | ppl 62.86 | wps 6052.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.573 | train_wall 317 | gb_free 6.1 | wall 28278
KL Stats: Epoch 82 Divergences: Uniform: 3.442120025700799 Unigram: 2.5180492928120173
2022-01-28 14:54:57 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 14:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:59:16 | INFO | train_inner | epoch 083:     52 / 64 loss=5.961, ppl=62.29, wps=6231.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.583, train_wall=496, gb_free=6.1, wall=28537
2022-01-28 15:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:00:42 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.262 | ppl 613.76 | wps 8112.6 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.009
2022-01-28 15:00:42 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 15:00:42 | INFO | train | epoch 083 | loss 5.951 | ppl 61.86 | wps 6057.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.592 | train_wall 317 | gb_free 6.1 | wall 28622
KL Stats: Epoch 83 Divergences: Uniform: 3.4361076982509173 Unigram: 2.5250881529891434
2022-01-28 15:00:42 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 15:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:06:27 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.293 | ppl 627.45 | wps 8129 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.009
2022-01-28 15:06:27 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 15:06:27 | INFO | train | epoch 084 | loss 5.925 | ppl 60.76 | wps 6054.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.567 | train_wall 317 | gb_free 6.1 | wall 28967
KL Stats: Epoch 84 Divergences: Uniform: 3.455145228454075 Unigram: 2.5376628850546616
2022-01-28 15:06:27 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 15:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:08:26 | INFO | train_inner | epoch 085:     24 / 64 loss=5.915, ppl=60.34, wps=5925.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.58, train_wall=495, gb_free=6.1, wall=29087
2022-01-28 15:11:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:12:12 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.309 | ppl 634.31 | wps 8115.1 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.009
2022-01-28 15:12:12 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 15:12:12 | INFO | train | epoch 085 | loss 5.902 | ppl 59.8 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.59 | train_wall 317 | gb_free 6.1 | wall 29312
KL Stats: Epoch 85 Divergences: Uniform: 3.467866020841806 Unigram: 2.544565463351822
2022-01-28 15:12:12 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 15:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:17:11 | INFO | train_inner | epoch 086:     60 / 64 loss=5.9, ppl=59.7, wps=6231.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.595, train_wall=496, gb_free=6.1, wall=29612
2022-01-28 15:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:17:56 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.367 | ppl 660.47 | wps 8128.9 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.009
2022-01-28 15:17:56 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 15:17:56 | INFO | train | epoch 086 | loss 5.88 | ppl 58.88 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.604 | train_wall 317 | gb_free 6.1 | wall 29657
KL Stats: Epoch 86 Divergences: Uniform: 3.4634328195374646 Unigram: 2.557568903451912
2022-01-28 15:17:56 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 15:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:23:42 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.32 | ppl 639.19 | wps 8114.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.009
2022-01-28 15:23:42 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 15:23:42 | INFO | train | epoch 087 | loss 5.858 | ppl 57.99 | wps 6050.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.621 | train_wall 317 | gb_free 6.1 | wall 30002
KL Stats: Epoch 87 Divergences: Uniform: 3.4766016593785802 Unigram: 2.5694375257199993
2022-01-28 15:23:42 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 15:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:26:21 | INFO | train_inner | epoch 088:     32 / 64 loss=5.845, ppl=57.46, wps=5920.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.616, train_wall=495, gb_free=6.1, wall=30162
2022-01-28 15:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:29:26 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.335 | ppl 645.81 | wps 8148.5 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.009
2022-01-28 15:29:26 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 15:29:26 | INFO | train | epoch 088 | loss 5.834 | ppl 57.06 | wps 6056 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.603 | train_wall 317 | gb_free 6.1 | wall 30347
KL Stats: Epoch 88 Divergences: Uniform: 3.480235182016731 Unigram: 2.5807237399719685
2022-01-28 15:29:26 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 15:29:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:35:11 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.346 | ppl 650.8 | wps 8139.3 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.009
2022-01-28 15:35:11 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 15:35:11 | INFO | train | epoch 089 | loss 5.816 | ppl 56.33 | wps 6057.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.614 | train_wall 317 | gb_free 6.1 | wall 30692
KL Stats: Epoch 89 Divergences: Uniform: 3.4902162363515448 Unigram: 2.5857325673262066
2022-01-28 15:35:11 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 15:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:35:31 | INFO | train_inner | epoch 090:      4 / 64 loss=5.826, ppl=56.74, wps=5927.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.609, train_wall=495, gb_free=6.1, wall=30712
2022-01-28 15:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:40:57 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.396 | ppl 673.75 | wps 8138 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.009
2022-01-28 15:40:57 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 15:40:57 | INFO | train | epoch 090 | loss 5.796 | ppl 55.55 | wps 6047.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.612 | train_wall 318 | gb_free 6.1 | wall 31037
KL Stats: Epoch 90 Divergences: Uniform: 3.496222103642084 Unigram: 2.5906418846069417
2022-01-28 15:40:57 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 15:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:44:16 | INFO | train_inner | epoch 091:     40 / 64 loss=5.778, ppl=54.89, wps=6228.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.615, train_wall=497, gb_free=6.1, wall=31237
2022-01-28 15:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:46:41 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.376 | ppl 664.31 | wps 8139.6 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.009
2022-01-28 15:46:41 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 15:46:41 | INFO | train | epoch 091 | loss 5.775 | ppl 54.77 | wps 6061.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.625 | train_wall 317 | gb_free 6.1 | wall 31382
KL Stats: Epoch 91 Divergences: Uniform: 3.505683210972305 Unigram: 2.608175058233648
2022-01-28 15:46:41 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 15:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:52:27 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.397 | ppl 674 | wps 8141.5 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.009
2022-01-28 15:52:27 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 15:52:27 | INFO | train | epoch 092 | loss 5.755 | ppl 53.99 | wps 6049.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.621 | train_wall 318 | gb_free 6.1 | wall 31727
KL Stats: Epoch 92 Divergences: Uniform: 3.516909936878663 Unigram: 2.6138816848099626
2022-01-28 15:52:27 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 15:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:53:26 | INFO | train_inner | epoch 093:     12 / 64 loss=5.764, ppl=54.35, wps=5923, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.623, train_wall=495, gb_free=6.1, wall=31787
2022-01-28 15:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:58:11 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.414 | ppl 682.23 | wps 8094.1 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.009
2022-01-28 15:58:11 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 15:58:11 | INFO | train | epoch 093 | loss 5.737 | ppl 53.34 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.627 | train_wall 317 | gb_free 6.1 | wall 32072
KL Stats: Epoch 93 Divergences: Uniform: 3.521783393698166 Unigram: 2.624496457209547
2022-01-28 15:58:11 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 15:58:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:02:11 | INFO | train_inner | epoch 094:     48 / 64 loss=5.723, ppl=52.83, wps=6230.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.624, train_wall=496, gb_free=6.1, wall=32312
2022-01-28 16:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:03:56 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.427 | ppl 688.11 | wps 8111.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.009
2022-01-28 16:03:56 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 16:03:56 | INFO | train | epoch 094 | loss 5.716 | ppl 52.58 | wps 6053.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.623 | train_wall 317 | gb_free 6.1 | wall 32417
KL Stats: Epoch 94 Divergences: Uniform: 3.516655202129921 Unigram: 2.6349609849509057
2022-01-28 16:03:56 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 16:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:09:42 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.451 | ppl 699.93 | wps 8135.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.009
2022-01-28 16:09:42 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 16:09:42 | INFO | train | epoch 095 | loss 5.699 | ppl 51.94 | wps 6050.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.628 | train_wall 317 | gb_free 6.1 | wall 32762
KL Stats: Epoch 95 Divergences: Uniform: 3.5250798486573296 Unigram: 2.643410128802127
2022-01-28 16:09:42 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 16:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:11:21 | INFO | train_inner | epoch 096:     20 / 64 loss=5.698, ppl=51.9, wps=5921.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.632, train_wall=495, gb_free=6.1, wall=32862
2022-01-28 16:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:15:26 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.389 | ppl 670.58 | wps 8130.4 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.009
2022-01-28 16:15:26 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 16:15:26 | INFO | train | epoch 096 | loss 5.683 | ppl 51.36 | wps 6057.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.646 | train_wall 317 | gb_free 6.1 | wall 33107
KL Stats: Epoch 96 Divergences: Uniform: 3.5334876968868034 Unigram: 2.6500223730597767
2022-01-28 16:15:26 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 16:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:20:06 | INFO | train_inner | epoch 097:     56 / 64 loss=5.676, ppl=51.14, wps=6235.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.65, train_wall=496, gb_free=6.1, wall=33386
2022-01-28 16:20:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:21:11 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.437 | ppl 693.1 | wps 8087.3 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.009
2022-01-28 16:21:11 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 16:21:11 | INFO | train | epoch 097 | loss 5.665 | ppl 50.74 | wps 6056.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.651 | train_wall 317 | gb_free 6.1 | wall 33452
KL Stats: Epoch 97 Divergences: Uniform: 3.5420201187709464 Unigram: 2.662495043983578
2022-01-28 16:21:11 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 16:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:26:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:26:56 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.472 | ppl 710.3 | wps 8135.5 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.009
2022-01-28 16:26:56 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 16:26:56 | INFO | train | epoch 098 | loss 5.645 | ppl 50.05 | wps 6058.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.636 | train_wall 317 | gb_free 6.1 | wall 33797
KL Stats: Epoch 98 Divergences: Uniform: 3.542173459696018 Unigram: 2.6640240836027087
2022-01-28 16:26:56 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 16:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:29:16 | INFO | train_inner | epoch 099:     28 / 64 loss=5.637, ppl=49.77, wps=5925.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.641, train_wall=495, gb_free=6.1, wall=33937
2022-01-28 16:32:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:32:41 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.471 | ppl 709.69 | wps 8149.4 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.009
2022-01-28 16:32:41 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 16:32:41 | INFO | train | epoch 099 | loss 5.63 | ppl 49.52 | wps 6055.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.659 | train_wall 317 | gb_free 6.1 | wall 34142
KL Stats: Epoch 99 Divergences: Uniform: 3.553824387705702 Unigram: 2.6771679491770306
2022-01-28 16:32:41 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 16:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:37:59 | INFO | train_inner | epoch 100:     64 / 64 loss=5.633, ppl=49.62, wps=6229.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.673, train_wall=495, gb_free=6.1, wall=34460
2022-01-28 16:37:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:38:26 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.451 | ppl 699.86 | wps 8088.3 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.009
2022-01-28 16:38:26 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 16:38:26 | INFO | train | epoch 100 | loss 5.617 | ppl 49.07 | wps 6052.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.676 | train_wall 317 | gb_free 6.1 | wall 34487
KL Stats: Epoch 100 Divergences: Uniform: 3.552975117022654 Unigram: 2.6810664823729358
2022-01-28 16:38:26 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 16:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:44:11 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.494 | ppl 720.93 | wps 8158.7 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.009
2022-01-28 16:44:11 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 16:44:11 | INFO | train | epoch 101 | loss 5.595 | ppl 48.34 | wps 6060.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.663 | train_wall 317 | gb_free 6.1 | wall 34832
KL Stats: Epoch 101 Divergences: Uniform: 3.5631428507768046 Unigram: 2.692593517379659
2022-01-28 16:44:11 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 16:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:47:11 | INFO | train_inner | epoch 102:     36 / 64 loss=5.581, ppl=47.87, wps=5926, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.66, train_wall=496, gb_free=6.1, wall=35011
2022-01-28 16:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:49:56 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.496 | ppl 722.06 | wps 8145 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.009
2022-01-28 16:49:56 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 16:49:56 | INFO | train | epoch 102 | loss 5.582 | ppl 47.89 | wps 6055.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.668 | train_wall 317 | gb_free 6.1 | wall 35176
KL Stats: Epoch 102 Divergences: Uniform: 3.5625719919344396 Unigram: 2.698766088676199
2022-01-28 16:49:56 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 16:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:55:40 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.506 | ppl 727.21 | wps 8135.5 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.009
2022-01-28 16:55:40 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 16:55:40 | INFO | train | epoch 103 | loss 5.565 | ppl 47.34 | wps 6057.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.661 | train_wall 317 | gb_free 6.1 | wall 35521
KL Stats: Epoch 103 Divergences: Uniform: 3.57114346515217 Unigram: 2.7070877731931087
2022-01-28 16:55:40 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 16:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:56:20 | INFO | train_inner | epoch 104:      8 / 64 loss=5.573, ppl=47.6, wps=5928.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.667, train_wall=495, gb_free=6.1, wall=35561
2022-01-28 17:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:01:25 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.499 | ppl 723.79 | wps 8139 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.009
2022-01-28 17:01:25 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 17:01:25 | INFO | train | epoch 104 | loss 5.553 | ppl 46.96 | wps 6059 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.675 | train_wall 317 | gb_free 6.1 | wall 35866
KL Stats: Epoch 104 Divergences: Uniform: 3.5663668433137325 Unigram: 2.7175213390067583
2022-01-28 17:01:25 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 17:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:05:04 | INFO | train_inner | epoch 105:     44 / 64 loss=5.541, ppl=46.56, wps=6236.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.679, train_wall=496, gb_free=6.1, wall=36085
2022-01-28 17:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:07:10 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.522 | ppl 735.08 | wps 8147.9 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.009
2022-01-28 17:07:10 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 17:07:10 | INFO | train | epoch 105 | loss 5.537 | ppl 46.42 | wps 6064.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.687 | train_wall 317 | gb_free 6.1 | wall 36210
KL Stats: Epoch 105 Divergences: Uniform: 3.57414467198236 Unigram: 2.722351854132167
2022-01-28 17:07:10 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 17:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:12:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:12:55 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.519 | ppl 733.66 | wps 8156.5 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.009
2022-01-28 17:12:55 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 17:12:55 | INFO | train | epoch 106 | loss 5.521 | ppl 45.91 | wps 6052.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.681 | train_wall 317 | gb_free 6.1 | wall 36555
KL Stats: Epoch 106 Divergences: Uniform: 3.572913254624835 Unigram: 2.729770827600282
2022-01-28 17:12:55 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 17:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:14:15 | INFO | train_inner | epoch 107:     16 / 64 loss=5.524, ppl=46.03, wps=5925.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.687, train_wall=495, gb_free=6.1, wall=36635
2022-01-28 17:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:18:41 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.488 | ppl 717.85 | wps 8103.1 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.009
2022-01-28 17:18:41 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 17:18:41 | INFO | train | epoch 107 | loss 5.506 | ppl 45.45 | wps 6036.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.686 | train_wall 318 | gb_free 6.1 | wall 36901
KL Stats: Epoch 107 Divergences: Uniform: 3.583171213355744 Unigram: 2.740475471211284
2022-01-28 17:18:41 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 17:18:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:23:02 | INFO | train_inner | epoch 108:     52 / 64 loss=5.501, ppl=45.3, wps=6202.1, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.685, train_wall=499, gb_free=6.1, wall=37162
2022-01-28 17:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:24:27 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.526 | ppl 737.14 | wps 8150.7 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.009
2022-01-28 17:24:27 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 17:24:27 | INFO | train | epoch 108 | loss 5.495 | ppl 45.1 | wps 6025.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.693 | train_wall 319 | gb_free 6.1 | wall 37248
KL Stats: Epoch 108 Divergences: Uniform: 3.5824417556808412 Unigram: 2.7449999577301742
2022-01-28 17:24:27 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 17:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:30:14 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.527 | ppl 737.66 | wps 8087.9 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.009
2022-01-28 17:30:14 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 17:30:14 | INFO | train | epoch 109 | loss 5.481 | ppl 44.65 | wps 6026.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.694 | train_wall 319 | gb_free 6.1 | wall 37595
KL Stats: Epoch 109 Divergences: Uniform: 3.587624964902415 Unigram: 2.7540535526808982
2022-01-28 17:30:14 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 17:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:32:14 | INFO | train_inner | epoch 110:     24 / 64 loss=5.475, ppl=44.49, wps=5899.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.701, train_wall=497, gb_free=6.1, wall=37715
2022-01-28 17:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:36:00 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.602 | ppl 777.16 | wps 8108.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.009
2022-01-28 17:36:00 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 17:36:00 | INFO | train | epoch 110 | loss 5.468 | ppl 44.26 | wps 6033.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.696 | train_wall 318 | gb_free 6.1 | wall 37941
KL Stats: Epoch 110 Divergences: Uniform: 3.592542974249395 Unigram: 2.760137829736133
2022-01-28 17:36:00 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 17:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:40:59 | INFO | train_inner | epoch 111:     60 / 64 loss=5.466, ppl=44.2, wps=6222.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.696, train_wall=497, gb_free=6.1, wall=38240
2022-01-28 17:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:41:45 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.546 | ppl 747.64 | wps 8143.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.009
2022-01-28 17:41:45 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 17:41:45 | INFO | train | epoch 111 | loss 5.454 | ppl 43.83 | wps 6055.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.705 | train_wall 317 | gb_free 6.1 | wall 38286
KL Stats: Epoch 111 Divergences: Uniform: 3.596666054888614 Unigram: 2.7699622454984
2022-01-28 17:41:45 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 17:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:47:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:47:30 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.582 | ppl 766.3 | wps 8113 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.009
2022-01-28 17:47:30 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 17:47:30 | INFO | train | epoch 112 | loss 5.441 | ppl 43.45 | wps 6052.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.716 | train_wall 317 | gb_free 6.1 | wall 38631
KL Stats: Epoch 112 Divergences: Uniform: 3.591142321500681 Unigram: 2.7773580899304195
2022-01-28 17:47:30 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 17:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:50:10 | INFO | train_inner | epoch 113:     32 / 64 loss=5.43, ppl=43.1, wps=5922.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.713, train_wall=495, gb_free=6.1, wall=38790
2022-01-28 17:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:53:15 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.54 | ppl 744.21 | wps 8137.5 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.009
2022-01-28 17:53:15 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 17:53:15 | INFO | train | epoch 113 | loss 5.425 | ppl 42.97 | wps 6056 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.716 | train_wall 317 | gb_free 6.1 | wall 38976
KL Stats: Epoch 113 Divergences: Uniform: 3.6093529991398796 Unigram: 2.7838400251538395
2022-01-28 17:53:15 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 17:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:59:00 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.547 | ppl 747.84 | wps 8130.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.009
2022-01-28 17:59:00 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 17:59:00 | INFO | train | epoch 114 | loss 5.414 | ppl 42.62 | wps 6055.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.716 | train_wall 317 | gb_free 6.1 | wall 39321
KL Stats: Epoch 114 Divergences: Uniform: 3.6003536758981594 Unigram: 2.7906372000046216
2022-01-28 17:59:00 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 17:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:59:20 | INFO | train_inner | epoch 115:      4 / 64 loss=5.425, ppl=42.97, wps=5925.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.721, train_wall=495, gb_free=6.1, wall=39341
2022-01-28 18:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:04:45 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.589 | ppl 770.28 | wps 8148.6 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.009
2022-01-28 18:04:45 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 18:04:45 | INFO | train | epoch 115 | loss 5.402 | ppl 42.28 | wps 6055.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.724 | train_wall 317 | gb_free 6.1 | wall 39665
KL Stats: Epoch 115 Divergences: Uniform: 3.6044157451912398 Unigram: 2.7970831100008406
2022-01-28 18:04:45 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 18:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:08:04 | INFO | train_inner | epoch 116:     40 / 64 loss=5.389, ppl=41.9, wps=6232.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.724, train_wall=496, gb_free=6.1, wall=39865
2022-01-28 18:10:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:10:30 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.567 | ppl 758.56 | wps 8128.7 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.009
2022-01-28 18:10:30 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 18:10:30 | INFO | train | epoch 116 | loss 5.389 | ppl 41.92 | wps 6056.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.725 | train_wall 317 | gb_free 6.1 | wall 40010
KL Stats: Epoch 116 Divergences: Uniform: 3.607220669190618 Unigram: 2.795517143439146
2022-01-28 18:10:30 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 18:10:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:16:14 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.594 | ppl 773.05 | wps 8129.1 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.009
2022-01-28 18:16:14 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 18:16:14 | INFO | train | epoch 117 | loss 5.379 | ppl 41.6 | wps 6058.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.729 | train_wall 317 | gb_free 6.1 | wall 40355
KL Stats: Epoch 117 Divergences: Uniform: 3.6110947721543125 Unigram: 2.811831327210624
2022-01-28 18:16:14 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 18:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:17:14 | INFO | train_inner | epoch 118:     12 / 64 loss=5.383, ppl=41.72, wps=5928.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.725, train_wall=495, gb_free=6.1, wall=40415
2022-01-28 18:21:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:21:59 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.623 | ppl 788.52 | wps 8133.5 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.009
2022-01-28 18:21:59 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 18:21:59 | INFO | train | epoch 118 | loss 5.365 | ppl 41.22 | wps 6054.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.731 | train_wall 317 | gb_free 6.1 | wall 40700
KL Stats: Epoch 118 Divergences: Uniform: 3.6135353160549997 Unigram: 2.8176280386544206
2022-01-28 18:21:59 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 18:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:25:59 | INFO | train_inner | epoch 119:     48 / 64 loss=5.356, ppl=40.96, wps=6230.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.735, train_wall=496, gb_free=6.1, wall=40939
2022-01-28 18:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:27:44 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.605 | ppl 778.87 | wps 8115.8 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.009
2022-01-28 18:27:44 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 18:27:44 | INFO | train | epoch 119 | loss 5.354 | ppl 40.9 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.74 | train_wall 317 | gb_free 6.1 | wall 41045
KL Stats: Epoch 119 Divergences: Uniform: 3.6196373358759093 Unigram: 2.8234028924162313
2022-01-28 18:27:44 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 18:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:33:29 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.618 | ppl 785.64 | wps 8112.1 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.009
2022-01-28 18:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 18:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint120.pt
2022-01-28 18:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint120.pt
2022-01-28 18:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.618) (writing took 4.173781894147396 seconds)
2022-01-28 18:33:34 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 18:33:34 | INFO | train | epoch 120 | loss 5.345 | ppl 40.64 | wps 5976.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.764 | train_wall 317 | gb_free 6.1 | wall 41394
KL Stats: Epoch 120 Divergences: Uniform: 3.6270321671612464 Unigram: 2.829969737353031
2022-01-28 18:33:34 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 18:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:35:13 | INFO | train_inner | epoch 121:     20 / 64 loss=5.346, ppl=40.66, wps=5875.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.755, train_wall=495, gb_free=6.1, wall=41494
2022-01-28 18:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:39:19 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.644 | ppl 800.21 | wps 8115.6 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.009
2022-01-28 18:39:19 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 18:39:19 | INFO | train | epoch 121 | loss 5.331 | ppl 40.26 | wps 6051.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.735 | train_wall 317 | gb_free 6.1 | wall 41740
KL Stats: Epoch 121 Divergences: Uniform: 3.634066661093111 Unigram: 2.8363568525657197
2022-01-28 18:39:19 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 18:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:43:58 | INFO | train_inner | epoch 122:     56 / 64 loss=5.33, ppl=40.23, wps=6227.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.744, train_wall=496, gb_free=6.1, wall=42019
2022-01-28 18:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:45:04 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.627 | ppl 790.77 | wps 8092.9 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.009
2022-01-28 18:45:04 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 18:45:04 | INFO | train | epoch 122 | loss 5.323 | ppl 40.04 | wps 6053.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.745 | train_wall 317 | gb_free 6.1 | wall 42085
KL Stats: Epoch 122 Divergences: Uniform: 3.630135078193133 Unigram: 2.8429513068607632
2022-01-28 18:45:04 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 18:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:50:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:50:49 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.645 | ppl 800.55 | wps 8119.3 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.009
2022-01-28 18:50:49 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 18:50:49 | INFO | train | epoch 123 | loss 5.311 | ppl 39.71 | wps 6054.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.767 | train_wall 317 | gb_free 6.1 | wall 42430
KL Stats: Epoch 123 Divergences: Uniform: 3.630253971072763 Unigram: 2.848719492521595
2022-01-28 18:50:49 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 18:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:53:09 | INFO | train_inner | epoch 124:     28 / 64 loss=5.305, ppl=39.53, wps=5920.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.765, train_wall=495, gb_free=6.1, wall=42570
2022-01-28 18:56:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:56:34 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.609 | ppl 781 | wps 8111.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.009
2022-01-28 18:56:34 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 18:56:34 | INFO | train | epoch 124 | loss 5.3 | ppl 39.41 | wps 6049.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.774 | train_wall 317 | gb_free 6.1 | wall 42775
KL Stats: Epoch 124 Divergences: Uniform: 3.623070460978583 Unigram: 2.849752055450487
2022-01-28 18:56:34 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 18:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:01:52 | INFO | train_inner | epoch 125:     64 / 64 loss=5.303, ppl=39.49, wps=6229.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.774, train_wall=495, gb_free=6.1, wall=43093
2022-01-28 19:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:02:19 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.647 | ppl 801.69 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.009
2022-01-28 19:02:19 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 19:02:19 | INFO | train | epoch 125 | loss 5.29 | ppl 39.12 | wps 6054.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.769 | train_wall 317 | gb_free 6.1 | wall 43120
KL Stats: Epoch 125 Divergences: Uniform: 3.631506224923064 Unigram: 2.860263746154081
2022-01-28 19:02:19 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 19:02:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:08:04 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.611 | ppl 782.1 | wps 8159.7 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.009
2022-01-28 19:08:04 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 19:08:04 | INFO | train | epoch 126 | loss 5.28 | ppl 38.86 | wps 6057 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.77 | train_wall 317 | gb_free 6.1 | wall 43465
KL Stats: Epoch 126 Divergences: Uniform: 3.638006690338988 Unigram: 2.8657396624895717
2022-01-28 19:08:04 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 19:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:11:04 | INFO | train_inner | epoch 127:     36 / 64 loss=5.269, ppl=38.56, wps=5925.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.785, train_wall=496, gb_free=6.1, wall=43644
2022-01-28 19:13:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:13:49 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.596 | ppl 774.05 | wps 8127 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.009
2022-01-28 19:13:49 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 19:13:49 | INFO | train | epoch 127 | loss 5.271 | ppl 38.62 | wps 6051.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.791 | train_wall 317 | gb_free 6.1 | wall 43810
KL Stats: Epoch 127 Divergences: Uniform: 3.633232295857077 Unigram: 2.869430785172789
2022-01-28 19:13:49 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 19:13:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:19:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:19:34 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.666 | ppl 812.16 | wps 8118.4 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.009
2022-01-28 19:19:34 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 19:19:34 | INFO | train | epoch 128 | loss 5.259 | ppl 38.3 | wps 6055.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.785 | train_wall 317 | gb_free 6.1 | wall 44155
KL Stats: Epoch 128 Divergences: Uniform: 3.638485621517095 Unigram: 2.8734306324020364
2022-01-28 19:19:34 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 19:19:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:20:14 | INFO | train_inner | epoch 129:      8 / 64 loss=5.267, ppl=38.5, wps=5924.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.782, train_wall=495, gb_free=6.1, wall=44195
2022-01-28 19:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:25:19 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.604 | ppl 778.38 | wps 8134.8 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.009
2022-01-28 19:25:19 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 19:25:19 | INFO | train | epoch 129 | loss 5.252 | ppl 38.12 | wps 6054.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.796 | train_wall 317 | gb_free 6.1 | wall 44500
KL Stats: Epoch 129 Divergences: Uniform: 3.640786589594137 Unigram: 2.8839078837376513
2022-01-28 19:25:19 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 19:25:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:28:59 | INFO | train_inner | epoch 130:     44 / 64 loss=5.241, ppl=37.82, wps=6226.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.79, train_wall=497, gb_free=6.1, wall=44719
2022-01-28 19:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:31:04 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.686 | ppl 823.84 | wps 8144.4 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.009
2022-01-28 19:31:04 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 19:31:04 | INFO | train | epoch 130 | loss 5.242 | ppl 37.84 | wps 6049.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.793 | train_wall 318 | gb_free 6.1 | wall 44845
KL Stats: Epoch 130 Divergences: Uniform: 3.637636764495044 Unigram: 2.885804488719224
2022-01-28 19:31:04 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 19:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:36:49 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.639 | ppl 797.18 | wps 8128.3 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.009
2022-01-28 19:36:49 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 19:36:49 | INFO | train | epoch 131 | loss 5.233 | ppl 37.61 | wps 6057.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.805 | train_wall 317 | gb_free 6.1 | wall 45190
KL Stats: Epoch 131 Divergences: Uniform: 3.6399579457690647 Unigram: 2.89303993829557
2022-01-28 19:36:49 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 19:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:38:09 | INFO | train_inner | epoch 132:     16 / 64 loss=5.236, ppl=37.68, wps=5926.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.808, train_wall=495, gb_free=6.1, wall=45270
2022-01-28 19:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:42:34 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.642 | ppl 798.7 | wps 8147.6 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.009
2022-01-28 19:42:34 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 19:42:34 | INFO | train | epoch 132 | loss 5.223 | ppl 37.35 | wps 6054.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.827 | train_wall 317 | gb_free 6.1 | wall 45535
KL Stats: Epoch 132 Divergences: Uniform: 3.6466273704847123 Unigram: 2.8975914451634677
2022-01-28 19:42:34 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 19:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:46:54 | INFO | train_inner | epoch 133:     52 / 64 loss=5.218, ppl=37.21, wps=6226.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.819, train_wall=497, gb_free=6.1, wall=45794
2022-01-28 19:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:48:19 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.663 | ppl 810.81 | wps 8064.6 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.009
2022-01-28 19:48:19 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 19:48:19 | INFO | train | epoch 133 | loss 5.213 | ppl 37.1 | wps 6045.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.811 | train_wall 318 | gb_free 6.1 | wall 45880
KL Stats: Epoch 133 Divergences: Uniform: 3.6518192060566244 Unigram: 2.9050686239825847
2022-01-28 19:48:19 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 19:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:54:03 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.706 | ppl 835.38 | wps 8154.1 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.009
2022-01-28 19:54:03 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 19:54:03 | INFO | train | epoch 134 | loss 5.204 | ppl 36.87 | wps 6071.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.832 | train_wall 316 | gb_free 6.1 | wall 46224
KL Stats: Epoch 134 Divergences: Uniform: 3.6480791519019427 Unigram: 2.9101508745234965
2022-01-28 19:54:03 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 19:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:56:03 | INFO | train_inner | epoch 135:     24 / 64 loss=5.204, ppl=36.87, wps=5934.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.829, train_wall=494, gb_free=6.1, wall=46344
2022-01-28 19:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:59:48 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.715 | ppl 840.22 | wps 8153.6 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.009
2022-01-28 19:59:48 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 19:59:48 | INFO | train | epoch 135 | loss 5.198 | ppl 36.7 | wps 6067 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.836 | train_wall 317 | gb_free 6.1 | wall 46568
KL Stats: Epoch 135 Divergences: Uniform: 3.6492440492060254 Unigram: 2.9117848818110614
2022-01-28 19:59:48 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 19:59:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:04:46 | INFO | train_inner | epoch 136:     60 / 64 loss=5.197, ppl=36.68, wps=6245.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.836, train_wall=495, gb_free=6.1, wall=46867
2022-01-28 20:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:05:32 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.705 | ppl 834.47 | wps 8174.3 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.009
2022-01-28 20:05:32 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 20:05:32 | INFO | train | epoch 136 | loss 5.187 | ppl 36.43 | wps 6070 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.835 | train_wall 316 | gb_free 6.1 | wall 46912
KL Stats: Epoch 136 Divergences: Uniform: 3.65010239461026 Unigram: 2.915059778778171
2022-01-28 20:05:32 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 20:05:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:11:16 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.706 | ppl 835.17 | wps 8139.4 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.009
2022-01-28 20:11:16 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 20:11:16 | INFO | train | epoch 137 | loss 5.179 | ppl 36.23 | wps 6071.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.836 | train_wall 316 | gb_free 6.1 | wall 47256
KL Stats: Epoch 137 Divergences: Uniform: 3.6543129217450057 Unigram: 2.925772658465335
2022-01-28 20:11:16 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 20:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:13:55 | INFO | train_inner | epoch 138:     32 / 64 loss=5.171, ppl=36.03, wps=5940.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.831, train_wall=494, gb_free=6.1, wall=47416
2022-01-28 20:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:17:00 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.749 | ppl 860.67 | wps 8156.7 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.009
2022-01-28 20:17:00 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 20:17:00 | INFO | train | epoch 138 | loss 5.17 | ppl 36 | wps 6069.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.839 | train_wall 316 | gb_free 6.1 | wall 47601
KL Stats: Epoch 138 Divergences: Uniform: 3.652531548600381 Unigram: 2.926376465316143
2022-01-28 20:17:00 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 20:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:22:47 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.704 | ppl 834.01 | wps 8019.4 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.009
2022-01-28 20:22:47 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 20:22:47 | INFO | train | epoch 139 | loss 5.16 | ppl 35.75 | wps 6024.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.853 | train_wall 319 | gb_free 6.1 | wall 47947
KL Stats: Epoch 139 Divergences: Uniform: 3.6550008673907066 Unigram: 2.9365365360241387
2022-01-28 20:22:47 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 20:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:23:07 | INFO | train_inner | epoch 140:      4 / 64 loss=5.167, ppl=35.93, wps=5909.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.853, train_wall=496, gb_free=6.1, wall=47967
2022-01-28 20:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:28:33 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.689 | ppl 825.44 | wps 8143.5 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.009
2022-01-28 20:28:33 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 20:28:33 | INFO | train | epoch 140 | loss 5.154 | ppl 35.59 | wps 6032.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.849 | train_wall 319 | gb_free 6.1 | wall 48294
KL Stats: Epoch 140 Divergences: Uniform: 3.652970990656325 Unigram: 2.938250049717205
2022-01-28 20:28:33 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 20:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:31:53 | INFO | train_inner | epoch 141:     40 / 64 loss=5.146, ppl=35.41, wps=6210.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.851, train_wall=498, gb_free=6.1, wall=48494
2022-01-28 20:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:34:19 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.734 | ppl 851.78 | wps 8106.5 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.009
2022-01-28 20:34:19 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 20:34:19 | INFO | train | epoch 141 | loss 5.145 | ppl 35.39 | wps 6041.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.847 | train_wall 318 | gb_free 6.1 | wall 48639
KL Stats: Epoch 141 Divergences: Uniform: 3.658104648073673 Unigram: 2.9436591811249957
2022-01-28 20:34:19 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 20:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:40:04 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.71 | ppl 837.5 | wps 8131.9 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.009
2022-01-28 20:40:04 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 20:40:04 | INFO | train | epoch 142 | loss 5.137 | ppl 35.18 | wps 6053.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.889 | train_wall 317 | gb_free 6.1 | wall 48984
KL Stats: Epoch 142 Divergences: Uniform: 3.6627726715721134 Unigram: 2.947411313461189
2022-01-28 20:40:04 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 20:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:41:04 | INFO | train_inner | epoch 143:     12 / 64 loss=5.138, ppl=35.22, wps=5918.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.879, train_wall=496, gb_free=6.1, wall=49044
2022-01-28 20:45:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:45:49 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.697 | ppl 830.25 | wps 8129.2 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.009
2022-01-28 20:45:49 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 20:45:49 | INFO | train | epoch 143 | loss 5.129 | ppl 35 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.862 | train_wall 318 | gb_free 6.1 | wall 49330
KL Stats: Epoch 143 Divergences: Uniform: 3.6667158812138965 Unigram: 2.952382946353037
2022-01-28 20:45:49 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 20:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:49:49 | INFO | train_inner | epoch 144:     48 / 64 loss=5.126, ppl=34.92, wps=6221, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.865, train_wall=497, gb_free=6.1, wall=49570
2022-01-28 20:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:51:35 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.765 | ppl 870.35 | wps 8116.7 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.009
2022-01-28 20:51:35 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 20:51:35 | INFO | train | epoch 144 | loss 5.124 | ppl 34.86 | wps 6044.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.886 | train_wall 318 | gb_free 6.1 | wall 49675
KL Stats: Epoch 144 Divergences: Uniform: 3.6558527630062247 Unigram: 2.952256314446542
2022-01-28 20:51:35 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 20:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:57:21 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.707 | ppl 835.66 | wps 8082.8 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.009
2022-01-28 20:57:21 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 20:57:21 | INFO | train | epoch 145 | loss 5.116 | ppl 34.68 | wps 6033.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.894 | train_wall 318 | gb_free 6.1 | wall 50022
KL Stats: Epoch 145 Divergences: Uniform: 3.6682677521898226 Unigram: 2.959221578734322
2022-01-28 20:57:21 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 20:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:59:01 | INFO | train_inner | epoch 146:     20 / 64 loss=5.112, ppl=34.59, wps=5905.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.898, train_wall=497, gb_free=6.1, wall=50122
2022-01-28 21:02:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:03:07 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.735 | ppl 851.98 | wps 8104.7 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.009
2022-01-28 21:03:07 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 21:03:07 | INFO | train | epoch 146 | loss 5.104 | ppl 34.39 | wps 6025.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.892 | train_wall 319 | gb_free 6.1 | wall 50368
KL Stats: Epoch 146 Divergences: Uniform: 3.66695579295152 Unigram: 2.9641040903803404
2022-01-28 21:03:07 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 21:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:07:48 | INFO | train_inner | epoch 147:     56 / 64 loss=5.106, ppl=34.43, wps=6195.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.893, train_wall=499, gb_free=6.1, wall=50649
2022-01-28 21:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:08:54 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.738 | ppl 854.23 | wps 8133.9 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.009
2022-01-28 21:08:54 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 21:08:54 | INFO | train | epoch 147 | loss 5.097 | ppl 34.23 | wps 6026.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.896 | train_wall 319 | gb_free 6.1 | wall 50715
KL Stats: Epoch 147 Divergences: Uniform: 3.6698805798015433 Unigram: 2.9713860863957784
2022-01-28 21:08:54 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 21:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:14:41 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.717 | ppl 841.53 | wps 8082.6 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.009
2022-01-28 21:14:41 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 21:14:41 | INFO | train | epoch 148 | loss 5.091 | ppl 34.09 | wps 6018 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.927 | train_wall 319 | gb_free 6.1 | wall 51062
KL Stats: Epoch 148 Divergences: Uniform: 3.6647216851479523 Unigram: 2.9742977461495297
2022-01-28 21:14:41 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 21:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:17:02 | INFO | train_inner | epoch 149:     28 / 64 loss=5.087, ppl=33.99, wps=5892.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.916, train_wall=498, gb_free=6.1, wall=51202
2022-01-28 21:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:20:27 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.717 | ppl 841.81 | wps 8104.3 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.009
2022-01-28 21:20:27 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 21:20:27 | INFO | train | epoch 149 | loss 5.086 | ppl 33.98 | wps 6030.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.927 | train_wall 319 | gb_free 6.1 | wall 51408
KL Stats: Epoch 149 Divergences: Uniform: 3.677355895188455 Unigram: 2.980064830619179
2022-01-28 21:20:27 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 21:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:25:46 | INFO | train_inner | epoch 150:     64 / 64 loss=5.087, ppl=34, wps=6213.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.916, train_wall=496, gb_free=6.1, wall=51727
2022-01-28 21:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:26:13 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.766 | ppl 870.93 | wps 8110.4 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.009
2022-01-28 21:26:13 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 21:26:13 | INFO | train | epoch 150 | loss 5.077 | ppl 33.76 | wps 6040.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.896 | train_wall 318 | gb_free 6.1 | wall 51754
KL Stats: Epoch 150 Divergences: Uniform: 3.671291739370259 Unigram: 2.9803245663378326
2022-01-28 21:26:13 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 21:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:31:59 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.792 | ppl 886.41 | wps 8086.8 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.009
2022-01-28 21:31:59 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 21:31:59 | INFO | train | epoch 151 | loss 5.07 | ppl 33.59 | wps 6040.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.925 | train_wall 318 | gb_free 6.1 | wall 52100
KL Stats: Epoch 151 Divergences: Uniform: 3.666666473116919 Unigram: 2.9867107796235133
2022-01-28 21:31:59 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 21:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:34:59 | INFO | train_inner | epoch 152:     36 / 64 loss=5.058, ppl=33.32, wps=5911.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.934, train_wall=497, gb_free=6.1, wall=52280
2022-01-28 21:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:37:45 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.768 | ppl 871.64 | wps 8103.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.009
2022-01-28 21:37:45 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 21:37:45 | INFO | train | epoch 152 | loss 5.064 | ppl 33.44 | wps 6041.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.94 | train_wall 318 | gb_free 6.1 | wall 52445
KL Stats: Epoch 152 Divergences: Uniform: 3.675082438901113 Unigram: 2.9894952257633
2022-01-28 21:37:45 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 21:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:43:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:43:31 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.808 | ppl 896.37 | wps 8095.2 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.009
2022-01-28 21:43:31 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 21:43:31 | INFO | train | epoch 153 | loss 5.055 | ppl 33.24 | wps 6038.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.913 | train_wall 318 | gb_free 6.1 | wall 52791
KL Stats: Epoch 153 Divergences: Uniform: 3.6801620811237212 Unigram: 2.995284402523896
2022-01-28 21:43:31 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 21:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:44:11 | INFO | train_inner | epoch 154:      8 / 64 loss=5.063, ppl=33.42, wps=5908, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.915, train_wall=496, gb_free=6.1, wall=52832
2022-01-28 21:48:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:49:16 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.844 | ppl 919.35 | wps 8130.9 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.009
2022-01-28 21:49:16 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 21:49:16 | INFO | train | epoch 154 | loss 5.05 | ppl 33.14 | wps 6037.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.944 | train_wall 318 | gb_free 6.1 | wall 53137
KL Stats: Epoch 154 Divergences: Uniform: 3.686172065023735 Unigram: 2.9968064896964095
2022-01-28 21:49:17 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 21:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:52:57 | INFO | train_inner | epoch 155:     44 / 64 loss=5.042, ppl=32.94, wps=6216.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.944, train_wall=498, gb_free=6.1, wall=53357
2022-01-28 21:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:55:02 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.769 | ppl 872.64 | wps 8104 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.009
2022-01-28 21:55:02 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 21:55:02 | INFO | train | epoch 155 | loss 5.043 | ppl 32.97 | wps 6040.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.94 | train_wall 318 | gb_free 6.1 | wall 53483
KL Stats: Epoch 155 Divergences: Uniform: 3.6761195482913513 Unigram: 3.008150766121246
2022-01-28 21:55:02 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 21:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:00:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:00:48 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.781 | ppl 879.77 | wps 8095.6 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.009
2022-01-28 22:00:48 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 22:00:48 | INFO | train | epoch 156 | loss 5.037 | ppl 32.84 | wps 6044.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 0.974 | train_wall 318 | gb_free 6.1 | wall 53829
KL Stats: Epoch 156 Divergences: Uniform: 3.6823237693632542 Unigram: 3.0045392518566283
2022-01-28 22:00:48 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 22:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:02:08 | INFO | train_inner | epoch 157:     16 / 64 loss=5.043, ppl=32.96, wps=5915, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=0.959, train_wall=496, gb_free=6.1, wall=53909
2022-01-28 22:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:06:33 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.774 | ppl 875.59 | wps 8117.1 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.009
2022-01-28 22:06:33 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 22:06:33 | INFO | train | epoch 157 | loss 5.027 | ppl 32.61 | wps 6046 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 0.929 | train_wall 318 | gb_free 6.1 | wall 54174
KL Stats: Epoch 157 Divergences: Uniform: 3.6805278324731656 Unigram: 3.0121319127834165
2022-01-28 22:06:33 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 22:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:10:53 | INFO | train_inner | epoch 158:     52 / 64 loss=5.022, ppl=32.49, wps=6220.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.944, train_wall=497, gb_free=6.1, wall=54434
2022-01-28 22:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:12:19 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.829 | ppl 909.48 | wps 8097.9 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.009
2022-01-28 22:12:19 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 22:12:19 | INFO | train | epoch 158 | loss 5.024 | ppl 32.54 | wps 6042.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.955 | train_wall 318 | gb_free 6.1 | wall 54520
KL Stats: Epoch 158 Divergences: Uniform: 3.6796940160337366 Unigram: 3.0149860412768668
2022-01-28 22:12:19 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 22:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:18:05 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 9.844 | ppl 919.16 | wps 8106.3 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.009
2022-01-28 22:18:05 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 22:18:05 | INFO | train | epoch 159 | loss 5.017 | ppl 32.38 | wps 6042.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 0.974 | train_wall 318 | gb_free 6.1 | wall 54865
KL Stats: Epoch 159 Divergences: Uniform: 3.676641606035838 Unigram: 3.019719273896943
2022-01-28 22:18:05 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 22:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:20:05 | INFO | train_inner | epoch 160:     24 / 64 loss=5.016, ppl=32.36, wps=5911.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=0.968, train_wall=496, gb_free=6.1, wall=54985
2022-01-28 22:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:23:50 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.804 | ppl 893.99 | wps 8126.3 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.009
2022-01-28 22:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 22:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint160.pt
2022-01-28 22:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint160.pt
2022-01-28 22:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 9.804) (writing took 4.1556924469769 seconds)
2022-01-28 22:23:55 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 22:23:55 | INFO | train | epoch 160 | loss 5.012 | ppl 32.26 | wps 5967.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 0.97 | train_wall 318 | gb_free 6.1 | wall 55215
KL Stats: Epoch 160 Divergences: Uniform: 3.682219453456928 Unigram: 3.0244746631481783
2022-01-28 22:23:55 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 22:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:28:55 | INFO | train_inner | epoch 161:     60 / 64 loss=5.012, ppl=32.27, wps=6164.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=0.969, train_wall=498, gb_free=6.1, wall=55516
2022-01-28 22:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:29:40 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.799 | ppl 891.02 | wps 8117.7 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.009
2022-01-28 22:29:40 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 22:29:40 | INFO | train | epoch 161 | loss 5.004 | ppl 32.09 | wps 6039 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 0.966 | train_wall 318 | gb_free 6.1 | wall 55561
KL Stats: Epoch 161 Divergences: Uniform: 3.68539387313091 Unigram: 3.028154842281045
2022-01-28 22:29:40 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 22:29:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:35:26 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.796 | ppl 888.95 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.009
2022-01-28 22:35:26 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 22:35:26 | INFO | train | epoch 162 | loss 4.999 | ppl 31.98 | wps 6045.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 0.984 | train_wall 318 | gb_free 6.1 | wall 55907
KL Stats: Epoch 162 Divergences: Uniform: 3.68840867648694 Unigram: 3.030267064644398
2022-01-28 22:35:26 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 22:35:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:38:06 | INFO | train_inner | epoch 163:     32 / 64 loss=4.986, ppl=31.7, wps=5915.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=0.99, train_wall=496, gb_free=6.1, wall=56067
2022-01-28 22:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:41:11 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.851 | ppl 923.66 | wps 8116.4 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.009
2022-01-28 22:41:11 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 22:41:11 | INFO | train | epoch 163 | loss 4.994 | ppl 31.86 | wps 6045.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 0.987 | train_wall 318 | gb_free 6.1 | wall 56252
KL Stats: Epoch 163 Divergences: Uniform: 3.6867606583776023 Unigram: 3.0370482003694104
2022-01-28 22:41:11 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 22:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:46:57 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.783 | ppl 880.87 | wps 8124.6 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.009
2022-01-28 22:46:57 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 22:46:57 | INFO | train | epoch 164 | loss 4.987 | ppl 31.71 | wps 6046.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.014 | train_wall 318 | gb_free 6.1 | wall 56598
KL Stats: Epoch 164 Divergences: Uniform: 3.681256752357026 Unigram: 3.0380510769576112
2022-01-28 22:46:57 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 22:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:47:17 | INFO | train_inner | epoch 165:      4 / 64 loss=5.001, ppl=32.02, wps=5914.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.002, train_wall=496, gb_free=6.1, wall=56618
2022-01-28 22:52:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:52:43 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.85 | ppl 922.9 | wps 8108 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.009
2022-01-28 22:52:43 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 22:52:43 | INFO | train | epoch 165 | loss 4.98 | ppl 31.55 | wps 6041.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 0.977 | train_wall 318 | gb_free 6.1 | wall 56943
KL Stats: Epoch 165 Divergences: Uniform: 3.6918122520776944 Unigram: 3.0441433861686344
2022-01-28 22:52:43 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 22:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:56:03 | INFO | train_inner | epoch 166:     40 / 64 loss=4.973, ppl=31.42, wps=6217.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=0.998, train_wall=497, gb_free=6.1, wall=57143
2022-01-28 22:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:58:29 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.768 | ppl 871.87 | wps 8089.1 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.009
2022-01-28 22:58:29 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 22:58:29 | INFO | train | epoch 166 | loss 4.976 | ppl 31.47 | wps 6038.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.028 | train_wall 318 | gb_free 6.1 | wall 57289
KL Stats: Epoch 166 Divergences: Uniform: 3.687299452831202 Unigram: 3.0452084972019255
2022-01-28 22:58:29 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 22:58:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:04:15 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.81 | ppl 897.5 | wps 8114.1 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.009
2022-01-28 23:04:15 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-28 23:04:15 | INFO | train | epoch 167 | loss 4.967 | ppl 31.27 | wps 6035.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 0.995 | train_wall 318 | gb_free 6.1 | wall 57635
KL Stats: Epoch 167 Divergences: Uniform: 3.6860490606141205 Unigram: 3.048711921075583
2022-01-28 23:04:15 | INFO | fairseq.trainer | begin training epoch 168
2022-01-28 23:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:05:15 | INFO | train_inner | epoch 168:     12 / 64 loss=4.97, ppl=31.33, wps=5905.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.001, train_wall=497, gb_free=6.1, wall=57695
2022-01-28 23:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:10:00 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.823 | ppl 905.61 | wps 8116.2 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.009
2022-01-28 23:10:00 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-28 23:10:00 | INFO | train | epoch 168 | loss 4.964 | ppl 31.21 | wps 6043 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.022 | train_wall 318 | gb_free 6.1 | wall 57981
KL Stats: Epoch 168 Divergences: Uniform: 3.6918146973231925 Unigram: 3.049855128109217
2022-01-28 23:10:00 | INFO | fairseq.trainer | begin training epoch 169
2022-01-28 23:10:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:14:00 | INFO | train_inner | epoch 169:     48 / 64 loss=4.962, ppl=31.17, wps=6218.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.031, train_wall=497, gb_free=6.1, wall=58221
2022-01-28 23:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:15:46 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.867 | ppl 933.63 | wps 8117.4 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.009
2022-01-28 23:15:46 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-28 23:15:46 | INFO | train | epoch 169 | loss 4.956 | ppl 31.04 | wps 6041.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.032 | train_wall 318 | gb_free 6.1 | wall 58327
KL Stats: Epoch 169 Divergences: Uniform: 3.69353079234977 Unigram: 3.056548699240551
2022-01-28 23:15:46 | INFO | fairseq.trainer | begin training epoch 170
2022-01-28 23:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:21:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:21:32 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.838 | ppl 915.33 | wps 8139.1 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.009
2022-01-28 23:21:32 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-28 23:21:32 | INFO | train | epoch 170 | loss 4.952 | ppl 30.96 | wps 6042.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.044 | train_wall 318 | gb_free 6.1 | wall 58672
KL Stats: Epoch 170 Divergences: Uniform: 3.6904632362640015 Unigram: 3.0575357264431116
2022-01-28 23:21:32 | INFO | fairseq.trainer | begin training epoch 171
2022-01-28 23:21:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:23:12 | INFO | train_inner | epoch 171:     20 / 64 loss=4.947, ppl=30.85, wps=5912, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.057, train_wall=496, gb_free=6.1, wall=58772
2022-01-28 23:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:27:17 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.833 | ppl 912.18 | wps 8113 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.009
2022-01-28 23:27:17 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-28 23:27:17 | INFO | train | epoch 171 | loss 4.948 | ppl 30.86 | wps 6042.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.075 | train_wall 318 | gb_free 6.1 | wall 59018
KL Stats: Epoch 171 Divergences: Uniform: 3.6906360157637716 Unigram: 3.0608273413887144
2022-01-28 23:27:17 | INFO | fairseq.trainer | begin training epoch 172
2022-01-28 23:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:31:58 | INFO | train_inner | epoch 172:     56 / 64 loss=4.95, ppl=30.9, wps=6214.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.052, train_wall=498, gb_free=6.1, wall=59298
2022-01-28 23:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:33:03 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.866 | ppl 933.46 | wps 8096.1 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.009
2022-01-28 23:33:03 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-28 23:33:03 | INFO | train | epoch 172 | loss 4.941 | ppl 30.72 | wps 6034.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.053 | train_wall 318 | gb_free 6.1 | wall 59364
KL Stats: Epoch 172 Divergences: Uniform: 3.6939352419023983 Unigram: 3.0660393448654832
2022-01-28 23:33:03 | INFO | fairseq.trainer | begin training epoch 173
2022-01-28 23:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:38:50 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.812 | ppl 898.85 | wps 8106.6 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.009
2022-01-28 23:38:50 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-28 23:38:50 | INFO | train | epoch 173 | loss 4.935 | ppl 30.6 | wps 6033.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.083 | train_wall 318 | gb_free 6.1 | wall 59710
KL Stats: Epoch 173 Divergences: Uniform: 3.696299109731946 Unigram: 3.0669490866697053
2022-01-28 23:38:50 | INFO | fairseq.trainer | begin training epoch 174
2022-01-28 23:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:41:10 | INFO | train_inner | epoch 174:     28 / 64 loss=4.93, ppl=30.48, wps=5905.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.07, train_wall=497, gb_free=6.1, wall=59850
2022-01-28 23:44:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:44:35 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.903 | ppl 957.7 | wps 8116.3 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.009
2022-01-28 23:44:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-28 23:44:35 | INFO | train | epoch 174 | loss 4.93 | ppl 30.48 | wps 6042.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.054 | train_wall 318 | gb_free 6.1 | wall 60056
KL Stats: Epoch 174 Divergences: Uniform: 3.692955771817454 Unigram: 3.0723202522733293
2022-01-28 23:44:35 | INFO | fairseq.trainer | begin training epoch 175
2022-01-28 23:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:49:54 | INFO | train_inner | epoch 175:     64 / 64 loss=4.932, ppl=30.53, wps=6215.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.067, train_wall=496, gb_free=6.1, wall=60375
2022-01-28 23:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:50:21 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.842 | ppl 917.7 | wps 8125.2 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.009
2022-01-28 23:50:21 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-28 23:50:21 | INFO | train | epoch 175 | loss 4.923 | ppl 30.33 | wps 6040.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.065 | train_wall 318 | gb_free 6.1 | wall 60402
KL Stats: Epoch 175 Divergences: Uniform: 3.699994783003596 Unigram: 3.076490356929557
2022-01-28 23:50:21 | INFO | fairseq.trainer | begin training epoch 176
2022-01-28 23:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:55:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:56:07 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.844 | ppl 919.02 | wps 8108.4 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.009
2022-01-28 23:56:07 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-28 23:56:07 | INFO | train | epoch 176 | loss 4.92 | ppl 30.27 | wps 6035.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.081 | train_wall 318 | gb_free 6.1 | wall 60748
KL Stats: Epoch 176 Divergences: Uniform: 3.6990028380077784 Unigram: 3.078307791492752
2022-01-28 23:56:07 | INFO | fairseq.trainer | begin training epoch 177
2022-01-28 23:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:59:07 | INFO | train_inner | epoch 177:     36 / 64 loss=4.909, ppl=30.04, wps=5910.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.089, train_wall=498, gb_free=6.1, wall=60928
2022-01-29 00:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:01:53 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.823 | ppl 905.98 | wps 8106.9 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.009
2022-01-29 00:01:53 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-29 00:01:53 | INFO | train | epoch 177 | loss 4.916 | ppl 30.19 | wps 6038.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.099 | train_wall 318 | gb_free 6.1 | wall 61094
KL Stats: Epoch 177 Divergences: Uniform: 3.6975742512367273 Unigram: 3.079769308282384
2022-01-29 00:01:53 | INFO | fairseq.trainer | begin training epoch 178
2022-01-29 00:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:07:39 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.869 | ppl 935.4 | wps 8128.6 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.009
2022-01-29 00:07:39 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-29 00:07:39 | INFO | train | epoch 178 | loss 4.912 | ppl 30.1 | wps 6042.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.084 | train_wall 318 | gb_free 6.1 | wall 61439
KL Stats: Epoch 178 Divergences: Uniform: 3.704200741454225 Unigram: 3.0857642566792656
2022-01-29 00:07:39 | INFO | fairseq.trainer | begin training epoch 179
2022-01-29 00:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:08:19 | INFO | train_inner | epoch 179:      8 / 64 loss=4.919, ppl=30.25, wps=5910.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.089, train_wall=496, gb_free=6.1, wall=61479
2022-01-29 00:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:13:24 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.853 | ppl 925.06 | wps 8087.4 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.009
2022-01-29 00:13:24 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-29 00:13:24 | INFO | train | epoch 179 | loss 4.905 | ppl 29.97 | wps 6044.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.126 | train_wall 318 | gb_free 6.1 | wall 61785
KL Stats: Epoch 179 Divergences: Uniform: 3.706509803910812 Unigram: 3.087161754958639
2022-01-29 00:13:24 | INFO | fairseq.trainer | begin training epoch 180
2022-01-29 00:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:17:05 | INFO | train_inner | epoch 180:     44 / 64 loss=4.901, ppl=29.87, wps=6211.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.119, train_wall=498, gb_free=6.1, wall=62005
2022-01-29 00:18:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:19:10 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.816 | ppl 901.2 | wps 8136 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.009
2022-01-29 00:19:10 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-29 00:19:10 | INFO | train | epoch 180 | loss 4.9 | ppl 29.86 | wps 6031.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.104 | train_wall 319 | gb_free 6.1 | wall 62131
KL Stats: Epoch 180 Divergences: Uniform: 3.705578864123416 Unigram: 3.0929732812652047
2022-01-29 00:19:10 | INFO | fairseq.trainer | begin training epoch 181
2022-01-29 00:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:24:56 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.844 | ppl 919.32 | wps 8119.3 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.009
2022-01-29 00:24:56 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-29 00:24:56 | INFO | train | epoch 181 | loss 4.894 | ppl 29.73 | wps 6048.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.107 | train_wall 318 | gb_free 6.1 | wall 62476
KL Stats: Epoch 181 Divergences: Uniform: 3.7032642732765004 Unigram: 3.095802035270349
2022-01-29 00:24:56 | INFO | fairseq.trainer | begin training epoch 182
2022-01-29 00:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:26:16 | INFO | train_inner | epoch 182:     16 / 64 loss=4.894, ppl=29.73, wps=5916.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.103, train_wall=496, gb_free=6.1, wall=62556
2022-01-29 00:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:30:41 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.873 | ppl 938.03 | wps 8120.3 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.009
2022-01-29 00:30:41 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-29 00:30:41 | INFO | train | epoch 182 | loss 4.891 | ppl 29.67 | wps 6046.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.106 | train_wall 318 | gb_free 6.1 | wall 62822
KL Stats: Epoch 182 Divergences: Uniform: 3.704442675252306 Unigram: 3.0972182426884394
2022-01-29 00:30:41 | INFO | fairseq.trainer | begin training epoch 183
2022-01-29 00:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:35:01 | INFO | train_inner | epoch 183:     52 / 64 loss=4.89, ppl=29.65, wps=6224.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.141, train_wall=497, gb_free=6.1, wall=63081
2022-01-29 00:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:36:26 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.883 | ppl 943.92 | wps 8123.1 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.009
2022-01-29 00:36:26 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-29 00:36:26 | INFO | train | epoch 183 | loss 4.887 | ppl 29.58 | wps 6049.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.164 | train_wall 317 | gb_free 6.1 | wall 63167
KL Stats: Epoch 183 Divergences: Uniform: 3.703238027338129 Unigram: 3.099644393429881
2022-01-29 00:36:26 | INFO | fairseq.trainer | begin training epoch 184
2022-01-29 00:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:42:13 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.816 | ppl 901.16 | wps 8052.4 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.009
2022-01-29 00:42:13 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-29 00:42:13 | INFO | train | epoch 184 | loss 4.88 | ppl 29.45 | wps 6017.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.147 | train_wall 319 | gb_free 6.1 | wall 63514
KL Stats: Epoch 184 Divergences: Uniform: 3.7017624128462736 Unigram: 3.1013904557564604
2022-01-29 00:42:13 | INFO | fairseq.trainer | begin training epoch 185
2022-01-29 00:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:44:14 | INFO | train_inner | epoch 185:     24 / 64 loss=4.881, ppl=29.46, wps=5891.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.145, train_wall=498, gb_free=6.1, wall=63635
2022-01-29 00:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:48:00 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.89 | ppl 949.07 | wps 8134.8 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.009
2022-01-29 00:48:00 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 00:48:00 | INFO | train | epoch 185 | loss 4.875 | ppl 29.35 | wps 6023.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.148 | train_wall 319 | gb_free 6.1 | wall 63861
KL Stats: Epoch 185 Divergences: Uniform: 3.701363009132389 Unigram: 3.103535597344478
2022-01-29 00:48:00 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 00:48:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:53:02 | INFO | train_inner | epoch 186:     60 / 64 loss=4.876, ppl=29.37, wps=6191.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.154, train_wall=500, gb_free=6.1, wall=64163
2022-01-29 00:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:53:48 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.797 | ppl 889.7 | wps 8022.7 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.009
2022-01-29 00:53:48 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 00:53:48 | INFO | train | epoch 186 | loss 4.873 | ppl 29.3 | wps 6005.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.161 | train_wall 320 | gb_free 6.1 | wall 64209
KL Stats: Epoch 186 Divergences: Uniform: 3.7035721589658612 Unigram: 3.1073449895057053
2022-01-29 00:53:48 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 00:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:59:36 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.893 | ppl 950.68 | wps 8086.3 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.009
2022-01-29 00:59:36 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 00:59:36 | INFO | train | epoch 187 | loss 4.868 | ppl 29.2 | wps 6001.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.162 | train_wall 320 | gb_free 6.1 | wall 64557
KL Stats: Epoch 187 Divergences: Uniform: 3.698446346398094 Unigram: 3.1115734451249923
2022-01-29 00:59:36 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 00:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:02:16 | INFO | train_inner | epoch 188:     32 / 64 loss=4.862, ppl=29.07, wps=5878.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.163, train_wall=499, gb_free=6.1, wall=64717
2022-01-29 01:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:05:22 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.839 | ppl 915.75 | wps 8085.8 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.009
2022-01-29 01:05:22 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 01:05:22 | INFO | train | epoch 188 | loss 4.862 | ppl 29.08 | wps 6035.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.182 | train_wall 318 | gb_free 6.1 | wall 64903
KL Stats: Epoch 188 Divergences: Uniform: 3.704503821416585 Unigram: 3.1140189850219238
2022-01-29 01:05:22 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 01:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:11:08 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.866 | ppl 932.99 | wps 8113.5 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.009
2022-01-29 01:11:08 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 01:11:08 | INFO | train | epoch 189 | loss 4.858 | ppl 29 | wps 6039.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.211 | train_wall 318 | gb_free 6.1 | wall 65249
KL Stats: Epoch 189 Divergences: Uniform: 3.7120361155633974 Unigram: 3.1173764911165676
2022-01-29 01:11:08 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 01:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:11:28 | INFO | train_inner | epoch 190:      4 / 64 loss=4.864, ppl=29.12, wps=5911.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.207, train_wall=496, gb_free=6.1, wall=65269
2022-01-29 01:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:16:53 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.866 | ppl 933.09 | wps 8113.5 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.009
2022-01-29 01:16:53 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 01:16:53 | INFO | train | epoch 190 | loss 4.851 | ppl 28.86 | wps 6045.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.158 | train_wall 318 | gb_free 6.1 | wall 65594
KL Stats: Epoch 190 Divergences: Uniform: 3.7097855823811456 Unigram: 3.1202696340114766
2022-01-29 01:16:53 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 01:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:20:13 | INFO | train_inner | epoch 191:     40 / 64 loss=4.842, ppl=28.67, wps=6220, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.179, train_wall=497, gb_free=6.1, wall=65794
2022-01-29 01:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:22:39 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.894 | ppl 951.16 | wps 8106 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.009
2022-01-29 01:22:39 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 01:22:39 | INFO | train | epoch 191 | loss 4.85 | ppl 28.84 | wps 6045 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.209 | train_wall 318 | gb_free 6.1 | wall 65940
KL Stats: Epoch 191 Divergences: Uniform: 3.707490485665854 Unigram: 3.121324998772626
2022-01-29 01:22:39 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 01:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:28:24 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.864 | ppl 931.99 | wps 8127.9 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.009
2022-01-29 01:28:24 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 01:28:24 | INFO | train | epoch 192 | loss 4.845 | ppl 28.74 | wps 6047.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.199 | train_wall 318 | gb_free 6.1 | wall 66285
KL Stats: Epoch 192 Divergences: Uniform: 3.702183196240936 Unigram: 3.1186286841188067
2022-01-29 01:28:24 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 01:28:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:29:24 | INFO | train_inner | epoch 193:     12 / 64 loss=4.852, ppl=28.87, wps=5915.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.209, train_wall=496, gb_free=6.1, wall=66345
2022-01-29 01:33:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:34:10 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.85 | ppl 922.7 | wps 8109.5 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.009
2022-01-29 01:34:10 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 01:34:10 | INFO | train | epoch 193 | loss 4.841 | ppl 28.67 | wps 6037 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.23 | train_wall 318 | gb_free 6.1 | wall 66631
KL Stats: Epoch 193 Divergences: Uniform: 3.7114427114030386 Unigram: 3.128049825172238
2022-01-29 01:34:10 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 01:34:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:38:10 | INFO | train_inner | epoch 194:     48 / 64 loss=4.838, ppl=28.59, wps=6215.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.226, train_wall=498, gb_free=6.1, wall=66871
2022-01-29 01:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:39:56 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.864 | ppl 931.77 | wps 8096.7 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.009
2022-01-29 01:39:56 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 01:39:56 | INFO | train | epoch 194 | loss 4.836 | ppl 28.57 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.233 | train_wall 318 | gb_free 6.1 | wall 66977
KL Stats: Epoch 194 Divergences: Uniform: 3.704978866043802 Unigram: 3.1284492283570096
2022-01-29 01:39:56 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 01:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:45:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:45:41 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.868 | ppl 934.16 | wps 8094.5 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.009
2022-01-29 01:45:41 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 01:45:41 | INFO | train | epoch 195 | loss 4.834 | ppl 28.52 | wps 6046.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.259 | train_wall 318 | gb_free 6.1 | wall 67322
KL Stats: Epoch 195 Divergences: Uniform: 3.7061409482519942 Unigram: 3.1315820241471792
2022-01-29 01:45:41 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 01:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:47:22 | INFO | train_inner | epoch 196:     20 / 64 loss=4.832, ppl=28.48, wps=5911.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.251, train_wall=496, gb_free=6.1, wall=67422
2022-01-29 01:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:51:28 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.86 | ppl 929.35 | wps 8099.1 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.009
2022-01-29 01:51:28 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 01:51:28 | INFO | train | epoch 196 | loss 4.831 | ppl 28.46 | wps 6034.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.248 | train_wall 318 | gb_free 6.1 | wall 67668
KL Stats: Epoch 196 Divergences: Uniform: 3.702206689095529 Unigram: 3.1321892090707264
2022-01-29 01:51:28 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 01:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:56:07 | INFO | train_inner | epoch 197:     56 / 64 loss=4.83, ppl=28.44, wps=6214.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.279, train_wall=498, gb_free=6.1, wall=67948
2022-01-29 01:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:57:13 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.833 | ppl 911.84 | wps 8072.4 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.009
2022-01-29 01:57:13 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 01:57:13 | INFO | train | epoch 197 | loss 4.824 | ppl 28.33 | wps 6041.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.303 | train_wall 318 | gb_free 6.1 | wall 68014
KL Stats: Epoch 197 Divergences: Uniform: 3.7074781666318417 Unigram: 3.131846492151869
2022-01-29 01:57:13 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 01:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:02:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:02:59 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.897 | ppl 953.49 | wps 8121.3 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.009
2022-01-29 02:02:59 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 02:02:59 | INFO | train | epoch 198 | loss 4.821 | ppl 28.26 | wps 6049 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.279 | train_wall 317 | gb_free 6.1 | wall 68359
KL Stats: Epoch 198 Divergences: Uniform: 3.714961446448003 Unigram: 3.1410911482173076
2022-01-29 02:02:59 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 02:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:05:19 | INFO | train_inner | epoch 199:     28 / 64 loss=4.815, ppl=28.14, wps=5915.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.272, train_wall=496, gb_free=6.1, wall=68499
2022-01-29 02:08:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:08:45 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.896 | ppl 952.99 | wps 8100.3 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.009
2022-01-29 02:08:45 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 02:08:45 | INFO | train | epoch 199 | loss 4.815 | ppl 28.16 | wps 6031.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.26 | train_wall 318 | gb_free 6.1 | wall 68706
KL Stats: Epoch 199 Divergences: Uniform: 3.7089405701100113 Unigram: 3.141721309792239
2022-01-29 02:08:45 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 02:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:14:03 | INFO | train_inner | epoch 200:     64 / 64 loss=4.823, ppl=28.31, wps=6214.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.279, train_wall=496, gb_free=6.1, wall=69024
2022-01-29 02:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:14:30 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.912 | ppl 963.46 | wps 8106.4 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.009
2022-01-29 02:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 02:14:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint200.pt
2022-01-29 02:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint200.pt
2022-01-29 02:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.05_0.05_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 9.912) (writing took 4.200239337980747 seconds)
2022-01-29 02:14:34 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 02:14:34 | INFO | train | epoch 200 | loss 4.811 | ppl 28.07 | wps 5975.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.277 | train_wall 317 | gb_free 6.1 | wall 69055
KL Stats: Epoch 200 Divergences: Uniform: 3.709741987125957 Unigram: 3.1431409602582163
2022-01-29 02:14:34 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 02:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:20:22 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.903 | ppl 957.72 | wps 8066.9 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.009
2022-01-29 02:20:22 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 02:20:22 | INFO | train | epoch 201 | loss 4.809 | ppl 28.02 | wps 6010.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.292 | train_wall 319 | gb_free 6.1 | wall 69403
KL Stats: Epoch 201 Divergences: Uniform: 3.70799695974554 Unigram: 3.144039777877645
2022-01-29 02:20:22 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 02:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:23:22 | INFO | train_inner | epoch 202:     36 / 64 loss=4.796, ppl=27.77, wps=5848.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.309, train_wall=499, gb_free=6.1, wall=69583
2022-01-29 02:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:26:07 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.912 | ppl 963.52 | wps 8101.3 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.009
2022-01-29 02:26:07 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 02:26:07 | INFO | train | epoch 202 | loss 4.803 | ppl 27.91 | wps 6042.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.312 | train_wall 318 | gb_free 6.1 | wall 69748
KL Stats: Epoch 202 Divergences: Uniform: 3.7102162660200015 Unigram: 3.15027756252873
2022-01-29 02:26:07 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 02:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:31:54 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.891 | ppl 949.63 | wps 8124.5 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.009
2022-01-29 02:31:54 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-01-29 02:31:54 | INFO | train | epoch 203 | loss 4.799 | ppl 27.83 | wps 6030.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.296 | train_wall 319 | gb_free 6.1 | wall 70095
KL Stats: Epoch 203 Divergences: Uniform: 3.7045526720394943 Unigram: 3.1534486358767873
2022-01-29 02:31:54 | INFO | fairseq.trainer | begin training epoch 204
2022-01-29 02:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:32:34 | INFO | train_inner | epoch 204:      8 / 64 loss=4.807, ppl=27.99, wps=5904.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.299, train_wall=497, gb_free=6.1, wall=70135
2022-01-29 02:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:37:40 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.954 | ppl 991.82 | wps 8085.5 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.009
2022-01-29 02:37:40 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-01-29 02:37:40 | INFO | train | epoch 204 | loss 4.796 | ppl 27.78 | wps 6035.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.348 | train_wall 318 | gb_free 6.1 | wall 70441
KL Stats: Epoch 204 Divergences: Uniform: 3.7146917528117758 Unigram: 3.1563808967735945
2022-01-29 02:37:40 | INFO | fairseq.trainer | begin training epoch 205
2022-01-29 02:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:41:21 | INFO | train_inner | epoch 205:     44 / 64 loss=4.792, ppl=27.71, wps=6199.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.345, train_wall=499, gb_free=6.1, wall=70662
2022-01-29 02:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:43:27 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.92 | ppl 968.56 | wps 8107.7 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.009
2022-01-29 02:43:27 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-01-29 02:43:27 | INFO | train | epoch 205 | loss 4.793 | ppl 27.72 | wps 6016.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.35 | train_wall 319 | gb_free 6.1 | wall 70788
KL Stats: Epoch 205 Divergences: Uniform: 3.715192915755169 Unigram: 3.158911503424816
2022-01-29 02:43:27 | INFO | fairseq.trainer | begin training epoch 206
2022-01-29 02:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:48:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:49:13 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.921 | ppl 969.18 | wps 8083.7 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.009
2022-01-29 02:49:13 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-01-29 02:49:13 | INFO | train | epoch 206 | loss 4.789 | ppl 27.65 | wps 6035.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.31 | train_wall 318 | gb_free 6.1 | wall 71134
KL Stats: Epoch 206 Divergences: Uniform: 3.7085026236465124 Unigram: 3.159815151533761
2022-01-29 02:49:13 | INFO | fairseq.trainer | begin training epoch 207
2022-01-29 02:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:50:33 | INFO | train_inner | epoch 207:     16 / 64 loss=4.79, ppl=27.67, wps=5904.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.323, train_wall=497, gb_free=6.1, wall=71214
2022-01-29 02:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:54:59 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.953 | ppl 991.24 | wps 8115.7 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.009
2022-01-29 02:54:59 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-01-29 02:54:59 | INFO | train | epoch 207 | loss 4.786 | ppl 27.58 | wps 6032.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.349 | train_wall 318 | gb_free 6.1 | wall 71480
KL Stats: Epoch 207 Divergences: Uniform: 3.712485179338146 Unigram: 3.1624697402906694
2022-01-29 02:54:59 | INFO | fairseq.trainer | begin training epoch 208
2022-01-29 02:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:59:20 | INFO | train_inner | epoch 208:     52 / 64 loss=4.783, ppl=27.52, wps=6208.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.345, train_wall=498, gb_free=6.1, wall=71740
2022-01-29 03:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:00:45 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.943 | ppl 984.62 | wps 8105.2 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.009
2022-01-29 03:00:45 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-01-29 03:00:45 | INFO | train | epoch 208 | loss 4.78 | ppl 27.48 | wps 6034.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.346 | train_wall 318 | gb_free 6.1 | wall 71826
KL Stats: Epoch 208 Divergences: Uniform: 3.7107221236823666 Unigram: 3.1614041087154385
2022-01-29 03:00:45 | INFO | fairseq.trainer | begin training epoch 209
2022-01-29 03:00:45 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
