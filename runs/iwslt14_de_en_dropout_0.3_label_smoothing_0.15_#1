Sender: LSF System <lsfadmin@eu-g3-062>
Subject: Job 210580736: <iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:23:11 2022
Job was executed on host(s) <eu-g3-062>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:23:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:23:23 2022
Terminated at Wed Mar 23 10:33:41 2022
Results reported at Wed Mar 23 10:33:41 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.15 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4202.93 sec.
    Max Memory :                                 5468 MB
    Average Memory :                             4215.97 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14532.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4217 sec.
    Turnaround time :                            4230 sec.

The output (if any) follows:

2022-03-23 09:23:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.15, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.15, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:23:31 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:23:31 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:23:31 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:23:31 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:23:31 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:23:31 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:23:31 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:23:31 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:23:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:23:31 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:23:31 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:23:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:23:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:23:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:23:36 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:23:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:23:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:23:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:23:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:23:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:23:36 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:23:36 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:23:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:23:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:23:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:23:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:24:11 | INFO | train_inner | epoch 001:    104 / 157 loss=12.099, nll_loss=11.856, ppl=3707.35, wps=79593.8, ups=3.16, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.116, loss_scale=8, train_wall=34, gb_free=14, wall=35
2022-03-23 09:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:24:30 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:24:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:24:33 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:24:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,...
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:24:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 09:24:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:24:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:24:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:24:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:24:58 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:25:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:25:08 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:25:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.55 | nll_loss 10.007 | ppl 1029.32 | bleu 0.01 | wps 4350.7 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:25:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.7170232301577926 seconds)
2022-03-23 09:25:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:25:10 | INFO | train | epoch 001 | loss 11.689 | nll_loss 11.37 | ppl 2646.05 | wps 42239.8 | ups 1.68 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.487 | loss_scale 8 | train_wall 50 | gb_free 22.4 | wall 94
2022-03-23 09:25:10 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:25 | INFO | train_inner | epoch 002:     47 / 157 loss=10.686, nll_loss=10.182, ppl=1161.56, wps=34116.3, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.23, loss_scale=8, train_wall=30, gb_free=14.7, wall=109
2022-03-23 09:25:56 | INFO | train_inner | epoch 002:    147 / 157 loss=10.043, nll_loss=9.379, ppl=665.85, wps=80292.3, ups=3.19, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.336, loss_scale=8, train_wall=31, gb_free=14, wall=141
2022-03-23 09:25:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:03 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:26:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:26:06 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the.
2022-03-23 09:26:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the the.
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:26:15 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:21 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:26:26 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:26:32 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:47 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:47 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.736 | nll_loss 8.938 | ppl 490.55 | bleu 0.01 | wps 3648.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:26:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:26:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:26:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:26:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.8171305540017784 seconds)
2022-03-23 09:26:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:26:49 | INFO | train | epoch 002 | loss 10.154 | nll_loss 9.521 | ppl 734.5 | wps 39688.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.271 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 194
2022-03-23 09:26:50 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:26:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:18 | INFO | train_inner | epoch 003:     90 / 157 loss=9.767, nll_loss=9.006, ppl=513.99, wps=30251.6, ups=1.23, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.223, loss_scale=8, train_wall=30, gb_free=13.7, wall=222
2022-03-23 09:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the.
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the.
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:27:50 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the of the of the the of the of the of the of the of the of the of the of the of the of the of the.
2022-03-23 09:27:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:27:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, and it's's, and it's's, and it's's, and it's's's.
2022-03-23 09:27:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's's's that that's's's's that that that that that's's's's's's's's's that that's's's's's's.
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:05 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of the the the the the the the the the the
2022-03-23 09:28:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's, and it's, and it's, and it's's's's's's the the the the the the the the the, and the the the the, and the the the the the, and the the the the the, and the the the the, and the the the the, and the,
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:17 | INFO | fairseq.tasks.translation | example hypothesis: and and we, and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:28:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:27 | INFO | fairseq.tasks.translation | example hypothesis: and it's a a a a a a a a a a, and the a a a, and the a, and the a a a a a a a a a, and the a a a a a a a a, and the, and the a a a a a a a a a, and the, and the, and the the the the a a a a a a a a a a a a a a a a a a a, and the a a a a a a a a a a a a a a a a a, and the a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the, and the a a a a a a a a a a, and the a a a a a a a a a a a a a a, and the, and the, and the, and the a a a a a a a a a a a a a a a a a a a,
2022-03-23 09:28:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.506 | nll_loss 8.626 | ppl 395.18 | bleu 0.11 | wps 3643.1 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.11
2022-03-23 09:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:28:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.11) (writing took 1.8947122090030462 seconds)
2022-03-23 09:28:29 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:28:29 | INFO | train | epoch 003 | loss 9.693 | nll_loss 8.911 | ppl 481.27 | wps 39631.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.322 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 293
2022-03-23 09:28:29 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:28:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:40 | INFO | train_inner | epoch 004:     33 / 157 loss=9.561, nll_loss=8.745, ppl=428.99, wps=30941.4, ups=1.22, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.38, loss_scale=8, train_wall=31, gb_free=13.9, wall=304
2022-03-23 09:29:11 | INFO | train_inner | epoch 004:    133 / 157 loss=9.356, nll_loss=8.491, ppl=359.83, wps=80367.8, ups=3.18, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.454, loss_scale=8, train_wall=31, gb_free=12.6, wall=336
2022-03-23 09:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:22 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 09:29:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world of the world of the world.
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:30 | INFO | fairseq.tasks.translation | example hypothesis: now, you're the world of the world.
2022-03-23 09:29:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:35 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world, and it's a world, and it's a world.
2022-03-23 09:29:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not it's not not not not not not not not not not not not not not not it.
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world, and this is the world of the world, and the world of the world of the world of the world of the world of the world.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:29:51 | INFO | fairseq.tasks.translation | example hypothesis: but it's the world, but it's the world, but it's the world, but it's not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not to be be be be be
2022-03-23 09:29:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example hypothesis: and so we can can can can can can can see the world of the world of the world, and we have the world, and we have the world, and we have the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:04 | INFO | fairseq.tasks.translation | example hypothesis: it's a "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:30:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example hypothesis: so we have to be to be a a a to be a a a a to be the world of the world of the world, and it's the world of the world of the world of the world of the world, which is the world of the world of the world of the world, which is the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, which is the world of the world of the world, and we have to do we have to do we've've've've've've've've've've've've've've've've've've've've've've've've've've have to be be be be be be be be be be be be be be be be to be be be be be be be be be be be be be be be be be be be be to be be be be be be be be be be be be be be be be be be be be be be be be be be be
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.028 | nll_loss 8.032 | ppl 261.79 | bleu 0.94 | wps 3688.3 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.94
2022-03-23 09:30:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:30:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:30:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:30:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.94) (writing took 1.866166204912588 seconds)
2022-03-23 09:30:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:30:08 | INFO | train | epoch 004 | loss 9.362 | nll_loss 8.5 | ppl 361.99 | wps 39698.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.423 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 393
2022-03-23 09:30:09 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:33 | INFO | train_inner | epoch 005:     76 / 157 loss=9.135, nll_loss=8.218, ppl=297.86, wps=30203.2, ups=1.23, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.593, loss_scale=8, train_wall=30, gb_free=13.4, wall=417
2022-03-23 09:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 09:31:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the world.
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:09 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to have to be two.
2022-03-23 09:31:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:31:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're going to do that we're going to do it.
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world, and the world in the world.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:23 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to have to have to be the world, but they're going to have to be the world, but they're going to be the world.
2022-03-23 09:31:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:28 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to see the world of the world, and we're going to make the world of the world of the world, and we're going to make the world.
2022-03-23 09:31:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" this is, "" this is, "" "" "this is," that we've've've've've've've've've've've have to have to have to say, "" "" "" "" "" this is, "that," "" "" "" "this is," that we've've've've've've've've've've've've've've've've've've've've've've've've have to have to have to say, "" "" "" "" "" "" "" "" "" "" "" "" "" that, "" "that," "" "that,", "that," that, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example hypothesis: so, we've have to have a lot of the world, and we've've have to have the world of the world, which is the world, which is the world, which is the world, which is the world, which is the world, which is that we have to be the world, which is the world, which is the world, which is that we have to be the world, which is the world, which is the world, which is that we have to have to have to be the world, which is the world, which is that we have to have to have to be the world, which is the world, and we have to have to have to have to be the world, which is that we have to have to be the world, which is the world, which is the world, which is the world, which is the world, which is the world, and the world, which is the world, and we have to have to have to have to have to have to have to have to have to have to have to have
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.663 | nll_loss 7.577 | ppl 190.9 | bleu 1.8 | wps 4659.3 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.8
2022-03-23 09:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.8) (writing took 1.8937939889729023 seconds)
2022-03-23 09:31:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:31:39 | INFO | train | epoch 005 | loss 8.975 | nll_loss 8.018 | ppl 259.14 | wps 43683.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.476 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 483
2022-03-23 09:31:39 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:45 | INFO | train_inner | epoch 006:     19 / 157 loss=8.864, nll_loss=7.878, ppl=235.3, wps=35055.1, ups=1.38, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.464, loss_scale=8, train_wall=31, gb_free=14.6, wall=489
2022-03-23 09:32:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:32:17 | INFO | train_inner | epoch 006:    120 / 157 loss=8.697, nll_loss=7.664, ppl=202.83, wps=79725.9, ups=3.16, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=1.437, loss_scale=4, train_wall=31, gb_free=14.1, wall=521
2022-03-23 09:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of this is here.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:32:41 | INFO | fairseq.tasks.translation | example hypothesis: these are two two of our new new new new new new new new new lot of our new new new new new new new new new new new new new new new new new new
2022-03-23 09:32:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of course.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do that we're going to do it's going to do that we're going to do that we're going to do it's going to do that we're going to do it's not not not going
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:32:56 | INFO | fairseq.tasks.translation | example hypothesis: and and in the people, in the people, in the people, and people are in the world, and people, in the world, and people for the people, and people for the people are in the world, and people in the people in the world, and people in the world.
2022-03-23 09:32:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not going to get a lot of these things, but they're not not not not, but they're going to be a lot of the same way.
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:07 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see that we can see, and then we can see that we can see, and then we can see that we can see, and then we can see that we can see the brain.
2022-03-23 09:33:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "this is," it, "you know," this is, "you know," you know, "this is," it's a good, "it's going to say," this is, "" "it's a good," you know, "you know," you know, "it's a lot of this is," "it's a good," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "" ""
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:17 | INFO | fairseq.tasks.translation | example hypothesis: if you know, it's a lot of fact, it's a lot of fact, it's a lot of the world, it's a lot of the world, it's a lot of the world, it's a lot of the world, and it's a lot of the world, and it's a lot of the world, it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and we can't know that we can be a lot of the world, and it's a lot of the world, and it's going to be a lot of the world, and it's going to be a lot of the world, it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's going to be a lot of the world, and it's going to do that we can have to be, and we're going to do that we can be a lot of the world, and it's going to
2022-03-23 09:33:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:17 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.41 | nll_loss 7.237 | ppl 150.86 | bleu 1.77 | wps 3668.1 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.8
2022-03-23 09:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 6 @ 937 updates, score 1.77) (writing took 0.8067201049998403 seconds)
2022-03-23 09:33:18 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:33:18 | INFO | train | epoch 006 | loss 8.686 | nll_loss 7.65 | ppl 200.91 | wps 39615.7 | ups 1.58 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 1.491 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 582
2022-03-23 09:33:18 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:38 | INFO | train_inner | epoch 007:     63 / 157 loss=8.504, nll_loss=7.424, ppl=171.75, wps=31057.6, ups=1.23, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.232, loss_scale=4, train_wall=30, gb_free=14.9, wall=602
2022-03-23 09:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:11 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go on this.
2022-03-23 09:34:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the most idea of the most most of the most of the most of the most.
2022-03-23 09:34:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:19 | INFO | fairseq.tasks.translation | example hypothesis: so these are going to be able to be new new new new new new new york.
2022-03-23 09:34:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's going to be a lot, and you're going to see, and you're going to be a lot.
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example hypothesis: it's it's just just just just just just to be, and we're going to do that we're going to do it, and we're going to do that we're going to do that we're going to do it.
2022-03-23 09:34:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:34 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the world, in the world, and it's the people in the people in the world, and the world, and it's the world, and the world, and it's the most people in the people in the people in the world.
2022-03-23 09:34:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:34:39 | INFO | fairseq.tasks.translation | example hypothesis: well, some of course, you're going to see, but they're going to be a lot of the same way, but they're going to go to be a lot of them, but they're going to be able to be a lot of them, but they're going to be able to be a lot of the same way, but they're going
2022-03-23 09:34:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, and we're going to see the world, and we can see the world, and we can see that we're going to see the world, and we're going to see the world, and we're going to see the world, and we can see that we can see that we can see the world, and we're going to see the world, and we're going to see the world, and
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example hypothesis: well, if you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "well," you're going to say, "you're going to say," you're going to say, "
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:55 | INFO | fairseq.tasks.translation | example hypothesis: and so, if we're going to get a lot of the world, and we're going to see that we're going to be a lot of the world, and we're going to see the world, and we're going to be a lot of the world, and we're going to go to see the world, and we're going to see the world, and we're going to see that we're going to go to see that we're going to see the world, and we're going to see the world, and we're going to be a lot of the world, and we're going to go to see that we're going to see that we're going to see that we're going to go to see that we're going to see that we're going to see the world, and then we're going to be a lot of the world, and we're going to see that we're going to go to see that we're going to go to be able to see that we're going to go to see that we're going to go to
2022-03-23 09:34:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.136 | nll_loss 6.877 | ppl 117.54 | bleu 2.25 | wps 3669.4 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.25
2022-03-23 09:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:34:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.25) (writing took 1.8319349749945104 seconds)
2022-03-23 09:34:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:34:57 | INFO | train | epoch 007 | loss 8.39 | nll_loss 7.283 | ppl 155.79 | wps 39652 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.189 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 682
2022-03-23 09:34:58 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:34:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:00 | INFO | train_inner | epoch 008:      6 / 157 loss=8.327, nll_loss=7.205, ppl=147.53, wps=30544.2, ups=1.22, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.229, loss_scale=4, train_wall=30, gb_free=14.4, wall=684
2022-03-23 09:35:31 | INFO | train_inner | epoch 008:    106 / 157 loss=8.133, nll_loss=6.962, ppl=124.69, wps=81233.4, ups=3.22, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.312, loss_scale=4, train_wall=31, gb_free=14.7, wall=715
2022-03-23 09:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:51 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the middle of the earth.
2022-03-23 09:35:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:35:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most most of the most most most most most most of the most most most most most of the most most most most most of
2022-03-23 09:35:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example, there's an example, and there's a lot of example, where it's going to be going to be going to be where you're going to see where where where
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're not going to do what we're going to do is that we're going to do, and what we're going to do is what we're going to do is that's going to
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people like people in the most people in the most people in the most people in the most people, for the most people, for the most people, for the most people, for the people, for the most people, and the most people, the most people who are
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example hypothesis: are some of some of some of some of some of some of the things, but if you're going to go to the same same same same way, but if you're going to see it, but it's not not the same, but if you're going to see the same, but it, but it's the same way, but it's not
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the brain, if we can see the brain, we can see that we can see the brain, we can see the brain, the brain, and then we can see that we can see the brain can see the brain can see the brain, the brain can see the brain, we can see the brain, the brain, we can see the brain, the brain, we can see the brain, the brain can see the brain,
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:37 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the first one: it's going to say, "well," you know, "you know," you know, "you know," you know, "you know," it's a lot of the first time, "you know," you know, "you're going to say," well, "well," you know, "you know," you know, "well," you know, "well," you know, "well," you know, "you know," well, "well," you know, "you know," you know, "it's going to say," well, "you know," you know, "it's going to say," well, "you know," you know, "you know," you know, "you know," you know, "you know,"
2022-03-23 09:36:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're going to be a lot of the world, if you're going to see the world, if you're going to see the world, if you're going to see the world, when we're going to be a lot of the world, if you're going to see the world, and then we're going to see the world that we're going to be a lot of the world, if you're going to get a lot of the world, when we're going to see the world, and then we're going to be a lot of the world, and then we're going to be a lot of the world, when we're going to see the world, if you're going to see the world, when we're going to be a lot of the world, when we're going to see the world, when we're going to see the world, when we're going to see the world, and then we're going to be a lot of the world, when we're going to see the world, when we're going to
2022-03-23 09:36:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:40 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.932 | nll_loss 6.625 | ppl 98.69 | bleu 2.86 | wps 3356.5 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.86
2022-03-23 09:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:36:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:36:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.86) (writing took 1.8525777279864997 seconds)
2022-03-23 09:36:41 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:36:41 | INFO | train | epoch 008 | loss 8.158 | nll_loss 6.992 | ppl 127.32 | wps 37915.7 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.248 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 786
2022-03-23 09:36:42 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:57 | INFO | train_inner | epoch 009:     49 / 157 loss=8.065, nll_loss=6.876, ppl=117.47, wps=29565.3, ups=1.15, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.18, loss_scale=4, train_wall=31, gb_free=14.9, wall=802
2022-03-23 09:37:28 | INFO | train_inner | epoch 009:    149 / 157 loss=7.942, nll_loss=6.72, ppl=105.43, wps=80242.7, ups=3.23, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.228, loss_scale=4, train_wall=31, gb_free=14.3, wall=833
2022-03-23 09:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:35 | INFO | fairseq.tasks.translation | example hypothesis: we had these pppon the top of the top.
2022-03-23 09:37:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the middle of the most most most most most of the most most most most most most most most.
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new new new new new york.
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's example, there's a great place, where you're going to go and where it's going to be where it's going to be where it's going to be where it's going
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do a few few few of his life, and what's going to do is what's going to do.
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like people like people, for the people, for the people, and the most people, and the most people who are a lot of people in the most people in the most people, and the world.
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of the water, but if you're going to go, but it's the same way, if you don't have to go out, and if you're going to see it, it's going to go out, but it's the same time, and it's the same time, it's going to go out,
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see the brain, we can use the brain, and we can get a lot of the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain, and we can use the brain
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the other people, and it's going to say, "you know," and then you know, "you know," well, "you know," you know, "you know," you know, "you know," well, "well," well, "well," well, "well," you know, "well," well, "you know," well, "well," well, "well," you know, "you know," you know, "well," well, "well," well, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:20 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, it's still still still still more than the same time, and if we're going to get a lot of the world that we're going to do that we're going to have a lot of the world, and if we're going to do that we're going to have a new world, we're going to do that we're going to have to be able to do that we're going to do that we're going to have to be able to do that we're going to do that we're going to have a lot of the world that we're going to have a little bit of the world, and if we're going to have a new new new new world that we're going to do that we're going to do that we're going to be able to have to be able to do that we're going to be able to be able to do that we're going to do that we're going to have to be able to be able to have to be able to be able to be able to be able to be able to do
2022-03-23 09:38:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:20 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.614 | nll_loss 6.212 | ppl 74.15 | bleu 4.62 | wps 3625.2 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.62
2022-03-23 09:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.62) (writing took 1.8425809990148991 seconds)
2022-03-23 09:38:22 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:38:22 | INFO | train | epoch 009 | loss 7.935 | nll_loss 6.713 | ppl 104.89 | wps 39313.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.23 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 886
2022-03-23 09:38:22 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:51 | INFO | train_inner | epoch 010:     92 / 157 loss=7.724, nll_loss=6.451, ppl=87.48, wps=30216.3, ups=1.2, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.052, loss_scale=4, train_wall=31, gb_free=14.3, wall=916
2022-03-23 09:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most. most of you know, most of most of the most most most most most.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new york.
2022-03-23 09:39:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese.
2022-03-23 09:39:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to do a few few few of his head, and what's going to do.
2022-03-23 09:39:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamay of people who have been working for the number of the number of people, and that's a few years.
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these are some of the water, but if you don't need to use the energy.
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information, we can use this.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:52 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of one of the other thing, and it's interesting for me, and then it's going to show you that if we have to say, "well," well, "well," well, "well," well, "well," well, if we've got to tell you know that if you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well, if you know," well, "well," well, if we have to do you know that there's the first first for you know, "well," well, "well," well, if you know, "well," well, "well, if we have to do you know,"
2022-03-23 09:39:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still still still a few years, and when we have a little bit of the world, and if we have a little bit of the system that we had to have a little bit of the system, and then we had a little bit of the system that we had to have a little bit of the system that we had to have a little bit of the system that we had a little bit of the system that we had to have a little bit of the system that we had to have a little bit of the system that we have a little bit that we had to have a little bit of the system that we had a little bit of the system that we had to have a little bit of the system that we had to have a little bit of the system that we have a little bit of the system that we had a little bit of the system, if we had to have a little bit of the system, and then have a little bit of the system, if we had a little bit of the system, if we had a little bit
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:54 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.348 | nll_loss 5.875 | ppl 58.7 | bleu 7.25 | wps 4188.3 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.25
2022-03-23 09:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:39:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:39:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.25) (writing took 1.8025224949233234 seconds)
2022-03-23 09:39:56 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:39:56 | INFO | train | epoch 010 | loss 7.647 | nll_loss 6.355 | ppl 81.85 | wps 41848.6 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.091 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 981
2022-03-23 09:39:57 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:08 | INFO | train_inner | epoch 011:     35 / 157 loss=7.571, nll_loss=6.26, ppl=76.66, wps=32574.3, ups=1.31, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.175, loss_scale=4, train_wall=30, gb_free=13.4, wall=992
2022-03-23 09:40:39 | INFO | train_inner | epoch 011:    135 / 157 loss=7.369, nll_loss=6.009, ppl=64.41, wps=81308.7, ups=3.18, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.156, loss_scale=4, train_wall=31, gb_free=13.3, wall=1024
2022-03-23 09:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppin the center.
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:40:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the maha, most of most of most of most of you know here.
2022-03-23 09:40:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:40:58 | INFO | fairseq.tasks.translation | example hypothesis: so these are new new new new new new new new new new technologies that are going to be able.
2022-03-23 09:40:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an chinese chinese chinese, where they're going to go with it.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure that we're not just just just a few few of his head, and what's going on.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamase people like the number of animals, the number of animals, and that's a number of reviviiiiiiiiiiiiiity.
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some kind of mats, but if they don't need the energy, if they don't need the energy, and the energy, the energy, the energy is so the energy.
2022-03-23 09:41:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:18 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that we can use this structure, we can take a structure of the structure, and we can use the structure of the structure of the structure, and the structure that are all the structure of the structure.
2022-03-23 09:41:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:22 | INFO | fairseq.tasks.translation | example hypothesis: second, one of the reasons, and it's interesting for me that i'm going to say, "well," you know, "well," you know, "you know," well, "well," you know, "you know," you know, "well," you know, "you know," well, "you know," you know, "you know," we're going to say, "well," well, "well," well, "well," you know, "well," well, "well," you know, "well," you know, "well," well, "well," you know, "you know," well, "you know," you know, "you know," you know, "you know," well, "you know," you know, "you know,"
2022-03-23 09:41:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and a lot of work that we had to create a little bit of the world that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:25 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.108 | nll_loss 5.566 | ppl 47.37 | bleu 10.26 | wps 4750.3 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.26
2022-03-23 09:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:41:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.26) (writing took 1.8299372519832104 seconds)
2022-03-23 09:41:26 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:41:26 | INFO | train | epoch 011 | loss 7.418 | nll_loss 6.069 | ppl 67.15 | wps 43737.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.154 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1071
2022-03-23 09:41:27 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:51 | INFO | train_inner | epoch 012:     78 / 157 loss=7.258, nll_loss=5.87, ppl=58.5, wps=34575.2, ups=1.38, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.1, loss_scale=4, train_wall=31, gb_free=14, wall=1096
2022-03-23 09:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:20 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the clinics.
2022-03-23 09:42:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example hypothesis: that's the right line of ha, most of most of most of most of most.
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be a new way that will be two ways.
2022-03-23 09:42:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese food, where you're going to get up with it.
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:36 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just a couple of camera on his head on his head, and what's going on on.
2022-03-23 09:42:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of people like the responsibility for the number of animals, the number of animals, and the number of animals, and this is a very important way for the reviiiiiiiiiiibia.
2022-03-23 09:42:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some fiddddm in the lines, but if you don't need to use the energy, it doesn't need your energy, and you need your energy, and you need to need your energy.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we're going to start with a new structure, we can start to start with a very different structure of the structure of the structure, and the structure of the structure, and the information that's all the structure of the structure.
2022-03-23 09:42:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons, and it's interesting for me to make me here for women for me, "well," well, "well," if we've got to tell you that the first time, "and then we're going to say," you're going to say, "well," well, "you're going to tell you're going to tell you're going to tell you're going to tell you," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "we're going to tell you know," well, "you're going to tell you know," well, "well," well, "well," well, "well," well, "well
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the great part of the work that we had to do in our work on the world, if we had to create a huge way that we had to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to see that if
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.783 | nll_loss 5.133 | ppl 35.1 | bleu 11.93 | wps 4516.3 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.93
2022-03-23 09:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.93) (writing took 1.8652722828555852 seconds)
2022-03-23 09:42:58 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:42:58 | INFO | train | epoch 012 | loss 7.145 | nll_loss 5.73 | ppl 53.07 | wps 42981.8 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.111 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1163
2022-03-23 09:42:59 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:42:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:05 | INFO | train_inner | epoch 013:     21 / 157 loss=7.038, nll_loss=5.597, ppl=48.39, wps=33933.2, ups=1.35, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.187, loss_scale=4, train_wall=30, gb_free=13.9, wall=1170
2022-03-23 09:43:37 | INFO | train_inner | epoch 013:    121 / 157 loss=6.941, nll_loss=5.472, ppl=44.37, wps=80319.1, ups=3.18, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.071, loss_scale=4, train_wall=31, gb_free=13.6, wall=1201
2022-03-23 09:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppon in the clinic.
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:56 | INFO | fairseq.tasks.translation | example hypothesis: that's the car of doha, most of most of the most.
2022-03-23 09:43:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be a new congress that will be two new.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese food, where you're going to do with pppace.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrodes on his head, and what's going on on.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamase people like the responsibility for the number of animals, and this is a number of animals.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic line in the lines, but it doesn't want to move your energy, if you need your energy energy, and you need the energy.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that can be able to be able to be able to be able to start with a traditional form of the shape of the structure, and the shape of the structure, which is a whole structure of the structure.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting for me, and i'm going to be talking about women, "yeah," yeah, "well," you know, "the best time," and then we're going to say, "well," well, if you're going to have a lot of you're going to say, "you're going to have a lot of you're working with you're working with you're going to have a lot of you're going to have a lot of this time."
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the fact that the mother has been part of the work, and we've had to solve a huge problem that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:25 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.63 | nll_loss 4.902 | ppl 29.9 | bleu 13.38 | wps 4955.7 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.38
2022-03-23 09:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:44:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.38) (writing took 1.858855788828805 seconds)
2022-03-23 09:44:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:44:27 | INFO | train | epoch 013 | loss 6.917 | nll_loss 5.443 | ppl 43.51 | wps 44596.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.088 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1251
2022-03-23 09:44:27 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:48 | INFO | train_inner | epoch 014:     64 / 157 loss=6.792, nll_loss=5.287, ppl=39.03, wps=35363.7, ups=1.42, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.063, loss_scale=4, train_wall=31, gb_free=14, wall=1272
2022-03-23 09:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example hypothesis: we made this ppink in the clinic.
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the superline of the doha, the most most of the most knows here.
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks of the two new ways that are going to be able to be able.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where they're going to eat with the legs, and they're going to be able.
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on the electroelectrodes and understand what all the thoughts are in the mind.
2022-03-23 09:45:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamaes like the responsibility of the responsibility, the number of animals grew up, and this has become become become a convivital.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic of the lines in the lines, but it doesn't have to move to the energy, and they need to move.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional traditional view of the shape of the information, and the whole structure of the information.
2022-03-23 09:45:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedwomen, "well, when we said," and then we've been talking to you. "
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's a need to be the mother, and the invention of the great design that we had to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 09:45:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:52 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.554 | nll_loss 4.791 | ppl 27.69 | bleu 15.28 | wps 5145.5 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.28
2022-03-23 09:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:45:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.28) (writing took 1.8773599660489708 seconds)
2022-03-23 09:45:54 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:45:54 | INFO | train | epoch 014 | loss 6.682 | nll_loss 5.148 | ppl 35.46 | wps 45289 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.052 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1339
2022-03-23 09:45:54 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:57 | INFO | train_inner | epoch 015:      7 / 157 loss=6.594, nll_loss=5.038, ppl=32.86, wps=36755.6, ups=1.44, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.992, loss_scale=4, train_wall=31, gb_free=13.9, wall=1341
2022-03-23 09:46:28 | INFO | train_inner | epoch 015:    107 / 157 loss=6.458, nll_loss=4.867, ppl=29.19, wps=80141.6, ups=3.19, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.02, loss_scale=4, train_wall=31, gb_free=13.9, wall=1373
2022-03-23 09:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:48 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinic clinic.
2022-03-23 09:46:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know here.
2022-03-23 09:46:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that will create two new covers.
2022-03-23 09:46:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where the legs are happy with and ppace.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrodes on his head and understand what all his thoughts are on the mind.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamacy, the responsibility of the responsibility grew up, and this is a number of animals that has become a priiiiiiiiibia.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic magic lines in the lines, but in the way, if you don't want to move, if you don't need your energy energy, you need your energy, and you need to move out there.
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start with a big face of the face of the information, and we can start looking at the shape of the structure of the information, and the structure of the information.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to make me here for tedwomen -- that's the best time, "oh, when someone said," oh, "the best thing that we're going to say," if we're going to support you're working with you're going to have a long time. "
2022-03-23 09:47:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention of the invention, and one part of our work on the airplane, we have to solve a problem that we had to solve a unique problem, and that if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to use the most effective, if you're able to use the most effective, if you're able to use the most effective, if you're going to see that it, it's the most effective, if you're going to use the most effective, the most effective, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:25 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.166 | nll_loss 4.308 | ppl 19.8 | bleu 16.93 | wps 4483.6 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.93
2022-03-23 09:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:47:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.93) (writing took 1.8794323350302875 seconds)
2022-03-23 09:47:26 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:47:26 | INFO | train | epoch 015 | loss 6.48 | nll_loss 4.892 | ppl 29.7 | wps 42800.9 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.993 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1431
2022-03-23 09:47:27 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:43 | INFO | train_inner | epoch 016:     50 / 157 loss=6.465, nll_loss=4.868, ppl=29.21, wps=34120.8, ups=1.34, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.957, loss_scale=4, train_wall=31, gb_free=14.3, wall=1447
2022-03-23 09:48:14 | INFO | train_inner | epoch 016:    150 / 157 loss=6.205, nll_loss=4.547, ppl=23.37, wps=79856.1, ups=3.24, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.897, loss_scale=4, train_wall=30, gb_free=14.5, wall=1478
2022-03-23 09:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 09:48:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 09:48:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are going to be done.
2022-03-23 09:48:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:35 | INFO | fairseq.tasks.translation | example hypothesis: it's not just a few electrodes on his head and understand what all its thoughts are on.
2022-03-23 09:48:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamic as people grew up to the wild, the number of animals, and this is a foundation for conservation.
2022-03-23 09:48:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic lines in the inside, but the sullant doesn't move if they don't need their energy, and they need their energy.
2022-03-23 09:48:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face that can start able to start able to start able to start able to start able to start with the very large form of the face, and that's the shape of the structure of the structure.
2022-03-23 09:48:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons we're going to measure it interesting and measure for me to be here for tedsters, "well, when we're working on the best time."
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and one part of the work that we have to solve in our airplane was a unique result that we had to solve a unique result that we had to solve.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:52 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.07 | nll_loss 4.187 | ppl 18.22 | bleu 15.56 | wps 5228.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.93
2022-03-23 09:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 15.56) (writing took 0.8438029950484633 seconds)
2022-03-23 09:48:52 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:48:52 | INFO | train | epoch 016 | loss 6.261 | nll_loss 4.616 | ppl 24.53 | wps 45863.4 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.939 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1517
2022-03-23 09:48:53 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:23 | INFO | train_inner | epoch 017:     93 / 157 loss=6.108, nll_loss=4.425, ppl=21.48, wps=36812.4, ups=1.45, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.93, loss_scale=4, train_wall=31, gb_free=14.9, wall=1547
2022-03-23 09:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:46 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic in the clinic.
2022-03-23 09:49:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks of the two new locks that are going to be transmitted.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food food, where happy legs are going to be a salt and salt.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to understand a few electroelectrodes on his head and understand what all its thoughts are on the top.
2022-03-23 09:50:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping like the human responsibility, the number of animals grew up, and this is a foundation for the namibia.
2022-03-23 09:50:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bols of magnetic lines, but the sulalalty doesn't move, if you need your energy, and so you need some of the sucks.
2022-03-23 09:50:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can begin to start with a traditional face of the face, and that's where we can start through the basic shape, and the information that's going through the structure of the structure, and the whole structure, the structure of the structure, which is going to be able to be able to make a reflect the structure, the structure, the reflection of this reflection of reflection
2022-03-23 09:50:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here for tedwomen, "well, it was the best thing that someone said," when you say, "the men," and then we're going to support you. "
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example hypothesis: luily, fortunately, the mother of the invention, and a big design of work that we have to solve in our airplane, that we had to solve a unique result of it, so we had to solve it.
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:23 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.94 | nll_loss 4.005 | ppl 16.06 | bleu 19.39 | wps 4417.7 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.39
2022-03-23 09:50:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:50:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.39) (writing took 1.8587897198740393 seconds)
2022-03-23 09:50:25 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:50:25 | INFO | train | epoch 017 | loss 6.093 | nll_loss 4.405 | ppl 21.19 | wps 42560.2 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.927 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1610
2022-03-23 09:50:26 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:37 | INFO | train_inner | epoch 018:     36 / 157 loss=6.035, nll_loss=4.331, ppl=20.12, wps=33780.9, ups=1.34, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.919, loss_scale=4, train_wall=30, gb_free=14.3, wall=1622
2022-03-23 09:51:08 | INFO | train_inner | epoch 018:    136 / 157 loss=5.909, nll_loss=4.176, ppl=18.07, wps=79456.9, ups=3.2, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.864, loss_scale=4, train_wall=31, gb_free=14.1, wall=1653
2022-03-23 09:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:19 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:51:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of them.
2022-03-23 09:51:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will create two new pigs.
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where happy legs are going to be filled with salz and fat.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to put some electrodes on his head and understand what all his thoughts are on the way.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, like the people who grew up for the life of the wild animals, and this is a foundation for the natural conservation.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic field in the inner lines, but the susulal superconductor may not move if they're moving, they don't need energy, they need their energy, and so that's how it's like that.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face that can start with the big face of the face and regret the real face, and then the information that makes the whole structure.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, for me, for example, is that, you know, when you're working on the piano, it was the best thing that the men said, "if you're working on a table," and then we have a long time. "
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother's invention of invention, and a big part of the design system that we're going to be able to solve in our plane, that we had to solve a result that we had to solve the unique way that we had to solve it -- it's all the way we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:53 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.676 | nll_loss 3.674 | ppl 12.77 | bleu 21.32 | wps 4741.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.32
2022-03-23 09:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:51:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.32) (writing took 1.8465707059949636 seconds)
2022-03-23 09:51:55 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:51:55 | INFO | train | epoch 018 | loss 5.914 | nll_loss 4.182 | ppl 18.15 | wps 43933.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.839 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1700
2022-03-23 09:51:56 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:51:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:21 | INFO | train_inner | epoch 019:     79 / 157 loss=5.804, nll_loss=4.046, ppl=16.51, wps=35429, ups=1.38, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.779, loss_scale=4, train_wall=31, gb_free=14, wall=1725
2022-03-23 09:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:49 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:52:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that will become the two new pigs.
2022-03-23 09:52:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being serving with salz and fefeeding.
2022-03-23 09:53:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head, and understand exactly what all of his thoughts are on the road.
2022-03-23 09:53:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people took responsibility for the wild, grew up the number of wild animals again, and this is a foundation for conservation in namibia.
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloods of magnetic field, but the sususulal aleggs may not move when they need energy and so forth.
2022-03-23 09:53:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, the big constructions of the face and remove it through the whole information that goes through the whole structure and fold the whole structure.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... "well, when the best shriny said to you," the men in a table, "and if we've been talking about a table revolution, and then we've been talking to you."
2022-03-23 09:53:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of the design work that we had to solve in our airplane was a result that we had to solve the unique problems on the ground -- all the mother of us had to solve a continent, and a big part of the invention of the invention of the industry, and a big part of the design system, which is that it allows us to get a refrifrigergergergergergergergergergergergergergergergergergergergergergergergerman to get a refufufufufufufufufufufufufufugeous, if you to get an airairairaircraft, or to get a restore, if you to get an aircraft, or, if we had to get an aircraft, or that we had to get a promotmotors to get a promotors to the engine, if we had to get an aircraft into a refrigergergergergergergergergergergerman
2022-03-23 09:53:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:23 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.626 | nll_loss 3.621 | ppl 12.3 | bleu 21.96 | wps 4766.2 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.96
2022-03-23 09:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:53:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.96) (writing took 1.8510289671830833 seconds)
2022-03-23 09:53:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:53:25 | INFO | train | epoch 019 | loss 5.74 | nll_loss 3.967 | ppl 15.64 | wps 44038.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.794 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1789
2022-03-23 09:53:25 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:32 | INFO | train_inner | epoch 020:     22 / 157 loss=5.669, nll_loss=3.879, ppl=14.72, wps=34683.7, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.785, loss_scale=4, train_wall=30, gb_free=14.7, wall=1797
2022-03-23 09:54:04 | INFO | train_inner | epoch 020:    122 / 157 loss=5.594, nll_loss=3.787, ppl=13.8, wps=81050.4, ups=3.13, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.703, loss_scale=4, train_wall=32, gb_free=13.6, wall=1829
2022-03-23 09:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:54:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:54:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create two new pigs.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are being served with salz and pink.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring some electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, how people took responsibility for the wild, grew up the number of wild animals again, and this is a foundation of conservation in namibia.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic fields in the inside the inner, but the susulant eggs may not be able to move if they need to move, because their energy needs energy, and so the suicide disorder.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional facial, the big constructions of the face and the basic shape of the information, and through the whole portion, which is the whole ports.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it interesting and measure it interesting, for me to be here at tedwomen, is that... yes, when someone was in the best, "when someone said to you," the men in a table, and when the revolution starts to give you the revolution, it starts to be here at me here at tedwomen in tedwomen, the fact that we've already started to be here at tedwomen's a long time, and then, we've been supported for the fact that we've been supported for the fact that we've been working with the fact, "well," well, then, "well, then," well, it's a silly, the fact that the fact, it's a silent for example, it's a long time, and then we've been working on the fact that the fact that, "
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention of invention, and a big part of design work that we're working on our airplane, and it was a result that we had to solve the unique problems that were connected to the ground -- everything from a continent -- everything from a continuous variation of the continent -- and a big part of the design system that allows us to be able to be able to be able to be able to be able to be able to be able to be able to see in the aircraft up with the aircraft, or the aircraft, if it is either the aircraft, or to see that it was a market, or the aircraft, if we had to see that we had to solve the aircraft up in the aircraft out the aircraft up the aircraft, or to be able to see the aircraft, or to be a market, or to be able to solve the aircraft, if it's an aircraft up to be able to be able to be able to be able to solve the aircraft,
2022-03-23 09:54:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:54 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.499 | nll_loss 3.459 | ppl 11 | bleu 24.46 | wps 4598.6 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 24.46
2022-03-23 09:54:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:54:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:54:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 24.46) (writing took 1.875105716055259 seconds)
2022-03-23 09:54:56 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:54:56 | INFO | train | epoch 020 | loss 5.587 | nll_loss 3.779 | ppl 13.73 | wps 43353.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.748 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1880
2022-03-23 09:54:56 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:54:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:17 | INFO | train_inner | epoch 021:     65 / 157 loss=5.497, nll_loss=3.669, ppl=12.72, wps=34178.1, ups=1.37, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.795, loss_scale=4, train_wall=30, gb_free=13.9, wall=1901
2022-03-23 09:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dining the two new pigments.
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and puppets.
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all the thoughts on the road.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for the wild, the number of animals grew back again, and this is a foundation for the natural protection in namibia.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloodle of magnetic fields in the inside, but the sulalous eggs don't like if they're moving, because their movements need to move around, and so the susulant disorder.
2022-03-23 09:56:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face that can start with the big constructions of the face and the basic form, and refuse it through that information, and fold it through the whole structure and fold all the structure.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make you on your table and you say, "well, you know, the truth is that..."
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:25 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're going to be able to use in the plane, and you know, if we had to solve a result of it, we had to solve the unique problems that were connected to the ground -- everything from a continuous variable system, and you can use it in the aircraft.
2022-03-23 09:56:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:25 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.383 | nll_loss 3.322 | ppl 10 | bleu 24.89 | wps 4736.5 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.89
2022-03-23 09:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.89) (writing took 1.9086958500556648 seconds)
2022-03-23 09:56:27 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:56:27 | INFO | train | epoch 021 | loss 5.479 | nll_loss 3.646 | ppl 12.51 | wps 43525.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.741 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1971
2022-03-23 09:56:27 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:30 | INFO | train_inner | epoch 022:      8 / 157 loss=5.488, nll_loss=3.656, ppl=12.61, wps=34059.1, ups=1.38, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.722, loss_scale=4, train_wall=31, gb_free=13.9, wall=1974
2022-03-23 09:57:01 | INFO | train_inner | epoch 022:    108 / 157 loss=5.423, nll_loss=3.578, ppl=11.94, wps=78726.7, ups=3.19, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.767, loss_scale=4, train_wall=31, gb_free=13.8, wall=2005
2022-03-23 09:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks of dining the two new pigs.
2022-03-23 09:57:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppet.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild animals, and this is a foundation for conservation in namibia.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble rocks are caught inside the inner, but the suprouter doesn't like if they're moving, because their movements don't need to disorder.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape of the structure of the face.
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured for me here at tedwomen is that... "well, you know, you know, you know, you know, you know, you know, you know, you know," and then you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, "and then, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,"
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work that we're going to be able to see in our airplane, or if we had to solve the unique problems that were connected to the ground so that we had to solve the ground, all of the things that were connected to a refrigerators, or to a refrigerators in the aircraft.
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:53 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.345 | nll_loss 3.269 | ppl 9.64 | bleu 24.58 | wps 5025.5 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.89
2022-03-23 09:57:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:57:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 09:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 24.58) (writing took 0.837440055096522 seconds)
2022-03-23 09:57:54 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:57:54 | INFO | train | epoch 022 | loss 5.391 | nll_loss 3.538 | ppl 11.61 | wps 45194.6 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.72 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2058
2022-03-23 09:57:54 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:11 | INFO | train_inner | epoch 023:     51 / 157 loss=5.325, nll_loss=3.455, ppl=10.96, wps=36680.1, ups=1.44, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.601, loss_scale=4, train_wall=31, gb_free=13.8, wall=2075
2022-03-23 09:58:42 | INFO | train_inner | epoch 023:    151 / 157 loss=5.219, nll_loss=3.331, ppl=10.06, wps=81586.5, ups=3.21, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.642, loss_scale=4, train_wall=31, gb_free=13.8, wall=2106
2022-03-23 09:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and ppet.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the makeen like people's responsibility for wild animals, the number of wild animals grew again. and this is a foundation for conservation protection in namibia.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field in the inner, but the superconductor doesn't like, if they move, because their energy needs energy, and so the suproule disorder.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:16 | INFO | fairseq.tasks.translation | example hypothesis: so, when we use the information that comes from this reflection, we can start with a traditional facial can start with the big constructions of the face and the basic shape of the face, and through the basic form of the basic restoration of the face of the face, and restoring it through the basic configuration of the real constructions of the face of the face of the face of the face of the face of the face
2022-03-23 09:59:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured to me here at tedwomen is that... well, when i was stripped, it was best, when someone said, "turn you to the men on a table and say," turn you to the men in your own table and say, "if we've already started to be silent for you."
2022-03-23 09:59:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work that we're in our aircraft at the stest, was a result that we had to solve the unique problems that have to solve the unique problems that were connected to the ground -- it's connected to surgery -- everything from a refrigerator and refrightened to a refugeous machine, and that we're either going to be able to be able to be able to be able to be able to be able to be able to use the prophetted by a restored by a restored by a restored by a refugeous, and refugeous, and restored by a mechanism machine, and restored by a mechanism, and restored by a restored by a restored by a refugee, and refugee, and restored by a refugee, and refugee, if we're either, if we can
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:24 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.297 | nll_loss 3.219 | ppl 9.31 | bleu 26.25 | wps 4509.8 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.25
2022-03-23 09:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 09:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 09:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.25) (writing took 1.8442879819776863 seconds)
2022-03-23 09:59:25 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:59:25 | INFO | train | epoch 023 | loss 5.251 | nll_loss 3.369 | ppl 10.33 | wps 43187.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.62 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2150
2022-03-23 09:59:26 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:55 | INFO | train_inner | epoch 024:     94 / 157 loss=5.193, nll_loss=3.298, ppl=9.84, wps=33809.1, ups=1.36, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.641, loss_scale=4, train_wall=31, gb_free=13.8, wall=2180
2022-03-23 10:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:00:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pit.
2022-03-23 10:00:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, grew up the number of wild animals, and that's a foundation for conservation in namibia.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught in the inside, but the superconductor doesn't like if they move, because their movements need energy, and so the superconductor disorders.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face, and the basic shape of information that pulls up all the ports.
2022-03-23 10:00:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured, to me here at tedwomen, is that... well, when the dinner was the best thing when someone said, "turn on the men on a table and tell you, '' 'the revolution starts to support you.' '' the truth is that we've already been supporting you for a long time."
2022-03-23 10:00:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variable system, and that allows us to be refrightened by a refrightening device, or to be able to see that it would be a refrightened by the aircraft, or to either if you can't see the propelled by the propelled by the resistance of the resistance to the resistance, or the resistance of an aircraft.
2022-03-23 10:00:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.145 | nll_loss 3.023 | ppl 8.13 | bleu 27.65 | wps 5017 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.65
2022-03-23 10:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.65) (writing took 1.8515464637894183 seconds)
2022-03-23 10:00:54 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:00:54 | INFO | train | epoch 024 | loss 5.167 | nll_loss 3.267 | ppl 9.63 | wps 44663.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.608 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2238
2022-03-23 10:00:54 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:06 | INFO | train_inner | epoch 025:     37 / 157 loss=5.092, nll_loss=3.177, ppl=9.04, wps=36081.9, ups=1.42, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.577, loss_scale=4, train_wall=30, gb_free=14, wall=2250
2022-03-23 10:01:37 | INFO | train_inner | epoch 025:    137 / 157 loss=5.159, nll_loss=3.256, ppl=9.56, wps=79950.7, ups=3.19, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.65, loss_scale=4, train_wall=31, gb_free=13.9, wall=2282
2022-03-23 10:01:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that make two new pigs.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and ppet.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildwildanimals grew again, and that's a basis for conservation in namibia.
2022-03-23 10:02:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor may not be if they're moving, because their movements need energy, and so the superconductor disorders.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional facial reflection, which is the great configurations of face and the basic shape, and restoring it through the bottom of the information that pulls the whole porter structure and put it into a fold.
2022-03-23 10:02:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, when the dinner was best summarized when someone said, "turn you to dtable and tell you," 'if the revolution starts supporting you. "' we support you."
2022-03-23 10:02:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuously varied to a continuously variable system and a refrigering system that allows us to make a refrightening, to a refrigering device, or to a refrigerator, if we're going to a refrightening device, if we're going to the fly, if we're going to a car car car car car car car car car car, if we're either going to the same thing that allows us to the same time you're going to the air, if you can see it's going to the same thing, if you're going to the same thing that allows us to the same thing that allows us to do, if you can't see the most unique problems that allows us to the same thing, if you to do it, if you to do it's going to
2022-03-23 10:02:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:21 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.148 | nll_loss 3.025 | ppl 8.14 | bleu 27 | wps 4815.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.65
2022-03-23 10:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:02:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.0) (writing took 0.8476904379203916 seconds)
2022-03-23 10:02:22 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:02:22 | INFO | train | epoch 025 | loss 5.114 | nll_loss 3.204 | ppl 9.21 | wps 44761.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.624 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2327
2022-03-23 10:02:22 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:48 | INFO | train_inner | epoch 026:     80 / 157 loss=5.012, nll_loss=3.08, ppl=8.46, wps=36156.7, ups=1.42, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.551, loss_scale=4, train_wall=31, gb_free=14, wall=2352
2022-03-23 10:03:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep pans in the clinic.
2022-03-23 10:03:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:03:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:03:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all the thoughts are on the track.
2022-03-23 10:03:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people of the wild surveys, the number of wild animals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines in the inside, but the superconductor may not like you move, because your movements are disorders.
2022-03-23 10:03:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face and restoring the basic form, and refuse it through the diean information that contains all the ports of the ports and all the fits.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that -- well, one of the reasons that we've already been working together when someone said, "turn you to the men on a table and tell them," if the revolution starts to support you, "the truth is that we've already started to support you in this long time is that we've been working with, we've been working with, we've been on," well, "well, we've been working with you know, we've been working with a grain of sandra rape, we've been working with, we've been working with," well, "well, we've been working on the fact, you know, we've been working on the fact, we've been working with, we've been working with, you know, we've been working with,"
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation of the design system and a refrigering system that allows us to use a refrigerator of the aircraft that allows us to use, if we're in the aircraft, or to use it to use the propellyield, or to use the propellism, or to use the trajectory of a mechanism, or to use the propellyieleld, or to use it's a mechanism, or to use the trajectory of a mechanism, it's going to see the propellism, it's a specific device that it's going to use the trajectory of the propellism, it's a trajectory of it's going to use it's going to use it's going to use it's a
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.033 | nll_loss 2.897 | ppl 7.45 | bleu 29.14 | wps 4652.5 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.14
2022-03-23 10:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:03:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.14) (writing took 1.840140555985272 seconds)
2022-03-23 10:03:52 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:03:52 | INFO | train | epoch 026 | loss 5.015 | nll_loss 3.084 | ppl 8.48 | wps 43728.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.578 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2417
2022-03-23 10:03:53 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:00 | INFO | train_inner | epoch 027:     23 / 157 loss=4.976, nll_loss=3.038, ppl=8.21, wps=34311, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.592, loss_scale=4, train_wall=31, gb_free=14.8, wall=2425
2022-03-23 10:04:32 | INFO | train_inner | epoch 027:    123 / 157 loss=4.969, nll_loss=3.029, ppl=8.16, wps=80347.3, ups=3.21, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.558, loss_scale=4, train_wall=31, gb_free=13.6, wall=2456
2022-03-23 10:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:46 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:04:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 10:04:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of two new pigs.
2022-03-23 10:04:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:04:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:05:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of people's responsibility for wildlife, the number of wildanimals grew back. and this is a foundation for conservation in namibia.
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductive disorder.
2022-03-23 10:05:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:13 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic shape, and restores it through the themes of information that fits all the pores structure and all the fits.
2022-03-23 10:05:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your desk and tell you," if the truth starts to support you for that long time. "
2022-03-23 10:05:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large piece of design work that we're at our plane at the stest toe, a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous refrigerator system that allows us to use a machine until you can see the propeller.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:18 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.983 | nll_loss 2.838 | ppl 7.15 | bleu 29.07 | wps 5128.3 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.14
2022-03-23 10:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:05:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:05:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.07) (writing took 0.8425975539721549 seconds)
2022-03-23 10:05:19 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:05:19 | INFO | train | epoch 027 | loss 4.943 | nll_loss 2.998 | ppl 7.99 | wps 45805.9 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.555 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2503
2022-03-23 10:05:19 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:40 | INFO | train_inner | epoch 028:     66 / 157 loss=4.892, nll_loss=2.936, ppl=7.65, wps=36509.2, ups=1.47, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.536, loss_scale=4, train_wall=30, gb_free=14.7, wall=2524
2022-03-23 10:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:06:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:06:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:20 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will write two new pigs.
2022-03-23 10:06:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:24 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:06:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:06:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for the wildlife, the number of wildlife grew back, and this is a basis for conservation in namibia.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like if they move, because their movements use their energy, and so the superconducting disorders.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that repeat the large constructures of the face and the basic form, and recontexts it through the theft of the whole porter structure and all the fold.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate, for me here at tedwomen, is that... well, in the striking dinner, it was best summarized when someone said, "turn you to your desk and tell you, if the revolution starts to support you." the truth is that we've already been supporting you for a long time. "
2022-03-23 10:06:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a large part of the design work that we are at our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable and a cooling system that allows us to use a refrigerator in the aircraft, until we can see the fly, or the air, if you can see the crashes, if you can see the crashes, until the air, if you can see the crashes, or the air, if you can see the crashes, if you can see the air, or the same, if you can see the air, if you can see the crashes, if you can see the crashes, if you can see the air, or the air, you can see the crashes, if you can see the crashes, if you can see the crashes, if you can see the earth
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:46 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.925 | nll_loss 2.772 | ppl 6.83 | bleu 30.34 | wps 4822.6 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.34
2022-03-23 10:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:06:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.34) (writing took 1.825861455872655 seconds)
2022-03-23 10:06:48 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:06:48 | INFO | train | epoch 028 | loss 4.883 | nll_loss 2.926 | ppl 7.6 | wps 44147.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.556 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2593
2022-03-23 10:06:48 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:51 | INFO | train_inner | epoch 029:      9 / 157 loss=4.905, nll_loss=2.953, ppl=7.75, wps=35209.7, ups=1.4, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.592, loss_scale=4, train_wall=30, gb_free=13.6, wall=2596
2022-03-23 10:07:23 | INFO | train_inner | epoch 029:    109 / 157 loss=4.813, nll_loss=2.843, ppl=7.17, wps=80086.6, ups=3.19, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.5, loss_scale=4, train_wall=31, gb_free=13.6, wall=2627
2022-03-23 10:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:07:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that generate two new pigs.
2022-03-23 10:07:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 10:07:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were taking responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:08:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like when they move, and so the superconducting disorder.
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can restore the large configurations of the face and the basic shape, and refuse it through this information that refers all the porn structure and all the fits.
2022-03-23 10:08:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized, "turn you to the men on a table and tell them," if the truth is that we've already supported you for this long term, we've already supported you for a long time, we've been supporting you, "and then we've been supporting you," well, "well, you've been supporting you," you've already been supporting you with a coke, "and then we've been supporting you've already been supported by"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need to be the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigerator system that allows us to use a refrigerator in the aircraft, that it allows us to use a refugee in the aircraft, or to use the propellism, or if you can see the propellism, or if you can see the propelled by a mechanism, or if you can see the propelled the propelled to a mechanism, that it, that it, that it's either, that it allows us to a mechanism, that it allows us to a refueling system that it allows us to a refueling system that it allows us to use it's a refueling system that allows us to build a refueling system that allows us to see
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:16 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.915 | nll_loss 2.757 | ppl 6.76 | bleu 30.19 | wps 4790.3 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.34
2022-03-23 10:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:08:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 29 @ 4548 updates, score 30.19) (writing took 0.900306971045211 seconds)
2022-03-23 10:08:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:08:17 | INFO | train | epoch 029 | loss 4.808 | nll_loss 2.836 | ppl 7.14 | wps 44588.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.514 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2681
2022-03-23 10:08:17 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:33 | INFO | train_inner | epoch 030:     52 / 157 loss=4.786, nll_loss=2.81, ppl=7.01, wps=35462.2, ups=1.41, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.507, loss_scale=4, train_wall=31, gb_free=13.9, wall=2698
2022-03-23 10:09:05 | INFO | train_inner | epoch 030:    152 / 157 loss=4.741, nll_loss=2.758, ppl=6.76, wps=81241.4, ups=3.21, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.477, loss_scale=4, train_wall=31, gb_free=14.7, wall=2729
2022-03-23 10:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that generate two new pigs.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of your thoughts are on the track.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people responsibility for wildlife, the number of wild animals grew back again, and that has become a basis for conservation in namibia.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic shape, and then by the one of the information that refers the entire por-structure and all the fits.
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, the best dinner was summarized when someone said, "turn to the men on your table and say," the truth is that we've been supporting you for this long time. "
2022-03-23 10:09:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a refrigeration to the refrigeration of a refrigeration machine to a specific vehicle, to the remoting to a specific vehicle, to a specific vehicle vehicle, to the remoteness to a specific vehicle, to a specific vehicle, to a particular vehicle, to the earth, or to the point that we could be able to the point that we have to the point that will be able to the remotely be able to the remotely be able to see if we use it, to the earth until one to the earth.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:44 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.845 | nll_loss 2.678 | ppl 6.4 | bleu 30.97 | wps 4849.9 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.97
2022-03-23 10:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.97) (writing took 1.8634496671147645 seconds)
2022-03-23 10:09:46 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:09:46 | INFO | train | epoch 030 | loss 4.75 | nll_loss 2.767 | ppl 6.81 | wps 44331.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.486 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2770
2022-03-23 10:09:46 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:16 | INFO | train_inner | epoch 031:     95 / 157 loss=4.725, nll_loss=2.738, ppl=6.67, wps=35611.6, ups=1.39, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.521, loss_scale=4, train_wall=31, gb_free=13.6, wall=2801
2022-03-23 10:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will transcend two new pigs.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the gram of how people took responsibility for wildlife, the number of wildanimals grew back again, and that's become a foundation for conservation in namibia.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, so the superconducting.
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and reconcipating it through the one information that refers the entire por-structure and all the fits.
2022-03-23 10:11:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to your men on your table and tell them," if the revolution starts to support you, "the truth is that we've already been supported you for a long time."
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big piece of design work that we're at our plane at the crust, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigeration system, which allows us to use a refrigerator to use the aircraft to be specific, or if we're going to be able to use it in a car car car car station, or if you can see it, or if you can see it, or if you can see it's a trajectory, or if you can see it's a trajectory of a trajectory, or if you can see it, or if you can see it's a trajectory where you can't see it, or if you can't see it, or if you can see it, or if you can see it's a trajectory system that's a trajectory where you can use it,
2022-03-23 10:11:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:14 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.811 | nll_loss 2.64 | ppl 6.23 | bleu 31.53 | wps 4734.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.53
2022-03-23 10:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:11:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.53) (writing took 1.8717799328733236 seconds)
2022-03-23 10:11:16 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:11:16 | INFO | train | epoch 031 | loss 4.727 | nll_loss 2.74 | ppl 6.68 | wps 43709.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.52 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2861
2022-03-23 10:11:16 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:29 | INFO | train_inner | epoch 032:     38 / 157 loss=4.675, nll_loss=2.677, ppl=6.4, wps=34406.9, ups=1.38, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.482, loss_scale=4, train_wall=30, gb_free=14.3, wall=2873
2022-03-23 10:12:00 | INFO | train_inner | epoch 032:    138 / 157 loss=4.676, nll_loss=2.68, ppl=6.41, wps=80748.5, ups=3.19, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.514, loss_scale=4, train_wall=31, gb_free=14.4, wall=2904
2022-03-23 10:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to produce new goldilocks that are going to cross two new pigs.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were taking responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it, as they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and then refers it through the one that pulls the entire porn structure and all the fits.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, when dinner was first summarized, when someone said, "turn you to your desk and tell you," when the revolution begins, we support you, the truth is that we've already supported you for this topic for a long time. "
2022-03-23 10:12:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to surgery -- everything, from a continuous variation and a refrigeration system, that allows us to use an aircraft in the go-to-specific traffic, to a particular passenger, to a specific vehicle, or a particular vehicle vehicle vehicle, or a particular vehicle, to the logic, to the logic, to the ground, to the logic, to a specific vehicle, to the ground, to the ground, to a refueling, to a refueling, to a refueling, to a remotely, to a specific vehicle, to the ground, to a specific vehicle, to the ground, to the ground, to a specific vehicle, to the ground, all, to the earth, all, to the crattribute, all, to the crassessive, to the
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:44 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.797 | nll_loss 2.622 | ppl 6.16 | bleu 31.29 | wps 4797.2 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.53
2022-03-23 10:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.29) (writing took 0.8852414849679917 seconds)
2022-03-23 10:12:45 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:12:45 | INFO | train | epoch 032 | loss 4.66 | nll_loss 2.661 | ppl 6.32 | wps 44667.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.491 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2949
2022-03-23 10:12:45 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:11 | INFO | train_inner | epoch 033:     81 / 157 loss=4.585, nll_loss=2.571, ppl=5.94, wps=35554, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.463, loss_scale=4, train_wall=30, gb_free=14, wall=2975
2022-03-23 10:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep beep in the clinic.
2022-03-23 10:13:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks beds that are going to cross two new pigs.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were taking responsibility for wildlife, the number of wildwildanimals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 10:13:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can, which repeats the big constructions of the face and the basic shape, and deploy it through the one of the information that refers the whole porn structure and all the fits.
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you, "the truth is that we've already been supporting you for this long time," well, by the fact that we've already been supporting you, "silly stream," and then "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a staggering, a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously variable system, and a cooling system of refrigeration, that allows us to use an aircraft in the go-to-special traffic, to be able to do that, if you can see the propelled, or if you can see the promoting space of a promoting system.
2022-03-23 10:14:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:13 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.761 | nll_loss 2.583 | ppl 5.99 | bleu 32.59 | wps 4711.4 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.59
2022-03-23 10:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.59) (writing took 1.8543579529505223 seconds)
2022-03-23 10:14:15 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:14:15 | INFO | train | epoch 033 | loss 4.616 | nll_loss 2.607 | ppl 6.09 | wps 43744.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.467 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3039
2022-03-23 10:14:15 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:23 | INFO | train_inner | epoch 034:     24 / 157 loss=4.641, nll_loss=2.636, ppl=6.22, wps=34653.8, ups=1.38, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.474, loss_scale=4, train_wall=31, gb_free=13.8, wall=3048
2022-03-23 10:14:55 | INFO | train_inner | epoch 034:    124 / 157 loss=4.565, nll_loss=2.547, ppl=5.84, wps=80269.4, ups=3.19, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.484, loss_scale=4, train_wall=31, gb_free=13.7, wall=3079
2022-03-23 10:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to generate new goldilocks that will transcend two new pigs.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wildlife grew back, and this has become a foundation for conservation in namibia.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements are using energy, so the superconductor disturbs.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that restores the big contures of the face, and the basic form, and refers it through the one of the information that refers the entire porn structure and all the fits.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to your men on your desk and tell you," if the revolution begins to support you. "the truth is that we've already supported you for a long time. at this time, we've been supporting you."
2022-03-23 10:15:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on our plane are the most proud toe, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a cooling system that allows us to use a refrigerator in the aircraft to be a specialized transport, to a refueling device, to a particular driver's aircraft, to a particular propeller, to the ground, to the right, to the earth, to the right, to the earth, to the earth, to the right?
2022-03-23 10:15:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:44 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.75 | nll_loss 2.583 | ppl 5.99 | bleu 32.55 | wps 4649.6 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.59
2022-03-23 10:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.55) (writing took 0.8326070338953286 seconds)
2022-03-23 10:15:44 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:15:44 | INFO | train | epoch 034 | loss 4.579 | nll_loss 2.564 | ppl 5.91 | wps 44049.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.488 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3129
2022-03-23 10:15:45 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:06 | INFO | train_inner | epoch 035:     67 / 157 loss=4.585, nll_loss=2.569, ppl=5.93, wps=35206, ups=1.4, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.49, loss_scale=4, train_wall=30, gb_free=14.7, wall=3150
2022-03-23 10:16:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to cross two new pigs.
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildwildlife grew again, and that has become a basis for conservation in namibia.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field captain inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional facial can that repeats the big contures of the face and the basic shape, and then through that one information that refers all the por-structure and all the fine folds.
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be highly interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized, when somebody said, "turn you to your men on your table and tell them," if the revolution starts to support you, "the truth is that we've already been supporting you for this long time."
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a cooling system with liquid liquid that allows us to use an aircraft in the interior to a special transportation, until we're either going to be able to use the propelled by a propeller, or if you look at the propelled to a mechanism, or if you can see it's gone, or if you can see it's all, that's all the propelled by a promoting system that's all the way, that's going to the way, that's gone from a steady machine, to the way, that's going to the way, that's going to the propelled by an aircraft that's going to the way down to be done by which is to the propelled to be done by which is to the air,
2022-03-23 10:17:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:12 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.715 | nll_loss 2.539 | ppl 5.81 | bleu 32.43 | wps 4757.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.59
2022-03-23 10:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:17:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:17:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.43) (writing took 1.3546507230494171 seconds)
2022-03-23 10:17:13 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:17:13 | INFO | train | epoch 035 | loss 4.535 | nll_loss 2.51 | ppl 5.7 | wps 44393.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.454 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3218
2022-03-23 10:17:14 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:17 | INFO | train_inner | epoch 036:     10 / 157 loss=4.514, nll_loss=2.486, ppl=5.6, wps=34983.2, ups=1.4, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.434, loss_scale=4, train_wall=31, gb_free=14.7, wall=3221
2022-03-23 10:17:49 | INFO | train_inner | epoch 036:    110 / 157 loss=4.503, nll_loss=2.471, ppl=5.54, wps=80513.1, ups=3.18, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.474, loss_scale=4, train_wall=31, gb_free=14.7, wall=3253
2022-03-23 10:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:07 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:18:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:18:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:18:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disturbs.
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which repeats the big contures of the face, and then restore it through the fundamental information that refers the entire por-structure, and all the fits folds.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be highly interesting and appropriate for me here at tedwomen is that... tja, when constrict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, we'll support you. "" "" the truth, women, love you, is that we've already been supporting you for a long time. "
2022-03-23 10:18:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on our plane are most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variables and a refrigerator system that allows us to use an aircraft on the top of the aircraft and gogo-traffic, to a specially appropriate device, or if you're going to be able to make a propelled, or if you're going to the fend of a refueled, you're going to the fuse of a refueled to the fuse of a refueled, you're going to the fuse of a refueled, you're going to the fuse of a refueled, you're going to the fuse of a refueled, you're going to the fuse of a refueled, you're going to be able to
2022-03-23 10:18:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:42 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.705 | nll_loss 2.533 | ppl 5.79 | bleu 32.88 | wps 4639.1 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.88
2022-03-23 10:18:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:18:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.88) (writing took 1.9464348230976611 seconds)
2022-03-23 10:18:44 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:18:44 | INFO | train | epoch 036 | loss 4.51 | nll_loss 2.481 | ppl 5.58 | wps 43610.1 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.477 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3308
2022-03-23 10:18:44 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:01 | INFO | train_inner | epoch 037:     53 / 157 loss=4.462, nll_loss=2.424, ppl=5.37, wps=35024.8, ups=1.37, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.464, loss_scale=4, train_wall=30, gb_free=14.7, wall=3326
2022-03-23 10:19:33 | INFO | train_inner | epoch 037:    153 / 157 loss=4.527, nll_loss=2.499, ppl=5.65, wps=79542.1, ups=3.21, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.463, loss_scale=4, train_wall=31, gb_free=13.5, wall=3357
2022-03-23 10:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:19:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-23 10:19:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because they use their energy, and they use the superconducting disorder.
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection, we can start with a traditional facial reflection that repeats the big contures of the face, and then release it through that basic information that refers all the porn structure and all the fits.
2022-03-23 10:20:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen, is that -- well, in a strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, we support you. "'" the truth, women, is that we've already been supporting you with this topic for a long time. "in carroson's"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of invention, and a large part of the design work that we're on our plane at the stumest toes, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable drive and a cooling system of fluid that allows us to use an aircraft on our aircraft on our aircraft, and to use a specially appropriate vehicle traffic, or if you're driving the propeller, if you're going to a propeller, you're going to see the earth, if you're going to see the wrong, you're going to see the wrong, you're going to see it's going to see it's going to see it, and you can see it, and you're going to see a refrigerator, if you're going to see it, you're going to see it's going to see it, and you can see it, and you're going to see it,
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:13 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.673 | nll_loss 2.493 | ppl 5.63 | bleu 33.23 | wps 4693.8 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.23
2022-03-23 10:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.23) (writing took 1.8956203579436988 seconds)
2022-03-23 10:20:15 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:20:15 | INFO | train | epoch 037 | loss 4.477 | nll_loss 2.441 | ppl 5.43 | wps 43369 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.452 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3399
2022-03-23 10:20:15 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:46 | INFO | train_inner | epoch 038:     96 / 157 loss=4.47, nll_loss=2.431, ppl=5.39, wps=33673, ups=1.37, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.483, loss_scale=4, train_wall=31, gb_free=14.3, wall=3430
2022-03-23 10:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you here know.
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:21:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wildanimals grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:21:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that repeates the large constraints of the face and the basic shape, and adding it through the one that refers all the por-structure and all the fine.
2022-03-23 10:21:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn to men on your table and tell them," when the revolution begins, we support you. '"the truth is that we've already supported you about this for a long time."
2022-03-23 10:21:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of design work that we're on our airplane is the most stumbling, a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable and a cooling system that allows us to use an aircraft in the aircraft on the rift and go-ness to a special intercourse of passing, to a propeller, or an automation, or a promoting machine, or a flying space that allows us to use of propellant, to use of a promoting mechanism, to an aircraft that drill an aircraft, to an automature system that allows us to use of an aircraft, to use of a special transportation, to an aircraft that drilling machine, to an aircraft that drilling machine, to an aircraft that drives you can see the most specific drive, to an aircraft that drilling mundling machine
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:43 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.682 | nll_loss 2.496 | ppl 5.64 | bleu 32.73 | wps 4841.6 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.23
2022-03-23 10:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.73) (writing took 0.9205911490134895 seconds)
2022-03-23 10:21:44 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:21:44 | INFO | train | epoch 038 | loss 4.463 | nll_loss 2.423 | ppl 5.36 | wps 44532.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.478 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3488
2022-03-23 10:21:44 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:57 | INFO | train_inner | epoch 039:     39 / 157 loss=4.391, nll_loss=2.339, ppl=5.06, wps=36712.8, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.431, loss_scale=4, train_wall=31, gb_free=13.6, wall=3501
2022-03-23 10:22:28 | INFO | train_inner | epoch 039:    139 / 157 loss=4.458, nll_loss=2.418, ppl=5.34, wps=79539.6, ups=3.2, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.49, loss_scale=4, train_wall=31, gb_free=14.7, wall=3532
2022-03-23 10:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most people know here.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:22:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:22:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were responsible for wildlife, the number of wild animals grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 10:22:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field bundles are captured inside, but the superconductor doesn't like it, if you move, because you use your energy, and you have the superconducting disorder.
2022-03-23 10:23:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional face can that restores the big constraints of the face and the basic shape, and we use it through the one that refers all the porn structure and all the fine folds.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be highly interesting and appropriate for me here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, we support you. '"" "" "" the truth, women, is that we've already supported you for a long time. "
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're on our plane is the most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and a cooling system of refrigeration, that it allows us to use an aircraft on our aircraft in the aircraft, to use a specially appropriate transportation, until one of the operational drive, or when we're either going to be propelled by the crype for a mechanism that's going on the ground.
2022-03-23 10:23:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:12 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.665 | nll_loss 2.475 | ppl 5.56 | bleu 33.4 | wps 4726.4 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.4
2022-03-23 10:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.4) (writing took 1.9207245700526983 seconds)
2022-03-23 10:23:14 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:23:14 | INFO | train | epoch 039 | loss 4.423 | nll_loss 2.376 | ppl 5.19 | wps 43544.2 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.457 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3579
2022-03-23 10:23:15 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:23:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:41 | INFO | train_inner | epoch 040:     82 / 157 loss=4.397, nll_loss=2.344, ppl=5.08, wps=34054.6, ups=1.37, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.421, loss_scale=4, train_wall=30, gb_free=14.1, wall=3605
2022-03-23 10:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:24:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:24:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:16 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:24:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:24:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:24:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wildlife grew again, and this has become a foundation for conservation in namibia.
2022-03-23 10:24:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like moving because their movements use energy, and so the superconductor disturbs.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constraints of the face and the basic shape, and then add it through that information that refers all the pores structure and all the fine folds.
2022-03-23 10:24:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be highly interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your desk and tell them, 'if the revolution starts, then we support you.' 'the truth is that we've been supporting you at this point for a long time." at rael silspring's "and then we're going to download the future."
2022-03-23 10:24:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane are the stumbling toes, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variables and a cooling system, that allows us to use an aircraft on the aircraft to stop and go to a particular passage that is either going to be propelled to the ground, or if you see the propelled to see the aircraft on the ground, or to see the aircraft that's going to see the reverse, and see it's going to the aircraft that's going to the aircraft, and see it's going to see it allows us to see it's going to see it allows us to see it allows us to use it, to use it's going to the aircraft in the aircraft in the aircraft in the aircraft in the aircraft, to be on the aircraft, to be a
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:42 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.664 | nll_loss 2.466 | ppl 5.52 | bleu 33.28 | wps 4900.8 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.4
2022-03-23 10:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:24:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.28) (writing took 0.863249798072502 seconds)
2022-03-23 10:24:43 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:24:43 | INFO | train | epoch 040 | loss 4.387 | nll_loss 2.333 | ppl 5.04 | wps 44602.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.43 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3667
2022-03-23 10:24:43 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:51 | INFO | train_inner | epoch 041:     25 / 157 loss=4.4, nll_loss=2.349, ppl=5.09, wps=36139.6, ups=1.42, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.44, loss_scale=4, train_wall=31, gb_free=14.4, wall=3676
2022-03-23 10:25:23 | INFO | train_inner | epoch 041:    125 / 157 loss=4.373, nll_loss=2.315, ppl=4.98, wps=79376.4, ups=3.18, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.473, loss_scale=4, train_wall=31, gb_free=13.8, wall=3707
2022-03-23 10:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:36 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:25:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in new goldilocks that will transcend two new pigs.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:25:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wildlife grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field caps are captured inside, but the superconductor doesn't like it when they move, because their movements use, and so the superconductor disturbs.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that repeats the big constraints of the face and the basic shape, and then through the one of the information that refers the whole porn structure and all the fits.
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. '' "the truth, women, we've been supporting you on this topic for a long time." at raw silly borson: "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:26:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable gear and a cooling system, that allows us to use an aircraft in our aircraft in our aircraft in the closing and traffic to a special passage of a propeller, or if you're on the ground, to the propelled, to the crash of an aircraft, to the crash, to a plane, to the point where you're going to see it's going to the point where you're going to be rift, or to fly, you know, if you're going to fly, you're going to fly, you're going to fly, you're going to the crash.
2022-03-23 10:26:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:12 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 4.633 | nll_loss 2.442 | ppl 5.44 | bleu 33.9 | wps 4734.6 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.9
2022-03-23 10:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:26:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.9) (writing took 1.8704507721122354 seconds)
2022-03-23 10:26:14 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:26:14 | INFO | train | epoch 041 | loss 4.373 | nll_loss 2.316 | ppl 4.98 | wps 43605.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.455 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3758
2022-03-23 10:26:14 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:35 | INFO | train_inner | epoch 042:     68 / 157 loss=4.341, nll_loss=2.277, ppl=4.85, wps=34604.7, ups=1.38, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.44, loss_scale=4, train_wall=30, gb_free=22.4, wall=3780
2022-03-23 10:27:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:07 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:27:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people here know.
2022-03-23 10:27:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people took responsibility for wildlife, the number of wildlife grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 10:27:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy, and so the superconducting disorder.
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that restores the big contures of the face and the basic shape, and deploy it through the one information that refers all the por-structure and all the fine folds.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, at dinner, it was best summarized when someone said, "turn to the men at your table and tell them, 'when the revolution begins, we support you.' '" the truth is women, we've already been supporting you for a long time. "with rael silson's" silly border, then "to the future of sand, and to download our gains."
2022-03-23 10:27:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most stumbling on on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variables and a cooling system, that allows us to use an aircraft in the aircraft and go-traffic, until a particular passenger passage that either drives the propeller or when you fly to the ground, until you see an automacy room, until you see the same thing.
2022-03-23 10:27:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:41 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 4.66 | nll_loss 2.461 | ppl 5.51 | bleu 33.16 | wps 4843.1 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.9
2022-03-23 10:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.16) (writing took 0.8684943960979581 seconds)
2022-03-23 10:27:42 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:27:42 | INFO | train | epoch 042 | loss 4.341 | nll_loss 2.277 | ppl 4.85 | wps 44784.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.439 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3846
2022-03-23 10:27:42 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:46 | INFO | train_inner | epoch 043:     11 / 157 loss=4.324, nll_loss=2.259, ppl=4.79, wps=36207.6, ups=1.42, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.424, loss_scale=4, train_wall=31, gb_free=13.9, wall=3850
2022-03-23 10:28:17 | INFO | train_inner | epoch 043:    111 / 157 loss=4.367, nll_loss=2.307, ppl=4.95, wps=79593.1, ups=3.2, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.482, loss_scale=4, train_wall=31, gb_free=13.8, wall=3881
2022-03-23 10:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:39 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most people here know.
2022-03-23 10:28:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks, which will be crossing two new pigs.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the rate of how people took responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use, and so the superconducting disorder.
2022-03-23 10:28:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can begin with a traditional face can that repeats the large contures of the face and the basic form, and then add it through the information that refers the entire por-structure and all the fine folds.
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them, 'when the revolution begins, we support you.' the truth, women, is that we've already been supporting you for a long time." at racel's "] [[[[[["] ["] ["] ["] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] [unclear] ["] [unclear] [unclear] ["] [unclear] [unclear] [unclear] [unclear] [unclear] [[[
2022-03-23 10:29:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of invention, and a large part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable drive and cooling system with fluid that allows us to use an aircraft in the stopand go-traffic, to a particular drive, or when you get the propelled to the land.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:10 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 4.622 | nll_loss 2.429 | ppl 5.38 | bleu 34.03 | wps 4706.9 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 34.03
2022-03-23 10:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:29:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt
2022-03-23 10:29:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 34.03) (writing took 1.8739004090894014 seconds)
2022-03-23 10:29:12 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:29:12 | INFO | train | epoch 043 | loss 4.329 | nll_loss 2.262 | ppl 4.8 | wps 43816 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.456 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3936
2022-03-23 10:29:12 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:29 | INFO | train_inner | epoch 044:     54 / 157 loss=4.29, nll_loss=2.217, ppl=4.65, wps=34443.6, ups=1.39, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.461, loss_scale=4, train_wall=31, gb_free=14.2, wall=3954
2022-03-23 10:30:00 | INFO | train_inner | epoch 044:    154 / 157 loss=4.302, nll_loss=2.231, ppl=4.69, wps=82209.5, ups=3.22, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.419, loss_scale=4, train_wall=31, gb_free=13.8, wall=3985
2022-03-23 10:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:05 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:30:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:30:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:30:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense that people took responsibility for wildlife, the number of wildanimals grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 10:30:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because they use their movements, and so the superconduction disturbs.
2022-03-23 10:30:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that repeats the big constraints of the face and the basic shape, and then add it through the one information that refers the entire porn structure and all the fine folds.
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it extremely interesting and appropriate for me here at tedwomen is that -- well, at dinner, it's the best summarized when someone said, "turn to the men on your desk and tell them," when the revolution begins, we support you. '"the truth, women, we've been supporting you at this point for a long time." at rael carson's "silspring," until the future of sand. "
2022-03-23 10:30:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of invention, and a large piece of design work that we're on our plane are the most staggering, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and a cooling system with fluid that allows us to use an aircraft in the stopand go-traffic to a particular passenger drive, either when you run the propeller or when you get propeller, or when you get to the propeller, to the propeller, or when you get on the ground, to the propeller, to the propeller, to the propeller, to the ground, to the propeller, to the propeller or when you see it's going to the propeller, to the ground, to the propeller, to the ground, to the propeller, to the earth -- everything, to see it's going to the wheels, to the same place, to the fly,
2022-03-23 10:30:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:39 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 4.629 | nll_loss 2.431 | ppl 5.39 | bleu 33.69 | wps 4787.9 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 34.03
2022-03-23 10:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:30:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.69) (writing took 0.8387079059612006 seconds)
2022-03-23 10:30:40 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:30:40 | INFO | train | epoch 044 | loss 4.303 | nll_loss 2.231 | ppl 4.69 | wps 44612.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.447 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4025
2022-03-23 10:30:41 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:12 | INFO | train_inner | epoch 045:     97 / 157 loss=4.262, nll_loss=2.182, ppl=4.54, wps=35998.4, ups=1.4, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.428, loss_scale=4, train_wall=31, gb_free=14.6, wall=4056
2022-03-23 10:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:31:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 10:31:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:31:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:31:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back up again, and that has become a foundation for conservation in namibia.
2022-03-23 10:31:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use, and so the superconduction disturbs.
2022-03-23 10:31:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that restores the big constrations of the face and the basic shape, and deals it through that information that refers all the por-structure and all the fine folds.
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it extremely interesting and appropriate to be here at tedwomen is that... well, when dinner strikes, it was best summarized when someone said, "turn you to the men on your table and tell them," when the revolution begins, we support you. '"the truth, women, love you, is that we've already been supporting you for a long time with racel silks,"] ["] ["] turn to the future of our living "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:32:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of invention, and a large part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to operating it on the ground -- all, from a continuously variable propulsion system, and a refrigerator system, that allows us to use an aircraft in the stop-go-traffic, to a particular passenger vehicle vehicle, or a propellant, to the soil, to the deflection system.
2022-03-23 10:32:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:09 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 4.617 | nll_loss 2.428 | ppl 5.38 | bleu 33.93 | wps 4634.9 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 34.03
2022-03-23 10:32:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:32:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.93) (writing took 0.867223994107917 seconds)
2022-03-23 10:32:10 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:32:10 | INFO | train | epoch 045 | loss 4.293 | nll_loss 2.219 | ppl 4.66 | wps 44027.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.473 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4114
2022-03-23 10:32:10 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:23 | INFO | train_inner | epoch 046:     40 / 157 loss=4.316, nll_loss=2.246, ppl=4.74, wps=34067.3, ups=1.4, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.504, loss_scale=4, train_wall=30, gb_free=14.3, wall=4127
2022-03-23 10:32:54 | INFO | train_inner | epoch 046:    140 / 157 loss=4.253, nll_loss=2.171, ppl=4.5, wps=80990, ups=3.18, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.412, loss_scale=4, train_wall=31, gb_free=13.6, wall=4159
2022-03-23 10:32:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:03 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:33:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you probably know here.
2022-03-23 10:33:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:11 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:33:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:33:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:33:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people have surpassed responsibility for wildlife, the number of wildlife grew back again, and that has become a basis for conservation in namibia.
2022-03-23 10:33:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move because they use their movements, and so the superconductor disturbs.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big constraints of the face and the basic shape, and emphasize it through that information that refers all the por-structure and all the fine folds.
2022-03-23 10:33:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and appropriate to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and tell them," when the revolution begins, we'll support you. '"the truth, love is that we've been supporting you for a long time."
2022-03-23 10:33:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- all, from a continuously variable drive and a cooling system with fluid that allows us to use an aircraft in the stop-go-traffic to a particular passenger propeller or when you're going to fly the ground.
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:36 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 4.609 | nll_loss 2.414 | ppl 5.33 | bleu 33.8 | wps 4971.5 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 34.03
2022-03-23 10:33:36 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt
2022-03-23 10:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.15_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.8) (writing took 0.8463900340721011 seconds)
2022-03-23 10:33:37 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:33:37 | INFO | train | epoch 046 | loss 4.256 | nll_loss 2.175 | ppl 4.52 | wps 45329.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.425 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4202
2022-03-23 10:33:37 | INFO | fairseq_cli.train | done training in 4201.0 seconds
