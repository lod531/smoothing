Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 210653125: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:56:28 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:56:38 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:56:38 2022
Terminated at Wed Mar 23 23:35:56 2022
Results reported at Wed Mar 23 23:35:56 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.95 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   16735.62 sec.
    Max Memory :                                 4964 MB
    Average Memory :                             4263.69 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15036.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   16757 sec.
    Turnaround time :                            16768 sec.

The output (if any) follows:

2022-03-23 18:56:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.95, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.95, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:56:48 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:56:48 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:56:49 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:56:49 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:56:49 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1124/160239 [00:00<00:14, 11239.42it/s]  2%|▏         | 2423/160239 [00:00<00:12, 12253.18it/s]  2%|▏         | 3794/160239 [00:00<00:12, 12912.13it/s]  3%|▎         | 5115/160239 [00:00<00:11, 13029.51it/s]  4%|▍         | 6418/160239 [00:00<00:12, 12816.55it/s]  5%|▍         | 7701/160239 [00:00<00:12, 12703.64it/s]  6%|▌         | 8972/160239 [00:00<00:12, 12549.73it/s]  6%|▋         | 10303/160239 [00:00<00:11, 12786.08it/s]  7%|▋         | 11585/160239 [00:00<00:11, 12796.05it/s]  8%|▊         | 12866/160239 [00:01<00:11, 12783.92it/s]  9%|▉         | 14145/160239 [00:01<00:11, 12762.17it/s] 10%|▉         | 15422/160239 [00:01<00:11, 12582.05it/s] 10%|█         | 16681/160239 [00:01<00:11, 12422.17it/s] 11%|█         | 17924/160239 [00:01<00:11, 12343.42it/s] 12%|█▏        | 19198/160239 [00:01<00:11, 12459.79it/s] 13%|█▎        | 20593/160239 [00:01<00:10, 12901.58it/s] 14%|█▎        | 21885/160239 [00:01<00:11, 12452.32it/s] 14%|█▍        | 23134/160239 [00:01<00:11, 12385.82it/s] 15%|█▌        | 24397/160239 [00:01<00:10, 12457.05it/s] 16%|█▌        | 25698/160239 [00:02<00:10, 12617.45it/s] 17%|█▋        | 26962/160239 [00:02<00:10, 12399.02it/s] 18%|█▊        | 28312/160239 [00:02<00:10, 12720.28it/s] 18%|█▊        | 29586/160239 [00:02<00:10, 12605.22it/s] 19%|█▉        | 30848/160239 [00:02<00:10, 12310.49it/s] 20%|██        | 32221/160239 [00:02<00:10, 12723.33it/s] 21%|██        | 33497/160239 [00:02<00:10, 12482.41it/s] 22%|██▏       | 34748/160239 [00:02<00:10, 12284.55it/s] 22%|██▏       | 36041/160239 [00:02<00:09, 12469.60it/s] 23%|██▎       | 37290/160239 [00:02<00:09, 12319.07it/s] 24%|██▍       | 38578/160239 [00:03<00:09, 12479.17it/s] 25%|██▍       | 39828/160239 [00:03<00:09, 12416.49it/s] 26%|██▌       | 41135/160239 [00:03<00:09, 12609.09it/s] 26%|██▋       | 42397/160239 [00:03<00:09, 12248.83it/s] 27%|██▋       | 43625/160239 [00:03<00:09, 12222.40it/s] 28%|██▊       | 44850/160239 [00:03<00:09, 12054.04it/s] 29%|██▉       | 46197/160239 [00:03<00:09, 12467.82it/s] 30%|██▉       | 47487/160239 [00:03<00:08, 12592.13it/s] 30%|███       | 48748/160239 [00:03<00:08, 12409.45it/s] 31%|███       | 50034/160239 [00:03<00:08, 12539.81it/s] 32%|███▏      | 51317/160239 [00:04<00:08, 12621.99it/s] 33%|███▎      | 52632/160239 [00:04<00:08, 12778.39it/s] 34%|███▎      | 53911/160239 [00:04<00:08, 12624.02it/s] 34%|███▍      | 55175/160239 [00:04<00:08, 12579.39it/s] 35%|███▌      | 56436/160239 [00:04<00:08, 12583.96it/s] 36%|███▌      | 57725/160239 [00:04<00:08, 12671.24it/s] 37%|███▋      | 59055/160239 [00:04<00:07, 12857.12it/s] 38%|███▊      | 60375/160239 [00:04<00:07, 12957.09it/s] 38%|███▊      | 61672/160239 [00:04<00:07, 12506.64it/s] 39%|███▉      | 63033/160239 [00:05<00:07, 12825.71it/s] 40%|████      | 64319/160239 [00:05<00:07, 12829.85it/s] 41%|████      | 65766/160239 [00:05<00:07, 13309.99it/s] 42%|████▏     | 67100/160239 [00:05<00:07, 13091.18it/s] 43%|████▎     | 68412/160239 [00:05<00:07, 13002.33it/s] 44%|████▎     | 69714/160239 [00:05<00:07, 12541.55it/s] 44%|████▍     | 71061/160239 [00:05<00:06, 12808.75it/s] 45%|████▌     | 72346/160239 [00:05<00:06, 12662.94it/s] 46%|████▌     | 73615/160239 [00:05<00:06, 12501.59it/s] 47%|████▋     | 74868/160239 [00:05<00:06, 12443.72it/s] 48%|████▊     | 76115/160239 [00:06<00:06, 12449.50it/s] 48%|████▊     | 77472/160239 [00:06<00:06, 12776.38it/s] 49%|████▉     | 78762/160239 [00:06<00:06, 12812.69it/s] 50%|████▉     | 80085/160239 [00:06<00:06, 12936.56it/s] 51%|█████     | 81493/160239 [00:06<00:05, 13275.78it/s] 52%|█████▏    | 82822/160239 [00:06<00:05, 13096.68it/s] 53%|█████▎    | 84133/160239 [00:06<00:05, 12927.09it/s] 53%|█████▎    | 85452/160239 [00:06<00:05, 13002.26it/s] 54%|█████▍    | 86855/160239 [00:06<00:05, 13304.81it/s] 55%|█████▌    | 88187/160239 [00:06<00:05, 13051.14it/s] 56%|█████▌    | 89531/160239 [00:07<00:05, 13164.60it/s] 57%|█████▋    | 90849/160239 [00:07<00:05, 13069.00it/s] 58%|█████▊    | 92157/160239 [00:07<00:05, 12944.43it/s] 58%|█████▊    | 93464/160239 [00:07<00:05, 12977.54it/s] 59%|█████▉    | 94763/160239 [00:07<00:05, 12627.68it/s] 60%|█████▉    | 96083/160239 [00:07<00:05, 12793.70it/s] 61%|██████    | 97365/160239 [00:07<00:05, 12547.73it/s] 62%|██████▏   | 98664/160239 [00:07<00:04, 12676.52it/s] 62%|██████▏   | 100004/160239 [00:07<00:04, 12887.38it/s] 63%|██████▎   | 101321/160239 [00:07<00:04, 12969.33it/s] 64%|██████▍   | 102620/160239 [00:08<00:04, 12722.37it/s] 65%|██████▍   | 103894/160239 [00:08<00:04, 12617.50it/s] 66%|██████▌   | 105271/160239 [00:08<00:04, 12953.45it/s] 67%|██████▋   | 106568/160239 [00:08<00:04, 12895.72it/s] 67%|██████▋   | 107859/160239 [00:08<00:04, 12573.20it/s] 68%|██████▊   | 109119/160239 [00:08<00:04, 12335.44it/s] 69%|██████▉   | 110367/160239 [00:08<00:04, 12375.33it/s] 70%|██████▉   | 111736/160239 [00:08<00:03, 12757.28it/s] 71%|███████   | 113014/160239 [00:08<00:03, 12596.78it/s] 71%|███████▏  | 114338/160239 [00:09<00:03, 12785.36it/s] 72%|███████▏  | 115619/160239 [00:09<00:03, 12728.14it/s] 73%|███████▎  | 116893/160239 [00:09<00:03, 12503.75it/s] 74%|███████▍  | 118214/160239 [00:09<00:03, 12710.44it/s] 75%|███████▍  | 119543/160239 [00:09<00:03, 12877.49it/s] 75%|███████▌  | 120832/160239 [00:09<00:03, 12629.40it/s] 76%|███████▋  | 122266/160239 [00:09<00:02, 13125.53it/s] 77%|███████▋  | 123581/160239 [00:09<00:02, 12899.85it/s] 78%|███████▊  | 124874/160239 [00:09<00:02, 12652.51it/s] 79%|███████▊  | 126142/160239 [00:09<00:02, 12642.26it/s] 80%|███████▉  | 127421/160239 [00:10<00:02, 12685.27it/s] 80%|████████  | 128739/160239 [00:10<00:02, 12828.79it/s] 81%|████████  | 130023/160239 [00:10<00:02, 12529.54it/s] 82%|████████▏ | 131282/160239 [00:10<00:02, 12544.58it/s] 83%|████████▎ | 132538/160239 [00:10<00:02, 12541.17it/s] 83%|████████▎ | 133794/160239 [00:10<00:02, 12312.64it/s] 84%|████████▍ | 135046/160239 [00:10<00:02, 12369.62it/s] 85%|████████▌ | 136317/160239 [00:10<00:01, 12468.78it/s] 86%|████████▌ | 137655/160239 [00:10<00:01, 12737.49it/s] 87%|████████▋ | 138950/160239 [00:10<00:01, 12797.11it/s] 88%|████████▊ | 140298/160239 [00:11<00:01, 12999.82it/s] 88%|████████▊ | 141599/160239 [00:11<00:01, 13001.73it/s] 89%|████████▉ | 142900/160239 [00:11<00:01, 12694.30it/s] 90%|████████▉ | 144172/160239 [00:11<00:01, 12623.20it/s] 91%|█████████ | 145436/160239 [00:11<00:01, 12558.20it/s] 92%|█████████▏| 146693/160239 [00:11<00:01, 12492.83it/s] 92%|█████████▏| 147943/160239 [00:11<00:00, 12473.14it/s] 93%|█████████▎| 149191/160239 [00:11<00:00, 12254.38it/s] 94%|█████████▍| 150481/160239 [00:11<00:00, 12443.26it/s] 95%|█████████▍| 151771/160239 [00:11<00:00, 12577.77it/s] 96%|█████████▌| 153030/160239 [00:12<00:00, 12567.58it/s] 96%|█████████▋| 154320/160239 [00:12<00:00, 12665.44it/s] 97%|█████████▋| 155666/160239 [00:12<00:00, 12901.53it/s] 98%|█████████▊| 156973/160239 [00:12<00:00, 12950.98it/s] 99%|█████████▉| 158269/160239 [00:12<00:00, 12528.00it/s]100%|█████████▉| 159606/160239 [00:12<00:00, 12771.89it/s]100%|██████████| 160239/160239 [00:12<00:00, 12669.18it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 27/6629 [00:00<00:24, 268.89it/s]  1%|          | 54/6629 [00:00<00:24, 263.87it/s]  1%|          | 81/6629 [00:00<00:24, 263.49it/s]  2%|▏         | 108/6629 [00:00<00:24, 263.54it/s]  2%|▏         | 135/6629 [00:00<00:24, 262.64it/s]  2%|▏         | 162/6629 [00:00<00:24, 263.09it/s]  3%|▎         | 189/6629 [00:00<00:24, 263.38it/s]  3%|▎         | 216/6629 [00:00<00:24, 263.43it/s]  4%|▎         | 243/6629 [00:00<00:24, 262.86it/s]  4%|▍         | 270/6629 [00:01<00:24, 262.57it/s]  4%|▍         | 297/6629 [00:01<00:24, 262.66it/s]  5%|▍         | 324/6629 [00:01<00:24, 261.80it/s]  5%|▌         | 351/6629 [00:01<00:23, 261.80it/s]  6%|▌         | 378/6629 [00:01<00:23, 262.20it/s]  6%|▌         | 405/6629 [00:01<00:23, 262.74it/s]  7%|▋         | 432/6629 [00:01<00:23, 262.28it/s]  7%|▋         | 459/6629 [00:01<00:23, 262.24it/s]  7%|▋         | 486/6629 [00:01<00:23, 262.41it/s]  8%|▊         | 513/6629 [00:01<00:23, 262.77it/s]  8%|▊         | 540/6629 [00:02<00:23, 263.13it/s]  9%|▊         | 567/6629 [00:02<00:22, 264.48it/s]  9%|▉         | 594/6629 [00:02<00:22, 264.74it/s]  9%|▉         | 621/6629 [00:02<00:22, 264.39it/s] 10%|▉         | 648/6629 [00:02<00:22, 264.14it/s] 10%|█         | 675/6629 [00:02<00:22, 264.09it/s] 11%|█         | 702/6629 [00:02<00:22, 263.72it/s] 11%|█         | 729/6629 [00:02<00:22, 265.01it/s] 11%|█▏        | 756/6629 [00:02<00:22, 264.96it/s] 12%|█▏        | 783/6629 [00:02<00:22, 264.90it/s] 12%|█▏        | 810/6629 [00:03<00:21, 264.71it/s] 13%|█▎        | 837/6629 [00:03<00:21, 263.78it/s] 13%|█▎        | 864/6629 [00:03<00:21, 263.02it/s] 13%|█▎        | 891/6629 [00:03<00:21, 262.48it/s] 14%|█▍        | 918/6629 [00:03<00:21, 262.50it/s] 14%|█▍        | 945/6629 [00:03<00:21, 261.96it/s] 15%|█▍        | 972/6629 [00:03<00:21, 262.10it/s] 15%|█▌        | 999/6629 [00:03<00:21, 261.89it/s] 15%|█▌        | 1026/6629 [00:03<00:21, 262.47it/s] 16%|█▌        | 1054/6629 [00:04<00:20, 266.34it/s] 16%|█▋        | 1082/6629 [00:04<00:20, 268.93it/s] 17%|█▋        | 1110/6629 [00:04<00:20, 271.39it/s] 17%|█▋        | 1138/6629 [00:04<00:20, 273.17it/s] 18%|█▊        | 1166/6629 [00:04<00:19, 273.95it/s] 18%|█▊        | 1194/6629 [00:04<00:19, 274.77it/s] 18%|█▊        | 1222/6629 [00:04<00:19, 275.47it/s] 19%|█▉        | 1250/6629 [00:04<00:19, 276.11it/s] 19%|█▉        | 1278/6629 [00:04<00:19, 275.45it/s] 20%|█▉        | 1306/6629 [00:04<00:19, 275.13it/s] 20%|██        | 1334/6629 [00:05<00:19, 274.26it/s] 21%|██        | 1362/6629 [00:05<00:19, 274.56it/s] 21%|██        | 1390/6629 [00:05<00:19, 275.28it/s] 21%|██▏       | 1418/6629 [00:05<00:18, 275.78it/s] 22%|██▏       | 1446/6629 [00:05<00:18, 276.21it/s] 22%|██▏       | 1474/6629 [00:05<00:18, 275.81it/s] 23%|██▎       | 1502/6629 [00:05<00:18, 275.78it/s] 23%|██▎       | 1530/6629 [00:05<00:18, 275.68it/s] 24%|██▎       | 1558/6629 [00:05<00:18, 275.50it/s] 24%|██▍       | 1586/6629 [00:05<00:18, 276.53it/s] 24%|██▍       | 1614/6629 [00:06<00:18, 276.52it/s] 25%|██▍       | 1642/6629 [00:06<00:17, 277.40it/s] 25%|██▌       | 1671/6629 [00:06<00:17, 278.13it/s] 26%|██▌       | 1699/6629 [00:06<00:17, 278.04it/s] 26%|██▌       | 1727/6629 [00:06<00:17, 277.40it/s] 26%|██▋       | 1755/6629 [00:06<00:17, 277.31it/s] 27%|██▋       | 1783/6629 [00:06<00:17, 276.35it/s] 27%|██▋       | 1811/6629 [00:06<00:17, 275.28it/s] 28%|██▊       | 1839/6629 [00:06<00:17, 275.31it/s] 28%|██▊       | 1867/6629 [00:06<00:17, 275.39it/s] 29%|██▊       | 1895/6629 [00:07<00:17, 274.55it/s] 29%|██▉       | 1923/6629 [00:07<00:17, 273.73it/s] 29%|██▉       | 1951/6629 [00:07<00:17, 274.93it/s] 30%|██▉       | 1979/6629 [00:07<00:16, 275.58it/s] 30%|███       | 2007/6629 [00:07<00:16, 273.84it/s] 31%|███       | 2035/6629 [00:07<00:16, 274.46it/s] 31%|███       | 2063/6629 [00:07<00:16, 274.61it/s] 32%|███▏      | 2091/6629 [00:07<00:16, 274.39it/s] 32%|███▏      | 2119/6629 [00:07<00:16, 274.37it/s] 32%|███▏      | 2147/6629 [00:07<00:16, 274.84it/s] 33%|███▎      | 2175/6629 [00:08<00:16, 275.64it/s] 33%|███▎      | 2203/6629 [00:08<00:16, 275.61it/s] 34%|███▎      | 2231/6629 [00:08<00:16, 274.80it/s] 34%|███▍      | 2259/6629 [00:08<00:15, 276.22it/s] 35%|███▍      | 2288/6629 [00:08<00:15, 277.50it/s] 35%|███▍      | 2316/6629 [00:08<00:15, 277.52it/s] 35%|███▌      | 2344/6629 [00:08<00:15, 277.81it/s] 36%|███▌      | 2373/6629 [00:08<00:15, 278.75it/s] 36%|███▌      | 2401/6629 [00:08<00:15, 278.01it/s] 37%|███▋      | 2429/6629 [00:08<00:15, 277.83it/s] 37%|███▋      | 2457/6629 [00:09<00:14, 278.18it/s] 37%|███▋      | 2485/6629 [00:09<00:14, 277.66it/s] 38%|███▊      | 2514/6629 [00:09<00:14, 278.54it/s] 38%|███▊      | 2542/6629 [00:09<00:14, 278.14it/s] 39%|███▉      | 2570/6629 [00:09<00:14, 278.42it/s] 39%|███▉      | 2598/6629 [00:09<00:14, 278.27it/s] 40%|███▉      | 2626/6629 [00:09<00:14, 277.05it/s] 40%|████      | 2654/6629 [00:09<00:14, 277.29it/s] 40%|████      | 2682/6629 [00:09<00:14, 276.78it/s] 41%|████      | 2710/6629 [00:09<00:14, 276.03it/s] 41%|████▏     | 2738/6629 [00:10<00:14, 274.78it/s] 42%|████▏     | 2766/6629 [00:10<00:14, 274.80it/s] 42%|████▏     | 2794/6629 [00:10<00:13, 276.19it/s] 43%|████▎     | 2822/6629 [00:10<00:13, 276.89it/s] 43%|████▎     | 2850/6629 [00:10<00:13, 276.84it/s] 43%|████▎     | 2878/6629 [00:10<00:13, 276.41it/s] 44%|████▍     | 2906/6629 [00:10<00:13, 276.16it/s] 44%|████▍     | 2934/6629 [00:10<00:13, 275.28it/s] 45%|████▍     | 2962/6629 [00:10<00:13, 274.34it/s] 45%|████▌     | 2990/6629 [00:11<00:13, 275.03it/s] 46%|████▌     | 3018/6629 [00:11<00:13, 275.39it/s] 46%|████▌     | 3046/6629 [00:11<00:12, 276.23it/s] 46%|████▋     | 3074/6629 [00:11<00:12, 276.37it/s] 47%|████▋     | 3102/6629 [00:11<00:12, 275.69it/s] 47%|████▋     | 3130/6629 [00:11<00:12, 276.10it/s] 48%|████▊     | 3158/6629 [00:11<00:12, 275.69it/s] 48%|████▊     | 3186/6629 [00:11<00:12, 275.96it/s] 48%|████▊     | 3214/6629 [00:11<00:12, 276.02it/s] 49%|████▉     | 3242/6629 [00:11<00:12, 275.93it/s] 49%|████▉     | 3270/6629 [00:12<00:12, 275.79it/s] 50%|████▉     | 3298/6629 [00:12<00:12, 276.23it/s] 50%|█████     | 3326/6629 [00:12<00:11, 277.16it/s] 51%|█████     | 3354/6629 [00:12<00:11, 277.70it/s] 51%|█████     | 3382/6629 [00:12<00:11, 277.16it/s] 51%|█████▏    | 3410/6629 [00:12<00:11, 276.98it/s] 52%|█████▏    | 3438/6629 [00:12<00:11, 276.13it/s] 52%|█████▏    | 3466/6629 [00:12<00:11, 275.72it/s] 53%|█████▎    | 3494/6629 [00:12<00:11, 276.21it/s] 53%|█████▎    | 3522/6629 [00:12<00:11, 275.87it/s] 54%|█████▎    | 3550/6629 [00:13<00:11, 275.82it/s] 54%|█████▍    | 3578/6629 [00:13<00:11, 275.72it/s] 54%|█████▍    | 3606/6629 [00:13<00:10, 275.97it/s] 55%|█████▍    | 3634/6629 [00:13<00:10, 275.70it/s] 55%|█████▌    | 3662/6629 [00:13<00:10, 275.55it/s] 56%|█████▌    | 3690/6629 [00:13<00:10, 274.91it/s] 56%|█████▌    | 3718/6629 [00:13<00:10, 274.25it/s] 57%|█████▋    | 3746/6629 [00:13<00:10, 274.77it/s] 57%|█████▋    | 3774/6629 [00:13<00:10, 274.00it/s] 57%|█████▋    | 3802/6629 [00:13<00:10, 274.12it/s] 58%|█████▊    | 3830/6629 [00:14<00:10, 274.42it/s] 58%|█████▊    | 3858/6629 [00:14<00:10, 275.85it/s] 59%|█████▊    | 3886/6629 [00:14<00:09, 276.09it/s] 59%|█████▉    | 3914/6629 [00:14<00:09, 276.67it/s] 59%|█████▉    | 3942/6629 [00:14<00:09, 276.71it/s] 60%|█████▉    | 3970/6629 [00:14<00:09, 276.40it/s] 60%|██████    | 3998/6629 [00:14<00:09, 275.64it/s] 61%|██████    | 4026/6629 [00:14<00:09, 275.64it/s] 61%|██████    | 4054/6629 [00:14<00:09, 275.89it/s] 62%|██████▏   | 4082/6629 [00:14<00:09, 276.38it/s] 62%|██████▏   | 4110/6629 [00:15<00:09, 276.23it/s] 62%|██████▏   | 4138/6629 [00:15<00:09, 275.74it/s] 63%|██████▎   | 4166/6629 [00:15<00:08, 276.62it/s] 63%|██████▎   | 4194/6629 [00:15<00:08, 277.62it/s] 64%|██████▎   | 4222/6629 [00:15<00:08, 277.31it/s] 64%|██████▍   | 4250/6629 [00:15<00:08, 277.46it/s] 65%|██████▍   | 4278/6629 [00:15<00:08, 277.54it/s] 65%|██████▍   | 4307/6629 [00:15<00:08, 278.32it/s] 65%|██████▌   | 4335/6629 [00:15<00:08, 277.89it/s] 66%|██████▌   | 4363/6629 [00:15<00:08, 277.68it/s] 66%|██████▌   | 4391/6629 [00:16<00:08, 277.81it/s] 67%|██████▋   | 4419/6629 [00:16<00:07, 277.19it/s] 67%|██████▋   | 4447/6629 [00:16<00:07, 276.17it/s] 68%|██████▊   | 4475/6629 [00:16<00:07, 276.10it/s] 68%|██████▊   | 4503/6629 [00:16<00:07, 275.49it/s] 68%|██████▊   | 4531/6629 [00:16<00:07, 275.38it/s] 69%|██████▉   | 4559/6629 [00:16<00:07, 275.00it/s] 69%|██████▉   | 4587/6629 [00:16<00:07, 275.30it/s] 70%|██████▉   | 4615/6629 [00:16<00:07, 274.54it/s] 70%|███████   | 4643/6629 [00:16<00:07, 274.62it/s] 70%|███████   | 4671/6629 [00:17<00:07, 273.30it/s] 71%|███████   | 4699/6629 [00:17<00:07, 274.33it/s] 71%|███████▏  | 4727/6629 [00:17<00:06, 274.17it/s] 72%|███████▏  | 4755/6629 [00:17<00:06, 273.95it/s] 72%|███████▏  | 4783/6629 [00:17<00:06, 275.23it/s] 73%|███████▎  | 4811/6629 [00:17<00:06, 275.00it/s] 73%|███████▎  | 4839/6629 [00:17<00:06, 275.83it/s] 73%|███████▎  | 4867/6629 [00:17<00:06, 274.41it/s] 74%|███████▍  | 4895/6629 [00:17<00:06, 273.56it/s] 74%|███████▍  | 4923/6629 [00:18<00:06, 274.09it/s] 75%|███████▍  | 4951/6629 [00:18<00:06, 273.87it/s] 75%|███████▌  | 4979/6629 [00:18<00:06, 273.54it/s] 76%|███████▌  | 5007/6629 [00:18<00:05, 273.15it/s] 76%|███████▌  | 5035/6629 [00:18<00:05, 273.07it/s] 76%|███████▋  | 5063/6629 [00:18<00:05, 272.69it/s] 77%|███████▋  | 5091/6629 [00:18<00:05, 272.66it/s] 77%|███████▋  | 5119/6629 [00:18<00:05, 272.10it/s] 78%|███████▊  | 5147/6629 [00:18<00:05, 272.41it/s] 78%|███████▊  | 5175/6629 [00:18<00:05, 272.89it/s] 78%|███████▊  | 5203/6629 [00:19<00:05, 273.43it/s] 79%|███████▉  | 5231/6629 [00:19<00:05, 274.22it/s] 79%|███████▉  | 5259/6629 [00:19<00:04, 274.97it/s] 80%|███████▉  | 5287/6629 [00:19<00:04, 274.43it/s] 80%|████████  | 5315/6629 [00:19<00:04, 275.19it/s] 81%|████████  | 5343/6629 [00:19<00:04, 275.98it/s] 81%|████████  | 5371/6629 [00:19<00:04, 276.50it/s] 81%|████████▏ | 5399/6629 [00:19<00:04, 275.35it/s] 82%|████████▏ | 5427/6629 [00:19<00:04, 276.01it/s] 82%|████████▏ | 5455/6629 [00:19<00:04, 276.36it/s] 83%|████████▎ | 5483/6629 [00:20<00:04, 276.44it/s] 83%|████████▎ | 5511/6629 [00:20<00:04, 276.15it/s] 84%|████████▎ | 5539/6629 [00:20<00:03, 275.25it/s] 84%|████████▍ | 5567/6629 [00:20<00:03, 273.83it/s] 84%|████████▍ | 5595/6629 [00:20<00:03, 273.77it/s] 85%|████████▍ | 5623/6629 [00:20<00:03, 274.57it/s] 85%|████████▌ | 5651/6629 [00:20<00:03, 274.70it/s] 86%|████████▌ | 5679/6629 [00:20<00:03, 275.53it/s] 86%|████████▌ | 5707/6629 [00:20<00:03, 276.26it/s] 87%|████████▋ | 5735/6629 [00:20<00:03, 275.82it/s] 87%|████████▋ | 5763/6629 [00:21<00:03, 275.71it/s] 87%|████████▋ | 5791/6629 [00:21<00:03, 275.03it/s] 88%|████████▊ | 5819/6629 [00:21<00:02, 274.46it/s] 88%|████████▊ | 5847/6629 [00:21<00:02, 274.39it/s] 89%|████████▊ | 5875/6629 [00:21<00:02, 274.32it/s] 89%|████████▉ | 5903/6629 [00:21<00:02, 274.98it/s] 89%|████████▉ | 5931/6629 [00:21<00:02, 274.23it/s] 90%|████████▉ | 5959/6629 [00:21<00:02, 274.13it/s] 90%|█████████ | 5987/6629 [00:21<00:02, 274.36it/s] 91%|█████████ | 6015/6629 [00:21<00:02, 274.48it/s] 91%|█████████ | 6043/6629 [00:22<00:02, 275.81it/s] 92%|█████████▏| 6071/6629 [00:22<00:02, 275.31it/s] 92%|█████████▏| 6099/6629 [00:22<00:01, 275.16it/s] 92%|█████████▏| 6127/6629 [00:22<00:01, 275.33it/s] 93%|█████████▎| 6155/6629 [00:22<00:01, 275.24it/s] 93%|█████████▎| 6183/6629 [00:22<00:01, 275.45it/s] 94%|█████████▎| 6211/6629 [00:22<00:01, 274.80it/s] 94%|█████████▍| 6239/6629 [00:22<00:01, 274.62it/s] 95%|█████████▍| 6267/6629 [00:22<00:01, 274.57it/s] 95%|█████████▍| 6295/6629 [00:23<00:01, 274.13it/s] 95%|█████████▌| 6323/6629 [00:23<00:01, 273.63it/s] 96%|█████████▌| 6351/6629 [00:23<00:01, 274.03it/s] 96%|█████████▌| 6379/6629 [00:23<00:00, 274.43it/s] 97%|█████████▋| 6407/6629 [00:23<00:00, 275.12it/s] 97%|█████████▋| 6435/6629 [00:23<00:00, 275.07it/s] 97%|█████████▋| 6463/6629 [00:23<00:00, 275.16it/s] 98%|█████████▊| 6492/6629 [00:23<00:00, 277.63it/s] 98%|█████████▊| 6520/6629 [00:23<00:00, 273.59it/s] 99%|█████████▉| 6549/6629 [00:23<00:00, 276.06it/s] 99%|█████████▉| 6577/6629 [00:24<00:00, 272.83it/s]100%|█████████▉| 6605/6629 [00:24<00:00, 274.91it/s]100%|██████████| 6629/6629 [00:24<00:00, 273.69it/s]AVERAGE DENSITY :0.0
2022-03-23 18:57:44 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:57:44 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:57:44 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:57:44 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:57:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:57:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:57:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:57:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:57:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_last.pt
2022-03-23 18:57:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_last.pt
2022-03-23 18:57:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:57:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:57:45 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:57:45 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:57:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:57:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:57:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 19:02:46 | INFO | train_inner | epoch 001:    104 / 157 loss=11.348, ppl=2607.09, wps=8703.7, ups=0.35, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.643, loss_scale=8, train_wall=300, gb_free=13.2, wall=301
2022-03-23 19:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:05:19 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 19:05:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:05:24 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 19:05:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:05:29 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 19:05:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:05:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 19:05:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:05:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:05:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:05:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:06:02 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:06:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:06:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:06:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:06:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:06:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:06:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.686 | ppl 823.77 | bleu 0.01 | wps 2990 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 19:06:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 19:06:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 0.8046393310651183 seconds)
2022-03-23 19:06:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:06:14 | INFO | train | epoch 001 | loss 10.96 | ppl 1991.37 | wps 7699 | ups 0.31 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.822 | loss_scale 8 | train_wall 449 | gb_free 13.5 | wall 510
2022-03-23 19:06:15 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:08:28 | INFO | train_inner | epoch 002:     47 / 157 loss=9.949, ppl=988.68, wps=7272.1, ups=0.29, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.307, loss_scale=8, train_wall=282, gb_free=22.4, wall=644
2022-03-23 19:13:11 | INFO | train_inner | epoch 002:    147 / 157 loss=9.084, ppl=542.85, wps=8849.7, ups=0.35, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.357, loss_scale=8, train_wall=283, gb_free=13.5, wall=927
2022-03-23 19:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:13:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,.
2022-03-23 19:13:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:13:51 | INFO | fairseq.tasks.translation | example hypothesis: a a a a a a a.
2022-03-23 19:13:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:13:57 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i i i i i i i i i i i.
2022-03-23 19:13:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:14:02 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,.
2022-03-23 19:14:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:14:09 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 19:14:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:14:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:14:24 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:14:31 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:14:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:14:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:14:43 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.644 | ppl 399.95 | bleu 0.01 | wps 2869.6 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 19:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 19:14:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:14:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:14:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 0.7826643930748105 seconds)
2022-03-23 19:14:43 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:14:43 | INFO | train | epoch 002 | loss 9.227 | ppl 599.35 | wps 7757.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.366 | loss_scale 8 | train_wall 445 | gb_free 13.6 | wall 1019
2022-03-23 19:14:44 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:18:56 | INFO | train_inner | epoch 003:     90 / 157 loss=8.745, ppl=428.92, wps=7226, ups=0.29, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.417, loss_scale=8, train_wall=281, gb_free=13.4, wall=1272
2022-03-23 19:22:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:22:14 | INFO | fairseq.tasks.translation | example hypothesis: 's.
2022-03-23 19:22:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:22:20 | INFO | fairseq.tasks.translation | example hypothesis: 's a a.
2022-03-23 19:22:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:22:26 | INFO | fairseq.tasks.translation | example hypothesis: i, i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i
2022-03-23 19:22:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:22:33 | INFO | fairseq.tasks.translation | example hypothesis: was was was was, was was was was was was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 19:22:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:22:40 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we, we we we we we we we we we we we we we we we we we we we
2022-03-23 19:22:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:22:48 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 19:22:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:22:56 | INFO | fairseq.tasks.translation | example hypothesis: , you you you you you you you you you you you you you you you you the the the the the the the, it it it it it it it it it it it it it it it it it it it it it it it's's's's it's's's's's's's's's's's's's's's's's's's
2022-03-23 19:22:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:23:05 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:23:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:23:14 | INFO | fairseq.tasks.translation | example hypothesis: 's, "" "" "," "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:23:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:23:17 | INFO | fairseq.tasks.translation | example hypothesis: , we we we the, we we we we we we we we we we we we we we we we the the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to the the the the the the the the the the the the the the the the the the the the the to to to to to to to to to to to to to to to that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that
2022-03-23 19:23:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:23:17 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.381 | ppl 333.35 | bleu 0.05 | wps 2600.7 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.05
2022-03-23 19:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 19:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:23:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:23:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.05) (writing took 0.7786713340319693 seconds)
2022-03-23 19:23:18 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:23:18 | INFO | train | epoch 003 | loss 8.615 | ppl 392.2 | wps 7681.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.414 | loss_scale 8 | train_wall 444 | gb_free 14.3 | wall 1533
2022-03-23 19:23:18 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:24:53 | INFO | train_inner | epoch 004:     33 / 157 loss=8.469, ppl=354.39, wps=7180.6, ups=0.28, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=1.542, loss_scale=8, train_wall=287, gb_free=13.4, wall=1628
2022-03-23 19:29:37 | INFO | train_inner | epoch 004:    133 / 157 loss=8.133, ppl=280.75, wps=8875.2, ups=0.35, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.583, loss_scale=8, train_wall=284, gb_free=13.8, wall=1913
2022-03-23 19:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:30:49 | INFO | fairseq.tasks.translation | example hypothesis: if you can can can can can can can can can can can can can can can can can can can be be be.
2022-03-23 19:30:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:30:56 | INFO | fairseq.tasks.translation | example hypothesis: he he he he he he he he he he he he he he he he he he he he he.
2022-03-23 19:30:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:31:03 | INFO | fairseq.tasks.translation | example hypothesis: i think, i think, i think to think to be be be a lot of a lot of a lot of a lot.
2022-03-23 19:31:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:31:10 | INFO | fairseq.tasks.translation | example hypothesis: he he was was was was was was he he was was was was was was was was was was was was was was was was was was was was was was was was was he he he he he he he
2022-03-23 19:31:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:31:18 | INFO | fairseq.tasks.translation | example hypothesis: we know, what we know, we know, what we're're do we know, and we know to do we know to do we know to do we know to do do do do do we have to do do do do do do do
2022-03-23 19:31:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:31:25 | INFO | fairseq.tasks.translation | example hypothesis: we can can can be to do to be be be be or or or or or or or or or or or or or or or or or or or or or or or or.
2022-03-23 19:31:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:31:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not the world, and you're're're're're the world, but they're're the world, but but they're're're're're're're be be be the world, but but they're're're're're're're're're're're're're're the world of the world of the world.
2022-03-23 19:31:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:31:41 | INFO | fairseq.tasks.translation | example hypothesis: we have the world, and we can can can can see the world of the world, and we can can see the world of the world, and we can can can can can see the world of the world.
2022-03-23 19:31:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:31:49 | INFO | fairseq.tasks.translation | example hypothesis: we've said, "we've've've've said," "" you can can can be be be be to be be be be the world, "" "" "you can be be be be be be be be be be the world," "it's the world," "" "" "" it's the world, "" we're be be be be be be be be be be be be be be be be be the world, "" "" "it's the world." "" "
2022-03-23 19:31:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:31:52 | INFO | fairseq.tasks.translation | example hypothesis: we have the world, that we've've've've've've've've've've've've've've've've have the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've have the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've
2022-03-23 19:31:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:31:52 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.814 | ppl 225.06 | bleu 0.86 | wps 2596.7 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.86
2022-03-23 19:31:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 19:31:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:31:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:31:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.86) (writing took 0.7710472149774432 seconds)
2022-03-23 19:31:53 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:31:53 | INFO | train | epoch 004 | loss 8.224 | ppl 298.93 | wps 7667.2 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.61 | loss_scale 8 | train_wall 445 | gb_free 14 | wall 2048
2022-03-23 19:31:53 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:31:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:35:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:35:33 | INFO | train_inner | epoch 005:     77 / 157 loss=7.835, ppl=228.41, wps=7051.9, ups=0.28, wpb=25082.2, bsz=1060.2, num_updates=700, lr=8.75e-05, gnorm=1.849, loss_scale=4, train_wall=286, gb_free=13.5, wall=2268
2022-03-23 19:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:39:23 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can can can can see the world.
2022-03-23 19:39:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:39:30 | INFO | fairseq.tasks.translation | example hypothesis: he can can can can be the world.
2022-03-23 19:39:30 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:39:37 | INFO | fairseq.tasks.translation | example hypothesis: i can can can be a lot of a lot of a lot of the world, i can can be a lot of the world.
2022-03-23 19:39:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:39:43 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was a lot, he was a lot, he was a lot of the time.
2022-03-23 19:39:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:39:51 | INFO | fairseq.tasks.translation | example hypothesis: we know, what we know, what we know, and we know, what we know, what we know, and we know, what we know, what we have to do, and we have to do, and we have to do,
2022-03-23 19:39:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:39:59 | INFO | fairseq.tasks.translation | example hypothesis: then we have to do, and we have to do, or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 19:39:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:40:07 | INFO | fairseq.tasks.translation | example hypothesis: if if if if if if if if if if if if if if you have a lot of the way, but it's not just just just just just just just just just just just just just just just just just just just just just just just just just just just just, but it, but it, but it, but it, but it, but the
2022-03-23 19:40:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:40:15 | INFO | fairseq.tasks.translation | example hypothesis: we can see the world of the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world
2022-03-23 19:40:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:40:24 | INFO | fairseq.tasks.translation | example hypothesis: i said, "i said," i said, "i said," i said, "we said," we said, "i said," we said, "i said," i said, "i said," we said, "we said," i said, "i said," i said, "i said," "" we said, "i said," we said, "i said," "" "we said," i said, "" "" "" "" "" "" "" "" we said, "i said," i said, "" "we said," i said, "i said," "" we said, "i said," we said, "we said," i said, "we said," i said, "" "" "" we said, "" ""
2022-03-23 19:40:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:40:27 | INFO | fairseq.tasks.translation | example hypothesis: i think, if we think, if we think, if we think, that we think, if we have to see the world of the world of the world of the world of the world, and the world, and the world of the world of the world, and the world, and the world, and the world of the world of the world, and the world, that we've've've've've've've've have to see, and the world of the world, which is, and the world, and the world, and the world, and the world, and the world, and the world, and the world, and the world, and we think, and the world of the world, that we think, that we've've've've've've've've think, and the world of the world of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first of the world of the
2022-03-23 19:40:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:40:27 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.373 | ppl 165.81 | bleu 1.3 | wps 2582.8 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.3
2022-03-23 19:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:40:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.3) (writing took 0.7851730193942785 seconds)
2022-03-23 19:40:27 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:40:27 | INFO | train | epoch 005 | loss 7.741 | ppl 213.94 | wps 7624.3 | ups 0.3 | wpb 25157.3 | bsz 1025.1 | num_updates 780 | lr 9.75e-05 | gnorm 1.695 | loss_scale 4 | train_wall 444 | gb_free 13.2 | wall 2563
2022-03-23 19:40:28 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:41:25 | INFO | train_inner | epoch 006:     20 / 157 loss=7.689, ppl=206.38, wps=7119.7, ups=0.28, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.6, loss_scale=4, train_wall=282, gb_free=13.6, wall=2621
2022-03-23 19:46:09 | INFO | train_inner | epoch 006:    120 / 157 loss=7.493, ppl=180.1, wps=8842.2, ups=0.35, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.431, loss_scale=4, train_wall=283, gb_free=13.5, wall=2904
2022-03-23 19:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:47:58 | INFO | fairseq.tasks.translation | example hypothesis: you can't can't be.
2022-03-23 19:47:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:48:04 | INFO | fairseq.tasks.translation | example hypothesis: he can't be in the time.
2022-03-23 19:48:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:48:11 | INFO | fairseq.tasks.translation | example hypothesis: i can can't make this way that i can can make this way that can be a way.
2022-03-23 19:48:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:48:18 | INFO | fairseq.tasks.translation | example hypothesis: he was she had had had had had had had had had had had had had had had had had had had had had had his his his his father.
2022-03-23 19:48:18 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:48:26 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do, and we're going to do this is what we're going to do, and we're going to do, and we're going to do what we're going to do, and we're going to do,
2022-03-23 19:48:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:48:34 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to do that we're going to do the world, and we're going to do it, and we're going to do it, and we're going to do the world, and we're going to do that we're going to do it, and we're going to
2022-03-23 19:48:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:48:42 | INFO | fairseq.tasks.translation | example hypothesis: if if if if if you're not just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just be the
2022-03-23 19:48:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:48:51 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that we can see the world, and we can see the world, and we can see that we can see the world, and we can see that we can see that we can see the world, and we can see that we can see that we can see the world, and we can see that we can see that we can see that we can see the world, and we can see the world, we can see that we can see the
2022-03-23 19:48:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:49:00 | INFO | fairseq.tasks.translation | example hypothesis: he said, "we said," if you're going to say, "you're going to say," he said, "it's going to do you're going to do you're going to say," he said, "we're going to do it's going to do it's going to say," it's going to do you're going to do you're going to do you're going to say, "it's going to do you're going to do you're going to say," it's going to do it's going to say, "we're going to do it's going to do you're going to say," we're going to do you're going to say, "we're going to do it's going to do you're going to do it's going to do you're going to say," it's going to do you're going to do you know
2022-03-23 19:49:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:49:03 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see the world, and then we're going to see that we're going to see that we're going to see that we're going to see the world, and they're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see the other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other people,
2022-03-23 19:49:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:49:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.107 | ppl 137.82 | bleu 1.39 | wps 2541.8 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.39
2022-03-23 19:49:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:49:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:49:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:49:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.39) (writing took 0.7736212429590523 seconds)
2022-03-23 19:49:03 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:49:03 | INFO | train | epoch 006 | loss 7.384 | ppl 167.03 | wps 7652.1 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.563 | loss_scale 4 | train_wall 444 | gb_free 14.2 | wall 3079
2022-03-23 19:49:04 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:49:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:52:01 | INFO | train_inner | epoch 007:     63 / 157 loss=7.164, ppl=143.37, wps=7095.7, ups=0.28, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.438, loss_scale=4, train_wall=281, gb_free=13.4, wall=3256
2022-03-23 19:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:56:33 | INFO | fairseq.tasks.translation | example hypothesis: you can't have no.
2022-03-23 19:56:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:56:39 | INFO | fairseq.tasks.translation | example hypothesis: he's a year.
2022-03-23 19:56:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:56:45 | INFO | fairseq.tasks.translation | example hypothesis: i can't have a lot of course.
2022-03-23 19:56:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:56:51 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was his father, because he was his father, he was his father.
2022-03-23 19:56:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:56:58 | INFO | fairseq.tasks.translation | example hypothesis: what's what we had to do, and we have a little bit of what we have to do?
2022-03-23 19:56:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:57:04 | INFO | fairseq.tasks.translation | example hypothesis: we don't know about our time, or our time, or we can't know about our own or our own or or or our own or or or or or or or our time.
2022-03-23 19:57:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:57:12 | INFO | fairseq.tasks.translation | example hypothesis: if you're not not, but you're going to look at the way, but they're not not, but if you're not, but they're not not the same, but they're not, but they're not, but they're not, but they're not, but they're not, but they're not, but they're not, but
2022-03-23 19:57:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:57:20 | INFO | fairseq.tasks.translation | example hypothesis: we can see that, and if we can see, we can see the world, and we can see the world, and we can see, and then we can see the world, and we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world, and we can see that we can see that we can see that the
2022-03-23 19:57:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:57:29 | INFO | fairseq.tasks.translation | example hypothesis: we said, "" "if we said," "if you're going to say," "and we're going to say," "and we're going to say," and then we're going to do, "and then you're going to do," "and then we're going to do," "and then we're going to do," and then you're going to do it, "it," it, "it," and then we're going to do, "" "and then we're going to do it," and then we're going to do it, "" and then you're going to say, "and then we're going to say," "" "and then we're going to do," and then we're going to do it, "and then you're going to be a" "" "" "" ""
2022-03-23 19:57:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:57:32 | INFO | fairseq.tasks.translation | example hypothesis: if you know, if we have a lot of the world, we've got to be a lot of the world, and it, and it's a lot of the way that we're going to be a lot of the world, and it, and if we're going to be a lot of the middle of the middle of the middle of the middle of the way, and we're going to be a lot of the world, and then we're going to get to get to be a lot of the world, and then we're going to get to be a lot of the world, and then we're going to be a lot of the middle of the middle of the middle of the middle of the way, and we're going to get to get to get the way, and then we're going to get the middle of the world, and then we're going to be a lot of the middle of the way that we're going to be able to be a, which is that we're going to be a lot of the middle of the middle of the
2022-03-23 19:57:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:57:32 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.78 | ppl 109.9 | bleu 2.39 | wps 2800.4 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.39
2022-03-23 19:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:57:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 19:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.39) (writing took 0.7696600933559239 seconds)
2022-03-23 19:57:33 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:57:33 | INFO | train | epoch 007 | loss 7.084 | ppl 135.69 | wps 7756.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.337 | loss_scale 4 | train_wall 444 | gb_free 13.4 | wall 3588
2022-03-23 19:57:33 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:57:50 | INFO | train_inner | epoch 008:      6 / 157 loss=6.989, ppl=127.06, wps=7262.2, ups=0.29, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.326, loss_scale=4, train_wall=284, gb_free=14.9, wall=3605
2022-03-23 20:02:32 | INFO | train_inner | epoch 008:    106 / 157 loss=6.866, ppl=116.62, wps=8864.7, ups=0.35, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=1.4, loss_scale=4, train_wall=282, gb_free=22.4, wall=3888
2022-03-23 20:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:05:03 | INFO | fairseq.tasks.translation | example hypothesis: these can't be a lot of water.
2022-03-23 20:05:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:05:09 | INFO | fairseq.tasks.translation | example hypothesis: it's a year in the last year.
2022-03-23 20:05:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:05:16 | INFO | fairseq.tasks.translation | example hypothesis: so, i can use this kind of course, because i can get a lot of course.
2022-03-23 20:05:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:05:23 | INFO | fairseq.tasks.translation | example hypothesis: he didn't had his father, because he had his father was his father, because he had his father was his father was his father.
2022-03-23 20:05:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:05:30 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a friend, what we had a little bit of what we have to do with what we're going to do?
2022-03-23 20:05:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:05:37 | INFO | fairseq.tasks.translation | example hypothesis: we're going to talk about our time or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 20:05:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:05:44 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of the water, but it's not not not not like, but if you're not not going to get it, but they're not not not not not not not going to get it.
2022-03-23 20:05:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:05:51 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to take the brain, we can get a kind of the brain, and we can make a kind of the brain, which is that we can make a kind of the brain.
2022-03-23 20:05:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:05:59 | INFO | fairseq.tasks.translation | example hypothesis: one of the one of you said, "if you're going to say," you're going to say, "you're going to say," you're going to say, "well," we're going to say, "well," well, "you're going to say," you're going to say, "well," we're going to say, "well," you're going to say, "you're going to say," you're going to say, "well," well, "you're going to say," well, "well," you're going to say, "well," you're going to say, "we're going to say," you're going to say, "we're going to say," you're going to say, "you're going to say," you're going to say, "well," the
2022-03-23 20:05:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:06:01 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of course that we're going to get to get to be a little bit of the way that we're going to get to be able to get to get to be a little bit of the way that we're going to get to get to get to get to get to get to get to get to be a kind of the way that we're going to get to get to be a little bit of the brain, or or or or a little bit of that we're going to get to get to get to get to get to get to get to get to get to get to get to be a little bit of the way to be a little bit of the way to be a little bit of the way that we're going to get a little bit of the way that we're going to get to get to get to be able to get to get a little bit of the way that we're going to be a little bit of the way that we're going to be able to get to get to get to get to get to get it, or
2022-03-23 20:06:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:06:01 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.545 | ppl 93.37 | bleu 3.05 | wps 2818.2 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.05
2022-03-23 20:06:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:06:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.05) (writing took 0.7898816331289709 seconds)
2022-03-23 20:06:02 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:06:02 | INFO | train | epoch 008 | loss 6.853 | ppl 115.6 | wps 7754.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.425 | loss_scale 4 | train_wall 443 | gb_free 13.6 | wall 4097
2022-03-23 20:06:02 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:08:20 | INFO | train_inner | epoch 009:     49 / 157 loss=6.757, ppl=108.14, wps=7246.1, ups=0.29, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.48, loss_scale=4, train_wall=282, gb_free=13.2, wall=4235
2022-03-23 20:13:04 | INFO | train_inner | epoch 009:    149 / 157 loss=6.605, ppl=97.37, wps=8919.3, ups=0.35, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.343, loss_scale=4, train_wall=284, gb_free=13.5, wall=4519
2022-03-23 20:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:13:31 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 20:13:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:13:37 | INFO | fairseq.tasks.translation | example hypothesis: it's year.
2022-03-23 20:13:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:13:44 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, i can't get a lot of course of course of course, and i can make a lot of course.
2022-03-23 20:13:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:13:51 | INFO | fairseq.tasks.translation | example hypothesis: he didn't know his father, because he was his father, because she was his father, because she was his father, she was his father.
2022-03-23 20:13:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:13:58 | INFO | fairseq.tasks.translation | example hypothesis: my mother is a lot of my mother and my mother and said, and what we're going to do, and what we're going to do?
2022-03-23 20:13:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:14:06 | INFO | fairseq.tasks.translation | example hypothesis: we're going to talk about our time about our time, and we're talking about our time to talk about our time, or our own or or or or or or the other other other people are not going to be able to talk about the world.
2022-03-23 20:14:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:14:14 | INFO | fairseq.tasks.translation | example hypothesis: some of them are some of them, but they don't know, but if you don't get the way, but they don't get it, but if you don't get it, but they don't get it.
2022-03-23 20:14:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:14:22 | INFO | fairseq.tasks.translation | example hypothesis: if we look at the information, we can use the information of the information, we can see that we can make this information, and then we can make a little bit of information, and then we can see that we can see that we can use the information, and create a kind of the information, and then we can see that we can make a kind of the structure of the structure of the environment, which is a kind of information, which we can use the
2022-03-23 20:14:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:14:31 | INFO | fairseq.tasks.translation | example hypothesis: one of the one of the question, it's one of the question, and it's going to say, and it's going to say, "well," if we're going to say, "well," if we're going to say, "well," we're going to say, "well," if we're going to say, "well," well, "well," you're going to say, you're going to say, "well," well, "well," well, "well," well, "well," well, it's going to say, "well, you're going to do it's going to say, you're going to say," well, "well," we're going to say, you're going to say, "you're going to say," you're going to say, you're going to say, "
2022-03-23 20:14:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:14:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not a lot of course, and it's a lot of course, and if we've got a lot of course, if we're going to get a little bit that we're going to do that we're going to do that we're going to get to get to make a lot of the brain, and we're going to do that we're going to do that we're going to have a lot of the way that we're going to do that we're going to do that we're going to get to get to get to get to get to make a lot of the way to make a little bit that we're going to get to do that we're going to do that we're going to do that we're going to get to get to get to get to get to make a little bit of the way to make a little bit of the way to get to make a little bit that we're going to make a little bit that we're going to make a little bit of the way to get to get to make a lot of the planet,
2022-03-23 20:14:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:14:34 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.313 | ppl 79.5 | bleu 3.47 | wps 2631.7 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.47
2022-03-23 20:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.47) (writing took 0.7858993350528181 seconds)
2022-03-23 20:14:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:14:34 | INFO | train | epoch 009 | loss 6.615 | ppl 98.04 | wps 7706.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.394 | loss_scale 4 | train_wall 443 | gb_free 13.7 | wall 4610
2022-03-23 20:14:35 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:19:00 | INFO | train_inner | epoch 010:     92 / 157 loss=6.324, ppl=80.09, wps=7155.2, ups=0.28, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.527, loss_scale=4, train_wall=287, gb_free=12.2, wall=4875
2022-03-23 20:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:22:05 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 20:22:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:22:11 | INFO | fairseq.tasks.translation | example hypothesis: year, he can be about 30,000 miles.
2022-03-23 20:22:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:22:17 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of course of course, i can use a lot of course.
2022-03-23 20:22:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:22:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never never never seen his father because he had his father, because she was his father.
2022-03-23 20:22:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:22:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a lot of mother and a child, and we said, "well, what we do?"
2022-03-23 20:22:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:22:35 | INFO | fairseq.tasks.translation | example hypothesis: our time we're talking about our time, and we don't know about how to talk about the time.
2022-03-23 20:22:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:22:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you know, but if you don't know, but if you don't have to get your body, but if you don't get your body.
2022-03-23 20:22:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:22:48 | INFO | fairseq.tasks.translation | example hypothesis: if we use the information of information that information, we can use this information, and then we can use the structure of the structure, and then we can use the structure of the surface of the structure, and all the structure.
2022-03-23 20:22:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:22:55 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, and it's interesting for me, "and you know," you know, "you know," if you want to say, "if you're going to say," well, "you're going to say," if you're going to say, "oh," you're going to say, "oh," you're going to say, "oh," oh, "oh," oh, "you're going to say," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," if you're going to say, "oh," if you're going to say, "if you're going to say," oh, "oh," you're going to say, "you're going to say," if you're
2022-03-23 20:22:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:22:57 | INFO | fairseq.tasks.translation | example hypothesis: it's always always always always the mother, and the internet, and if we were able to get a lot of the way that we were able to get a very big, and that we were going to get a big idea that we were going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a big.
2022-03-23 20:22:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:22:57 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.913 | ppl 60.27 | bleu 6.66 | wps 3145.5 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.66
2022-03-23 20:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.66) (writing took 0.7902724747546017 seconds)
2022-03-23 20:22:58 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:22:58 | INFO | train | epoch 010 | loss 6.353 | ppl 81.75 | wps 7843.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.433 | loss_scale 4 | train_wall 444 | gb_free 13 | wall 5113
2022-03-23 20:22:58 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:24:39 | INFO | train_inner | epoch 011:     35 / 157 loss=6.321, ppl=79.94, wps=7330.4, ups=0.29, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=1.337, loss_scale=4, train_wall=280, gb_free=22.4, wall=5215
2022-03-23 20:29:22 | INFO | train_inner | epoch 011:    135 / 157 loss=6.059, ppl=66.69, wps=8917.4, ups=0.35, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=1.428, loss_scale=4, train_wall=283, gb_free=13.9, wall=5498
2022-03-23 20:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:30:29 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to use these cells.
2022-03-23 20:30:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:30:35 | INFO | fairseq.tasks.translation | example hypothesis: last year, he can be about about 7,000 miles in the house.
2022-03-23 20:30:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:30:41 | INFO | fairseq.tasks.translation | example hypothesis: so, these kinds of course, i can also also also also have a lot of course of course.
2022-03-23 20:30:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:30:47 | INFO | fairseq.tasks.translation | example hypothesis: he had his father his father, because his father was his father because his father had his father his father had his father with his father.
2022-03-23 20:30:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:30:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a lot of aids, and a child has got a child, and a child who said, "what we do?
2022-03-23 20:30:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:31:00 | INFO | fairseq.tasks.translation | example hypothesis: so, our time we're going to talk about our time about things like our own time, and we don't talk about the cost of the world.
2022-03-23 20:31:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:31:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of you're looking at the map of the alalalalalalaline, but if you don't need to get the energy, and it doesn't need to change the energy.
2022-03-23 20:31:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:31:13 | INFO | fairseq.tasks.translation | example hypothesis: if we look at information, the information of this information, we can use this information, we can see a little bit of a little bit of the information, and the structure of the structure, and all the structure of the structure of the structure.
2022-03-23 20:31:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:31:18 | INFO | fairseq.tasks.translation | example hypothesis: one of one of the reasons that there's interesting interesting interesting interesting for me, and for me for me for me for me for me, for me, "let's say," let's say, "let's say," if we're going to say, "if we're going to tell you know," if we're going to tell you're going to say, "and say," we're going to tell you're going to say, "the next to tell you're going to say," well, "well," well, "well," well, "well," well, "well," if we're going to tell you're going to tell you're going to say, "if we're going to tell you're going to tell you're going to tell you're going to tell you're going to say," the next next next next next next next next
2022-03-23 20:31:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:31:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, the mother is still the mother, and the great part of the work, and the design of the work that we had to see the work, if we were going to see that it was going to see that we had to make a lot of the future.
2022-03-23 20:31:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:31:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.629 | ppl 49.48 | bleu 8.55 | wps 3219.6 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.55
2022-03-23 20:31:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:31:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.55) (writing took 0.7850466230884194 seconds)
2022-03-23 20:31:20 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:31:20 | INFO | train | epoch 011 | loss 6.034 | ppl 65.51 | wps 7859.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.372 | loss_scale 4 | train_wall 444 | gb_free 13.3 | wall 5616
2022-03-23 20:31:21 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:31:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:35:08 | INFO | train_inner | epoch 012:     78 / 157 loss=5.656, ppl=50.42, wps=7404.9, ups=0.29, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=1.29, loss_scale=4, train_wall=288, gb_free=14.3, wall=5844
2022-03-23 20:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:38:51 | INFO | fairseq.tasks.translation | example hypothesis: it can't use these chemical chemical materials.
2022-03-23 20:38:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:38:57 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 88,000 miles in the restaurant.
2022-03-23 20:38:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:39:03 | INFO | fairseq.tasks.translation | example hypothesis: this pattern of course, i can also also also make a lot of course.
2022-03-23 20:39:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:39:10 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, his father had his father, his father had his father with him.
2022-03-23 20:39:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:39:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is, and a child has got a child, and we said, "well, what do we do?
2022-03-23 20:39:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:39:23 | INFO | fairseq.tasks.translation | example hypothesis: so our time we spend time to talk about how things are not going to talk about the time, or not talking about poverty or poverty or every time.
2022-03-23 20:39:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:39:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some of those are some of you're going to go into the field, but if you don't need it, it doesn't need your energy, but if you don't need your energy, it doesn't need the energy, and you need to use your energy, you need the energy, you need, you need to use it.
2022-03-23 20:39:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:39:37 | INFO | fairseq.tasks.translation | example hypothesis: if we use information information, we can use this information, we can start with one of these kinds of materials, and then we can start with the structure of the structure, and the structure of the structure, and all the structure of the structure, and all the structure of the structure, and all the structure of the structure, and all the structure, and all the structure.
2022-03-23 20:39:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:39:45 | INFO | fairseq.tasks.translation | example hypothesis: one of one of the reasons, it's interesting, and it's interesting for me to say, "for me," for me, "hey," hey, "for you know," well, "well," if you've said, "well," well, "well," well, "for this is the best time," you're going to say, "well," well, "well," well, "well," you've said, "well," well, "for this is," for this is, "for this is the best," for this is the best, "for this is," for this is the best, "the best," for this is the best time, "for this is the best time," for this is the best time, "you have a" you have a young young women, "you have a
2022-03-23 20:39:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:39:48 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of mother, and the great part of our work is that we had a great work on our work, we had to see that if we were able to use it, we had to use it with a big system, we had to make it to make it with a big system, or a big system, we had to be able to make it with a big system, or a huge system that it was able to make it, we had to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that it, or a huge system, or a huge system that if
2022-03-23 20:39:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:39:48 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.267 | ppl 38.5 | bleu 9.22 | wps 2909.3 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.22
2022-03-23 20:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.22) (writing took 0.7891274616122246 seconds)
2022-03-23 20:39:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:39:48 | INFO | train | epoch 012 | loss 5.745 | ppl 53.62 | wps 7771.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.375 | loss_scale 4 | train_wall 444 | gb_free 13.3 | wall 6124
2022-03-23 20:39:49 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:39:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:40:50 | INFO | train_inner | epoch 013:     21 / 157 loss=5.774, ppl=54.73, wps=7218.4, ups=0.29, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=1.422, loss_scale=4, train_wall=278, gb_free=13.6, wall=6185
2022-03-23 20:45:33 | INFO | train_inner | epoch 013:    121 / 157 loss=5.426, ppl=42.99, wps=8869.1, ups=0.35, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=1.316, loss_scale=4, train_wall=283, gb_free=13.4, wall=6469
2022-03-23 20:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:47:19 | INFO | fairseq.tasks.translation | example hypothesis: these are not able to use it.
2022-03-23 20:47:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:47:24 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 miles.
2022-03-23 20:47:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:47:30 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also make course, of course, of course, of course, of course, a lot of forms.
2022-03-23 20:47:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:47:35 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother.
2022-03-23 20:47:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:47:41 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends has died, and a child has been a child, so we asked what do we do?
2022-03-23 20:47:41 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:47:47 | INFO | fairseq.tasks.translation | example hypothesis: so so we spend our time to talk about how the genetic disease, and not talk about any of poverty or global poverty.
2022-03-23 20:47:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:47:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the mechanics are in the field, but it doesn't be able to be able if it doesn't need your energy, it doesn't need your energy, so if you need the energy.
2022-03-23 20:47:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:47:59 | INFO | fairseq.tasks.translation | example hypothesis: if we use the information, we can use the reflection of this reflection, we can start with one of the traditional traditional patterns, and then we can start using the structure of the structure.
2022-03-23 20:47:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:48:05 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting, and it's interesting for me to be here for me here, "yes, it's the best time," yes, "yes," well, "if we're going to tell you," the best time we're going to say, "the best revolution."
2022-03-23 20:48:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:48:06 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the invention of the invention, and a lot of design that we're working on our airplane, so if we were able to see the surface of our body, we had to make it all the genetic system, if we had to use it.
2022-03-23 20:48:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:48:06 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.065 | ppl 33.48 | bleu 10.4 | wps 3466.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 10.4
2022-03-23 20:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 13 @ 2036 updates, score 10.4) (writing took 0.7663275660015643 seconds)
2022-03-23 20:48:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:48:07 | INFO | train | epoch 013 | loss 5.431 | ppl 43.15 | wps 7925 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.334 | loss_scale 4 | train_wall 444 | gb_free 13.6 | wall 6622
2022-03-23 20:48:07 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:51:14 | INFO | train_inner | epoch 014:     64 / 157 loss=5.213, ppl=37.09, wps=7480.7, ups=0.29, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=1.329, loss_scale=4, train_wall=287, gb_free=13.5, wall=6810
2022-03-23 20:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:55:38 | INFO | fairseq.tasks.translation | example hypothesis: these chemical chemical can't use chemical chemical chemical chemical chemical chemical chemical.
2022-03-23 20:55:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:55:44 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 dollars in the restaurant.
2022-03-23 20:55:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:55:50 | INFO | fairseq.tasks.translation | example hypothesis: these magnets can also be able to be able to be a very popular bible of course.
2022-03-23 20:55:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:55:56 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his father, when she had his mother.
2022-03-23 20:55:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:56:02 | INFO | fairseq.tasks.translation | example hypothesis: one of my coucouses has died in aids, and a child said, "well, what do we do?
2022-03-23 20:56:02 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:56:08 | INFO | fairseq.tasks.translation | example hypothesis: so so why we spend time time to talk about things like gender, and we don't talk about how to the ultimate of poverty or poverty.
2022-03-23 20:56:08 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:56:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some of course, some of course, you're going to start with the magic of the field, but if you don't need your energy, you don't need your energy, and if you need your energy.
2022-03-23 20:56:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:56:22 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use the reflect of this information, we can start with a traditional traditional, and then we can start using it all the structure of the structure of the structure, and the structure of the structure of information, and the structure of the structure of information, and if you can take it all the information.
2022-03-23 20:56:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:56:29 | INFO | fairseq.tasks.translation | example hypothesis: th th th: one of the reasons, and it's interesting to be interesting for tedtalks to me to be here, "well," well, "hey," hey, "if we're going to tell you," the best revolution, "and we're going to say," if you're going to tell you. "
2022-03-23 20:56:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:56:31 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, unfortunately, the mother is still the invention of invention, and a big design work that we had to use with our airplanes, and if we had to use it, if we have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 20:56:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:56:31 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.814 | ppl 28.13 | bleu 12.81 | wps 3057 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.81
2022-03-23 20:56:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:56:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 20:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.81) (writing took 0.763161791022867 seconds)
2022-03-23 20:56:32 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:56:32 | INFO | train | epoch 014 | loss 5.177 | ppl 36.17 | wps 7816.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.36 | loss_scale 4 | train_wall 444 | gb_free 13.2 | wall 7128
2022-03-23 20:56:32 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:56:54 | INFO | train_inner | epoch 015:      7 / 157 loss=5.18, ppl=36.24, wps=7307.4, ups=0.29, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=1.343, loss_scale=4, train_wall=278, gb_free=13.5, wall=7149
2022-03-23 21:01:35 | INFO | train_inner | epoch 015:    107 / 157 loss=4.938, ppl=30.64, wps=8890.7, ups=0.36, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=1.288, loss_scale=4, train_wall=281, gb_free=13.3, wall=7430
2022-03-23 21:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:04:02 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use chemical chemical rays.
2022-03-23 21:04:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:04:09 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 miles in the restaurant in the restaurant.
2022-03-23 21:04:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:04:15 | INFO | fairseq.tasks.translation | example hypothesis: these magnets can also be able to be able to make a very popular bible bible of forms.
2022-03-23 21:04:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:04:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his father, his father had been pregnant with his pregnant pregnant.
2022-03-23 21:04:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:04:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my couver is died in aids, and a child has died a child, so we asked us what do we do?
2022-03-23 21:04:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:04:34 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about how to talk about things like gender and not talk about the nuclear weapons of poverty or poverty or poverty or other weapons.
2022-03-23 21:04:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:04:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bbass is from magnetic magnetic lines, but if you don't want to move it, but if you don't need your movements, you don't need your energy, you need your energy and you need to move your energy.
2022-03-23 21:04:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:04:47 | INFO | fairseq.tasks.translation | example hypothesis: if we use the information to use the reflection of this reflection, we can start with a traditional traditional factors, and we can start able to begin to start with the interfaces of the shape of the shape of the shape of the shape of the information, and then the information is all the information, and the information that's going through it's going through it.
2022-03-23 21:04:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:04:55 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that we're doing is interesting, and it's interesting for me to be here for ted4 women, "yes, that it's the best time, it's the best time when someone said," oh, "if you're going to say," if you're going to say, "if you're going to have a long time to take it up with you're going to take a long time," oh, "oh," oh, "and then you're going to take it's going to take it's going to take a long time for you're going to take it's going to take a long time for you're going to take it," oh, "oh," oh, "oh, you're going to take it's going to take a long time for you're going to take a long time for you're going to take it," oh,
2022-03-23 21:04:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:04:58 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, if we're still able to use the mother, and a big part of the design design, we had to solve the plane on our plane, we had to solve the unique problems that we had to solve it, that it was able to solve it, to solve it, to solve it, to solve it's a unique, and that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to solve the
2022-03-23 21:04:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:04:58 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.483 | ppl 22.37 | bleu 14.17 | wps 2972.8 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 14.17
2022-03-23 21:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 21:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 14.17) (writing took 0.7886279760859907 seconds)
2022-03-23 21:04:58 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 21:04:58 | INFO | train | epoch 015 | loss 4.901 | ppl 29.88 | wps 7799.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.232 | loss_scale 4 | train_wall 443 | gb_free 13.2 | wall 7634
2022-03-23 21:04:59 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 21:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:07:22 | INFO | train_inner | epoch 016:     50 / 157 loss=4.832, ppl=28.49, wps=7275.2, ups=0.29, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=1.131, loss_scale=4, train_wall=285, gb_free=13.9, wall=7778
2022-03-23 21:12:04 | INFO | train_inner | epoch 016:    150 / 157 loss=4.521, ppl=22.96, wps=8914.6, ups=0.36, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=1.18, loss_scale=4, train_wall=281, gb_free=13.3, wall=8059
2022-03-23 21:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:12:29 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical chemical use.
2022-03-23 21:12:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:12:35 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 80,000 places in the restaurant.
2022-03-23 21:12:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:12:41 | INFO | fairseq.tasks.translation | example hypothesis: these magnets can also, of course, i can also avoid a popular bicycle.
2022-03-23 21:12:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:12:46 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had been pregnant when she was pregnant.
2022-03-23 21:12:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:12:52 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died, and a phanphantom child said, "well, what do we do?
2022-03-23 21:12:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:12:58 | INFO | fairseq.tasks.translation | example hypothesis: so we spend time to talk about things like gender gender and not talking about the nuclear weapons of nuclear weapons or poverty.
2022-03-23 21:12:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:13:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field of magnetic magnetic lines, but if you don't move, if you don't need your movements, you don't need your movements and so forth.
2022-03-23 21:13:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:13:11 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection comes from reflection, we can start with a traditional face of the face of the texts, and the real shape of the face of the structure, and the whole structure of this structure.
2022-03-23 21:13:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:13:18 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that we're doing is interesting, and it's interesting to take me here for tedra women. "yes, it's the best time that somebody said,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 21:13:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:13:20 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of the airplane that we had to use on our plane, and we had to solve the unique problems that we had to solve it, and we had to use it, and that it's all of us, and it's all of the way that there's a very different combination of the current system, and we've got to use, and we've got to use, and we've got to see it, and we've got to see it, and it, or a big, and we've got to see it, or a big, which is, and we've got to use it, or a big, and we've got to see it in the general general, and we've got to be a big, or the current current current current current current current current current current current current current current system, and we've got to see that it, and we've got to be a lot of the latest, and we had to see it, and we had to
2022-03-23 21:13:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:13:20 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.341 | ppl 20.27 | bleu 15.8 | wps 3221.9 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.8
2022-03-23 21:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:13:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:13:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 15.8) (writing took 0.8818810950033367 seconds)
2022-03-23 21:13:21 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:13:21 | INFO | train | epoch 016 | loss 4.611 | ppl 24.43 | wps 7858.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.162 | loss_scale 4 | train_wall 444 | gb_free 13.4 | wall 8136
2022-03-23 21:13:21 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:17:54 | INFO | train_inner | epoch 017:     93 / 157 loss=4.394, ppl=21.03, wps=7387.4, ups=0.29, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=1.046, loss_scale=4, train_wall=292, gb_free=13.4, wall=8410
2022-03-23 21:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:20:53 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:20:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:20:59 | INFO | fairseq.tasks.translation | example hypothesis: then it can be about 8,000 places in the restaurant.
2022-03-23 21:20:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:21:05 | INFO | fairseq.tasks.translation | example hypothesis: i can also increase these magnets, of course, of course, i can also reduce a popular bike.
2022-03-23 21:21:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:21:11 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned to leave his mother when she was pregnant with him pregnant.
2022-03-23 21:21:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:21:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousine is died and a phanphantom child, so we asked us, so what do we do with her?
2022-03-23 21:21:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:21:24 | INFO | fairseq.tasks.translation | example hypothesis: so so we spend our time to talk about things like gender times and not talking about the same time we're talking about nuclear weapons or the nuclear weapons of poverty or any other topic.
2022-03-23 21:21:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:21:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic magnetic lines are starting in the field of magnetic field, but the susususususuer doesn't move when they need your movements, and so the energy needs.
2022-03-23 21:21:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:21:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that can start with a traditional face of the face of the face, and there's a real shape of the information, and then through it, and it's all the structure of the structure of the structure, and the structure of the structure, and it's all the structure of the structure of this structure, the structure.
2022-03-23 21:21:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:21:45 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, one of the reasons that it's interesting and measure it's interesting to be here for me to be here in tedra women, "yes, in fact, the best time, when someone said," somebody said, "somebody said," when they say, "'' men," and then we're going to support them to help you know, "the women's first interesting," and then we're going to help you know, "the truth," the truth is that the truth is that the truth is the truth is that the truth is that there's a s.ra ra ra ra ra ra ra ra ra ra ra ra ra ra ra and then we've got a long time we've got a long time we're going to help you're going to help you're going to help you're going to help you're going to help you're going to help you
2022-03-23 21:21:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:21:47 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, the mother still is still the mother of the invention of invention, and a big part of design work that we have to solve on our airplane, and that we had to solve a unique result that we had to solve all the problems that were connected to us to the soil, and we have to see all the soil, if we have to see it, it's all sorts of isolated by the soil, we need to the soil, we need to see the soil, or to see it's a high-high-tech system, to the soil, we need to see that it's a heat heat heat heat heat, to the soil, we need to the soil, or to see it's a high-tech system, and we need to see that it's a high-tech system, to the soil, to the soil, we have to see that it's a high-tech system, we need to the soil, to the soil, or to the soil, we have to the soil, to the soil, to see it, or to the first
2022-03-23 21:21:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:21:47 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.109 | ppl 17.25 | bleu 17.47 | wps 2992.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17.47
2022-03-23 21:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:21:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.47) (writing took 0.8029077700339258 seconds)
2022-03-23 21:21:48 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:21:48 | INFO | train | epoch 017 | loss 4.338 | ppl 20.22 | wps 7784.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.059 | loss_scale 4 | train_wall 445 | gb_free 13.7 | wall 8644
2022-03-23 21:21:49 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:23:31 | INFO | train_inner | epoch 018:     36 / 157 loss=4.223, ppl=18.67, wps=7246.6, ups=0.3, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=1.115, loss_scale=4, train_wall=275, gb_free=13.6, wall=8747
2022-03-23 21:28:18 | INFO | train_inner | epoch 018:    136 / 157 loss=4.151, ppl=17.77, wps=8902.2, ups=0.35, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=1.049, loss_scale=4, train_wall=286, gb_free=13.2, wall=9033
2022-03-23 21:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:29:18 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:29:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:29:25 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 21:29:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:29:31 | INFO | fairseq.tasks.translation | example hypothesis: this is what i can also suggest, of course, to form a popular bible.
2022-03-23 21:29:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:29:37 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother, when she was pregnant.
2022-03-23 21:29:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:29:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples is died to aids and a phanphanage child, so we said, "well, what do we do with?
2022-03-23 21:29:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:29:49 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about the spread of nuclear weapons or the lack of poverty.
2022-03-23 21:29:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:29:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic magnetic magnetic magnetic magnetic lines are starting to start in the inside of the inside, but the suck doesn't like, if you need to move your movements, your movements, and you need your energy, and you need to get your energy.
2022-03-23 21:29:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:30:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional face, we can start with a traditional facial face, and the real shape of the face, and there's the information, and it's the structure of the structure, and the structure of the structure, and the structure of the structure.
2022-03-23 21:30:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:30:09 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measuring interesting, for me, for tedsters, "is that..." well, as a long time, as someone said, "and then," and then, "if we're going to help you," and then, "the truth is," for you. "
2022-03-23 21:30:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:30:12 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, the mother is still the invention of invention, and a big part of design work that we're on our plane, to see is that we had to solve the unique problems that we had to solve, and to be able to be able to be able to be able to be able to the air, and to the air system, and to be able to be able to be able to be able to be able to the air, and to the air, and to be in the air, and to the air, and to the air system, and to the air, and to the air, and to the air, and to be the air, and to the air, and to the air system, and to be the air.
2022-03-23 21:30:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:30:12 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.87 | ppl 14.62 | bleu 20.31 | wps 3128.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.31
2022-03-23 21:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:30:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.31) (writing took 0.8808947009965777 seconds)
2022-03-23 21:30:12 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:30:12 | INFO | train | epoch 018 | loss 4.145 | ppl 17.7 | wps 7832.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.1 | loss_scale 4 | train_wall 443 | gb_free 14.3 | wall 9148
2022-03-23 21:30:13 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:33:54 | INFO | train_inner | epoch 019:     79 / 157 loss=3.989, ppl=15.88, wps=7268.5, ups=0.3, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=1.052, loss_scale=4, train_wall=276, gb_free=13.2, wall=9370
2022-03-23 21:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:37:44 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:37:44 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:37:49 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 21:37:49 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:37:55 | INFO | fairseq.tasks.translation | example hypothesis: these rough magnets, of course, i can also depend up to form a popular bias.
2022-03-23 21:37:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:38:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left with him pregnant.
2022-03-23 21:38:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:38:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples has died to aids and got a wake child, so we asked, what do we do with?
2022-03-23 21:38:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:38:12 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 21:38:12 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:38:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some bellull lines of magnetic field, but the superconductor doesn't seem to move when they're moving, because they don't need to move their movements.
2022-03-23 21:38:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:38:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial factors of the face of the face of the face and the basic shape of the face of the face.
2022-03-23 21:38:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:38:30 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that makes it interesting and measuring you to be here in tedwomen.
2022-03-23 21:38:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:38:33 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, the mother's invention of invention, and a big part of design that we're on on the plane, was a result of it.
2022-03-23 21:38:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:38:33 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.752 | ppl 13.47 | bleu 19.36 | wps 3322.6 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.31
2022-03-23 21:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:38:33 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:38:33 | INFO | train | epoch 019 | loss 3.935 | ppl 15.3 | wps 7891.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.011 | loss_scale 4 | train_wall 444 | gb_free 13.9 | wall 9648
2022-03-23 21:38:33 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:38:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:39:34 | INFO | train_inner | epoch 020:     22 / 157 loss=3.93, ppl=15.24, wps=7410.5, ups=0.29, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.988, loss_scale=4, train_wall=284, gb_free=14.1, wall=9710
2022-03-23 21:44:24 | INFO | train_inner | epoch 020:    122 / 157 loss=3.634, ppl=12.41, wps=8939.4, ups=0.35, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.918, loss_scale=4, train_wall=289, gb_free=22.4, wall=9999
2022-03-23 21:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:46:04 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:46:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:46:10 | INFO | fairseq.tasks.translation | example hypothesis: this is about 8,000 places in restaurant.
2022-03-23 21:46:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:46:16 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this tiny magnets to form a popular bike.
2022-03-23 21:46:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:46:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 21:46:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:46:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids and had a wash child, so we asked us what do we do with her?
2022-03-23 21:46:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:46:33 | INFO | fairseq.tasks.translation | example hypothesis: so that's why we spend time talking about things like gender times and not about genocide or poverty or poverty or every other issue.
2022-03-23 21:46:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:46:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bellle of magnetic field are starting in the inner lines, but the superconductor doesn't like when they move, when they need their movements, and so the sucks of altitude.
2022-03-23 21:46:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:46:46 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional face that can start the big confrontier of face and the basic shape of facial factors, and the information, through that information, which gives them all the structure of these ports and fold.
2022-03-23 21:46:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:46:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen is that -- yes, in fact, when someone said, "listen to the best one of the men who said," listen to you guys who start to a table, and then when you're going to say, and then when you're going to help them, "shrony."
2022-03-23 21:46:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:46:55 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of design work that we're in our plane, was a result that we had to solve the unique problems that we had to solve the unique problems that they had to be connected to the ground -- all the way to the ground -- all the way of the way that they're working on the ground, and that they're going to be able to be able to be able to put it into a traffic, or a traffic system, or a traffic system, or a traffic system, or a traffic system, or a traffic system, or a pioneer, or a pioneer, or a traffic system, or a traffic system, or a pioneer, when we're put it's put it into a pioneer, or a pioneer, or a pioneer, or a pioneer, or a traffic system, or a traffic system that it, either, when we're put it into the heat, or a pioneer, it, or a
2022-03-23 21:46:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:46:55 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.552 | ppl 11.73 | bleu 22.29 | wps 3228.9 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.29
2022-03-23 21:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.29) (writing took 0.8543993150815368 seconds)
2022-03-23 21:46:56 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:46:56 | INFO | train | epoch 020 | loss 3.72 | ppl 13.17 | wps 7853 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.955 | loss_scale 4 | train_wall 445 | gb_free 14.2 | wall 10151
2022-03-23 21:46:56 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:50:02 | INFO | train_inner | epoch 021:     65 / 157 loss=3.703, ppl=13.02, wps=7282.6, ups=0.3, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.968, loss_scale=4, train_wall=280, gb_free=14.2, wall=10338
2022-03-23 21:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:54:27 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:54:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:54:33 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 21:54:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:54:39 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this rough magnets.
2022-03-23 21:54:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:54:44 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his mother had left his mother when she was pregnant.
2022-03-23 21:54:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:54:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died on aids and has a phanage child, so we said, well, what do we do with?
2022-03-23 21:54:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:54:56 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 21:54:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:55:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic fields are starting in the inner lines, but the superconductor doesn't like when they move their movements, and so the superconductor disorders.
2022-03-23 21:55:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:55:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big configurations of the face and the real shape of the information, and through this one of the single information that makes all the ports and fold the structure.
2022-03-23 21:55:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:55:14 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to be here at tedwomen is that... yes, when someone said, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [you go to the men and tell you, and then the truth starts to support the truth.
2022-03-23 21:55:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:55:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of design that we're in our plane was a result that we had to solve the unique problems that were connected to the soil -- all the way to a continually reliable solar solar system, and that they could use a fixed solar solar system, and that they're allowed us to see that there would be no reliable, to make a progressive and that they could either be a source of the pancreationally reliable solar solar solar solar panels in the way.
2022-03-23 21:55:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:55:16 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.424 | ppl 10.73 | bleu 23.02 | wps 3366.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.02
2022-03-23 21:55:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:55:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:55:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 21:55:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.02) (writing took 0.8915649577975273 seconds)
2022-03-23 21:55:17 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:55:17 | INFO | train | epoch 021 | loss 3.542 | ppl 11.65 | wps 7878.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.885 | loss_scale 4 | train_wall 445 | gb_free 13.9 | wall 10653
2022-03-23 21:55:17 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:55:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:55:42 | INFO | train_inner | epoch 022:      8 / 157 loss=3.464, ppl=11.04, wps=7457.6, ups=0.29, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.862, loss_scale=4, train_wall=284, gb_free=13.9, wall=10678
2022-03-23 22:00:26 | INFO | train_inner | epoch 022:    108 / 157 loss=3.468, ppl=11.07, wps=8898.8, ups=0.35, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.948, loss_scale=4, train_wall=283, gb_free=13.4, wall=10962
2022-03-23 22:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:02:48 | INFO | fairseq.tasks.translation | example hypothesis: these sonic rockets can't use chemical rockets.
2022-03-23 22:02:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:02:53 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in restaurant.
2022-03-23 22:02:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:03:00 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnetic magnets.
2022-03-23 22:03:00 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:03:05 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his mother had left his mother when she was pregnant.
2022-03-23 22:03:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:03:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died to aids, so we asked us well what do we do with her?
2022-03-23 22:03:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:03:17 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 22:03:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:03:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic fields are caught in inside inside, but the superconductor doesn't like when they move their movements, and so the superconductor disorder.
2022-03-23 22:03:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:03:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, the big constructures of the face and the basic form, and then repair it through the information that puts all the ports and fold.
2022-03-23 22:03:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:03:34 | INFO | fairseq.tasks.translation | example hypothesis: , th th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... tyes, when he said, "when someone said," you know, you know, it's already started to help the men and say, "if you're going to support the truth."
2022-03-23 22:03:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:03:37 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still invention, and a big part of design that we're on our plane, was a result that we had to solve the unique problems that were connected to it was to operate on the ground -- all sorts of continuing to produce a continually cooling system, and that allows us to use a portable vehicle, either in the vehicle, or the vehicle, if we're going to be able to use the vehicle, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to move the vehicle, or the same, or the vehicle, or the vehicle, or the vehicle, or the vehicle, or the vehicle, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a
2022-03-23 22:03:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:03:37 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.348 | ppl 10.18 | bleu 22.84 | wps 3322.2 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.02
2022-03-23 22:03:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 22:03:37 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 22:03:37 | INFO | train | epoch 022 | loss 3.419 | ppl 10.69 | wps 7898.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.892 | loss_scale 4 | train_wall 444 | gb_free 14.2 | wall 11152
2022-03-23 22:03:37 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 22:03:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:06:04 | INFO | train_inner | epoch 023:     51 / 157 loss=3.237, ppl=9.43, wps=7432.8, ups=0.3, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.828, loss_scale=4, train_wall=283, gb_free=14.2, wall=11300
2022-03-23 22:10:44 | INFO | train_inner | epoch 023:    151 / 157 loss=3.322, ppl=10, wps=8879, ups=0.36, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.881, loss_scale=4, train_wall=279, gb_free=13.4, wall=11579
2022-03-23 22:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:11:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 22:11:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:11:14 | INFO | fairseq.tasks.translation | example hypothesis: he can do about 8,000 places in the restaurant.
2022-03-23 22:11:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:11:20 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand, to form a popular equivalent of shape.
2022-03-23 22:11:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:11:26 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 22:11:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:11:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died on aids, and there's an orphanage child left, so we asked us, well, what do we do with?
2022-03-23 22:11:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:11:38 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or the prevalence of nuclear weapons or poverty.
2022-03-23 22:11:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:11:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field lines are trapped inside the inner lines, but the superconductor doesn't like it, if you're moving movements, and so the superconductor disorder.
2022-03-23 22:11:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:11:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that gives the big configuration of the face and the basic shape of information, which includes all the ports and all the structure of the structure of the fabric.
2022-03-23 22:11:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:11:57 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and measured it to be here at tedwomen is that... tyes, when someone said, "turn you to the men on your table and say," if you're going to support the revolution, we're going to support the truth, "and then the truth is that we're already supported to help you've already started, and then we've already started to help you have a great theme is that you've already started," norman is that you've already started, "norman's already started to have already started," northra ra ra rocket, "] ["] ["] ["] ["] ["] ["
2022-03-23 22:11:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:12:00 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of design work that we're on our plane, was a result that we had to solve unique problems that were operating on the ground -- all of a continually variation of a continually variation, and that allows us to use a refrigeration system, and allows us to be interrupted, and that it was a mechanical, it was a mechanical, it was also a mechanical, and it would be a mechanical, it would be, and it would be also allows us to see that we're also a propulsed by a mechanical, it would be a mechanical, and it was also a mechanical, to be a mechanical, and it would be built, to be built, and it would be, it was also a mechanical, and it would be built, to be built by the interrupted, and it would be more interrupted, and it would be, and it would be a mechanical, and
2022-03-23 22:12:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:12:00 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.113 | ppl 8.65 | bleu 26.27 | wps 3181.6 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.27
2022-03-23 22:12:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:12:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:12:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.27) (writing took 0.8872338919900358 seconds)
2022-03-23 22:12:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:12:01 | INFO | train | epoch 023 | loss 3.26 | ppl 9.58 | wps 7838.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.863 | loss_scale 4 | train_wall 445 | gb_free 13.8 | wall 11656
2022-03-23 22:12:01 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:12:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:16:27 | INFO | train_inner | epoch 024:     94 / 157 loss=3.1, ppl=8.57, wps=7321.3, ups=0.29, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.807, loss_scale=4, train_wall=285, gb_free=13.5, wall=11923
2022-03-23 22:19:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:19:33 | INFO | fairseq.tasks.translation | example hypothesis: these sonic rockets can't use chemical rockets.
2022-03-23 22:19:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:19:39 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 22:19:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:19:44 | INFO | fairseq.tasks.translation | example hypothesis: that round magnets, of course, i can expand to form a popular equal equal equal equal.
2022-03-23 22:19:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:19:50 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant.
2022-03-23 22:19:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:19:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died on aids, and a wais-child, so we asked, well, what do we do with her?
2022-03-23 22:19:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:20:02 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and we don't know about nuclear weapons or poverty or any other promising topic.
2022-03-23 22:20:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:20:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic fields are caught in the inner inner lines, but the superconductor doesn't like when they move, because their movements use, and so the superconductive disorder.
2022-03-23 22:20:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:20:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face, which is the big constructures of the face and the basic shape, and repair it through the threshold of all the ports and fold all the porting structure.
2022-03-23 22:20:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:20:20 | INFO | fairseq.tasks.translation | example hypothesis: finally, one of the reasons that makes it interesting and measured for me here at tedwomen, is that... tyes, who was the most committed when somebody said, "stop you guys at your table and say," if the revolution begins to be able to be able to support you. "
2022-03-23 22:20:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:20:21 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of design work that we're on our airplane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a continually variation system that allows us to exploit on the ground, if you're going to use it.
2022-03-23 22:20:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:20:21 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.007 | ppl 8.04 | bleu 26.25 | wps 3377.8 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.27
2022-03-23 22:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:20:21 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:20:21 | INFO | train | epoch 024 | loss 3.119 | ppl 8.69 | wps 7889 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.8 | loss_scale 4 | train_wall 445 | gb_free 13.5 | wall 12157
2022-03-23 22:20:22 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:22:03 | INFO | train_inner | epoch 025:     37 / 157 loss=3.1, ppl=8.58, wps=7391.1, ups=0.3, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.79, loss_scale=4, train_wall=281, gb_free=14.3, wall=12259
2022-03-23 22:26:48 | INFO | train_inner | epoch 025:    137 / 157 loss=3.05, ppl=8.28, wps=8893.4, ups=0.35, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.879, loss_scale=4, train_wall=285, gb_free=13.3, wall=12544
2022-03-23 22:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:27:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 22:27:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:27:59 | INFO | fairseq.tasks.translation | example hypothesis: he can save about 8,000 places in the restaurant.
2022-03-23 22:27:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:28:05 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet can also expand, of course, to form any popular glimpse.
2022-03-23 22:28:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:28:10 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 22:28:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:28:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died on aids and left a waisenchild, so we said, well, what do we do with her?
2022-03-23 22:28:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:28:22 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:28:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:28:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble lines are caught in the inner lines, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 22:28:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:28:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructures of the face and the basic form, and restoring it through the absolute information that the whole porter structure and all the folds.
2022-03-23 22:28:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:28:41 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it really interesting and measured for me here at tedwomen is that... tyes, when it was stripped out, it was the best together when someone said, "shut on the men on a table and say," well, if the revolution starts to be able to support you. "
2022-03-23 22:28:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:28:43 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation, all the way to a continuous variation, all of a continuous variation, and allows us to make a cooling system that allows us to see, and then you to use the cooling on the atmosphere, and then you to make it easier to make it more reliable, if you get rid of a spacecraft to operate in the atmosphere, to operate, and then you can see that would be able to operate in the distance, you see that would be able to operate in the atmosphere, to operate, to operate, you see that would be able to operate at the same way.
2022-03-23 22:28:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:28:43 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.938 | ppl 7.66 | bleu 27.69 | wps 3252.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.69
2022-03-23 22:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 27.69) (writing took 0.9059357671067119 seconds)
2022-03-23 22:28:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:28:44 | INFO | train | epoch 025 | loss 3.028 | ppl 8.16 | wps 7850.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.838 | loss_scale 4 | train_wall 445 | gb_free 13.3 | wall 12660
2022-03-23 22:28:45 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:32:32 | INFO | train_inner | epoch 026:     80 / 157 loss=2.909, ppl=7.51, wps=7373.3, ups=0.29, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.782, loss_scale=4, train_wall=286, gb_free=13.5, wall=12888
2022-03-23 22:36:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:36:16 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 22:36:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:36:22 | INFO | fairseq.tasks.translation | example hypothesis: he can travel about 8,000 places in the restaurant.
2022-03-23 22:36:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:36:28 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets.
2022-03-23 22:36:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:36:34 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father because his father had left his mother when she was pregnant.
2022-03-23 22:36:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:36:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids, and we asked us a wais-child, so we asked us, well, what do we do with?
2022-03-23 22:36:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:36:46 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:36:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:36:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorder.
2022-03-23 22:36:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:36:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which is the big constructures of facial facial and the basic shape, and by the theast information, which draws the entire porter structure and all the folds.
2022-03-23 22:36:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:37:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen is that... tyes, when controversial dinner became the best summarized as someone said, "turn you to men at dtable and say," if the revolution starts to support you. "
2022-03-23 22:37:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:37:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continual variation and a system that allows us to use a hardware engine, either if you can use the vehicle, if you can use the vehicle, or you can use the regulations, if you can use the engine, if you can use it, or you can use it, if you can use it's a specific traffic, if you can use the engine, if you can use the engine, if you can use the engine, or you can use it, if you can use it, if you can use it, or you can use it, if you can use it, if you can use it, if you can use it, if you can use it, you can use it, you can use it, you can use it's automainframe, you can use it,
2022-03-23 22:37:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:37:06 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.887 | ppl 7.4 | bleu 27.48 | wps 3274.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 27.69
2022-03-23 22:37:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:37:06 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:37:06 | INFO | train | epoch 026 | loss 2.907 | ppl 7.5 | wps 7864.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.794 | loss_scale 4 | train_wall 446 | gb_free 12.9 | wall 13162
2022-03-23 22:37:07 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:38:14 | INFO | train_inner | epoch 027:     23 / 157 loss=2.912, ppl=7.53, wps=7385.6, ups=0.29, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.818, loss_scale=4, train_wall=285, gb_free=13.2, wall=13229
2022-03-23 22:42:57 | INFO | train_inner | epoch 027:    123 / 157 loss=2.805, ppl=6.99, wps=8819.7, ups=0.35, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.752, loss_scale=4, train_wall=283, gb_free=13.7, wall=13512
2022-03-23 22:44:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:44:40 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 22:44:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:44:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 22:44:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:44:52 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnet, of course, to make any equivalent of shape.
2022-03-23 22:44:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:44:58 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 22:44:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:45:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died on aids and left a phantom, so we asked ourselves, well, what do we do with them?
2022-03-23 22:45:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:45:10 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or distribution of nuclear weapons or poverty or any other promising issue.
2022-03-23 22:45:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:45:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs are caught by magnet field lines, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 22:45:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:45:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big configurations of the face and the basic shape, and restoring it through the one of these single information that makes the entire porter structure and all a fold.
2022-03-23 22:45:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:45:28 | INFO | fairseq.tasks.translation | example hypothesis: i think one of the reasons that makes it interesting and measured for me here at tedwomen is that... tja, dinner has been put it best together when someone said, "take you to the men in your table and say," if the revolution starts to support you. "
2022-03-23 22:45:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:45:30 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of design work that we're on our plane at the stest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a system that allows us to use an aircraft, either when you see a portable vehicle, if you take the vehicle, or you put it in a particular vehicle, if you see the sun, or the vehicle, if you put it into a particular vehicle, or the vehicle, if you put it into a particular vehicle, if you put it, you get the same thing, or the vehicle, if you put it to the vehicle, you get the vehicle, you get the same thing, or the vehicle, you get it to the same thing, if you get it to the vehicle, you see the same thing, if you get it to the vehicle, you get it to the same thing, and you get it to the same thing, and you put it to the same thing, or
2022-03-23 22:45:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:45:30 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.789 | ppl 6.91 | bleu 28.42 | wps 3278.9 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.42
2022-03-23 22:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:45:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 28.42) (writing took 0.8508152607828379 seconds)
2022-03-23 22:45:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:45:31 | INFO | train | epoch 027 | loss 2.792 | ppl 6.92 | wps 7827.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.77 | loss_scale 4 | train_wall 447 | gb_free 13 | wall 13667
2022-03-23 22:45:31 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:48:42 | INFO | train_inner | epoch 028:     66 / 157 loss=2.72, ppl=6.59, wps=7356.1, ups=0.29, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.756, loss_scale=4, train_wall=288, gb_free=13.4, wall=13858
2022-03-23 22:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:53:04 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 22:53:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:53:10 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 22:53:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:53:16 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to make any glimpse.
2022-03-23 22:53:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:53:21 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 22:53:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:53:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died at aids, and we left a waisenchild, so we asked ourselves, well what do we do with them?
2022-03-23 22:53:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:53:34 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:53:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:53:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic fields are caught in the inner, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 22:53:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:53:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that recovers the big constellation of the face and the basic shape, and recovers it through that one piece of information that draws all the portraits the fabric structure and all the fits it.
2022-03-23 22:53:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:53:51 | INFO | fairseq.tasks.translation | example hypothesis: i mean, one of the reasons that makes it interesting and appropriate to me here at tedwomen is that... tja, when controversial dinner, it was the best thing when someone said, "turn to men on your table and say," if the revolution starts to support you. "the truth is that we've already supported you for you."
2022-03-23 22:53:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:53:54 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design work that we are on our plane at the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a robotic aircraft on the surface, and if you're in the surface, you have to get rid of a little bit more sophisticated, you can see the propeller, you can get rid of a mechanism, you can get rid of the device, and you can get rid of the speed up when you can get rid of the speed up, you can get rid of a bit more sophisticated, you get rid of a bit more sophisticated, you get rid of the speed up, you can get rid of the vehicle, you can get rid of a bit more sophisticated mechanism, and you can get rid of the speed up, you get rid of the speed up, and you get rid of the device,
2022-03-23 22:53:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:53:54 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.687 | ppl 6.44 | bleu 28.72 | wps 3303.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.72
2022-03-23 22:53:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:53:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:53:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 22:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.72) (writing took 0.8524305638857186 seconds)
2022-03-23 22:53:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:53:55 | INFO | train | epoch 028 | loss 2.71 | ppl 6.55 | wps 7840.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.784 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 14170
2022-03-23 22:53:55 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:54:23 | INFO | train_inner | epoch 029:      9 / 157 loss=2.676, ppl=6.39, wps=7373.6, ups=0.29, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.772, loss_scale=4, train_wall=284, gb_free=13.7, wall=14199
2022-03-23 22:59:09 | INFO | train_inner | epoch 029:    109 / 157 loss=2.612, ppl=6.11, wps=8851.1, ups=0.35, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.776, loss_scale=4, train_wall=285, gb_free=14.1, wall=14484
2022-03-23 23:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:01:28 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 23:01:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:01:33 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 23:01:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:01:39 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can expand that silent magnets.
2022-03-23 23:01:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:01:45 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 23:01:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:01:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and we asked us, well, what do we do with them?
2022-03-23 23:01:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:01:57 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or distribution of nuclear weapons or poverty or any other promising topic.
2022-03-23 23:01:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:02:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic fields are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder.
2022-03-23 23:02:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:02:09 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection, which is restoring the big constitution of the face and basic form, and draws it through the absolute information that draws all the porter structure and all a folding.
2022-03-23 23:02:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:02:15 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting, and measured for me here at tedwomen is that... tja, when it was stripped, it was best, when somebody said, "shut on your table, and say," if the revolution begins, we supported you. '"the truth is that women, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, it's
2022-03-23 23:02:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:02:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a large part of the design work that we're stumbling at our plane was a result that we had to solve the unique problems that were connected to operate -- all from a continuous variation, and a system that allows us to do with the aircraft, or the aircraft, or the aircraft, or if you move the air, or the aircraft, or the air, or the air, or if you move, or the water, or the water, or the air, or the air, or the air, or the air, or if you move, if you put it in the air, or the air, or the air, or the air, or the water, or the air, you get the air, or the air, you get the water, you put it in the air, or the air, you get the air, you put it in the air, or the air, you get the air, you get the air, you get the air, you know, or
2022-03-23 23:02:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:02:17 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.662 | ppl 6.33 | bleu 27.85 | wps 3307.4 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.72
2022-03-23 23:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 23:02:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 23:02:17 | INFO | train | epoch 029 | loss 2.589 | ppl 6.02 | wps 7855.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.767 | loss_scale 4 | train_wall 447 | gb_free 14 | wall 14673
2022-03-23 23:02:18 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 23:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:04:48 | INFO | train_inner | epoch 030:     52 / 157 loss=2.501, ppl=5.66, wps=7348.5, ups=0.29, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.773, loss_scale=4, train_wall=283, gb_free=13.9, wall=14824
2022-03-23 23:09:31 | INFO | train_inner | epoch 030:    152 / 157 loss=2.525, ppl=5.76, wps=8887, ups=0.35, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.752, loss_scale=4, train_wall=282, gb_free=13.5, wall=15107
2022-03-23 23:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:09:51 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 23:09:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:09:57 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 23:09:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:10:03 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand these round magnets to make any glimpse.
2022-03-23 23:10:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:10:09 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his dad, because his dad had left his mother when she was pregnant with him.
2022-03-23 23:10:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:10:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins have died in aids and left a waisenchild, so we asked ourselves, well, what do we do with her?
2022-03-23 23:10:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:10:21 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 23:10:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:10:27 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of the magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and the superconductive disorder.
2022-03-23 23:10:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:10:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which is repeating the big configuration of the face and the basic shape, and deployment it through that single information that draws the whole porter structure and all a folding fold.
2022-03-23 23:10:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:10:40 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and measured for me here at tedwomen, is that... tja, has been summed by controversial dinner, when someone said, "turn on the men on your table and say," if the revolution starts to help you. '"the truth is that we've already been supporting you for a long time of sand chairs," and then we've already been supporting you, "windmills"] "]"
2022-03-23 23:10:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:10:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- all of us from a continuous variation and a refrigeration system that allows us to use an aircraft, to either be adapted to a vehicle, to the air, or a particular, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate, either be able to operate, or a vehicle, to operate, to operate, or a vehicle, or a vehicle, to operate, either if you can see the wheel, to the same thing that would be able to be able to be able to be able to be able to move the wheel, to the wheel, to a vehicle, to the wheel, to be able to be able to
2022-03-23 23:10:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:10:42 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.542 | ppl 5.82 | bleu 30.39 | wps 3199.5 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.39
2022-03-23 23:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 23:10:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt
2022-03-23 23:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.39) (writing took 0.9231845298781991 seconds)
2022-03-23 23:10:43 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:10:43 | INFO | train | epoch 030 | loss 2.5 | ppl 5.66 | wps 7809.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.759 | loss_scale 4 | train_wall 447 | gb_free 13.5 | wall 15179
2022-03-23 23:10:43 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:15:15 | INFO | train_inner | epoch 031:     95 / 157 loss=2.401, ppl=5.28, wps=7297.6, ups=0.29, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.783, loss_scale=4, train_wall=285, gb_free=14, wall=15450
2022-03-23 23:18:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:18:17 | INFO | fairseq.tasks.translation | example hypothesis: they can't use any chemical rockets.
2022-03-23 23:18:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:18:22 | INFO | fairseq.tasks.translation | example hypothesis: overyear, he can occur about 8,000 places in the restaurant.
2022-03-23 23:18:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:18:28 | INFO | fairseq.tasks.translation | example hypothesis: , of course, these round magnets, i can also expand to form any kind of glimpse.
2022-03-23 23:18:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:18:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 23:18:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:18:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins have died at aids and left an orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 23:18:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:18:46 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not about genocide or the spread of nuclear weapons or poverty or any other talking about it.
2022-03-23 23:18:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:18:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like when they move, because they need energy, and so the superconductor disorder.
2022-03-23 23:18:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:18:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big configuration of the facial and the basic form, and by the details of the information that attracts the entire porter structure and all the fits.
2022-03-23 23:18:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:19:05 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and appropriate for me here at tedwomen, is that... tye, while striking dinner, it was the best summary, when someone said, "take you to the men in your table and say," if the revolution starts to support you. let's support you. "
2022-03-23 23:19:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:19:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're stumbling at our airplane was a result that we had to solve the uniquely problems that were connected to operate it on the ground -- everything from a continuous variation and a cooling system that allows us to do in the aircraft, or if you're going to use the vehicle for a specific cycle, or if you're going to move the vehicle, or if you're going to operate the vehicle, or if you're going to have to move the vehicle, or not to have to move the vehicle, or for a specific vehicle, if you.
2022-03-23 23:19:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:19:07 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.501 | ppl 5.66 | bleu 30.01 | wps 3255 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.39
2022-03-23 23:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:19:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:19:07 | INFO | train | epoch 031 | loss 2.414 | ppl 5.33 | wps 7837.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.808 | loss_scale 4 | train_wall 447 | gb_free 13.3 | wall 15683
2022-03-23 23:19:07 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:20:57 | INFO | train_inner | epoch 032:     38 / 157 loss=2.433, ppl=5.4, wps=7393.3, ups=0.29, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.867, loss_scale=4, train_wall=285, gb_free=14.5, wall=15792
2022-03-23 23:25:43 | INFO | train_inner | epoch 032:    138 / 157 loss=2.279, ppl=4.85, wps=8839.8, ups=0.35, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.736, loss_scale=4, train_wall=286, gb_free=13.7, wall=16078
2022-03-23 23:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:26:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 23:26:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:26:47 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 23:26:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:26:52 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand these round magnets to make any glimpse.
2022-03-23 23:26:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:26:58 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his dad closer because his father had left his mother when she was pregnant with him.
2022-03-23 23:26:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:27:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died on aids and left a orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 23:27:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:27:10 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 23:27:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:27:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements are energy, and the superconductor disrupted.
2022-03-23 23:27:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:27:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that gives the big configurations of the face and the basic form, and release it through the thief information that attracts all the porter structure and all the fine folds.
2022-03-23 23:27:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:27:28 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and measured for me here at tedwomen is that... tja, it was best summarized when someone said, "turn to men in your table and say," 'if the revolution begins, we support you.' "'" the truth is that we've already supported you for a long time with stone borra, "and then we've been supporting you for the future."
2022-03-23 23:27:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:27:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we are stumbling on our airplane was a result that we had to solve unique problems that were connected to operate on the ground -- everything from a continuously varied and a cooling system with refrigeration that allows us to use a stop-to-the aircraft, to either be a mechanical vehicle, or a bite, to the wheel, to a bite.
2022-03-23 23:27:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:27:29 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.418 | ppl 5.35 | bleu 30.16 | wps 3357.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.39
2022-03-23 23:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:27:29 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:27:29 | INFO | train | epoch 032 | loss 2.319 | ppl 4.99 | wps 7857.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.788 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 16185
2022-03-23 23:27:30 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:31:22 | INFO | train_inner | epoch 033:     81 / 157 loss=2.268, ppl=4.82, wps=7401.1, ups=0.29, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.823, loss_scale=4, train_wall=284, gb_free=13.1, wall=16417
2022-03-23 23:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:35:02 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 23:35:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:35:08 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 23:35:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:35:14 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand these round magnets to make any glimpse.
2022-03-23 23:35:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:35:19 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 23:35:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:35:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died in aids, and a waphanage kid, so we asked ourselves, well, what do we do with them?
2022-03-23 23:35:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:35:32 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not over anxiety or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 23:35:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:35:38 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some columns of magnetic rocks are trapped inside, but the superconductor doesn't like it if you move, because your movements are going, and so the superconductor disrupted.
2022-03-23 23:35:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:35:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face configuration that restores the big contextures of the face and the basic form of information, which includes the entire porter structure and all the fine folds.
2022-03-23 23:35:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:35:50 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it really interesting and reasonable, for me here at tedwomen, is that... tyes, when controversial dinner, it's the best thing to do when someone said, "turn to men at your table and tell them, 'when the revolution starts supporting you.'" 'well, we support you.' the truth is that we have already supported you for a long time. "
2022-03-23 23:35:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:35:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're stumbling at our plane was a result of that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a cooling system, and a cooling system with refrigeration that allows us to use a spacecraft, or if you're going to move it in the ground, or if you're going to move it in a little bit of a little bit of a vehicle, or if you're going to the right away, or if you're going to the ground, you're going to the same.
2022-03-23 23:35:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:35:53 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.387 | ppl 5.23 | bleu 29.86 | wps 3247.7 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 30.39
2022-03-23 23:35:53 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 23:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:35:53 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:35:53 | INFO | train | epoch 033 | loss 2.225 | ppl 4.68 | wps 7850.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.828 | loss_scale 4 | train_wall 446 | gb_free 13.4 | wall 16688
2022-03-23 23:35:53 | INFO | fairseq_cli.train | done training in 16687.7 seconds
