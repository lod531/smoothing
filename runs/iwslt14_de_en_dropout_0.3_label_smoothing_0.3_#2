Sender: LSF System <lsfadmin@eu-g3-060>
Subject: Job 210581541: <iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:25:12 2022
Job was executed on host(s) <eu-g3-060>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:25:24 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:25:24 2022
Terminated at Wed Mar 23 10:30:37 2022
Results reported at Wed Mar 23 10:30:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.3 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575612 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3906.76 sec.
    Max Memory :                                 4943 MB
    Average Memory :                             3747.64 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15057.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3914 sec.
    Turnaround time :                            3925 sec.

The output (if any) follows:

2022-03-23 09:25:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.3, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575612, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.3, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:25:30 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:25:30 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:25:30 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:25:30 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:25:30 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:25:30 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:25:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:25:30 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:25:30 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:25:33 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:25:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:33 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:25:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:25:33 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:25:33 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:25:33 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:25:33 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:25:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:25:33 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:25:33 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:25:33 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:25:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:25:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:26:09 | INFO | train_inner | epoch 001:    104 / 157 loss=12.349, nll_loss=11.874, ppl=3752.49, wps=80351, ups=3.17, wpb=25305.7, bsz=1024.9, num_updates=100, lr=1.25e-05, gnorm=2.587, loss_scale=8, train_wall=35, gb_free=14, wall=36
2022-03-23 09:26:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:26:35 | INFO | fairseq.tasks.translation | example hypothesis: the the the,,,,,,,,,,,,,,,,,
2022-03-23 09:26:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:26:41 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:41 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:45 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:26:51 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:58 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:00 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.057 | nll_loss 10.014 | ppl 1034.01 | bleu 0.01 | wps 5021.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.594910110012279 seconds)
2022-03-23 09:27:02 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:27:02 | INFO | train | epoch 001 | loss 12.012 | nll_loss 11.395 | ppl 2692.13 | wps 45324.2 | ups 1.8 | wpb 25225.5 | bsz 1001.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.028 | loss_scale 8 | train_wall 51 | gb_free 14 | wall 89
2022-03-23 09:27:02 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:17 | INFO | train_inner | epoch 002:     47 / 157 loss=11.218, nll_loss=10.269, ppl=1233.99, wps=36585.3, ups=1.45, wpb=25181.6, bsz=982.6, num_updates=200, lr=2.5e-05, gnorm=0.835, loss_scale=8, train_wall=31, gb_free=13.8, wall=105
2022-03-23 09:27:48 | INFO | train_inner | epoch 002:    147 / 157 loss=10.683, nll_loss=9.456, ppl=702.56, wps=81031.1, ups=3.23, wpb=25113.7, bsz=1018.9, num_updates=300, lr=3.75e-05, gnorm=1.223, loss_scale=8, train_wall=31, gb_free=13.8, wall=136
2022-03-23 09:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example hypothesis: and the.
2022-03-23 09:27:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:58 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and,,,,.
2022-03-23 09:27:58 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:28:01 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and.
2022-03-23 09:28:01 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the.
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i i.
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example hypothesis: we we,,,,,,,,,,.
2022-03-23 09:28:11 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:28:14 | INFO | fairseq.tasks.translation | example hypothesis: and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:14 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:28:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:24 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:28:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:24 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.466 | nll_loss 9.017 | ppl 518.1 | bleu 0.02 | wps 5617.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:28:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:28:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:28:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.6923639750020811 seconds)
2022-03-23 09:28:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:28:26 | INFO | train | epoch 002 | loss 10.783 | nll_loss 9.612 | ppl 782.44 | wps 47301.7 | ups 1.88 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.037 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 173
2022-03-23 09:28:26 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:55 | INFO | train_inner | epoch 003:     90 / 157 loss=10.425, nll_loss=9.02, ppl=519.09, wps=38277.4, ups=1.51, wpb=25301.4, bsz=1112.6, num_updates=400, lr=5e-05, gnorm=0.867, loss_scale=8, train_wall=31, gb_free=13.6, wall=202
2022-03-23 09:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:18 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 09:29:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:29:22 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's, and it's's's.
2022-03-23 09:29:22 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example hypothesis: and and and it's's a a a, but but but but but but but but but but but but but but but but but but but but but but but but but but
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:29:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and the the the the, and the the the the the the the the the, and the, and the the, and the, and the the, and the.
2022-03-23 09:29:29 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:29:34 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i i i to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to.
2022-03-23 09:29:34 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:29:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, we a a a, we to to to to to to to to to to to to to to to to to to.
2022-03-23 09:29:38 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's, we, we, we, we, and we, and we, we, we, we, we, we, we, we, we, we, and we, and we, we to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:29:49 | INFO | fairseq.tasks.translation | example hypothesis: and and we, and we, we, we, we, and we, we, and we, we, and we, we, and we, we, and we, we, and we, we, and we, and we, and we, we, and we, and we, and we the the the the the the the the the the the the the the the the the, and we to to to to to to to to to to to to
2022-03-23 09:29:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example hypothesis: and "", "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:58 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to, and and and and and and and and and and and and and and and and and and and and to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:29:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.284 | nll_loss 8.68 | ppl 410.12 | bleu 0.2 | wps 4102.9 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.2
2022-03-23 09:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:29:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.2) (writing took 1.6725913770060288 seconds)
2022-03-23 09:30:00 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:30:00 | INFO | train | epoch 003 | loss 10.421 | nll_loss 9.011 | ppl 515.99 | wps 41803 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.913 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 267
2022-03-23 09:30:00 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:11 | INFO | train_inner | epoch 004:     33 / 157 loss=10.402, nll_loss=8.98, ppl=504.93, wps=32959.7, ups=1.31, wpb=25178.3, bsz=910.4, num_updates=500, lr=6.25e-05, gnorm=1.024, loss_scale=8, train_wall=30, gb_free=14.4, wall=278
2022-03-23 09:30:42 | INFO | train_inner | epoch 004:    133 / 157 loss=10.158, nll_loss=8.605, ppl=389.36, wps=79354.8, ups=3.2, wpb=24784.3, bsz=1026.2, num_updates=600, lr=7.5e-05, gnorm=1.206, loss_scale=8, train_wall=31, gb_free=14, wall=310
2022-03-23 09:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example hypothesis: this is this.
2022-03-23 09:30:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world of the world.
2022-03-23 09:30:57 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:31:01 | INFO | fairseq.tasks.translation | example hypothesis: and it's a of the world, but we've've've've've've've've've've've've've've've have a very.
2022-03-23 09:31:01 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example hypothesis: and the world of the world, they are are are the world of the world.
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:31:10 | INFO | fairseq.tasks.translation | example hypothesis: i think i've've've've've've've've think to be the world, and i've've've've've've've've've've've've've've've've've've've've've've've've've've've've to be
2022-03-23 09:31:10 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:31:15 | INFO | fairseq.tasks.translation | example hypothesis: we've've've've've've've've've have to have to have to have to be the the world of the world of the world of the world.
2022-03-23 09:31:15 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example hypothesis: and we've've've've've've've've've've have to have to have the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we have the world, and we've've've've've've've've've've've've've've've've have
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example hypothesis: and we've've've've've've've've've've've've've have to have the world, and we have the world of the world of the world of the world of the world of the world of the world of the world of the world and we have the world of the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've have
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:34 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "i had had had a," "" i had had had had a, "" "i had had had had had had had had had a" "" "" "" i was a a, "" "i had had had had had a of the world," "" "" "" "" "" "" "" "," "" "" "," "" "" "" "" "" "" "" "" "i was the world," i was the world, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "", ",", "" "", "" "" "" "i was the world," "i was the world," "" ""
2022-03-23 09:31:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example hypothesis: and i was the that we have a that we've've have a a of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've have to have to have to have to have to have to have to have to have to have to have to have to have the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we have the world of the world, and we have to have to have to have the world of the world of the world, and that we have the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and that we have to have to have
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:37 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.932 | nll_loss 8.149 | ppl 283.83 | bleu 1.24 | wps 3769.4 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.24
2022-03-23 09:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:31:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.24) (writing took 1.674159582995344 seconds)
2022-03-23 09:31:38 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:31:38 | INFO | train | epoch 004 | loss 10.175 | nll_loss 8.631 | ppl 396.33 | wps 40157.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.178 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 366
2022-03-23 09:31:39 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:03 | INFO | train_inner | epoch 005:     76 / 157 loss=9.989, nll_loss=8.34, ppl=323.97, wps=31172, ups=1.24, wpb=25085, bsz=977.3, num_updates=700, lr=8.75e-05, gnorm=1.169, loss_scale=8, train_wall=31, gb_free=14, wall=390
2022-03-23 09:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example hypothesis: these can't't be this.
2022-03-23 09:32:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world of the world, and the world.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:32:40 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot, but it's a lot, but it's a lot, but it's a lot of a lot.
2022-03-23 09:32:40 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world, and it's the world, and it's the world, and it's the world.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to see it, but i'm going to do it's going to do it.
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:32:55 | INFO | fairseq.tasks.translation | example hypothesis: so we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see the world.
2022-03-23 09:32:55 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do it, and we're going to do it?
2022-03-23 09:33:00 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see, and we have a lot of the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we can see
2022-03-23 09:33:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" "" "" we said, "" "" we said, "" we said, "we said," we said, "" "" we said, "" we said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we said," "" "we said," "" "" "" "" "" we said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:33:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:16 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of that we have to be a lot of that we have to be a lot of the time, and we have to do that we have to be a lot of the world, and we have to do that we have to be a lot of the world, and we have to do that we have to be a lot of the world, and we have to do that we have to do that we have to be a lot of the world, and we have to be a lot of the world, and we have to do that we're going to be a lot of the world, and that we're going to be a lot of the world, and that we have to be a lot of the world, and that we've have to be a lot of the world, and that we're going to see that we've've've've've've've have to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to see
2022-03-23 09:33:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:16 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.654 | nll_loss 7.683 | ppl 205.44 | bleu 1.54 | wps 3695.1 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.54
2022-03-23 09:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.54) (writing took 1.7220533880026778 seconds)
2022-03-23 09:33:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:33:18 | INFO | train | epoch 005 | loss 9.879 | nll_loss 8.166 | ppl 287.21 | wps 39792 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.232 | loss_scale 8 | train_wall 48 | gb_free 14.8 | wall 465
2022-03-23 09:33:18 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:24 | INFO | train_inner | epoch 006:     19 / 157 loss=9.78, nll_loss=8.011, ppl=258.01, wps=30933.6, ups=1.23, wpb=25153, bsz=1065, num_updates=800, lr=0.0001, gnorm=1.247, loss_scale=8, train_wall=30, gb_free=13.9, wall=471
2022-03-23 09:33:55 | INFO | train_inner | epoch 006:    119 / 157 loss=9.623, nll_loss=7.765, ppl=217.5, wps=80671.4, ups=3.18, wpb=25334.9, bsz=1059.3, num_updates=900, lr=0.0001125, gnorm=1.159, loss_scale=8, train_wall=31, gb_free=14, wall=503
2022-03-23 09:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:11 | INFO | fairseq.tasks.translation | example hypothesis: these can't have this.
2022-03-23 09:34:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example hypothesis: and you can see the world, and they can see the world.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:34:18 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of a lot, but it's a lot of a lot.
2022-03-23 09:34:18 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and it's going to be the world, and it's going to the world.
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to see that i'm going to be a lot of the way, i'm going to be going to be going to be going to be going to be going to be the world.
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example hypothesis: so we can be a lot of the way that we can see that we can be a lot of the way that we can be a lot of our way.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do that we're going to be a lot of the world, and we're going to do that we're going to do that we're going to do, and we're going to do that we're going to do, and we're going to do it?
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see that we can see that, and we can see that we can be a lot of the world, and we can be a lot of the world, and we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can be a lot of the world.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" we said, "" "we said," it's going to say, "" "we've got to be a little little little little little little little little little little little little bit," the first, "that's going to say," we've got to say, "" "" "" we've got to say, "" "" "" "" "the first first first first first," we've got to say, "we've said," we've got to be going to be going to say, "" "" the first first first first first first first first first, "" "" "the first first first first first first," we've got to be a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little bit, "
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:54 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way, and we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way, and that we're going to be a lot of the way that we're going to be a lot of the way, and then we're going to be a lot of the way, and that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to see that we're going to see that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to get to
2022-03-23 09:34:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:54 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.451 | nll_loss 7.349 | ppl 163.04 | bleu 1.8 | wps 3779.3 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.8
2022-03-23 09:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 09:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.8) (writing took 1.7665196470043156 seconds)
2022-03-23 09:34:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:34:56 | INFO | train | epoch 006 | loss 9.632 | nll_loss 7.778 | ppl 219.46 | wps 40306.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.133 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 563
2022-03-23 09:34:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:15 | INFO | train_inner | epoch 007:     62 / 157 loss=9.516, nll_loss=7.596, ppl=193.48, wps=31450.4, ups=1.25, wpb=25123.8, bsz=1040.4, num_updates=1000, lr=0.000125, gnorm=1.163, loss_scale=8, train_wall=30, gb_free=13.5, wall=583
2022-03-23 09:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:49 | INFO | fairseq.tasks.translation | example hypothesis: these can can't have these these can can't have this.
2022-03-23 09:35:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:35:54 | INFO | fairseq.tasks.translation | example hypothesis: and you can see the world, and you see the world, you can see the world.
2022-03-23 09:35:54 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: but but there's a lot of the world, and a lot of the world, and it's a lot of the world, and it's a lot of the world, and
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:36:05 | INFO | fairseq.tasks.translation | example hypothesis: now, it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world
2022-03-23 09:36:05 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example hypothesis: it can me to me in the world, i can see the world, i can see it, and i can do it in the world, i'm going to do it in the world, i can do it.
2022-03-23 09:36:11 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: so we can do this, as we can be a lot of the way, as we can be able to make the way that we can see the way of the way that we can see the way of the way of the way of the way that we can see the way of the way,
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:36:22 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's going to do that we're going to do that we're going to do the world, and we're going to do about the world, and we're going to do it?
2022-03-23 09:36:22 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we can look at the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see that we can see that we can see that we can see that we can see that we can see the world, and we can see the world, and we can see the world,
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:36 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "the" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:36:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get to make the way that we're going to be to make the way that we're going to get to make the way, and we're going to be to be to be to get to make the world, and that we're going to be to be to be to be to make the world, and the way that we're going to be to be to be to make the way of the way that we're going to be to be to make the way, we're going to be to be to make the way to make the world, and the way that we're going to make the way, and the way that we're going to be to be to be to be to be to be to make the way that we're going to do that we're going to do that we're going to make the way that we're going to make the way that we're going to make the way that we're going to make the way that we're going to be to be to be to be to be to be to be to
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:39 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.302 | nll_loss 7.145 | ppl 141.51 | bleu 1.85 | wps 3325.2 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 1.85
2022-03-23 09:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 09:36:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 7 @ 1095 updates, score 1.85) (writing took 1.6844634860026417 seconds)
2022-03-23 09:36:40 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:36:40 | INFO | train | epoch 007 | loss 9.461 | nll_loss 7.508 | ppl 182.09 | wps 37755.5 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 1.065 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 668
2022-03-23 09:36:41 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:42 | INFO | train_inner | epoch 008:      5 / 157 loss=9.455, nll_loss=7.498, ppl=180.82, wps=29039.3, ups=1.15, wpb=25268.7, bsz=978.1, num_updates=1100, lr=0.0001375, gnorm=0.962, loss_scale=8, train_wall=31, gb_free=14.7, wall=670
2022-03-23 09:37:14 | INFO | train_inner | epoch 008:    105 / 157 loss=9.308, nll_loss=7.269, ppl=154.27, wps=80050.2, ups=3.17, wpb=25262.6, bsz=1008.3, num_updates=1200, lr=0.00015, gnorm=1.013, loss_scale=8, train_wall=31, gb_free=13.5, wall=701
2022-03-23 09:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:34 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these things can't use.
2022-03-23 09:37:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:38 | INFO | fairseq.tasks.translation | example hypothesis: and that's that they're going to see the world, it's the world.
2022-03-23 09:37:38 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, there's a lot of life, and it's a lot of life, and it's a lot of life.
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example hypothesis: now, it's going to see it, and it's in the world, and it's in the world, and it's the world.
2022-03-23 09:37:48 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example hypothesis: it also also also also also like me, i can see how i can see that i can see that i can see in the world.
2022-03-23 09:37:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:37:59 | INFO | fairseq.tasks.translation | example hypothesis: so as as we can see how as we can see this as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as we can be as as as as as as as as as as as
2022-03-23 09:37:59 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example hypothesis: it's going to think about the world, we're going to talk about the world, and we're going to do that we're going to go from the world, and we're going to go from the world, and we're going to go out of the world, and we're going to go out of the world, and we're going to do
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we can look at the way that we can see that we can see the way, and we can see that we can look at the world, and we can see that we can look at the world, and we can see that we can see that we can see that we can see that we can see that we can see that we can see the world, and then we can see that we can see the world, and then can see that we can see
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example hypothesis: one of the one of the one of the first time, "the first one of the first time, and it's going to say," we're going to be going to say, "and we're going to be going to say, and we're going to tell you know," we're going to be going to be going to say, "and we're going to do it's going to tell you know," what we're going to be going to be going to be going to be going to be going to be going to be going to say, "and then we're going to be going to be going to be going to be going to say," and the first time, "and then we're going to tell you know," and then we're going to say, "the first time," the first time, "the first time," the first time, "and
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're going to have to be a few years, if we're going to see that we're going to be going to see that we're going to be going to be going to see the way that we're going to see that we're going to be going to be going to be going to think of the most of the way that we're going to see that we're going to think of the way that we're going to see that we're going to be going to see that we're going to be going to be going to be going to be going to think that we're going to do that we're going to do that we're going to see the way that we're going to think that we're going to do that we're going to do that we're going to be going to see that we're going to be going to be going to be going to think that we're going to be going to be going to be going to do that we're going to see the most of the most of the most of the most of the
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:21 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.079 | nll_loss 6.728 | ppl 105.97 | bleu 3 | wps 3487.6 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3
2022-03-23 09:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 09:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.0) (writing took 1.695716086003813 seconds)
2022-03-23 09:38:22 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:38:22 | INFO | train | epoch 008 | loss 9.265 | nll_loss 7.205 | ppl 147.56 | wps 38630.9 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.963 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 770
2022-03-23 09:38:23 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:38 | INFO | train_inner | epoch 009:     48 / 157 loss=9.175, nll_loss=7.064, ppl=133.82, wps=29330, ups=1.19, wpb=24701.8, bsz=1007.2, num_updates=1300, lr=0.0001625, gnorm=0.881, loss_scale=8, train_wall=30, gb_free=13.8, wall=785
2022-03-23 09:38:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:39:10 | INFO | train_inner | epoch 009:    149 / 157 loss=9.07, nll_loss=6.899, ppl=119.37, wps=81036.9, ups=3.15, wpb=25720.8, bsz=1029.5, num_updates=1400, lr=0.000175, gnorm=0.999, loss_scale=4, train_wall=31, gb_free=13.4, wall=817
2022-03-23 09:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:16 | INFO | fairseq.tasks.translation | example hypothesis: these can't use.
2022-03-23 09:39:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example hypothesis: and so, we're going to see it, they're going to see the world.
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example hypothesis: but all, there's a lot of between between between between between between between between between between between between between between between between between between between and.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example hypothesis: now, very simple, and it's been working on the united states, and the united states, and the united states are the united states, the united states.
2022-03-23 09:39:28 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example hypothesis: it also also also also also, like me, i can be in the way, i can be in the way.
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:39:36 | INFO | fairseq.tasks.translation | example hypothesis: so, how we can be able to be able to do this, if we can be able to be a new new system, it would be a new new system.
2022-03-23 09:39:36 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example hypothesis: this is what we have to have to do?
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:39:46 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can do the information, we can do this, and we can do this, and we can see the brain, and we can see the brain, and we can see the brain.
2022-03-23 09:39:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example hypothesis: : one of the idea, and it's a lot of the time, and it's going to go, and you know, and you know, and we're going to go up with this, and you know, you know, you know, you know, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go out, you know, you know, you know, you know, you know, you know, if you know, you know, you know, you know, you know, you know, you're going to the time, and we're going to go up, you know, you're going to the time, you know, you know, you're going to the time,
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example hypothesis: so, it's still still still the way, and we're going to get a way, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to get the same time, and we're going to have to have to have to have to have to have to get the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to the same time, and we're going to get the same time, and
2022-03-23 09:39:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:55 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.87 | nll_loss 6.38 | ppl 83.28 | bleu 5.46 | wps 4151.1 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5.46
2022-03-23 09:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:39:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.46) (writing took 1.729063295002561 seconds)
2022-03-23 09:39:57 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:39:57 | INFO | train | epoch 009 | loss 9.099 | nll_loss 6.945 | ppl 123.23 | wps 41431.5 | ups 1.65 | wpb 25120.1 | bsz 1008.1 | num_updates 1408 | lr 0.000176 | gnorm 0.986 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 864
2022-03-23 09:39:57 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:27 | INFO | train_inner | epoch 010:     92 / 157 loss=8.904, nll_loss=6.645, ppl=100.08, wps=32357.4, ups=1.3, wpb=24869.8, bsz=1053.8, num_updates=1500, lr=0.0001875, gnorm=0.894, loss_scale=4, train_wall=31, gb_free=14.7, wall=894
2022-03-23 09:40:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:51 | INFO | fairseq.tasks.translation | example hypothesis: these can't use this can't use a use.
2022-03-23 09:40:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:55 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, they're going to see that they can see the world.
2022-03-23 09:40:55 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:40:59 | INFO | fairseq.tasks.translation | example hypothesis: but everybody has a lot between between between between between between between between between between between between between between between between between between between between between between between between between between between between between.
2022-03-23 09:40:59 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:41:03 | INFO | fairseq.tasks.translation | example hypothesis: now, it's very difficult on the united states, and the united states are the united states, and the united states are the united states.
2022-03-23 09:41:03 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example hypothesis: it could also also also be like, as i'm going to look at the way i can see it in the other other other other way.
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example hypothesis: so as we can make our computer that can be able to be able to be able to be a new new new new new new york, if it would be able to be able to be able to be a new new new way.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example hypothesis: it's it's going to have to have a lot of the mey, from the kids who are going to go from our children, and many children are going to the children, and many children are going to go from our children.
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this information, we can make a little bit of the brain, and we can make a little bit of the brain, and we can see that there's a lot of the brain, which is a lot of the brain.
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:26 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reason it's interesting for me for me, and we've said, "you know," if you've got a few years, "and we've got a few people who said," you're going to tell you know, "well," well, "you know," you know, "you know," you know, "you know," you know, "well," you know, "you know," you know, "you know," you know, "you know," well, "you know," well, "well," you know, "well," you know, "you know," you know, "you know," you know, "you know," you know, "well," you know, "you know," you know, "you know," you know, "you know,
2022-03-23 09:41:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example hypothesis: now, it's still still still a mother, and we're going to see the way that we're going to see a way that we're going to have a way that we're going to make a way that we're going to have a way that we're going to have a way that we're going to have to be able to have a new way that we're going to have a few years, and that we're going to make a few years, and that we're going to have a little bit of the same way that we're going to make a few years, and that we're going to have a few years, and that we're going to have a few years that we're going to have a little bit of the same way that we're going to have a little bit of the same way that we're going to have a little bit of the same way that we're going to make the same way that we're going to have a way that we're going to have a few years that we're going to have a few years, and
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:28 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.664 | nll_loss 6.074 | ppl 67.37 | bleu 7.19 | wps 4377.2 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.19
2022-03-23 09:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:41:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:41:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.19) (writing took 1.7001126800023485 seconds)
2022-03-23 09:41:30 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:41:30 | INFO | train | epoch 010 | loss 8.891 | nll_loss 6.622 | ppl 98.5 | wps 42413 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.915 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 957
2022-03-23 09:41:30 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:42 | INFO | train_inner | epoch 011:     35 / 157 loss=8.83, nll_loss=6.525, ppl=92.11, wps=33679.7, ups=1.34, wpb=25206.7, bsz=992.5, num_updates=1600, lr=0.0002, gnorm=1.005, loss_scale=4, train_wall=30, gb_free=13.8, wall=969
2022-03-23 09:42:13 | INFO | train_inner | epoch 011:    135 / 157 loss=8.749, nll_loss=6.403, ppl=84.64, wps=78781.6, ups=3.18, wpb=24785.7, bsz=1016.1, num_updates=1700, lr=0.0002125, gnorm=0.981, loss_scale=4, train_wall=31, gb_free=14.4, wall=1000
2022-03-23 09:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example hypothesis: this can't use.
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:42:27 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, no, they're going to see that they see the world.
2022-03-23 09:42:27 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:42:31 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's got a different difference between between between between between between between between between between the difference, and language.
2022-03-23 09:42:31 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:42:35 | INFO | fairseq.tasks.translation | example hypothesis: very simple. it's going to go on the united states, and the united states, and the united states, the united states are the united states.
2022-03-23 09:42:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:42:40 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in fact, i'm going to be so so i'm looking at the other side of the side of the other side.
2022-03-23 09:42:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:42:44 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can take our computer, we can take the computer, which can be able to be able to be a new process of new new york, if it would be able to be a new process.
2022-03-23 09:42:44 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example hypothesis: is it?
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of this information, we can do with a whole process that we can do with the information, and then we can actually make the information of information, and the information, and the information of information, which is the information, which is the information that can actually actually actually actually make a different information, and the information, and the information, and the information, and the information, and the information, which is the information that can do
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting for me, and it's really interesting for me, "and" "and we've got to tell you that," and then we've got to tell you, "if we've got to tell you," if you know, "if you know," if you know, "if you're going to tell you know," if we've got a little bit of these women, "when we've got a little bit of the women," when we've got to tell you know, "if you know," when we've got to tell you know, "when we've got to tell you know," and then, "and then," and then, "when we've got a little bit of the women," then, "and then," if you know, "if we've got to tell you know
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:03 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still the mother, and the way that we're going to see, and if we're going to see that we're going to see that we were going to be able to see the same way that we had to be able to be able to see that we had to be able to be able to be able to see the same way to see that we had to be able to see the same way to see that we had to see that we had to see that we had to be able to see that we had to see, and that we had to be able to look at the same way to see, and that if we had to see that we had to see that we had to be able to look at the same way to see in a big problems of the same way to see that we had to see, and that we had to see that we had to see that we had to see that we were going to see, and that if we had to see that we were going to see that we were going to see, and
2022-03-23 09:43:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:03 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.469 | nll_loss 5.727 | ppl 52.96 | bleu 8.32 | wps 4190.9 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.32
2022-03-23 09:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.32) (writing took 1.7240986039978452 seconds)
2022-03-23 09:43:04 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:43:04 | INFO | train | epoch 011 | loss 8.731 | nll_loss 6.374 | ppl 82.95 | wps 41879.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.966 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1052
2022-03-23 09:43:05 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:29 | INFO | train_inner | epoch 012:     78 / 157 loss=8.55, nll_loss=6.094, ppl=68.32, wps=33614.6, ups=1.31, wpb=25690.2, bsz=1080.7, num_updates=1800, lr=0.000225, gnorm=0.935, loss_scale=4, train_wall=31, gb_free=13.9, wall=1077
2022-03-23 09:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:58 | INFO | fairseq.tasks.translation | example hypothesis: and these kinds can't use any chemical use.
2022-03-23 09:43:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:44:02 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without them without them, they see the world.
2022-03-23 09:44:02 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else else else else else else between between between between between and intelligence.
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example hypothesis: very, it's very hard on japan, and there are the united states, the united states of the united states.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:44:13 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm thinking about my way, so i can do in the other side of the other side.
2022-03-23 09:44:13 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:44:17 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer can imagine that new new brain can be able to be able to be a new new part of the brain when it would be able to be a part of the brain.
2022-03-23 09:44:17 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:44:21 | INFO | fairseq.tasks.translation | example hypothesis: it's the ability? we've got to come from the pary, from the public science, and many children come from our children, and many children, and many children come from our children.
2022-03-23 09:44:21 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information that we can start able to do with a sense of dna that can do with a different structure, and the structure of information, and all of the information.
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me for me, "here's what we've got to say," well, "well," well, "if we said," it's a long time for you know, "if you're going to say," the best time. "
2022-03-23 09:44:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:32 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still the mother, and the whole thing we're going to see our work on the same way that we had to be able to be able to be able to be able to create a big system, and if we had to do it.
2022-03-23 09:44:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:32 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.287 | nll_loss 5.397 | ppl 42.13 | bleu 11.34 | wps 4851.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.34
2022-03-23 09:44:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:44:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:44:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.34) (writing took 1.7495055409963243 seconds)
2022-03-23 09:44:33 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:44:33 | INFO | train | epoch 012 | loss 8.545 | nll_loss 6.086 | ppl 67.92 | wps 44425.7 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.922 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1141
2022-03-23 09:44:34 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:41 | INFO | train_inner | epoch 013:     21 / 157 loss=8.537, nll_loss=6.073, ppl=67.3, wps=35288.5, ups=1.41, wpb=25090.3, bsz=964, num_updates=1900, lr=0.0002375, gnorm=0.894, loss_scale=4, train_wall=31, gb_free=13.6, wall=1148
2022-03-23 09:45:12 | INFO | train_inner | epoch 013:    121 / 157 loss=8.32, nll_loss=5.737, ppl=53.33, wps=80266.3, ups=3.21, wpb=24993.5, bsz=1065.4, num_updates=2000, lr=0.00025, gnorm=0.887, loss_scale=4, train_wall=31, gb_free=13.5, wall=1179
2022-03-23 09:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:27 | INFO | fairseq.tasks.translation | example hypothesis: this can't use a chemical materials.
2022-03-23 09:45:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:45:31 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you can see it without the world, you see the world.
2022-03-23 09:45:31 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example hypothesis: but everybody find a musician between any sense between its own, and think between intelligence and intelligence, and intelligence.
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example hypothesis: it's very difficult on japan, in japan, japan, japan and countries, the united states, the united states are the united states.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:45:43 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm thinking about how i'm so so so on the other side of the other side of the other side.
2022-03-23 09:45:43 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can take our computer, we can imagine our computer, the new brain can take this new new new brain, when it would be part of the brain.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: so it's the impact? we've got from the age of ddy, from the university, from the university, and many children are going to get a lot of kids.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:45:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use from this kind of view, we can actually start with a traditional traditional traditional cell, and we can start the whole structure of the information and all the information.
2022-03-23 09:45:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and it's interesting for me to say, "yes," well, "and then we're going to tell you the best time, and then we're going to tell you the best women."
2022-03-23 09:45:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example hypothesis: well, unfortunately, the mother is still the mother of mother, and the great design of our work, and we're going to see the same thing that we had to solve the same way to take the same system, and the same thing that we had to take the same way to create the same way to take the same way to the ground.
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:00 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.138 | nll_loss 5.124 | ppl 34.87 | bleu 13.26 | wps 4990.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.26
2022-03-23 09:46:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:46:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.26) (writing took 1.7068921550089726 seconds)
2022-03-23 09:46:01 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:46:01 | INFO | train | epoch 013 | loss 8.339 | nll_loss 5.768 | ppl 54.49 | wps 44842.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.858 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1229
2022-03-23 09:46:02 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:22 | INFO | train_inner | epoch 014:     64 / 157 loss=8.181, nll_loss=5.525, ppl=46.05, wps=36546.8, ups=1.42, wpb=25789, bsz=1069.9, num_updates=2100, lr=0.0002625, gnorm=0.795, loss_scale=4, train_wall=31, gb_free=13.9, wall=1250
2022-03-23 09:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical chemical rarations can use.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:46:59 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you can see it, you see the world.
2022-03-23 09:46:59 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:47:03 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different amount between the weight between and intelligence, intelligence and intelligence.
2022-03-23 09:47:03 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example hypothesis: especially, it's very focus on japan, japan, japan, japan, and the united states, the united states are the united states.
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:47:11 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm so on my mind, so i'm so on the other side, in the other side.
2022-03-23 09:47:11 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:47:15 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can make our computer, we can imagine that the brain allows this new tool to use this new tool as a new tool, when it would be part of the body.
2022-03-23 09:47:15 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:47:19 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got to come from from the doors, from the national science, and the science of science, which is many kids come from our research, and many of our research.
2022-03-23 09:47:19 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that can come from this kind of reflect, we can start with a traditional face, and we can start able to start with the face of the information, and there's a real structure.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons it's interesting and interesting for me, "this is to be a tedtedtedtedtedson -- that's the best thing," yes, "yes," well, "it's the best thing we've been working with you know," when we've been working with you've been working with you've been working with you know, "and then," you've been working with you know, "you've been working with you know," you've been looking at the best. "
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the mother of the mother, and a big work that we're going to solve our work on our plane, we had to solve the way that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that the ground with the ground with the surface of the surface of the ground.
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:30 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.916 | nll_loss 4.814 | ppl 28.13 | bleu 14.65 | wps 4638.3 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.65
2022-03-23 09:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.65) (writing took 1.799647631996777 seconds)
2022-03-23 09:47:32 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:47:32 | INFO | train | epoch 014 | loss 8.175 | nll_loss 5.512 | ppl 45.63 | wps 43626.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.836 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1319
2022-03-23 09:47:32 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:34 | INFO | train_inner | epoch 015:      7 / 157 loss=8.223, nll_loss=5.582, ppl=47.92, wps=33735.6, ups=1.38, wpb=24372, bsz=907.3, num_updates=2200, lr=0.000275, gnorm=0.848, loss_scale=4, train_wall=30, gb_free=14.3, wall=1322
2022-03-23 09:48:06 | INFO | train_inner | epoch 015:    107 / 157 loss=7.994, nll_loss=5.23, ppl=37.54, wps=79449.1, ups=3.16, wpb=25109.4, bsz=1095.3, num_updates=2300, lr=0.0002875, gnorm=0.815, loss_scale=4, train_wall=31, gb_free=14.7, wall=1353
2022-03-23 09:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:26 | INFO | fairseq.tasks.translation | example hypothesis: and this shock can't use chemical rarations.
2022-03-23 09:48:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, they see that they see the world.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another equation between weight and uncertainty.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, japan, japan and australia, australia, the united states are the united states.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example hypothesis: it might also be interested in my attention, as i'm able to get my attention on the other side.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can imagine our computer, the brain to build this new tool.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:48:47 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact?
2022-03-23 09:48:47 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with traditional physictivity that can start able to start able to start with the physical shape of the information, and that's all the information.
2022-03-23 09:48:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:55 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting for me to be able to be here for tedtedtedson -- that's the best thing that she said, "well," well, "somebody said," well, "well," if we're working with you know, "and then we've been working with the truth."
2022-03-23 09:48:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:57 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother's mother, and a lot of design that we have to solve the design of work on our airplane was that we had to solve a unique way that we had to solve the same thing that we had to be able to be able to be able to be able to be able to be able to solve the ground.
2022-03-23 09:48:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:57 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 7.821 | nll_loss 4.669 | ppl 25.45 | bleu 12.97 | wps 5261.7 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 14.65
2022-03-23 09:48:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:48:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 15 @ 2350 updates, score 12.97) (writing took 0.7407070799963549 seconds)
2022-03-23 09:48:58 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:48:58 | INFO | train | epoch 015 | loss 8 | nll_loss 5.239 | ppl 37.77 | wps 46103.6 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.787 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1405
2022-03-23 09:48:58 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:14 | INFO | train_inner | epoch 016:     50 / 157 loss=7.875, nll_loss=5.046, ppl=33.04, wps=38187.3, ups=1.47, wpb=25944, bsz=1069.2, num_updates=2400, lr=0.0003, gnorm=0.723, loss_scale=4, train_wall=31, gb_free=14, wall=1421
2022-03-23 09:49:45 | INFO | train_inner | epoch 016:    150 / 157 loss=7.894, nll_loss=5.068, ppl=33.54, wps=79208, ups=3.24, wpb=24484.4, bsz=910, num_updates=2500, lr=0.0003125, gnorm=0.762, loss_scale=4, train_wall=31, gb_free=14.8, wall=1452
2022-03-23 09:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example hypothesis: and this thing can't use chemical chemical rations.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly suddenly, without you see it, you see the world, you see the different world.
2022-03-23 09:49:56 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another equation between weight and uncertainty, and intelligence and intelligence.
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:50:04 | INFO | fairseq.tasks.translation | example hypothesis: very focus it on japan and australia, australia, australia, countries, the united states, the united states of the united states are in the united states.
2022-03-23 09:50:04 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:50:08 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested, as i'm focused on my attention, so i'm so on the other side of the other side of it.
2022-03-23 09:50:08 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:50:12 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reimagine our computer, the brain to build this new tool, if it would be part of the brain, if it would be part of the body.
2022-03-23 09:50:12 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact?
2022-03-23 09:50:16 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this reflection, we can start with traditional face, we can start with a traditional face of the face of the face, and there's a real shape of the information, and then we're all using it, and all the information that all the information that you can do.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:26 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and it's interesting for me to be in tedtedwomen, "yes, you know, you know," you know, you know, you know, you know, "you know, you know," you know, you know, you know, you know, you know, you know, you know, you know, "you know," you know, you know, the best, you know, you know, "you know, you know, you know," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, the best know, you know, you know, "you know, the best, you know, you know, you know, you know,
2022-03-23 09:50:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, need to be the mother of the invention, and a big design of design that we've had to solve on our plane, and if we had to solve a unique way that we had to solve it on the ground, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:50:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:28 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.708 | nll_loss 4.431 | ppl 21.57 | bleu 16.9 | wps 4420.2 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.9
2022-03-23 09:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:50:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 16 @ 2507 updates, score 16.9) (writing took 1.7463811899942812 seconds)
2022-03-23 09:50:30 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:50:30 | INFO | train | epoch 016 | loss 7.846 | nll_loss 4.998 | ppl 31.97 | wps 42612.6 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.767 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1498
2022-03-23 09:50:31 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:00 | INFO | train_inner | epoch 017:     93 / 157 loss=7.729, nll_loss=4.816, ppl=28.17, wps=33452.3, ups=1.33, wpb=25136.7, bsz=1023.9, num_updates=2600, lr=0.000325, gnorm=0.733, loss_scale=4, train_wall=31, gb_free=14.4, wall=1527
2022-03-23 09:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:24 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rape.
2022-03-23 09:51:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you know, you know, you can see the world.
2022-03-23 09:51:27 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between the weight between and insane, unconscious intelligence and intelligence.
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, and australia, australia, australia, the countries that were in the united states.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused, so i'm focused on my attention in the other side.
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can imagine our computers can reform the brain to create this new tool when it would be part of the body.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact that we have? we've come from professor, from berbery, at stanford, from the indian science institute, and the kids come to our children, and get a lot of scientific scientific science that are going to go to school.
2022-03-23 09:51:48 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional face of the face, and the real face of the face of the face, and the information, and the information, and the information, and then there is a whole structure.
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:57 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and measure for me to be in tedson, is that... yes, it was the best thing when someone said, "when someone said," and if you're working on a table, "if you're working on a table," and then we're working with you're working with a long time, "you know," you know, "you know, you know," you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 09:51:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, we had to solve the mother of the invention, and a big part of the design that we're in our plane, is that we had to solve a result of it, so we had to solve the problems that we had to be connected to the ground, to the ground, and if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you to see that if we're able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:51:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:59 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.5 | nll_loss 4.116 | ppl 17.34 | bleu 19.3 | wps 4574.8 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.3
2022-03-23 09:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:51:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.3) (writing took 1.7600655400019605 seconds)
2022-03-23 09:52:01 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:52:01 | INFO | train | epoch 017 | loss 7.685 | nll_loss 4.748 | ppl 26.87 | wps 43400.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.683 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1589
2022-03-23 09:52:02 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:13 | INFO | train_inner | epoch 018:     36 / 157 loss=7.635, nll_loss=4.671, ppl=25.47, wps=34404.3, ups=1.37, wpb=25105.8, bsz=998.2, num_updates=2700, lr=0.0003375, gnorm=0.668, loss_scale=4, train_wall=31, gb_free=13.8, wall=1600
2022-03-23 09:52:44 | INFO | train_inner | epoch 018:    136 / 157 loss=7.504, nll_loss=4.472, ppl=22.19, wps=80501.9, ups=3.18, wpb=25301.2, bsz=1070.7, num_updates=2800, lr=0.00035, gnorm=0.659, loss_scale=4, train_wall=31, gb_free=14.9, wall=1632
2022-03-23 09:52:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rains.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:52:59 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without all the time you see it, you see the world differently.
2022-03-23 09:52:59 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe and reason, instinct intelligence and intelligence.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, korea, and australia, the countries of the united states of the united states.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me as i'm focused, so i'm my attention to the circuit on the other side.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can restore our computers, the brains to form this new tool as it would be part of the body.
2022-03-23 09:53:14 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professor professor from berbery, at stanford, from the indian institute of science institute, and our children get a lot of scientific experiments that are going to go to normal school.
2022-03-23 09:53:18 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional face, the big face of the face of the face of the face, and the information is recovering the information, and all the structure of the structure.
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:27 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and measure interesting, for me to be here at tedwomen, is that... yes, it was the best thing when someone said, "the table said," you know, the men '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:53:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's mother's invention, and a big part of design that we're at the airplane, was a result of the ground that we had to solve the problems that we had to be connected to the ground -- it's all over the ground.
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:28 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.395 | nll_loss 3.938 | ppl 15.33 | bleu 20.83 | wps 4893.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.83
2022-03-23 09:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.83) (writing took 1.716632234005374 seconds)
2022-03-23 09:53:30 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:53:30 | INFO | train | epoch 018 | loss 7.536 | nll_loss 4.52 | ppl 22.95 | wps 44671.3 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.678 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1677
2022-03-23 09:53:30 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:55 | INFO | train_inner | epoch 019:     79 / 157 loss=7.428, nll_loss=4.354, ppl=20.45, wps=36091.4, ups=1.41, wpb=25544.4, bsz=989.9, num_updates=2900, lr=0.0003625, gnorm=0.616, loss_scale=4, train_wall=31, gb_free=13.6, wall=1703
2022-03-23 09:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rains.
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you see it, you see the world differently.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe between believe between believe and reason, instinct intelligence and intelligence.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example hypothesis: especially focus on japan, korea, korea and australia, countries that are very focused on the united states.
2022-03-23 09:54:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on my attention in the circuit on the other side.
2022-03-23 09:54:39 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can rereconstruct our computers, we can reform the brains of this new tool to make this new tool as it would be part of the primate primates.
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley institute that come from the indian science institute that come from the indian science institute, and our children get a lot of scientific scientific experiments that go beyond normal education.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from these reflection reflection reflection, we can start with a traditional face that can start with a traditional face of the face, and the basic shape of the face, and through that information, which is the whole structure of this structure, and all of this structure, and all of these things that are able to fold a structure.
2022-03-23 09:54:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:57 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that are interesting, and measure it interesting and measure interesting for me to be here at tedwomen, is that...... yes...... at the best time, when somebody said, "and if you say," the men who are working on a table, and then you say, "if you're working on the truth," well, "well," we've been working on this talk to you've been working on this talk to you know, "hey," well, "well," well, "well," well, "well," hey, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "
2022-03-23 09:54:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of invention, and a great part of design work that we're at the plane on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything that was connected to the ground on the ground, and a large part of the ground, and a large part of the design system that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to be able to be able to be able to be able to be able to be able to see that if we were able to be able to be able to see
2022-03-23 09:55:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:00 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.331 | nll_loss 3.815 | ppl 14.07 | bleu 22.03 | wps 4474.9 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.03
2022-03-23 09:55:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:55:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:55:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.03) (writing took 1.7391772319970187 seconds)
2022-03-23 09:55:01 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:55:01 | INFO | train | epoch 019 | loss 7.386 | nll_loss 4.291 | ppl 19.58 | wps 43074 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.622 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1769
2022-03-23 09:55:02 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:09 | INFO | train_inner | epoch 020:     22 / 157 loss=7.363, nll_loss=4.257, ppl=19.12, wps=33541.8, ups=1.36, wpb=24602.2, bsz=1016.5, num_updates=3000, lr=0.000375, gnorm=0.656, loss_scale=4, train_wall=30, gb_free=13.8, wall=1776
2022-03-23 09:55:40 | INFO | train_inner | epoch 020:    122 / 157 loss=7.255, nll_loss=4.093, ppl=17.06, wps=81120.4, ups=3.16, wpb=25699.2, bsz=1067.5, num_updates=3100, lr=0.0003875, gnorm=0.585, loss_scale=4, train_wall=31, gb_free=14.3, wall=1808
2022-03-23 09:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:55 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rakekekekeen.
2022-03-23 09:55:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example hypothesis: but each musicians find a different balance between believe and reason, instinct and intelligence.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 09:56:06 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how concentrated i'm so that i can wear my attention in the circuit on the other side.
2022-03-23 09:56:10 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reconstruct our computers, the brain naked up to form this new tool as it would be part of the prices of the primates.
2022-03-23 09:56:15 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, at stanford, from the indian science institute that come from and bring our kids to a lot of scientific ways that go beyond normal education.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big constructions of the face and the shape of the face, and through that information, which is all the porports and all the structure.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that said, "you know, and if we're going to be here in tedwomen," well, you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know, you know," you know, "you know," you know, "you're going to have a long."
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at at our aircraft, was a result of it that we had to solve the unique problems that were connected to the ground -- all of us.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:30 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.176 | nll_loss 3.639 | ppl 12.46 | bleu 23.49 | wps 4683 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.49
2022-03-23 09:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.49) (writing took 1.800990449002711 seconds)
2022-03-23 09:56:31 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:56:31 | INFO | train | epoch 020 | loss 7.279 | nll_loss 4.128 | ppl 17.48 | wps 43815.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.606 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1859
2022-03-23 09:56:32 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:52 | INFO | train_inner | epoch 021:     65 / 157 loss=7.222, nll_loss=4.041, ppl=16.46, wps=34170.7, ups=1.39, wpb=24609.9, bsz=972.3, num_updates=3200, lr=0.0004, gnorm=0.582, loss_scale=4, train_wall=30, gb_free=14.3, wall=1880
2022-03-23 09:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:25 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rocket.
2022-03-23 09:57:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world different.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else find a different balance between believe and reason, instinct and intelligence.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: especially focused on japan, korea, and australia, the endangered of the united states.
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i'm so that i can carry my attention to the circuit on the other side.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example hypothesis: so, as quickly as we can restore our computers, the brains to form this new tool as it would be part of the priority.
2022-03-23 09:57:44 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford from the indian science institute that come and bring our kids to normal class.
2022-03-23 09:57:48 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big contemporary and the basic shape of the face of the face of the face of the face of the face of the face, and it's restored by that information that all the ports the porting the ports and all the structure.
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be very interesting, and then, for me, is that... twell, when it was put it up the best thing that somebody said, "turn it up to the men's table," and then, "if we're working on the truth for you."
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design, which we're at the latest aircraft, was a result of it that we had to solve the unique problems that were connected to the ground -- all of the way to the refrigergeration, and if you're in the refrigergergeration system, or the refrigergergergeration, or if you could see the refrigergergeration of an aircraft.
2022-03-23 09:57:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:58 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.148 | nll_loss 3.57 | ppl 11.87 | bleu 23 | wps 5012.9 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.49
2022-03-23 09:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 09:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 21 @ 3292 updates, score 23.0) (writing took 0.8127059889957309 seconds)
2022-03-23 09:57:59 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:57:59 | INFO | train | epoch 021 | loss 7.194 | nll_loss 4 | ppl 16 | wps 45336.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.61 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1946
2022-03-23 09:57:59 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:02 | INFO | train_inner | epoch 022:      8 / 157 loss=7.21, nll_loss=4.024, ppl=16.26, wps=36469.7, ups=1.44, wpb=25247.4, bsz=1007.4, num_updates=3300, lr=0.0004125, gnorm=0.639, loss_scale=4, train_wall=31, gb_free=14.3, wall=1949
2022-03-23 09:58:33 | INFO | train_inner | epoch 022:    108 / 157 loss=7.048, nll_loss=3.783, ppl=13.76, wps=81059.9, ups=3.13, wpb=25856.5, bsz=1029.7, num_updates=3400, lr=0.000425, gnorm=0.507, loss_scale=4, train_wall=31, gb_free=14.2, wall=1981
2022-03-23 09:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rocket.
2022-03-23 09:58:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe and reason, instinct and intelligence.
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are connected to the united states.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention degree in the circulation on the other side.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reconstruct our computer, the brain activity to form this new tool as if it would be a body part of primates.
2022-03-23 09:59:11 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:59:15 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professor from berkeley, at stanford, from the indian science institute that come and teach our kids a lot of scientific formers that go far beyond normal education.
2022-03-23 09:59:15 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and the basic shape of the face and rerepeat it, and through the one of these instructural information that's going to fold through.
2022-03-23 09:59:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it starts to be interesting, and if we're going to be here at tedwomen, is that... well, in the best way, when somebody said, "turn it up to the men and say," turn it up with you, "well," well, you know, you know, "well, you know, you know, you know," well, you know, you know, "well, you know, you know, when you know, you know," well, when you know, when you know, when you know, when you know, when you're going to have been working on the guy said, "well," well, "well," well, when you know, when you know, when you know, when you know, when you're going to have been working on the guy said, when you know, "
2022-03-23 09:59:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on our plane, was a result that we had to solve the unique problems that were connected to the ground -- so that we had to solve the ground -- all the continuous variation -- and a big part of the refrigergergering system, and it allows us to see that if we're going to go down the refrigergergergergergering the refrigergerism, if we had to see the buridge the buridge, if we had to go down the buridge the burefrigergerism, it's going to the buridge the buridge the buridge the burial engine, it's going to see that if we had to be able to see that if we had to be able to be able to go down the unique problems that we had to go down the ground.
2022-03-23 09:59:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:26 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.072 | nll_loss 3.457 | ppl 10.98 | bleu 24.85 | wps 4783.9 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.85
2022-03-23 09:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 09:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 22 @ 3449 updates, score 24.85) (writing took 1.952288855012739 seconds)
2022-03-23 09:59:28 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:59:28 | INFO | train | epoch 022 | loss 7.072 | nll_loss 3.819 | ppl 14.12 | wps 43967.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.546 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2036
2022-03-23 09:59:29 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:45 | INFO | train_inner | epoch 023:     51 / 157 loss=7.057, nll_loss=3.799, ppl=13.92, wps=34051.2, ups=1.4, wpb=24328.4, bsz=1036.3, num_updates=3500, lr=0.0004375, gnorm=0.58, loss_scale=4, train_wall=30, gb_free=14, wall=2052
2022-03-23 10:00:16 | INFO | train_inner | epoch 023:    151 / 157 loss=6.987, nll_loss=3.693, ppl=12.94, wps=80606.4, ups=3.21, wpb=25147.8, bsz=992, num_updates=3600, lr=0.00045, gnorm=0.514, loss_scale=4, train_wall=31, gb_free=14, wall=2083
2022-03-23 10:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example hypothesis: this sond can't use chemical rockets.
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:00:25 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 10:00:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:00:29 | INFO | fairseq.tasks.translation | example hypothesis: but everybody musicians find a different balance between believe and reason, instinct and intelligence.
2022-03-23 10:00:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:00:33 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are endangered to the united states.
2022-03-23 10:00:33 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:00:37 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention degree in the circuit on the other side.
2022-03-23 10:00:37 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can restore our computers, we can reform the brain activity to form this new tool as if it would be a body part of the primates.
2022-03-23 10:00:41 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got professors from berkeley, stanford, from indian science institute that come and teach our children a lot of scientific formers that go far beyond normal education.
2022-03-23 10:00:45 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start to a traditional face, which is the big constructions of the face and the basic shape, and through that one information that makes the whole portion and all the time.
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured to me here at tedwomen is that... well, when it was put it on the best thing when someone said, "turn you up to the men and tell you, and then we're going to support the revolution, and then we're going to support you,"] ["] ["] ["] ["] [unks, women's truth, "] ["] ["] ["] ["] ["] ["] [unks, and then we've already supporting them."] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [unclear] ["] ["] ["] ["] ["
2022-03-23 10:00:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at our airplane, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrightening system that we're able to use it, and that if we're able to use the refrightening, or to the refrigering machine, or to see that if we're able to see the refrightening, or to the refrightening, or to the refrightening, to the refrightening machine, or to the refrightening, or to the refrightening, or to the refrightening machine, to the oil system, to the surface, or to the refrightening, and to a refrightening, and to the oil, and to the oil, and to the surface, and to see the surface, and to see the
2022-03-23 10:00:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:56 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.964 | nll_loss 3.283 | ppl 9.74 | bleu 26.6 | wps 4807.7 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.6
2022-03-23 10:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.6) (writing took 1.907864652996068 seconds)
2022-03-23 10:00:58 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:00:58 | INFO | train | epoch 023 | loss 6.989 | nll_loss 3.696 | ppl 12.96 | wps 44246.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.517 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2125
2022-03-23 10:00:58 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:28 | INFO | train_inner | epoch 024:     94 / 157 loss=6.928, nll_loss=3.609, ppl=12.2, wps=35366.2, ups=1.39, wpb=25359.4, bsz=1073.3, num_updates=3700, lr=0.0004625, gnorm=0.538, loss_scale=4, train_wall=31, gb_free=14, wall=2155
2022-03-23 10:01:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice the world differently.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example hypothesis: but everyone musicians find another balance between faith and reason, instinct and intelligence.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example hypothesis: especially focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:02:03 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused, so i can carry my attention degrees on the other side.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computer, the brain activity to form this new tool as if it was a body part of primate.
2022-03-23 10:02:10 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:02:14 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific form that go far beyond normal class.
2022-03-23 10:02:14 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:02:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the big constructions of the face and the basic shape, and put it through the one of these information that folds the whole portion and a structure.
2022-03-23 10:02:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting and measured to me here is that -- well, when someone said, "turn on the men to dtable," and they say, "if the revolution begins to support you."
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of design work that we're at the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation, and a refrigeration system that allows us to be able to use a refrigeration, or if we're either using the refrigeration, if we're able to see the most specific, if you're going to use the buricultivation, if you're going to see the burigation, if you're going to go to go into a mechanism, if you're able to be able to see the ground.
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:24 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.97 | nll_loss 3.32 | ppl 9.99 | bleu 25.02 | wps 5073.8 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.6
2022-03-23 10:02:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:02:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:02:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:02:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 24 @ 3763 updates, score 25.02) (writing took 0.7611869750107871 seconds)
2022-03-23 10:02:25 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:02:25 | INFO | train | epoch 024 | loss 6.928 | nll_loss 3.607 | ppl 12.19 | wps 45302.5 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.515 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2212
2022-03-23 10:02:25 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:02:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:37 | INFO | train_inner | epoch 025:     37 / 157 loss=6.871, nll_loss=3.522, ppl=11.48, wps=36492.9, ups=1.44, wpb=25260, bsz=1026.2, num_updates=3800, lr=0.000475, gnorm=0.468, loss_scale=4, train_wall=31, gb_free=14.8, wall=2224
2022-03-23 10:03:09 | INFO | train_inner | epoch 025:    137 / 157 loss=6.871, nll_loss=3.525, ppl=11.51, wps=80075.2, ups=3.16, wpb=25303.9, bsz=1010.7, num_updates=3900, lr=0.0004875, gnorm=0.515, loss_scale=4, train_wall=31, gb_free=14, wall=2256
2022-03-23 10:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 10:03:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:22 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 10:03:22 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example hypothesis: but everyone musicians find another balance between beliefs and reason, instinct and intelligence.
2022-03-23 10:03:26 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are enabled to the united states.
2022-03-23 10:03:30 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in what i'm focused on, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 10:03:34 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example hypothesis: and as fast as we can restore our computers, the brain activity is to form this new tool when it was a body part of the primates.
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:03:42 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formulas experiments that go far beyond normal education.
2022-03-23 10:03:42 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which is the big configuration of the face and the basic shape of the face, and it goes through the entire porting structure and all the folds.
2022-03-23 10:03:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that women have already been supported -- yes, when they were sucked at the best than someone said, "turn on the men on your table and say," when the revolution begins to support you. "
2022-03-23 10:03:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a great part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation of a continuous variation and a system that allows us to be able to use a refrigerator to the ratio machine that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that, to
2022-03-23 10:03:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:53 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.824 | nll_loss 3.092 | ppl 8.53 | bleu 28.53 | wps 4753.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.53
2022-03-23 10:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:03:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:03:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.53) (writing took 1.8240494150086306 seconds)
2022-03-23 10:03:54 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:03:54 | INFO | train | epoch 025 | loss 6.849 | nll_loss 3.491 | ppl 11.24 | wps 44041 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.491 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2302
2022-03-23 10:03:55 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:20 | INFO | train_inner | epoch 026:     80 / 157 loss=6.785, nll_loss=3.398, ppl=10.54, wps=34358, ups=1.39, wpb=24652.2, bsz=1026.6, num_updates=4000, lr=0.0005, gnorm=0.466, loss_scale=4, train_wall=30, gb_free=20.1, wall=2328
2022-03-23 10:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example hypothesis: this sond can't use chemical rockets.
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example hypothesis: but everyone musicians find another equilibrium between faith and reason, instinct and intelligence.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:05:04 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i am so that i can carry my attention degree in the circuit on the other side.
2022-03-23 10:05:04 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:05:08 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity lasts to form this new tool as if it was a body part of primates.
2022-03-23 10:05:08 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:05:12 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford, from indian science institute that come and bring our children a lot of scientific forms that go far beyond normal class.
2022-03-23 10:05:12 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:05:16 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the face and the basic shape, and refuse it through the whole porting structure and fold it all the ports.
2022-03-23 10:05:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured for me here at tedwomen, is that... tyes, when he said, "well, when somebody said," stop the men at dtable and say, "when the revolution begins to support you."
2022-03-23 10:05:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on on on our plane, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a system that allows us to use the refrigeration until you see that if you can see that there's a refrigeration of a refrigeration to the water.
2022-03-23 10:05:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:23 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.837 | nll_loss 3.102 | ppl 8.59 | bleu 27.98 | wps 4823.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.53
2022-03-23 10:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:05:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:05:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:05:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 26 @ 4077 updates, score 27.98) (writing took 0.7675917580054374 seconds)
2022-03-23 10:05:24 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:05:24 | INFO | train | epoch 026 | loss 6.802 | nll_loss 3.423 | ppl 10.72 | wps 44282.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.487 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2391
2022-03-23 10:05:24 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:31 | INFO | train_inner | epoch 027:     23 / 157 loss=6.796, nll_loss=3.414, ppl=10.66, wps=35245.5, ups=1.41, wpb=25007.4, bsz=1000.1, num_updates=4100, lr=0.000493865, gnorm=0.478, loss_scale=4, train_wall=31, gb_free=13.8, wall=2399
2022-03-23 10:06:03 | INFO | train_inner | epoch 027:    123 / 157 loss=6.755, nll_loss=3.356, ppl=10.24, wps=79603.4, ups=3.19, wpb=24952.8, bsz=975.6, num_updates=4200, lr=0.00048795, gnorm=0.471, loss_scale=4, train_wall=31, gb_free=14.1, wall=2430
2022-03-23 10:06:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example hypothesis: this sonde can't use chemical rockets.
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world different.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:06:29 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can put my attention degree in the board on the other side.
2022-03-23 10:06:32 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: so as quickly as we can reinvent our computer, the brain activity will reform this new tool as if it was a body part of the primates.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:06:40 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:06:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the face and the basic form, and refuse it through the whole portion structure and all the fold.
2022-03-23 10:06:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured, for me here at tedwomen, is that -- well, when dinner was best summarized when somebody said, "turn to the men in your table and say," if the revolution begins to support you. "'the truth is that we've already started to support you, in this very long time," and then we've already been supporting. "
2022-03-23 10:06:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the stumber was a result that we had to solve the unique problems that were connected to the ground -- all from a continuous variation and a refrigeration system that allows us to use the refrigerator, to the refrigerator, to the refrigerator, if we're in the ground, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the buridge the burice or to see the burice, if you can see the burice or to see the burefrigerator, if you can see the burice or to see the burefrigerator, if you can see the refrigerators, or to see the burice of the burefrigerators, if you can see the ground,
2022-03-23 10:06:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:51 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.77 | nll_loss 3.001 | ppl 8.01 | bleu 29.6 | wps 4840 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.6
2022-03-23 10:06:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:06:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:06:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.6) (writing took 1.8503570040047634 seconds)
2022-03-23 10:06:53 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:06:53 | INFO | train | epoch 027 | loss 6.735 | nll_loss 3.325 | ppl 10.02 | wps 44334.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.457 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2480
2022-03-23 10:06:53 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:06:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:14 | INFO | train_inner | epoch 028:     66 / 157 loss=6.676, nll_loss=3.239, ppl=9.44, wps=35845.2, ups=1.41, wpb=25425.4, bsz=1071.8, num_updates=4300, lr=0.000482243, gnorm=0.451, loss_scale=4, train_wall=30, gb_free=14.5, wall=2501
2022-03-23 10:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:46 | INFO | fairseq.tasks.translation | example hypothesis: this sonde can't use chemical rockets.
2022-03-23 10:07:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you can see the world differently.
2022-03-23 10:07:50 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-23 10:07:54 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:07:58 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degrees in the board on the other side.
2022-03-23 10:08:02 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example hypothesis: so as quickly as we can restore our computers, the brain activity has to create this new tool, as if it's a body part of primates.
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers that go far beyond normal education.
2022-03-23 10:08:10 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which gives the big conversations of the face and the basic shape, and refits it through that one information that refits all the ports structure and all the ffits.
2022-03-23 10:08:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting and measured for me here at tedwomen is that... tyes, when someone said, "turn to the men in your table and say," if the revolution begins to support you. "
2022-03-23 10:08:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our aircraft is the result of that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use on the ground, or if you can see the refrigeration, or if you can see the refrigerators.
2022-03-23 10:08:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:18 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.75 | nll_loss 2.987 | ppl 7.93 | bleu 29.3 | wps 5118.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.6
2022-03-23 10:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:08:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:08:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:08:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 28 @ 4391 updates, score 29.3) (writing took 0.7606334480078658 seconds)
2022-03-23 10:08:19 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:08:19 | INFO | train | epoch 028 | loss 6.672 | nll_loss 3.235 | ppl 9.41 | wps 45695 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.435 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2567
2022-03-23 10:08:19 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:08:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:22 | INFO | train_inner | epoch 029:      9 / 157 loss=6.683, nll_loss=3.251, ppl=9.52, wps=36847.7, ups=1.45, wpb=25343.1, bsz=984.4, num_updates=4400, lr=0.000476731, gnorm=0.434, loss_scale=4, train_wall=31, gb_free=13.7, wall=2570
2022-03-23 10:08:54 | INFO | train_inner | epoch 029:    109 / 157 loss=6.612, nll_loss=3.146, ppl=8.85, wps=79683.8, ups=3.19, wpb=24969.6, bsz=1032.4, num_updates=4500, lr=0.000471405, gnorm=0.393, loss_scale=4, train_wall=31, gb_free=14.8, wall=2601
2022-03-23 10:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 10:09:16 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:09:20 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:09:20 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:09:24 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:09:24 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in what i'm focused on so that i can carry my attention degree in the board on the other side.
2022-03-23 10:09:28 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity enables to form this new tool as if it was a body part of the primate.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:09:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic shape, and refits it through the one information that fits the whole portion structure and all the fits.
2022-03-23 10:09:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and say," if the revolution starts to support you. "the truth is that we've already been supporting a long time on this."
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our plane was a result of that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variation and refrigeration to a vehicle that allows us to be able to use a motor engine, to either the ground.
2022-03-23 10:09:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:45 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.677 | nll_loss 2.929 | ppl 7.62 | bleu 30.26 | wps 5033.5 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.26
2022-03-23 10:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:09:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.26) (writing took 1.7413994139933493 seconds)
2022-03-23 10:09:47 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:09:47 | INFO | train | epoch 029 | loss 6.614 | nll_loss 3.151 | ppl 8.88 | wps 45018.2 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.398 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2654
2022-03-23 10:09:47 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:04 | INFO | train_inner | epoch 030:     52 / 157 loss=6.595, nll_loss=3.125, ppl=8.73, wps=36365.4, ups=1.43, wpb=25459.7, bsz=1003, num_updates=4600, lr=0.000466252, gnorm=0.394, loss_scale=4, train_wall=31, gb_free=14.7, wall=2671
2022-03-23 10:10:35 | INFO | train_inner | epoch 030:    152 / 157 loss=6.587, nll_loss=3.114, ppl=8.66, wps=80537.4, ups=3.21, wpb=25116.1, bsz=1053.4, num_updates=4700, lr=0.000461266, gnorm=0.433, loss_scale=4, train_wall=31, gb_free=13.8, wall=2702
2022-03-23 10:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instincts and intelligence.
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example hypothesis: in particular, it's focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so i can carry my attention level in the board on the other side.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can recreate our computers, the brain activity lays up to form this new tool as if it was a body part of the primate.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:11:04 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which gives the big conversations of the face and the basic shape, and put it through the one information that pulls all the porous structure and all the fits.
2022-03-23 10:11:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men in your table and say," if the revolution begins to support you. "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'
2022-03-23 10:11:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use in the aircraft, or if you put it on the ground, you can either use it in a mechanical traffic, or if you can see the vehicle, you can see it in the ground, or if you're going to see it, you're going to see it in the ground, you're going to the aircraft, you're going to a mechanism, you're going to see it, you're going to see it, or if you're going to see it, you're going to see it, you're going to a mechanism, you're going to see it, you're going to see it, you're going to see it, you're going to see it in the
2022-03-23 10:11:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:15 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.654 | nll_loss 2.858 | ppl 7.25 | bleu 31.01 | wps 4766.8 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.01
2022-03-23 10:11:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:11:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:11:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.01) (writing took 1.7346875029907096 seconds)
2022-03-23 10:11:16 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:11:16 | INFO | train | epoch 030 | loss 6.586 | nll_loss 3.111 | ppl 8.64 | wps 44130.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.424 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2744
2022-03-23 10:11:17 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:11:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:47 | INFO | train_inner | epoch 031:     95 / 157 loss=6.537, nll_loss=3.039, ppl=8.22, wps=35127.9, ups=1.39, wpb=25253.7, bsz=993, num_updates=4800, lr=0.000456435, gnorm=0.395, loss_scale=4, train_wall=31, gb_free=13.5, wall=2774
2022-03-23 10:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 10:12:14 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:12:18 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are enabled in the united states.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: it could also be me interested in how i'm focused so i can carry my attention degree on the board.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of primates.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial reflection, which is the big contextures of the face and the basic shape, and deploy it through the whole portion structure and all the fits.
2022-03-23 10:12:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men in your table," and say, "if the revolution starts to support you," the truth is that we've already started to support you for a long time.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work that we're on on on our airplane was a result that we had to solve the unique problems that were connected to operating it -- everything from a continuous variation and refrigeration system that allows us to use aircraft to stop, to a special traffic machine, to the most trigger, to the ground, to see, to the most reliable, to see, to be the ground, to see, or to be the most reliable, if you can see the deployed by the most reliable, by the ground, you can see the defeat the same time you can see the same time you can see the ground, or if you can see the most reliable, you can see the most reliable to see the ground in the ground, and the defeat the most reliable, you can see it in the ground, or if you can see the most reliable, you can see it in the most reliable
2022-03-23 10:12:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:44 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.635 | nll_loss 2.834 | ppl 7.13 | bleu 30.92 | wps 4863.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.01
2022-03-23 10:12:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:12:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:12:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:12:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 31 @ 4862 updates, score 30.92) (writing took 0.8672205690090777 seconds)
2022-03-23 10:12:45 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:12:45 | INFO | train | epoch 031 | loss 6.532 | nll_loss 3.034 | ppl 8.19 | wps 44694.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.394 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2832
2022-03-23 10:12:45 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:12:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:58 | INFO | train_inner | epoch 032:     38 / 157 loss=6.511, nll_loss=3.003, ppl=8.01, wps=35228.7, ups=1.41, wpb=24898.9, bsz=1067.6, num_updates=4900, lr=0.000451754, gnorm=0.405, loss_scale=4, train_wall=30, gb_free=13.7, wall=2845
2022-03-23 10:13:29 | INFO | train_inner | epoch 032:    138 / 157 loss=6.522, nll_loss=3.019, ppl=8.11, wps=80232.7, ups=3.16, wpb=25391.9, bsz=991.7, num_updates=5000, lr=0.000447214, gnorm=0.387, loss_scale=4, train_wall=31, gb_free=13.6, wall=2877
2022-03-23 10:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:13:43 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-23 10:13:43 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are enabled to the united states.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so that i can carry my attention level in the board on the other side.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reinvent our computers, the brain activity shifts to form this new tool, as if it was a body part of the primate.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that gives the big contextures of the face and the basic shape, and recongestion it through the theft of that information, which refits the whole portion structure and all the fits.
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen, is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution starts to support you, "if the truth is that we already started supporting you for a long time."
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on on the aircraft was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable operating and refrigeration system, that it allows us to use an aircraft on the stop traffic until a particular passenger, until you see the ground.
2022-03-23 10:14:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.585 | nll_loss 2.789 | ppl 6.91 | bleu 32.1 | wps 4849.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 32.1
2022-03-23 10:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 32 @ 5019 updates, score 32.1) (writing took 1.755881919991225 seconds)
2022-03-23 10:14:14 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:14:14 | INFO | train | epoch 032 | loss 6.503 | nll_loss 2.992 | ppl 7.95 | wps 44111.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.391 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2922
2022-03-23 10:14:15 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:40 | INFO | train_inner | epoch 033:     81 / 157 loss=6.456, nll_loss=2.922, ppl=7.58, wps=34927.8, ups=1.4, wpb=24880.4, bsz=1026.3, num_updates=5100, lr=0.000442807, gnorm=0.39, loss_scale=4, train_wall=31, gb_free=14.8, wall=2948
2022-03-23 10:15:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:15:15 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:15:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: in particular, it's focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:15:19 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i'm, so i can put my attention degree in the board on the other side.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reinvent our computers, the brain activity shifts to form this new tool, as if it was a body part of the primate.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which gives the big conversations of the face and the basic shape, and through those information that includes the whole porous structure and all the fits.
2022-03-23 10:15:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here, is that... well, by the end of the dinner, it was best summarized when someone said, "turn to the men in your table and say," if the revolution begins to support you, '"well,' the truth is that we've already started to support you." '"'" '"'" '"'" '"'" '"well, you know, you know, you know, you know, you know,"' "i mean, you know," i mean, you know, you know, you know, you know, you know, "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still necessary, and a big part of the design work that we're most proud about at our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation of design work, and a cooling system that we're on the plane at the go-go-by-sighted level, or if you're going to see the ground, if you're going to be able to go, if you're going to the security or if you're going to be able to be able to be able to be able to see the most specific, if you're going to the ground, or if you're going to be able to be able to be able to go, or if you're going to go, you're going to be able to be able to see the most important, you're going to go, or if you're going to be able to see the safety, or if you're going to be able to the
2022-03-23 10:15:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:43 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.597 | nll_loss 2.817 | ppl 7.05 | bleu 31.89 | wps 4673.6 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.1
2022-03-23 10:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 33 @ 5176 updates, score 31.89) (writing took 0.858561375993304 seconds)
2022-03-23 10:15:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:15:44 | INFO | train | epoch 033 | loss 6.471 | nll_loss 2.946 | ppl 7.71 | wps 44166.7 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.412 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3011
2022-03-23 10:15:44 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:52 | INFO | train_inner | epoch 034:     24 / 157 loss=6.487, nll_loss=2.97, ppl=7.84, wps=35707.6, ups=1.4, wpb=25446.9, bsz=1002.9, num_updates=5200, lr=0.000438529, gnorm=0.436, loss_scale=4, train_wall=31, gb_free=13.7, wall=3019
2022-03-23 10:16:23 | INFO | train_inner | epoch 034:    124 / 157 loss=6.417, nll_loss=2.866, ppl=7.29, wps=79921.4, ups=3.19, wpb=25063.4, bsz=1053.4, num_updates=5300, lr=0.000434372, gnorm=0.351, loss_scale=4, train_wall=31, gb_free=14.1, wall=3050
2022-03-23 10:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:37 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:16:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between believing and reason, instinct and intelligence.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can put my attention degree in the board on the other side.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to reform this new tool as if it was a body part of primates.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:17:01 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial face, and the basic shape, and put it through that information that refits the entire porter structure and all the fits.
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's getting up and measured, for me here at tedwomen, is that... well, when dinner was best summarized when somebody said, "turn to the men on your table and tell them," when the revolution starts supporting you, "the truth is that we've already started to support you for this long time."
2022-03-23 10:17:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're stumbling on on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable operating and a refrigerator system, that allows us to use an aircraft in clogon the go-bound traffic, to either drive the car drivers until you see the floor, to see the car storm, to see the same thing when you're going to the first mechanism -- everything from a continuous variation of a continuous variation -- everything from a continuous variation, and a continuous variation system -- everything from a continuous variation system, to a refrigeration system, to a refrigerator, to a refrigerator, to a refrigeration system, to a refrigerator, to a refrigeration system, to a refrigeration system that allows us to see
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:11 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.561 | nll_loss 2.774 | ppl 6.84 | bleu 31.96 | wps 4767.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.1
2022-03-23 10:17:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:17:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:17:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:17:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 34 @ 5333 updates, score 31.96) (writing took 0.7857990390039049 seconds)
2022-03-23 10:17:12 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:17:12 | INFO | train | epoch 034 | loss 6.433 | nll_loss 2.89 | ppl 7.41 | wps 44619.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.377 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3100
2022-03-23 10:17:12 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:34 | INFO | train_inner | epoch 035:     67 / 157 loss=6.423, nll_loss=2.875, ppl=7.33, wps=35086.8, ups=1.41, wpb=24815.7, bsz=930.4, num_updates=5400, lr=0.000430331, gnorm=0.369, loss_scale=4, train_wall=31, gb_free=13.8, wall=3121
2022-03-23 10:18:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:05 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:18:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:18:09 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 10:18:09 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:18:13 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instinct and intelligence.
2022-03-23 10:18:13 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:18:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 10:18:17 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:18:21 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can put my attention level on the board on the other side.
2022-03-23 10:18:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reconcile our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 10:18:25 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which gives back the big contextures of the face and the basic shape, and refits it through the entire pore-structure and all the fits.
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that -- well, when you put it on a striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you, 'when the revolution begins, we support you.' '' '' '' '' '' '' '' '' the truth, women, we've already started to support you for a long time." '"'" '"'" '"'" '"'" '"' well, you know, you know," '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on on on our plane, was a result of how we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variant variables, and a refrigeration system that it allows us to use an aircraft in close-up, or if you're in a rift, or if you're on the ground, or if you're in the car, or you're going to move it, or if you're in the sailing, or the sailing, or the car, or the versest one, or you're going to a deathly, or the burial, or the burial, or a deathly, or a deathly, or the burial, you're going to the burial.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:41 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.554 | nll_loss 2.753 | ppl 6.74 | bleu 32.53 | wps 4657.6 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.53
2022-03-23 10:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.53) (writing took 1.7820570759940892 seconds)
2022-03-23 10:18:42 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:18:42 | INFO | train | epoch 035 | loss 6.4 | nll_loss 2.843 | ppl 7.17 | wps 43789.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.376 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3190
2022-03-23 10:18:43 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:46 | INFO | train_inner | epoch 036:     10 / 157 loss=6.385, nll_loss=2.822, ppl=7.07, wps=35206.1, ups=1.39, wpb=25384, bsz=1089.6, num_updates=5500, lr=0.000426401, gnorm=0.387, loss_scale=4, train_wall=30, gb_free=13.8, wall=3193
2022-03-23 10:19:17 | INFO | train_inner | epoch 036:    110 / 157 loss=6.371, nll_loss=2.801, ppl=6.97, wps=80905, ups=3.2, wpb=25274.9, bsz=1040, num_updates=5600, lr=0.000422577, gnorm=0.379, loss_scale=4, train_wall=31, gb_free=14.8, wall=3225
2022-03-23 10:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:35 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:19:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-23 10:19:40 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:19:44 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instincts and intelligence.
2022-03-23 10:19:44 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are ending allies in the united states.
2022-03-23 10:19:47 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i'm so that i can put my attention level in the board on the other side.
2022-03-23 10:19:51 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reconcile our computers, the brain activity shifts to this new tool as if it was a body part of the primates.
2022-03-23 10:19:55 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:19:59 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which gives the big contextures of the face and the basic shape, and reconcile it through those information that pulls all the porous structure and all the fones.
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here in tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and say," if the revolution begins to support you, then we support you. "the truth is that, women are supporting you."
2022-03-23 10:20:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation of the design and a refrigerator system with refrigeration that allows us to use an aircraft on the go-go-traffic and traffic machine to a specific traffic machine, to a specific amount of passage, to a passing machine that either drifts on the ground, if you can see the ground, or if you can see it's going to run it at the same time you can see it in the same time you're going to the same mechanism, if you can see it's going to the same mechanism that you're going to the same time you're going to operate on a mechanism that you're going to the same mechanism, if you can see it in a mechanism, and you can see it's going to run it's going to the
2022-03-23 10:20:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:11 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.526 | nll_loss 2.712 | ppl 6.55 | bleu 32.96 | wps 4680.3 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.96
2022-03-23 10:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:20:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.96) (writing took 1.9285866980062565 seconds)
2022-03-23 10:20:12 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:20:12 | INFO | train | epoch 036 | loss 6.38 | nll_loss 2.814 | ppl 7.03 | wps 43826.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.375 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3280
2022-03-23 10:20:13 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:20:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:30 | INFO | train_inner | epoch 037:     53 / 157 loss=6.381, nll_loss=2.816, ppl=7.04, wps=34363.9, ups=1.38, wpb=24912.3, bsz=1024.3, num_updates=5700, lr=0.000418854, gnorm=0.384, loss_scale=4, train_wall=31, gb_free=14.2, wall=3297
2022-03-23 10:21:01 | INFO | train_inner | epoch 037:    153 / 157 loss=6.366, nll_loss=2.793, ppl=6.93, wps=82368.3, ups=3.22, wpb=25589.5, bsz=1001.1, num_updates=5800, lr=0.000415227, gnorm=0.37, loss_scale=4, train_wall=31, gb_free=14.2, wall=3328
2022-03-23 10:21:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:06 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:21:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:21:10 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-23 10:21:10 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:21:14 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are tied to the united states.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i'm so that i can put my attention degree in the circuit board on the other side.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reconcile our computers, the brain activity shifts to this new tool as if it was a body part of the primates.
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:21:29 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:21:29 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that resembles the big contextures of the face and the basic shape, and congestion it through the whole porous structure and all the fine folding.
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that, well, when you stick dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins to support you. "the truth, women have already started to support you for a long time.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're stumbling on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation to a refrigerator system that allows us to use an aircraft machine at the go-traffic until a refrigeration system with a refrigeration system with a refrigeration system with a refrigerator, to be able to use an aircraft on a static traffic, to either triggerator or a special transport, to move it to move it to a stairrefrigerator, to move it to a stairrefrigerator, to an aircraft machine, to a special transport.
2022-03-23 10:21:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.522 | nll_loss 2.702 | ppl 6.51 | bleu 32.47 | wps 4788.6 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.96
2022-03-23 10:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:21:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:21:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:21:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.47) (writing took 0.868429150999873 seconds)
2022-03-23 10:21:41 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:21:41 | INFO | train | epoch 037 | loss 6.361 | nll_loss 2.786 | ppl 6.9 | wps 44766 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.38 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3368
2022-03-23 10:21:41 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:21:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:12 | INFO | train_inner | epoch 038:     96 / 157 loss=6.308, nll_loss=2.709, ppl=6.54, wps=35601.1, ups=1.41, wpb=25250.9, bsz=1067.8, num_updates=5900, lr=0.000411693, gnorm=0.362, loss_scale=4, train_wall=31, gb_free=14.3, wall=3399
2022-03-23 10:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are ending allies in the united states.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:22:50 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so i can put my attention degree in the board on the other hand.
2022-03-23 10:22:50 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can rehire our computers, the brain activity shifts to form this new tool as if it was a body of primates.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:23:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection, we can start with a traditional facial can that restores the grows contexts of the face and the basic shape, and revives it by the one that refuses the entire porous structure and all the fits.
2022-03-23 10:23:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me here at tedwomen is that... well, when it was stripped to dinner, it was best summarized when someone said, "turn to the men at your table and say," well, if the revolution begins to support you. '"' the truth, women, love is that we've already started to support you for a long time." in this topic, "and we've been supported with raw borrows'"
2022-03-23 10:23:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a great part of the design work that we're on on on our plane was a result of how we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable gear and refrigeration system with liquid, that it allows us to use an aircraft in stop traffic, or if you could see the ground, or when you get rid of the deprived in the first mechanism, and you can see it in the same way, and you can see it in the same way that we can see it in the same way that we can see it in the same way that we can see it in a continuous variable to the ground with a continuous variation with a continuous variation, and see it's going on the same way that we can see it, and we can use a refrigeration with a refrigeration with a refrigerator, and see it, and see it
2022-03-23 10:23:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.501 | nll_loss 2.689 | ppl 6.45 | bleu 33.2 | wps 4716.5 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.2
2022-03-23 10:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:23:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 38 @ 5961 updates, score 33.2) (writing took 2.0376804389961762 seconds)
2022-03-23 10:23:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:23:11 | INFO | train | epoch 038 | loss 6.328 | nll_loss 2.739 | ppl 6.67 | wps 43496.7 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.366 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3459
2022-03-23 10:23:12 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:23:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:24 | INFO | train_inner | epoch 039:     39 / 157 loss=6.334, nll_loss=2.746, ppl=6.71, wps=34314.6, ups=1.38, wpb=24921.4, bsz=967, num_updates=6000, lr=0.000408248, gnorm=0.349, loss_scale=4, train_wall=30, gb_free=13.6, wall=3472
2022-03-23 10:23:56 | INFO | train_inner | epoch 039:    139 / 157 loss=6.299, nll_loss=2.695, ppl=6.47, wps=79675.5, ups=3.2, wpb=24936.7, bsz=1028.5, num_updates=6100, lr=0.000404888, gnorm=0.357, loss_scale=4, train_wall=31, gb_free=14.2, wall=3503
2022-03-23 10:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:05 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:24:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:24:13 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:24:13 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:24:17 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:24:17 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:24:20 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how i'm focused so i can put my attention degree on the board on the other side.
2022-03-23 10:24:20 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:24:24 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool, as if it was a body part of the primate.
2022-03-23 10:24:24 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:24:28 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal class.
2022-03-23 10:24:28 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape of it, and deploy it through the one of the information that pulls all the porous structure and all the fine folds.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen, is that... well, when striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins to support you, then we say, "the truth, women is that we've already been supporting you for a long period of time." with rake's "and then we said," and then we said, "turn to the future of sand." and then, "and then,"
2022-03-23 10:24:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable gear, and a refrigerator system with liquid that allows us to use an aircraft in stop traffic to a particular driver, or if you're going to see the ground on the ground, if you can see it, or if you're on the ground, it's on the ground, you can see it, all the ground, or if you're on the ground, it's all the ground, if you're going to go, all the ground, it's right, if you can, you can see it's going to go, all the ground, or if you can see it's right, if you're going to the ground, you're going to go, it's all the ground, you're going to go, or if you can see it's the
2022-03-23 10:24:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:39 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.504 | nll_loss 2.678 | ppl 6.4 | bleu 33.13 | wps 4913.8 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.2
2022-03-23 10:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 39 @ 6118 updates, score 33.13) (writing took 0.7964584100118373 seconds)
2022-03-23 10:24:39 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:24:39 | INFO | train | epoch 039 | loss 6.299 | nll_loss 2.696 | ppl 6.48 | wps 44888.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.346 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3547
2022-03-23 10:24:40 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:05 | INFO | train_inner | epoch 040:     82 / 157 loss=6.32, nll_loss=2.725, ppl=6.61, wps=35525.6, ups=1.43, wpb=24790.6, bsz=935.9, num_updates=6200, lr=0.00040161, gnorm=0.388, loss_scale=4, train_wall=30, gb_free=13.8, wall=3573
2022-03-23 10:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:33 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:25:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world differently.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instincts and intelligence.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so that i can put my attention level in the board on the other side of the board.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can rehire our computers, the brain activity to form this new tool as if it was a body part of the primate.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:25:56 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face can, which gives the big contextures of the face and the basic shape, and reconcile it through the one of the information that pulls all the porous structure and all the fine folds.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured, for me here at tedwomen, is that... well, when dinner stripped dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution begins, then we support you. 'the truth is that we've already started to support you for a long time. "
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on on on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable operator and a refrigerator system with liquid, that it allows us to use an aircraft in stop traffic to a special passenger, either if you can see the ground, or if you're going to the first mechanism, or if you can see it's a mechanism, all the ground.
2022-03-23 10:26:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:07 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.462 | nll_loss 2.642 | ppl 6.24 | bleu 33.68 | wps 4905.5 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.68
2022-03-23 10:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt
2022-03-23 10:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_best.pt (epoch 40 @ 6275 updates, score 33.68) (writing took 1.9053242840018356 seconds)
2022-03-23 10:26:09 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:26:09 | INFO | train | epoch 040 | loss 6.289 | nll_loss 2.681 | ppl 6.41 | wps 44312.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.364 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3636
2022-03-23 10:26:09 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:17 | INFO | train_inner | epoch 041:     25 / 157 loss=6.256, nll_loss=2.633, ppl=6.2, wps=35609.8, ups=1.4, wpb=25484.2, bsz=1081.8, num_updates=6300, lr=0.00039841, gnorm=0.334, loss_scale=4, train_wall=31, gb_free=14, wall=3644
2022-03-23 10:26:49 | INFO | train_inner | epoch 041:    125 / 157 loss=6.278, nll_loss=2.667, ppl=6.35, wps=81061.4, ups=3.16, wpb=25630.3, bsz=1010.1, num_updates=6400, lr=0.000395285, gnorm=0.357, loss_scale=4, train_wall=31, gb_free=13.7, wall=3676
2022-03-23 10:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, look at the world differently.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between believing and reason, instinct and intelligence.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how i'm focused so that i can put my attention degree on the board on the other hand.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reframe our computers, the activity of brain shifts to form this new tool, as if it were a body part of the primate.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that resurrects the grove contextures of the face and the basic shape, and deploy it by the one that refits the entire porous structure and all the fine.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and appropriate for me to be here at tedwomen is that... well, when controversial dinner, it was best summarized best when someone said, "turn to men on your table and tell you, 'when the revolution begins, we support you.' the truth is women, we've been supporting you in this topic for a long time. chel carrays"
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still, and a big part of the design work that we're most stumbling on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation of the design system with refrigerator, that it allows us to use an aircraft machine in stop go-traffic to a special passenger, either the propeller on the ground, or if you can see the mechanism of a mechanism, or if you can see the same mechanism on the ground.
2022-03-23 10:27:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:36 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.476 | nll_loss 2.649 | ppl 6.27 | bleu 33.11 | wps 4852.4 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.68
2022-03-23 10:27:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:27:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:27:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.11) (writing took 0.8629117759992369 seconds)
2022-03-23 10:27:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:27:37 | INFO | train | epoch 041 | loss 6.263 | nll_loss 2.645 | ppl 6.26 | wps 44850.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.349 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 3724
2022-03-23 10:27:37 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:59 | INFO | train_inner | epoch 042:     68 / 157 loss=6.254, nll_loss=2.63, ppl=6.19, wps=36118.1, ups=1.42, wpb=25376.9, bsz=1000.6, num_updates=6500, lr=0.000392232, gnorm=0.36, loss_scale=4, train_wall=31, gb_free=13.7, wall=3746
2022-03-23 10:28:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:30 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:28:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:28:34 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 10:28:34 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between believing and reason, instinct and intelligence.
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so i can put my attention degree on the board on the other side.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go way beyond normal education.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face can that restores the big contextures of the face and the basic shape, and deploy it through the information that refers all the porous structure and all the fine folds.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was stripped, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins to support you. '"the truth, women love is that we've already been supporting you in this topic for a long time, and then we've been supporting you with rachel carraw spring," and then we're going to download the future of sand. "
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a lot of the design work that we're most stumbling on on on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation of the design work, and a refrigerator system with liquid, that it allows us to use an aircraft machine in stop traffic to a particular passage that either drives the propelled to the ground if you see the propelled by a mechanism, or when you see the same mechanism, until a mechanism, until you see the mechanism is the intersection of the first mechanism, to the intersection of a mechanism, to the intersection of one of the interior ior ior ior ior ior ior ior ior ior ior ior ior ior ior ior fluid, to the mechanism, to the interior ior ior ior ior ior fluid, to the intersection of the interior ior ior fluid
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:05 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.455 | nll_loss 2.629 | ppl 6.19 | bleu 33.64 | wps 4696 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.68
2022-03-23 10:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.64) (writing took 0.8718832510057837 seconds)
2022-03-23 10:29:06 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:29:06 | INFO | train | epoch 042 | loss 6.247 | nll_loss 2.62 | ppl 6.15 | wps 44278.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.36 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3813
2022-03-23 10:29:06 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:10 | INFO | train_inner | epoch 043:     11 / 157 loss=6.228, nll_loss=2.594, ppl=6.04, wps=34246.5, ups=1.41, wpb=24246.7, bsz=1056.9, num_updates=6600, lr=0.000389249, gnorm=0.359, loss_scale=4, train_wall=30, gb_free=13.6, wall=3817
2022-03-23 10:29:41 | INFO | train_inner | epoch 043:    111 / 157 loss=6.222, nll_loss=2.582, ppl=5.99, wps=80285.5, ups=3.16, wpb=25396.6, bsz=1031.2, num_updates=6700, lr=0.000386334, gnorm=0.35, loss_scale=4, train_wall=31, gb_free=13.8, wall=3849
2022-03-23 10:29:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:59 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:29:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:30:03 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without knowing it, you see the world differently.
2022-03-23 10:30:03 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:30:07 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instincts and intelligence.
2022-03-23 10:30:07 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:30:11 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are tight allies in the united states.
2022-03-23 10:30:11 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:30:15 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how i'm focused so i can put my attention degree on the board on the other side.
2022-03-23 10:30:15 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can reframe our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 10:30:19 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 10:30:23 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which resurrects the grove contexts of the face and the basic shape, and put it through the one of the information that refers all the porous structure and all the fine folds.
2022-03-23 10:30:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to me here at tedwomen is that... well, when stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, then we support you. "'" the truth, women love is that we've already been supporting you for a long time. "carrays down," and then we said, "goodbye to the sand stream."
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example hypothesis: thankfully, the mother of invention is still a large part of the design work that we are on on our plane at the stumble, a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variation of the design work, and a refrigerator system with liquid that allows us to use an aircraft on stop go-traffic, to a particular passenger the ground, if you drift the propelled the ground, or when you hit the bureaucracy of a mechanism, to the security system, to the car storm, to the ground, to the same time you can see, until a mechanical storm, until a mechanical storm, to a mechanism, to the security system, to the first time you can see the bug, to a mechanism, to the bug, to the car storm, to the crash, to the ground, and when you can see the bug, to the
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:34 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.468 | nll_loss 2.617 | ppl 6.13 | bleu 33.53 | wps 4743.4 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.68
2022-03-23 10:30:34 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:30:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:30:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:30:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt
2022-03-23 10:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.3_#2/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.53) (writing took 0.8078325879905606 seconds)
2022-03-23 10:30:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:30:35 | INFO | train | epoch 043 | loss 6.227 | nll_loss 2.591 | ppl 6.03 | wps 44513.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.354 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3902
2022-03-23 10:30:35 | INFO | fairseq_cli.train | done training in 3901.5 seconds
