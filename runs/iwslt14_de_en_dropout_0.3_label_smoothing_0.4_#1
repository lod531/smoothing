Sender: LSF System <lsfadmin@eu-g3-049>
Subject: Job 210581981: <iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:26:36 2022
Job was executed on host(s) <eu-g3-049>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:26:54 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:26:54 2022
Terminated at Wed Mar 23 10:45:01 2022
Results reported at Wed Mar 23 10:45:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.4 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4670.96 sec.
    Max Memory :                                 5239 MB
    Average Memory :                             4038.10 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14761.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4686 sec.
    Turnaround time :                            4705 sec.

The output (if any) follows:

2022-03-23 09:27:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.4, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.4, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:27:04 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:27:04 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:27:04 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:27:04 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:27:04 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:27:04 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:27:04 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:27:04 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:27:04 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:27:08 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:27:08 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:27:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:27:08 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:27:08 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:27:08 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:27:08 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:27:08 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:27:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:27:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:27:08 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:27:09 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:27:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:27:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:27:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:27:45 | INFO | train_inner | epoch 001:    104 / 157 loss=12.499, nll_loss=11.875, ppl=3757.21, wps=79934.5, ups=3.18, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.166, loss_scale=8, train_wall=36, gb_free=14, wall=37
2022-03-23 09:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:28:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:28:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:28:13 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:28:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:28:17 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.387 | nll_loss 10.061 | ppl 1068.28 | bleu 0.01 | wps 4305.8 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:28:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.590984476992162 seconds)
2022-03-23 09:28:44 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:28:44 | INFO | train | epoch 001 | loss 12.208 | nll_loss 11.403 | ppl 2707.81 | wps 42249.9 | ups 1.68 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 1.72 | loss_scale 8 | train_wall 52 | gb_free 22.4 | wall 96
2022-03-23 09:28:44 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:59 | INFO | train_inner | epoch 002:     47 / 157 loss=11.5, nll_loss=10.264, ppl=1229.25, wps=34085.2, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.83, loss_scale=8, train_wall=30, gb_free=14.7, wall=111
2022-03-23 09:29:31 | INFO | train_inner | epoch 002:    147 / 157 loss=11.088, nll_loss=9.548, ppl=748.43, wps=79887.6, ups=3.17, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.9, loss_scale=8, train_wall=31, gb_free=14, wall=143
2022-03-23 09:29:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the.
2022-03-23 09:29:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:50 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example hypothesis: and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:29:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:30:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:12 | INFO | fairseq.tasks.translation | example hypothesis: and and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:30:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:19 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:30:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:21 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.893 | nll_loss 9.098 | ppl 547.81 | bleu 0.01 | wps 3667.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:30:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.6715817440126557 seconds)
2022-03-23 09:30:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:30:23 | INFO | train | epoch 002 | loss 11.155 | nll_loss 9.672 | ppl 815.83 | wps 39866.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.856 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 195
2022-03-23 09:30:23 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:52 | INFO | train_inner | epoch 003:     90 / 157 loss=10.936, nll_loss=9.243, ppl=605.85, wps=30456.6, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.865, loss_scale=8, train_wall=30, gb_free=13.7, wall=223
2022-03-23 09:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:31:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the.
2022-03-23 09:31:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example hypothesis: and the the the of the of the the of the of the.
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, and it's, and it's, and it's, and it's, and it's's's, and it's's's's.
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's's, it's, it's's's, it's, it's's's, and it's's, it's's's's's, it's's's's's, and it's's's's
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example hypothesis: and and the the, and the the, and the the the the, and the the the, and and the the the, and and and the the the the the the the the the the the the the the the the the the of the the the the the the the the the the the
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:46 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's, it's, it's, and it's, it's's, and it's, it's's's's's, and it's's's's, and it's, and it's, and it's's, it's's's's's's's, and the the the the the the the
2022-03-23 09:31:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example hypothesis: and we, and we, and we the the the the the the, we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and the the the the the the, and the the the the the the the the the, and the the the the the the the the the the the the the the the the the, and the the
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example hypothesis: and it's, we, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:32:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, the the the the the the the the the the the the the the the the the the the the the, we, we, we, we, we, the the the the the the the the the the the the the the the the the the, we, we, we, we, we, we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:02 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.768 | nll_loss 8.815 | ppl 450.46 | bleu 0.19 | wps 3515.3 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.19
2022-03-23 09:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.19) (writing took 1.673006066994276 seconds)
2022-03-23 09:32:04 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:32:04 | INFO | train | epoch 003 | loss 10.891 | nll_loss 9.16 | ppl 571.89 | wps 39155 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.923 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 296
2022-03-23 09:32:04 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:15 | INFO | train_inner | epoch 004:     33 / 157 loss=10.809, nll_loss=9.008, ppl=514.7, wps=30504.7, ups=1.2, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=0.893, loss_scale=8, train_wall=31, gb_free=13.9, wall=307
2022-03-23 09:32:47 | INFO | train_inner | epoch 004:    133 / 157 loss=10.691, nll_loss=8.794, ppl=443.97, wps=79994.9, ups=3.17, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.022, loss_scale=8, train_wall=31, gb_free=12.6, wall=338
2022-03-23 09:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example hypothesis: we've've've've've've've've've've've've have in the world in the world.
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the that is that's the world of the world.
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:33:05 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to be to be to be a a to be to be.
2022-03-23 09:33:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, it's a to be a a of the world, and it's a.
2022-03-23 09:33:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not that we're not not not that's not not not not not not not not not not not that we have to do it.
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world of the world, and the world of the world of the world of the world of the world.
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:27 | INFO | fairseq.tasks.translation | example hypothesis: but it's a, but you can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't have
2022-03-23 09:33:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:33 | INFO | fairseq.tasks.translation | example hypothesis: so, we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the the the to be to be to be be be be be be be be to be to be to be to be be be be be be be the the the the the the world.
2022-03-23 09:33:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:40 | INFO | fairseq.tasks.translation | example hypothesis: so, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:33:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:42 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to be a a a a a to be to be to be a to be to be to be to be to be to be to be to be a to be to be to be to be to be to be to be to be to be to be to be to be to be, and it, and it, and it, and it's a a a a a a a a a a a a a a to be to be a a to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be be be be be be be be be be to be to be to be be be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be a
2022-03-23 09:33:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:42 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.492 | nll_loss 8.276 | ppl 309.98 | bleu 0.82 | wps 3604.7 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.82
2022-03-23 09:33:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:33:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.82) (writing took 1.7502464479766786 seconds)
2022-03-23 09:33:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:33:44 | INFO | train | epoch 004 | loss 10.692 | nll_loss 8.796 | ppl 444.46 | wps 39380.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.934 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 396
2022-03-23 09:33:45 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:33:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:08 | INFO | train_inner | epoch 005:     76 / 157 loss=10.553, nll_loss=8.541, ppl=372.55, wps=30064.9, ups=1.22, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.028, loss_scale=8, train_wall=30, gb_free=13.4, wall=420
2022-03-23 09:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:37 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 09:34:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the world.
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:48 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:34:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not not not not not not not not not not not not not that we're going to do that.
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world in the world, and the world in the world.
2022-03-23 09:34:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example hypothesis: but there are a lot of the world, but they're not not not not a lot of the lot, but but they're not not not not not not not not not a lot of the world.
2022-03-23 09:35:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:05 | INFO | fairseq.tasks.translation | example hypothesis: and we're a lot of the lot of the lot of the world, and we can see the lot of the world, and the world, and the world, and we can see the world.
2022-03-23 09:35:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:13 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot, "" "" "" "" "" "" "" "" "the first first," the first, "it's a lot," it's a lot, "" it's a lot, "" "" "" "" "" "" "it," it's a lot, "" "" "" "" "" "" it's a lot, "" "" "" "it's a lot," "" "" "" "it's a lot," "it's a lot," "it's a lot," "" "" "it's a lot," "it's a lot," "it's a lot," "it's a lot," "" "" "it," it's a lot, "" "" "" "" "" "
2022-03-23 09:35:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:15 | INFO | fairseq.tasks.translation | example hypothesis: and that was a lot of the lot of the lot of the world, which was a lot of the world, and the world, that we have a lot of the world, that we have a lot of the world that was a lot of the world, that was a lot of the world, that was a lot of the world, which was a lot of the world, that was a lot of the world, that was a lot of the world, which was a lot of the world, which was a lot of the world, and the world, and the world, that we've've've've've've've've've've've've've have a lot of the world that was a lot of the world that was a lot of the world to be a lot of the world, and the world to be a lot of the world that was a lot of the world, and the world, and the world, and the world, that was a lot of the world that was a lot of the world, which was a lot of the world, and the
2022-03-23 09:35:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:15 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.284 | nll_loss 7.957 | ppl 248.4 | bleu 1.71 | wps 4334.8 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.71
2022-03-23 09:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.71) (writing took 1.6829154829902109 seconds)
2022-03-23 09:35:17 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:35:17 | INFO | train | epoch 005 | loss 10.455 | nll_loss 8.358 | ppl 328.08 | wps 42731.3 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.02 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 489
2022-03-23 09:35:17 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:23 | INFO | train_inner | epoch 006:     19 / 157 loss=10.39, nll_loss=8.237, ppl=301.61, wps=33984.5, ups=1.34, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.058, loss_scale=8, train_wall=31, gb_free=14.6, wall=495
2022-03-23 09:35:54 | INFO | train_inner | epoch 006:    119 / 157 loss=10.281, nll_loss=8.033, ppl=261.92, wps=80373.1, ups=3.17, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=0.938, loss_scale=8, train_wall=31, gb_free=13.7, wall=526
2022-03-23 09:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:10 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 09:36:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the first thing that the first thing is that's the first thing.
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be two of the world.
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, there's a lot of the world, and there's going to be going to be a lot of it.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do that we're going to do it's going to do that we're going to do that we're going to do it's going to do it's going to do it's going to do it
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:33 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world in the world, and in the world, and the world, and the world is the world in the world in the world in the world in the world in the world, and the world in the world, and the world, and the world, and the world,
2022-03-23 09:36:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be not not not going to see, but they're going to be a lot of the world, but they're going to be not not going to be not not going to be not not going to see the same of the world.
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:45 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to see that we're going to see the world, and we're going to see the world, and we're going to see that we're going to see the world, and we're going to see that we're going to see the world, and we're going to see the world, and we're going to see the world, and then we're going to see the world, and then we're going to see the world, we can
2022-03-23 09:36:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "it's the" "" "" "it's the" "" "it's the first first first first first first first first first first first first first first first first first first first first" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example hypothesis: if we think that we're going to be a lot of the world, that we're going to be that we're going to be that we're going to be a lot of that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to do that we're going to be a lot of the world, but we're going to be that we're going to do that we're going to be a lot of the world that we're going to be a lot of the world that we're going to do that we're going to make the world that we're going to do that we're going to do that we're going to be a lot of the world that we're going to make the world that we're going to do that we're going to do that we're going to do that we're going to do that we're going to make the world that we're going to do that we're going to do that we're going
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:55 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.095 | nll_loss 7.493 | ppl 180.13 | bleu 1.56 | wps 3610.8 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.71
2022-03-23 09:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 09:36:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.56) (writing took 0.7599858939938713 seconds)
2022-03-23 09:36:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:36:56 | INFO | train | epoch 006 | loss 10.268 | nll_loss 8.007 | ppl 257.2 | wps 39797.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.957 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 588
2022-03-23 09:36:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:16 | INFO | train_inner | epoch 007:     62 / 157 loss=10.154, nll_loss=7.795, ppl=222.12, wps=30943.8, ups=1.23, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.868, loss_scale=8, train_wall=31, gb_free=13.5, wall=608
2022-03-23 09:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most thing that you're going to see that you're going to see here.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:59 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be able to be going to be able to be able to be able to be able to be two.
2022-03-23 09:37:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there are going to be, and there's a lot of the world, and there's a lot of the world.
2022-03-23 09:38:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do it, and it's going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do it.
2022-03-23 09:38:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:15 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people in the world, in the world, in the world, in the world, in the world, and in the world, and it's in the world.
2022-03-23 09:38:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but they're not going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world.
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to be a lot of the world, and we can see that we can see that we can see that we can see the world, and we can see that we can see that we can see the world.
2022-03-23 09:38:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:34 | INFO | fairseq.tasks.translation | example hypothesis: and if you're going to say, "you know," you know, "you're going to say," you know, "you know," you're going to say, "you're going to say," you know, "you know," you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "" ""
2022-03-23 09:38:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:36 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, we're going to be a lot of the world, and we're going to see that we're going to get a lot of the world, and then we're going to be a lot of the world, and then we're going to be a lot of the world, and then we're going to see that we're going to be a lot of the world, and then we're going to be a lot of the world.
2022-03-23 09:38:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:36 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.977 | nll_loss 7.262 | ppl 153.52 | bleu 1.89 | wps 3473.1 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 1.89
2022-03-23 09:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 09:38:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 1.89) (writing took 1.6922646640159655 seconds)
2022-03-23 09:38:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:38:38 | INFO | train | epoch 007 | loss 10.1 | nll_loss 7.695 | ppl 207.23 | wps 38630.6 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.941 | loss_scale 8 | train_wall 48 | gb_free 14.5 | wall 690
2022-03-23 09:38:38 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:38:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:40 | INFO | train_inner | epoch 008:      5 / 157 loss=10.06, nll_loss=7.62, ppl=196.74, wps=29667.7, ups=1.19, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.939, loss_scale=8, train_wall=30, gb_free=13.8, wall=692
2022-03-23 09:39:11 | INFO | train_inner | epoch 008:    105 / 157 loss=9.942, nll_loss=7.402, ppl=169.11, wps=80498, ups=3.2, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.854, loss_scale=8, train_wall=31, gb_free=14.2, wall=723
2022-03-23 09:39:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the world.
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the most thing of the most most most of the most of the most of the most of the most of the most of the most of the
2022-03-23 09:39:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, it's a lot of life, and it's going to be a lot of life, and it's going to be in the brain, where you're going to be in the
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do that we're going to do, and we're not going to do that we're going to do it in the way.
2022-03-23 09:39:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:59 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the people in the people who are the people in the people in the people in the people in the people, and people who are the people in the most people in the people in the people in the people in the people in the people in the people
2022-03-23 09:39:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:05 | INFO | fairseq.tasks.translation | example hypothesis: some are some of some people, but they're not a lot, but they're not a lot, but they're not a lot of it, but they're not not a lot of it, but they're not a lot, but it, but they're not not not not a lot, but they're not not not the same, but they can
2022-03-23 09:40:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the world, and we can see that we can see that we can see the world, and we can see that we can see the world, and can see the brain, and we can see the brain, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the brain, and can see the world, and we can see
2022-03-23 09:40:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:19 | INFO | fairseq.tasks.translation | example hypothesis: so: one: "it's one of me," "" and it's a, "" "" "it's the first thing," "" and it's a question, "" "" "" "and it's the first thing," and it's the first thing, "" "" "it's a good," it's the first thing, "" "" "and it's a" "" "" "" "" "" "" "" "" "" "" and it's a question, "and it's a question," it's a "" "" "" "and it's a question," "" "" "" it's a question, "and it's a question," and it's a question, "it's a question," "" "" "" "" "" "" "
2022-03-23 09:40:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:21 | INFO | fairseq.tasks.translation | example hypothesis: and so, if we're going to be able to be a lot of the world, and we're going to be able to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we can be able to be able to be able to be able to be able to be able to be a lot of the world, which is that we can be able to be a lot of the world, and that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, which is that we can be able to be able to be able to be a lot of the world, which is that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 09:40:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:21 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.84 | nll_loss 6.99 | ppl 127.08 | bleu 2.44 | wps 3334.4 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 2.44
2022-03-23 09:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 09:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 2.44) (writing took 1.9196620340226218 seconds)
2022-03-23 09:40:23 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:40:23 | INFO | train | epoch 008 | loss 9.955 | nll_loss 7.425 | ppl 171.87 | wps 37596.8 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.84 | loss_scale 8 | train_wall 48 | gb_free 13.6 | wall 795
2022-03-23 09:40:23 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:39 | INFO | train_inner | epoch 009:     48 / 157 loss=9.897, nll_loss=7.318, ppl=159.59, wps=29347.6, ups=1.14, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.801, loss_scale=8, train_wall=31, gb_free=14.5, wall=811
2022-03-23 09:41:10 | INFO | train_inner | epoch 009:    148 / 157 loss=9.814, nll_loss=7.165, ppl=143.51, wps=79624.9, ups=3.21, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.726, loss_scale=8, train_wall=31, gb_free=13.8, wall=842
2022-03-23 09:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example hypothesis: we've got this on this.
2022-03-23 09:41:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most most of the most most of the most.
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new york are going to go on the new york.
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a example, and there's a lot of life.
2022-03-23 09:41:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just just just a few of what we're going to do.
2022-03-23 09:41:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:39 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people like people like people like the people, and people who have been been in the most people for the people for people for people, and the people for the people for the most people in the people, and the most people in the people who have been been a
2022-03-23 09:41:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of them are going to see, but if you're going to see, but if you're going to see, but it's a lot of course, but if you're going to see, but it's a lot of the same time, but it's going to see, but if you're going to see, it
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the world, we can see that we can see that we can see the world, and then we can see that we can see that we can see the world, and then we can see that we can see the one of the world, and then we can see that we can see that we can see that we can see that we can see that we can see the world, and see the world, and see that we can see
2022-03-23 09:41:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:58 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the one of the world, and it's going to say, and it's a lot of people, "and it's going to say," you know, "you know," and it's a lot of you know, "you know," and it's going to say, "and it's a lot of you know," and it's going to say, "you know," you know, and it's a lot of the time, "and it's a lot of you know," well, and it's a lot of you know, "you know," you know, "and it's going to say, and it's a lot of you know," you know, "you know," you know, and it's a lot of you know, "and it's going to say, and it's going to say, and it's
2022-03-23 09:41:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:01 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, it's still still still still still, and if we're going to be a lot of the world, and if we're going to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and then we're going to be able to be a lot of the world, and then we're going to be a lot of the world that we're going to be able to be able to be able to be able to be a lot of the world, and then we're going to be a lot of the world that we're going to be able to be able to be a lot of the world, and then we're going to be able to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be a lot of the
2022-03-23 09:42:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:01 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.642 | nll_loss 6.622 | ppl 98.47 | bleu 4.37 | wps 3737.8 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.37
2022-03-23 09:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 09:42:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.37) (writing took 1.7753291089902632 seconds)
2022-03-23 09:42:03 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:42:03 | INFO | train | epoch 009 | loss 9.803 | nll_loss 7.146 | ppl 141.66 | wps 39737.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.745 | loss_scale 8 | train_wall 48 | gb_free 14.7 | wall 894
2022-03-23 09:42:03 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:32 | INFO | train_inner | epoch 010:     91 / 157 loss=9.677, nll_loss=6.915, ppl=120.67, wps=30772.6, ups=1.22, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.761, loss_scale=8, train_wall=31, gb_free=14.5, wall=924
2022-03-23 09:42:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the way.
2022-03-23 09:42:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most, most of you know, most of you know, most of the most.
2022-03-23 09:43:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:04 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be going to be two two of the new york.
2022-03-23 09:43:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a sssan, where you're going to go and get.
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just a few days, and what's going on.
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people have people for the people for the people, and the people for the people, and this is a few years, and that's a lot of the people for the people for the people for the people for the people for the people for the people, and for the
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:24 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the water, but if you're going to see it, but if you don't have it, but if you can't have it, but if you can't get it, but if you can't have it, but if you have to get it.
2022-03-23 09:43:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can see this, we can see this, and we can see that, and we can take a lot of the light, and we can see that we can take a little bit of the brain, and we can be able, and we can see that we can see the one, and we can see that we can see the one of the one of the brain, and we can use of it, and we can take a
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:38 | INFO | fairseq.tasks.translation | example hypothesis: well, one of the other thing, and it's very interesting, and it's very interesting, "and it's going to be for me," and "and" and "and" "and" and "and" and "and" and "and" and "and" it's a very good for me, "" "" "and" and "and" "and" and "" and "and" and "and" and "and" and "and" and "and" "" "" "" and it's a very good for me, "it's about it's about it's really interesting," and it's about it's about it's a good for me, "it's a very good for me," and "and" and "and" and "and" and "" and "and" and "and" and "and" and "
2022-03-23 09:43:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and then, it's still still still still, and the mother, and the "and the most thing that we're going to have to be a lot of the world, and if we're going to be a new way that we've got to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and if we're going to be a lot of the world, and if we're going to be a little bit of the world, if we're going to be a new way, if we're going to be able to be a very much one of the world, and if we're going to be able to be a little bit that we're going to be able to be a little bit of the world, if we're going to be able to be a little bit of the world, if we're going to be able to be a very much of the most one, and if we're going to be able to be able to be a
2022-03-23 09:43:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.498 | nll_loss 6.294 | ppl 78.49 | bleu 5.18 | wps 3691.2 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 5.18
2022-03-23 09:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 5.18) (writing took 2.0100182610040065 seconds)
2022-03-23 09:43:42 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:43:42 | INFO | train | epoch 010 | loss 9.671 | nll_loss 6.9 | ppl 119.39 | wps 39271.8 | ups 1.56 | wpb 25127.3 | bsz 1014.9 | num_updates 1565 | lr 0.000195625 | gnorm 0.818 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 994
2022-03-23 09:43:43 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:54 | INFO | train_inner | epoch 011:     35 / 157 loss=9.661, nll_loss=6.877, ppl=117.55, wps=30240.8, ups=1.22, wpb=24781, bsz=994.3, num_updates=1600, lr=0.0002, gnorm=0.872, loss_scale=4, train_wall=31, gb_free=13.4, wall=1006
2022-03-23 09:44:25 | INFO | train_inner | epoch 011:    135 / 157 loss=9.485, nll_loss=6.563, ppl=94.52, wps=81175.3, ups=3.18, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.782, loss_scale=4, train_wall=31, gb_free=13.3, wall=1037
2022-03-23 09:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:36 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppppon the way.
2022-03-23 09:44:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:44:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the most thing that most of most of most of most most of the most most most here.
2022-03-23 09:44:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:44 | INFO | fairseq.tasks.translation | example hypothesis: they're going to get new new new new new new new new technologies that are going to be going to be able.
2022-03-23 09:44:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example where where where you're going to get with the pppppy, and it's going to be going to be a pppy.
2022-03-23 09:44:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:53 | INFO | fairseq.tasks.translation | example hypothesis: it's not just just a few years ago that we're not going to understand what's going to do.
2022-03-23 09:44:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamase of people like the number of the number, and the number of the number of the number of the number of the number of the number.
2022-03-23 09:44:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are some of the water, but if you don't have the energy, it's not the energy, and if you don't need your energy, you need to have the energy.
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this information, we can take a form of the information, and we can take a structure of the information, and that's all the information.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons that it's interesting, and it's interesting for me for me that we said, "you know," you know, "you know," you know, if you're going to say, "you're going to say," you know, "well," you know, "well," you know, "you know," you're going to talk about that it's a good for this is a good for me, "you're going to say," you know, "you know," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, you know, "you know," you know, "you know, you know," you know, "you know," you're going to say
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:11 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still still the mother, and the work of our work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a global global change the world.
2022-03-23 09:45:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:11 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.327 | nll_loss 6.008 | ppl 64.37 | bleu 8.92 | wps 4669.8 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.92
2022-03-23 09:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.92) (writing took 1.7565323740127496 seconds)
2022-03-23 09:45:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:45:13 | INFO | train | epoch 011 | loss 9.525 | nll_loss 6.636 | ppl 99.45 | wps 43532.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.782 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1085
2022-03-23 09:45:13 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:45:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:38 | INFO | train_inner | epoch 012:     78 / 157 loss=9.422, nll_loss=6.45, ppl=87.42, wps=34310.5, ups=1.37, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.736, loss_scale=4, train_wall=31, gb_free=14, wall=1110
2022-03-23 09:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:06 | INFO | fairseq.tasks.translation | example hypothesis: we did that in the middle of the center.
2022-03-23 09:46:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:10 | INFO | fairseq.tasks.translation | example hypothesis: and that's the car. most of most of most of most of most of most of the most.
2022-03-23 09:46:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:14 | INFO | fairseq.tasks.translation | example hypothesis: these are new york.
2022-03-23 09:46:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese, where they're going to get with, and they're going to be going on.
2022-03-23 09:46:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just going to understand a few years on his head, and what's going on on.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamaze people like this, for the number of animals, and that's a number of animals, and it's a few years ago.
2022-03-23 09:46:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:46:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are in the same way, but they don't need to go into the top, but if they don't need to use the energy, and if they need to use their energy, they need to use their energy, and they need the energy and they need the energy, and they need to use their energy.
2022-03-23 09:46:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, we can start from this structure, we can start with a structure, and we can start able to start with the structure of the structure, and all the structure of the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure, and all the structure of the structure of the structure of the information, and
2022-03-23 09:46:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons, and it's interesting to be interesting for me for me, "if we've got to say," well, "if we're going to say," if you're going to go to you're going to say, "and then you're going to say," you're going to say, "well," if you're going to say that you're going to say, "you're going to say," well, "well," you know, "you're going to say," you're going to say, "well," you've got to say, "you're going to say," you're going to say, "well," well, "well," well, "well," you're going to say that it's a good for you're going to go to say, "you're going to go to be a
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:44 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still the mother, and we've got a lot of work that we had to be able to see that if we had to use a huge system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to see that if we had to be able to be able to be able to see that we had to see that we had to see that we were able to use it, and use it, and use it, and we had to see that we had to use it, and use it in a little bit that we had to be a little bit of a little bit of a huge system, we had to see that we had to see that we had to be able to be able to be able to be able to be able to be able to see that
2022-03-23 09:46:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:44 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.166 | nll_loss 5.651 | ppl 50.24 | bleu 9.8 | wps 4327.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.8
2022-03-23 09:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.8) (writing took 1.7622219509794377 seconds)
2022-03-23 09:46:46 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:46:46 | INFO | train | epoch 012 | loss 9.349 | nll_loss 6.317 | ppl 79.74 | wps 42462.5 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.742 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1178
2022-03-23 09:46:46 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:53 | INFO | train_inner | epoch 013:     21 / 157 loss=9.28, nll_loss=6.191, ppl=73.04, wps=33456.5, ups=1.33, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.785, loss_scale=4, train_wall=31, gb_free=13.9, wall=1185
2022-03-23 09:47:25 | INFO | train_inner | epoch 013:    121 / 157 loss=9.219, nll_loss=6.076, ppl=67.48, wps=80083.2, ups=3.17, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.728, loss_scale=4, train_wall=31, gb_free=13.6, wall=1217
2022-03-23 09:47:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppin the clinic.
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the monha, most of most of most of most of the most.
2022-03-23 09:47:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be a new car that are going to be able to be able to be able.
2022-03-23 09:47:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, and they're going to get with ppppon.
2022-03-23 09:47:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few different camera on his head, and what's going on on.
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamaze people like the experience for the number of animals, and this is a number of animals.
2022-03-23 09:47:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are in the magic of neurons, but it doesn't need to be able to go to the energy, and if you need your energy and the energy.
2022-03-23 09:48:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this structure, we can start able to start with a big form of the structure, and the structure of the structure of the structure, and the structure of the structure.
2022-03-23 09:48:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting to be interesting for me to be here for women, "well, it's the best time to say," and then, "if we said," well, "it's a lot of women."
2022-03-23 09:48:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of mother, and a lot of work that we've had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that the entire entire entire entire entire entire entire entire entire entire entire system, or a machine.
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:13 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.04 | nll_loss 5.373 | ppl 41.44 | bleu 11.93 | wps 4942 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.93
2022-03-23 09:48:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:48:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:48:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 11.93) (writing took 1.795652961009182 seconds)
2022-03-23 09:48:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:48:14 | INFO | train | epoch 013 | loss 9.204 | nll_loss 6.05 | ppl 66.28 | wps 44746.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.739 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1266
2022-03-23 09:48:15 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:35 | INFO | train_inner | epoch 014:     64 / 157 loss=9.12, nll_loss=5.898, ppl=59.65, wps=35581.1, ups=1.43, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.704, loss_scale=4, train_wall=31, gb_free=14, wall=1287
2022-03-23 09:49:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:08 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppppin the clinic.
2022-03-23 09:49:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:12 | INFO | fairseq.tasks.translation | example hypothesis: so this is the car of the doha, the most most most of the most of the most.
2022-03-23 09:49:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be a new cameras that are going to create two new ways.
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese food, where they're going to go with and get it.
2022-03-23 09:49:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we don't just get a few different electrodes on his head on his head, and all of his mind.
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:49:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamaze people like the responsibility for people who came to the number of animals, the number of animals, and this has become become become a congress.
2022-03-23 09:49:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:49:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic of the lines in the lines, but it doesn't go into the alalalalalalalalalalable, if you need your energy and the energy.
2022-03-23 09:49:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can look at this structure, we can start able to start with a traditional structure of the structure, and the whole structure of the information.
2022-03-23 09:49:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me for me to be here for me, "oh, when we said," and then we're going to tell you that the truth is, "when we've been working with this issue."
2022-03-23 09:49:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still a need to the mother, and the invention of the design of the work that we had to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:42 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.899 | nll_loss 5.089 | ppl 34.04 | bleu 14.5 | wps 4807.1 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.5
2022-03-23 09:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:49:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.5) (writing took 1.7643944740120787 seconds)
2022-03-23 09:49:44 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:49:44 | INFO | train | epoch 014 | loss 9.035 | nll_loss 5.743 | ppl 53.56 | wps 44144.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.679 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1356
2022-03-23 09:49:44 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:49:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:47 | INFO | train_inner | epoch 015:      7 / 157 loss=8.971, nll_loss=5.627, ppl=49.42, wps=35583.4, ups=1.39, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.646, loss_scale=4, train_wall=31, gb_free=13.9, wall=1359
2022-03-23 09:50:18 | INFO | train_inner | epoch 015:    107 / 157 loss=8.898, nll_loss=5.493, ppl=45.02, wps=80239, ups=3.19, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.705, loss_scale=4, train_wall=31, gb_free=13.9, wall=1390
2022-03-23 09:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the new line of doha, most of the most knows here.
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:50:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new tracks.
2022-03-23 09:50:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:50:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where they're going to do with legs, and they're going to be degrace.
2022-03-23 09:50:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head and understand what all his mind are on the mind.
2022-03-23 09:50:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamaking of the people like the responsibility for the responsibility, the number of animals, and this is a number of animals.
2022-03-23 09:50:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic magic in the lines, but it doesn't be able to move when it doesn't like it, if you need your energy, it doesn't need your energy, and you need your energy.
2022-03-23 09:51:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional face that we can start able to start able to start able to start with the shape of the structure of the structure, and then the information, the information of the information.
2022-03-23 09:51:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to do with tedtedwomen -- that's the best thing that he said, "well, it's the best thing that we're working with the best revolution," and then, "when we're working with you're working with you're working with a long revolution," and then, "well," well, "well," well, "well," well, "well," if we've got a lot of you're working with you've got a lot of you're working with you're working with you're working with you're working with you're working with you know, "well," well, "well," well. "
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a big design that we're working on the airplane, is that we had to solve an airplane that we had to solve a unique system that we had to be able to do with a unique system, or to see that if we had to use it in the ground.
2022-03-23 09:51:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:14 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.718 | nll_loss 4.744 | ppl 26.79 | bleu 15.92 | wps 4488.3 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.92
2022-03-23 09:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.92) (writing took 1.8145182479929645 seconds)
2022-03-23 09:51:15 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:51:15 | INFO | train | epoch 015 | loss 8.906 | nll_loss 5.505 | ppl 45.4 | wps 43052.9 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.676 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1447
2022-03-23 09:51:16 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:32 | INFO | train_inner | epoch 016:     50 / 157 loss=8.892, nll_loss=5.475, ppl=44.48, wps=34351.7, ups=1.35, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.628, loss_scale=4, train_wall=31, gb_free=14.3, wall=1464
2022-03-23 09:52:03 | INFO | train_inner | epoch 016:    150 / 157 loss=8.724, nll_loss=5.172, ppl=36.06, wps=79709.7, ups=3.23, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.612, loss_scale=4, train_wall=31, gb_free=14.5, wall=1495
2022-03-23 09:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pace in the clinic.
2022-03-23 09:52:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha that most of the most know.
2022-03-23 09:52:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ances.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs will be and salt.
2022-03-23 09:52:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:52:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrode on his head and understand what all its thoughts are on.
2022-03-23 09:52:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility of responsibility, the number of animals, and that's a part of the animals.
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:52:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic lines in the field, but it doesn't be able to move if you need your energy, and you need your energy.
2022-03-23 09:52:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start with the real shape of the shape of the structure, and the whole structure of the structure.
2022-03-23 09:52:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here for tedwomen -- that's the best thing when we say, "well," the best thing we're going to support you. "
2022-03-23 09:52:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and one part of the work that we've been able to solve is that we had to solve a very unique result of the ground, so we had to be able to be able to be able to be able to be able to be able to be able to be able to see all of the ground.
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:39 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.646 | nll_loss 4.608 | ppl 24.39 | bleu 15.09 | wps 5373.9 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.92
2022-03-23 09:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 09:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 15.09) (writing took 0.7765157410176471 seconds)
2022-03-23 09:52:40 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:52:40 | INFO | train | epoch 016 | loss 8.76 | nll_loss 5.239 | ppl 37.76 | wps 46673.8 | ups 1.86 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.629 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1532
2022-03-23 09:52:40 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:10 | INFO | train_inner | epoch 017:     93 / 157 loss=8.655, nll_loss=5.048, ppl=33.08, wps=37770.2, ups=1.49, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.63, loss_scale=4, train_wall=31, gb_free=14.9, wall=1562
2022-03-23 09:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example hypothesis: and we made these ppace in the clinic clinic clinic.
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:53:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most of the most know here.
2022-03-23 09:53:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:53:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new lololocks that are going to create the two new locks.
2022-03-23 09:53:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs are and degrace.
2022-03-23 09:53:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all his thoughts are on the ground.
2022-03-23 09:53:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the life, the number of animals grew up, and this is a foundation for the world.
2022-03-23 09:53:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble of magnetic field, but it doesn't like the sulens, if you need your energy, and you don't need your energy energy, and you need a few bloop of the alarm.
2022-03-23 09:54:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial faces that are able to start able to start with a big form of the face of the structure, and the information that all the structure of the structure, and the structure of the structure, and the structure of the structure, and the structure of this structure is a structure, and the structure that all the structure of the structure of this structure of this structure
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, for me, for tedwomen, is that the best thing that we've been working on, when you've got to support the best thing, and then you know, you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you have a long time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you've got it's been working with this is, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 09:54:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be the mother of the invention, and a big part of the design that we've been able to solve is that we had to solve a unique result of these problems that we had to solve the ground in the ground, and if you've been able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the same with a specific with a specific with a particular, and see, and see that if we're able to be able to be able
2022-03-23 09:54:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:14 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.527 | nll_loss 4.408 | ppl 21.22 | bleu 16.44 | wps 4114.6 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.44
2022-03-23 09:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.44) (writing took 1.7629785400058609 seconds)
2022-03-23 09:54:15 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:54:15 | INFO | train | epoch 017 | loss 8.651 | nll_loss 5.038 | ppl 32.85 | wps 41407.7 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.635 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1627
2022-03-23 09:54:16 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:28 | INFO | train_inner | epoch 018:     36 / 157 loss=8.606, nll_loss=4.954, ppl=30.99, wps=32522.2, ups=1.29, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.618, loss_scale=4, train_wall=30, gb_free=14.3, wall=1639
2022-03-23 09:54:59 | INFO | train_inner | epoch 018:    136 / 157 loss=8.506, nll_loss=4.778, ppl=27.44, wps=79085.4, ups=3.19, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.557, loss_scale=4, train_wall=31, gb_free=14.1, wall=1671
2022-03-23 09:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:55:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 09:55:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are going to be degraded with sales and feeding.
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:55:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand exactly what all its thoughts are on the top.
2022-03-23 09:55:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammers like the responsibility for the wild, the number of animals, and this is a foundation of natural conservation.
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example hypothesis: first, there's some bloop of magnetic field, but the sucks of sucks, but it doesn't like the sucks, if you don't need your energy, you need your energy, you need your energy, you need the energy, and so you need the aluminum.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that can start with the big factors, and the real shape of the faces, and the structure of the structure, and the information, and the whole structure, which has a structure of the structure.
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it interesting, for me, for tedwomen, is that... yes, when it was the best thing that someone said, "and then," you know, you know, you know, you know, "and if you have a lot of the time, we've got a lot of you're working with the anxiety."
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of the design work on our plane, we're a result of it, a result that we had to solve the unique problems that were connected to the ground -- and it's all the way that we're going to see that if you're going to be able to be able to use the power of a constraigightforward, and that if you're going to be able to see that if you're going to be able to be able to see the power, it's a different, it's a certain way to be able to be able to use the power of a constraigightforward to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:44 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.369 | nll_loss 4.08 | ppl 16.91 | bleu 20.67 | wps 4688.1 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.67
2022-03-23 09:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:55:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:55:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:55:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.67) (writing took 1.7741623570036609 seconds)
2022-03-23 09:55:46 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:55:46 | INFO | train | epoch 018 | loss 8.508 | nll_loss 4.782 | ppl 27.5 | wps 43546.1 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.542 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1718
2022-03-23 09:55:47 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:55:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:12 | INFO | train_inner | epoch 019:     79 / 157 loss=8.441, nll_loss=4.66, ppl=25.28, wps=35208.4, ups=1.37, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.53, loss_scale=4, train_wall=31, gb_free=14, wall=1744
2022-03-23 09:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:40 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:56:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:56:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know here.
2022-03-23 09:56:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are going to be salt with salz and fat.
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all of his thoughts are on the top.
2022-03-23 09:56:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the wild, the number of the wild animals, and this is a foundation of natural conservation.
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic field, but the susuick doesn't move when they need energy and so forth.
2022-03-23 09:57:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face, and the real information that we use the whole structure of this structure, the whole structure of this reflection, the structure of this reflection, the structure of this reflection, and we can get a structure of the structure.
2022-03-23 09:57:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here at tedtedwomen, that... yeah, when someone said, "you know, when the men said," and then we were talking about the table of the table, and then we've been talking to you, "if we have love the truth for you.
2022-03-23 09:57:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a big part of the design work that we're in our plane is a result that we had to solve the problems on the ground -- all of us were connected to the ground -- that it allows us to see that the mother's going to be able to see that if we're using a transfer to be able to use the ground, or that if you can use the transfer the transfer the top of the top of the air, or that we're going to see the air.
2022-03-23 09:57:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:14 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.348 | nll_loss 4.01 | ppl 16.11 | bleu 21.09 | wps 4762.7 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.09
2022-03-23 09:57:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:57:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:57:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:57:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.09) (writing took 1.780191461002687 seconds)
2022-03-23 09:57:16 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:57:16 | INFO | train | epoch 019 | loss 8.398 | nll_loss 4.585 | ppl 24 | wps 44066.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.55 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1808
2022-03-23 09:57:16 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:57:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:23 | INFO | train_inner | epoch 020:     22 / 157 loss=8.349, nll_loss=4.498, ppl=22.59, wps=34651.8, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.536, loss_scale=4, train_wall=30, gb_free=14.7, wall=1815
2022-03-23 09:57:55 | INFO | train_inner | epoch 020:    122 / 157 loss=8.288, nll_loss=4.389, ppl=20.95, wps=81105.2, ups=3.14, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.468, loss_scale=4, train_wall=32, gb_free=13.6, wall=1847
2022-03-23 09:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:58:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-23 09:58:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are going to be served with salz and puppets.
2022-03-23 09:58:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly exactly what all its thoughts are on the way.
2022-03-23 09:58:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, as the people were responsibility for the wild, the number of animals grew back to the wild animals, and that's a foundation of natural conservation in namibia.
2022-03-23 09:58:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:58:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are magnetic field lines in the inside the inner, but the susulant may not be able to move when they need their energy, and the susuile disorders.
2022-03-23 09:58:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and rerepeat the basic shape of the information, and through the information, which is the whole structure of these reflection, and the whole structure of these reflection.
2022-03-23 09:58:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it interesting and measure it interesting, for me to be here at tedwomen, is that...... yes, when someone was the best, when someone said to you, "the men who say the men who are working on a table and measure it interesting and measure it interesting and measure it interesting and measure it interesting and measure it interesting," if they're going to be here at tedwomen who are going to be here at tedwomen in tedwomen who are going to be here at tedwomen, and measure it interesting to be here at tedwomen who are going to be here at tedwomen's in tedwomen's in tedwomen who are working on a long, and measure it interesting, and measure it interesting, and measure it interesting, and measure it interesting to be here at tedwomen who are going to be here at tedwomen who are going
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:46 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of the invention, and a big part of design work on the plane that we have to be a result of the aircraft, or a result of it is that we had to solve the unique problems that were connected to the ground -- all the way of the mother of the way, and a big part of the mother of the invention of the invention of the invention of the invention of the invention of the invention of the design work, and a big part of the design work, and a big part of the design work, and a big part of the design work that we have to see that we've got to make a big part of the design work that we had to see that we had to see that we had to a big part of the way that we had to see that we had to be able to see in our aircraft that we had to be able to make a lot of the way that we had to solve in the way that we had to solve in our airplane in the way that we had to make it is
2022-03-23 09:58:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.241 | nll_loss 3.886 | ppl 14.78 | bleu 23.21 | wps 4437.6 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.21
2022-03-23 09:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 09:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.21) (writing took 1.8119947380037047 seconds)
2022-03-23 09:58:48 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:58:48 | INFO | train | epoch 020 | loss 8.284 | nll_loss 4.381 | ppl 20.84 | wps 42746.8 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.501 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1900
2022-03-23 09:58:49 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:09 | INFO | train_inner | epoch 021:     65 / 157 loss=8.216, nll_loss=4.262, ppl=19.18, wps=33615.4, ups=1.35, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.531, loss_scale=4, train_wall=30, gb_free=13.9, wall=1921
2022-03-23 09:59:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:59:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably, most of you know.
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz.
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 09:59:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for the wild animals, and this is a foundation for the natural protection in namibia.
2022-03-23 10:00:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some bars of magnetic field in the inside of the inside, but the sulalan doesn't like, if you move your movements, and the suck of the superconductor.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face of the face of the face, and the basic shape of it, and by the top of the top of that information, which is the whole structure.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you're going to measure the men and say, "if we're talking about that."
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're going to see in our plane, was a result of that we had to solve the unique problems that were connected to the ground, or if you can see it in the same way that we're going to be able to be able to see the car.
2022-03-23 10:00:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:16 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.163 | nll_loss 3.774 | ppl 13.68 | bleu 22.61 | wps 4788.9 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.21
2022-03-23 10:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 10:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 22.61) (writing took 0.8433649099897593 seconds)
2022-03-23 10:00:17 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 10:00:17 | INFO | train | epoch 021 | loss 8.207 | nll_loss 4.245 | ppl 18.96 | wps 44628.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.5 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1989
2022-03-23 10:00:17 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 10:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:20 | INFO | train_inner | epoch 022:      8 / 157 loss=8.217, nll_loss=4.264, ppl=19.21, wps=35106.8, ups=1.42, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.506, loss_scale=4, train_wall=31, gb_free=13.9, wall=1992
2022-03-23 10:00:51 | INFO | train_inner | epoch 022:    108 / 157 loss=8.17, nll_loss=4.179, ppl=18.12, wps=79032.1, ups=3.21, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.522, loss_scale=4, train_wall=31, gb_free=13.8, wall=2023
2022-03-23 10:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:01:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know the most here.
2022-03-23 10:01:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:18 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 10:01:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salz.
2022-03-23 10:01:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 10:01:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people responsibility for the wild animals, the number of wild animals grew again. and this is a foundation for the natural protection in namibia.
2022-03-23 10:01:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:01:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnet lines in the inside, but the sulalegter doesn't like, if you need your energy, and so the sulouts need the suick disorder.
2022-03-23 10:01:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the basic constructions of the face and the basic shape of the shape of the information that's restored by the one of the one.
2022-03-23 10:01:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measure, for me here at tedwomen, is that... well, you know, you know, you know, when somebody said, "you know," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know. "
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're in our plane, or a result of that we had to solve the unique problems that we had to solve the unique problems that we had to be connected to the ground so that they had to be connected to the ground.
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:42 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.138 | nll_loss 3.682 | ppl 12.84 | bleu 23.48 | wps 5104.9 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.48
2022-03-23 10:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 10:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 23.48) (writing took 1.8091353540075943 seconds)
2022-03-23 10:01:44 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 10:01:44 | INFO | train | epoch 022 | loss 8.149 | nll_loss 4.142 | ppl 17.66 | wps 45221.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.499 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2076
2022-03-23 10:01:44 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 10:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:00 | INFO | train_inner | epoch 023:     51 / 157 loss=8.105, nll_loss=4.064, ppl=16.72, wps=36672.8, ups=1.44, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.417, loss_scale=4, train_wall=31, gb_free=13.8, wall=2092
2022-03-23 10:02:32 | INFO | train_inner | epoch 023:    151 / 157 loss=8.023, nll_loss=3.928, ppl=15.22, wps=81210.9, ups=3.2, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.451, loss_scale=4, train_wall=31, gb_free=13.8, wall=2124
2022-03-23 10:02:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheet in the clinic.
2022-03-23 10:02:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigments.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food where frog legs are served with salz and ppet.
2022-03-23 10:02:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the way.
2022-03-23 10:02:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, the number of wild animals grew up, and this is a foundation of conservation in namibia.
2022-03-23 10:02:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are starting in the inside, but the superconductor doesn't like when they move, because their movements are energy, and so the superconducting disorders.
2022-03-23 10:03:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial reflection, the big constraints of the face and the basic form of the face and the basic form of the real face and the basic form of information that all the ports of that all the ports and the porting structure and the structure of this structure that are going to fold the whole portion.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that -- well, in a long time, when someone said, "turn it together to the best thing that men and tell you about a table and say," if the revolution starts to be here at tedwomen. "
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of design work that we're going to use in our plane, which is a result that we had to solve the unique problems that were connected to surgical problems that were connected to the ground -- everything from a continues to a continuous continent -- everything from a continuous part of the design work, and a large part of the design work of the design work that we use to refrightening in our aircraft, to be able to refrightening, to refrightened to be able to be able to refrightened to be able to refrightened to refrightened to be able to refrightened to use in the refrightened to be able to use with a mechanism, that we have to be able to refrightened to be able to refrightened to be able to refrightened to be able to refrightened to use in the
2022-03-23 10:03:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:13 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.079 | nll_loss 3.568 | ppl 11.86 | bleu 25.48 | wps 4672.9 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.48
2022-03-23 10:03:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:03:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:03:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.48) (writing took 1.7957537370093632 seconds)
2022-03-23 10:03:14 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:03:14 | INFO | train | epoch 023 | loss 8.05 | nll_loss 3.972 | ppl 15.69 | wps 43661.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.431 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2166
2022-03-23 10:03:15 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:03:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:44 | INFO | train_inner | epoch 024:     94 / 157 loss=8.008, nll_loss=3.899, ppl=14.92, wps=34285.6, ups=1.38, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.439, loss_scale=4, train_wall=31, gb_free=13.8, wall=2196
2022-03-23 10:04:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:04:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:16 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 10:04:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pace.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back, and that's a foundation of conservation in namibia.
2022-03-23 10:04:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines in the inside, but the superconductors don't like it, if you move your movements, and so the superconducting disorders.
2022-03-23 10:04:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, the big contextures of the face and the basic form of information that makes the whole portion of the facial facial and restores.
2022-03-23 10:04:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... well, when someone said, "turn it up to the best than someone said," turn you on the men on a table and say, "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'"
2022-03-23 10:04:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continually variation and a system that we can use to be able to be able to see that if we're in our airplane.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:41 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.98 | nll_loss 3.407 | ppl 10.61 | bleu 27.08 | wps 4866.9 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.08
2022-03-23 10:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:04:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.08) (writing took 1.8450438829895575 seconds)
2022-03-23 10:04:43 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:04:43 | INFO | train | epoch 024 | loss 7.989 | nll_loss 3.866 | ppl 14.58 | wps 44451.7 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.418 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2255
2022-03-23 10:04:44 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:56 | INFO | train_inner | epoch 025:     37 / 157 loss=7.931, nll_loss=3.768, ppl=13.62, wps=35828.2, ups=1.41, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.389, loss_scale=4, train_wall=31, gb_free=14, wall=2267
2022-03-23 10:05:27 | INFO | train_inner | epoch 025:    137 / 157 loss=7.961, nll_loss=3.821, ppl=14.14, wps=79587.2, ups=3.18, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.437, loss_scale=4, train_wall=31, gb_free=13.9, wall=2299
2022-03-23 10:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:05:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:05:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:05:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to have two new pigs.
2022-03-23 10:05:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill.
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:05:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:05:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inside, but the superconductor doesn't like you move, because your movements are using energy, and so the superconducting disorders.
2022-03-23 10:06:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big contexture of the face and the basic form of information that draws the whole portion structure and fold it all a fold.
2022-03-23 10:06:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and then we support you here at tedwomen, is that, we've been supported for the future. "when someone said," turn you to your table and say, "if the revolution begins, then we'll support you."
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a great part of design work that we're on our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation variation variation and a system that allows us to refrightened with a continent variation and a system that allows us to use a fluid system to a fluid in the air, or if you can use it.
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:11 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.987 | nll_loss 3.433 | ppl 10.8 | bleu 26.38 | wps 4939.7 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.08
2022-03-23 10:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.38) (writing took 0.779372945020441 seconds)
2022-03-23 10:06:11 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:06:11 | INFO | train | epoch 025 | loss 7.938 | nll_loss 3.782 | ppl 13.76 | wps 44833.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.423 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2343
2022-03-23 10:06:12 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:37 | INFO | train_inner | epoch 026:     80 / 157 loss=7.887, nll_loss=3.692, ppl=12.92, wps=36282.6, ups=1.43, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.401, loss_scale=4, train_wall=31, gb_free=14, wall=2369
2022-03-23 10:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheets in the clinic.
2022-03-23 10:07:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:09 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here.
2022-03-23 10:07:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:07:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:07:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it, if you move, because your movements, and so the superconductor disorders.
2022-03-23 10:07:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constraints of the face and the basic form, and through the one of the one information that fits the whole portion structure and all the fits.
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured, for me here at tedwomen, is that... tyes, when someone said, "turn you to the men on your table and say," '"' if the revolution starts to support you in your desk," '"we're telling you that women are already supporting you," we've already been supporting you, "we've already been supported for a long time."
2022-03-23 10:07:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we are on our plane, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and a refrigeration system that allows us to refrightened us to be in the aircraft, or we're in a particular way that we're going to have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 10:07:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:40 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.884 | nll_loss 3.254 | ppl 9.54 | bleu 28.89 | wps 4654.4 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.89
2022-03-23 10:07:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:07:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:07:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.89) (writing took 1.7497881650051568 seconds)
2022-03-23 10:07:42 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:07:42 | INFO | train | epoch 026 | loss 7.884 | nll_loss 3.688 | ppl 12.89 | wps 43671.6 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.413 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2434
2022-03-23 10:07:42 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:50 | INFO | train_inner | epoch 027:     23 / 157 loss=7.852, nll_loss=3.635, ppl=12.42, wps=34173.5, ups=1.37, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.42, loss_scale=4, train_wall=31, gb_free=14.8, wall=2442
2022-03-23 10:08:21 | INFO | train_inner | epoch 027:    123 / 157 loss=7.843, nll_loss=3.619, ppl=12.28, wps=80103.4, ups=3.2, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.374, loss_scale=4, train_wall=31, gb_free=13.6, wall=2473
2022-03-23 10:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:08:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:08:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:08:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:08:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:08:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:08:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:08:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are captured inside, but the superconductor doesn't like it if they're moving, because their movements are using energy, and so the superconductor disorder.
2022-03-23 10:09:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big constraints of the face and the basic form, and through the one of those ports and all the fits.
2022-03-23 10:09:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to your men on your table and say," if the revolution starts to support you. "
2022-03-23 10:09:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on our plane are the ststest, was a result that we had to solve the unique problems that were connected to operational -- everything from a continuous variation and a refrigerator system that allows us to have a refrigerator, to be able to use a special transportation, or if you can see the refrigerator, or if you can see the most propelled, it is either to the propelled, you can see the propelled, you can see that it, you can see that it, or if you can see the car, you can use it, you can use it, you can see it, you can't see it, you can see it, you can see it, you can see it, you can see it's a specific, you can't see it, or if you can see the most expensive, you can use it, and you can see the car car car,
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:11 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.861 | nll_loss 3.2 | ppl 9.19 | bleu 29.09 | wps 4743.6 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.09
2022-03-23 10:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:09:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.09) (writing took 1.7404024110001046 seconds)
2022-03-23 10:09:12 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:09:12 | INFO | train | epoch 027 | loss 7.822 | nll_loss 3.583 | ppl 11.98 | wps 43658.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.37 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2524
2022-03-23 10:09:13 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:33 | INFO | train_inner | epoch 028:     66 / 157 loss=7.789, nll_loss=3.527, ppl=11.53, wps=34550.4, ups=1.39, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.368, loss_scale=4, train_wall=31, gb_free=14.7, wall=2545
2022-03-23 10:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep sheep in the clinic.
2022-03-23 10:10:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 10:10:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will write two new pigs.
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for the wildlife, the number of animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:10:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:10:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and through the one of the one of the things that contains the whole porting structure and all the fits.
2022-03-23 10:10:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me here at tedwomen, is that -- well, when dinner, it was best embedded when someone said, "turn to your men on your table and say," if the revolution begins, we support you. '"
2022-03-23 10:10:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the proud of the stack, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a refrigeration system that allows us to stop a refrigeration in the aircraft, or if you can't see the refrigeration, or even if you can use the refrightening, or if you're going to have to have to have to use the refrigeration, if you're going to use the only to stop, or if you're going to have to have to have to have to have to have to be a security, if you're going to have to have to have to be a specific traffic, if you're in the air, if you're in the same time you're in the same way that you're going to have to have to have to have to have to use the most specific, it,
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:40 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.824 | nll_loss 3.138 | ppl 8.8 | bleu 29.97 | wps 4743.2 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.97
2022-03-23 10:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.97) (writing took 1.9057128530112095 seconds)
2022-03-23 10:10:42 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:10:42 | INFO | train | epoch 028 | loss 7.787 | nll_loss 3.524 | ppl 11.5 | wps 43917.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.389 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2614
2022-03-23 10:10:43 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:45 | INFO | train_inner | epoch 029:      9 / 157 loss=7.802, nll_loss=3.55, ppl=11.71, wps=35037, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.409, loss_scale=4, train_wall=31, gb_free=13.6, wall=2617
2022-03-23 10:11:17 | INFO | train_inner | epoch 029:    109 / 157 loss=7.742, nll_loss=3.448, ppl=10.91, wps=79967.4, ups=3.18, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.359, loss_scale=4, train_wall=31, gb_free=13.6, wall=2649
2022-03-23 10:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:11:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:11:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most here.
2022-03-23 10:11:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:11:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:11:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:11:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pills.
2022-03-23 10:11:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:11:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:11:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:11:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a couple of magnetic fields are captured in the inside, but the superconductor doesn't like it if they use their movements, and so the superconductor disorder.
2022-03-23 10:11:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:03 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic form, and the information that refers the whole porter structure and all the folk.
2022-03-23 10:12:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high and interesting to me here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn to men on your table and say," if the revolution starts. "
2022-03-23 10:12:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are at our aircraft at the stumes, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft in the same way, or if you can see the promoting, or if you can see the mechanism, or if you can use a mechanism, or if you can use the promoting, or if you have to use the promoting, or if you can use the promoting, or if you can use the promoting, or if you can use the promoting, or if you can see the mechanism, or if you can use the promoting, the promoting, or if you can use the promoting, or if you can see the mechanism.
2022-03-23 10:12:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:10 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.797 | nll_loss 3.132 | ppl 8.76 | bleu 29.84 | wps 4805 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.97
2022-03-23 10:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.84) (writing took 0.7725477640051395 seconds)
2022-03-23 10:12:10 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:12:10 | INFO | train | epoch 029 | loss 7.749 | nll_loss 3.46 | ppl 11.01 | wps 44731.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.377 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2702
2022-03-23 10:12:11 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:12:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:28 | INFO | train_inner | epoch 030:     52 / 157 loss=7.745, nll_loss=3.453, ppl=10.95, wps=35346.6, ups=1.41, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.381, loss_scale=4, train_wall=31, gb_free=13.9, wall=2720
2022-03-23 10:12:59 | INFO | train_inner | epoch 030:    152 / 157 loss=7.679, nll_loss=3.343, ppl=10.15, wps=81037.4, ups=3.2, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.316, loss_scale=4, train_wall=31, gb_free=14.7, wall=2751
2022-03-23 10:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 10:13:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new vibrations.
2022-03-23 10:13:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pills.
2022-03-23 10:13:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:13:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:13:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it if they're moving, because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:13:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constraints of the face and the basic shape, and through the one of the information that refuses the whole portion structure and all the folds.
2022-03-23 10:13:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to your men on your table and tell you," if the revolution starts to help you. "
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on at our aircraft was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft until a special device, until you have to solve the most unique problems that we had to solve the unique problems that we had to do, or if you have to do, or if you have to do it's connected to do it, you have to use it is to do it, or if you can see it is to use it is to use it is to use it is to use it, or to use it's either to use it is to use it's either to use it, you can see it, you can see it, you can see it, or if you can see it's possible to use it's possible to use it's possible to use it, or if you can see it's
2022-03-23 10:13:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:39 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.763 | nll_loss 3.064 | ppl 8.36 | bleu 30.54 | wps 4734.3 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.54
2022-03-23 10:13:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:13:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:13:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.54) (writing took 1.713654997991398 seconds)
2022-03-23 10:13:41 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:13:41 | INFO | train | epoch 030 | loss 7.693 | nll_loss 3.365 | ppl 10.3 | wps 43765.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.334 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2793
2022-03-23 10:13:41 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:13:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:11 | INFO | train_inner | epoch 031:     95 / 157 loss=7.68, nll_loss=3.343, ppl=10.15, wps=35300.1, ups=1.38, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.366, loss_scale=4, train_wall=31, gb_free=13.6, wall=2823
2022-03-23 10:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:14:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:14:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:14:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilock dinners that are going to make two new pigs.
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:14:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:14:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:14:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:14:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:14:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the may like the people's responsibility for the wildlife, the number grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:14:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:14:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the baseline, and restores it through the one of the information that fits the whole porter structure and all the fits.
2022-03-23 10:15:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, in the striking dinner, it was the best summarized when someone said, "turn to men on your table and say," if the revolution begins, then we support you. "'"' the truth is that we've already been supporting you for a long time. "
2022-03-23 10:15:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on at our aircraft was a result that we had to solve the unique problems that were connected to the soil -- everything from a continuous variable operating and a refrigeration system that allows us to stop in the aircraft, until you can see the operations, or if you're in the air, or you're going to use it, or if you're going to use it, or if you're in the air, or if you're going to use it, or if you're going to use it, or you're going to use it, or if you're going to use it, or if you're going to use it, or if you're going to use it, or if you're going to use it, or if you're going to use it, or if you're going to use it, or you're going to use it, or if you're going to use it, or if you're going to see the
2022-03-23 10:15:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:09 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.731 | nll_loss 3.021 | ppl 8.12 | bleu 31.29 | wps 4708.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.29
2022-03-23 10:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:15:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:15:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.29) (writing took 1.7952723030175548 seconds)
2022-03-23 10:15:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:15:11 | INFO | train | epoch 031 | loss 7.676 | nll_loss 3.338 | ppl 10.11 | wps 43899.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.366 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2883
2022-03-23 10:15:11 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:23 | INFO | train_inner | epoch 032:     38 / 157 loss=7.639, nll_loss=3.274, ppl=9.67, wps=34615.6, ups=1.39, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.341, loss_scale=4, train_wall=30, gb_free=14.3, wall=2895
2022-03-23 10:15:55 | INFO | train_inner | epoch 032:    138 / 157 loss=7.64, nll_loss=3.278, ppl=9.7, wps=80149.1, ups=3.17, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.35, loss_scale=4, train_wall=31, gb_free=14.4, wall=2927
2022-03-23 10:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:16:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:16:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new vibrations.
2022-03-23 10:16:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pills.
2022-03-23 10:16:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:16:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people took responsibility for the wild, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:16:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:16:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that restores the big constraints of the face and the basic form, and through the one of the information that refers all the pores structure and all the fits.
2022-03-23 10:16:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen is that -- well, when congestion dinner, it's one of the reasons it's done best when someone said, "turn you to your table and say," 'if the revolution begins, we support you. "'" '"'" the truth is that we have been supporting you for this topic for a long time.
2022-03-23 10:16:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on at our plane is the result that we had to solve the unique problems that were linked to the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the air, to a very fluid traffic, to a specific basis, or a specialized, to a prosperous, to a specific basis, to the most propellism, or a specific promoting, to a specific, or a prosperity, to a promoting device that, which is either to the most propellyicide, to the most propellism, to a specific, or a particular promoting device that, which is either by the same as a promote-of-the-art, to the most propellism that if you see the same.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.721 | nll_loss 2.999 | ppl 7.99 | bleu 30.95 | wps 4781.7 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.29
2022-03-23 10:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:16:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:16:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 30.95) (writing took 0.8076897200080566 seconds)
2022-03-23 10:16:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:16:39 | INFO | train | epoch 032 | loss 7.632 | nll_loss 3.262 | ppl 9.59 | wps 44568.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.337 | loss_scale 4 | train_wall 49 | gb_free 14.5 | wall 2971
2022-03-23 10:16:40 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:16:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:05 | INFO | train_inner | epoch 033:     81 / 157 loss=7.577, nll_loss=3.171, ppl=9, wps=35546.7, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.325, loss_scale=4, train_wall=30, gb_free=14, wall=2997
2022-03-23 10:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic clinic.
2022-03-23 10:17:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:17:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:17:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:17:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that create two new pigs.
2022-03-23 10:17:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:17:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pfat suitcase.
2022-03-23 10:17:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:17:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:17:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:17:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wild animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 10:17:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:17:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:17:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constructures of the face and the basic shape, and then refuse it through the one of the one of the information that refers the whole porting structure and all the fits.
2022-03-23 10:18:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured to me here at tedwomen is that -- well, when congestion dinner, it was best summarized when someone said, "turn you to the men on your table and tell them, 'if the revolution begins, then we support you.' ''" the truth, women, we've already been supporting you about this topic for a long time. "
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on at our aircraft was a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to stop a machine in the go-bble, until you can use the aircraft, until you see the most unique problems that you're going to do, or if you're going to do it, or if you're going to do it, you're going to be connected to be able to be able to operate it.
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:08 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.681 | nll_loss 2.965 | ppl 7.81 | bleu 32.13 | wps 4642.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.13
2022-03-23 10:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:18:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.13) (writing took 2.3072032970085274 seconds)
2022-03-23 10:18:10 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:18:10 | INFO | train | epoch 033 | loss 7.607 | nll_loss 3.22 | ppl 9.32 | wps 43443.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.341 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3062
2022-03-23 10:18:10 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:19 | INFO | train_inner | epoch 034:     24 / 157 loss=7.631, nll_loss=3.26, ppl=9.58, wps=34186, ups=1.36, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.354, loss_scale=4, train_wall=30, gb_free=13.8, wall=3071
2022-03-23 10:18:50 | INFO | train_inner | epoch 034:    124 / 157 loss=7.565, nll_loss=3.15, ppl=8.88, wps=80042.7, ups=3.18, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.339, loss_scale=4, train_wall=31, gb_free=13.7, wall=3102
2022-03-23 10:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:19:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:19:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will generate two new pigs.
2022-03-23 10:19:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:19:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 10:19:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 10:19:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constraints of the face, and the basic form of the information that refers the whole portion structure and all the fits it through the one of the one that refits all the folding folds the folding structure and all the fits it.
2022-03-23 10:19:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:19:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn you to your table and tell you, 'if the revolution begins, then we support you, then we support you," the truth of the truth, we've already been supporting you for this topic for a long time, "and then we've done it," well, "well, you know, you know, you know, you've been the future spring and then you've been best summarized to downstream."
2022-03-23 10:19:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on at our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerating system that allows us to make a refrigerators to stop an aircraft in the aircraft, until you can see the most promoting, until you can see the most specific operations, until you can see the air, or if you can see the most reliable, or if you can see the air, you can see the most sophisticated, you can see the most sophisticated mechanism, you can see the air, until you can see the most sophisticated, you can actually see the air, you can see the most expensive, you can either see the most sophisticated, until you can see the most sophisticated, until you can see the most sophisticated, you can actually see the air, you can actually see the most expensive
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:41 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.707 | nll_loss 2.976 | ppl 7.87 | bleu 32.1 | wps 4508.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.13
2022-03-23 10:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:19:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:19:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:19:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.1) (writing took 1.3452463559806347 seconds)
2022-03-23 10:19:43 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:19:43 | INFO | train | epoch 034 | loss 7.577 | nll_loss 3.17 | ppl 9 | wps 42647.1 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.344 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3155
2022-03-23 10:19:43 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:04 | INFO | train_inner | epoch 035:     67 / 157 loss=7.585, nll_loss=3.183, ppl=9.08, wps=33988.3, ups=1.35, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.348, loss_scale=4, train_wall=30, gb_free=14.7, wall=3176
2022-03-23 10:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:20:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:20:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:20:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:20:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to translate two new pigs.
2022-03-23 10:20:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:20:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:20:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:20:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:20:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:20:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:20:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:21:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which gives the big constraints of the face and the basic form, and through the one of the information that refers the whole porch structure and all the fits folds.
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to your table and say," 'if the revolution begins, we support you. "the truth is that we've been supporting you for this long time for silver spring."
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft in a special way, until we're driving the aircraft in a special way, or if you're in the air, or if you're in the ground, you're in the air, you're going to run the air, you're going to run the air, or if you're going to run the air, you're going to a special way that you're going to the air, you're going to the air, until you're going to the air, you're going to the air, you're going to run the air, or if you're going to run the air that you're going to a special, or if you're going to be in the ground, you're going to be in a
2022-03-23 10:21:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:10 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.653 | nll_loss 2.932 | ppl 7.63 | bleu 32.05 | wps 4785 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.13
2022-03-23 10:21:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:21:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:21:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.05) (writing took 1.2140291710093152 seconds)
2022-03-23 10:21:12 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:21:12 | INFO | train | epoch 035 | loss 7.549 | nll_loss 3.123 | ppl 8.71 | wps 44475.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.321 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3243
2022-03-23 10:21:12 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:15 | INFO | train_inner | epoch 036:     10 / 157 loss=7.533, nll_loss=3.097, ppl=8.56, wps=35078.4, ups=1.41, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.306, loss_scale=4, train_wall=31, gb_free=14.7, wall=3247
2022-03-23 10:21:47 | INFO | train_inner | epoch 036:    110 / 157 loss=7.519, nll_loss=3.07, ppl=8.4, wps=79775.5, ups=3.15, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.32, loss_scale=4, train_wall=31, gb_free=14.7, wall=3279
2022-03-23 10:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:22:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most of you here.
2022-03-23 10:22:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to make two new pigs.
2022-03-23 10:22:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pills.
2022-03-23 10:22:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the math of how people took responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:22:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder disorder.
2022-03-23 10:22:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructures of the face, and the basic form of information that refers the entire porch structure and all the fone folds.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:22:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that -- well, in the congestion dinner, it's been the best summarized when someone said, "turn you to your table and say," 'if the revolution begins, we will support you.' '' "'the truth, we love it is that we've already been supporting you about this topic for a long time.
2022-03-23 10:22:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still a mother of invention, and it's a big part of the design work that we're working on in our airplane, and it's a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable operating, and a refrigerator system with fluid, that allows us to use it in the aircraft, or go-go-blowing, to use it to use it, until a specialize it, it, it, or a promotely, until the remotely, it, it allows us to use it, to make it, to make it, to use it, to make it, to make it, to make it, to use of the remove the burigitilaccomplish it, to make it, to make it, to run it, to make it, to run it, to run it, to run it, to make it happen, to run the refrigergerger
2022-03-23 10:22:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:22:41 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.663 | nll_loss 2.919 | ppl 7.56 | bleu 32.36 | wps 4609.1 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.36
2022-03-23 10:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.36) (writing took 1.859899739996763 seconds)
2022-03-23 10:22:43 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:22:43 | INFO | train | epoch 036 | loss 7.528 | nll_loss 3.086 | ppl 8.49 | wps 43348.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.331 | loss_scale 4 | train_wall 49 | gb_free 13.9 | wall 3335
2022-03-23 10:22:43 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:00 | INFO | train_inner | epoch 037:     53 / 157 loss=7.5, nll_loss=3.041, ppl=8.23, wps=35097.4, ups=1.38, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.34, loss_scale=4, train_wall=30, gb_free=14.7, wall=3352
2022-03-23 10:23:31 | INFO | train_inner | epoch 037:    153 / 157 loss=7.541, nll_loss=3.108, ppl=8.62, wps=79223.7, ups=3.19, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.323, loss_scale=4, train_wall=31, gb_free=13.5, wall=3383
2022-03-23 10:23:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:23:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:23:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:23:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:23:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to translate two new pigs.
2022-03-23 10:23:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:23:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:23:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:23:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:23:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:23:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:23:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:24:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic form, and then we recover it through the one of the one of the porting structure and all the fits.
2022-03-23 10:24:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate and appropriate to be here at tedwomen is that -- well, in congestion dinner, it was best summarized when someone said, "turn you to the men on your table and say to you," 'if the revolution begins, we support you.' "'the truth, women love, that we've already been supported to you at this topic for a long time.
2022-03-23 10:24:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system with fluid that allows us to use a machine on our aircraft on the stump of the guns of go-to-go-to-go-transportation to an aircraft, to a specific basis, to a particular basis, to a car car car car car car car car station, to the same.
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:11 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.641 | nll_loss 2.884 | ppl 7.38 | bleu 32.68 | wps 4688.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.68
2022-03-23 10:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.68) (writing took 1.8279538249771576 seconds)
2022-03-23 10:24:13 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:24:13 | INFO | train | epoch 037 | loss 7.508 | nll_loss 3.053 | ppl 8.3 | wps 43802.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.321 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3425
2022-03-23 10:24:13 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:43 | INFO | train_inner | epoch 038:     96 / 157 loss=7.508, nll_loss=3.054, ppl=8.31, wps=33992, ups=1.38, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.35, loss_scale=4, train_wall=31, gb_free=14.3, wall=3455
2022-03-23 10:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:25:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new goldilocks that will transcend two new pigs.
2022-03-23 10:25:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:25:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:25:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wild animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:25:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic form, and then then we recover it through the one of the information that includes the whole por-structure and all the fine folds.
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:25:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, in congestion dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. "the truth is that we've already been supporting you about this topic for a long time.
2022-03-23 10:25:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft on the go-traffic, to a particular drive to be the most propelled, to be the most propanized, to the ground if you look at a mechanism, or if you look at the same mechanism, which you can see the safety space of an aircraft that you see the earth, or if you're going to the same thing that you're going to see the air, it allows us to be the earth, or when you're going to be the air, it's going to be refrightened by a mechanism that you're going to be refrightened by a particular mechanism, or when you're going to be able to be able to see the
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:25:40 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.628 | nll_loss 2.873 | ppl 7.32 | bleu 32.46 | wps 4797.3 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.68
2022-03-23 10:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:25:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.46) (writing took 0.8961818570096511 seconds)
2022-03-23 10:25:41 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:25:41 | INFO | train | epoch 038 | loss 7.498 | nll_loss 3.036 | ppl 8.2 | wps 44708.4 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.338 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3513
2022-03-23 10:25:41 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:54 | INFO | train_inner | epoch 039:     39 / 157 loss=7.44, nll_loss=2.939, ppl=7.67, wps=36933, ups=1.42, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.295, loss_scale=4, train_wall=31, gb_free=13.6, wall=3526
2022-03-23 10:26:25 | INFO | train_inner | epoch 039:    139 / 157 loss=7.494, nll_loss=3.03, ppl=8.17, wps=79577.5, ups=3.2, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.346, loss_scale=4, train_wall=31, gb_free=14.7, wall=3557
2022-03-23 10:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:34 | INFO | fairseq.tasks.translation | example hypothesis: we put up these beep in the clinic.
2022-03-23 10:26:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:26:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:26:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:26:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will exclude two new pigs.
2022-03-23 10:26:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:26:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pill suitcase.
2022-03-23 10:26:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:26:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:26:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:26:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 10:26:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:26:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:26:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial session that gives the big constraints of the face and the basic form back through the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:27:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's been very interesting and appropriate to be here at tedwomen is that -- well, when dinner was best summarized, it's been said, "turn you to the men on your table and tell them," 'when the revolution begins, we support you. "' the truth, women love, we've already started to support you for a long time in silly spring, and then we've started to downstream with the future."
2022-03-23 10:27:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our aircraft are most stumbling, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variation and a refrigeration system of liquid that allows us to use an aircraft in the goand to a particular vehicle traffic, or when you're in the ground, or when you're in the air, or when you're going to go to be able to operate at the same time you're going to see that you're going to be able to be able to be able to be able to get rid of a mechanism, to be able to be able to be able to be able to be able to be able to be able to get rid of a more propelled in the aircraft, or to be able to be able to get rid of a steady when you're in the air, or to be able to be able to
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:10 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.617 | nll_loss 2.857 | ppl 7.24 | bleu 33.18 | wps 4602.1 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.18
2022-03-23 10:27:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:27:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:27:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:27:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.18) (writing took 1.89947696600575 seconds)
2022-03-23 10:27:12 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:27:12 | INFO | train | epoch 039 | loss 7.469 | nll_loss 2.987 | ppl 7.93 | wps 43503 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.321 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3604
2022-03-23 10:27:12 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:27:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:38 | INFO | train_inner | epoch 040:     82 / 157 loss=7.456, nll_loss=2.964, ppl=7.8, wps=34015.6, ups=1.37, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.301, loss_scale=4, train_wall=31, gb_free=14.1, wall=3630
2022-03-23 10:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:28:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:28:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will create two new pigs.
2022-03-23 10:28:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepsuitcase.
2022-03-23 10:28:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, the number of wildanimals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:28:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disturbs.
2022-03-23 10:28:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constraints of the face and restores the basic form, and then converts it through the one of the information that includes the whole porch structure and all the fine folds.
2022-03-23 10:28:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and appropriate to be here at tedwomen is that... well, in congestion dinner, it was the best summarized when someone said, "turn to the men on your table and say to them," if the revolution begins, we support you. "
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our aircraft on the stumble, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a refrigerated system with fluid that allows us to use an aircraft on the top of go-traffic, to a special drive that was connected to the ground, or if you see the aircraft that's on the ground, it's on the ground, it's on the ground, it's all the same time you see it's going to the same.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:28:40 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.62 | nll_loss 2.852 | ppl 7.22 | bleu 32.96 | wps 4748.6 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.18
2022-03-23 10:28:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:28:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:28:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 32.96) (writing took 0.8014979150029831 seconds)
2022-03-23 10:28:41 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:28:41 | INFO | train | epoch 040 | loss 7.448 | nll_loss 2.952 | ppl 7.74 | wps 44486.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.308 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3693
2022-03-23 10:28:41 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:28:49 | INFO | train_inner | epoch 041:     25 / 157 loss=7.458, nll_loss=2.97, ppl=7.83, wps=35995.3, ups=1.41, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.313, loss_scale=4, train_wall=31, gb_free=14.4, wall=3701
2022-03-23 10:29:20 | INFO | train_inner | epoch 041:    125 / 157 loss=7.429, nll_loss=2.92, ppl=7.57, wps=79254.1, ups=3.18, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.311, loss_scale=4, train_wall=31, gb_free=13.8, wall=3732
2022-03-23 10:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:34 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:29:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:29:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:29:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:29:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to cross two new pigs.
2022-03-23 10:29:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:29:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:29:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:29:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:29:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:29:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:29:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:29:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:29:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial session that gives the big contextures of the face and the basic form, and then we recover it through the one of the information that refers the whole porch structure and all the fine wrinkles.
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it's been best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution begins, we support you.'" 'the truth is that we've been supporting you for a long time with rachel spring, and then we started to downstream to the future of sand. "
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we were on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system that allows us to use an aircraft on the aircraft in a particular way, either to be propelled, or when you see the tragic facilities in the ground.
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:08 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.584 | nll_loss 2.824 | ppl 7.08 | bleu 33.21 | wps 4879.2 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.21
2022-03-23 10:30:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:30:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:30:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.21) (writing took 1.7994086160033476 seconds)
2022-03-23 10:30:10 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:30:10 | INFO | train | epoch 041 | loss 7.432 | nll_loss 2.926 | ppl 7.6 | wps 44465.1 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.305 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3781
2022-03-23 10:30:10 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:30:31 | INFO | train_inner | epoch 042:     68 / 157 loss=7.417, nll_loss=2.899, ppl=7.46, wps=35466.1, ups=1.41, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.31, loss_scale=4, train_wall=31, gb_free=22.4, wall=3803
2022-03-23 10:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:03 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:31:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:31:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:11 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will make two new pigs.
2022-03-23 10:31:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:31:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:31:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:31:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inside, but the superconductor doesn't like it when they move because their movements use energy, and so the superconductor disorder.
2022-03-23 10:31:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:31:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial session that gives the big constraints of the face and the basic again, and deploy it through the one of the information that refers the whole pores structure and all the fine wrinkles.
2022-03-23 10:31:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:31:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, in the strict dinner, it's been the best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" '"the truth, we love you is that we've already been supporting you about this topic for a long time. at rachel spring, and then we started to download the future."
2022-03-23 10:31:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a refrigerator system with fluid that allows us to use an aircraft in the stop traffic to a special drive, which is either when you see the aircraft in the ground, or when you fly a mechanism.
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:31:36 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.6 | nll_loss 2.838 | ppl 7.15 | bleu 33.27 | wps 4921 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.27
2022-03-23 10:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:31:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 42 @ 6589 updates, score 33.27) (writing took 1.8209454739990178 seconds)
2022-03-23 10:31:38 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:31:38 | INFO | train | epoch 042 | loss 7.414 | nll_loss 2.894 | ppl 7.44 | wps 44606.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.303 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3870
2022-03-23 10:31:38 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:42 | INFO | train_inner | epoch 043:     11 / 157 loss=7.397, nll_loss=2.867, ppl=7.3, wps=36045, ups=1.41, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.286, loss_scale=4, train_wall=31, gb_free=13.9, wall=3874
2022-03-23 10:32:13 | INFO | train_inner | epoch 043:    111 / 157 loss=7.428, nll_loss=2.917, ppl=7.55, wps=79598.7, ups=3.2, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.323, loss_scale=4, train_wall=31, gb_free=13.8, wall=3905
2022-03-23 10:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:32:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:32:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:32:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most people probably know here.
2022-03-23 10:32:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:32:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will make two new pigs.
2022-03-23 10:32:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:32:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:32:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:32:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:32:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:32:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:32:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:32:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:32:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial bar that gives the big constructures of the face and the basic form of the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:33:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in the strict dinner, it's been the best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" '"' the truth, we've already been supporting you about this topic for a long time.
2022-03-23 10:33:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variables and a refrigerator system that allows us to use an aircraft on the top of the aircraft on the guns of the go-traffic to a special drive, or if you see the soil, or the folding mechanism, all the same way away from a continuously variables.
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:06 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.585 | nll_loss 2.808 | ppl 7 | bleu 33.4 | wps 4729.8 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.4
2022-03-23 10:33:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:33:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:33:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:33:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.4) (writing took 1.8496323099825531 seconds)
2022-03-23 10:33:08 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:33:08 | INFO | train | epoch 043 | loss 7.403 | nll_loss 2.876 | ppl 7.34 | wps 43912.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.316 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3960
2022-03-23 10:33:08 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:33:25 | INFO | train_inner | epoch 044:     54 / 157 loss=7.383, nll_loss=2.842, ppl=7.17, wps=34510.4, ups=1.39, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.331, loss_scale=4, train_wall=31, gb_free=14.2, wall=3977
2022-03-23 10:33:57 | INFO | train_inner | epoch 044:    154 / 157 loss=7.382, nll_loss=2.842, ppl=7.17, wps=81764.8, ups=3.2, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.285, loss_scale=4, train_wall=31, gb_free=13.8, wall=4009
2022-03-23 10:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:01 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:34:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:34:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:34:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 10:34:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:34:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:34:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:34:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:34:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:34:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:34:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductions are disturbing disorder.
2022-03-23 10:34:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:34:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that gives the big constructions of the face and restores the basic form, and then through the one of the information that pulls the whole porch structure and all the fine wrinkles.
2022-03-23 10:34:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:34:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, at the controversial dinner, we started with rato's "turn to the men on your table and say to them," 'when the revolution begins, we support you. "'" '"' the truth, women have already been supporting you about this for a long time."
2022-03-23 10:34:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:34:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we were on our airplane the proud of our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigerator system that allows us to use an aircraft in the stop and go-traffic to a special drive, or if you're on the ground, or if you're on the ground, you're on the ground, all the way up to the security facility, all the security facilities.
2022-03-23 10:34:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:34:36 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.583 | nll_loss 2.824 | ppl 7.08 | bleu 33.5 | wps 4803.2 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.5
2022-03-23 10:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 44 @ 6903 updates, score 33.5) (writing took 1.812964123004349 seconds)
2022-03-23 10:34:37 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:34:37 | INFO | train | epoch 044 | loss 7.387 | nll_loss 2.849 | ppl 7.2 | wps 44139.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.31 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4049
2022-03-23 10:34:38 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:09 | INFO | train_inner | epoch 045:     97 / 157 loss=7.371, nll_loss=2.822, ppl=7.07, wps=35641.4, ups=1.39, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.327, loss_scale=4, train_wall=31, gb_free=14.6, wall=4080
2022-03-23 10:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:35:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:35:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:35:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think is most of the people here.
2022-03-23 10:35:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:35:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 10:35:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:35:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepsuitcase.
2022-03-23 10:35:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:35:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:35:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:35:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife animals grew up again, and it's become a basis for conservation in namibia.
2022-03-23 10:35:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:35:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a couple of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder disorder.
2022-03-23 10:35:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:35:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial bar that gives the big constraints of the face and restores it through the one of the information that refers all the pores structure and all the folds.
2022-03-23 10:35:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, when constricted dinner, it was the best summarized when someone said, "turn to the men to your table and tell them," when the revolution begins, we'll support you, "the truth, women have already supported you about this for a long time."
2022-03-23 10:36:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a great part of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- all from a continuous variation and a refrigeration system that allows us to use an aircraft on the ground, or if you're going to be drifted, or if you're going to run the tragic, or if you're going to see the tragic, you're going to run the soil, you're going to be able to get rid of one of one of the same thing that's going to the same thing that's going to the same as a mechanism that's going to the air, it's going to go down to the air, to the air, to the ground, to the ground, to the same thing that we're going to the air, to the air, to the same thing that we're going to be able to be able to be able to be
2022-03-23 10:36:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:05 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.572 | nll_loss 2.806 | ppl 6.99 | bleu 33.47 | wps 4835 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.5
2022-03-23 10:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.47) (writing took 0.8874444200191647 seconds)
2022-03-23 10:36:06 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:36:06 | INFO | train | epoch 045 | loss 7.381 | nll_loss 2.84 | ppl 7.16 | wps 44800.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.328 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4137
2022-03-23 10:36:06 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:36:19 | INFO | train_inner | epoch 046:     40 / 157 loss=7.389, nll_loss=2.852, ppl=7.22, wps=34574.3, ups=1.42, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.323, loss_scale=4, train_wall=30, gb_free=14.3, wall=4151
2022-03-23 10:36:51 | INFO | train_inner | epoch 046:    140 / 157 loss=7.355, nll_loss=2.796, ppl=6.94, wps=80461.8, ups=3.16, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.291, loss_scale=4, train_wall=31, gb_free=13.6, wall=4182
2022-03-23 10:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:00 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:37:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know about this.
2022-03-23 10:37:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:37:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:37:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:37:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:37:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:37:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:37:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:37:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:37:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements consume energy, and so the superconductions are disturbing.
2022-03-23 10:37:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:37:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial session that gives the big constructions of the face and restores the basic form of information that refers the whole pores structure and all the fine folds.
2022-03-23 10:37:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:37:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that -- well, at the strict dinner, it was the best summarized when someone said, "turn to the men on your table and say to them," when the revolution begins, we support you. '"the truth, women have already been supported for a long time."
2022-03-23 10:37:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system with fluid that allows us to use an aircraft machine at the same time, or when you're driving the tragic to the ground, or when you're driving the security facilities.
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:37:33 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.585 | nll_loss 2.786 | ppl 6.9 | bleu 33.38 | wps 5041.4 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.5
2022-03-23 10:37:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:37:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:37:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.38) (writing took 0.9231550959812012 seconds)
2022-03-23 10:37:34 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:37:34 | INFO | train | epoch 046 | loss 7.359 | nll_loss 2.802 | ppl 6.97 | wps 44908.5 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.303 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4225
2022-03-23 10:37:34 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:37:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:00 | INFO | train_inner | epoch 047:     83 / 157 loss=7.34, nll_loss=2.768, ppl=6.81, wps=35996.1, ups=1.43, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.307, loss_scale=4, train_wall=31, gb_free=13.8, wall=4252
2022-03-23 10:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:38:28 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:38:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:38:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, i think most of you know about here.
2022-03-23 10:38:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:38:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:38:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:38:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:38:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:38:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:38:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:38:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:38:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:38:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:38:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:38:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and restores it through the information that refers the whole pores structure and all the fine wrinkles.
2022-03-23 10:38:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, at the strict dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" 'the truth, women, love, is that we've already been supporting you for a long time.
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we were most proud of on our plane was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything from a continuous variation and a cooling system with fluid that allows us to use an aircraft machine in the ga-go-traffic, until one particular vehicle, or if you see the tragic, or if you're flying.
2022-03-23 10:39:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:01 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.557 | nll_loss 2.801 | ppl 6.97 | bleu 33.89 | wps 4970.2 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.89
2022-03-23 10:39:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 10:39:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:39:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 47 @ 7374 updates, score 33.89) (writing took 1.983993478002958 seconds)
2022-03-23 10:39:03 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:39:03 | INFO | train | epoch 047 | loss 7.345 | nll_loss 2.777 | ppl 6.85 | wps 44210.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.299 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4315
2022-03-23 10:39:03 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 10:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:39:11 | INFO | train_inner | epoch 048:     26 / 157 loss=7.34, nll_loss=2.771, ppl=6.83, wps=35320.3, ups=1.41, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.312, loss_scale=4, train_wall=30, gb_free=13.6, wall=4323
2022-03-23 10:39:43 | INFO | train_inner | epoch 048:    126 / 157 loss=7.344, nll_loss=2.776, ppl=6.85, wps=80408.8, ups=3.13, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.28, loss_scale=4, train_wall=31, gb_free=14, wall=4355
2022-03-23 10:39:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:39:56 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:39:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which most of you probably know about here.
2022-03-23 10:40:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:40:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:40:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:40:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:40:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:40:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back up again, and that has become a basis for conservation in namibia.
2022-03-23 10:40:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:40:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:40:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:40:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face and restores the basic shape, and add it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:40:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:40:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that -- well, at the controversial dinner, it was the best summarized when someone said, "turn you to your table and tell you, 'when the revolution begins, we support you.'" the truth, women are already supporting you about this topic for a long time. at rachel's "
2022-03-23 10:40:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:40:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we were on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a cooling system of liquid, that it allows us to use an aircraft machine on the stop go-traffic, to a special drive, either when you run the prophecy, or when you fly the propanized, or when you fly on the ground, or when you see the promote a prophecy that you see it's going to run it's going to be on the air to be on the ground, or if you're going to run it's going to run it's going to run it at the air, you're going to run it's going to run it at the ground, or if you're going to run it's a particular, you're going to be able to run it, you're going to be able to run
2022-03-23 10:40:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:40:32 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.554 | nll_loss 2.804 | ppl 6.98 | bleu 34.07 | wps 4624.8 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 34.07
2022-03-23 10:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 10:40:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:40:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:40:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 34.07) (writing took 2.0316024599887896 seconds)
2022-03-23 10:40:34 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 10:40:34 | INFO | train | epoch 048 | loss 7.333 | nll_loss 2.757 | ppl 6.76 | wps 43410.9 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.303 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4406
2022-03-23 10:40:34 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 10:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:40:56 | INFO | train_inner | epoch 049:     69 / 157 loss=7.325, nll_loss=2.743, ppl=6.7, wps=33575.9, ups=1.38, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.314, loss_scale=4, train_wall=30, gb_free=14.1, wall=4428
2022-03-23 10:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:41:27 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:41:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:41:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 10:41:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:41:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will cross two new pigs.
2022-03-23 10:41:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:41:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:41:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:41:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:41:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:41:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:41:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:41:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move, because their movements consume energy, so the superconductor disorder.
2022-03-23 10:41:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:41:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can that restores the big constructions of the face and the basic form of information that includes the whole pores structure and all the fine folds.
2022-03-23 10:41:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:41:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, at the strict dinner, it was the best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.' the truth, women love you about this long time."
2022-03-23 10:41:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:42:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our aircraft is a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable drive and a refrigerator system that allows us to use an aircraft on the gavage of go-traffic to a particular drive, or when you're driving the ground, or if you're going to see the security institutions that are on the ground, we're going to see the raced, to see the races of an aircraft until the races.
2022-03-23 10:42:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:42:00 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.557 | nll_loss 2.81 | ppl 7.01 | bleu 33.51 | wps 4898.7 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 34.07
2022-03-23 10:42:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 10:42:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:42:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.51) (writing took 0.9279558769776486 seconds)
2022-03-23 10:42:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 10:42:01 | INFO | train | epoch 049 | loss 7.322 | nll_loss 2.74 | ppl 6.68 | wps 45082.8 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.302 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4493
2022-03-23 10:42:02 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 10:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:42:06 | INFO | train_inner | epoch 050:     12 / 157 loss=7.319, nll_loss=2.735, ppl=6.66, wps=36668.5, ups=1.43, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.306, loss_scale=4, train_wall=31, gb_free=14.7, wall=4498
2022-03-23 10:42:37 | INFO | train_inner | epoch 050:    112 / 157 loss=7.304, nll_loss=2.709, ppl=6.54, wps=81085.5, ups=3.19, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.299, loss_scale=4, train_wall=31, gb_free=13.7, wall=4529
2022-03-23 10:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:42:55 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:42:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:42:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:42:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:43:02 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:43:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:43:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:43:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:43:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of their thoughts are on the track.
2022-03-23 10:43:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:43:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like people's responsibility for wildlife, the number of wild animals grew back up again, and this has become a basis for conservation in namibia.
2022-03-23 10:43:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:43:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor may not like it when they move, because their movements use energy, and so the superconductor is disturbing.
2022-03-23 10:43:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:43:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constructures of the face and the basic form of information that restores the whole pores structure and all the fine wrinkles.
2022-03-23 10:43:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:43:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, at the congestion dinner, it was the best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" the truth, women are already supporting you with this topic for a long time.
2022-03-23 10:43:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still, and a big part of the design work that we stumbled on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable gears and a refrigerator system that allows us to use a ga-go-traffic aircraft machine to fit a particular vehicle, either to run the propellant, or if you're flying the ground, or if you're going to be on the aircraft the ground, you're going to see the airplanes.
2022-03-23 10:43:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:43:29 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.548 | nll_loss 2.781 | ppl 6.88 | bleu 34.07 | wps 4792.7 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.07
2022-03-23 10:43:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 10:43:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt
2022-03-23 10:43:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 34.07) (writing took 2.0126375959953293 seconds)
2022-03-23 10:43:31 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 10:43:31 | INFO | train | epoch 050 | loss 7.31 | nll_loss 2.718 | ppl 6.58 | wps 44156.7 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.301 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 4583
2022-03-23 10:43:31 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 10:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:43:49 | INFO | train_inner | epoch 051:     55 / 157 loss=7.304, nll_loss=2.707, ppl=6.53, wps=34848.5, ups=1.4, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.293, loss_scale=4, train_wall=30, gb_free=14.8, wall=4601
2022-03-23 10:44:20 | INFO | train_inner | epoch 051:    155 / 157 loss=7.301, nll_loss=2.705, ppl=6.52, wps=81293.3, ups=3.23, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.304, loss_scale=4, train_wall=31, gb_free=13.5, wall=4631
2022-03-23 10:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:44:24 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:44:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:44:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know here.
2022-03-23 10:44:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:44:32 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:44:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:44:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:44:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:44:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:44:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:44:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people's responsibility for the wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:44:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:44:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move, because their movements are consuming energy, and so the superconductor is disturbing.
2022-03-23 10:44:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:44:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial session that gives the big configurations of the face and restores the basic shape, and enables it through the one that refers the whole pores structure and all the fine folds.
2022-03-23 10:44:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:44:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, at the strict dinner, it was the best summarized when someone said, "turn you to the men on your table and tell them, 'when the revolution begins, we support you.'" the truth, women is that we've already been supporting you about this topic for a long time. at rael spring, we started with the future, stumbled our stone rows. "
2022-03-23 10:44:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:44:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable drive and a cooling system with fluid that allows us to use a stop machine in a particular passenger traffic, to either drive a propeller, or if you fly the ground, or if you see the false mechanism, the security institutions that are going to the same.
2022-03-23 10:44:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:44:57 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.554 | nll_loss 2.755 | ppl 6.75 | bleu 33.91 | wps 4948.5 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.07
2022-03-23 10:44:57 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 10:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt
2022-03-23 10:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.4_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 33.91) (writing took 0.925774809991708 seconds)
2022-03-23 10:44:58 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 10:44:58 | INFO | train | epoch 051 | loss 7.296 | nll_loss 2.695 | ppl 6.48 | wps 45257.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.299 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4670
2022-03-23 10:44:58 | INFO | fairseq_cli.train | done training in 4669.5 seconds
