Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 207263904: <w103_size_0.03125_fp16_label_smoothing_0.02_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.02_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:18:04 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:15 2022
Terminated at Sat Mar  5 14:18:55 2022
Results reported at Sat Mar  5 14:18:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.02 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   28.90 sec.
    Max Memory :                                 3085 MB
    Average Memory :                             1057.75 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16915.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   40 sec.
    Turnaround time :                            51 sec.

The output (if any) follows:

2022-03-05 14:18:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.02, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:18:25 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-05 14:18:27 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-05 14:18:27 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:18:27 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:18:27 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:18:27 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-05 14:18:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:18:27 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-05 14:18:33 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:18:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:18:33 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-05 14:18:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:18:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:18:33 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:18:33 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 14:18:33 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 14:18:33 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:18:33 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-05 14:18:33 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:18:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:18:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:18:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 771, in train_step
    torch.cuda.empty_cache()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/cuda/memory.py", line 87, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 207264048: <w103_size_0.03125_fp16_label_smoothing_0.02_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.02_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:28 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:21:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:21:45 2022
Terminated at Sun Mar  6 08:56:02 2022
Results reported at Sun Mar  6 08:56:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.02 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66812.26 sec.
    Max Memory :                                 6707 MB
    Average Memory :                             3685.68 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13293.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   66857 sec.
    Turnaround time :                            66874 sec.

The output (if any) follows:

2022-03-05 14:21:52 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.02, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:21:52 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:21:53 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:21:53 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:21:53 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:21:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:21:53 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:21:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:21:53 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:21:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:21:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-05 14:21:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:21:56 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:21:56 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 14:21:56 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 14:21:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:21:56 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:21:56 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:22:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.432 | nll_loss 15.393 | ppl 43023.9 | wps 48067.9 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:24:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:24:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.432) (writing took 4.220686472021043 seconds)
2022-03-05 14:24:12 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:12 | INFO | train | epoch 001 | loss 16.541 | nll_loss 16.525 | ppl 94297.8 | wps 26914 | ups 0.42 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.985 | loss_scale 4 | train_wall 116 | gb_free 21.6 | wall 136
2022-03-05 14:24:12 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.948 | nll_loss 13.878 | ppl 15060.5 | wps 48115.5 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.948
2022-03-05 14:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.948) (writing took 4.314246136927977 seconds)
2022-03-05 14:26:09 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:09 | INFO | train | epoch 002 | loss 14.64 | nll_loss 14.585 | ppl 24572.7 | wps 27216 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.262 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 253
2022-03-05 14:26:09 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:25 | INFO | train_inner | epoch 003:      7 / 49 loss=15.429, nll_loss=15.39, ppl=42939.1, wps=27218.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.412, loss_scale=4, train_wall=227, gb_free=21.6, wall=269
2022-03-05 14:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.269 | nll_loss 13.186 | ppl 9319.27 | wps 47829.7 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.269
2022-03-05 14:28:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:28:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.269) (writing took 4.270942978095263 seconds)
2022-03-05 14:28:06 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:06 | INFO | train | epoch 003 | loss 13.685 | nll_loss 13.611 | ppl 12511.6 | wps 27185.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.502 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 370
2022-03-05 14:28:06 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:29:58 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.412 | nll_loss 12.31 | ppl 5076.49 | wps 47800.7 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.412
2022-03-05 14:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:30:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.412) (writing took 4.204130962025374 seconds)
2022-03-05 14:30:03 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:03 | INFO | train | epoch 004 | loss 12.909 | nll_loss 12.819 | ppl 7226.97 | wps 27205.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.291 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 487
2022-03-05 14:30:03 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:23 | INFO | train_inner | epoch 005:      9 / 49 loss=13.165, nll_loss=13.08, ppl=8658.63, wps=27240.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.356, loss_scale=8, train_wall=198, gb_free=21.6, wall=507
2022-03-05 14:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:31:55 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.629 | nll_loss 11.506 | ppl 2908.88 | wps 47822.9 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.629
2022-03-05 14:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:31:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.629) (writing took 4.091400523902848 seconds)
2022-03-05 14:31:59 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:31:59 | INFO | train | epoch 005 | loss 12.04 | nll_loss 11.929 | ppl 3899.67 | wps 27231.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.983 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 603
2022-03-05 14:31:59 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:31:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:33:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:33:52 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.001 | nll_loss 10.858 | ppl 1855.94 | wps 47731.3 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.001
2022-03-05 14:33:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:33:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:33:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.001) (writing took 4.243176180869341 seconds)
2022-03-05 14:33:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:33:56 | INFO | train | epoch 006 | loss 11.302 | nll_loss 11.171 | ppl 2305.31 | wps 27215.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.764 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 720
2022-03-05 14:33:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:21 | INFO | train_inner | epoch 007:     11 / 49 loss=11.522, nll_loss=11.397, ppl=2695.93, wps=27263, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.831, loss_scale=16, train_wall=198, gb_free=21.6, wall=745
2022-03-05 14:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:35:49 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.596 | nll_loss 10.436 | ppl 1385.33 | wps 47770 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.596
2022-03-05 14:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:35:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.596) (writing took 4.1357597899623215 seconds)
2022-03-05 14:35:53 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:35:53 | INFO | train | epoch 007 | loss 10.752 | nll_loss 10.602 | ppl 1554.3 | wps 27218.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.625 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 837
2022-03-05 14:35:53 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:37:45 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.349 | nll_loss 10.176 | ppl 1156.55 | wps 47632.9 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.349
2022-03-05 14:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:37:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.349) (writing took 4.070494134910405 seconds)
2022-03-05 14:37:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:37:49 | INFO | train | epoch 008 | loss 10.412 | nll_loss 10.245 | ppl 1213.62 | wps 27259.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.475 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 953
2022-03-05 14:37:49 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:37:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:18 | INFO | train_inner | epoch 009:     13 / 49 loss=10.502, nll_loss=10.339, ppl=1295.57, wps=27289.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.523, loss_scale=32, train_wall=198, gb_free=21.6, wall=982
2022-03-05 14:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:39:42 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.17 | nll_loss 9.986 | ppl 1014.28 | wps 47828.6 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.17
2022-03-05 14:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.17) (writing took 4.109049876919016 seconds)
2022-03-05 14:39:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:39:46 | INFO | train | epoch 009 | loss 10.188 | nll_loss 10.009 | ppl 1030.37 | wps 27233.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1070
2022-03-05 14:39:46 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:39:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:41:39 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.006 | nll_loss 9.815 | ppl 900.77 | wps 47802.8 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.006
2022-03-05 14:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:41:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.006) (writing took 4.3418268989771605 seconds)
2022-03-05 14:41:43 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:41:43 | INFO | train | epoch 010 | loss 10.003 | nll_loss 9.815 | ppl 900.84 | wps 27145.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1187
2022-03-05 14:41:43 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:17 | INFO | train_inner | epoch 011:     15 / 49 loss=10.044, nll_loss=9.859, ppl=928.39, wps=27223.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.537, loss_scale=32, train_wall=198, gb_free=21.6, wall=1221
2022-03-05 14:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:43:36 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.866 | nll_loss 9.669 | ppl 814.06 | wps 47780.5 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 9.866
2022-03-05 14:43:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:43:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:43:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 9.866) (writing took 4.055924997199327 seconds)
2022-03-05 14:43:40 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:43:40 | INFO | train | epoch 011 | loss 9.833 | nll_loss 9.639 | ppl 797.12 | wps 26677.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.562 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1304
2022-03-05 14:43:40 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:45:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:45:33 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.724 | nll_loss 9.521 | ppl 734.84 | wps 47860.6 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.724
2022-03-05 14:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:45:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.724) (writing took 4.040957116987556 seconds)
2022-03-05 14:45:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:45:37 | INFO | train | epoch 012 | loss 9.673 | nll_loss 9.473 | ppl 710.46 | wps 27228.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.639 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1421
2022-03-05 14:45:37 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:17 | INFO | train_inner | epoch 013:     18 / 49 loss=9.696, nll_loss=9.497, ppl=722.37, wps=27026.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.614, loss_scale=32, train_wall=200, gb_free=21.6, wall=1461
2022-03-05 14:47:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:47:29 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.61 | nll_loss 9.404 | ppl 677.62 | wps 48474.5 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.61
2022-03-05 14:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.61) (writing took 4.0882100421004 seconds)
2022-03-05 14:47:33 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:47:33 | INFO | train | epoch 013 | loss 9.522 | nll_loss 9.316 | ppl 637.49 | wps 27211.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.708 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1537
2022-03-05 14:47:33 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:47:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:49:26 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.485 | nll_loss 9.273 | ppl 618.66 | wps 47889.4 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.485
2022-03-05 14:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:49:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.485) (writing took 4.047331850975752 seconds)
2022-03-05 14:49:30 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:49:30 | INFO | train | epoch 014 | loss 9.38 | nll_loss 9.169 | ppl 575.78 | wps 26714 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.721 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1654
2022-03-05 14:49:30 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:50:17 | INFO | train_inner | epoch 015:     21 / 49 loss=9.394, nll_loss=9.184, ppl=581.47, wps=27037.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.726, loss_scale=16, train_wall=200, gb_free=21.6, wall=1701
2022-03-05 14:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:51:23 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.387 | nll_loss 9.172 | ppl 576.65 | wps 47966 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.387
2022-03-05 14:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:51:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.387) (writing took 4.089282051892951 seconds)
2022-03-05 14:51:27 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:51:27 | INFO | train | epoch 015 | loss 9.243 | nll_loss 9.027 | ppl 521.7 | wps 27227.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.757 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1771
2022-03-05 14:51:27 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:53:19 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.298 | nll_loss 9.079 | ppl 540.64 | wps 47925.7 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.298
2022-03-05 14:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 14:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.298) (writing took 4.08729583886452 seconds)
2022-03-05 14:53:23 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:53:23 | INFO | train | epoch 016 | loss 9.108 | nll_loss 8.888 | ppl 473.67 | wps 27242.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.85 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1887
2022-03-05 14:53:23 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:15 | INFO | train_inner | epoch 017:     23 / 49 loss=9.116, nll_loss=8.896, ppl=476.26, wps=27262.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.828, loss_scale=32, train_wall=198, gb_free=21.6, wall=1939
2022-03-05 14:55:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:55:16 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.188 | nll_loss 8.963 | ppl 499.1 | wps 48064.9 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.188
2022-03-05 14:55:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-05 14:55:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:55:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.188) (writing took 4.15724832797423 seconds)
2022-03-05 14:55:20 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:55:20 | INFO | train | epoch 017 | loss 8.975 | nll_loss 8.749 | ppl 430.36 | wps 27189.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.832 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2004
2022-03-05 14:55:20 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:57:13 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.098 | nll_loss 8.873 | ppl 469 | wps 47977.4 | wpb 510.9 | bsz 1 | num_updates 875 | best_loss 9.098
2022-03-05 14:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 875 updates
2022-03-05 14:57:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:57:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:57:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 18 @ 875 updates, score 9.098) (writing took 4.081529004033655 seconds)
2022-03-05 14:57:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:57:17 | INFO | train | epoch 018 | loss 8.848 | nll_loss 8.618 | ppl 392.79 | wps 27224.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 875 | lr 0.000109453 | gnorm 0.911 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2121
2022-03-05 14:57:17 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:57:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:58:15 | INFO | train_inner | epoch 019:     26 / 49 loss=8.847, nll_loss=8.617, ppl=392.65, wps=27008.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.905, loss_scale=32, train_wall=200, gb_free=21.6, wall=2179
2022-03-05 14:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:59:10 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.009 | nll_loss 8.775 | ppl 438.02 | wps 47709 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.009
2022-03-05 14:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:59:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:59:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 14:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.009) (writing took 4.077848101966083 seconds)
2022-03-05 14:59:14 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 14:59:14 | INFO | train | epoch 019 | loss 8.725 | nll_loss 8.491 | ppl 359.77 | wps 26662.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.963 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2238
2022-03-05 14:59:14 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 14:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:00:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:01:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:06 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.943 | nll_loss 8.706 | ppl 417.59 | wps 47927 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 8.943
2022-03-05 15:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-05 15:01:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:01:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 20 @ 971 updates, score 8.943) (writing took 4.1266425780486315 seconds)
2022-03-05 15:01:11 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:01:11 | INFO | train | epoch 020 | loss 8.607 | nll_loss 8.369 | ppl 330.56 | wps 26618.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.924 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2355
2022-03-05 15:01:11 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:02:15 | INFO | train_inner | epoch 021:     29 / 49 loss=8.601, nll_loss=8.362, ppl=328.96, wps=26993.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.936, loss_scale=16, train_wall=200, gb_free=21.6, wall=2419
2022-03-05 15:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:03 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.863 | nll_loss 8.624 | ppl 394.4 | wps 47827.2 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.863
2022-03-05 15:03:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:03:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.863) (writing took 4.281380485976115 seconds)
2022-03-05 15:03:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:03:07 | INFO | train | epoch 021 | loss 8.494 | nll_loss 8.251 | ppl 304.61 | wps 27179.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.935 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2472
2022-03-05 15:03:07 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:00 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.804 | nll_loss 8.562 | ppl 377.85 | wps 47815.1 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.804
2022-03-05 15:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.804) (writing took 4.1365095630753785 seconds)
2022-03-05 15:05:04 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:04 | INFO | train | epoch 022 | loss 8.381 | nll_loss 8.134 | ppl 280.9 | wps 27215.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.897 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 2588
2022-03-05 15:05:04 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:06:13 | INFO | train_inner | epoch 023:     31 / 49 loss=8.371, nll_loss=8.123, ppl=278.87, wps=27230.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.952, loss_scale=32, train_wall=198, gb_free=21.6, wall=2657
2022-03-05 15:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:06:57 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.745 | nll_loss 8.504 | ppl 363.01 | wps 47794.9 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 8.745
2022-03-05 15:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 8.745) (writing took 4.196923414012417 seconds)
2022-03-05 15:07:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:01 | INFO | train | epoch 023 | loss 8.279 | nll_loss 8.028 | ppl 261.1 | wps 27191 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 1.062 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2705
2022-03-05 15:07:01 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:08:54 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.704 | nll_loss 8.455 | ppl 351.03 | wps 47481.6 | wpb 510.9 | bsz 1 | num_updates 1167 | best_loss 8.704
2022-03-05 15:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1167 updates
2022-03-05 15:08:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 24 @ 1167 updates, score 8.704) (writing took 4.139964980073273 seconds)
2022-03-05 15:08:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:08:58 | INFO | train | epoch 024 | loss 8.171 | nll_loss 7.917 | ppl 241.7 | wps 27183.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1167 | lr 0.000145946 | gnorm 0.947 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2822
2022-03-05 15:08:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:08:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:10:12 | INFO | train_inner | epoch 025:     33 / 49 loss=8.154, nll_loss=7.899, ppl=238.72, wps=27230.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.975, loss_scale=32, train_wall=198, gb_free=21.6, wall=2896
2022-03-05 15:10:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:10:51 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.638 | nll_loss 8.389 | ppl 335.15 | wps 47885.7 | wpb 510.9 | bsz 1 | num_updates 1216 | best_loss 8.638
2022-03-05 15:10:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1216 updates
2022-03-05 15:10:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 25 @ 1216 updates, score 8.638) (writing took 4.106591121992096 seconds)
2022-03-05 15:10:55 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:10:55 | INFO | train | epoch 025 | loss 8.067 | nll_loss 7.809 | ppl 224.31 | wps 27203.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1216 | lr 0.00015207 | gnorm 0.929 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2939
2022-03-05 15:10:55 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:11:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:12:48 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.591 | nll_loss 8.34 | ppl 323.95 | wps 47991.3 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 8.591
2022-03-05 15:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 8.591) (writing took 4.046418881975114 seconds)
2022-03-05 15:12:52 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:12:52 | INFO | train | epoch 026 | loss 7.971 | nll_loss 7.709 | ppl 209.25 | wps 26645 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 1.032 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3056
2022-03-05 15:12:52 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:14:12 | INFO | train_inner | epoch 027:     36 / 49 loss=7.95, nll_loss=7.688, ppl=206.17, wps=27005.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.984, loss_scale=32, train_wall=200, gb_free=21.6, wall=3136
2022-03-05 15:14:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:14:44 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.549 | nll_loss 8.292 | ppl 313.48 | wps 47734.2 | wpb 510.9 | bsz 1 | num_updates 1313 | best_loss 8.549
2022-03-05 15:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1313 updates
2022-03-05 15:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 27 @ 1313 updates, score 8.549) (writing took 4.096108902012929 seconds)
2022-03-05 15:14:48 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:14:48 | INFO | train | epoch 027 | loss 7.869 | nll_loss 7.603 | ppl 194.47 | wps 27238.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1313 | lr 0.000164192 | gnorm 0.982 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3172
2022-03-05 15:14:48 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:16:41 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.521 | nll_loss 8.264 | ppl 307.45 | wps 47915 | wpb 510.9 | bsz 1 | num_updates 1362 | best_loss 8.521
2022-03-05 15:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1362 updates
2022-03-05 15:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:16:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 28 @ 1362 updates, score 8.521) (writing took 4.165521734859794 seconds)
2022-03-05 15:16:45 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:16:45 | INFO | train | epoch 028 | loss 7.769 | nll_loss 7.5 | ppl 181.08 | wps 27191.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1362 | lr 0.000170316 | gnorm 1.011 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 3289
2022-03-05 15:16:45 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:16:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:18:12 | INFO | train_inner | epoch 029:     39 / 49 loss=7.741, nll_loss=7.471, ppl=177.48, wps=26988.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1.026, loss_scale=32, train_wall=200, gb_free=21.6, wall=3376
2022-03-05 15:18:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:18:38 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.47 | nll_loss 8.207 | ppl 295.48 | wps 47969.8 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 8.47
2022-03-05 15:18:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:18:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:18:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 8.47) (writing took 4.084744510939345 seconds)
2022-03-05 15:18:42 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:18:42 | INFO | train | epoch 029 | loss 7.67 | nll_loss 7.397 | ppl 168.59 | wps 26651.5 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 1.02 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3406
2022-03-05 15:18:42 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:20:35 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.463 | nll_loss 8.203 | ppl 294.65 | wps 47874.5 | wpb 510.9 | bsz 1 | num_updates 1459 | best_loss 8.463
2022-03-05 15:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1459 updates
2022-03-05 15:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:20:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 30 @ 1459 updates, score 8.463) (writing took 4.055109039880335 seconds)
2022-03-05 15:20:39 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:20:39 | INFO | train | epoch 030 | loss 7.569 | nll_loss 7.293 | ppl 156.88 | wps 27222.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1459 | lr 0.000182439 | gnorm 1.043 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3523
2022-03-05 15:20:39 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:22:10 | INFO | train_inner | epoch 031:     41 / 49 loss=7.536, nll_loss=7.259, ppl=153.19, wps=27261.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.005, loss_scale=64, train_wall=198, gb_free=21.6, wall=3614
2022-03-05 15:22:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:22:31 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.4 | nll_loss 8.131 | ppl 280.37 | wps 47876.2 | wpb 510.9 | bsz 1 | num_updates 1508 | best_loss 8.4
2022-03-05 15:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1508 updates
2022-03-05 15:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:22:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 31 @ 1508 updates, score 8.4) (writing took 4.12616996280849 seconds)
2022-03-05 15:22:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:22:36 | INFO | train | epoch 031 | loss 7.467 | nll_loss 7.188 | ppl 145.79 | wps 27200.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1508 | lr 0.000188562 | gnorm 0.997 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 3640
2022-03-05 15:22:36 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:22:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:22:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:24:28 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.389 | nll_loss 8.123 | ppl 278.86 | wps 47924.7 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 8.389
2022-03-05 15:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:24:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 8.389) (writing took 4.149475092999637 seconds)
2022-03-05 15:24:32 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:24:32 | INFO | train | epoch 032 | loss 7.365 | nll_loss 7.082 | ppl 135.47 | wps 26638.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 1.019 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3757
2022-03-05 15:24:32 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:26:10 | INFO | train_inner | epoch 033:     44 / 49 loss=7.329, nll_loss=7.045, ppl=132.03, wps=26998.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.04, loss_scale=32, train_wall=200, gb_free=21.6, wall=3854
2022-03-05 15:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:26:25 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.361 | nll_loss 8.09 | ppl 272.47 | wps 47905.2 | wpb 510.9 | bsz 1 | num_updates 1605 | best_loss 8.361
2022-03-05 15:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1605 updates
2022-03-05 15:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 33 @ 1605 updates, score 8.361) (writing took 4.068224563030526 seconds)
2022-03-05 15:26:29 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:26:29 | INFO | train | epoch 033 | loss 7.269 | nll_loss 6.982 | ppl 126.45 | wps 27239 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1605 | lr 0.000200685 | gnorm 1.056 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3873
2022-03-05 15:26:29 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:27:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:28:22 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.345 | nll_loss 8.074 | ppl 269.5 | wps 48142.3 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.345
2022-03-05 15:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.345) (writing took 4.079367301892489 seconds)
2022-03-05 15:28:26 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:28:26 | INFO | train | epoch 034 | loss 7.17 | nll_loss 6.879 | ppl 117.74 | wps 26664.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 1.048 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3990
2022-03-05 15:28:26 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:30:11 | INFO | train_inner | epoch 035:     47 / 49 loss=7.129, nll_loss=6.837, ppl=114.34, wps=27007.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.06, loss_scale=32, train_wall=200, gb_free=21.6, wall=4095
2022-03-05 15:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:30:19 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.336 | nll_loss 8.066 | ppl 267.92 | wps 47818.9 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 8.336
2022-03-05 15:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:30:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 35 @ 1702 updates, score 8.336) (writing took 4.045506939059123 seconds)
2022-03-05 15:30:23 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:30:23 | INFO | train | epoch 035 | loss 7.073 | nll_loss 6.78 | ppl 109.89 | wps 27212.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 1.08 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4107
2022-03-05 15:30:23 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:30:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:32:15 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.315 | nll_loss 8.04 | ppl 263.18 | wps 47947.3 | wpb 510.9 | bsz 1 | num_updates 1751 | best_loss 8.315
2022-03-05 15:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1751 updates
2022-03-05 15:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 36 @ 1751 updates, score 8.315) (writing took 4.064375598914921 seconds)
2022-03-05 15:32:19 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:32:19 | INFO | train | epoch 036 | loss 6.975 | nll_loss 6.678 | ppl 102.38 | wps 27207.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1751 | lr 0.000218931 | gnorm 1.063 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4224
2022-03-05 15:32:19 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:33:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:34:12 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.291 | nll_loss 8.016 | ppl 258.89 | wps 47805.9 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 8.291
2022-03-05 15:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 37 @ 1799 updates, score 8.291) (writing took 4.023914839141071 seconds)
2022-03-05 15:34:16 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:34:16 | INFO | train | epoch 037 | loss 6.878 | nll_loss 6.578 | ppl 95.51 | wps 26662.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 1.11 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4340
2022-03-05 15:34:16 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:19 | INFO | train_inner | epoch 038:      1 / 49 loss=6.927, nll_loss=6.628, ppl=98.88, wps=26032.7, ups=0.4, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.086, loss_scale=32, train_wall=200, gb_free=21.6, wall=4343
2022-03-05 15:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:36:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.288 | nll_loss 8.01 | ppl 257.8 | wps 47749.4 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 8.288
2022-03-05 15:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-05 15:36:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:36:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt
2022-03-05 15:36:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_best.pt (epoch 38 @ 1848 updates, score 8.288) (writing took 4.093818192137405 seconds)
2022-03-05 15:36:13 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:36:13 | INFO | train | epoch 038 | loss 6.784 | nll_loss 6.48 | ppl 89.27 | wps 27187.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 1.114 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4457
2022-03-05 15:36:13 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:38:06 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.308 | nll_loss 8.027 | ppl 260.76 | wps 47813.7 | wpb 510.9 | bsz 1 | num_updates 1897 | best_loss 8.288
2022-03-05 15:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1897 updates
2022-03-05 15:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 39 @ 1897 updates, score 8.308) (writing took 1.9198245680890977 seconds)
2022-03-05 15:38:08 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:38:08 | INFO | train | epoch 039 | loss 6.686 | nll_loss 6.378 | ppl 83.15 | wps 27735.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1897 | lr 0.000237178 | gnorm 1.071 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4572
2022-03-05 15:38:08 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:14 | INFO | train_inner | epoch 040:      3 / 49 loss=6.731, nll_loss=6.425, ppl=85.9, wps=27496.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.1, loss_scale=32, train_wall=198, gb_free=21.6, wall=4579
2022-03-05 15:39:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:40:00 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.34 | nll_loss 8.056 | ppl 266.21 | wps 47904.3 | wpb 510.9 | bsz 1 | num_updates 1945 | best_loss 8.288
2022-03-05 15:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1945 updates
2022-03-05 15:40:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:40:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:40:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 40 @ 1945 updates, score 8.34) (writing took 1.8640410921070725 seconds)
2022-03-05 15:40:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:40:02 | INFO | train | epoch 040 | loss 6.592 | nll_loss 6.28 | ppl 77.72 | wps 27166 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1945 | lr 0.000243176 | gnorm 1.123 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4686
2022-03-05 15:40:02 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:40:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:41:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:41:55 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.325 | nll_loss 8.044 | ppl 263.87 | wps 47833.2 | wpb 510.9 | bsz 1 | num_updates 1994 | best_loss 8.288
2022-03-05 15:41:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1994 updates
2022-03-05 15:41:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 41 @ 1994 updates, score 8.325) (writing took 1.9746502079069614 seconds)
2022-03-05 15:41:57 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:41:57 | INFO | train | epoch 041 | loss 6.499 | nll_loss 6.184 | ppl 72.72 | wps 27697.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1994 | lr 0.0002493 | gnorm 1.113 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4801
2022-03-05 15:41:57 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:10 | INFO | train_inner | epoch 042:      6 / 49 loss=6.534, nll_loss=6.22, ppl=74.54, wps=27489.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.109, loss_scale=32, train_wall=200, gb_free=21.6, wall=4814
2022-03-05 15:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:43:50 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.338 | nll_loss 8.056 | ppl 266.07 | wps 47832.8 | wpb 510.9 | bsz 1 | num_updates 2043 | best_loss 8.288
2022-03-05 15:43:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2043 updates
2022-03-05 15:43:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 42 @ 2043 updates, score 8.338) (writing took 1.9550387300550938 seconds)
2022-03-05 15:43:52 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:43:52 | INFO | train | epoch 042 | loss 6.405 | nll_loss 6.086 | ppl 67.94 | wps 27717.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2043 | lr 0.000255424 | gnorm 1.143 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4916
2022-03-05 15:43:52 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:44:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:45:44 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.378 | nll_loss 8.091 | ppl 272.73 | wps 47887.2 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 8.288
2022-03-05 15:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 8.378) (writing took 1.9055337051395327 seconds)
2022-03-05 15:45:46 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:45:46 | INFO | train | epoch 043 | loss 6.315 | nll_loss 5.993 | ppl 63.67 | wps 27162.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.151 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5030
2022-03-05 15:45:46 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:06 | INFO | train_inner | epoch 044:      9 / 49 loss=6.344, nll_loss=6.023, ppl=65.03, wps=27498.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.162, loss_scale=32, train_wall=200, gb_free=21.6, wall=5050
2022-03-05 15:47:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:47:39 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.393 | nll_loss 8.106 | ppl 275.54 | wps 48079.6 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 8.288
2022-03-05 15:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:47:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:47:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 8.393) (writing took 1.937868116889149 seconds)
2022-03-05 15:47:41 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:47:41 | INFO | train | epoch 044 | loss 6.223 | nll_loss 5.898 | ppl 59.61 | wps 27717 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.192 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5145
2022-03-05 15:47:41 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:47:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:49:34 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.429 | nll_loss 8.143 | ppl 282.71 | wps 47777.6 | wpb 510.9 | bsz 1 | num_updates 2189 | best_loss 8.288
2022-03-05 15:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2189 updates
2022-03-05 15:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:49:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:49:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 45 @ 2189 updates, score 8.429) (writing took 1.900764310033992 seconds)
2022-03-05 15:49:36 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:49:36 | INFO | train | epoch 045 | loss 6.131 | nll_loss 5.802 | ppl 55.77 | wps 27724.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2189 | lr 0.00027367 | gnorm 1.194 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 5260
2022-03-05 15:49:36 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:49:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:49:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:50:02 | INFO | train_inner | epoch 046:     12 / 49 loss=6.158, nll_loss=5.83, ppl=56.87, wps=27492.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.177, loss_scale=32, train_wall=200, gb_free=21.6, wall=5286
2022-03-05 15:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:51:28 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.466 | nll_loss 8.18 | ppl 289.94 | wps 47824.4 | wpb 510.9 | bsz 1 | num_updates 2237 | best_loss 8.288
2022-03-05 15:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2237 updates
2022-03-05 15:51:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:51:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:51:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 46 @ 2237 updates, score 8.466) (writing took 1.8385329968295991 seconds)
2022-03-05 15:51:30 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:51:30 | INFO | train | epoch 046 | loss 6.037 | nll_loss 5.705 | ppl 52.15 | wps 27171.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2237 | lr 0.000279669 | gnorm 1.214 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5374
2022-03-05 15:51:30 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:53:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:53:23 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.495 | nll_loss 8.211 | ppl 296.32 | wps 47867.1 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.288
2022-03-05 15:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-05 15:53:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.495) (writing took 1.9330620621331036 seconds)
2022-03-05 15:53:25 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:53:25 | INFO | train | epoch 047 | loss 5.947 | nll_loss 5.61 | ppl 48.85 | wps 27155.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.207 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5489
2022-03-05 15:53:25 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:53:58 | INFO | train_inner | epoch 048:     15 / 49 loss=5.967, nll_loss=5.631, ppl=49.55, wps=27507.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.21, loss_scale=16, train_wall=200, gb_free=21.6, wall=5522
2022-03-05 15:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:55:17 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.542 | nll_loss 8.255 | ppl 305.41 | wps 47905.9 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.288
2022-03-05 15:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-05 15:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 48 @ 2334 updates, score 8.542) (writing took 1.865516982972622 seconds)
2022-03-05 15:55:19 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:55:19 | INFO | train | epoch 048 | loss 5.862 | nll_loss 5.522 | ppl 45.96 | wps 27730.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.202 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5603
2022-03-05 15:55:19 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:57:12 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.569 | nll_loss 8.281 | ppl 311.07 | wps 48075.2 | wpb 510.9 | bsz 1 | num_updates 2383 | best_loss 8.288
2022-03-05 15:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2383 updates
2022-03-05 15:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 49 @ 2383 updates, score 8.569) (writing took 1.7974326668772846 seconds)
2022-03-05 15:57:14 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:57:14 | INFO | train | epoch 049 | loss 5.768 | nll_loss 5.425 | ppl 42.95 | wps 27780.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2383 | lr 0.000297915 | gnorm 1.268 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5718
2022-03-05 15:57:14 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:57:52 | INFO | train_inner | epoch 050:     17 / 49 loss=5.789, nll_loss=5.446, ppl=43.59, wps=27783.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.262, loss_scale=16, train_wall=198, gb_free=21.6, wall=5756
2022-03-05 15:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:59:06 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.639 | nll_loss 8.348 | ppl 325.75 | wps 47897.5 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.288
2022-03-05 15:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 15:59:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:59:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 15:59:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 8.639) (writing took 1.9188514871057123 seconds)
2022-03-05 15:59:08 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 15:59:08 | INFO | train | epoch 050 | loss 5.677 | nll_loss 5.329 | ppl 40.21 | wps 27711.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.228 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5832
2022-03-05 15:59:08 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 15:59:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:01:01 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.63 | nll_loss 8.338 | ppl 323.62 | wps 48004 | wpb 510.9 | bsz 1 | num_updates 2481 | best_loss 8.288
2022-03-05 16:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2481 updates
2022-03-05 16:01:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:01:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:01:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 51 @ 2481 updates, score 8.63) (writing took 1.8584611108526587 seconds)
2022-03-05 16:01:03 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:01:03 | INFO | train | epoch 051 | loss 5.589 | nll_loss 5.238 | ppl 37.73 | wps 27748.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2481 | lr 0.000310163 | gnorm 1.287 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5947
2022-03-05 16:01:03 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:01:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:01:45 | INFO | train_inner | epoch 052:     19 / 49 loss=5.591, nll_loss=5.24, ppl=37.8, wps=27765.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.251, loss_scale=32, train_wall=198, gb_free=21.6, wall=5989
2022-03-05 16:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:02:56 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.691 | nll_loss 8.405 | ppl 338.96 | wps 47858 | wpb 510.9 | bsz 1 | num_updates 2530 | best_loss 8.288
2022-03-05 16:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2530 updates
2022-03-05 16:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:02:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 52 @ 2530 updates, score 8.691) (writing took 1.8133974049706012 seconds)
2022-03-05 16:02:57 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:02:57 | INFO | train | epoch 052 | loss 5.497 | nll_loss 5.142 | ppl 35.32 | wps 27750.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2530 | lr 0.000316287 | gnorm 1.276 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6061
2022-03-05 16:02:57 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:04:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:04:50 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.764 | nll_loss 8.472 | ppl 355.1 | wps 47763.8 | wpb 510.9 | bsz 1 | num_updates 2578 | best_loss 8.288
2022-03-05 16:04:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2578 updates
2022-03-05 16:04:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:04:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:04:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 53 @ 2578 updates, score 8.764) (writing took 1.8639830979518592 seconds)
2022-03-05 16:04:52 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:04:52 | INFO | train | epoch 053 | loss 5.407 | nll_loss 5.049 | ppl 33.1 | wps 27154.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2578 | lr 0.000322286 | gnorm 1.285 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6176
2022-03-05 16:04:52 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:41 | INFO | train_inner | epoch 054:     22 / 49 loss=5.42, nll_loss=5.062, ppl=33.41, wps=27504.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.338, loss_scale=32, train_wall=200, gb_free=21.6, wall=6225
2022-03-05 16:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:06:45 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.801 | nll_loss 8.514 | ppl 365.48 | wps 47745.2 | wpb 510.9 | bsz 1 | num_updates 2627 | best_loss 8.288
2022-03-05 16:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2627 updates
2022-03-05 16:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 54 @ 2627 updates, score 8.801) (writing took 1.84537084819749 seconds)
2022-03-05 16:06:47 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:06:47 | INFO | train | epoch 054 | loss 5.325 | nll_loss 4.963 | ppl 31.19 | wps 27725 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2627 | lr 0.000328409 | gnorm 1.315 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6291
2022-03-05 16:06:47 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:08:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:08:39 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.833 | nll_loss 8.546 | ppl 373.79 | wps 48072.9 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 8.288
2022-03-05 16:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 8.833) (writing took 1.8236722680740058 seconds)
2022-03-05 16:08:41 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:08:41 | INFO | train | epoch 055 | loss 5.235 | nll_loss 4.869 | ppl 29.23 | wps 27182 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6405
2022-03-05 16:08:41 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:37 | INFO | train_inner | epoch 056:     25 / 49 loss=5.235, nll_loss=4.869, ppl=29.22, wps=27514.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.303, loss_scale=32, train_wall=200, gb_free=21.6, wall=6461
2022-03-05 16:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:10:34 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.844 | nll_loss 8.551 | ppl 375.17 | wps 47878.6 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.288
2022-03-05 16:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 8.844) (writing took 1.885781453922391 seconds)
2022-03-05 16:10:36 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:10:36 | INFO | train | epoch 056 | loss 5.149 | nll_loss 4.78 | ppl 27.47 | wps 27753.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.377 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6520
2022-03-05 16:10:36 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:10:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:12:28 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.004 | nll_loss 8.721 | ppl 421.96 | wps 47897.1 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 8.288
2022-03-05 16:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-05 16:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.004) (writing took 1.8929860070347786 seconds)
2022-03-05 16:12:30 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:12:30 | INFO | train | epoch 057 | loss 5.054 | nll_loss 4.681 | ppl 25.65 | wps 27163.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.331 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6634
2022-03-05 16:12:30 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:13:33 | INFO | train_inner | epoch 058:     28 / 49 loss=5.056, nll_loss=4.683, ppl=25.68, wps=27513, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.385, loss_scale=16, train_wall=200, gb_free=21.6, wall=6697
2022-03-05 16:14:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:14:23 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 8.933 | nll_loss 8.638 | ppl 398.3 | wps 47867.9 | wpb 510.9 | bsz 1 | num_updates 2821 | best_loss 8.288
2022-03-05 16:14:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2821 updates
2022-03-05 16:14:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:14:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 58 @ 2821 updates, score 8.933) (writing took 2.014730616007 seconds)
2022-03-05 16:14:25 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:14:25 | INFO | train | epoch 058 | loss 4.975 | nll_loss 4.598 | ppl 24.22 | wps 27687.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2821 | lr 0.000352654 | gnorm 1.39 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6749
2022-03-05 16:14:25 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:14:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:16:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:16:18 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.02 | nll_loss 8.728 | ppl 424.11 | wps 47945.3 | wpb 510.9 | bsz 1 | num_updates 2870 | best_loss 8.288
2022-03-05 16:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2870 updates
2022-03-05 16:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 59 @ 2870 updates, score 9.02) (writing took 1.8455495841335505 seconds)
2022-03-05 16:16:20 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:16:20 | INFO | train | epoch 059 | loss 4.89 | nll_loss 4.509 | ppl 22.77 | wps 27763 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2870 | lr 0.000358778 | gnorm 1.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6864
2022-03-05 16:16:20 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:17:26 | INFO | train_inner | epoch 060:     30 / 49 loss=4.882, nll_loss=4.501, ppl=22.64, wps=27753.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.412, loss_scale=32, train_wall=198, gb_free=21.6, wall=6930
2022-03-05 16:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:18:12 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.086 | nll_loss 8.787 | ppl 441.8 | wps 47836.9 | wpb 510.9 | bsz 1 | num_updates 2919 | best_loss 8.288
2022-03-05 16:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2919 updates
2022-03-05 16:18:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:18:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:18:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 60 @ 2919 updates, score 9.086) (writing took 1.8705733711831272 seconds)
2022-03-05 16:18:14 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:18:14 | INFO | train | epoch 060 | loss 4.802 | nll_loss 4.417 | ppl 21.37 | wps 27730.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2919 | lr 0.000364902 | gnorm 1.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6978
2022-03-05 16:18:14 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:18:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:20:07 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.118 | nll_loss 8.827 | ppl 454.19 | wps 47958.4 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 8.288
2022-03-05 16:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-05 16:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:20:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 61 @ 2967 updates, score 9.118) (writing took 1.7863348070532084 seconds)
2022-03-05 16:20:09 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:20:09 | INFO | train | epoch 061 | loss 4.72 | nll_loss 4.331 | ppl 20.13 | wps 27200.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.49 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7093
2022-03-05 16:20:09 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:21:22 | INFO | train_inner | epoch 062:     33 / 49 loss=4.701, nll_loss=4.312, ppl=19.87, wps=27531, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.439, loss_scale=16, train_wall=200, gb_free=21.6, wall=7166
2022-03-05 16:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:22:01 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.108 | nll_loss 8.809 | ppl 448.5 | wps 47784.3 | wpb 510.9 | bsz 1 | num_updates 3016 | best_loss 8.288
2022-03-05 16:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3016 updates
2022-03-05 16:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:22:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 62 @ 3016 updates, score 9.108) (writing took 1.863656154135242 seconds)
2022-03-05 16:22:03 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:22:03 | INFO | train | epoch 062 | loss 4.636 | nll_loss 4.244 | ppl 18.95 | wps 27752.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3016 | lr 0.000377025 | gnorm 1.493 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7207
2022-03-05 16:22:03 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:23:56 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.256 | nll_loss 8.966 | ppl 500.11 | wps 47910 | wpb 510.9 | bsz 1 | num_updates 3065 | best_loss 8.288
2022-03-05 16:23:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3065 updates
2022-03-05 16:23:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 63 @ 3065 updates, score 9.256) (writing took 1.909754374064505 seconds)
2022-03-05 16:23:58 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:23:58 | INFO | train | epoch 063 | loss 4.544 | nll_loss 4.148 | ppl 17.72 | wps 27732.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3065 | lr 0.000383148 | gnorm 1.389 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7322
2022-03-05 16:23:58 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:25:16 | INFO | train_inner | epoch 064:     35 / 49 loss=4.534, nll_loss=4.137, ppl=17.59, wps=27762.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.47, loss_scale=32, train_wall=198, gb_free=21.6, wall=7400
2022-03-05 16:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:25:50 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.275 | nll_loss 8.984 | ppl 506.37 | wps 47710.4 | wpb 510.9 | bsz 1 | num_updates 3114 | best_loss 8.288
2022-03-05 16:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3114 updates
2022-03-05 16:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:25:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 64 @ 3114 updates, score 9.275) (writing took 1.8618173249997199 seconds)
2022-03-05 16:25:52 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:25:52 | INFO | train | epoch 064 | loss 4.463 | nll_loss 4.062 | ppl 16.71 | wps 27715.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3114 | lr 0.000389272 | gnorm 1.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 7436
2022-03-05 16:25:52 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:25:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:27:45 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.303 | nll_loss 9.005 | ppl 513.84 | wps 47884.3 | wpb 510.9 | bsz 1 | num_updates 3162 | best_loss 8.288
2022-03-05 16:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3162 updates
2022-03-05 16:27:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:27:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:27:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 65 @ 3162 updates, score 9.303) (writing took 1.8679953450337052 seconds)
2022-03-05 16:27:47 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:27:47 | INFO | train | epoch 065 | loss 4.388 | nll_loss 3.984 | ppl 15.82 | wps 27159.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3162 | lr 0.000395271 | gnorm 1.55 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7551
2022-03-05 16:27:47 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:27:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:29:12 | INFO | train_inner | epoch 066:     38 / 49 loss=4.371, nll_loss=3.967, ppl=15.63, wps=27497.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.529, loss_scale=16, train_wall=200, gb_free=21.6, wall=7636
2022-03-05 16:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:29:40 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.379 | nll_loss 9.074 | ppl 538.97 | wps 47900.2 | wpb 510.9 | bsz 1 | num_updates 3211 | best_loss 8.288
2022-03-05 16:29:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3211 updates
2022-03-05 16:29:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 66 @ 3211 updates, score 9.379) (writing took 1.869697632966563 seconds)
2022-03-05 16:29:42 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:29:42 | INFO | train | epoch 066 | loss 4.311 | nll_loss 3.903 | ppl 14.96 | wps 27729.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3211 | lr 0.000401395 | gnorm 1.513 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7666
2022-03-05 16:29:42 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:31:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:31:34 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.453 | nll_loss 9.145 | ppl 566.16 | wps 47772.4 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.288
2022-03-05 16:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-05 16:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:31:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:31:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 67 @ 3259 updates, score 9.453) (writing took 1.790105759166181 seconds)
2022-03-05 16:31:36 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:31:36 | INFO | train | epoch 067 | loss 4.215 | nll_loss 3.803 | ppl 13.95 | wps 27190.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.437 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7780
2022-03-05 16:31:36 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:33:07 | INFO | train_inner | epoch 068:     41 / 49 loss=4.195, nll_loss=3.782, ppl=13.76, wps=27507.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.457, loss_scale=16, train_wall=200, gb_free=21.6, wall=7872
2022-03-05 16:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:33:29 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.495 | nll_loss 9.192 | ppl 584.73 | wps 47748.5 | wpb 510.9 | bsz 1 | num_updates 3308 | best_loss 8.288
2022-03-05 16:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3308 updates
2022-03-05 16:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 68 @ 3308 updates, score 9.495) (writing took 1.8944343209732324 seconds)
2022-03-05 16:33:31 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:33:31 | INFO | train | epoch 068 | loss 4.148 | nll_loss 3.733 | ppl 13.29 | wps 27698.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3308 | lr 0.000413517 | gnorm 1.55 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7895
2022-03-05 16:33:31 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:35:24 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.567 | nll_loss 9.268 | ppl 616.47 | wps 47780.1 | wpb 510.9 | bsz 1 | num_updates 3357 | best_loss 8.288
2022-03-05 16:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3357 updates
2022-03-05 16:35:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 69 @ 3357 updates, score 9.567) (writing took 1.8849917817860842 seconds)
2022-03-05 16:35:25 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:35:25 | INFO | train | epoch 069 | loss 4.065 | nll_loss 3.646 | ppl 12.52 | wps 27707.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3357 | lr 0.000419641 | gnorm 1.567 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8010
2022-03-05 16:35:25 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:37:03 | INFO | train_inner | epoch 070:     44 / 49 loss=4.037, nll_loss=3.616, ppl=12.27, wps=27489.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.558, loss_scale=16, train_wall=200, gb_free=21.6, wall=8108
2022-03-05 16:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:37:18 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.672 | nll_loss 9.362 | ppl 657.92 | wps 47798.9 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.288
2022-03-05 16:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-05 16:37:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 70 @ 3405 updates, score 9.672) (writing took 1.8188701909966767 seconds)
2022-03-05 16:37:20 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:37:20 | INFO | train | epoch 070 | loss 3.981 | nll_loss 3.558 | ppl 11.78 | wps 27184.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.511 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8124
2022-03-05 16:37:20 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:39:13 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.702 | nll_loss 9.4 | ppl 675.46 | wps 48037.2 | wpb 510.9 | bsz 1 | num_updates 3454 | best_loss 8.288
2022-03-05 16:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3454 updates
2022-03-05 16:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:39:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 71 @ 3454 updates, score 9.702) (writing took 1.8266852851957083 seconds)
2022-03-05 16:39:15 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:39:15 | INFO | train | epoch 071 | loss 3.905 | nll_loss 3.477 | ppl 11.14 | wps 27728.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3454 | lr 0.000431764 | gnorm 1.539 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8239
2022-03-05 16:39:15 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:40:57 | INFO | train_inner | epoch 072:     46 / 49 loss=3.873, nll_loss=3.444, ppl=10.88, wps=27765.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.527, loss_scale=16, train_wall=198, gb_free=21.6, wall=8341
2022-03-05 16:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:41:07 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.76 | nll_loss 9.459 | ppl 703.61 | wps 48005.4 | wpb 510.9 | bsz 1 | num_updates 3503 | best_loss 8.288
2022-03-05 16:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3503 updates
2022-03-05 16:41:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:41:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 72 @ 3503 updates, score 9.76) (writing took 1.8276625277940184 seconds)
2022-03-05 16:41:09 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:41:09 | INFO | train | epoch 072 | loss 3.828 | nll_loss 3.396 | ppl 10.53 | wps 27731.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3503 | lr 0.000437887 | gnorm 1.539 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8353
2022-03-05 16:41:09 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:43:02 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.847 | nll_loss 9.54 | ppl 744.39 | wps 48006.1 | wpb 510.9 | bsz 1 | num_updates 3552 | best_loss 8.288
2022-03-05 16:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3552 updates
2022-03-05 16:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:43:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:43:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 73 @ 3552 updates, score 9.847) (writing took 1.8137306380085647 seconds)
2022-03-05 16:43:04 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:43:04 | INFO | train | epoch 073 | loss 3.751 | nll_loss 3.316 | ppl 9.96 | wps 27770 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3552 | lr 0.000444011 | gnorm 1.542 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 8468
2022-03-05 16:43:04 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:43:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:44:52 | INFO | train_inner | epoch 074:     49 / 49 loss=3.719, nll_loss=3.282, ppl=9.72, wps=27510.7, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.559, loss_scale=16, train_wall=199, gb_free=21.6, wall=8576
2022-03-05 16:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:44:56 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.965 | nll_loss 9.661 | ppl 809.82 | wps 47925.3 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.288
2022-03-05 16:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-05 16:44:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 74 @ 3600 updates, score 9.965) (writing took 1.8749229810200632 seconds)
2022-03-05 16:44:58 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:44:58 | INFO | train | epoch 074 | loss 3.677 | nll_loss 3.238 | ppl 9.43 | wps 27163 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.569 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8582
2022-03-05 16:44:58 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:46:51 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.032 | nll_loss 9.734 | ppl 851.39 | wps 47965 | wpb 510.9 | bsz 1 | num_updates 3649 | best_loss 8.288
2022-03-05 16:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3649 updates
2022-03-05 16:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 75 @ 3649 updates, score 10.032) (writing took 1.8265278940089047 seconds)
2022-03-05 16:46:53 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:46:53 | INFO | train | epoch 075 | loss 3.602 | nll_loss 3.159 | ppl 8.93 | wps 27738.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3649 | lr 0.000456134 | gnorm 1.564 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8697
2022-03-05 16:46:53 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:48:46 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.094 | nll_loss 9.791 | ppl 886.05 | wps 47951.5 | wpb 510.9 | bsz 1 | num_updates 3698 | best_loss 8.288
2022-03-05 16:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3698 updates
2022-03-05 16:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 76 @ 3698 updates, score 10.094) (writing took 1.8245813969988376 seconds)
2022-03-05 16:48:47 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:48:47 | INFO | train | epoch 076 | loss 3.535 | nll_loss 3.088 | ppl 8.5 | wps 27744.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3698 | lr 0.000462258 | gnorm 1.59 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 8811
2022-03-05 16:48:47 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:48:52 | INFO | train_inner | epoch 077:      2 / 49 loss=3.566, nll_loss=3.12, ppl=8.7, wps=27011.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.574, loss_scale=32, train_wall=198, gb_free=21.6, wall=8816
2022-03-05 16:49:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:50:40 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.181 | nll_loss 9.867 | ppl 933.92 | wps 47848.2 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.288
2022-03-05 16:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-05 16:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:50:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 77 @ 3746 updates, score 10.181) (writing took 1.8287059899885207 seconds)
2022-03-05 16:50:42 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:50:42 | INFO | train | epoch 077 | loss 3.475 | nll_loss 3.024 | ppl 8.14 | wps 27180.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.686 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8926
2022-03-05 16:50:42 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:52:34 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.216 | nll_loss 9.906 | ppl 959.56 | wps 47870.8 | wpb 510.9 | bsz 1 | num_updates 3795 | best_loss 8.288
2022-03-05 16:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3795 updates
2022-03-05 16:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 78 @ 3795 updates, score 10.216) (writing took 1.8174833818338811 seconds)
2022-03-05 16:52:36 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:52:36 | INFO | train | epoch 078 | loss 3.386 | nll_loss 2.931 | ppl 7.63 | wps 27772.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3795 | lr 0.00047438 | gnorm 1.463 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9040
2022-03-05 16:52:36 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:52:47 | INFO | train_inner | epoch 079:      5 / 49 loss=3.423, nll_loss=2.969, ppl=7.83, wps=27534.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.574, loss_scale=16, train_wall=200, gb_free=21.6, wall=9052
2022-03-05 16:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:54:29 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.34 | nll_loss 10.028 | ppl 1044.13 | wps 48056.5 | wpb 510.9 | bsz 1 | num_updates 3844 | best_loss 8.288
2022-03-05 16:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3844 updates
2022-03-05 16:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 79 @ 3844 updates, score 10.34) (writing took 1.7542539529968053 seconds)
2022-03-05 16:54:31 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:54:31 | INFO | train | epoch 079 | loss 3.324 | nll_loss 2.865 | ppl 7.28 | wps 27800.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3844 | lr 0.000480504 | gnorm 1.562 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 9155
2022-03-05 16:54:31 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:56:23 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.404 | nll_loss 10.092 | ppl 1091.25 | wps 47945.7 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.288
2022-03-05 16:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-05 16:56:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 80 @ 3892 updates, score 10.404) (writing took 1.7766925259493291 seconds)
2022-03-05 16:56:25 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:56:25 | INFO | train | epoch 080 | loss 3.268 | nll_loss 2.805 | ppl 6.99 | wps 27202.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.658 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9269
2022-03-05 16:56:25 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:56:43 | INFO | train_inner | epoch 081:      8 / 49 loss=3.282, nll_loss=2.821, ppl=7.07, wps=27555.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.6, loss_scale=16, train_wall=200, gb_free=21.6, wall=9287
2022-03-05 16:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:58:18 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.518 | nll_loss 10.214 | ppl 1187.77 | wps 48060 | wpb 510.9 | bsz 1 | num_updates 3941 | best_loss 8.288
2022-03-05 16:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3941 updates
2022-03-05 16:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 16:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 81 @ 3941 updates, score 10.518) (writing took 1.828796606976539 seconds)
2022-03-05 16:58:19 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 16:58:19 | INFO | train | epoch 081 | loss 3.189 | nll_loss 2.722 | ppl 6.6 | wps 27782.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3941 | lr 0.000492626 | gnorm 1.584 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9383
2022-03-05 16:58:19 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 16:58:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:00:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:00:12 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.578 | nll_loss 10.268 | ppl 1233.44 | wps 47769.2 | wpb 510.9 | bsz 1 | num_updates 3990 | best_loss 8.288
2022-03-05 17:00:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3990 updates
2022-03-05 17:00:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:00:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:00:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 82 @ 3990 updates, score 10.578) (writing took 1.7528065850492567 seconds)
2022-03-05 17:00:14 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:00:14 | INFO | train | epoch 082 | loss 3.126 | nll_loss 2.655 | ppl 6.3 | wps 27773.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3990 | lr 0.00049875 | gnorm 1.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 9498
2022-03-05 17:00:14 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:00:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:00:36 | INFO | train_inner | epoch 083:     10 / 49 loss=3.145, nll_loss=2.675, ppl=6.39, wps=27810.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.575, loss_scale=32, train_wall=198, gb_free=21.6, wall=9520
2022-03-05 17:00:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:06 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.693 | nll_loss 10.39 | ppl 1342.19 | wps 48066.7 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.288
2022-03-05 17:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-05 17:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 83 @ 4038 updates, score 10.693) (writing took 1.7912460640072823 seconds)
2022-03-05 17:02:08 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:02:08 | INFO | train | epoch 083 | loss 3.052 | nll_loss 2.577 | ppl 5.97 | wps 27201.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.507 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9612
2022-03-05 17:02:08 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:02:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:01 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.751 | nll_loss 10.44 | ppl 1389 | wps 47943.3 | wpb 510.9 | bsz 1 | num_updates 4087 | best_loss 8.288
2022-03-05 17:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4087 updates
2022-03-05 17:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 84 @ 4087 updates, score 10.751) (writing took 1.783826069906354 seconds)
2022-03-05 17:04:03 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:04:03 | INFO | train | epoch 084 | loss 2.987 | nll_loss 2.508 | ppl 5.69 | wps 27768.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4087 | lr 0.00049465 | gnorm 1.515 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9727
2022-03-05 17:04:03 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:04:32 | INFO | train_inner | epoch 085:     13 / 49 loss=3.009, nll_loss=2.531, ppl=5.78, wps=27541.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.555, loss_scale=16, train_wall=200, gb_free=21.6, wall=9756
2022-03-05 17:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:05:55 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.86 | nll_loss 10.549 | ppl 1498.61 | wps 48021.2 | wpb 510.9 | bsz 1 | num_updates 4136 | best_loss 8.288
2022-03-05 17:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4136 updates
2022-03-05 17:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 85 @ 4136 updates, score 10.86) (writing took 1.7266307370737195 seconds)
2022-03-05 17:05:57 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:05:57 | INFO | train | epoch 085 | loss 2.935 | nll_loss 2.453 | ppl 5.47 | wps 27782.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4136 | lr 0.000491711 | gnorm 1.588 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 9841
2022-03-05 17:05:57 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:07:50 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.948 | nll_loss 10.633 | ppl 1587.71 | wps 48001.8 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.288
2022-03-05 17:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-05 17:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:07:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 86 @ 4184 updates, score 10.948) (writing took 1.7825291340705007 seconds)
2022-03-05 17:07:52 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:07:52 | INFO | train | epoch 086 | loss 2.856 | nll_loss 2.37 | ppl 5.17 | wps 27204.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.479 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9956
2022-03-05 17:07:52 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:08:27 | INFO | train_inner | epoch 087:     16 / 49 loss=2.867, nll_loss=2.381, ppl=5.21, wps=27543.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.467, loss_scale=16, train_wall=200, gb_free=21.6, wall=9991
2022-03-05 17:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:09:44 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.957 | nll_loss 10.64 | ppl 1596.05 | wps 48210.8 | wpb 510.9 | bsz 1 | num_updates 4233 | best_loss 8.288
2022-03-05 17:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4233 updates
2022-03-05 17:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 87 @ 4233 updates, score 10.957) (writing took 1.7511407150886953 seconds)
2022-03-05 17:09:46 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:09:46 | INFO | train | epoch 087 | loss 2.806 | nll_loss 2.316 | ppl 4.98 | wps 27763.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4233 | lr 0.000486044 | gnorm 1.536 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10070
2022-03-05 17:09:46 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:11:39 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.127 | nll_loss 10.814 | ppl 1800.42 | wps 48020.8 | wpb 510.9 | bsz 1 | num_updates 4282 | best_loss 8.288
2022-03-05 17:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4282 updates
2022-03-05 17:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 88 @ 4282 updates, score 11.127) (writing took 1.7320306070614606 seconds)
2022-03-05 17:11:40 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:11:40 | INFO | train | epoch 088 | loss 2.731 | nll_loss 2.237 | ppl 4.71 | wps 27795.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4282 | lr 0.000483255 | gnorm 1.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 10184
2022-03-05 17:11:40 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:12:20 | INFO | train_inner | epoch 089:     18 / 49 loss=2.747, nll_loss=2.254, ppl=4.77, wps=27815.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.478, loss_scale=32, train_wall=198, gb_free=21.6, wall=10225
2022-03-05 17:13:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:13:33 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.212 | nll_loss 10.907 | ppl 1920.4 | wps 48001.2 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.288
2022-03-05 17:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-05 17:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:13:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:13:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.212) (writing took 1.7630833152215928 seconds)
2022-03-05 17:13:35 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:13:35 | INFO | train | epoch 089 | loss 2.676 | nll_loss 2.178 | ppl 4.53 | wps 27206.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.467 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10299
2022-03-05 17:13:35 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:15:27 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.27 | nll_loss 10.96 | ppl 1992.15 | wps 48051.7 | wpb 510.9 | bsz 1 | num_updates 4379 | best_loss 8.288
2022-03-05 17:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4379 updates
2022-03-05 17:15:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:15:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 90 @ 4379 updates, score 11.27) (writing took 1.8068154328502715 seconds)
2022-03-05 17:15:29 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:15:29 | INFO | train | epoch 090 | loss 2.617 | nll_loss 2.116 | ppl 4.33 | wps 27762.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4379 | lr 0.000477873 | gnorm 1.411 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10413
2022-03-05 17:15:29 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:16 | INFO | train_inner | epoch 091:     21 / 49 loss=2.625, nll_loss=2.124, ppl=4.36, wps=27537.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.442, loss_scale=16, train_wall=200, gb_free=21.6, wall=10460
2022-03-05 17:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:17:22 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.371 | nll_loss 11.062 | ppl 2137.86 | wps 47960.8 | wpb 510.9 | bsz 1 | num_updates 4428 | best_loss 8.288
2022-03-05 17:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4428 updates
2022-03-05 17:17:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 91 @ 4428 updates, score 11.371) (writing took 1.7632371508516371 seconds)
2022-03-05 17:17:24 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:17:24 | INFO | train | epoch 091 | loss 2.568 | nll_loss 2.064 | ppl 4.18 | wps 27775.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4428 | lr 0.000475222 | gnorm 1.442 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10528
2022-03-05 17:17:24 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:18:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:19:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:19:16 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.487 | nll_loss 11.176 | ppl 2314.24 | wps 48024.1 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.288
2022-03-05 17:19:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-05 17:19:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:19:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:19:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 92 @ 4476 updates, score 11.487) (writing took 1.768778522964567 seconds)
2022-03-05 17:19:18 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:19:18 | INFO | train | epoch 092 | loss 2.512 | nll_loss 2.004 | ppl 4.01 | wps 27197.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.415 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10642
2022-03-05 17:19:18 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:19:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:20:12 | INFO | train_inner | epoch 093:     24 / 49 loss=2.514, nll_loss=2.006, ppl=4.02, wps=27547.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.414, loss_scale=16, train_wall=200, gb_free=21.6, wall=10696
2022-03-05 17:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:21:11 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.558 | nll_loss 11.249 | ppl 2434.64 | wps 48064.2 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.288
2022-03-05 17:21:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4525 updates
2022-03-05 17:21:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:21:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 93 @ 4525 updates, score 11.558) (writing took 1.7210001680068672 seconds)
2022-03-05 17:21:12 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:21:12 | INFO | train | epoch 093 | loss 2.465 | nll_loss 1.953 | ppl 3.87 | wps 27800.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4525 | lr 0.0004701 | gnorm 1.425 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10756
2022-03-05 17:21:12 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:23:05 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.637 | nll_loss 11.331 | ppl 2576.29 | wps 48054 | wpb 510.9 | bsz 1 | num_updates 4574 | best_loss 8.288
2022-03-05 17:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4574 updates
2022-03-05 17:23:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 94 @ 4574 updates, score 11.637) (writing took 1.7409864570945501 seconds)
2022-03-05 17:23:07 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:23:07 | INFO | train | epoch 094 | loss 2.411 | nll_loss 1.897 | ppl 3.72 | wps 27814.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4574 | lr 0.000467576 | gnorm 1.383 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10871
2022-03-05 17:23:07 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:24:05 | INFO | train_inner | epoch 095:     26 / 49 loss=2.413, nll_loss=1.899, ppl=3.73, wps=27832.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.404, loss_scale=32, train_wall=198, gb_free=21.6, wall=10929
2022-03-05 17:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:24:59 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.759 | nll_loss 11.451 | ppl 2800.43 | wps 47905.7 | wpb 510.9 | bsz 1 | num_updates 4623 | best_loss 8.288
2022-03-05 17:24:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4623 updates
2022-03-05 17:24:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:25:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 95 @ 4623 updates, score 11.759) (writing took 1.761348573025316 seconds)
2022-03-05 17:25:01 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:25:01 | INFO | train | epoch 095 | loss 2.362 | nll_loss 1.844 | ppl 3.59 | wps 27761.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4623 | lr 0.000465091 | gnorm 1.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 10985
2022-03-05 17:25:01 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:25:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:26:54 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.793 | nll_loss 11.482 | ppl 2860.32 | wps 47433 | wpb 510.9 | bsz 1 | num_updates 4672 | best_loss 8.288
2022-03-05 17:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4672 updates
2022-03-05 17:26:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 96 @ 4672 updates, score 11.793) (writing took 1.7694685279857367 seconds)
2022-03-05 17:26:56 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:26:56 | INFO | train | epoch 096 | loss 2.323 | nll_loss 1.801 | ppl 3.49 | wps 27752.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4672 | lr 0.000462646 | gnorm 1.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 11100
2022-03-05 17:26:56 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:27:58 | INFO | train_inner | epoch 097:     28 / 49 loss=2.314, nll_loss=1.793, ppl=3.47, wps=27790.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.366, loss_scale=32, train_wall=198, gb_free=21.6, wall=11162
2022-03-05 17:28:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:28:48 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.867 | nll_loss 11.562 | ppl 3023.82 | wps 48083 | wpb 510.9 | bsz 1 | num_updates 4720 | best_loss 8.288
2022-03-05 17:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4720 updates
2022-03-05 17:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 97 @ 4720 updates, score 11.867) (writing took 1.7513316320255399 seconds)
2022-03-05 17:28:50 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:28:50 | INFO | train | epoch 097 | loss 2.266 | nll_loss 1.741 | ppl 3.34 | wps 27212.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4720 | lr 0.000460287 | gnorm 1.294 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 11214
2022-03-05 17:28:50 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:28:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:30:43 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.02 | nll_loss 11.716 | ppl 3363.61 | wps 47827.4 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 8.288
2022-03-05 17:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-05 17:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.02) (writing took 1.7682519510854036 seconds)
2022-03-05 17:30:44 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:30:44 | INFO | train | epoch 098 | loss 2.23 | nll_loss 1.703 | ppl 3.26 | wps 27198.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.345 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11328
2022-03-05 17:30:44 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:31:56 | INFO | train_inner | epoch 099:     32 / 49 loss=2.231, nll_loss=1.703, ppl=3.26, wps=27297.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.348, loss_scale=16, train_wall=202, gb_free=21.6, wall=11400
2022-03-05 17:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:32:37 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.011 | nll_loss 11.701 | ppl 3330.13 | wps 47883.3 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.288
2022-03-05 17:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-05 17:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 99 @ 4817 updates, score 12.011) (writing took 1.7979521879460663 seconds)
2022-03-05 17:32:39 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:32:39 | INFO | train | epoch 099 | loss 2.193 | nll_loss 1.663 | ppl 3.17 | wps 27773.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.323 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11443
2022-03-05 17:32:39 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:34:31 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.14 | nll_loss 11.828 | ppl 3636.18 | wps 47933.6 | wpb 510.9 | bsz 1 | num_updates 4866 | best_loss 8.288
2022-03-05 17:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4866 updates
2022-03-05 17:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 100 @ 4866 updates, score 12.14) (writing took 1.7709857679437846 seconds)
2022-03-05 17:34:33 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:34:33 | INFO | train | epoch 100 | loss 2.148 | nll_loss 1.615 | ppl 3.06 | wps 27788.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4866 | lr 0.000453329 | gnorm 1.291 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 11557
2022-03-05 17:34:33 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:35:51 | INFO | train_inner | epoch 101:     35 / 49 loss=2.14, nll_loss=1.606, ppl=3.05, wps=27551.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.285, loss_scale=16, train_wall=200, gb_free=21.6, wall=11635
2022-03-05 17:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:36:26 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.216 | nll_loss 11.91 | ppl 3848.19 | wps 48021.1 | wpb 510.9 | bsz 1 | num_updates 4914 | best_loss 8.288
2022-03-05 17:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4914 updates
2022-03-05 17:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 101 @ 4914 updates, score 12.216) (writing took 1.6967515640426427 seconds)
2022-03-05 17:36:27 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:36:27 | INFO | train | epoch 101 | loss 2.113 | nll_loss 1.578 | ppl 2.98 | wps 27248 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4914 | lr 0.00045111 | gnorm 1.337 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11672
2022-03-05 17:36:27 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:38:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:38:20 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.299 | nll_loss 11.994 | ppl 4079.39 | wps 47806.4 | wpb 510.9 | bsz 1 | num_updates 4963 | best_loss 8.288
2022-03-05 17:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4963 updates
2022-03-05 17:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 102 @ 4963 updates, score 12.299) (writing took 1.6521376280579716 seconds)
2022-03-05 17:38:22 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:38:22 | INFO | train | epoch 102 | loss 2.073 | nll_loss 1.535 | ppl 2.9 | wps 27797.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4963 | lr 0.000448878 | gnorm 1.266 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11786
2022-03-05 17:38:22 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:44 | INFO | train_inner | epoch 103:     37 / 49 loss=2.066, nll_loss=1.527, ppl=2.88, wps=27840, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.285, loss_scale=16, train_wall=198, gb_free=21.6, wall=11868
2022-03-05 17:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:40:14 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.383 | nll_loss 12.077 | ppl 4321.3 | wps 47789.1 | wpb 510.9 | bsz 1 | num_updates 5012 | best_loss 8.288
2022-03-05 17:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5012 updates
2022-03-05 17:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 103 @ 5012 updates, score 12.383) (writing took 1.6847147149965167 seconds)
2022-03-05 17:40:16 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:40:16 | INFO | train | epoch 103 | loss 2.038 | nll_loss 1.497 | ppl 2.82 | wps 27808.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5012 | lr 0.000446678 | gnorm 1.271 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 11900
2022-03-05 17:40:16 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:42:09 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.424 | nll_loss 12.118 | ppl 4444.47 | wps 47768.2 | wpb 510.9 | bsz 1 | num_updates 5060 | best_loss 8.288
2022-03-05 17:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5060 updates
2022-03-05 17:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 104 @ 5060 updates, score 12.424) (writing took 1.7629363390151411 seconds)
2022-03-05 17:42:10 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:42:10 | INFO | train | epoch 104 | loss 2.004 | nll_loss 1.461 | ppl 2.75 | wps 27206.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5060 | lr 0.000444554 | gnorm 1.286 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12015
2022-03-05 17:42:10 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:43:40 | INFO | train_inner | epoch 105:     40 / 49 loss=1.998, nll_loss=1.454, ppl=2.74, wps=27559.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.274, loss_scale=16, train_wall=200, gb_free=21.6, wall=12104
2022-03-05 17:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:44:03 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.58 | nll_loss 12.279 | ppl 4971.42 | wps 47740.3 | wpb 510.9 | bsz 1 | num_updates 5109 | best_loss 8.288
2022-03-05 17:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5109 updates
2022-03-05 17:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 105 @ 5109 updates, score 12.58) (writing took 1.7121724628377706 seconds)
2022-03-05 17:44:05 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:44:05 | INFO | train | epoch 105 | loss 1.973 | nll_loss 1.427 | ppl 2.69 | wps 27790.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5109 | lr 0.000442417 | gnorm 1.249 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12129
2022-03-05 17:44:05 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:45:58 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.645 | nll_loss 12.34 | ppl 5183.24 | wps 47943.5 | wpb 510.9 | bsz 1 | num_updates 5158 | best_loss 8.288
2022-03-05 17:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5158 updates
2022-03-05 17:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 106 @ 5158 updates, score 12.645) (writing took 1.7140372679568827 seconds)
2022-03-05 17:45:59 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:45:59 | INFO | train | epoch 106 | loss 1.938 | nll_loss 1.389 | ppl 2.62 | wps 27775.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5158 | lr 0.000440311 | gnorm 1.241 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 12243
2022-03-05 17:45:59 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:47:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:47:35 | INFO | train_inner | epoch 107:     43 / 49 loss=1.932, nll_loss=1.383, ppl=2.61, wps=27547.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.251, loss_scale=16, train_wall=200, gb_free=21.6, wall=12339
2022-03-05 17:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:47:52 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.647 | nll_loss 12.343 | ppl 5196.7 | wps 47886.1 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.288
2022-03-05 17:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-05 17:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 107 @ 5206 updates, score 12.647) (writing took 1.6812344179488719 seconds)
2022-03-05 17:47:54 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:47:54 | INFO | train | epoch 107 | loss 1.91 | nll_loss 1.36 | ppl 2.57 | wps 27219.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.256 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12358
2022-03-05 17:47:54 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:49:46 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.782 | nll_loss 12.487 | ppl 5741.02 | wps 47978.9 | wpb 510.9 | bsz 1 | num_updates 5255 | best_loss 8.288
2022-03-05 17:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5255 updates
2022-03-05 17:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 108 @ 5255 updates, score 12.782) (writing took 1.699771106010303 seconds)
2022-03-05 17:49:48 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:49:48 | INFO | train | epoch 108 | loss 1.878 | nll_loss 1.325 | ppl 2.51 | wps 27784.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5255 | lr 0.000436228 | gnorm 1.223 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12472
2022-03-05 17:49:48 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:51:28 | INFO | train_inner | epoch 109:     45 / 49 loss=1.87, nll_loss=1.317, ppl=2.49, wps=27823.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.242, loss_scale=16, train_wall=198, gb_free=21.6, wall=12572
2022-03-05 17:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:51:41 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.79 | nll_loss 12.487 | ppl 5739.96 | wps 47927.2 | wpb 510.9 | bsz 1 | num_updates 5304 | best_loss 8.288
2022-03-05 17:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5304 updates
2022-03-05 17:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 109 @ 5304 updates, score 12.79) (writing took 1.7346895998343825 seconds)
2022-03-05 17:51:42 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:51:42 | INFO | train | epoch 109 | loss 1.856 | nll_loss 1.301 | ppl 2.46 | wps 27787 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5304 | lr 0.000434208 | gnorm 1.268 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12586
2022-03-05 17:51:42 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:53:35 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.783 | nll_loss 12.481 | ppl 5717.84 | wps 47878.4 | wpb 510.9 | bsz 1 | num_updates 5353 | best_loss 8.288
2022-03-05 17:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5353 updates
2022-03-05 17:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 110 @ 5353 updates, score 12.783) (writing took 1.7300818259827793 seconds)
2022-03-05 17:53:37 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:53:37 | INFO | train | epoch 110 | loss 1.823 | nll_loss 1.266 | ppl 2.4 | wps 27787.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5353 | lr 0.000432217 | gnorm 1.189 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 12701
2022-03-05 17:53:37 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:55:21 | INFO | train_inner | epoch 111:     47 / 49 loss=1.812, nll_loss=1.254, ppl=2.39, wps=27816.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.185, loss_scale=32, train_wall=198, gb_free=21.6, wall=12805
2022-03-05 17:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:55:29 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.888 | nll_loss 12.592 | ppl 6174.96 | wps 47848.4 | wpb 510.9 | bsz 1 | num_updates 5402 | best_loss 8.288
2022-03-05 17:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5402 updates
2022-03-05 17:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 111 @ 5402 updates, score 12.888) (writing took 1.7074768701568246 seconds)
2022-03-05 17:55:31 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:55:31 | INFO | train | epoch 111 | loss 1.796 | nll_loss 1.237 | ppl 2.36 | wps 27786.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5402 | lr 0.000430252 | gnorm 1.177 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 12815
2022-03-05 17:55:31 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:57:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:57:24 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 13.059 | nll_loss 12.761 | ppl 6939.79 | wps 47797.7 | wpb 510.9 | bsz 1 | num_updates 5450 | best_loss 8.288
2022-03-05 17:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5450 updates
2022-03-05 17:57:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 112 @ 5450 updates, score 13.059) (writing took 1.7643204010091722 seconds)
2022-03-05 17:57:26 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:57:26 | INFO | train | epoch 112 | loss 1.773 | nll_loss 1.212 | ppl 2.32 | wps 27194.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5450 | lr 0.000428353 | gnorm 1.224 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 12930
2022-03-05 17:57:26 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:59:18 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.03 | nll_loss 12.735 | ppl 6816.35 | wps 47843.1 | wpb 510.9 | bsz 1 | num_updates 5499 | best_loss 8.288
2022-03-05 17:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5499 updates
2022-03-05 17:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 17:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 113 @ 5499 updates, score 13.03) (writing took 1.687573374947533 seconds)
2022-03-05 17:59:20 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 17:59:20 | INFO | train | epoch 113 | loss 1.748 | nll_loss 1.185 | ppl 2.27 | wps 27810.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5499 | lr 0.00042644 | gnorm 1.175 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13044
2022-03-05 17:59:20 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 17:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:59:22 | INFO | train_inner | epoch 114:      1 / 49 loss=1.761, nll_loss=1.199, ppl=2.3, wps=26808.6, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.203, loss_scale=32, train_wall=199, gb_free=21.6, wall=13046
2022-03-05 18:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:01:12 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.1 | nll_loss 12.803 | ppl 7145.37 | wps 48104.3 | wpb 510.9 | bsz 1 | num_updates 5548 | best_loss 8.288
2022-03-05 18:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5548 updates
2022-03-05 18:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 114 @ 5548 updates, score 13.1) (writing took 1.7060026628896594 seconds)
2022-03-05 18:01:14 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:01:14 | INFO | train | epoch 114 | loss 1.724 | nll_loss 1.16 | ppl 2.23 | wps 27796.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5548 | lr 0.000424553 | gnorm 1.172 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13158
2022-03-05 18:01:14 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:02:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:03:07 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.169 | nll_loss 12.868 | ppl 7476.86 | wps 47885.9 | wpb 510.9 | bsz 1 | num_updates 5596 | best_loss 8.288
2022-03-05 18:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5596 updates
2022-03-05 18:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 115 @ 5596 updates, score 13.169) (writing took 1.6926057380624115 seconds)
2022-03-05 18:03:08 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:03:08 | INFO | train | epoch 115 | loss 1.7 | nll_loss 1.133 | ppl 2.19 | wps 27247.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5596 | lr 0.000422728 | gnorm 1.142 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13272
2022-03-05 18:03:08 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:03:17 | INFO | train_inner | epoch 116:      4 / 49 loss=1.71, nll_loss=1.144, ppl=2.21, wps=27579, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.154, loss_scale=32, train_wall=200, gb_free=21.6, wall=13281
2022-03-05 18:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:05:01 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.217 | nll_loss 12.92 | ppl 7749.63 | wps 47783.5 | wpb 510.9 | bsz 1 | num_updates 5645 | best_loss 8.288
2022-03-05 18:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5645 updates
2022-03-05 18:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 116 @ 5645 updates, score 13.217) (writing took 1.7024338620249182 seconds)
2022-03-05 18:05:03 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:05:03 | INFO | train | epoch 116 | loss 1.679 | nll_loss 1.111 | ppl 2.16 | wps 27807.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5645 | lr 0.000420889 | gnorm 1.14 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13387
2022-03-05 18:05:03 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:06:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:06:55 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.295 | nll_loss 13.007 | ppl 8233.88 | wps 48007.6 | wpb 510.9 | bsz 1 | num_updates 5694 | best_loss 8.288
2022-03-05 18:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5694 updates
2022-03-05 18:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 117 @ 5694 updates, score 13.295) (writing took 1.7118428000248969 seconds)
2022-03-05 18:06:57 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:06:57 | INFO | train | epoch 117 | loss 1.661 | nll_loss 1.092 | ppl 2.13 | wps 27785 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5694 | lr 0.000419075 | gnorm 1.147 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13501
2022-03-05 18:06:57 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:07:10 | INFO | train_inner | epoch 118:      6 / 49 loss=1.668, nll_loss=1.099, ppl=2.14, wps=27829, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.144, loss_scale=32, train_wall=198, gb_free=21.6, wall=13515
2022-03-05 18:07:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:08:50 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.385 | nll_loss 13.089 | ppl 8714.87 | wps 48023.6 | wpb 510.9 | bsz 1 | num_updates 5742 | best_loss 8.288
2022-03-05 18:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5742 updates
2022-03-05 18:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 118 @ 5742 updates, score 13.385) (writing took 1.756399380043149 seconds)
2022-03-05 18:08:51 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:08:51 | INFO | train | epoch 118 | loss 1.637 | nll_loss 1.066 | ppl 2.09 | wps 27222.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5742 | lr 0.000417319 | gnorm 1.134 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13615
2022-03-05 18:08:51 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:10:44 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.522 | nll_loss 13.233 | ppl 9624.55 | wps 47987.6 | wpb 510.9 | bsz 1 | num_updates 5791 | best_loss 8.288
2022-03-05 18:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5791 updates
2022-03-05 18:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 119 @ 5791 updates, score 13.522) (writing took 1.738431585021317 seconds)
2022-03-05 18:10:46 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:10:46 | INFO | train | epoch 119 | loss 1.616 | nll_loss 1.043 | ppl 2.06 | wps 27791.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5791 | lr 0.00041555 | gnorm 1.104 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13730
2022-03-05 18:10:46 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:11:06 | INFO | train_inner | epoch 120:      9 / 49 loss=1.622, nll_loss=1.05, ppl=2.07, wps=27556.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.122, loss_scale=32, train_wall=200, gb_free=21.6, wall=13750
2022-03-05 18:12:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:12:38 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.535 | nll_loss 13.241 | ppl 9682.27 | wps 47942.4 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.288
2022-03-05 18:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-05 18:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 120 @ 5839 updates, score 13.535) (writing took 1.6982308719307184 seconds)
2022-03-05 18:12:40 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:12:40 | INFO | train | epoch 120 | loss 1.597 | nll_loss 1.023 | ppl 2.03 | wps 27228.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.116 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13844
2022-03-05 18:12:40 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:14:33 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.603 | nll_loss 13.316 | ppl 10197.5 | wps 47778.9 | wpb 510.9 | bsz 1 | num_updates 5888 | best_loss 8.288
2022-03-05 18:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5888 updates
2022-03-05 18:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 121 @ 5888 updates, score 13.603) (writing took 1.7301074350252748 seconds)
2022-03-05 18:14:34 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:14:34 | INFO | train | epoch 121 | loss 1.582 | nll_loss 1.006 | ppl 2.01 | wps 27775 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5888 | lr 0.000412113 | gnorm 1.126 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 13959
2022-03-05 18:14:34 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:15:01 | INFO | train_inner | epoch 122:     12 / 49 loss=1.585, nll_loss=1.009, ppl=2.01, wps=27562.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.115, loss_scale=32, train_wall=200, gb_free=21.6, wall=13985
2022-03-05 18:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:16:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:16:27 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.543 | nll_loss 13.254 | ppl 9770.93 | wps 47696.9 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.288
2022-03-05 18:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-05 18:16:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.543) (writing took 1.7032608361914754 seconds)
2022-03-05 18:16:29 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:16:29 | INFO | train | epoch 122 | loss 1.562 | nll_loss 0.985 | ppl 1.98 | wps 27201.7 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.112 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14073
2022-03-05 18:16:29 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:18:21 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.686 | nll_loss 13.4 | ppl 10810.4 | wps 47881.2 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.288
2022-03-05 18:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-05 18:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 123 @ 5985 updates, score 13.686) (writing took 1.6997915969695896 seconds)
2022-03-05 18:18:23 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:18:23 | INFO | train | epoch 123 | loss 1.545 | nll_loss 0.967 | ppl 1.95 | wps 27809.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 1.08 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14187
2022-03-05 18:18:23 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:18:57 | INFO | train_inner | epoch 124:     15 / 49 loss=1.549, nll_loss=0.971, ppl=1.96, wps=27563.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.095, loss_scale=16, train_wall=200, gb_free=21.6, wall=14221
2022-03-05 18:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:20:16 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.716 | nll_loss 13.43 | ppl 11034.1 | wps 47893.9 | wpb 510.9 | bsz 1 | num_updates 6034 | best_loss 8.288
2022-03-05 18:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6034 updates
2022-03-05 18:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 124 @ 6034 updates, score 13.716) (writing took 1.666842439910397 seconds)
2022-03-05 18:20:18 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:20:18 | INFO | train | epoch 124 | loss 1.527 | nll_loss 0.947 | ppl 1.93 | wps 27798.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6034 | lr 0.000407096 | gnorm 1.059 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14302
2022-03-05 18:20:18 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:22:10 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.686 | nll_loss 13.395 | ppl 10775.3 | wps 47919.6 | wpb 510.9 | bsz 1 | num_updates 6083 | best_loss 8.288
2022-03-05 18:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6083 updates
2022-03-05 18:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 125 @ 6083 updates, score 13.686) (writing took 1.6678457020316273 seconds)
2022-03-05 18:22:12 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:22:12 | INFO | train | epoch 125 | loss 1.513 | nll_loss 0.932 | ppl 1.91 | wps 27790 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6083 | lr 0.000405454 | gnorm 1.075 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 14416
2022-03-05 18:22:12 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:22:50 | INFO | train_inner | epoch 126:     17 / 49 loss=1.513, nll_loss=0.933, ppl=1.91, wps=27816.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.055, loss_scale=32, train_wall=198, gb_free=21.6, wall=14454
2022-03-05 18:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:24:05 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.835 | nll_loss 13.554 | ppl 12024.7 | wps 47927.3 | wpb 510.9 | bsz 1 | num_updates 6132 | best_loss 8.288
2022-03-05 18:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6132 updates
2022-03-05 18:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 126 @ 6132 updates, score 13.835) (writing took 1.683429769007489 seconds)
2022-03-05 18:24:06 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:24:06 | INFO | train | epoch 126 | loss 1.497 | nll_loss 0.916 | ppl 1.89 | wps 27782.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6132 | lr 0.00040383 | gnorm 1.029 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 14530
2022-03-05 18:24:06 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:25:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:59 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.852 | nll_loss 13.573 | ppl 12183.4 | wps 47694.3 | wpb 510.9 | bsz 1 | num_updates 6180 | best_loss 8.288
2022-03-05 18:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6180 updates
2022-03-05 18:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:26:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 127 @ 6180 updates, score 13.852) (writing took 1.6932977919932455 seconds)
2022-03-05 18:26:01 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:26:01 | INFO | train | epoch 127 | loss 1.48 | nll_loss 0.897 | ppl 1.86 | wps 27216.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6180 | lr 0.000402259 | gnorm 1.039 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14645
2022-03-05 18:26:01 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:26:45 | INFO | train_inner | epoch 128:     20 / 49 loss=1.483, nll_loss=0.901, ppl=1.87, wps=27564.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.038, loss_scale=16, train_wall=200, gb_free=21.6, wall=14689
2022-03-05 18:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:53 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.86 | nll_loss 13.578 | ppl 12229.1 | wps 48022.7 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.288
2022-03-05 18:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-05 18:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:27:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 128 @ 6229 updates, score 13.86) (writing took 1.7022210729774088 seconds)
2022-03-05 18:27:55 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:27:55 | INFO | train | epoch 128 | loss 1.471 | nll_loss 0.888 | ppl 1.85 | wps 27795.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 1.062 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14759
2022-03-05 18:27:55 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:47 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.879 | nll_loss 13.598 | ppl 12401.6 | wps 48097.1 | wpb 510.9 | bsz 1 | num_updates 6278 | best_loss 8.288
2022-03-05 18:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6278 updates
2022-03-05 18:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 129 @ 6278 updates, score 13.879) (writing took 1.7035635029897094 seconds)
2022-03-05 18:29:49 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:29:49 | INFO | train | epoch 129 | loss 1.457 | nll_loss 0.873 | ppl 1.83 | wps 27838.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6278 | lr 0.000399107 | gnorm 1.054 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14873
2022-03-05 18:29:49 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:30:38 | INFO | train_inner | epoch 130:     22 / 49 loss=1.458, nll_loss=0.873, ppl=1.83, wps=27849.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.045, loss_scale=32, train_wall=198, gb_free=21.6, wall=14922
2022-03-05 18:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:31:42 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.971 | nll_loss 13.687 | ppl 13190.6 | wps 47850.6 | wpb 510.9 | bsz 1 | num_updates 6327 | best_loss 8.288
2022-03-05 18:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6327 updates
2022-03-05 18:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:31:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 130 @ 6327 updates, score 13.971) (writing took 1.690878642955795 seconds)
2022-03-05 18:31:43 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:31:43 | INFO | train | epoch 130 | loss 1.437 | nll_loss 0.851 | ppl 1.8 | wps 27812.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6327 | lr 0.000397559 | gnorm 1 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 14987
2022-03-05 18:31:43 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:32:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:33:36 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 14.026 | nll_loss 13.747 | ppl 13744.3 | wps 47906.6 | wpb 510.9 | bsz 1 | num_updates 6375 | best_loss 8.288
2022-03-05 18:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6375 updates
2022-03-05 18:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 131 @ 6375 updates, score 14.026) (writing took 1.7142924810759723 seconds)
2022-03-05 18:33:38 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:33:38 | INFO | train | epoch 131 | loss 1.426 | nll_loss 0.84 | ppl 1.79 | wps 27265.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6375 | lr 0.000396059 | gnorm 1.033 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15102
2022-03-05 18:33:38 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:34:33 | INFO | train_inner | epoch 132:     25 / 49 loss=1.424, nll_loss=0.838, ppl=1.79, wps=27607.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=1.004, loss_scale=16, train_wall=200, gb_free=21.6, wall=15157
2022-03-05 18:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:35:30 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 14.019 | nll_loss 13.738 | ppl 13665.8 | wps 47512.9 | wpb 510.9 | bsz 1 | num_updates 6424 | best_loss 8.288
2022-03-05 18:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6424 updates
2022-03-05 18:35:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 132 @ 6424 updates, score 14.019) (writing took 1.7247521521057934 seconds)
2022-03-05 18:35:32 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:35:32 | INFO | train | epoch 132 | loss 1.411 | nll_loss 0.824 | ppl 1.77 | wps 27830.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6424 | lr 0.000394546 | gnorm 0.989 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15216
2022-03-05 18:35:32 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:37:24 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 14.097 | nll_loss 13.813 | ppl 14393.9 | wps 48695.2 | wpb 510.9 | bsz 1 | num_updates 6473 | best_loss 8.288
2022-03-05 18:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6473 updates
2022-03-05 18:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 133 @ 6473 updates, score 14.097) (writing took 1.6995413831900805 seconds)
2022-03-05 18:37:26 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:37:26 | INFO | train | epoch 133 | loss 1.403 | nll_loss 0.816 | ppl 1.76 | wps 27844.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6473 | lr 0.000393049 | gnorm 1.016 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15330
2022-03-05 18:37:26 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:38:26 | INFO | train_inner | epoch 134:     27 / 49 loss=1.403, nll_loss=0.815, ppl=1.76, wps=27863.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=1.011, loss_scale=32, train_wall=198, gb_free=21.6, wall=15390
2022-03-05 18:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:39:18 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 14.186 | nll_loss 13.913 | ppl 15424.8 | wps 47934 | wpb 510.9 | bsz 1 | num_updates 6522 | best_loss 8.288
2022-03-05 18:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6522 updates
2022-03-05 18:39:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 134 @ 6522 updates, score 14.186) (writing took 1.7148668731097132 seconds)
2022-03-05 18:39:20 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:39:20 | INFO | train | epoch 134 | loss 1.391 | nll_loss 0.803 | ppl 1.74 | wps 27805.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6522 | lr 0.00039157 | gnorm 0.993 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15444
2022-03-05 18:39:20 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:41:13 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 14.178 | nll_loss 13.905 | ppl 15337.8 | wps 48018.6 | wpb 510.9 | bsz 1 | num_updates 6571 | best_loss 8.288
2022-03-05 18:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6571 updates
2022-03-05 18:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 135 @ 6571 updates, score 14.178) (writing took 1.6935562500730157 seconds)
2022-03-05 18:41:14 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:41:14 | INFO | train | epoch 135 | loss 1.379 | nll_loss 0.79 | ppl 1.73 | wps 27830.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6571 | lr 0.000390107 | gnorm 0.976 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15558
2022-03-05 18:41:14 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:42:19 | INFO | train_inner | epoch 136:     29 / 49 loss=1.379, nll_loss=0.79, ppl=1.73, wps=27849.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.987, loss_scale=64, train_wall=198, gb_free=21.6, wall=15623
2022-03-05 18:42:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:43:07 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 14.236 | nll_loss 13.962 | ppl 15955.6 | wps 47968.5 | wpb 510.9 | bsz 1 | num_updates 6619 | best_loss 8.288
2022-03-05 18:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6619 updates
2022-03-05 18:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:43:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 136 @ 6619 updates, score 14.236) (writing took 1.6880331479478627 seconds)
2022-03-05 18:43:09 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:43:09 | INFO | train | epoch 136 | loss 1.367 | nll_loss 0.777 | ppl 1.71 | wps 27256.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6619 | lr 0.00038869 | gnorm 0.98 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15673
2022-03-05 18:43:09 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:45:01 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 14.266 | nll_loss 13.996 | ppl 16338.1 | wps 47898.4 | wpb 510.9 | bsz 1 | num_updates 6668 | best_loss 8.288
2022-03-05 18:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6668 updates
2022-03-05 18:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:45:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 137 @ 6668 updates, score 14.266) (writing took 1.7307693508919328 seconds)
2022-03-05 18:45:03 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:45:03 | INFO | train | epoch 137 | loss 1.355 | nll_loss 0.765 | ppl 1.7 | wps 27800.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6668 | lr 0.00038726 | gnorm 0.952 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15787
2022-03-05 18:45:03 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:46:14 | INFO | train_inner | epoch 138:     32 / 49 loss=1.355, nll_loss=0.765, ppl=1.7, wps=27579.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.954, loss_scale=32, train_wall=200, gb_free=21.6, wall=15858
2022-03-05 18:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:46:55 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 14.291 | nll_loss 14.023 | ppl 16652.3 | wps 47994.3 | wpb 510.9 | bsz 1 | num_updates 6717 | best_loss 8.288
2022-03-05 18:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6717 updates
2022-03-05 18:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 138 @ 6717 updates, score 14.291) (writing took 1.701599596068263 seconds)
2022-03-05 18:46:57 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:46:57 | INFO | train | epoch 138 | loss 1.347 | nll_loss 0.757 | ppl 1.69 | wps 27808.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6717 | lr 0.000385845 | gnorm 0.962 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 15901
2022-03-05 18:46:57 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:47:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:48:50 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 14.284 | nll_loss 14.013 | ppl 16531.8 | wps 48040.7 | wpb 510.9 | bsz 1 | num_updates 6765 | best_loss 8.288
2022-03-05 18:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6765 updates
2022-03-05 18:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:48:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 139 @ 6765 updates, score 14.284) (writing took 1.7283526211977005 seconds)
2022-03-05 18:48:51 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:48:51 | INFO | train | epoch 139 | loss 1.334 | nll_loss 0.743 | ppl 1.67 | wps 27241.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6765 | lr 0.000384473 | gnorm 0.938 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16015
2022-03-05 18:48:51 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:48:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:50:09 | INFO | train_inner | epoch 140:     35 / 49 loss=1.333, nll_loss=0.742, ppl=1.67, wps=27585.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.948, loss_scale=32, train_wall=200, gb_free=21.6, wall=16093
2022-03-05 18:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:50:44 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 14.283 | nll_loss 14.015 | ppl 16553.3 | wps 48133.3 | wpb 510.9 | bsz 1 | num_updates 6814 | best_loss 8.288
2022-03-05 18:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6814 updates
2022-03-05 18:50:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:50:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 140 @ 6814 updates, score 14.283) (writing took 1.7122978519182652 seconds)
2022-03-05 18:50:46 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:50:46 | INFO | train | epoch 140 | loss 1.325 | nll_loss 0.733 | ppl 1.66 | wps 27833 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6814 | lr 0.000383088 | gnorm 0.946 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16130
2022-03-05 18:50:46 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:52:38 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 14.307 | nll_loss 14.036 | ppl 16792.2 | wps 47897.4 | wpb 510.9 | bsz 1 | num_updates 6863 | best_loss 8.288
2022-03-05 18:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6863 updates
2022-03-05 18:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 141 @ 6863 updates, score 14.307) (writing took 1.7277836899738759 seconds)
2022-03-05 18:52:40 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:52:40 | INFO | train | epoch 141 | loss 1.318 | nll_loss 0.725 | ppl 1.65 | wps 27838.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6863 | lr 0.000381718 | gnorm 0.947 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 16244
2022-03-05 18:52:40 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:54:04 | INFO | train_inner | epoch 142:     38 / 49 loss=1.314, nll_loss=0.722, ppl=1.65, wps=27605.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.939, loss_scale=32, train_wall=200, gb_free=21.6, wall=16328
2022-03-05 18:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:54:32 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 14.241 | nll_loss 13.966 | ppl 16007 | wps 47855 | wpb 510.9 | bsz 1 | num_updates 6911 | best_loss 8.288
2022-03-05 18:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6911 updates
2022-03-05 18:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 142 @ 6911 updates, score 14.241) (writing took 1.7288757499773055 seconds)
2022-03-05 18:54:34 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:54:34 | INFO | train | epoch 142 | loss 1.305 | nll_loss 0.712 | ppl 1.64 | wps 27250 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6911 | lr 0.00038039 | gnorm 0.924 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16358
2022-03-05 18:54:34 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:56:26 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 14.33 | nll_loss 14.06 | ppl 17077.8 | wps 47903.3 | wpb 510.9 | bsz 1 | num_updates 6960 | best_loss 8.288
2022-03-05 18:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6960 updates
2022-03-05 18:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:56:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 143 @ 6960 updates, score 14.33) (writing took 1.7404000537935644 seconds)
2022-03-05 18:56:28 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:56:28 | INFO | train | epoch 143 | loss 1.298 | nll_loss 0.704 | ppl 1.63 | wps 27823.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6960 | lr 0.000379049 | gnorm 0.93 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16472
2022-03-05 18:56:28 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:57:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:57:59 | INFO | train_inner | epoch 144:     41 / 49 loss=1.295, nll_loss=0.702, ppl=1.63, wps=27585, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.923, loss_scale=32, train_wall=200, gb_free=21.6, wall=16563
2022-03-05 18:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:58:21 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 14.408 | nll_loss 14.144 | ppl 18105.9 | wps 47884.9 | wpb 510.9 | bsz 1 | num_updates 7008 | best_loss 8.288
2022-03-05 18:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7008 updates
2022-03-05 18:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 18:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 144 @ 7008 updates, score 14.408) (writing took 1.7313666988629848 seconds)
2022-03-05 18:58:22 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 18:58:22 | INFO | train | epoch 144 | loss 1.288 | nll_loss 0.695 | ppl 1.62 | wps 27234 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7008 | lr 0.000377749 | gnorm 0.917 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16587
2022-03-05 18:58:23 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 18:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:00:15 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 14.373 | nll_loss 14.103 | ppl 17596 | wps 47889.7 | wpb 510.9 | bsz 1 | num_updates 7057 | best_loss 8.288
2022-03-05 19:00:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7057 updates
2022-03-05 19:00:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 145 @ 7057 updates, score 14.373) (writing took 1.730804902035743 seconds)
2022-03-05 19:00:17 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:00:17 | INFO | train | epoch 145 | loss 1.28 | nll_loss 0.686 | ppl 1.61 | wps 27825.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7057 | lr 0.000376435 | gnorm 0.903 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16701
2022-03-05 19:00:17 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:52 | INFO | train_inner | epoch 146:     43 / 49 loss=1.277, nll_loss=0.683, ppl=1.61, wps=27856.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.901, loss_scale=32, train_wall=198, gb_free=21.6, wall=16796
2022-03-05 19:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:02:09 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 14.433 | nll_loss 14.169 | ppl 18416.8 | wps 47875.9 | wpb 510.9 | bsz 1 | num_updates 7106 | best_loss 8.288
2022-03-05 19:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7106 updates
2022-03-05 19:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 146 @ 7106 updates, score 14.433) (writing took 1.7165235748980194 seconds)
2022-03-05 19:02:11 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:02:11 | INFO | train | epoch 146 | loss 1.271 | nll_loss 0.677 | ppl 1.6 | wps 27827.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7106 | lr 0.000375135 | gnorm 0.901 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16815
2022-03-05 19:02:11 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:02:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:04:03 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 14.5 | nll_loss 14.24 | ppl 19351.1 | wps 47920.8 | wpb 510.9 | bsz 1 | num_updates 7154 | best_loss 8.288
2022-03-05 19:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7154 updates
2022-03-05 19:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 147 @ 7154 updates, score 14.5) (writing took 1.6945553291589022 seconds)
2022-03-05 19:04:05 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:04:05 | INFO | train | epoch 147 | loss 1.263 | nll_loss 0.669 | ppl 1.59 | wps 27255.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7154 | lr 0.000373874 | gnorm 0.921 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 16929
2022-03-05 19:04:05 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:05:47 | INFO | train_inner | epoch 148:     46 / 49 loss=1.26, nll_loss=0.665, ppl=1.59, wps=27589.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.898, loss_scale=32, train_wall=200, gb_free=21.6, wall=17032
2022-03-05 19:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:58 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 14.425 | nll_loss 14.16 | ppl 18306.3 | wps 47501.5 | wpb 510.9 | bsz 1 | num_updates 7203 | best_loss 8.288
2022-03-05 19:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7203 updates
2022-03-05 19:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 148 @ 7203 updates, score 14.425) (writing took 1.711609459016472 seconds)
2022-03-05 19:05:59 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:05:59 | INFO | train | epoch 148 | loss 1.252 | nll_loss 0.658 | ppl 1.58 | wps 27800.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7203 | lr 0.0003726 | gnorm 0.868 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17043
2022-03-05 19:05:59 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:07:52 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 14.499 | nll_loss 14.238 | ppl 19319.7 | wps 47993.1 | wpb 510.9 | bsz 1 | num_updates 7252 | best_loss 8.288
2022-03-05 19:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7252 updates
2022-03-05 19:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 149 @ 7252 updates, score 14.499) (writing took 1.7269528100732714 seconds)
2022-03-05 19:07:54 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:07:54 | INFO | train | epoch 149 | loss 1.245 | nll_loss 0.65 | ppl 1.57 | wps 27835.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7252 | lr 0.000371339 | gnorm 0.881 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 17158
2022-03-05 19:07:54 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:09:42 | INFO | train_inner | epoch 150:     49 / 49 loss=1.244, nll_loss=0.649, ppl=1.57, wps=27572.6, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.891, loss_scale=32, train_wall=199, gb_free=21.6, wall=17266
2022-03-05 19:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:09:46 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 14.53 | nll_loss 14.268 | ppl 19724.2 | wps 48458.4 | wpb 510.9 | bsz 1 | num_updates 7300 | best_loss 8.288
2022-03-05 19:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7300 updates
2022-03-05 19:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 150 @ 7300 updates, score 14.53) (writing took 1.7445891369134188 seconds)
2022-03-05 19:09:48 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:09:48 | INFO | train | epoch 150 | loss 1.24 | nll_loss 0.645 | ppl 1.56 | wps 27244.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7300 | lr 0.000370117 | gnorm 0.896 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17272
2022-03-05 19:09:48 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:11:40 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 14.556 | nll_loss 14.295 | ppl 20105.1 | wps 48042.5 | wpb 510.9 | bsz 1 | num_updates 7349 | best_loss 8.288
2022-03-05 19:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7349 updates
2022-03-05 19:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 151 @ 7349 updates, score 14.556) (writing took 1.7384704661089927 seconds)
2022-03-05 19:11:42 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:11:42 | INFO | train | epoch 151 | loss 1.231 | nll_loss 0.636 | ppl 1.55 | wps 27827.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7349 | lr 0.000368881 | gnorm 0.87 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17386
2022-03-05 19:11:42 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:13:35 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 14.498 | nll_loss 14.234 | ppl 19268.8 | wps 48093.7 | wpb 510.9 | bsz 1 | num_updates 7397 | best_loss 8.288
2022-03-05 19:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7397 updates
2022-03-05 19:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 152 @ 7397 updates, score 14.498) (writing took 1.7256490900181234 seconds)
2022-03-05 19:13:36 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:13:36 | INFO | train | epoch 152 | loss 1.223 | nll_loss 0.628 | ppl 1.55 | wps 27257 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7397 | lr 0.000367682 | gnorm 0.877 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17500
2022-03-05 19:13:36 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:13:43 | INFO | train_inner | epoch 153:      3 / 49 loss=1.226, nll_loss=0.631, ppl=1.55, wps=26864.8, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.875, loss_scale=16, train_wall=200, gb_free=21.6, wall=17507
2022-03-05 19:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:15:29 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 14.525 | nll_loss 14.264 | ppl 19679 | wps 48073.8 | wpb 510.9 | bsz 1 | num_updates 7446 | best_loss 8.288
2022-03-05 19:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7446 updates
2022-03-05 19:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 153 @ 7446 updates, score 14.525) (writing took 1.7111603249795735 seconds)
2022-03-05 19:15:30 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:15:30 | INFO | train | epoch 153 | loss 1.216 | nll_loss 0.62 | ppl 1.54 | wps 27820.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7446 | lr 0.00036647 | gnorm 0.856 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17615
2022-03-05 19:15:30 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:17:23 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 14.567 | nll_loss 14.309 | ppl 20298.5 | wps 47974.2 | wpb 510.9 | bsz 1 | num_updates 7495 | best_loss 8.288
2022-03-05 19:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7495 updates
2022-03-05 19:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 154 @ 7495 updates, score 14.567) (writing took 1.722958608996123 seconds)
2022-03-05 19:17:25 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:17:25 | INFO | train | epoch 154 | loss 1.211 | nll_loss 0.616 | ppl 1.53 | wps 27826.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7495 | lr 0.00036527 | gnorm 0.862 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17729
2022-03-05 19:17:25 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:17:36 | INFO | train_inner | epoch 155:      5 / 49 loss=1.212, nll_loss=0.616, ppl=1.53, wps=27856.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.858, loss_scale=32, train_wall=198, gb_free=21.6, wall=17740
2022-03-05 19:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:19:17 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 14.575 | nll_loss 14.318 | ppl 20418.8 | wps 48052.2 | wpb 510.9 | bsz 1 | num_updates 7544 | best_loss 8.288
2022-03-05 19:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7544 updates
2022-03-05 19:19:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 155 @ 7544 updates, score 14.575) (writing took 1.7307274090126157 seconds)
2022-03-05 19:19:19 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:19:19 | INFO | train | epoch 155 | loss 1.204 | nll_loss 0.608 | ppl 1.52 | wps 27822.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7544 | lr 0.000364082 | gnorm 0.874 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17843
2022-03-05 19:19:19 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:19:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:21:11 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 14.549 | nll_loss 14.292 | ppl 20055.4 | wps 48005.5 | wpb 510.9 | bsz 1 | num_updates 7592 | best_loss 8.288
2022-03-05 19:21:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7592 updates
2022-03-05 19:21:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:21:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 156 @ 7592 updates, score 14.549) (writing took 1.6868799140211195 seconds)
2022-03-05 19:21:13 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:21:13 | INFO | train | epoch 156 | loss 1.194 | nll_loss 0.598 | ppl 1.51 | wps 27252.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7592 | lr 0.000362929 | gnorm 0.846 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17957
2022-03-05 19:21:13 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:21:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:21:31 | INFO | train_inner | epoch 157:      8 / 49 loss=1.198, nll_loss=0.602, ppl=1.52, wps=27592.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.857, loss_scale=16, train_wall=200, gb_free=21.6, wall=17975
2022-03-05 19:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:23:06 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 14.581 | nll_loss 14.32 | ppl 20449.4 | wps 48555 | wpb 510.9 | bsz 1 | num_updates 7641 | best_loss 8.288
2022-03-05 19:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7641 updates
2022-03-05 19:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 157 @ 7641 updates, score 14.581) (writing took 1.7469014150556177 seconds)
2022-03-05 19:23:07 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:23:07 | INFO | train | epoch 157 | loss 1.189 | nll_loss 0.593 | ppl 1.51 | wps 27823.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7641 | lr 0.000361764 | gnorm 0.848 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18071
2022-03-05 19:23:07 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:24:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:25:00 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 14.611 | nll_loss 14.35 | ppl 20884.1 | wps 47920.9 | wpb 510.9 | bsz 1 | num_updates 7690 | best_loss 8.288
2022-03-05 19:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7690 updates
2022-03-05 19:25:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 158 @ 7690 updates, score 14.611) (writing took 1.7268851150292903 seconds)
2022-03-05 19:25:02 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:25:02 | INFO | train | epoch 158 | loss 1.184 | nll_loss 0.587 | ppl 1.5 | wps 27804.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7690 | lr 0.000360609 | gnorm 0.843 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 18186
2022-03-05 19:25:02 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:25:24 | INFO | train_inner | epoch 159:     10 / 49 loss=1.185, nll_loss=0.589, ppl=1.5, wps=27847.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.844, loss_scale=32, train_wall=198, gb_free=21.6, wall=18208
2022-03-05 19:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:26:54 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 14.568 | nll_loss 14.312 | ppl 20334 | wps 48026.5 | wpb 510.9 | bsz 1 | num_updates 7739 | best_loss 8.288
2022-03-05 19:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7739 updates
2022-03-05 19:26:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 159 @ 7739 updates, score 14.568) (writing took 1.6790931369177997 seconds)
2022-03-05 19:26:56 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:26:56 | INFO | train | epoch 159 | loss 1.175 | nll_loss 0.579 | ppl 1.49 | wps 27828.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7739 | lr 0.000359466 | gnorm 0.829 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 18300
2022-03-05 19:26:56 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:28:48 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 14.617 | nll_loss 14.365 | ppl 21105.2 | wps 48024.1 | wpb 510.9 | bsz 1 | num_updates 7788 | best_loss 8.288
2022-03-05 19:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7788 updates
2022-03-05 19:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 160 @ 7788 updates, score 14.617) (writing took 1.7210352751426399 seconds)
2022-03-05 19:28:50 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:28:50 | INFO | train | epoch 160 | loss 1.169 | nll_loss 0.572 | ppl 1.49 | wps 27809.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7788 | lr 0.000358333 | gnorm 0.804 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 18414
2022-03-05 19:28:50 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:29:17 | INFO | train_inner | epoch 161:     12 / 49 loss=1.171, nll_loss=0.575, ppl=1.49, wps=27853.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.813, loss_scale=32, train_wall=198, gb_free=21.6, wall=18441
2022-03-05 19:29:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:30:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:30:43 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 14.655 | nll_loss 14.404 | ppl 21679.1 | wps 48013.2 | wpb 510.9 | bsz 1 | num_updates 7835 | best_loss 8.288
2022-03-05 19:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7835 updates
2022-03-05 19:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:30:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 161 @ 7835 updates, score 14.655) (writing took 1.7113601970486343 seconds)
2022-03-05 19:30:44 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:30:44 | INFO | train | epoch 161 | loss 1.165 | nll_loss 0.569 | ppl 1.48 | wps 26690.7 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 7835 | lr 0.000357257 | gnorm 0.81 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18528
2022-03-05 19:30:44 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:30:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:32:37 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 14.664 | nll_loss 14.41 | ppl 21776.4 | wps 48047.1 | wpb 510.9 | bsz 1 | num_updates 7884 | best_loss 8.288
2022-03-05 19:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7884 updates
2022-03-05 19:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 162 @ 7884 updates, score 14.664) (writing took 1.6983638028614223 seconds)
2022-03-05 19:32:39 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:32:39 | INFO | train | epoch 162 | loss 1.159 | nll_loss 0.563 | ppl 1.48 | wps 27803.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7884 | lr 0.000356145 | gnorm 0.818 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18643
2022-03-05 19:32:39 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:33:14 | INFO | train_inner | epoch 163:     16 / 49 loss=1.161, nll_loss=0.564, ppl=1.48, wps=27325.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.821, loss_scale=16, train_wall=202, gb_free=21.6, wall=18678
2022-03-05 19:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:34:31 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 14.643 | nll_loss 14.389 | ppl 21454.1 | wps 47708 | wpb 510.9 | bsz 1 | num_updates 7933 | best_loss 8.288
2022-03-05 19:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7933 updates
2022-03-05 19:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 163 @ 7933 updates, score 14.643) (writing took 1.7104904048610479 seconds)
2022-03-05 19:34:33 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:34:33 | INFO | train | epoch 163 | loss 1.155 | nll_loss 0.559 | ppl 1.47 | wps 27798.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7933 | lr 0.000355043 | gnorm 0.823 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18757
2022-03-05 19:34:33 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:36:25 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 14.687 | nll_loss 14.44 | ppl 22229 | wps 48090.3 | wpb 510.9 | bsz 1 | num_updates 7982 | best_loss 8.288
2022-03-05 19:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7982 updates
2022-03-05 19:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 164 @ 7982 updates, score 14.687) (writing took 1.7302900468930602 seconds)
2022-03-05 19:36:27 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:36:27 | INFO | train | epoch 164 | loss 1.148 | nll_loss 0.552 | ppl 1.47 | wps 27815.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7982 | lr 0.000353952 | gnorm 0.82 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 18871
2022-03-05 19:36:27 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:37:09 | INFO | train_inner | epoch 165:     19 / 49 loss=1.149, nll_loss=0.552, ppl=1.47, wps=27582.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.816, loss_scale=16, train_wall=200, gb_free=21.6, wall=18914
2022-03-05 19:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:38:20 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 14.668 | nll_loss 14.414 | ppl 21836.3 | wps 47912.3 | wpb 510.9 | bsz 1 | num_updates 8030 | best_loss 8.288
2022-03-05 19:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8030 updates
2022-03-05 19:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 165 @ 8030 updates, score 14.668) (writing took 1.6970982721541077 seconds)
2022-03-05 19:38:21 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:38:21 | INFO | train | epoch 165 | loss 1.141 | nll_loss 0.545 | ppl 1.46 | wps 27254 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8030 | lr 0.000352892 | gnorm 0.8 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18985
2022-03-05 19:38:21 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:40:14 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 14.775 | nll_loss 14.529 | ppl 23634.7 | wps 47902.1 | wpb 510.9 | bsz 1 | num_updates 8079 | best_loss 8.288
2022-03-05 19:40:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8079 updates
2022-03-05 19:40:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 166 @ 8079 updates, score 14.775) (writing took 1.7225728570483625 seconds)
2022-03-05 19:40:16 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:40:16 | INFO | train | epoch 166 | loss 1.136 | nll_loss 0.54 | ppl 1.45 | wps 27789.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8079 | lr 0.000351821 | gnorm 0.792 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19100
2022-03-05 19:40:16 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:41:02 | INFO | train_inner | epoch 167:     21 / 49 loss=1.137, nll_loss=0.54, ppl=1.45, wps=27838.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.788, loss_scale=16, train_wall=198, gb_free=21.6, wall=19147
2022-03-05 19:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:42:08 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 14.675 | nll_loss 14.429 | ppl 22060.8 | wps 48054 | wpb 510.9 | bsz 1 | num_updates 8128 | best_loss 8.288
2022-03-05 19:42:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8128 updates
2022-03-05 19:42:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 167 @ 8128 updates, score 14.675) (writing took 1.7023293590173125 seconds)
2022-03-05 19:42:10 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:42:10 | INFO | train | epoch 167 | loss 1.132 | nll_loss 0.536 | ppl 1.45 | wps 27845.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8128 | lr 0.000350758 | gnorm 0.79 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19214
2022-03-05 19:42:10 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:44:02 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 14.628 | nll_loss 14.374 | ppl 21235.1 | wps 47912.8 | wpb 510.9 | bsz 1 | num_updates 8177 | best_loss 8.288
2022-03-05 19:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8177 updates
2022-03-05 19:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:44:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 168 @ 8177 updates, score 14.628) (writing took 1.7490751259028912 seconds)
2022-03-05 19:44:04 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:44:04 | INFO | train | epoch 168 | loss 1.127 | nll_loss 0.531 | ppl 1.44 | wps 27788.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8177 | lr 0.000349706 | gnorm 0.783 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19328
2022-03-05 19:44:04 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:44:55 | INFO | train_inner | epoch 169:     23 / 49 loss=1.127, nll_loss=0.531, ppl=1.45, wps=27853.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.789, loss_scale=32, train_wall=198, gb_free=21.6, wall=19379
2022-03-05 19:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:45:57 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 14.747 | nll_loss 14.499 | ppl 23153.2 | wps 47884.1 | wpb 510.9 | bsz 1 | num_updates 8226 | best_loss 8.288
2022-03-05 19:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8226 updates
2022-03-05 19:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:45:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:45:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 169 @ 8226 updates, score 14.747) (writing took 1.716607596958056 seconds)
2022-03-05 19:45:58 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:45:58 | INFO | train | epoch 169 | loss 1.121 | nll_loss 0.525 | ppl 1.44 | wps 27826 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8226 | lr 0.000348663 | gnorm 0.776 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19443
2022-03-05 19:45:58 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:45:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:47:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:47:51 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 14.748 | nll_loss 14.496 | ppl 23112.8 | wps 48108.3 | wpb 510.9 | bsz 1 | num_updates 8274 | best_loss 8.288
2022-03-05 19:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8274 updates
2022-03-05 19:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 170 @ 8274 updates, score 14.748) (writing took 1.70752312685363 seconds)
2022-03-05 19:47:53 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:47:53 | INFO | train | epoch 170 | loss 1.116 | nll_loss 0.52 | ppl 1.43 | wps 27259.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8274 | lr 0.00034765 | gnorm 0.792 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19557
2022-03-05 19:47:53 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:48:51 | INFO | train_inner | epoch 171:     26 / 49 loss=1.116, nll_loss=0.52, ppl=1.43, wps=27586.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.785, loss_scale=32, train_wall=200, gb_free=21.6, wall=19615
2022-03-05 19:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:49:45 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 14.66 | nll_loss 14.41 | ppl 21775.6 | wps 47888.6 | wpb 510.9 | bsz 1 | num_updates 8323 | best_loss 8.288
2022-03-05 19:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8323 updates
2022-03-05 19:49:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 171 @ 8323 updates, score 14.66) (writing took 1.7441102089360356 seconds)
2022-03-05 19:49:47 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:49:47 | INFO | train | epoch 171 | loss 1.111 | nll_loss 0.516 | ppl 1.43 | wps 27806.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8323 | lr 0.000346625 | gnorm 0.778 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 19671
2022-03-05 19:49:47 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:51:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:51:39 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 14.678 | nll_loss 14.428 | ppl 22042.2 | wps 47914.3 | wpb 510.9 | bsz 1 | num_updates 8371 | best_loss 8.288
2022-03-05 19:51:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8371 updates
2022-03-05 19:51:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:51:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 172 @ 8371 updates, score 14.678) (writing took 1.7175414718221873 seconds)
2022-03-05 19:51:41 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:51:41 | INFO | train | epoch 172 | loss 1.106 | nll_loss 0.51 | ppl 1.42 | wps 27235.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8371 | lr 0.00034563 | gnorm 0.781 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19785
2022-03-05 19:51:41 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:51:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:52:46 | INFO | train_inner | epoch 173:     29 / 49 loss=1.105, nll_loss=0.51, ppl=1.42, wps=27580.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.772, loss_scale=16, train_wall=200, gb_free=21.6, wall=19850
2022-03-05 19:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:34 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 14.707 | nll_loss 14.461 | ppl 22553.3 | wps 47647.3 | wpb 510.9 | bsz 1 | num_updates 8420 | best_loss 8.288
2022-03-05 19:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8420 updates
2022-03-05 19:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 173 @ 8420 updates, score 14.707) (writing took 1.7002272550016642 seconds)
2022-03-05 19:53:35 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:53:35 | INFO | train | epoch 173 | loss 1.102 | nll_loss 0.506 | ppl 1.42 | wps 27807.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8420 | lr 0.000344623 | gnorm 0.767 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19900
2022-03-05 19:53:36 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:55:28 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 14.685 | nll_loss 14.439 | ppl 22211.4 | wps 47922.1 | wpb 510.9 | bsz 1 | num_updates 8469 | best_loss 8.288
2022-03-05 19:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8469 updates
2022-03-05 19:55:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:55:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:55:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 174 @ 8469 updates, score 14.685) (writing took 1.7478913650847971 seconds)
2022-03-05 19:55:30 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:55:30 | INFO | train | epoch 174 | loss 1.097 | nll_loss 0.501 | ppl 1.42 | wps 27818.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8469 | lr 0.000343624 | gnorm 0.745 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20014
2022-03-05 19:55:30 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:55:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:56:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:56:41 | INFO | train_inner | epoch 175:     32 / 49 loss=1.097, nll_loss=0.502, ppl=1.42, wps=27589.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.755, loss_scale=16, train_wall=200, gb_free=21.6, wall=20085
2022-03-05 19:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:57:22 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 14.732 | nll_loss 14.485 | ppl 22930.1 | wps 47369.4 | wpb 510.9 | bsz 1 | num_updates 8517 | best_loss 8.288
2022-03-05 19:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8517 updates
2022-03-05 19:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 175 @ 8517 updates, score 14.732) (writing took 1.7266624739859253 seconds)
2022-03-05 19:57:24 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 19:57:24 | INFO | train | epoch 175 | loss 1.094 | nll_loss 0.498 | ppl 1.41 | wps 27252.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8517 | lr 0.000342655 | gnorm 0.758 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20128
2022-03-05 19:57:24 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 19:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:59:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:59:17 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 14.73 | nll_loss 14.488 | ppl 22983.3 | wps 47946.8 | wpb 510.9 | bsz 1 | num_updates 8566 | best_loss 8.288
2022-03-05 19:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8566 updates
2022-03-05 19:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 19:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 176 @ 8566 updates, score 14.73) (writing took 1.695411467924714 seconds)
2022-03-05 19:59:18 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 19:59:18 | INFO | train | epoch 176 | loss 1.089 | nll_loss 0.493 | ppl 1.41 | wps 27808.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8566 | lr 0.000341673 | gnorm 0.759 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20242
2022-03-05 19:59:18 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 19:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:00:34 | INFO | train_inner | epoch 177:     34 / 49 loss=1.088, nll_loss=0.492, ppl=1.41, wps=27835.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.752, loss_scale=16, train_wall=198, gb_free=21.6, wall=20318
2022-03-05 20:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:01:11 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 14.662 | nll_loss 14.415 | ppl 21848.8 | wps 47953.6 | wpb 510.9 | bsz 1 | num_updates 8615 | best_loss 8.288
2022-03-05 20:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8615 updates
2022-03-05 20:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:01:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 177 @ 8615 updates, score 14.662) (writing took 1.7115381329786032 seconds)
2022-03-05 20:01:13 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:01:13 | INFO | train | epoch 177 | loss 1.084 | nll_loss 0.489 | ppl 1.4 | wps 27803.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8615 | lr 0.0003407 | gnorm 0.745 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 20357
2022-03-05 20:01:13 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:03:05 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 14.719 | nll_loss 14.471 | ppl 22716.2 | wps 47821.2 | wpb 510.9 | bsz 1 | num_updates 8663 | best_loss 8.288
2022-03-05 20:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8663 updates
2022-03-05 20:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 178 @ 8663 updates, score 14.719) (writing took 1.7269568229094148 seconds)
2022-03-05 20:03:07 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:03:07 | INFO | train | epoch 178 | loss 1.078 | nll_loss 0.483 | ppl 1.4 | wps 27211.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8663 | lr 0.000339755 | gnorm 0.737 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20471
2022-03-05 20:03:07 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:04:29 | INFO | train_inner | epoch 179:     37 / 49 loss=1.079, nll_loss=0.484, ppl=1.4, wps=27559.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.742, loss_scale=16, train_wall=200, gb_free=21.6, wall=20553
2022-03-05 20:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:05:00 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 14.756 | nll_loss 14.512 | ppl 23358.5 | wps 47899.8 | wpb 510.9 | bsz 1 | num_updates 8712 | best_loss 8.288
2022-03-05 20:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8712 updates
2022-03-05 20:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 179 @ 8712 updates, score 14.756) (writing took 1.725883750943467 seconds)
2022-03-05 20:05:01 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:05:01 | INFO | train | epoch 179 | loss 1.076 | nll_loss 0.481 | ppl 1.4 | wps 27793 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8712 | lr 0.000338798 | gnorm 0.74 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20585
2022-03-05 20:05:01 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:06:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:06:54 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 14.74 | nll_loss 14.496 | ppl 23099.3 | wps 47859.5 | wpb 510.9 | bsz 1 | num_updates 8761 | best_loss 8.288
2022-03-05 20:06:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8761 updates
2022-03-05 20:06:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 180 @ 8761 updates, score 14.74) (writing took 1.7077872690279037 seconds)
2022-03-05 20:06:56 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:06:56 | INFO | train | epoch 180 | loss 1.072 | nll_loss 0.477 | ppl 1.39 | wps 27800.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8761 | lr 0.000337849 | gnorm 0.735 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20700
2022-03-05 20:06:56 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:08:22 | INFO | train_inner | epoch 181:     39 / 49 loss=1.07, nll_loss=0.476, ppl=1.39, wps=27837.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.729, loss_scale=32, train_wall=198, gb_free=21.6, wall=20786
2022-03-05 20:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:08:48 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 14.715 | nll_loss 14.475 | ppl 22773 | wps 47482.3 | wpb 510.9 | bsz 1 | num_updates 8810 | best_loss 8.288
2022-03-05 20:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8810 updates
2022-03-05 20:08:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:08:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 181 @ 8810 updates, score 14.715) (writing took 1.7050119871273637 seconds)
2022-03-05 20:08:50 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:08:50 | INFO | train | epoch 181 | loss 1.067 | nll_loss 0.473 | ppl 1.39 | wps 27806.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8810 | lr 0.000336909 | gnorm 0.726 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 20814
2022-03-05 20:08:50 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:09:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:10:42 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 14.755 | nll_loss 14.516 | ppl 23434.8 | wps 48030.6 | wpb 510.9 | bsz 1 | num_updates 8858 | best_loss 8.288
2022-03-05 20:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8858 updates
2022-03-05 20:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 182 @ 8858 updates, score 14.755) (writing took 1.7073101468849927 seconds)
2022-03-05 20:10:44 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:10:44 | INFO | train | epoch 182 | loss 1.063 | nll_loss 0.469 | ppl 1.38 | wps 27268.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8858 | lr 0.000335994 | gnorm 0.729 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20928
2022-03-05 20:10:44 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:18 | INFO | train_inner | epoch 183:     42 / 49 loss=1.062, nll_loss=0.468, ppl=1.38, wps=27586.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.727, loss_scale=16, train_wall=200, gb_free=21.6, wall=21022
2022-03-05 20:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:37 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 14.672 | nll_loss 14.426 | ppl 22017 | wps 47954.7 | wpb 510.9 | bsz 1 | num_updates 8907 | best_loss 8.288
2022-03-05 20:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8907 updates
2022-03-05 20:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 183 @ 8907 updates, score 14.672) (writing took 1.7360219100955874 seconds)
2022-03-05 20:12:38 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:12:38 | INFO | train | epoch 183 | loss 1.059 | nll_loss 0.465 | ppl 1.38 | wps 27796.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8907 | lr 0.000335069 | gnorm 0.727 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21042
2022-03-05 20:12:38 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:31 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 14.859 | nll_loss 14.625 | ppl 25259.2 | wps 47875.2 | wpb 510.9 | bsz 1 | num_updates 8956 | best_loss 8.288
2022-03-05 20:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8956 updates
2022-03-05 20:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 184 @ 8956 updates, score 14.859) (writing took 1.7452985511627048 seconds)
2022-03-05 20:14:33 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:14:33 | INFO | train | epoch 184 | loss 1.055 | nll_loss 0.461 | ppl 1.38 | wps 27817.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8956 | lr 0.000334151 | gnorm 0.728 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21157
2022-03-05 20:14:33 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:11 | INFO | train_inner | epoch 185:     44 / 49 loss=1.054, nll_loss=0.46, ppl=1.38, wps=27838.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.719, loss_scale=32, train_wall=198, gb_free=21.6, wall=21255
2022-03-05 20:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:25 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 14.722 | nll_loss 14.486 | ppl 22944.4 | wps 48100.5 | wpb 510.9 | bsz 1 | num_updates 9005 | best_loss 8.288
2022-03-05 20:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9005 updates
2022-03-05 20:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 185 @ 9005 updates, score 14.722) (writing took 1.7067744941450655 seconds)
2022-03-05 20:16:27 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:16:27 | INFO | train | epoch 185 | loss 1.05 | nll_loss 0.457 | ppl 1.37 | wps 27806.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9005 | lr 0.000333241 | gnorm 0.703 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 21271
2022-03-05 20:16:27 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:18:19 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 14.755 | nll_loss 14.517 | ppl 23440 | wps 47992.3 | wpb 510.9 | bsz 1 | num_updates 9053 | best_loss 8.288
2022-03-05 20:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9053 updates
2022-03-05 20:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:18:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:18:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 186 @ 9053 updates, score 14.755) (writing took 1.744870175840333 seconds)
2022-03-05 20:18:21 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:18:21 | INFO | train | epoch 186 | loss 1.049 | nll_loss 0.455 | ppl 1.37 | wps 27231.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9053 | lr 0.000332356 | gnorm 0.717 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21385
2022-03-05 20:18:21 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:20:06 | INFO | train_inner | epoch 187:     47 / 49 loss=1.047, nll_loss=0.454, ppl=1.37, wps=27588.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.716, loss_scale=16, train_wall=200, gb_free=21.6, wall=21490
2022-03-05 20:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:20:14 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 14.672 | nll_loss 14.426 | ppl 22015.3 | wps 47768.3 | wpb 510.9 | bsz 1 | num_updates 9102 | best_loss 8.288
2022-03-05 20:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9102 updates
2022-03-05 20:20:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 187 @ 9102 updates, score 14.672) (writing took 1.7649479759857059 seconds)
2022-03-05 20:20:15 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:20:15 | INFO | train | epoch 187 | loss 1.044 | nll_loss 0.451 | ppl 1.37 | wps 27812.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9102 | lr 0.00033146 | gnorm 0.714 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21500
2022-03-05 20:20:15 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:22:08 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 14.803 | nll_loss 14.565 | ppl 24245.4 | wps 48123.7 | wpb 510.9 | bsz 1 | num_updates 9151 | best_loss 8.288
2022-03-05 20:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9151 updates
2022-03-05 20:22:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 188 @ 9151 updates, score 14.803) (writing took 1.7053586759138852 seconds)
2022-03-05 20:22:10 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:22:10 | INFO | train | epoch 188 | loss 1.04 | nll_loss 0.447 | ppl 1.36 | wps 27821.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9151 | lr 0.000330572 | gnorm 0.706 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21614
2022-03-05 20:22:10 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:24:02 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 14.799 | nll_loss 14.565 | ppl 24239.3 | wps 47859.6 | wpb 510.9 | bsz 1 | num_updates 9199 | best_loss 8.288
2022-03-05 20:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9199 updates
2022-03-05 20:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 189 @ 9199 updates, score 14.799) (writing took 1.7207466170657426 seconds)
2022-03-05 20:24:04 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:24:04 | INFO | train | epoch 189 | loss 1.037 | nll_loss 0.444 | ppl 1.36 | wps 27208.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9199 | lr 0.000329708 | gnorm 0.699 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21728
2022-03-05 20:24:04 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:24:06 | INFO | train_inner | epoch 190:      1 / 49 loss=1.039, nll_loss=0.446, ppl=1.36, wps=26811.3, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.704, loss_scale=16, train_wall=199, gb_free=21.6, wall=21730
2022-03-05 20:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:25:57 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 14.708 | nll_loss 14.468 | ppl 22657.8 | wps 47994.2 | wpb 510.9 | bsz 1 | num_updates 9248 | best_loss 8.288
2022-03-05 20:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9248 updates
2022-03-05 20:25:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 190 @ 9248 updates, score 14.708) (writing took 1.7062702730763704 seconds)
2022-03-05 20:25:58 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:25:58 | INFO | train | epoch 190 | loss 1.034 | nll_loss 0.442 | ppl 1.36 | wps 27811.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9248 | lr 0.000328834 | gnorm 0.703 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21842
2022-03-05 20:25:58 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:27:51 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 14.734 | nll_loss 14.494 | ppl 23073.4 | wps 48076.2 | wpb 510.9 | bsz 1 | num_updates 9297 | best_loss 8.288
2022-03-05 20:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9297 updates
2022-03-05 20:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 191 @ 9297 updates, score 14.734) (writing took 1.7113194100093096 seconds)
2022-03-05 20:27:53 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:27:53 | INFO | train | epoch 191 | loss 1.03 | nll_loss 0.437 | ppl 1.35 | wps 27797.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9297 | lr 0.000327966 | gnorm 0.704 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21957
2022-03-05 20:27:53 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:27:59 | INFO | train_inner | epoch 192:      3 / 49 loss=1.032, nll_loss=0.439, ppl=1.36, wps=27836.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.703, loss_scale=16, train_wall=198, gb_free=21.6, wall=21964
2022-03-05 20:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:45 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 14.775 | nll_loss 14.541 | ppl 23837.1 | wps 48010.5 | wpb 510.9 | bsz 1 | num_updates 9346 | best_loss 8.288
2022-03-05 20:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9346 updates
2022-03-05 20:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 192 @ 9346 updates, score 14.775) (writing took 1.7261948140803725 seconds)
2022-03-05 20:29:47 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:29:47 | INFO | train | epoch 192 | loss 1.026 | nll_loss 0.434 | ppl 1.35 | wps 27785 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9346 | lr 0.000327105 | gnorm 0.691 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22071
2022-03-05 20:29:47 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:31:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:40 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 14.856 | nll_loss 14.622 | ppl 25221.5 | wps 48011.2 | wpb 510.9 | bsz 1 | num_updates 9394 | best_loss 8.288
2022-03-05 20:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9394 updates
2022-03-05 20:31:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 193 @ 9394 updates, score 14.856) (writing took 1.7510009629186243 seconds)
2022-03-05 20:31:41 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:31:41 | INFO | train | epoch 193 | loss 1.023 | nll_loss 0.431 | ppl 1.35 | wps 27222.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9394 | lr 0.000326268 | gnorm 0.691 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22185
2022-03-05 20:31:41 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:31:55 | INFO | train_inner | epoch 194:      6 / 49 loss=1.024, nll_loss=0.431, ppl=1.35, wps=27554.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.69, loss_scale=16, train_wall=200, gb_free=21.6, wall=22199
2022-03-05 20:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:34 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 14.826 | nll_loss 14.594 | ppl 24731.3 | wps 47805.5 | wpb 510.9 | bsz 1 | num_updates 9443 | best_loss 8.288
2022-03-05 20:33:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9443 updates
2022-03-05 20:33:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 194 @ 9443 updates, score 14.826) (writing took 1.7301913101691753 seconds)
2022-03-05 20:33:36 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:33:36 | INFO | train | epoch 194 | loss 1.019 | nll_loss 0.427 | ppl 1.34 | wps 27802.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9443 | lr 0.000325421 | gnorm 0.686 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22300
2022-03-05 20:33:36 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:28 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 14.766 | nll_loss 14.53 | ppl 23659.6 | wps 47938.8 | wpb 510.9 | bsz 1 | num_updates 9492 | best_loss 8.288
2022-03-05 20:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9492 updates
2022-03-05 20:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 195 @ 9492 updates, score 14.766) (writing took 1.7474558879621327 seconds)
2022-03-05 20:35:30 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:35:30 | INFO | train | epoch 195 | loss 1.017 | nll_loss 0.425 | ppl 1.34 | wps 27775.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9492 | lr 0.00032458 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22414
2022-03-05 20:35:30 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:35:48 | INFO | train_inner | epoch 196:      8 / 49 loss=1.017, nll_loss=0.425, ppl=1.34, wps=27830.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.681, loss_scale=16, train_wall=198, gb_free=21.6, wall=22432
2022-03-05 20:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:23 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 14.677 | nll_loss 14.44 | ppl 22221.7 | wps 48095.5 | wpb 510.9 | bsz 1 | num_updates 9541 | best_loss 8.288
2022-03-05 20:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9541 updates
2022-03-05 20:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 196 @ 9541 updates, score 14.677) (writing took 1.7085466419812292 seconds)
2022-03-05 20:37:24 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:37:24 | INFO | train | epoch 196 | loss 1.014 | nll_loss 0.422 | ppl 1.34 | wps 27813.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9541 | lr 0.000323745 | gnorm 0.687 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22528
2022-03-05 20:37:24 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:39:17 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 14.762 | nll_loss 14.528 | ppl 23627.7 | wps 48048.5 | wpb 510.9 | bsz 1 | num_updates 9590 | best_loss 8.288
2022-03-05 20:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9590 updates
2022-03-05 20:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 197 @ 9590 updates, score 14.762) (writing took 1.8291642870754004 seconds)
2022-03-05 20:39:19 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:39:19 | INFO | train | epoch 197 | loss 1.01 | nll_loss 0.419 | ppl 1.34 | wps 27801.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9590 | lr 0.000322917 | gnorm 0.664 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22643
2022-03-05 20:39:19 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:41 | INFO | train_inner | epoch 198:     10 / 49 loss=1.011, nll_loss=0.42, ppl=1.34, wps=27836.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.673, loss_scale=32, train_wall=198, gb_free=21.6, wall=22665
2022-03-05 20:39:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:41:11 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 14.826 | nll_loss 14.597 | ppl 24782.9 | wps 47758.1 | wpb 510.9 | bsz 1 | num_updates 9638 | best_loss 8.288
2022-03-05 20:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9638 updates
2022-03-05 20:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 198 @ 9638 updates, score 14.826) (writing took 1.7175290249288082 seconds)
2022-03-05 20:41:13 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:41:13 | INFO | train | epoch 198 | loss 1.006 | nll_loss 0.415 | ppl 1.33 | wps 27237.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9638 | lr 0.000322112 | gnorm 0.671 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22757
2022-03-05 20:41:13 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:43:06 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 14.789 | nll_loss 14.555 | ppl 24068.9 | wps 47932.2 | wpb 510.9 | bsz 1 | num_updates 9687 | best_loss 8.288
2022-03-05 20:43:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9687 updates
2022-03-05 20:43:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:43:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 199 @ 9687 updates, score 14.789) (writing took 1.8082488048821688 seconds)
2022-03-05 20:43:07 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:43:07 | INFO | train | epoch 199 | loss 1.003 | nll_loss 0.413 | ppl 1.33 | wps 27759.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9687 | lr 0.000321296 | gnorm 0.667 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22872
2022-03-05 20:43:07 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:43:36 | INFO | train_inner | epoch 200:     13 / 49 loss=1.004, nll_loss=0.413, ppl=1.33, wps=27557.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.671, loss_scale=16, train_wall=200, gb_free=21.6, wall=22901
2022-03-05 20:44:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:45:00 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 14.829 | nll_loss 14.598 | ppl 24803.2 | wps 47826.2 | wpb 510.9 | bsz 1 | num_updates 9736 | best_loss 8.288
2022-03-05 20:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9736 updates
2022-03-05 20:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 200 @ 9736 updates, score 14.829) (writing took 1.6996037641074508 seconds)
2022-03-05 20:45:02 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:45:02 | INFO | train | epoch 200 | loss 1.001 | nll_loss 0.41 | ppl 1.33 | wps 27830.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9736 | lr 0.000320486 | gnorm 0.662 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22986
2022-03-05 20:45:02 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:45:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:46:54 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 14.818 | nll_loss 14.589 | ppl 24644.7 | wps 47791.4 | wpb 510.9 | bsz 1 | num_updates 9785 | best_loss 8.288
2022-03-05 20:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9785 updates
2022-03-05 20:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 201 @ 9785 updates, score 14.818) (writing took 1.7435741978697479 seconds)
2022-03-05 20:46:56 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:46:56 | INFO | train | epoch 201 | loss 0.998 | nll_loss 0.407 | ppl 1.33 | wps 27771.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9785 | lr 0.000319683 | gnorm 0.668 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23100
2022-03-05 20:46:56 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:47:30 | INFO | train_inner | epoch 202:     15 / 49 loss=0.999, nll_loss=0.408, ppl=1.33, wps=27834.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.665, loss_scale=32, train_wall=198, gb_free=21.6, wall=23134
2022-03-05 20:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:48:49 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 14.871 | nll_loss 14.64 | ppl 25530.6 | wps 48026.4 | wpb 510.9 | bsz 1 | num_updates 9834 | best_loss 8.288
2022-03-05 20:48:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9834 updates
2022-03-05 20:48:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:48:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:48:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 202 @ 9834 updates, score 14.871) (writing took 1.7596580050885677 seconds)
2022-03-05 20:48:50 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:48:50 | INFO | train | epoch 202 | loss 0.996 | nll_loss 0.406 | ppl 1.32 | wps 27800.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9834 | lr 0.000318886 | gnorm 0.662 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23214
2022-03-05 20:48:50 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:50:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:50:43 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 14.722 | nll_loss 14.49 | ppl 23017.8 | wps 47871.2 | wpb 510.9 | bsz 1 | num_updates 9882 | best_loss 8.288
2022-03-05 20:50:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9882 updates
2022-03-05 20:50:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:50:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:50:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 203 @ 9882 updates, score 14.722) (writing took 1.7095619190949947 seconds)
2022-03-05 20:50:45 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:50:45 | INFO | train | epoch 203 | loss 0.992 | nll_loss 0.402 | ppl 1.32 | wps 27244.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9882 | lr 0.00031811 | gnorm 0.658 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23329
2022-03-05 20:50:45 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:51:25 | INFO | train_inner | epoch 204:     18 / 49 loss=0.992, nll_loss=0.402, ppl=1.32, wps=27571.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.66, loss_scale=16, train_wall=200, gb_free=21.6, wall=23369
2022-03-05 20:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:52:37 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 14.693 | nll_loss 14.456 | ppl 22482.1 | wps 47980.3 | wpb 510.9 | bsz 1 | num_updates 9931 | best_loss 8.288
2022-03-05 20:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9931 updates
2022-03-05 20:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:52:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 204 @ 9931 updates, score 14.693) (writing took 1.734586575999856 seconds)
2022-03-05 20:52:39 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:52:39 | INFO | train | epoch 204 | loss 0.99 | nll_loss 0.401 | ppl 1.32 | wps 27809.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9931 | lr 0.000317324 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23443
2022-03-05 20:52:39 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:52:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:54:32 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 14.716 | nll_loss 14.481 | ppl 22866.7 | wps 47961 | wpb 510.9 | bsz 1 | num_updates 9980 | best_loss 8.288
2022-03-05 20:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9980 updates
2022-03-05 20:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 205 @ 9980 updates, score 14.716) (writing took 1.7230515850242227 seconds)
2022-03-05 20:54:33 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:54:33 | INFO | train | epoch 205 | loss 0.985 | nll_loss 0.395 | ppl 1.32 | wps 27791.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9980 | lr 0.000316544 | gnorm 0.655 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23557
2022-03-05 20:54:33 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:55:18 | INFO | train_inner | epoch 206:     20 / 49 loss=0.986, nll_loss=0.397, ppl=1.32, wps=27838.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.664, loss_scale=32, train_wall=198, gb_free=21.6, wall=23602
2022-03-05 20:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:56:26 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 14.74 | nll_loss 14.508 | ppl 23301 | wps 47868.2 | wpb 510.9 | bsz 1 | num_updates 10029 | best_loss 8.288
2022-03-05 20:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10029 updates
2022-03-05 20:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:56:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 206 @ 10029 updates, score 14.74) (writing took 1.6629678141325712 seconds)
2022-03-05 20:56:28 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:56:28 | INFO | train | epoch 206 | loss 0.983 | nll_loss 0.393 | ppl 1.31 | wps 27816 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10029 | lr 0.00031577 | gnorm 0.65 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23672
2022-03-05 20:56:28 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:58:20 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 14.732 | nll_loss 14.501 | ppl 23184.5 | wps 48085.6 | wpb 510.9 | bsz 1 | num_updates 10077 | best_loss 8.288
2022-03-05 20:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10077 updates
2022-03-05 20:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 20:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 207 @ 10077 updates, score 14.732) (writing took 1.7354859279002994 seconds)
2022-03-05 20:58:22 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 20:58:22 | INFO | train | epoch 207 | loss 0.981 | nll_loss 0.392 | ppl 1.31 | wps 27216 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10077 | lr 0.000315017 | gnorm 0.66 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23786
2022-03-05 20:58:22 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 20:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:59:13 | INFO | train_inner | epoch 208:     23 / 49 loss=0.98, nll_loss=0.391, ppl=1.31, wps=27575.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.655, loss_scale=16, train_wall=200, gb_free=21.6, wall=23837
2022-03-05 21:00:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:00:14 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 14.723 | nll_loss 14.495 | ppl 23085.7 | wps 48066.5 | wpb 510.9 | bsz 1 | num_updates 10126 | best_loss 8.288
2022-03-05 21:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10126 updates
2022-03-05 21:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:00:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 208 @ 10126 updates, score 14.723) (writing took 1.73202615394257 seconds)
2022-03-05 21:00:16 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:00:16 | INFO | train | epoch 208 | loss 0.978 | nll_loss 0.389 | ppl 1.31 | wps 27822.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10126 | lr 0.000314254 | gnorm 0.645 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23900
2022-03-05 21:00:16 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:02:09 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 14.739 | nll_loss 14.51 | ppl 23329.4 | wps 47987.5 | wpb 510.9 | bsz 1 | num_updates 10175 | best_loss 8.288
2022-03-05 21:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10175 updates
2022-03-05 21:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 209 @ 10175 updates, score 14.739) (writing took 1.6676200800575316 seconds)
2022-03-05 21:02:10 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:02:10 | INFO | train | epoch 209 | loss 0.976 | nll_loss 0.387 | ppl 1.31 | wps 27817.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10175 | lr 0.000313497 | gnorm 0.644 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24014
2022-03-05 21:02:10 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:03:06 | INFO | train_inner | epoch 210:     25 / 49 loss=0.976, nll_loss=0.388, ppl=1.31, wps=27845.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.646, loss_scale=32, train_wall=198, gb_free=21.6, wall=24070
2022-03-05 21:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:04:03 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 14.741 | nll_loss 14.512 | ppl 23362.9 | wps 47949.3 | wpb 510.9 | bsz 1 | num_updates 10224 | best_loss 8.288
2022-03-05 21:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10224 updates
2022-03-05 21:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 210 @ 10224 updates, score 14.741) (writing took 1.7440415828023106 seconds)
2022-03-05 21:04:05 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:04:05 | INFO | train | epoch 210 | loss 0.973 | nll_loss 0.385 | ppl 1.31 | wps 27791.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10224 | lr 0.000312744 | gnorm 0.644 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24129
2022-03-05 21:04:05 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:57 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 14.721 | nll_loss 14.491 | ppl 23033.6 | wps 47980.7 | wpb 510.9 | bsz 1 | num_updates 10273 | best_loss 8.288
2022-03-05 21:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10273 updates
2022-03-05 21:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 211 @ 10273 updates, score 14.721) (writing took 1.7779842810705304 seconds)
2022-03-05 21:05:59 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:05:59 | INFO | train | epoch 211 | loss 0.97 | nll_loss 0.382 | ppl 1.3 | wps 27792.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10273 | lr 0.000311998 | gnorm 0.646 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24243
2022-03-05 21:05:59 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:06:59 | INFO | train_inner | epoch 212:     27 / 49 loss=0.969, nll_loss=0.381, ppl=1.3, wps=27829.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.636, loss_scale=32, train_wall=198, gb_free=21.6, wall=24303
2022-03-05 21:07:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:07:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:07:52 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 14.701 | nll_loss 14.473 | ppl 22733.8 | wps 47881.9 | wpb 510.9 | bsz 1 | num_updates 10320 | best_loss 8.288
2022-03-05 21:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10320 updates
2022-03-05 21:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:07:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 212 @ 10320 updates, score 14.701) (writing took 1.688162102131173 seconds)
2022-03-05 21:07:53 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:07:53 | INFO | train | epoch 212 | loss 0.966 | nll_loss 0.378 | ppl 1.3 | wps 26679.1 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 10320 | lr 0.000311286 | gnorm 0.628 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24357
2022-03-05 21:07:53 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:09:46 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 14.705 | nll_loss 14.478 | ppl 22812.6 | wps 48030.6 | wpb 510.9 | bsz 1 | num_updates 10369 | best_loss 8.288
2022-03-05 21:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10369 updates
2022-03-05 21:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 213 @ 10369 updates, score 14.705) (writing took 1.7453613770194352 seconds)
2022-03-05 21:09:48 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:09:48 | INFO | train | epoch 213 | loss 0.966 | nll_loss 0.378 | ppl 1.3 | wps 27779.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10369 | lr 0.00031055 | gnorm 0.641 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24472
2022-03-05 21:09:48 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:10:57 | INFO | train_inner | epoch 214:     31 / 49 loss=0.965, nll_loss=0.377, ppl=1.3, wps=27313, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.64, loss_scale=16, train_wall=202, gb_free=21.6, wall=24541
2022-03-05 21:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:40 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 14.681 | nll_loss 14.454 | ppl 22446.6 | wps 47974.7 | wpb 510.9 | bsz 1 | num_updates 10418 | best_loss 8.288
2022-03-05 21:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10418 updates
2022-03-05 21:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 214 @ 10418 updates, score 14.681) (writing took 1.7444307950790972 seconds)
2022-03-05 21:11:42 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:11:42 | INFO | train | epoch 214 | loss 0.962 | nll_loss 0.374 | ppl 1.3 | wps 27812.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10418 | lr 0.000309819 | gnorm 0.637 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24586
2022-03-05 21:11:42 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:13:35 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 14.813 | nll_loss 14.588 | ppl 24620.9 | wps 48009 | wpb 510.9 | bsz 1 | num_updates 10467 | best_loss 8.288
2022-03-05 21:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10467 updates
2022-03-05 21:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 215 @ 10467 updates, score 14.813) (writing took 1.664640629896894 seconds)
2022-03-05 21:13:36 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:13:36 | INFO | train | epoch 215 | loss 0.959 | nll_loss 0.372 | ppl 1.29 | wps 27827.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10467 | lr 0.000309093 | gnorm 0.631 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 24700
2022-03-05 21:13:36 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:13:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:14:52 | INFO | train_inner | epoch 216:     34 / 49 loss=0.959, nll_loss=0.372, ppl=1.29, wps=27591.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.627, loss_scale=16, train_wall=200, gb_free=21.6, wall=24776
2022-03-05 21:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:15:29 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 14.776 | nll_loss 14.55 | ppl 23992.2 | wps 47783.7 | wpb 510.9 | bsz 1 | num_updates 10515 | best_loss 8.288
2022-03-05 21:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10515 updates
2022-03-05 21:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 216 @ 10515 updates, score 14.776) (writing took 1.7215437479317188 seconds)
2022-03-05 21:15:30 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:15:30 | INFO | train | epoch 216 | loss 0.957 | nll_loss 0.37 | ppl 1.29 | wps 27252.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10515 | lr 0.000308387 | gnorm 0.619 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24814
2022-03-05 21:15:30 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:17:23 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 14.684 | nll_loss 14.454 | ppl 22448.3 | wps 47974.1 | wpb 510.9 | bsz 1 | num_updates 10564 | best_loss 8.288
2022-03-05 21:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10564 updates
2022-03-05 21:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 217 @ 10564 updates, score 14.684) (writing took 1.7453152830712497 seconds)
2022-03-05 21:17:25 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:17:25 | INFO | train | epoch 217 | loss 0.955 | nll_loss 0.369 | ppl 1.29 | wps 27811.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10564 | lr 0.00030767 | gnorm 0.624 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24929
2022-03-05 21:17:25 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:18:45 | INFO | train_inner | epoch 218:     36 / 49 loss=0.955, nll_loss=0.368, ppl=1.29, wps=27850, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.624, loss_scale=32, train_wall=198, gb_free=21.6, wall=25009
2022-03-05 21:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:19:17 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 14.744 | nll_loss 14.517 | ppl 23450.3 | wps 47910.5 | wpb 510.9 | bsz 1 | num_updates 10613 | best_loss 8.288
2022-03-05 21:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10613 updates
2022-03-05 21:19:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 218 @ 10613 updates, score 14.744) (writing took 1.6751556750386953 seconds)
2022-03-05 21:19:19 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:19:19 | INFO | train | epoch 218 | loss 0.953 | nll_loss 0.366 | ppl 1.29 | wps 27835.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10613 | lr 0.000306959 | gnorm 0.625 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25043
2022-03-05 21:19:19 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:21:11 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 14.747 | nll_loss 14.523 | ppl 23540.3 | wps 47912.3 | wpb 510.9 | bsz 1 | num_updates 10662 | best_loss 8.288
2022-03-05 21:21:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10662 updates
2022-03-05 21:21:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:21:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:21:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 219 @ 10662 updates, score 14.747) (writing took 1.739266365999356 seconds)
2022-03-05 21:21:13 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:21:13 | INFO | train | epoch 219 | loss 0.949 | nll_loss 0.363 | ppl 1.29 | wps 27779.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10662 | lr 0.000306253 | gnorm 0.611 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25157
2022-03-05 21:21:13 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:21:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:22:38 | INFO | train_inner | epoch 220:     38 / 49 loss=0.95, nll_loss=0.363, ppl=1.29, wps=27823.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.613, loss_scale=32, train_wall=198, gb_free=21.6, wall=25242
2022-03-05 21:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:23:06 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 14.797 | nll_loss 14.573 | ppl 24377.2 | wps 48024.9 | wpb 510.9 | bsz 1 | num_updates 10711 | best_loss 8.288
2022-03-05 21:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10711 updates
2022-03-05 21:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 220 @ 10711 updates, score 14.797) (writing took 1.723700778093189 seconds)
2022-03-05 21:23:08 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:23:08 | INFO | train | epoch 220 | loss 0.948 | nll_loss 0.362 | ppl 1.29 | wps 27789.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10711 | lr 0.000305552 | gnorm 0.615 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25272
2022-03-05 21:23:08 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:23:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:25:00 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 14.784 | nll_loss 14.561 | ppl 24169.2 | wps 47939.7 | wpb 510.9 | bsz 1 | num_updates 10759 | best_loss 8.288
2022-03-05 21:25:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10759 updates
2022-03-05 21:25:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 221 @ 10759 updates, score 14.784) (writing took 1.675932231824845 seconds)
2022-03-05 21:25:02 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:25:02 | INFO | train | epoch 221 | loss 0.947 | nll_loss 0.361 | ppl 1.28 | wps 27238.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10759 | lr 0.00030487 | gnorm 0.615 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25386
2022-03-05 21:25:02 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:25:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:25:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:26:35 | INFO | train_inner | epoch 222:     42 / 49 loss=0.946, nll_loss=0.361, ppl=1.28, wps=27311.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.617, loss_scale=16, train_wall=202, gb_free=21.6, wall=25479
2022-03-05 21:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:54 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 14.724 | nll_loss 14.499 | ppl 23160.2 | wps 47894.8 | wpb 510.9 | bsz 1 | num_updates 10807 | best_loss 8.288
2022-03-05 21:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10807 updates
2022-03-05 21:26:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:26:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 222 @ 10807 updates, score 14.724) (writing took 1.735134675167501 seconds)
2022-03-05 21:26:56 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:26:56 | INFO | train | epoch 222 | loss 0.945 | nll_loss 0.359 | ppl 1.28 | wps 27215.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10807 | lr 0.000304192 | gnorm 0.616 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25500
2022-03-05 21:26:56 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:49 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 14.75 | nll_loss 14.527 | ppl 23603.4 | wps 47952.8 | wpb 510.9 | bsz 1 | num_updates 10856 | best_loss 8.288
2022-03-05 21:28:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10856 updates
2022-03-05 21:28:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 223 @ 10856 updates, score 14.75) (writing took 1.7040966299828142 seconds)
2022-03-05 21:28:50 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:28:50 | INFO | train | epoch 223 | loss 0.942 | nll_loss 0.357 | ppl 1.28 | wps 27817.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10856 | lr 0.000303504 | gnorm 0.624 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25615
2022-03-05 21:28:50 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:30:28 | INFO | train_inner | epoch 224:     44 / 49 loss=0.942, nll_loss=0.356, ppl=1.28, wps=27846, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.62, loss_scale=16, train_wall=198, gb_free=21.6, wall=25712
2022-03-05 21:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:43 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 14.724 | nll_loss 14.5 | ppl 23175.2 | wps 47792.8 | wpb 510.9 | bsz 1 | num_updates 10905 | best_loss 8.288
2022-03-05 21:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10905 updates
2022-03-05 21:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 224 @ 10905 updates, score 14.724) (writing took 1.707339929183945 seconds)
2022-03-05 21:30:45 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:30:45 | INFO | train | epoch 224 | loss 0.94 | nll_loss 0.355 | ppl 1.28 | wps 27813.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10905 | lr 0.000302822 | gnorm 0.618 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25729
2022-03-05 21:30:45 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:37 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 14.786 | nll_loss 14.562 | ppl 24193.9 | wps 48167.1 | wpb 510.9 | bsz 1 | num_updates 10954 | best_loss 8.288
2022-03-05 21:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10954 updates
2022-03-05 21:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 225 @ 10954 updates, score 14.786) (writing took 1.7642690669745207 seconds)
2022-03-05 21:32:39 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:32:39 | INFO | train | epoch 225 | loss 0.937 | nll_loss 0.352 | ppl 1.28 | wps 27794.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10954 | lr 0.000302144 | gnorm 0.6 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25843
2022-03-05 21:32:39 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:32:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:34:24 | INFO | train_inner | epoch 226:     47 / 49 loss=0.936, nll_loss=0.351, ppl=1.28, wps=27569.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.601, loss_scale=16, train_wall=200, gb_free=21.6, wall=25948
2022-03-05 21:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:34:32 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 14.79 | nll_loss 14.573 | ppl 24364.7 | wps 47958.4 | wpb 510.9 | bsz 1 | num_updates 11002 | best_loss 8.288
2022-03-05 21:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11002 updates
2022-03-05 21:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 226 @ 11002 updates, score 14.79) (writing took 1.7163582320790738 seconds)
2022-03-05 21:34:33 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:34:33 | INFO | train | epoch 226 | loss 0.933 | nll_loss 0.348 | ppl 1.27 | wps 27234.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11002 | lr 0.000301484 | gnorm 0.602 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25957
2022-03-05 21:34:33 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:36:26 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 14.742 | nll_loss 14.52 | ppl 23500.3 | wps 47844.9 | wpb 510.9 | bsz 1 | num_updates 11051 | best_loss 8.288
2022-03-05 21:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11051 updates
2022-03-05 21:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 227 @ 11051 updates, score 14.742) (writing took 1.6817197198979557 seconds)
2022-03-05 21:36:28 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:36:28 | INFO | train | epoch 227 | loss 0.933 | nll_loss 0.349 | ppl 1.27 | wps 27801.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11051 | lr 0.000300815 | gnorm 0.604 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26072
2022-03-05 21:36:28 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:37:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:38:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:38:20 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 14.781 | nll_loss 14.563 | ppl 24206.2 | wps 47911 | wpb 510.9 | bsz 1 | num_updates 11099 | best_loss 8.288
2022-03-05 21:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11099 updates
2022-03-05 21:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:38:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:38:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 228 @ 11099 updates, score 14.781) (writing took 1.7308922470547259 seconds)
2022-03-05 21:38:22 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:38:22 | INFO | train | epoch 228 | loss 0.932 | nll_loss 0.348 | ppl 1.27 | wps 27220.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11099 | lr 0.000300164 | gnorm 0.608 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26186
2022-03-05 21:38:22 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:38:24 | INFO | train_inner | epoch 229:      1 / 49 loss=0.933, nll_loss=0.348, ppl=1.27, wps=26815.4, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=11100, lr=0.00030015, gnorm=0.608, loss_scale=16, train_wall=199, gb_free=21.6, wall=26188
2022-03-05 21:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:40:15 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 14.752 | nll_loss 14.528 | ppl 23628.2 | wps 47948.9 | wpb 510.9 | bsz 1 | num_updates 11148 | best_loss 8.288
2022-03-05 21:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11148 updates
2022-03-05 21:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 229 @ 11148 updates, score 14.752) (writing took 1.732482427963987 seconds)
2022-03-05 21:40:16 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:40:16 | INFO | train | epoch 229 | loss 0.928 | nll_loss 0.344 | ppl 1.27 | wps 27806 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11148 | lr 0.000299503 | gnorm 0.594 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26300
2022-03-05 21:40:16 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:42:09 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 14.839 | nll_loss 14.62 | ppl 25174.7 | wps 47949.9 | wpb 510.9 | bsz 1 | num_updates 11197 | best_loss 8.288
2022-03-05 21:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11197 updates
2022-03-05 21:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 230 @ 11197 updates, score 14.839) (writing took 1.6806040999945253 seconds)
2022-03-05 21:42:10 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:42:10 | INFO | train | epoch 230 | loss 0.927 | nll_loss 0.343 | ppl 1.27 | wps 27844.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11197 | lr 0.000298847 | gnorm 0.594 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26415
2022-03-05 21:42:10 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:42:17 | INFO | train_inner | epoch 231:      3 / 49 loss=0.927, nll_loss=0.343, ppl=1.27, wps=27853.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.594, loss_scale=16, train_wall=198, gb_free=21.6, wall=26421
2022-03-05 21:43:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:43:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:44:03 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 14.78 | nll_loss 14.561 | ppl 24174.5 | wps 47945.6 | wpb 510.9 | bsz 1 | num_updates 11245 | best_loss 8.288
2022-03-05 21:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11245 updates
2022-03-05 21:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 231 @ 11245 updates, score 14.78) (writing took 1.7236282690428197 seconds)
2022-03-05 21:44:05 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:44:05 | INFO | train | epoch 231 | loss 0.925 | nll_loss 0.341 | ppl 1.27 | wps 27240.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11245 | lr 0.000298209 | gnorm 0.589 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26529
2022-03-05 21:44:05 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:57 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 14.74 | nll_loss 14.521 | ppl 23506.2 | wps 47839.8 | wpb 510.9 | bsz 1 | num_updates 11294 | best_loss 8.288
2022-03-05 21:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11294 updates
2022-03-05 21:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 232 @ 11294 updates, score 14.74) (writing took 1.7514370968565345 seconds)
2022-03-05 21:45:59 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:45:59 | INFO | train | epoch 232 | loss 0.922 | nll_loss 0.339 | ppl 1.27 | wps 27803.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11294 | lr 0.000297561 | gnorm 0.595 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26643
2022-03-05 21:45:59 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:46:12 | INFO | train_inner | epoch 233:      6 / 49 loss=0.923, nll_loss=0.34, ppl=1.27, wps=27582.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.592, loss_scale=16, train_wall=200, gb_free=21.6, wall=26657
2022-03-05 21:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:52 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 14.656 | nll_loss 14.433 | ppl 22116.3 | wps 47947.4 | wpb 510.9 | bsz 1 | num_updates 11343 | best_loss 8.288
2022-03-05 21:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11343 updates
2022-03-05 21:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 233 @ 11343 updates, score 14.656) (writing took 1.696999436011538 seconds)
2022-03-05 21:47:53 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:47:53 | INFO | train | epoch 233 | loss 0.92 | nll_loss 0.338 | ppl 1.26 | wps 27808.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11343 | lr 0.000296918 | gnorm 0.588 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26757
2022-03-05 21:47:53 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:46 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 14.732 | nll_loss 14.511 | ppl 23355.3 | wps 47977.6 | wpb 510.9 | bsz 1 | num_updates 11392 | best_loss 8.288
2022-03-05 21:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11392 updates
2022-03-05 21:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 234 @ 11392 updates, score 14.732) (writing took 1.7067470829933882 seconds)
2022-03-05 21:49:48 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:49:48 | INFO | train | epoch 234 | loss 0.92 | nll_loss 0.337 | ppl 1.26 | wps 27819.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11392 | lr 0.000296278 | gnorm 0.594 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26872
2022-03-05 21:49:48 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:50:05 | INFO | train_inner | epoch 235:      8 / 49 loss=0.92, nll_loss=0.337, ppl=1.26, wps=27842.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.59, loss_scale=32, train_wall=198, gb_free=21.6, wall=26890
2022-03-05 21:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:51:40 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 14.732 | nll_loss 14.51 | ppl 23324.8 | wps 47996.8 | wpb 510.9 | bsz 1 | num_updates 11441 | best_loss 8.288
2022-03-05 21:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11441 updates
2022-03-05 21:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:51:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 235 @ 11441 updates, score 14.732) (writing took 1.7491600359790027 seconds)
2022-03-05 21:51:42 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:51:42 | INFO | train | epoch 235 | loss 0.916 | nll_loss 0.334 | ppl 1.26 | wps 27786.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11441 | lr 0.000295643 | gnorm 0.578 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26986
2022-03-05 21:51:42 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:53:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:35 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 14.742 | nll_loss 14.526 | ppl 23592.7 | wps 47994.1 | wpb 510.9 | bsz 1 | num_updates 11489 | best_loss 8.288
2022-03-05 21:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11489 updates
2022-03-05 21:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:53:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 236 @ 11489 updates, score 14.742) (writing took 1.7082511058542877 seconds)
2022-03-05 21:53:36 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:53:36 | INFO | train | epoch 236 | loss 0.915 | nll_loss 0.333 | ppl 1.26 | wps 27232.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11489 | lr 0.000295025 | gnorm 0.585 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27100
2022-03-05 21:53:36 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:54:01 | INFO | train_inner | epoch 237:     11 / 49 loss=0.915, nll_loss=0.333, ppl=1.26, wps=27566.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.582, loss_scale=32, train_wall=200, gb_free=21.6, wall=27125
2022-03-05 21:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:55:29 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 14.778 | nll_loss 14.559 | ppl 24144.4 | wps 47901.6 | wpb 510.9 | bsz 1 | num_updates 11538 | best_loss 8.288
2022-03-05 21:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11538 updates
2022-03-05 21:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 237 @ 11538 updates, score 14.778) (writing took 1.7274024421349168 seconds)
2022-03-05 21:55:31 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:55:31 | INFO | train | epoch 237 | loss 0.913 | nll_loss 0.331 | ppl 1.26 | wps 27789.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11538 | lr 0.000294398 | gnorm 0.582 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27215
2022-03-05 21:55:31 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:57:23 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 14.69 | nll_loss 14.472 | ppl 22724.3 | wps 47905.9 | wpb 510.9 | bsz 1 | num_updates 11587 | best_loss 8.288
2022-03-05 21:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11587 updates
2022-03-05 21:57:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:57:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 238 @ 11587 updates, score 14.69) (writing took 1.730932620121166 seconds)
2022-03-05 21:57:25 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 21:57:25 | INFO | train | epoch 238 | loss 0.911 | nll_loss 0.33 | ppl 1.26 | wps 27805.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11587 | lr 0.000293775 | gnorm 0.589 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27329
2022-03-05 21:57:25 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 21:57:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:57:54 | INFO | train_inner | epoch 239:     13 / 49 loss=0.911, nll_loss=0.329, ppl=1.26, wps=27829.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.583, loss_scale=32, train_wall=198, gb_free=21.6, wall=27358
2022-03-05 21:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:59:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:59:18 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 14.712 | nll_loss 14.498 | ppl 23145.5 | wps 47888 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 8.288
2022-03-05 21:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-05 21:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 21:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 239 @ 11634 updates, score 14.712) (writing took 1.6832083130721003 seconds)
2022-03-05 21:59:19 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 21:59:19 | INFO | train | epoch 239 | loss 0.908 | nll_loss 0.326 | ppl 1.25 | wps 26649.1 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 11634 | lr 0.000293181 | gnorm 0.58 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27443
2022-03-05 21:59:19 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 21:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:01:12 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 14.684 | nll_loss 14.466 | ppl 22623.7 | wps 47929.9 | wpb 510.9 | bsz 1 | num_updates 11683 | best_loss 8.288
2022-03-05 22:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11683 updates
2022-03-05 22:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 240 @ 11683 updates, score 14.684) (writing took 1.7273284927941859 seconds)
2022-03-05 22:01:14 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:01:14 | INFO | train | epoch 240 | loss 0.908 | nll_loss 0.326 | ppl 1.25 | wps 27775.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11683 | lr 0.000292565 | gnorm 0.584 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27558
2022-03-05 22:01:14 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:52 | INFO | train_inner | epoch 241:     17 / 49 loss=0.907, nll_loss=0.326, ppl=1.25, wps=27296.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.581, loss_scale=16, train_wall=202, gb_free=21.6, wall=27596
2022-03-05 22:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:03:06 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 14.685 | nll_loss 14.468 | ppl 22654.7 | wps 48045.3 | wpb 510.9 | bsz 1 | num_updates 11732 | best_loss 8.288
2022-03-05 22:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11732 updates
2022-03-05 22:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 241 @ 11732 updates, score 14.685) (writing took 1.7414162911009043 seconds)
2022-03-05 22:03:08 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:03:08 | INFO | train | epoch 241 | loss 0.906 | nll_loss 0.325 | ppl 1.25 | wps 27813.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11732 | lr 0.000291954 | gnorm 0.573 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27672
2022-03-05 22:03:08 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:00 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 14.679 | nll_loss 14.463 | ppl 22591.5 | wps 47878 | wpb 510.9 | bsz 1 | num_updates 11781 | best_loss 8.288
2022-03-05 22:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11781 updates
2022-03-05 22:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 242 @ 11781 updates, score 14.679) (writing took 1.671704598935321 seconds)
2022-03-05 22:05:02 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:05:02 | INFO | train | epoch 242 | loss 0.904 | nll_loss 0.323 | ppl 1.25 | wps 27808.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11781 | lr 0.000291346 | gnorm 0.571 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27786
2022-03-05 22:05:02 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:05:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:05:47 | INFO | train_inner | epoch 243:     20 / 49 loss=0.904, nll_loss=0.323, ppl=1.25, wps=27585.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.575, loss_scale=16, train_wall=200, gb_free=21.6, wall=27831
2022-03-05 22:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:06:55 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 14.684 | nll_loss 14.468 | ppl 22666.5 | wps 47925.2 | wpb 510.9 | bsz 1 | num_updates 11829 | best_loss 8.288
2022-03-05 22:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11829 updates
2022-03-05 22:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 243 @ 11829 updates, score 14.684) (writing took 1.7268925970420241 seconds)
2022-03-05 22:06:56 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:06:56 | INFO | train | epoch 243 | loss 0.902 | nll_loss 0.321 | ppl 1.25 | wps 27227.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11829 | lr 0.000290754 | gnorm 0.575 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27901
2022-03-05 22:06:57 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:08:49 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 14.676 | nll_loss 14.458 | ppl 22510.4 | wps 47860.9 | wpb 510.9 | bsz 1 | num_updates 11878 | best_loss 8.288
2022-03-05 22:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11878 updates
2022-03-05 22:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 244 @ 11878 updates, score 14.676) (writing took 1.9178632451221347 seconds)
2022-03-05 22:08:51 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:08:51 | INFO | train | epoch 244 | loss 0.9 | nll_loss 0.319 | ppl 1.25 | wps 27753 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11878 | lr 0.000290154 | gnorm 0.566 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28015
2022-03-05 22:08:51 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:09:40 | INFO | train_inner | epoch 245:     22 / 49 loss=0.9, nll_loss=0.32, ppl=1.25, wps=27797.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.567, loss_scale=16, train_wall=198, gb_free=21.6, wall=28064
2022-03-05 22:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:10:44 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 14.727 | nll_loss 14.51 | ppl 23338.5 | wps 47967 | wpb 510.9 | bsz 1 | num_updates 11927 | best_loss 8.288
2022-03-05 22:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11927 updates
2022-03-05 22:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 245 @ 11927 updates, score 14.727) (writing took 1.7547606648877263 seconds)
2022-03-05 22:10:45 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:10:45 | INFO | train | epoch 245 | loss 0.899 | nll_loss 0.319 | ppl 1.25 | wps 27772 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11927 | lr 0.000289557 | gnorm 0.566 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28129
2022-03-05 22:10:45 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:12:38 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 14.776 | nll_loss 14.562 | ppl 24179.8 | wps 47908.2 | wpb 510.9 | bsz 1 | num_updates 11976 | best_loss 8.288
2022-03-05 22:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11976 updates
2022-03-05 22:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 246 @ 11976 updates, score 14.776) (writing took 1.7683751059230417 seconds)
2022-03-05 22:12:40 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:12:40 | INFO | train | epoch 246 | loss 0.897 | nll_loss 0.317 | ppl 1.25 | wps 27766.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11976 | lr 0.000288964 | gnorm 0.56 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28244
2022-03-05 22:12:40 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:13:33 | INFO | train_inner | epoch 247:     24 / 49 loss=0.897, nll_loss=0.317, ppl=1.25, wps=27810.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.56, loss_scale=32, train_wall=198, gb_free=21.6, wall=28297
2022-03-05 22:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:14:32 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 14.786 | nll_loss 14.573 | ppl 24375.6 | wps 47952.2 | wpb 510.9 | bsz 1 | num_updates 12025 | best_loss 8.288
2022-03-05 22:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12025 updates
2022-03-05 22:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 247 @ 12025 updates, score 14.786) (writing took 1.7867324268445373 seconds)
2022-03-05 22:14:34 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:14:34 | INFO | train | epoch 247 | loss 0.895 | nll_loss 0.315 | ppl 1.24 | wps 27797.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12025 | lr 0.000288375 | gnorm 0.557 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28358
2022-03-05 22:14:34 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:16:27 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 14.746 | nll_loss 14.533 | ppl 23712.8 | wps 47967.2 | wpb 510.9 | bsz 1 | num_updates 12073 | best_loss 8.288
2022-03-05 22:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12073 updates
2022-03-05 22:16:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:16:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 248 @ 12073 updates, score 14.746) (writing took 1.6749734298791736 seconds)
2022-03-05 22:16:28 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:16:28 | INFO | train | epoch 248 | loss 0.893 | nll_loss 0.314 | ppl 1.24 | wps 27244 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12073 | lr 0.000287801 | gnorm 0.567 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28473
2022-03-05 22:16:28 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:16:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:17:29 | INFO | train_inner | epoch 249:     27 / 49 loss=0.893, nll_loss=0.314, ppl=1.24, wps=27574.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.561, loss_scale=32, train_wall=200, gb_free=21.6, wall=28533
2022-03-05 22:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:18:21 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 14.663 | nll_loss 14.446 | ppl 22326.5 | wps 48019.6 | wpb 510.9 | bsz 1 | num_updates 12122 | best_loss 8.288
2022-03-05 22:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12122 updates
2022-03-05 22:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 249 @ 12122 updates, score 14.663) (writing took 1.7350646359845996 seconds)
2022-03-05 22:18:23 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:18:23 | INFO | train | epoch 249 | loss 0.891 | nll_loss 0.312 | ppl 1.24 | wps 27794 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12122 | lr 0.000287219 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28587
2022-03-05 22:18:23 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:20:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:20:15 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 14.659 | nll_loss 14.443 | ppl 22268.2 | wps 47886.2 | wpb 510.9 | bsz 1 | num_updates 12170 | best_loss 8.288
2022-03-05 22:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12170 updates
2022-03-05 22:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 250 @ 12170 updates, score 14.659) (writing took 1.7628886429592967 seconds)
2022-03-05 22:20:17 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:20:17 | INFO | train | epoch 250 | loss 0.891 | nll_loss 0.312 | ppl 1.24 | wps 27227.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12170 | lr 0.000286652 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28701
2022-03-05 22:20:17 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:21:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:21:26 | INFO | train_inner | epoch 251:     31 / 49 loss=0.891, nll_loss=0.312, ppl=1.24, wps=27313.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.563, loss_scale=16, train_wall=202, gb_free=21.6, wall=28770
2022-03-05 22:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:10 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 14.757 | nll_loss 14.542 | ppl 23849.9 | wps 47977.3 | wpb 510.9 | bsz 1 | num_updates 12218 | best_loss 8.288
2022-03-05 22:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12218 updates
2022-03-05 22:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 251 @ 12218 updates, score 14.757) (writing took 1.6968266570474952 seconds)
2022-03-05 22:22:11 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:22:11 | INFO | train | epoch 251 | loss 0.889 | nll_loss 0.31 | ppl 1.24 | wps 27252.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12218 | lr 0.000286088 | gnorm 0.563 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28815
2022-03-05 22:22:11 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:24:04 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 14.692 | nll_loss 14.479 | ppl 22830.1 | wps 48120.9 | wpb 510.9 | bsz 1 | num_updates 12267 | best_loss 8.288
2022-03-05 22:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12267 updates
2022-03-05 22:24:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 252 @ 12267 updates, score 14.692) (writing took 1.7294262030627578 seconds)
2022-03-05 22:24:06 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:24:06 | INFO | train | epoch 252 | loss 0.888 | nll_loss 0.309 | ppl 1.24 | wps 27800.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12267 | lr 0.000285516 | gnorm 0.554 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28930
2022-03-05 22:24:06 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:25:19 | INFO | train_inner | epoch 253:     33 / 49 loss=0.887, nll_loss=0.308, ppl=1.24, wps=27837.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.555, loss_scale=16, train_wall=198, gb_free=21.6, wall=29003
2022-03-05 22:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:25:58 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 14.663 | nll_loss 14.451 | ppl 22398.1 | wps 48155.9 | wpb 510.9 | bsz 1 | num_updates 12316 | best_loss 8.288
2022-03-05 22:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12316 updates
2022-03-05 22:25:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 253 @ 12316 updates, score 14.663) (writing took 1.717858319869265 seconds)
2022-03-05 22:26:00 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:26:00 | INFO | train | epoch 253 | loss 0.886 | nll_loss 0.308 | ppl 1.24 | wps 27809.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12316 | lr 0.000284948 | gnorm 0.556 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29044
2022-03-05 22:26:00 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:27:53 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 14.687 | nll_loss 14.472 | ppl 22732.6 | wps 47917.6 | wpb 510.9 | bsz 1 | num_updates 12365 | best_loss 8.288
2022-03-05 22:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12365 updates
2022-03-05 22:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 254 @ 12365 updates, score 14.687) (writing took 1.7074834280647337 seconds)
2022-03-05 22:27:54 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:27:54 | INFO | train | epoch 254 | loss 0.885 | nll_loss 0.306 | ppl 1.24 | wps 27804.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12365 | lr 0.000284383 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29158
2022-03-05 22:27:54 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:29:12 | INFO | train_inner | epoch 255:     35 / 49 loss=0.883, nll_loss=0.305, ppl=1.24, wps=27834.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.553, loss_scale=32, train_wall=198, gb_free=21.6, wall=29236
2022-03-05 22:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:29:47 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 14.678 | nll_loss 14.465 | ppl 22618.3 | wps 47898.5 | wpb 510.9 | bsz 1 | num_updates 12414 | best_loss 8.288
2022-03-05 22:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12414 updates
2022-03-05 22:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 255 @ 12414 updates, score 14.678) (writing took 1.7444121760781854 seconds)
2022-03-05 22:29:49 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:29:49 | INFO | train | epoch 255 | loss 0.882 | nll_loss 0.304 | ppl 1.23 | wps 27788 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12414 | lr 0.000283821 | gnorm 0.55 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29273
2022-03-05 22:29:49 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:31:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:31:41 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 14.709 | nll_loss 14.496 | ppl 23101.9 | wps 47951.7 | wpb 510.9 | bsz 1 | num_updates 12462 | best_loss 8.288
2022-03-05 22:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12462 updates
2022-03-05 22:31:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:31:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 256 @ 12462 updates, score 14.709) (writing took 1.7058620071038604 seconds)
2022-03-05 22:31:43 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:31:43 | INFO | train | epoch 256 | loss 0.88 | nll_loss 0.303 | ppl 1.23 | wps 27225.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12462 | lr 0.000283274 | gnorm 0.552 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29387
2022-03-05 22:31:43 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:33:08 | INFO | train_inner | epoch 257:     38 / 49 loss=0.881, nll_loss=0.303, ppl=1.23, wps=27570.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.552, loss_scale=32, train_wall=200, gb_free=21.6, wall=29472
2022-03-05 22:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:33:36 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 14.642 | nll_loss 14.429 | ppl 22054.5 | wps 47999.2 | wpb 510.9 | bsz 1 | num_updates 12511 | best_loss 8.288
2022-03-05 22:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12511 updates
2022-03-05 22:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 257 @ 12511 updates, score 14.642) (writing took 1.6762980250641704 seconds)
2022-03-05 22:33:37 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:33:37 | INFO | train | epoch 257 | loss 0.88 | nll_loss 0.303 | ppl 1.23 | wps 27814.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12511 | lr 0.000282718 | gnorm 0.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29501
2022-03-05 22:33:37 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:35:30 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 14.665 | nll_loss 14.453 | ppl 22421.5 | wps 47942 | wpb 510.9 | bsz 1 | num_updates 12560 | best_loss 8.288
2022-03-05 22:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12560 updates
2022-03-05 22:35:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 258 @ 12560 updates, score 14.665) (writing took 1.741434286115691 seconds)
2022-03-05 22:35:32 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:35:32 | INFO | train | epoch 258 | loss 0.877 | nll_loss 0.299 | ppl 1.23 | wps 27788.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12560 | lr 0.000282166 | gnorm 0.537 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29616
2022-03-05 22:35:32 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:37:03 | INFO | train_inner | epoch 259:     41 / 49 loss=0.877, nll_loss=0.3, ppl=1.23, wps=27562.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.543, loss_scale=32, train_wall=200, gb_free=21.6, wall=29707
2022-03-05 22:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:37:24 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 14.641 | nll_loss 14.429 | ppl 22055.8 | wps 47858.9 | wpb 510.9 | bsz 1 | num_updates 12608 | best_loss 8.288
2022-03-05 22:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12608 updates
2022-03-05 22:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 259 @ 12608 updates, score 14.641) (writing took 1.7406404830981046 seconds)
2022-03-05 22:37:26 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:37:26 | INFO | train | epoch 259 | loss 0.876 | nll_loss 0.299 | ppl 1.23 | wps 27204.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12608 | lr 0.000281629 | gnorm 0.546 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29730
2022-03-05 22:37:26 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:39:19 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 14.789 | nll_loss 14.581 | ppl 24506 | wps 48074.2 | wpb 510.9 | bsz 1 | num_updates 12657 | best_loss 8.288
2022-03-05 22:39:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12657 updates
2022-03-05 22:39:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 260 @ 12657 updates, score 14.789) (writing took 1.6809997779782861 seconds)
2022-03-05 22:39:20 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:39:20 | INFO | train | epoch 260 | loss 0.876 | nll_loss 0.299 | ppl 1.23 | wps 27805 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12657 | lr 0.000281083 | gnorm 0.547 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29844
2022-03-05 22:39:20 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:40:56 | INFO | train_inner | epoch 261:     43 / 49 loss=0.875, nll_loss=0.298, ppl=1.23, wps=27816.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.547, loss_scale=32, train_wall=198, gb_free=21.6, wall=29940
2022-03-05 22:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:13 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 14.672 | nll_loss 14.459 | ppl 22522.1 | wps 47988.9 | wpb 510.9 | bsz 1 | num_updates 12705 | best_loss 8.288
2022-03-05 22:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12705 updates
2022-03-05 22:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 261 @ 12705 updates, score 14.672) (writing took 1.7466702761594206 seconds)
2022-03-05 22:41:15 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:41:15 | INFO | train | epoch 261 | loss 0.874 | nll_loss 0.298 | ppl 1.23 | wps 27200.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12705 | lr 0.000280552 | gnorm 0.547 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29959
2022-03-05 22:41:15 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:43:07 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 14.731 | nll_loss 14.522 | ppl 23530.9 | wps 48096.5 | wpb 510.9 | bsz 1 | num_updates 12754 | best_loss 8.288
2022-03-05 22:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12754 updates
2022-03-05 22:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:43:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 262 @ 12754 updates, score 14.731) (writing took 1.759345404105261 seconds)
2022-03-05 22:43:09 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:43:09 | INFO | train | epoch 262 | loss 0.872 | nll_loss 0.295 | ppl 1.23 | wps 27798.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12754 | lr 0.000280012 | gnorm 0.54 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30073
2022-03-05 22:43:09 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:44:51 | INFO | train_inner | epoch 263:     46 / 49 loss=0.871, nll_loss=0.295, ppl=1.23, wps=27574.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.542, loss_scale=32, train_wall=200, gb_free=21.6, wall=30175
2022-03-05 22:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:45:02 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 14.751 | nll_loss 14.544 | ppl 23887.2 | wps 48046.7 | wpb 510.9 | bsz 1 | num_updates 12803 | best_loss 8.288
2022-03-05 22:45:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12803 updates
2022-03-05 22:45:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:45:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 263 @ 12803 updates, score 14.751) (writing took 1.6846518190577626 seconds)
2022-03-05 22:45:03 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:45:03 | INFO | train | epoch 263 | loss 0.871 | nll_loss 0.294 | ppl 1.23 | wps 27818.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12803 | lr 0.000279476 | gnorm 0.544 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30187
2022-03-05 22:45:03 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:46:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:46:56 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 14.629 | nll_loss 14.419 | ppl 21906.4 | wps 47827.5 | wpb 510.9 | bsz 1 | num_updates 12851 | best_loss 8.288
2022-03-05 22:46:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12851 updates
2022-03-05 22:46:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 264 @ 12851 updates, score 14.629) (writing took 1.7670234669931233 seconds)
2022-03-05 22:46:58 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:46:58 | INFO | train | epoch 264 | loss 0.87 | nll_loss 0.294 | ppl 1.23 | wps 27211.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12851 | lr 0.000278953 | gnorm 0.544 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30302
2022-03-05 22:46:58 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:46 | INFO | train_inner | epoch 265:     49 / 49 loss=0.869, nll_loss=0.293, ppl=1.22, wps=27538.7, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.538, loss_scale=32, train_wall=199, gb_free=21.6, wall=30410
2022-03-05 22:48:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:48:50 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 14.701 | nll_loss 14.49 | ppl 23015.1 | wps 47956 | wpb 510.9 | bsz 1 | num_updates 12900 | best_loss 8.288
2022-03-05 22:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12900 updates
2022-03-05 22:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:48:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 265 @ 12900 updates, score 14.701) (writing took 1.7521533258259296 seconds)
2022-03-05 22:48:52 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:48:52 | INFO | train | epoch 265 | loss 0.867 | nll_loss 0.291 | ppl 1.22 | wps 27774.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12900 | lr 0.000278423 | gnorm 0.528 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30416
2022-03-05 22:48:52 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:48:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:50:45 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 14.71 | nll_loss 14.503 | ppl 23216.2 | wps 47994.3 | wpb 510.9 | bsz 1 | num_updates 12949 | best_loss 8.288
2022-03-05 22:50:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12949 updates
2022-03-05 22:50:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:50:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 266 @ 12949 updates, score 14.71) (writing took 1.6841587859671563 seconds)
2022-03-05 22:50:46 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:50:46 | INFO | train | epoch 266 | loss 0.866 | nll_loss 0.29 | ppl 1.22 | wps 27814 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12949 | lr 0.000277896 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30530
2022-03-05 22:50:46 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:51:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:52:39 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 14.718 | nll_loss 14.511 | ppl 23346 | wps 47801.9 | wpb 510.9 | bsz 1 | num_updates 12997 | best_loss 8.288
2022-03-05 22:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12997 updates
2022-03-05 22:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 267 @ 12997 updates, score 14.718) (writing took 1.7385488590225577 seconds)
2022-03-05 22:52:41 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:52:41 | INFO | train | epoch 267 | loss 0.864 | nll_loss 0.289 | ppl 1.22 | wps 27232.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12997 | lr 0.000277382 | gnorm 0.525 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30645
2022-03-05 22:52:41 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:52:47 | INFO | train_inner | epoch 268:      3 / 49 loss=0.865, nll_loss=0.289, ppl=1.22, wps=26841, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.527, loss_scale=32, train_wall=200, gb_free=21.6, wall=30651
2022-03-05 22:54:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:54:33 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 14.659 | nll_loss 14.448 | ppl 22354.9 | wps 47724.2 | wpb 510.9 | bsz 1 | num_updates 13046 | best_loss 8.288
2022-03-05 22:54:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13046 updates
2022-03-05 22:54:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 268 @ 13046 updates, score 14.659) (writing took 1.7332698351237923 seconds)
2022-03-05 22:54:35 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:54:35 | INFO | train | epoch 268 | loss 0.864 | nll_loss 0.289 | ppl 1.22 | wps 27780.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13046 | lr 0.000276861 | gnorm 0.534 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30759
2022-03-05 22:54:35 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:56:28 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 14.672 | nll_loss 14.463 | ppl 22584.8 | wps 47705.1 | wpb 510.9 | bsz 1 | num_updates 13095 | best_loss 8.288
2022-03-05 22:56:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13095 updates
2022-03-05 22:56:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 269 @ 13095 updates, score 14.672) (writing took 1.6624562938231975 seconds)
2022-03-05 22:56:29 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 22:56:29 | INFO | train | epoch 269 | loss 0.863 | nll_loss 0.288 | ppl 1.22 | wps 27795 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13095 | lr 0.000276342 | gnorm 0.535 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30873
2022-03-05 22:56:29 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 22:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:56:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:56:43 | INFO | train_inner | epoch 270:      6 / 49 loss=0.863, nll_loss=0.288, ppl=1.22, wps=27559.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.534, loss_scale=32, train_wall=200, gb_free=21.6, wall=30887
2022-03-05 22:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:22 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 14.598 | nll_loss 14.389 | ppl 21453.8 | wps 47976.5 | wpb 510.9 | bsz 1 | num_updates 13143 | best_loss 8.288
2022-03-05 22:58:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13143 updates
2022-03-05 22:58:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:58:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 22:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 270 @ 13143 updates, score 14.598) (writing took 1.7448563310317695 seconds)
2022-03-05 22:58:24 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 22:58:24 | INFO | train | epoch 270 | loss 0.861 | nll_loss 0.286 | ppl 1.22 | wps 27234.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13143 | lr 0.000275837 | gnorm 0.535 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30988
2022-03-05 22:58:24 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 22:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:00:16 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 14.57 | nll_loss 14.358 | ppl 20993.5 | wps 47923 | wpb 510.9 | bsz 1 | num_updates 13192 | best_loss 8.288
2022-03-05 23:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13192 updates
2022-03-05 23:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:00:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 271 @ 13192 updates, score 14.57) (writing took 1.7107780969236046 seconds)
2022-03-05 23:00:18 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:00:18 | INFO | train | epoch 271 | loss 0.859 | nll_loss 0.285 | ppl 1.22 | wps 27800.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13192 | lr 0.000275324 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31102
2022-03-05 23:00:18 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:00:36 | INFO | train_inner | epoch 272:      8 / 49 loss=0.86, nll_loss=0.285, ppl=1.22, wps=27833.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.531, loss_scale=32, train_wall=198, gb_free=21.6, wall=31120
2022-03-05 23:01:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:02:10 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 14.612 | nll_loss 14.402 | ppl 21641.4 | wps 48129.9 | wpb 510.9 | bsz 1 | num_updates 13240 | best_loss 8.288
2022-03-05 23:02:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13240 updates
2022-03-05 23:02:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 272 @ 13240 updates, score 14.612) (writing took 1.658372713951394 seconds)
2022-03-05 23:02:12 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:02:12 | INFO | train | epoch 272 | loss 0.859 | nll_loss 0.284 | ppl 1.22 | wps 27272 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13240 | lr 0.000274825 | gnorm 0.531 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31216
2022-03-05 23:02:12 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:05 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 14.758 | nll_loss 14.552 | ppl 24020.8 | wps 48141.1 | wpb 510.9 | bsz 1 | num_updates 13289 | best_loss 8.288
2022-03-05 23:04:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13289 updates
2022-03-05 23:04:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 273 @ 13289 updates, score 14.758) (writing took 1.7064342088997364 seconds)
2022-03-05 23:04:06 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:04:06 | INFO | train | epoch 273 | loss 0.857 | nll_loss 0.283 | ppl 1.22 | wps 27830.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13289 | lr 0.000274318 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31330
2022-03-05 23:04:06 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:31 | INFO | train_inner | epoch 274:     11 / 49 loss=0.858, nll_loss=0.284, ppl=1.22, wps=27608.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.53, loss_scale=32, train_wall=200, gb_free=21.6, wall=31355
2022-03-05 23:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:05:59 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 14.594 | nll_loss 14.384 | ppl 21384.8 | wps 48091 | wpb 510.9 | bsz 1 | num_updates 13338 | best_loss 8.288
2022-03-05 23:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13338 updates
2022-03-05 23:05:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:06:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 274 @ 13338 updates, score 14.594) (writing took 1.6907990230247378 seconds)
2022-03-05 23:06:01 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:06:01 | INFO | train | epoch 274 | loss 0.857 | nll_loss 0.283 | ppl 1.22 | wps 27804.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13338 | lr 0.000273813 | gnorm 0.529 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31445
2022-03-05 23:06:01 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:06:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:07:53 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 14.621 | nll_loss 14.413 | ppl 21813.6 | wps 48086.6 | wpb 510.9 | bsz 1 | num_updates 13386 | best_loss 8.288
2022-03-05 23:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13386 updates
2022-03-05 23:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 275 @ 13386 updates, score 14.621) (writing took 1.6506949889007956 seconds)
2022-03-05 23:07:55 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:07:55 | INFO | train | epoch 275 | loss 0.854 | nll_loss 0.28 | ppl 1.21 | wps 27268.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13386 | lr 0.000273322 | gnorm 0.515 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31559
2022-03-05 23:07:55 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:08:26 | INFO | train_inner | epoch 276:     14 / 49 loss=0.855, nll_loss=0.281, ppl=1.21, wps=27595, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.522, loss_scale=32, train_wall=200, gb_free=21.6, wall=31590
2022-03-05 23:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:09:47 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 14.536 | nll_loss 14.328 | ppl 20564.2 | wps 48186 | wpb 510.9 | bsz 1 | num_updates 13435 | best_loss 8.288
2022-03-05 23:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13435 updates
2022-03-05 23:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 276 @ 13435 updates, score 14.536) (writing took 1.7132236168254167 seconds)
2022-03-05 23:09:49 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:09:49 | INFO | train | epoch 276 | loss 0.853 | nll_loss 0.279 | ppl 1.21 | wps 27822.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13435 | lr 0.000272823 | gnorm 0.521 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31673
2022-03-05 23:09:49 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:41 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 14.532 | nll_loss 14.323 | ppl 20497.8 | wps 47931.5 | wpb 510.9 | bsz 1 | num_updates 13484 | best_loss 8.288
2022-03-05 23:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13484 updates
2022-03-05 23:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 277 @ 13484 updates, score 14.532) (writing took 1.7103843369986862 seconds)
2022-03-05 23:11:43 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:11:43 | INFO | train | epoch 277 | loss 0.852 | nll_loss 0.278 | ppl 1.21 | wps 27828 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13484 | lr 0.000272327 | gnorm 0.517 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 31787
2022-03-05 23:11:43 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:12:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:12:21 | INFO | train_inner | epoch 278:     17 / 49 loss=0.852, nll_loss=0.278, ppl=1.21, wps=27578.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.518, loss_scale=32, train_wall=200, gb_free=21.6, wall=31825
2022-03-05 23:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:36 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 14.655 | nll_loss 14.449 | ppl 22364.6 | wps 47977.1 | wpb 510.9 | bsz 1 | num_updates 13532 | best_loss 8.288
2022-03-05 23:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13532 updates
2022-03-05 23:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 278 @ 13532 updates, score 14.655) (writing took 1.6867222050204873 seconds)
2022-03-05 23:13:38 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:13:38 | INFO | train | epoch 278 | loss 0.85 | nll_loss 0.277 | ppl 1.21 | wps 27184.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13532 | lr 0.000271844 | gnorm 0.509 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31902
2022-03-05 23:13:38 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:15:30 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 14.582 | nll_loss 14.374 | ppl 21233.2 | wps 47865.8 | wpb 510.9 | bsz 1 | num_updates 13581 | best_loss 8.288
2022-03-05 23:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13581 updates
2022-03-05 23:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 279 @ 13581 updates, score 14.582) (writing took 1.7334453570656478 seconds)
2022-03-05 23:15:32 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:15:32 | INFO | train | epoch 279 | loss 0.85 | nll_loss 0.277 | ppl 1.21 | wps 27743.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13581 | lr 0.000271353 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32016
2022-03-05 23:15:32 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:16:15 | INFO | train_inner | epoch 280:     19 / 49 loss=0.85, nll_loss=0.276, ppl=1.21, wps=27780.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.512, loss_scale=32, train_wall=199, gb_free=21.6, wall=32059
2022-03-05 23:17:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:17:25 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 14.614 | nll_loss 14.409 | ppl 21748.9 | wps 47857.7 | wpb 510.9 | bsz 1 | num_updates 13629 | best_loss 8.288
2022-03-05 23:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13629 updates
2022-03-05 23:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 280 @ 13629 updates, score 14.614) (writing took 1.7269160021096468 seconds)
2022-03-05 23:17:27 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:17:27 | INFO | train | epoch 280 | loss 0.848 | nll_loss 0.276 | ppl 1.21 | wps 27173.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13629 | lr 0.000270874 | gnorm 0.516 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32131
2022-03-05 23:17:27 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:19:20 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 14.586 | nll_loss 14.379 | ppl 21302.7 | wps 48335.8 | wpb 510.9 | bsz 1 | num_updates 13678 | best_loss 8.288
2022-03-05 23:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13678 updates
2022-03-05 23:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:19:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:19:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 281 @ 13678 updates, score 14.586) (writing took 1.910619247937575 seconds)
2022-03-05 23:19:22 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:19:22 | INFO | train | epoch 281 | loss 0.847 | nll_loss 0.274 | ppl 1.21 | wps 27597.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13678 | lr 0.000270389 | gnorm 0.513 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 32246
2022-03-05 23:19:22 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:19:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:20:11 | INFO | train_inner | epoch 282:     22 / 49 loss=0.847, nll_loss=0.274, ppl=1.21, wps=27470.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.515, loss_scale=32, train_wall=201, gb_free=21.6, wall=32295
2022-03-05 23:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:21:14 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 14.609 | nll_loss 14.405 | ppl 21698.5 | wps 48327.5 | wpb 510.9 | bsz 1 | num_updates 13727 | best_loss 8.288
2022-03-05 23:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13727 updates
2022-03-05 23:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 282 @ 13727 updates, score 14.609) (writing took 1.8994158441200852 seconds)
2022-03-05 23:21:16 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:21:16 | INFO | train | epoch 282 | loss 0.847 | nll_loss 0.274 | ppl 1.21 | wps 27853 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13727 | lr 0.000269906 | gnorm 0.516 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32360
2022-03-05 23:21:16 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:23:08 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 14.587 | nll_loss 14.379 | ppl 21309.2 | wps 48191.5 | wpb 510.9 | bsz 1 | num_updates 13775 | best_loss 8.288
2022-03-05 23:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13775 updates
2022-03-05 23:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 283 @ 13775 updates, score 14.587) (writing took 1.8962030159309506 seconds)
2022-03-05 23:23:10 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:23:10 | INFO | train | epoch 283 | loss 0.846 | nll_loss 0.273 | ppl 1.21 | wps 27291.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13775 | lr 0.000269435 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32474
2022-03-05 23:23:10 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:24:05 | INFO | train_inner | epoch 284:     25 / 49 loss=0.845, nll_loss=0.273, ppl=1.21, wps=27641.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.511, loss_scale=32, train_wall=200, gb_free=21.6, wall=32530
2022-03-05 23:24:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:25:02 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 14.674 | nll_loss 14.472 | ppl 22725.6 | wps 48401.4 | wpb 510.9 | bsz 1 | num_updates 13824 | best_loss 8.288
2022-03-05 23:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13824 updates
2022-03-05 23:25:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 284 @ 13824 updates, score 14.674) (writing took 1.985208299010992 seconds)
2022-03-05 23:25:04 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:25:04 | INFO | train | epoch 284 | loss 0.844 | nll_loss 0.272 | ppl 1.21 | wps 27855.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13824 | lr 0.000268957 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32588
2022-03-05 23:25:04 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:26:56 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 14.612 | nll_loss 14.408 | ppl 21733.7 | wps 48148.1 | wpb 510.9 | bsz 1 | num_updates 13873 | best_loss 8.288
2022-03-05 23:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13873 updates
2022-03-05 23:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 285 @ 13873 updates, score 14.612) (writing took 1.9010827469173819 seconds)
2022-03-05 23:26:58 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:26:58 | INFO | train | epoch 285 | loss 0.842 | nll_loss 0.27 | ppl 1.21 | wps 27834.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13873 | lr 0.000268482 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32702
2022-03-05 23:26:58 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:27:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:28:00 | INFO | train_inner | epoch 286:     28 / 49 loss=0.842, nll_loss=0.27, ppl=1.21, wps=27609.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.513, loss_scale=32, train_wall=200, gb_free=21.6, wall=32765
2022-03-05 23:28:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:28:51 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 14.634 | nll_loss 14.43 | ppl 22073.1 | wps 48226.3 | wpb 510.9 | bsz 1 | num_updates 13921 | best_loss 8.288
2022-03-05 23:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13921 updates
2022-03-05 23:28:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:28:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 286 @ 13921 updates, score 14.634) (writing took 1.9129521599970758 seconds)
2022-03-05 23:28:53 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:28:53 | INFO | train | epoch 286 | loss 0.84 | nll_loss 0.268 | ppl 1.2 | wps 27254.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13921 | lr 0.000268019 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32817
2022-03-05 23:28:53 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:30:45 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 14.622 | nll_loss 14.419 | ppl 21901.2 | wps 48313.1 | wpb 510.9 | bsz 1 | num_updates 13970 | best_loss 8.288
2022-03-05 23:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13970 updates
2022-03-05 23:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 287 @ 13970 updates, score 14.622) (writing took 1.9864237050060183 seconds)
2022-03-05 23:30:47 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:30:47 | INFO | train | epoch 287 | loss 0.839 | nll_loss 0.267 | ppl 1.2 | wps 27845.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13970 | lr 0.000267548 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32931
2022-03-05 23:30:47 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:31:53 | INFO | train_inner | epoch 288:     30 / 49 loss=0.839, nll_loss=0.267, ppl=1.2, wps=27866.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.502, loss_scale=32, train_wall=198, gb_free=21.6, wall=32997
2022-03-05 23:32:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:39 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 14.63 | nll_loss 14.426 | ppl 22004.8 | wps 48177.8 | wpb 510.9 | bsz 1 | num_updates 14018 | best_loss 8.288
2022-03-05 23:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14018 updates
2022-03-05 23:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 288 @ 14018 updates, score 14.63) (writing took 1.9415028640069067 seconds)
2022-03-05 23:32:41 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:32:41 | INFO | train | epoch 288 | loss 0.839 | nll_loss 0.268 | ppl 1.2 | wps 27270.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14018 | lr 0.00026709 | gnorm 0.504 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33045
2022-03-05 23:32:41 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:33 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 14.678 | nll_loss 14.476 | ppl 22786 | wps 48194.5 | wpb 510.9 | bsz 1 | num_updates 14067 | best_loss 8.288
2022-03-05 23:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14067 updates
2022-03-05 23:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 289 @ 14067 updates, score 14.678) (writing took 1.9534084359183908 seconds)
2022-03-05 23:34:35 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:34:35 | INFO | train | epoch 289 | loss 0.838 | nll_loss 0.267 | ppl 1.2 | wps 27827.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14067 | lr 0.000266624 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33159
2022-03-05 23:34:35 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:35:48 | INFO | train_inner | epoch 290:     33 / 49 loss=0.838, nll_loss=0.267, ppl=1.2, wps=27621.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.509, loss_scale=32, train_wall=200, gb_free=21.6, wall=33232
2022-03-05 23:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:27 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 14.599 | nll_loss 14.396 | ppl 21563.8 | wps 48044.2 | wpb 510.9 | bsz 1 | num_updates 14116 | best_loss 8.288
2022-03-05 23:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14116 updates
2022-03-05 23:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 290 @ 14116 updates, score 14.599) (writing took 1.902816851856187 seconds)
2022-03-05 23:36:29 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:36:29 | INFO | train | epoch 290 | loss 0.837 | nll_loss 0.266 | ppl 1.2 | wps 27883.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14116 | lr 0.000266161 | gnorm 0.505 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33273
2022-03-05 23:36:29 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:37:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:21 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 14.595 | nll_loss 14.389 | ppl 21456.4 | wps 48253.1 | wpb 510.9 | bsz 1 | num_updates 14164 | best_loss 8.288
2022-03-05 23:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14164 updates
2022-03-05 23:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 291 @ 14164 updates, score 14.595) (writing took 1.8219831080641598 seconds)
2022-03-05 23:38:23 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:38:23 | INFO | train | epoch 291 | loss 0.836 | nll_loss 0.265 | ppl 1.2 | wps 27317.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14164 | lr 0.000265709 | gnorm 0.513 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33387
2022-03-05 23:38:23 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:39:43 | INFO | train_inner | epoch 292:     36 / 49 loss=0.835, nll_loss=0.265, ppl=1.2, wps=27646.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.507, loss_scale=32, train_wall=200, gb_free=21.6, wall=33467
2022-03-05 23:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:15 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 14.693 | nll_loss 14.492 | ppl 23040.6 | wps 47944.3 | wpb 510.9 | bsz 1 | num_updates 14213 | best_loss 8.288
2022-03-05 23:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14213 updates
2022-03-05 23:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 292 @ 14213 updates, score 14.693) (writing took 1.9744864299427718 seconds)
2022-03-05 23:40:17 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:40:17 | INFO | train | epoch 292 | loss 0.834 | nll_loss 0.263 | ppl 1.2 | wps 27817 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14213 | lr 0.000265251 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33501
2022-03-05 23:40:17 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:09 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 14.481 | nll_loss 14.276 | ppl 19832.5 | wps 48044.8 | wpb 510.9 | bsz 1 | num_updates 14262 | best_loss 8.288
2022-03-05 23:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14262 updates
2022-03-05 23:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 293 @ 14262 updates, score 14.481) (writing took 1.7955999169498682 seconds)
2022-03-05 23:42:11 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:42:11 | INFO | train | epoch 293 | loss 0.834 | nll_loss 0.263 | ppl 1.2 | wps 27865 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14262 | lr 0.000264795 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33615
2022-03-05 23:42:11 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:42:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:43:38 | INFO | train_inner | epoch 294:     39 / 49 loss=0.833, nll_loss=0.263, ppl=1.2, wps=27613.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.5, loss_scale=32, train_wall=200, gb_free=21.6, wall=33702
2022-03-05 23:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:44:03 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 14.535 | nll_loss 14.33 | ppl 20595.2 | wps 48109.1 | wpb 510.9 | bsz 1 | num_updates 14310 | best_loss 8.288
2022-03-05 23:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14310 updates
2022-03-05 23:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 294 @ 14310 updates, score 14.535) (writing took 1.864610617980361 seconds)
2022-03-05 23:44:05 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:44:05 | INFO | train | epoch 294 | loss 0.832 | nll_loss 0.261 | ppl 1.2 | wps 27296 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14310 | lr 0.000264351 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33729
2022-03-05 23:44:05 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:45:57 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 14.668 | nll_loss 14.465 | ppl 22620.6 | wps 47924.4 | wpb 510.9 | bsz 1 | num_updates 14359 | best_loss 8.288
2022-03-05 23:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14359 updates
2022-03-05 23:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 295 @ 14359 updates, score 14.668) (writing took 2.0546389089431614 seconds)
2022-03-05 23:45:59 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:45:59 | INFO | train | epoch 295 | loss 0.831 | nll_loss 0.261 | ppl 1.2 | wps 27822.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14359 | lr 0.000263899 | gnorm 0.495 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33844
2022-03-05 23:45:59 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:47:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:47:33 | INFO | train_inner | epoch 296:     42 / 49 loss=0.831, nll_loss=0.261, ppl=1.2, wps=27618.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.495, loss_scale=32, train_wall=200, gb_free=21.6, wall=33937
2022-03-05 23:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:47:52 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 14.686 | nll_loss 14.485 | ppl 22923.2 | wps 48106.2 | wpb 510.9 | bsz 1 | num_updates 14407 | best_loss 8.288
2022-03-05 23:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14407 updates
2022-03-05 23:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 296 @ 14407 updates, score 14.686) (writing took 1.8728643811773509 seconds)
2022-03-05 23:47:53 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:47:53 | INFO | train | epoch 296 | loss 0.83 | nll_loss 0.26 | ppl 1.2 | wps 27298 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14407 | lr 0.000263459 | gnorm 0.496 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33958
2022-03-05 23:47:53 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:49:46 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 14.605 | nll_loss 14.404 | ppl 21682.9 | wps 48213 | wpb 510.9 | bsz 1 | num_updates 14456 | best_loss 8.288
2022-03-05 23:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14456 updates
2022-03-05 23:49:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 297 @ 14456 updates, score 14.605) (writing took 1.7936835249420255 seconds)
2022-03-05 23:49:47 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:49:47 | INFO | train | epoch 297 | loss 0.83 | nll_loss 0.26 | ppl 1.2 | wps 27886.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14456 | lr 0.000263012 | gnorm 0.495 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34071
2022-03-05 23:49:47 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:51:25 | INFO | train_inner | epoch 298:     44 / 49 loss=0.83, nll_loss=0.26, ppl=1.2, wps=27917.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.499, loss_scale=32, train_wall=198, gb_free=21.6, wall=34169
2022-03-05 23:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:51:40 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 14.515 | nll_loss 14.31 | ppl 20312.2 | wps 48068.9 | wpb 510.9 | bsz 1 | num_updates 14505 | best_loss 8.288
2022-03-05 23:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14505 updates
2022-03-05 23:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 298 @ 14505 updates, score 14.515) (writing took 1.943719054106623 seconds)
2022-03-05 23:51:42 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:51:42 | INFO | train | epoch 298 | loss 0.83 | nll_loss 0.26 | ppl 1.2 | wps 27860 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14505 | lr 0.000262568 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34186
2022-03-05 23:51:42 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:52:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:53:34 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 14.649 | nll_loss 14.449 | ppl 22369.7 | wps 48226.9 | wpb 510.9 | bsz 1 | num_updates 14553 | best_loss 8.288
2022-03-05 23:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14553 updates
2022-03-05 23:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 299 @ 14553 updates, score 14.649) (writing took 1.7741062119603157 seconds)
2022-03-05 23:53:35 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:53:35 | INFO | train | epoch 299 | loss 0.827 | nll_loss 0.257 | ppl 1.2 | wps 27347.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14553 | lr 0.000262134 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34299
2022-03-05 23:53:35 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:55:20 | INFO | train_inner | epoch 300:     47 / 49 loss=0.827, nll_loss=0.257, ppl=1.2, wps=27653.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.493, loss_scale=32, train_wall=200, gb_free=21.6, wall=34404
2022-03-05 23:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:27 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 14.607 | nll_loss 14.404 | ppl 21684.9 | wps 48175.2 | wpb 510.9 | bsz 1 | num_updates 14602 | best_loss 8.288
2022-03-05 23:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14602 updates
2022-03-05 23:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:55:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 300 @ 14602 updates, score 14.607) (writing took 1.7772849041502923 seconds)
2022-03-05 23:55:29 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:55:29 | INFO | train | epoch 300 | loss 0.827 | nll_loss 0.257 | ppl 1.2 | wps 27894.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14602 | lr 0.000261694 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34413
2022-03-05 23:55:29 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:21 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 14.591 | nll_loss 14.389 | ppl 21448.7 | wps 48202.4 | wpb 510.9 | bsz 1 | num_updates 14651 | best_loss 8.288
2022-03-05 23:57:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14651 updates
2022-03-05 23:57:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 301 @ 14651 updates, score 14.591) (writing took 1.8183863940648735 seconds)
2022-03-05 23:57:23 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-05 23:57:23 | INFO | train | epoch 301 | loss 0.826 | nll_loss 0.257 | ppl 1.19 | wps 27872.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14651 | lr 0.000261256 | gnorm 0.491 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 34527
2022-03-05 23:57:23 | INFO | fairseq.trainer | begin training epoch 302
2022-03-05 23:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:57:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:15 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 14.597 | nll_loss 14.395 | ppl 21551.4 | wps 48085.8 | wpb 510.9 | bsz 1 | num_updates 14699 | best_loss 8.288
2022-03-05 23:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14699 updates
2022-03-05 23:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-05 23:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 302 @ 14699 updates, score 14.597) (writing took 1.733311525080353 seconds)
2022-03-05 23:59:17 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-05 23:59:17 | INFO | train | epoch 302 | loss 0.824 | nll_loss 0.255 | ppl 1.19 | wps 27319.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14699 | lr 0.000260829 | gnorm 0.491 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34641
2022-03-05 23:59:17 | INFO | fairseq.trainer | begin training epoch 303
2022-03-05 23:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:20 | INFO | train_inner | epoch 303:      1 / 49 loss=0.825, nll_loss=0.256, ppl=1.19, wps=26893, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.492, loss_scale=32, train_wall=199, gb_free=21.6, wall=34644
2022-03-06 00:01:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:01:10 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 14.57 | nll_loss 14.37 | ppl 21170.5 | wps 48139 | wpb 510.9 | bsz 1 | num_updates 14748 | best_loss 8.288
2022-03-06 00:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14748 updates
2022-03-06 00:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 303 @ 14748 updates, score 14.57) (writing took 1.7459747330285609 seconds)
2022-03-06 00:01:11 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:01:11 | INFO | train | epoch 303 | loss 0.824 | nll_loss 0.255 | ppl 1.19 | wps 27863.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14748 | lr 0.000260395 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34755
2022-03-06 00:01:11 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:02:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:03:04 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 14.666 | nll_loss 14.467 | ppl 22642 | wps 48008.9 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 8.288
2022-03-06 00:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-06 00:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:03:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:03:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 304 @ 14796 updates, score 14.666) (writing took 1.839110563043505 seconds)
2022-03-06 00:03:05 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:03:05 | INFO | train | epoch 304 | loss 0.823 | nll_loss 0.254 | ppl 1.19 | wps 27282.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34869
2022-03-06 00:03:05 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:03:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:03:14 | INFO | train_inner | epoch 305:      4 / 49 loss=0.823, nll_loss=0.254, ppl=1.19, wps=27630.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.491, loss_scale=32, train_wall=200, gb_free=21.6, wall=34878
2022-03-06 00:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:04:58 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 14.565 | nll_loss 14.363 | ppl 21067 | wps 48166.4 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 8.288
2022-03-06 00:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-06 00:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 305 @ 14845 updates, score 14.565) (writing took 1.773240116192028 seconds)
2022-03-06 00:04:59 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:04:59 | INFO | train | epoch 305 | loss 0.822 | nll_loss 0.253 | ppl 1.19 | wps 27889.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34983
2022-03-06 00:04:59 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:06:52 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 14.482 | nll_loss 14.279 | ppl 19881.7 | wps 48081.3 | wpb 510.9 | bsz 1 | num_updates 14894 | best_loss 8.288
2022-03-06 00:06:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14894 updates
2022-03-06 00:06:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:06:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:06:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 306 @ 14894 updates, score 14.482) (writing took 1.7669291321653873 seconds)
2022-03-06 00:06:53 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:06:53 | INFO | train | epoch 306 | loss 0.821 | nll_loss 0.253 | ppl 1.19 | wps 27872.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14894 | lr 0.000259116 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35097
2022-03-06 00:06:53 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:06:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:07:07 | INFO | train_inner | epoch 307:      6 / 49 loss=0.821, nll_loss=0.253, ppl=1.19, wps=27907.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.484, loss_scale=32, train_wall=198, gb_free=21.6, wall=35111
2022-03-06 00:07:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:08:46 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 14.502 | nll_loss 14.298 | ppl 20137.9 | wps 48317.5 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 8.288
2022-03-06 00:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-06 00:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:08:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 307 @ 14942 updates, score 14.502) (writing took 1.7703790911473334 seconds)
2022-03-06 00:08:47 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:08:47 | INFO | train | epoch 307 | loss 0.821 | nll_loss 0.252 | ppl 1.19 | wps 27278.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35211
2022-03-06 00:08:47 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:08:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:10:40 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 14.562 | nll_loss 14.359 | ppl 21017.2 | wps 48261.3 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 8.288
2022-03-06 00:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-06 00:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 308 @ 14991 updates, score 14.562) (writing took 1.7451839421410114 seconds)
2022-03-06 00:10:42 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:10:42 | INFO | train | epoch 308 | loss 0.819 | nll_loss 0.251 | ppl 1.19 | wps 27860 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35326
2022-03-06 00:10:42 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:11:02 | INFO | train_inner | epoch 309:      9 / 49 loss=0.819, nll_loss=0.251, ppl=1.19, wps=27627, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.484, loss_scale=32, train_wall=200, gb_free=21.6, wall=35346
2022-03-06 00:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:12:34 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 14.518 | nll_loss 14.315 | ppl 20383 | wps 48191.9 | wpb 510.9 | bsz 1 | num_updates 15040 | best_loss 8.288
2022-03-06 00:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15040 updates
2022-03-06 00:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 309 @ 15040 updates, score 14.518) (writing took 1.8642768589779735 seconds)
2022-03-06 00:12:36 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:12:36 | INFO | train | epoch 309 | loss 0.817 | nll_loss 0.249 | ppl 1.19 | wps 27835.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15040 | lr 0.000257855 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35440
2022-03-06 00:12:36 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:14:28 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 14.554 | nll_loss 14.351 | ppl 20898.4 | wps 48002.1 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 8.288
2022-03-06 00:14:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-06 00:14:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 310 @ 15088 updates, score 14.554) (writing took 1.856494512874633 seconds)
2022-03-06 00:14:30 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:14:30 | INFO | train | epoch 310 | loss 0.817 | nll_loss 0.249 | ppl 1.19 | wps 27245.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35554
2022-03-06 00:14:30 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:14:57 | INFO | train_inner | epoch 311:     12 / 49 loss=0.817, nll_loss=0.249, ppl=1.19, wps=27598.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.484, loss_scale=32, train_wall=200, gb_free=21.6, wall=35581
2022-03-06 00:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:16:22 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 14.513 | nll_loss 14.313 | ppl 20349.8 | wps 48152.5 | wpb 510.9 | bsz 1 | num_updates 15137 | best_loss 8.288
2022-03-06 00:16:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15137 updates
2022-03-06 00:16:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 311 @ 15137 updates, score 14.513) (writing took 1.7334282689262182 seconds)
2022-03-06 00:16:24 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:16:24 | INFO | train | epoch 311 | loss 0.817 | nll_loss 0.249 | ppl 1.19 | wps 27837.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15137 | lr 0.000257028 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35668
2022-03-06 00:16:24 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:18:16 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 14.583 | nll_loss 14.38 | ppl 21314.1 | wps 48034.8 | wpb 510.9 | bsz 1 | num_updates 15186 | best_loss 8.288
2022-03-06 00:18:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15186 updates
2022-03-06 00:18:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:18:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 312 @ 15186 updates, score 14.583) (writing took 1.7450659349560738 seconds)
2022-03-06 00:18:18 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:18:18 | INFO | train | epoch 312 | loss 0.815 | nll_loss 0.247 | ppl 1.19 | wps 27842.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15186 | lr 0.000256613 | gnorm 0.478 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 35782
2022-03-06 00:18:18 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:18:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:18:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:18:52 | INFO | train_inner | epoch 313:     15 / 49 loss=0.815, nll_loss=0.248, ppl=1.19, wps=27603.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.481, loss_scale=32, train_wall=200, gb_free=21.6, wall=35816
2022-03-06 00:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:11 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 14.614 | nll_loss 14.415 | ppl 21849.3 | wps 48135.4 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 8.288
2022-03-06 00:20:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-06 00:20:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:20:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 313 @ 15234 updates, score 14.614) (writing took 1.8142917819786817 seconds)
2022-03-06 00:20:12 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:20:12 | INFO | train | epoch 313 | loss 0.814 | nll_loss 0.246 | ppl 1.19 | wps 27244 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35897
2022-03-06 00:20:12 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:05 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 14.508 | nll_loss 14.305 | ppl 20247.5 | wps 48004.6 | wpb 510.9 | bsz 1 | num_updates 15283 | best_loss 8.288
2022-03-06 00:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15283 updates
2022-03-06 00:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 314 @ 15283 updates, score 14.508) (writing took 1.7488359450362623 seconds)
2022-03-06 00:22:07 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:22:07 | INFO | train | epoch 314 | loss 0.812 | nll_loss 0.245 | ppl 1.19 | wps 27849.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15283 | lr 0.000255797 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36011
2022-03-06 00:22:07 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:22:44 | INFO | train_inner | epoch 315:     17 / 49 loss=0.813, nll_loss=0.246, ppl=1.19, wps=27870.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.476, loss_scale=32, train_wall=198, gb_free=21.6, wall=36048
2022-03-06 00:23:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:23:59 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 14.516 | nll_loss 14.315 | ppl 20383.8 | wps 48058.1 | wpb 510.9 | bsz 1 | num_updates 15331 | best_loss 8.288
2022-03-06 00:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15331 updates
2022-03-06 00:23:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 315 @ 15331 updates, score 14.516) (writing took 1.9010805450379848 seconds)
2022-03-06 00:24:01 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:24:01 | INFO | train | epoch 315 | loss 0.812 | nll_loss 0.245 | ppl 1.19 | wps 27245.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15331 | lr 0.000255396 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36125
2022-03-06 00:24:01 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:24:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:25:53 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 14.483 | nll_loss 14.279 | ppl 19876 | wps 48092.6 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 8.288
2022-03-06 00:25:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-06 00:25:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:25:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:25:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 316 @ 15380 updates, score 14.483) (writing took 1.9234825382009149 seconds)
2022-03-06 00:25:55 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:25:55 | INFO | train | epoch 316 | loss 0.811 | nll_loss 0.245 | ppl 1.18 | wps 27841.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36239
2022-03-06 00:25:55 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:26:39 | INFO | train_inner | epoch 317:     20 / 49 loss=0.811, nll_loss=0.245, ppl=1.18, wps=27601.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.475, loss_scale=32, train_wall=200, gb_free=21.6, wall=36283
2022-03-06 00:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:27:47 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 14.6 | nll_loss 14.4 | ppl 21616.9 | wps 48204.2 | wpb 510.9 | bsz 1 | num_updates 15429 | best_loss 8.288
2022-03-06 00:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15429 updates
2022-03-06 00:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 317 @ 15429 updates, score 14.6) (writing took 1.8896960271522403 seconds)
2022-03-06 00:27:49 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:27:49 | INFO | train | epoch 317 | loss 0.81 | nll_loss 0.244 | ppl 1.18 | wps 27806.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15429 | lr 0.000254584 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36353
2022-03-06 00:27:49 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:28:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:29:42 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 14.566 | nll_loss 14.367 | ppl 21130.5 | wps 48019.3 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 8.288
2022-03-06 00:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-06 00:29:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 318 @ 15477 updates, score 14.566) (writing took 1.894170920131728 seconds)
2022-03-06 00:29:44 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:29:44 | INFO | train | epoch 318 | loss 0.809 | nll_loss 0.243 | ppl 1.18 | wps 27221.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.476 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36468
2022-03-06 00:29:44 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:30:35 | INFO | train_inner | epoch 319:     23 / 49 loss=0.809, nll_loss=0.243, ppl=1.18, wps=27559.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.474, loss_scale=32, train_wall=200, gb_free=21.6, wall=36519
2022-03-06 00:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:31:36 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 14.527 | nll_loss 14.327 | ppl 20546.3 | wps 47968.2 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 8.288
2022-03-06 00:31:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-06 00:31:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 319 @ 15526 updates, score 14.527) (writing took 1.9537407218012959 seconds)
2022-03-06 00:31:38 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:31:38 | INFO | train | epoch 319 | loss 0.809 | nll_loss 0.243 | ppl 1.18 | wps 27773.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.475 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36582
2022-03-06 00:31:38 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:31:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:33:31 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 14.559 | nll_loss 14.36 | ppl 21020.7 | wps 47908.8 | wpb 510.9 | bsz 1 | num_updates 15575 | best_loss 8.288
2022-03-06 00:33:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15575 updates
2022-03-06 00:33:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:33:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 320 @ 15575 updates, score 14.559) (writing took 2.0432783749420196 seconds)
2022-03-06 00:33:33 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:33:33 | INFO | train | epoch 320 | loss 0.807 | nll_loss 0.241 | ppl 1.18 | wps 27729.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15575 | lr 0.000253388 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36697
2022-03-06 00:33:33 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:34:30 | INFO | train_inner | epoch 321:     26 / 49 loss=0.808, nll_loss=0.242, ppl=1.18, wps=27524.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.474, loss_scale=32, train_wall=200, gb_free=21.6, wall=36755
2022-03-06 00:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:35:25 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 14.55 | nll_loss 14.351 | ppl 20903.3 | wps 47975.9 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 8.288
2022-03-06 00:35:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-06 00:35:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 321 @ 15623 updates, score 14.55) (writing took 1.9920505320187658 seconds)
2022-03-06 00:35:27 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:35:27 | INFO | train | epoch 321 | loss 0.806 | nll_loss 0.24 | ppl 1.18 | wps 27183.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36811
2022-03-06 00:35:27 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:37:20 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 14.566 | nll_loss 14.369 | ppl 21154.6 | wps 47952 | wpb 510.9 | bsz 1 | num_updates 15672 | best_loss 8.288
2022-03-06 00:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15672 updates
2022-03-06 00:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:37:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 322 @ 15672 updates, score 14.566) (writing took 1.9318433569278568 seconds)
2022-03-06 00:37:22 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:37:22 | INFO | train | epoch 322 | loss 0.806 | nll_loss 0.24 | ppl 1.18 | wps 27753.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15672 | lr 0.000252603 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36926
2022-03-06 00:37:22 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:38:24 | INFO | train_inner | epoch 323:     28 / 49 loss=0.806, nll_loss=0.241, ppl=1.18, wps=27791.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.47, loss_scale=32, train_wall=198, gb_free=21.6, wall=36988
2022-03-06 00:38:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:39:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:39:14 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 14.516 | nll_loss 14.317 | ppl 20413.7 | wps 47823.6 | wpb 510.9 | bsz 1 | num_updates 15720 | best_loss 8.288
2022-03-06 00:39:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15720 updates
2022-03-06 00:39:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 323 @ 15720 updates, score 14.516) (writing took 1.9835289728362113 seconds)
2022-03-06 00:39:16 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:39:16 | INFO | train | epoch 323 | loss 0.806 | nll_loss 0.24 | ppl 1.18 | wps 27185.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15720 | lr 0.000252217 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37040
2022-03-06 00:39:16 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:41:09 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 14.482 | nll_loss 14.283 | ppl 19931.2 | wps 47983 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 8.288
2022-03-06 00:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-06 00:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 324 @ 15769 updates, score 14.482) (writing took 1.9595905058085918 seconds)
2022-03-06 00:41:11 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:41:11 | INFO | train | epoch 324 | loss 0.805 | nll_loss 0.239 | ppl 1.18 | wps 27752.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37155
2022-03-06 00:41:11 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:20 | INFO | train_inner | epoch 325:     31 / 49 loss=0.804, nll_loss=0.239, ppl=1.18, wps=27514.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.47, loss_scale=32, train_wall=200, gb_free=21.6, wall=37224
2022-03-06 00:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:43:03 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 14.545 | nll_loss 14.346 | ppl 20821.3 | wps 47931.8 | wpb 510.9 | bsz 1 | num_updates 15818 | best_loss 8.288
2022-03-06 00:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15818 updates
2022-03-06 00:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 325 @ 15818 updates, score 14.545) (writing took 1.92078384780325 seconds)
2022-03-06 00:43:05 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:43:05 | INFO | train | epoch 325 | loss 0.804 | nll_loss 0.238 | ppl 1.18 | wps 27745.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15818 | lr 0.000251434 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37269
2022-03-06 00:43:05 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:43:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:44:58 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 14.506 | nll_loss 14.306 | ppl 20259.1 | wps 48041 | wpb 510.9 | bsz 1 | num_updates 15866 | best_loss 8.288
2022-03-06 00:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15866 updates
2022-03-06 00:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 326 @ 15866 updates, score 14.506) (writing took 1.9222154808230698 seconds)
2022-03-06 00:45:00 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:45:00 | INFO | train | epoch 326 | loss 0.803 | nll_loss 0.237 | ppl 1.18 | wps 27196.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15866 | lr 0.000251053 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37384
2022-03-06 00:45:00 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:46:15 | INFO | train_inner | epoch 327:     34 / 49 loss=0.803, nll_loss=0.238, ppl=1.18, wps=27537.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.466, loss_scale=32, train_wall=200, gb_free=21.6, wall=37459
2022-03-06 00:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:46:52 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 14.503 | nll_loss 14.305 | ppl 20234.4 | wps 47923.8 | wpb 510.9 | bsz 1 | num_updates 15915 | best_loss 8.288
2022-03-06 00:46:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15915 updates
2022-03-06 00:46:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:46:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:46:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 327 @ 15915 updates, score 14.503) (writing took 1.8877675239928067 seconds)
2022-03-06 00:46:54 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:46:54 | INFO | train | epoch 327 | loss 0.802 | nll_loss 0.237 | ppl 1.18 | wps 27783.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15915 | lr 0.000250667 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37498
2022-03-06 00:46:54 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:46:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:48:47 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 14.588 | nll_loss 14.391 | ppl 21478 | wps 47982.8 | wpb 510.9 | bsz 1 | num_updates 15964 | best_loss 8.288
2022-03-06 00:48:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15964 updates
2022-03-06 00:48:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 328 @ 15964 updates, score 14.588) (writing took 1.927194532006979 seconds)
2022-03-06 00:48:49 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:48:49 | INFO | train | epoch 328 | loss 0.801 | nll_loss 0.236 | ppl 1.18 | wps 27738.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15964 | lr 0.000250282 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37613
2022-03-06 00:48:49 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:49:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:50:11 | INFO | train_inner | epoch 329:     37 / 49 loss=0.801, nll_loss=0.236, ppl=1.18, wps=27523.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.464, loss_scale=32, train_wall=200, gb_free=21.6, wall=37695
2022-03-06 00:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:50:41 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 14.47 | nll_loss 14.27 | ppl 19750.8 | wps 47941.1 | wpb 510.9 | bsz 1 | num_updates 16012 | best_loss 8.288
2022-03-06 00:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16012 updates
2022-03-06 00:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 329 @ 16012 updates, score 14.47) (writing took 1.921767990104854 seconds)
2022-03-06 00:50:43 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:50:43 | INFO | train | epoch 329 | loss 0.8 | nll_loss 0.235 | ppl 1.18 | wps 27187.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16012 | lr 0.000249906 | gnorm 0.464 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37727
2022-03-06 00:50:43 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:52:36 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 14.601 | nll_loss 14.404 | ppl 21671.5 | wps 48083.9 | wpb 510.9 | bsz 1 | num_updates 16061 | best_loss 8.288
2022-03-06 00:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16061 updates
2022-03-06 00:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 330 @ 16061 updates, score 14.601) (writing took 1.8995889239013195 seconds)
2022-03-06 00:52:38 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:52:38 | INFO | train | epoch 330 | loss 0.799 | nll_loss 0.235 | ppl 1.18 | wps 27773 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16061 | lr 0.000249525 | gnorm 0.461 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37842
2022-03-06 00:52:38 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:54:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:54:07 | INFO | train_inner | epoch 331:     40 / 49 loss=0.799, nll_loss=0.235, ppl=1.18, wps=27535.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.466, loss_scale=32, train_wall=200, gb_free=21.6, wall=37931
2022-03-06 00:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:54:30 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 14.492 | nll_loss 14.293 | ppl 20077.1 | wps 47970.7 | wpb 510.9 | bsz 1 | num_updates 16109 | best_loss 8.288
2022-03-06 00:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16109 updates
2022-03-06 00:54:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 331 @ 16109 updates, score 14.492) (writing took 1.83922557416372 seconds)
2022-03-06 00:54:32 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:54:32 | INFO | train | epoch 331 | loss 0.8 | nll_loss 0.235 | ppl 1.18 | wps 27192.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16109 | lr 0.000249153 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37956
2022-03-06 00:54:32 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:56:25 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 14.543 | nll_loss 14.346 | ppl 20821.8 | wps 47755.7 | wpb 510.9 | bsz 1 | num_updates 16158 | best_loss 8.288
2022-03-06 00:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16158 updates
2022-03-06 00:56:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 332 @ 16158 updates, score 14.543) (writing took 1.870740302838385 seconds)
2022-03-06 00:56:27 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 00:56:27 | INFO | train | epoch 332 | loss 0.798 | nll_loss 0.234 | ppl 1.18 | wps 27746.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16158 | lr 0.000248775 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38071
2022-03-06 00:56:27 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 00:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:58:00 | INFO | train_inner | epoch 333:     42 / 49 loss=0.798, nll_loss=0.234, ppl=1.18, wps=27801.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.462, loss_scale=32, train_wall=198, gb_free=21.6, wall=38164
2022-03-06 00:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:58:19 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 14.503 | nll_loss 14.305 | ppl 20242.4 | wps 48079.9 | wpb 510.9 | bsz 1 | num_updates 16207 | best_loss 8.288
2022-03-06 00:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16207 updates
2022-03-06 00:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 00:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 333 @ 16207 updates, score 14.503) (writing took 1.8398633908946067 seconds)
2022-03-06 00:58:21 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 00:58:21 | INFO | train | epoch 333 | loss 0.797 | nll_loss 0.233 | ppl 1.18 | wps 27807.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16207 | lr 0.000248398 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38185
2022-03-06 00:58:21 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 00:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:00:13 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 14.516 | nll_loss 14.319 | ppl 20434.5 | wps 48050.2 | wpb 510.9 | bsz 1 | num_updates 16255 | best_loss 8.288
2022-03-06 01:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16255 updates
2022-03-06 01:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 334 @ 16255 updates, score 14.516) (writing took 1.8527038570027798 seconds)
2022-03-06 01:00:15 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:00:15 | INFO | train | epoch 334 | loss 0.797 | nll_loss 0.233 | ppl 1.17 | wps 27203.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16255 | lr 0.000248031 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38299
2022-03-06 01:00:15 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:01:55 | INFO | train_inner | epoch 335:     45 / 49 loss=0.797, nll_loss=0.233, ppl=1.17, wps=27544, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.463, loss_scale=32, train_wall=200, gb_free=21.6, wall=38399
2022-03-06 01:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:02:08 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 14.524 | nll_loss 14.328 | ppl 20562.9 | wps 47986.6 | wpb 510.9 | bsz 1 | num_updates 16304 | best_loss 8.288
2022-03-06 01:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16304 updates
2022-03-06 01:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 335 @ 16304 updates, score 14.524) (writing took 1.8592761519830674 seconds)
2022-03-06 01:02:10 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:02:10 | INFO | train | epoch 335 | loss 0.796 | nll_loss 0.232 | ppl 1.17 | wps 27758.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16304 | lr 0.000247658 | gnorm 0.462 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38414
2022-03-06 01:02:10 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:02 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 14.552 | nll_loss 14.356 | ppl 20963.2 | wps 47941.7 | wpb 510.9 | bsz 1 | num_updates 16353 | best_loss 8.288
2022-03-06 01:04:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16353 updates
2022-03-06 01:04:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:04:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 336 @ 16353 updates, score 14.552) (writing took 1.8389000571332872 seconds)
2022-03-06 01:04:04 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:04:04 | INFO | train | epoch 336 | loss 0.794 | nll_loss 0.231 | ppl 1.17 | wps 27787.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16353 | lr 0.000247287 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38528
2022-03-06 01:04:04 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:04:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:05:51 | INFO | train_inner | epoch 337:     48 / 49 loss=0.795, nll_loss=0.231, ppl=1.17, wps=27545.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.46, loss_scale=32, train_wall=200, gb_free=21.6, wall=38635
2022-03-06 01:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:05:57 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 14.518 | nll_loss 14.321 | ppl 20460.2 | wps 47970.8 | wpb 510.9 | bsz 1 | num_updates 16401 | best_loss 8.288
2022-03-06 01:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16401 updates
2022-03-06 01:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 337 @ 16401 updates, score 14.518) (writing took 1.8164467841852456 seconds)
2022-03-06 01:05:59 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:05:59 | INFO | train | epoch 337 | loss 0.795 | nll_loss 0.231 | ppl 1.17 | wps 27201.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16401 | lr 0.000246925 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38643
2022-03-06 01:05:59 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:07:51 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 14.472 | nll_loss 14.276 | ppl 19834.8 | wps 48019.2 | wpb 510.9 | bsz 1 | num_updates 16450 | best_loss 8.288
2022-03-06 01:07:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16450 updates
2022-03-06 01:07:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:07:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 338 @ 16450 updates, score 14.472) (writing took 1.9103031640406698 seconds)
2022-03-06 01:07:53 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:07:53 | INFO | train | epoch 338 | loss 0.793 | nll_loss 0.23 | ppl 1.17 | wps 27760.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16450 | lr 0.000246557 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38757
2022-03-06 01:07:53 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:09:46 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 14.507 | nll_loss 14.31 | ppl 20316.8 | wps 47977.2 | wpb 510.9 | bsz 1 | num_updates 16498 | best_loss 8.288
2022-03-06 01:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16498 updates
2022-03-06 01:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 339 @ 16498 updates, score 14.507) (writing took 1.8336834679357708 seconds)
2022-03-06 01:09:47 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:09:47 | INFO | train | epoch 339 | loss 0.793 | nll_loss 0.229 | ppl 1.17 | wps 27220 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16498 | lr 0.000246198 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38871
2022-03-06 01:09:47 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:52 | INFO | train_inner | epoch 340:      2 / 49 loss=0.793, nll_loss=0.229, ppl=1.17, wps=26784.4, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.455, loss_scale=32, train_wall=199, gb_free=21.6, wall=38876
2022-03-06 01:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:11:40 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 14.459 | nll_loss 14.261 | ppl 19630 | wps 47993.1 | wpb 510.9 | bsz 1 | num_updates 16547 | best_loss 8.288
2022-03-06 01:11:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16547 updates
2022-03-06 01:11:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:11:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:11:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 340 @ 16547 updates, score 14.459) (writing took 1.8230624420102686 seconds)
2022-03-06 01:11:42 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:11:42 | INFO | train | epoch 340 | loss 0.792 | nll_loss 0.229 | ppl 1.17 | wps 27779.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16547 | lr 0.000245833 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38986
2022-03-06 01:11:42 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:11:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:13:34 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 14.499 | nll_loss 14.303 | ppl 20217.1 | wps 47946.5 | wpb 510.9 | bsz 1 | num_updates 16596 | best_loss 8.288
2022-03-06 01:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16596 updates
2022-03-06 01:13:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 341 @ 16596 updates, score 14.499) (writing took 1.857212231028825 seconds)
2022-03-06 01:13:36 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:13:36 | INFO | train | epoch 341 | loss 0.791 | nll_loss 0.228 | ppl 1.17 | wps 27746 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16596 | lr 0.00024547 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39100
2022-03-06 01:13:36 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:45 | INFO | train_inner | epoch 342:      4 / 49 loss=0.791, nll_loss=0.228, ppl=1.17, wps=27795, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.456, loss_scale=32, train_wall=198, gb_free=21.6, wall=39109
2022-03-06 01:14:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:15:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:15:29 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 14.416 | nll_loss 14.215 | ppl 19020.4 | wps 47925.7 | wpb 510.9 | bsz 1 | num_updates 16644 | best_loss 8.288
2022-03-06 01:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16644 updates
2022-03-06 01:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 342 @ 16644 updates, score 14.416) (writing took 1.8210441218689084 seconds)
2022-03-06 01:15:31 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:15:31 | INFO | train | epoch 342 | loss 0.79 | nll_loss 0.227 | ppl 1.17 | wps 27204.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16644 | lr 0.000245116 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39215
2022-03-06 01:15:31 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:17:23 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 14.52 | nll_loss 14.322 | ppl 20479.7 | wps 47939.3 | wpb 510.9 | bsz 1 | num_updates 16693 | best_loss 8.288
2022-03-06 01:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16693 updates
2022-03-06 01:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 343 @ 16693 updates, score 14.52) (writing took 1.8016989310272038 seconds)
2022-03-06 01:17:25 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:17:25 | INFO | train | epoch 343 | loss 0.789 | nll_loss 0.227 | ppl 1.17 | wps 27806.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16693 | lr 0.000244756 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39329
2022-03-06 01:17:25 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:41 | INFO | train_inner | epoch 344:      7 / 49 loss=0.79, nll_loss=0.227, ppl=1.17, wps=27562.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.452, loss_scale=32, train_wall=200, gb_free=21.6, wall=39345
2022-03-06 01:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:19:18 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 14.386 | nll_loss 14.187 | ppl 18656.1 | wps 47887.7 | wpb 510.9 | bsz 1 | num_updates 16742 | best_loss 8.288
2022-03-06 01:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16742 updates
2022-03-06 01:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 344 @ 16742 updates, score 14.386) (writing took 1.8454580740071833 seconds)
2022-03-06 01:19:19 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:19:19 | INFO | train | epoch 344 | loss 0.789 | nll_loss 0.227 | ppl 1.17 | wps 27785.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16742 | lr 0.000244397 | gnorm 0.451 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39443
2022-03-06 01:19:19 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:19:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:21:12 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 14.475 | nll_loss 14.277 | ppl 19858.6 | wps 48028.2 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 8.288
2022-03-06 01:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-06 01:21:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 345 @ 16790 updates, score 14.475) (writing took 1.8216739310882986 seconds)
2022-03-06 01:21:14 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:21:14 | INFO | train | epoch 345 | loss 0.788 | nll_loss 0.226 | ppl 1.17 | wps 27218.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39558
2022-03-06 01:21:14 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:36 | INFO | train_inner | epoch 346:     10 / 49 loss=0.788, nll_loss=0.226, ppl=1.17, wps=27561, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.45, loss_scale=32, train_wall=200, gb_free=21.6, wall=39580
2022-03-06 01:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:06 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 14.524 | nll_loss 14.33 | ppl 20593.5 | wps 48084.6 | wpb 510.9 | bsz 1 | num_updates 16839 | best_loss 8.288
2022-03-06 01:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16839 updates
2022-03-06 01:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 346 @ 16839 updates, score 14.524) (writing took 1.800053816055879 seconds)
2022-03-06 01:23:08 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:23:08 | INFO | train | epoch 346 | loss 0.787 | nll_loss 0.225 | ppl 1.17 | wps 27809.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16839 | lr 0.000243692 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39672
2022-03-06 01:23:08 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:24:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:25:01 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 14.454 | nll_loss 14.256 | ppl 19566.1 | wps 48009.1 | wpb 510.9 | bsz 1 | num_updates 16888 | best_loss 8.288
2022-03-06 01:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16888 updates
2022-03-06 01:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:25:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 347 @ 16888 updates, score 14.454) (writing took 1.8669044179841876 seconds)
2022-03-06 01:25:02 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:25:02 | INFO | train | epoch 347 | loss 0.786 | nll_loss 0.224 | ppl 1.17 | wps 27760.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16888 | lr 0.000243339 | gnorm 0.444 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 39787
2022-03-06 01:25:03 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:25:29 | INFO | train_inner | epoch 348:     12 / 49 loss=0.787, nll_loss=0.224, ppl=1.17, wps=27816.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.449, loss_scale=64, train_wall=198, gb_free=21.6, wall=39813
2022-03-06 01:25:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:26:55 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 14.536 | nll_loss 14.34 | ppl 20744.7 | wps 47956.5 | wpb 510.9 | bsz 1 | num_updates 16936 | best_loss 8.288
2022-03-06 01:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16936 updates
2022-03-06 01:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 348 @ 16936 updates, score 14.536) (writing took 1.787135090911761 seconds)
2022-03-06 01:26:57 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:26:57 | INFO | train | epoch 348 | loss 0.787 | nll_loss 0.225 | ppl 1.17 | wps 27202.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16936 | lr 0.000242993 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39901
2022-03-06 01:26:57 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:28:49 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 14.524 | nll_loss 14.328 | ppl 20573.4 | wps 48056.5 | wpb 510.9 | bsz 1 | num_updates 16985 | best_loss 8.288
2022-03-06 01:28:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16985 updates
2022-03-06 01:28:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:28:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 349 @ 16985 updates, score 14.524) (writing took 1.7647301538381726 seconds)
2022-03-06 01:28:51 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:28:51 | INFO | train | epoch 349 | loss 0.785 | nll_loss 0.223 | ppl 1.17 | wps 27809.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16985 | lr 0.000242643 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40015
2022-03-06 01:28:51 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:28:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:29:25 | INFO | train_inner | epoch 350:     15 / 49 loss=0.786, nll_loss=0.224, ppl=1.17, wps=27556.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.446, loss_scale=32, train_wall=200, gb_free=21.6, wall=40049
2022-03-06 01:30:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:30:44 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 14.483 | nll_loss 14.287 | ppl 19995.9 | wps 47883.6 | wpb 510.9 | bsz 1 | num_updates 17033 | best_loss 8.288
2022-03-06 01:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17033 updates
2022-03-06 01:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 350 @ 17033 updates, score 14.483) (writing took 1.837489628000185 seconds)
2022-03-06 01:30:46 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:30:46 | INFO | train | epoch 350 | loss 0.784 | nll_loss 0.223 | ppl 1.17 | wps 27209.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17033 | lr 0.000242301 | gnorm 0.451 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40130
2022-03-06 01:30:46 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:32:38 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 14.575 | nll_loss 14.383 | ppl 21364.4 | wps 47914.5 | wpb 510.9 | bsz 1 | num_updates 17082 | best_loss 8.288
2022-03-06 01:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17082 updates
2022-03-06 01:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 351 @ 17082 updates, score 14.575) (writing took 1.7679700828157365 seconds)
2022-03-06 01:32:40 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:32:40 | INFO | train | epoch 351 | loss 0.785 | nll_loss 0.223 | ppl 1.17 | wps 27804.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17082 | lr 0.000241953 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40244
2022-03-06 01:32:40 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:33:20 | INFO | train_inner | epoch 352:     18 / 49 loss=0.784, nll_loss=0.223, ppl=1.17, wps=27568.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.451, loss_scale=32, train_wall=200, gb_free=21.6, wall=40284
2022-03-06 01:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:34:32 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 14.505 | nll_loss 14.31 | ppl 20318 | wps 48072.2 | wpb 510.9 | bsz 1 | num_updates 17131 | best_loss 8.288
2022-03-06 01:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17131 updates
2022-03-06 01:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 352 @ 17131 updates, score 14.505) (writing took 1.7810572269372642 seconds)
2022-03-06 01:34:34 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:34:34 | INFO | train | epoch 352 | loss 0.783 | nll_loss 0.222 | ppl 1.17 | wps 27804.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17131 | lr 0.000241607 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40358
2022-03-06 01:34:34 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:35:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:36:27 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 14.438 | nll_loss 14.24 | ppl 19355.6 | wps 48033.7 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 8.288
2022-03-06 01:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-06 01:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 353 @ 17179 updates, score 14.438) (writing took 1.7470224529970437 seconds)
2022-03-06 01:36:29 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:36:29 | INFO | train | epoch 353 | loss 0.782 | nll_loss 0.221 | ppl 1.17 | wps 27211.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.441 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40473
2022-03-06 01:36:29 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:37:15 | INFO | train_inner | epoch 354:     21 / 49 loss=0.782, nll_loss=0.221, ppl=1.17, wps=27562.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.442, loss_scale=32, train_wall=200, gb_free=21.6, wall=40519
2022-03-06 01:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:38:21 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 14.399 | nll_loss 14.202 | ppl 18849.7 | wps 47928.7 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 8.288
2022-03-06 01:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-06 01:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 354 @ 17228 updates, score 14.399) (writing took 1.722039165906608 seconds)
2022-03-06 01:38:23 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:38:23 | INFO | train | epoch 354 | loss 0.782 | nll_loss 0.221 | ppl 1.17 | wps 27803.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40587
2022-03-06 01:38:23 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:40:15 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 14.452 | nll_loss 14.258 | ppl 19595.4 | wps 47990 | wpb 510.9 | bsz 1 | num_updates 17277 | best_loss 8.288
2022-03-06 01:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17277 updates
2022-03-06 01:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 355 @ 17277 updates, score 14.452) (writing took 1.7316193419974297 seconds)
2022-03-06 01:40:17 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:40:17 | INFO | train | epoch 355 | loss 0.782 | nll_loss 0.221 | ppl 1.17 | wps 27808.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17277 | lr 0.000240583 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40701
2022-03-06 01:40:17 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:41:11 | INFO | train_inner | epoch 356:     24 / 49 loss=0.782, nll_loss=0.22, ppl=1.17, wps=27570.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.448, loss_scale=32, train_wall=200, gb_free=21.6, wall=40755
2022-03-06 01:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:42:10 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 14.418 | nll_loss 14.223 | ppl 19116.4 | wps 47995.6 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.288
2022-03-06 01:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-06 01:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 356 @ 17325 updates, score 14.418) (writing took 1.7495793469715863 seconds)
2022-03-06 01:42:12 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:42:12 | INFO | train | epoch 356 | loss 0.78 | nll_loss 0.219 | ppl 1.16 | wps 27217.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40816
2022-03-06 01:42:12 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:44:04 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 14.461 | nll_loss 14.267 | ppl 19713.6 | wps 47922.6 | wpb 510.9 | bsz 1 | num_updates 17374 | best_loss 8.288
2022-03-06 01:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17374 updates
2022-03-06 01:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 357 @ 17374 updates, score 14.461) (writing took 1.7253024620003998 seconds)
2022-03-06 01:44:06 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:44:06 | INFO | train | epoch 357 | loss 0.78 | nll_loss 0.219 | ppl 1.16 | wps 27808.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17374 | lr 0.000239911 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40930
2022-03-06 01:44:06 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:45:04 | INFO | train_inner | epoch 358:     26 / 49 loss=0.78, nll_loss=0.219, ppl=1.16, wps=27837.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.443, loss_scale=32, train_wall=198, gb_free=21.6, wall=40988
2022-03-06 01:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:45:58 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 14.486 | nll_loss 14.292 | ppl 20064.5 | wps 47957.7 | wpb 510.9 | bsz 1 | num_updates 17423 | best_loss 8.288
2022-03-06 01:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17423 updates
2022-03-06 01:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 358 @ 17423 updates, score 14.486) (writing took 1.706491416087374 seconds)
2022-03-06 01:46:00 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:46:00 | INFO | train | epoch 358 | loss 0.779 | nll_loss 0.219 | ppl 1.16 | wps 27828.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17423 | lr 0.000239573 | gnorm 0.447 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 41044
2022-03-06 01:46:00 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:46:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:47:53 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 14.504 | nll_loss 14.311 | ppl 20321 | wps 48002.8 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 8.288
2022-03-06 01:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-06 01:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 359 @ 17471 updates, score 14.504) (writing took 1.726795765105635 seconds)
2022-03-06 01:47:54 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:47:54 | INFO | train | epoch 359 | loss 0.778 | nll_loss 0.218 | ppl 1.16 | wps 27242 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41158
2022-03-06 01:47:54 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:48:59 | INFO | train_inner | epoch 360:     29 / 49 loss=0.779, nll_loss=0.218, ppl=1.16, wps=27589.3, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.443, loss_scale=32, train_wall=200, gb_free=21.6, wall=41223
2022-03-06 01:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:49:47 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 14.535 | nll_loss 14.342 | ppl 20763.5 | wps 47922.1 | wpb 510.9 | bsz 1 | num_updates 17520 | best_loss 8.288
2022-03-06 01:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17520 updates
2022-03-06 01:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 360 @ 17520 updates, score 14.535) (writing took 1.718630600022152 seconds)
2022-03-06 01:49:48 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:49:48 | INFO | train | epoch 360 | loss 0.778 | nll_loss 0.218 | ppl 1.16 | wps 27821.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17520 | lr 0.000238909 | gnorm 0.447 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41273
2022-03-06 01:49:49 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:49:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:51:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:51:41 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 14.453 | nll_loss 14.258 | ppl 19598.3 | wps 48086.6 | wpb 510.9 | bsz 1 | num_updates 17568 | best_loss 8.288
2022-03-06 01:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17568 updates
2022-03-06 01:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 361 @ 17568 updates, score 14.453) (writing took 1.7011107390280813 seconds)
2022-03-06 01:51:43 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:51:43 | INFO | train | epoch 361 | loss 0.777 | nll_loss 0.216 | ppl 1.16 | wps 27241.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17568 | lr 0.000238583 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41387
2022-03-06 01:51:43 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:52:54 | INFO | train_inner | epoch 362:     32 / 49 loss=0.777, nll_loss=0.217, ppl=1.16, wps=27583.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.444, loss_scale=32, train_wall=200, gb_free=21.6, wall=41458
2022-03-06 01:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:53:35 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 14.404 | nll_loss 14.207 | ppl 18917.8 | wps 47973.1 | wpb 510.9 | bsz 1 | num_updates 17617 | best_loss 8.288
2022-03-06 01:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17617 updates
2022-03-06 01:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 362 @ 17617 updates, score 14.404) (writing took 1.7164272689260542 seconds)
2022-03-06 01:53:37 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:53:37 | INFO | train | epoch 362 | loss 0.777 | nll_loss 0.217 | ppl 1.16 | wps 27804.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17617 | lr 0.000238251 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41501
2022-03-06 01:53:37 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:55:30 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 14.418 | nll_loss 14.223 | ppl 19125.3 | wps 47967.7 | wpb 510.9 | bsz 1 | num_updates 17666 | best_loss 8.288
2022-03-06 01:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17666 updates
2022-03-06 01:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 363 @ 17666 updates, score 14.418) (writing took 1.673663005931303 seconds)
2022-03-06 01:55:31 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 01:55:31 | INFO | train | epoch 363 | loss 0.775 | nll_loss 0.215 | ppl 1.16 | wps 27802.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17666 | lr 0.00023792 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41615
2022-03-06 01:55:31 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 01:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:56:49 | INFO | train_inner | epoch 364:     35 / 49 loss=0.776, nll_loss=0.216, ppl=1.16, wps=27567.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.437, loss_scale=32, train_wall=200, gb_free=21.6, wall=41693
2022-03-06 01:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:24 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 14.482 | nll_loss 14.293 | ppl 20078.4 | wps 48017.5 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 8.288
2022-03-06 01:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-06 01:57:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 364 @ 17714 updates, score 14.482) (writing took 1.6870656691025943 seconds)
2022-03-06 01:57:26 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 01:57:26 | INFO | train | epoch 364 | loss 0.775 | nll_loss 0.215 | ppl 1.16 | wps 27230.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41730
2022-03-06 01:57:26 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 01:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:59:18 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 14.48 | nll_loss 14.288 | ppl 20005.6 | wps 48060.8 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 8.288
2022-03-06 01:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-06 01:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 01:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 365 @ 17763 updates, score 14.48) (writing took 1.7270479260478169 seconds)
2022-03-06 01:59:20 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 01:59:20 | INFO | train | epoch 365 | loss 0.774 | nll_loss 0.214 | ppl 1.16 | wps 27805.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41844
2022-03-06 01:59:20 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 01:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:00:42 | INFO | train_inner | epoch 366:     37 / 49 loss=0.774, nll_loss=0.215, ppl=1.16, wps=27849.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.434, loss_scale=32, train_wall=198, gb_free=21.6, wall=41926
2022-03-06 02:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:01:12 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 14.432 | nll_loss 14.238 | ppl 19317.9 | wps 48099.9 | wpb 510.9 | bsz 1 | num_updates 17812 | best_loss 8.288
2022-03-06 02:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17812 updates
2022-03-06 02:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 366 @ 17812 updates, score 14.432) (writing took 1.7096373490057886 seconds)
2022-03-06 02:01:14 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:01:14 | INFO | train | epoch 366 | loss 0.774 | nll_loss 0.215 | ppl 1.16 | wps 27832.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17812 | lr 0.000236943 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41958
2022-03-06 02:01:14 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:01:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:07 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 14.474 | nll_loss 14.281 | ppl 19912.7 | wps 48337.6 | wpb 510.9 | bsz 1 | num_updates 17860 | best_loss 8.288
2022-03-06 02:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17860 updates
2022-03-06 02:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 367 @ 17860 updates, score 14.474) (writing took 1.7496174771804363 seconds)
2022-03-06 02:03:08 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:03:08 | INFO | train | epoch 367 | loss 0.773 | nll_loss 0.213 | ppl 1.16 | wps 27232.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17860 | lr 0.000236624 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42073
2022-03-06 02:03:08 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:04:37 | INFO | train_inner | epoch 368:     40 / 49 loss=0.773, nll_loss=0.214, ppl=1.16, wps=27588.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.434, loss_scale=32, train_wall=200, gb_free=21.6, wall=42161
2022-03-06 02:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:01 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 14.515 | nll_loss 14.322 | ppl 20483.9 | wps 48135.9 | wpb 510.9 | bsz 1 | num_updates 17909 | best_loss 8.288
2022-03-06 02:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17909 updates
2022-03-06 02:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 368 @ 17909 updates, score 14.515) (writing took 1.6767267149407417 seconds)
2022-03-06 02:05:03 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:05:03 | INFO | train | epoch 368 | loss 0.773 | nll_loss 0.213 | ppl 1.16 | wps 27831.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17909 | lr 0.0002363 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42187
2022-03-06 02:05:03 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:06:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:06:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:06:55 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 14.373 | nll_loss 14.174 | ppl 18485.3 | wps 48116.7 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.288
2022-03-06 02:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-06 02:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:06:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 369 @ 17957 updates, score 14.373) (writing took 1.747278283117339 seconds)
2022-03-06 02:06:57 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:06:57 | INFO | train | epoch 369 | loss 0.772 | nll_loss 0.213 | ppl 1.16 | wps 27251.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42301
2022-03-06 02:06:57 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:08:33 | INFO | train_inner | epoch 370:     43 / 49 loss=0.772, nll_loss=0.213, ppl=1.16, wps=27590.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.435, loss_scale=32, train_wall=200, gb_free=21.6, wall=42397
2022-03-06 02:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:08:49 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 14.48 | nll_loss 14.286 | ppl 19978.1 | wps 48075.9 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 8.288
2022-03-06 02:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-06 02:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 370 @ 18006 updates, score 14.48) (writing took 1.7425341438502073 seconds)
2022-03-06 02:08:51 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:08:51 | INFO | train | epoch 370 | loss 0.772 | nll_loss 0.213 | ppl 1.16 | wps 27799.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42415
2022-03-06 02:08:51 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:10:44 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 14.423 | nll_loss 14.23 | ppl 19210.3 | wps 47859.1 | wpb 510.9 | bsz 1 | num_updates 18055 | best_loss 8.288
2022-03-06 02:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18055 updates
2022-03-06 02:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 371 @ 18055 updates, score 14.423) (writing took 1.7832663680892438 seconds)
2022-03-06 02:10:46 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:10:46 | INFO | train | epoch 371 | loss 0.77 | nll_loss 0.212 | ppl 1.16 | wps 27769.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18055 | lr 0.000235343 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42530
2022-03-06 02:10:46 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:12:26 | INFO | train_inner | epoch 372:     45 / 49 loss=0.77, nll_loss=0.212, ppl=1.16, wps=27820.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.432, loss_scale=64, train_wall=198, gb_free=21.6, wall=42630
2022-03-06 02:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:12:38 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 14.394 | nll_loss 14.203 | ppl 18858.7 | wps 47882.4 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.288
2022-03-06 02:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-06 02:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:12:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 372 @ 18103 updates, score 14.394) (writing took 1.6707757951226085 seconds)
2022-03-06 02:12:40 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:12:40 | INFO | train | epoch 372 | loss 0.77 | nll_loss 0.211 | ppl 1.16 | wps 27256.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42644
2022-03-06 02:12:40 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:12:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:14:32 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 14.49 | nll_loss 14.301 | ppl 20181.3 | wps 47997.4 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 8.288
2022-03-06 02:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-06 02:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 373 @ 18152 updates, score 14.49) (writing took 1.7165066190063953 seconds)
2022-03-06 02:14:34 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:14:34 | INFO | train | epoch 373 | loss 0.77 | nll_loss 0.212 | ppl 1.16 | wps 27811.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42758
2022-03-06 02:14:34 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:14:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:16:21 | INFO | train_inner | epoch 374:     48 / 49 loss=0.77, nll_loss=0.211, ppl=1.16, wps=27573.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.434, loss_scale=32, train_wall=200, gb_free=21.6, wall=42865
2022-03-06 02:16:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:16:27 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 14.381 | nll_loss 14.188 | ppl 18658.3 | wps 48067.4 | wpb 510.9 | bsz 1 | num_updates 18201 | best_loss 8.288
2022-03-06 02:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18201 updates
2022-03-06 02:16:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 374 @ 18201 updates, score 14.381) (writing took 1.8122995258308947 seconds)
2022-03-06 02:16:29 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:16:29 | INFO | train | epoch 374 | loss 0.769 | nll_loss 0.211 | ppl 1.16 | wps 27762.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18201 | lr 0.000234397 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42873
2022-03-06 02:16:29 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:17:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:18:21 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 14.389 | nll_loss 14.193 | ppl 18733.9 | wps 47794.2 | wpb 510.9 | bsz 1 | num_updates 18249 | best_loss 8.288
2022-03-06 02:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18249 updates
2022-03-06 02:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 375 @ 18249 updates, score 14.389) (writing took 1.7062633091118187 seconds)
2022-03-06 02:18:23 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:18:23 | INFO | train | epoch 375 | loss 0.768 | nll_loss 0.209 | ppl 1.16 | wps 27227.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18249 | lr 0.000234089 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42987
2022-03-06 02:18:23 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:20:15 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 14.406 | nll_loss 14.213 | ppl 18989 | wps 47893.2 | wpb 510.9 | bsz 1 | num_updates 18298 | best_loss 8.288
2022-03-06 02:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18298 updates
2022-03-06 02:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:20:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 376 @ 18298 updates, score 14.406) (writing took 1.7024021020624787 seconds)
2022-03-06 02:20:17 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:20:17 | INFO | train | epoch 376 | loss 0.767 | nll_loss 0.209 | ppl 1.16 | wps 27813.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18298 | lr 0.000233775 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43101
2022-03-06 02:20:17 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:22 | INFO | train_inner | epoch 377:      2 / 49 loss=0.768, nll_loss=0.209, ppl=1.16, wps=26814.6, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.432, loss_scale=32, train_wall=199, gb_free=21.6, wall=43106
2022-03-06 02:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:22:10 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 14.493 | nll_loss 14.301 | ppl 20185.7 | wps 47977 | wpb 510.9 | bsz 1 | num_updates 18347 | best_loss 8.288
2022-03-06 02:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18347 updates
2022-03-06 02:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 377 @ 18347 updates, score 14.493) (writing took 1.7704701549373567 seconds)
2022-03-06 02:22:12 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:22:12 | INFO | train | epoch 377 | loss 0.767 | nll_loss 0.209 | ppl 1.16 | wps 27774.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18347 | lr 0.000233463 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43216
2022-03-06 02:22:12 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:24:04 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 14.475 | nll_loss 14.285 | ppl 19969.3 | wps 47932.2 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.288
2022-03-06 02:24:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-06 02:24:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:24:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 378 @ 18395 updates, score 14.475) (writing took 1.6807314038742334 seconds)
2022-03-06 02:24:06 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:24:06 | INFO | train | epoch 378 | loss 0.766 | nll_loss 0.208 | ppl 1.16 | wps 27250.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43330
2022-03-06 02:24:06 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:17 | INFO | train_inner | epoch 379:      5 / 49 loss=0.766, nll_loss=0.208, ppl=1.16, wps=27569.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.429, loss_scale=32, train_wall=200, gb_free=21.6, wall=43341
2022-03-06 02:25:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:25:58 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 14.453 | nll_loss 14.263 | ppl 19654.6 | wps 47919.1 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 8.288
2022-03-06 02:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-06 02:25:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 379 @ 18444 updates, score 14.453) (writing took 1.6875122240744531 seconds)
2022-03-06 02:26:00 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:26:00 | INFO | train | epoch 379 | loss 0.765 | nll_loss 0.207 | ppl 1.15 | wps 27828.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43444
2022-03-06 02:26:00 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:27:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:53 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 14.437 | nll_loss 14.244 | ppl 19405.2 | wps 48054.1 | wpb 510.9 | bsz 1 | num_updates 18493 | best_loss 8.288
2022-03-06 02:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18493 updates
2022-03-06 02:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:27:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 380 @ 18493 updates, score 14.437) (writing took 1.742003601975739 seconds)
2022-03-06 02:27:54 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:27:54 | INFO | train | epoch 380 | loss 0.765 | nll_loss 0.208 | ppl 1.15 | wps 27794.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18493 | lr 0.000232539 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43558
2022-03-06 02:27:54 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:10 | INFO | train_inner | epoch 381:      7 / 49 loss=0.765, nll_loss=0.208, ppl=1.15, wps=27844.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.427, loss_scale=32, train_wall=198, gb_free=21.6, wall=43574
2022-03-06 02:28:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:29:47 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 14.404 | nll_loss 14.211 | ppl 18958.1 | wps 48034 | wpb 510.9 | bsz 1 | num_updates 18541 | best_loss 8.288
2022-03-06 02:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18541 updates
2022-03-06 02:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:29:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 381 @ 18541 updates, score 14.404) (writing took 1.6942618440371007 seconds)
2022-03-06 02:29:49 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:29:49 | INFO | train | epoch 381 | loss 0.765 | nll_loss 0.207 | ppl 1.15 | wps 27243 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18541 | lr 0.000232238 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43673
2022-03-06 02:29:49 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:31:41 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 14.432 | nll_loss 14.241 | ppl 19368.8 | wps 48048.4 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 8.288
2022-03-06 02:31:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-06 02:31:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:31:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:31:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 382 @ 18590 updates, score 14.432) (writing took 1.7228563849348575 seconds)
2022-03-06 02:31:43 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:31:43 | INFO | train | epoch 382 | loss 0.764 | nll_loss 0.207 | ppl 1.15 | wps 27797.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43787
2022-03-06 02:31:43 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:32:05 | INFO | train_inner | epoch 383:     10 / 49 loss=0.764, nll_loss=0.206, ppl=1.15, wps=27572.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.422, loss_scale=32, train_wall=200, gb_free=21.6, wall=43809
2022-03-06 02:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:33:36 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 14.456 | nll_loss 14.264 | ppl 19680.7 | wps 48080.4 | wpb 510.9 | bsz 1 | num_updates 18639 | best_loss 8.288
2022-03-06 02:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18639 updates
2022-03-06 02:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 383 @ 18639 updates, score 14.456) (writing took 1.7355628951918334 seconds)
2022-03-06 02:33:37 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:33:37 | INFO | train | epoch 383 | loss 0.764 | nll_loss 0.206 | ppl 1.15 | wps 27783.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18639 | lr 0.000231627 | gnorm 0.425 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 43901
2022-03-06 02:33:37 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:33:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:35:30 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 14.385 | nll_loss 14.189 | ppl 18681.3 | wps 48079.8 | wpb 510.9 | bsz 1 | num_updates 18687 | best_loss 8.288
2022-03-06 02:35:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18687 updates
2022-03-06 02:35:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 384 @ 18687 updates, score 14.385) (writing took 1.692295715911314 seconds)
2022-03-06 02:35:31 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:35:31 | INFO | train | epoch 384 | loss 0.764 | nll_loss 0.207 | ppl 1.15 | wps 27255.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18687 | lr 0.000231329 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44016
2022-03-06 02:35:31 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:36:00 | INFO | train_inner | epoch 385:     13 / 49 loss=0.764, nll_loss=0.206, ppl=1.15, wps=27582.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.429, loss_scale=32, train_wall=200, gb_free=21.6, wall=44044
2022-03-06 02:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:37:24 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 14.412 | nll_loss 14.219 | ppl 19066.4 | wps 48007.9 | wpb 510.9 | bsz 1 | num_updates 18736 | best_loss 8.288
2022-03-06 02:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18736 updates
2022-03-06 02:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 385 @ 18736 updates, score 14.412) (writing took 1.67868591286242 seconds)
2022-03-06 02:37:26 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:37:26 | INFO | train | epoch 385 | loss 0.763 | nll_loss 0.206 | ppl 1.15 | wps 27839.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18736 | lr 0.000231026 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44130
2022-03-06 02:37:26 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:38:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:39:18 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 14.423 | nll_loss 14.231 | ppl 19230.6 | wps 47942.1 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.288
2022-03-06 02:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18784 updates
2022-03-06 02:39:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 386 @ 18784 updates, score 14.423) (writing took 1.7518463148735464 seconds)
2022-03-06 02:39:20 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:39:20 | INFO | train | epoch 386 | loss 0.762 | nll_loss 0.205 | ppl 1.15 | wps 27224.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18784 | lr 0.000230731 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44244
2022-03-06 02:39:20 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:39:56 | INFO | train_inner | epoch 387:     16 / 49 loss=0.762, nll_loss=0.205, ppl=1.15, wps=27587, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.427, loss_scale=32, train_wall=200, gb_free=21.6, wall=44280
2022-03-06 02:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:41:12 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 14.46 | nll_loss 14.269 | ppl 19747 | wps 48452 | wpb 510.9 | bsz 1 | num_updates 18833 | best_loss 8.288
2022-03-06 02:41:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18833 updates
2022-03-06 02:41:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 387 @ 18833 updates, score 14.46) (writing took 1.7060981430113316 seconds)
2022-03-06 02:41:14 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:41:14 | INFO | train | epoch 387 | loss 0.761 | nll_loss 0.204 | ppl 1.15 | wps 27821.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18833 | lr 0.000230431 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44358
2022-03-06 02:41:14 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:43:07 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 14.373 | nll_loss 14.179 | ppl 18543.6 | wps 48629.6 | wpb 510.9 | bsz 1 | num_updates 18882 | best_loss 8.288
2022-03-06 02:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18882 updates
2022-03-06 02:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 388 @ 18882 updates, score 14.373) (writing took 1.7297656629234552 seconds)
2022-03-06 02:43:08 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:43:08 | INFO | train | epoch 388 | loss 0.761 | nll_loss 0.204 | ppl 1.15 | wps 27808.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18882 | lr 0.000230131 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44473
2022-03-06 02:43:08 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:43:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:43:49 | INFO | train_inner | epoch 389:     18 / 49 loss=0.761, nll_loss=0.204, ppl=1.15, wps=27840, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.417, loss_scale=32, train_wall=198, gb_free=21.6, wall=44513
2022-03-06 02:44:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:45:01 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 14.463 | nll_loss 14.27 | ppl 19761 | wps 47989.7 | wpb 510.9 | bsz 1 | num_updates 18930 | best_loss 8.288
2022-03-06 02:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18930 updates
2022-03-06 02:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:45:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 389 @ 18930 updates, score 14.463) (writing took 1.7418886369559914 seconds)
2022-03-06 02:45:03 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:45:03 | INFO | train | epoch 389 | loss 0.761 | nll_loss 0.204 | ppl 1.15 | wps 27225.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18930 | lr 0.00022984 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44587
2022-03-06 02:45:03 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:46:55 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 14.461 | nll_loss 14.27 | ppl 19759.5 | wps 48123.8 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 8.288
2022-03-06 02:46:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18979 updates
2022-03-06 02:46:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 390 @ 18979 updates, score 14.461) (writing took 1.6781531888991594 seconds)
2022-03-06 02:46:57 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:46:57 | INFO | train | epoch 390 | loss 0.76 | nll_loss 0.203 | ppl 1.15 | wps 27832.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18979 | lr 0.000229543 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44701
2022-03-06 02:46:57 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:47:44 | INFO | train_inner | epoch 391:     21 / 49 loss=0.76, nll_loss=0.203, ppl=1.15, wps=27587.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.42, loss_scale=32, train_wall=200, gb_free=21.6, wall=44748
2022-03-06 02:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:48:50 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 14.396 | nll_loss 14.204 | ppl 18867.1 | wps 47921.9 | wpb 510.9 | bsz 1 | num_updates 19028 | best_loss 8.288
2022-03-06 02:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19028 updates
2022-03-06 02:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:48:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:48:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 391 @ 19028 updates, score 14.396) (writing took 1.705018712207675 seconds)
2022-03-06 02:48:51 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:48:51 | INFO | train | epoch 391 | loss 0.76 | nll_loss 0.203 | ppl 1.15 | wps 27810.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19028 | lr 0.000229247 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44815
2022-03-06 02:48:51 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:48:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:49:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:50:44 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 14.515 | nll_loss 14.325 | ppl 20530.5 | wps 48068.2 | wpb 510.9 | bsz 1 | num_updates 19076 | best_loss 8.288
2022-03-06 02:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19076 updates
2022-03-06 02:50:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:50:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 392 @ 19076 updates, score 14.515) (writing took 1.7495376449078321 seconds)
2022-03-06 02:50:46 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:50:46 | INFO | train | epoch 392 | loss 0.758 | nll_loss 0.202 | ppl 1.15 | wps 27228.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19076 | lr 0.000228958 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44930
2022-03-06 02:50:46 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:50:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:51:39 | INFO | train_inner | epoch 393:     24 / 49 loss=0.759, nll_loss=0.203, ppl=1.15, wps=27578, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.42, loss_scale=32, train_wall=200, gb_free=21.6, wall=44983
2022-03-06 02:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:52:38 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 14.426 | nll_loss 14.236 | ppl 19293.9 | wps 48008.8 | wpb 510.9 | bsz 1 | num_updates 19125 | best_loss 8.288
2022-03-06 02:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19125 updates
2022-03-06 02:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 393 @ 19125 updates, score 14.426) (writing took 1.69675238779746 seconds)
2022-03-06 02:52:40 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:52:40 | INFO | train | epoch 393 | loss 0.758 | nll_loss 0.202 | ppl 1.15 | wps 27806.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19125 | lr 0.000228665 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45044
2022-03-06 02:52:40 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:54:32 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 14.333 | nll_loss 14.142 | ppl 18075.4 | wps 48033 | wpb 510.9 | bsz 1 | num_updates 19174 | best_loss 8.288
2022-03-06 02:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19174 updates
2022-03-06 02:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:54:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:54:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 394 @ 19174 updates, score 14.333) (writing took 1.7265699049457908 seconds)
2022-03-06 02:54:34 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 02:54:34 | INFO | train | epoch 394 | loss 0.758 | nll_loss 0.202 | ppl 1.15 | wps 27793.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19174 | lr 0.000228372 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45158
2022-03-06 02:54:34 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 02:54:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:55:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:55:34 | INFO | train_inner | epoch 395:     27 / 49 loss=0.758, nll_loss=0.202, ppl=1.15, wps=27561.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.418, loss_scale=32, train_wall=200, gb_free=21.6, wall=45218
2022-03-06 02:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:56:27 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 14.445 | nll_loss 14.256 | ppl 19566.8 | wps 47899.9 | wpb 510.9 | bsz 1 | num_updates 19222 | best_loss 8.288
2022-03-06 02:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19222 updates
2022-03-06 02:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 395 @ 19222 updates, score 14.445) (writing took 1.7626392832025886 seconds)
2022-03-06 02:56:29 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 02:56:29 | INFO | train | epoch 395 | loss 0.757 | nll_loss 0.201 | ppl 1.15 | wps 27209.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19222 | lr 0.000228087 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45273
2022-03-06 02:56:29 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 02:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:58:21 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 14.348 | nll_loss 14.155 | ppl 18239 | wps 48034.9 | wpb 510.9 | bsz 1 | num_updates 19271 | best_loss 8.288
2022-03-06 02:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19271 updates
2022-03-06 02:58:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:58:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 02:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 396 @ 19271 updates, score 14.348) (writing took 1.70283382688649 seconds)
2022-03-06 02:58:23 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 02:58:23 | INFO | train | epoch 396 | loss 0.757 | nll_loss 0.201 | ppl 1.15 | wps 27800 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19271 | lr 0.000227797 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45387
2022-03-06 02:58:23 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 02:58:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:59:27 | INFO | train_inner | epoch 397:     29 / 49 loss=0.757, nll_loss=0.201, ppl=1.15, wps=27824.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.42, loss_scale=32, train_wall=198, gb_free=21.6, wall=45452
2022-03-06 03:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:00:16 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 14.399 | nll_loss 14.212 | ppl 18972.4 | wps 47941.1 | wpb 510.9 | bsz 1 | num_updates 19320 | best_loss 8.288
2022-03-06 03:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19320 updates
2022-03-06 03:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:00:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 397 @ 19320 updates, score 14.399) (writing took 1.6932633819524199 seconds)
2022-03-06 03:00:17 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:00:17 | INFO | train | epoch 397 | loss 0.756 | nll_loss 0.2 | ppl 1.15 | wps 27796.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19320 | lr 0.000227508 | gnorm 0.414 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 45501
2022-03-06 03:00:17 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:00:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:00:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:02:10 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 14.43 | nll_loss 14.241 | ppl 19367.7 | wps 47952.5 | wpb 510.9 | bsz 1 | num_updates 19368 | best_loss 8.288
2022-03-06 03:02:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19368 updates
2022-03-06 03:02:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 398 @ 19368 updates, score 14.43) (writing took 1.7569525400176644 seconds)
2022-03-06 03:02:12 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:02:12 | INFO | train | epoch 398 | loss 0.755 | nll_loss 0.2 | ppl 1.15 | wps 27230.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19368 | lr 0.000227226 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45616
2022-03-06 03:02:12 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:03:23 | INFO | train_inner | epoch 399:     32 / 49 loss=0.756, nll_loss=0.2, ppl=1.15, wps=27561.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.416, loss_scale=32, train_wall=200, gb_free=21.6, wall=45687
2022-03-06 03:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:04:04 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 14.54 | nll_loss 14.353 | ppl 20931.5 | wps 47879.3 | wpb 510.9 | bsz 1 | num_updates 19417 | best_loss 8.288
2022-03-06 03:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19417 updates
2022-03-06 03:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 399 @ 19417 updates, score 14.54) (writing took 1.7250903160311282 seconds)
2022-03-06 03:04:06 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:04:06 | INFO | train | epoch 399 | loss 0.756 | nll_loss 0.2 | ppl 1.15 | wps 27780.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19417 | lr 0.000226939 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45730
2022-03-06 03:04:06 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:05:59 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 14.412 | nll_loss 14.221 | ppl 19102.5 | wps 48092.2 | wpb 510.9 | bsz 1 | num_updates 19466 | best_loss 8.288
2022-03-06 03:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19466 updates
2022-03-06 03:05:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 400 @ 19466 updates, score 14.412) (writing took 1.7041400740854442 seconds)
2022-03-06 03:06:00 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:06:00 | INFO | train | epoch 400 | loss 0.754 | nll_loss 0.199 | ppl 1.15 | wps 27794.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19466 | lr 0.000226653 | gnorm 0.411 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 45844
2022-03-06 03:06:00 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:06:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:07:18 | INFO | train_inner | epoch 401:     35 / 49 loss=0.754, nll_loss=0.199, ppl=1.15, wps=27570.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.414, loss_scale=32, train_wall=200, gb_free=21.6, wall=45922
2022-03-06 03:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:07:53 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 14.369 | nll_loss 14.179 | ppl 18550.2 | wps 47939.9 | wpb 510.9 | bsz 1 | num_updates 19514 | best_loss 8.288
2022-03-06 03:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19514 updates
2022-03-06 03:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 401 @ 19514 updates, score 14.369) (writing took 1.732377293985337 seconds)
2022-03-06 03:07:55 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:07:55 | INFO | train | epoch 401 | loss 0.754 | nll_loss 0.199 | ppl 1.15 | wps 27241 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19514 | lr 0.000226374 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45959
2022-03-06 03:07:55 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:47 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 14.42 | nll_loss 14.229 | ppl 19196.4 | wps 47998.1 | wpb 510.9 | bsz 1 | num_updates 19563 | best_loss 8.288
2022-03-06 03:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19563 updates
2022-03-06 03:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 402 @ 19563 updates, score 14.42) (writing took 1.678310563787818 seconds)
2022-03-06 03:09:49 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:09:49 | INFO | train | epoch 402 | loss 0.753 | nll_loss 0.198 | ppl 1.15 | wps 27799.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19563 | lr 0.00022609 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46073
2022-03-06 03:09:49 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:11:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:11:13 | INFO | train_inner | epoch 403:     38 / 49 loss=0.754, nll_loss=0.199, ppl=1.15, wps=27579.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.416, loss_scale=32, train_wall=200, gb_free=21.6, wall=46157
2022-03-06 03:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:11:41 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 14.45 | nll_loss 14.261 | ppl 19637.6 | wps 48054.7 | wpb 510.9 | bsz 1 | num_updates 19611 | best_loss 8.288
2022-03-06 03:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19611 updates
2022-03-06 03:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 403 @ 19611 updates, score 14.45) (writing took 1.6905756229534745 seconds)
2022-03-06 03:11:43 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:11:43 | INFO | train | epoch 403 | loss 0.753 | nll_loss 0.198 | ppl 1.15 | wps 27265.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19611 | lr 0.000225814 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46187
2022-03-06 03:11:43 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:13:36 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 14.505 | nll_loss 14.317 | ppl 20406 | wps 48091.7 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 8.288
2022-03-06 03:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-06 03:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 404 @ 19660 updates, score 14.505) (writing took 1.7294546018820256 seconds)
2022-03-06 03:13:37 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:13:37 | INFO | train | epoch 404 | loss 0.752 | nll_loss 0.198 | ppl 1.15 | wps 27825.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46301
2022-03-06 03:13:37 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:15:06 | INFO | train_inner | epoch 405:     40 / 49 loss=0.752, nll_loss=0.197, ppl=1.15, wps=27849.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.414, loss_scale=32, train_wall=198, gb_free=21.6, wall=46390
2022-03-06 03:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:15:30 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 14.446 | nll_loss 14.256 | ppl 19562.3 | wps 47815.9 | wpb 510.9 | bsz 1 | num_updates 19709 | best_loss 8.288
2022-03-06 03:15:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19709 updates
2022-03-06 03:15:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:15:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 405 @ 19709 updates, score 14.446) (writing took 1.7317245141603053 seconds)
2022-03-06 03:15:32 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:15:32 | INFO | train | epoch 405 | loss 0.752 | nll_loss 0.197 | ppl 1.15 | wps 27788.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19709 | lr 0.000225252 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46416
2022-03-06 03:15:32 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:16:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:17:24 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 14.5 | nll_loss 14.31 | ppl 20314 | wps 47917.9 | wpb 510.9 | bsz 1 | num_updates 19757 | best_loss 8.288
2022-03-06 03:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19757 updates
2022-03-06 03:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:17:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 406 @ 19757 updates, score 14.5) (writing took 1.6988321971148252 seconds)
2022-03-06 03:17:26 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:17:26 | INFO | train | epoch 406 | loss 0.752 | nll_loss 0.197 | ppl 1.15 | wps 27248.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19757 | lr 0.000224978 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46530
2022-03-06 03:17:26 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:19:02 | INFO | train_inner | epoch 407:     43 / 49 loss=0.752, nll_loss=0.197, ppl=1.15, wps=27579.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.414, loss_scale=32, train_wall=200, gb_free=21.6, wall=46626
2022-03-06 03:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:19:18 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 14.501 | nll_loss 14.312 | ppl 20345.4 | wps 47901.5 | wpb 510.9 | bsz 1 | num_updates 19806 | best_loss 8.288
2022-03-06 03:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19806 updates
2022-03-06 03:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:19:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 407 @ 19806 updates, score 14.501) (writing took 1.7375458111055195 seconds)
2022-03-06 03:19:20 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:19:20 | INFO | train | epoch 407 | loss 0.751 | nll_loss 0.197 | ppl 1.15 | wps 27802.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19806 | lr 0.000224699 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46644
2022-03-06 03:19:20 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:21:13 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 14.436 | nll_loss 14.247 | ppl 19439.7 | wps 48401.5 | wpb 510.9 | bsz 1 | num_updates 19855 | best_loss 8.288
2022-03-06 03:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19855 updates
2022-03-06 03:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 408 @ 19855 updates, score 14.436) (writing took 1.727114993846044 seconds)
2022-03-06 03:21:14 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:21:14 | INFO | train | epoch 408 | loss 0.75 | nll_loss 0.196 | ppl 1.15 | wps 27801 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19855 | lr 0.000224422 | gnorm 0.413 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 46759
2022-03-06 03:21:14 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:22:57 | INFO | train_inner | epoch 409:     46 / 49 loss=0.75, nll_loss=0.196, ppl=1.15, wps=27572.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.411, loss_scale=32, train_wall=200, gb_free=21.6, wall=46861
2022-03-06 03:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:23:07 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 14.364 | nll_loss 14.174 | ppl 18479.3 | wps 48047.7 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 8.288
2022-03-06 03:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-06 03:23:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 409 @ 19903 updates, score 14.364) (writing took 1.7019960670731962 seconds)
2022-03-06 03:23:09 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:23:09 | INFO | train | epoch 409 | loss 0.75 | nll_loss 0.195 | ppl 1.15 | wps 27239.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46873
2022-03-06 03:23:09 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:25:01 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 14.487 | nll_loss 14.299 | ppl 20162.1 | wps 48121.9 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 8.288
2022-03-06 03:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-06 03:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:25:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:25:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 410 @ 19952 updates, score 14.487) (writing took 1.7191193688195199 seconds)
2022-03-06 03:25:03 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:25:03 | INFO | train | epoch 410 | loss 0.749 | nll_loss 0.195 | ppl 1.14 | wps 27791.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46987
2022-03-06 03:25:03 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:26:50 | INFO | train_inner | epoch 411:     48 / 49 loss=0.749, nll_loss=0.195, ppl=1.14, wps=27843.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.408, loss_scale=32, train_wall=198, gb_free=21.6, wall=47094
2022-03-06 03:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:26:56 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 14.447 | nll_loss 14.258 | ppl 19594.8 | wps 48073.1 | wpb 510.9 | bsz 1 | num_updates 20001 | best_loss 8.288
2022-03-06 03:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20001 updates
2022-03-06 03:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 411 @ 20001 updates, score 14.447) (writing took 1.7030611240770668 seconds)
2022-03-06 03:26:57 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:26:57 | INFO | train | epoch 411 | loss 0.749 | nll_loss 0.195 | ppl 1.14 | wps 27836.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20001 | lr 0.000223601 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47101
2022-03-06 03:26:57 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:28:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:28:50 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 14.327 | nll_loss 14.136 | ppl 18008.2 | wps 48064.9 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 8.288
2022-03-06 03:28:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-06 03:28:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:28:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 412 @ 20049 updates, score 14.327) (writing took 1.7087512698490173 seconds)
2022-03-06 03:28:52 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:28:52 | INFO | train | epoch 412 | loss 0.749 | nll_loss 0.195 | ppl 1.14 | wps 27236.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47216
2022-03-06 03:28:52 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:30:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:30:44 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 14.485 | nll_loss 14.296 | ppl 20116.9 | wps 47976.7 | wpb 510.9 | bsz 1 | num_updates 20098 | best_loss 8.288
2022-03-06 03:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20098 updates
2022-03-06 03:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 413 @ 20098 updates, score 14.485) (writing took 1.7158321379683912 seconds)
2022-03-06 03:30:46 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:30:46 | INFO | train | epoch 413 | loss 0.749 | nll_loss 0.195 | ppl 1.14 | wps 27809.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20098 | lr 0.000223061 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47330
2022-03-06 03:30:46 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:30:50 | INFO | train_inner | epoch 414:      2 / 49 loss=0.749, nll_loss=0.195, ppl=1.14, wps=26829.6, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=20100, lr=0.00022305, gnorm=0.41, loss_scale=32, train_wall=199, gb_free=21.6, wall=47334
2022-03-06 03:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:32:38 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 14.407 | nll_loss 14.218 | ppl 19053.7 | wps 47934.2 | wpb 510.9 | bsz 1 | num_updates 20147 | best_loss 8.288
2022-03-06 03:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20147 updates
2022-03-06 03:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 414 @ 20147 updates, score 14.407) (writing took 1.704987266100943 seconds)
2022-03-06 03:32:40 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:32:40 | INFO | train | epoch 414 | loss 0.748 | nll_loss 0.194 | ppl 1.14 | wps 27816.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20147 | lr 0.00022279 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47444
2022-03-06 03:32:40 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:34:33 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 14.41 | nll_loss 14.22 | ppl 19079.7 | wps 47884.2 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 8.288
2022-03-06 03:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-06 03:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 415 @ 20195 updates, score 14.41) (writing took 1.709404608933255 seconds)
2022-03-06 03:34:34 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:34:34 | INFO | train | epoch 415 | loss 0.748 | nll_loss 0.194 | ppl 1.14 | wps 27226 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47558
2022-03-06 03:34:34 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:34:46 | INFO | train_inner | epoch 416:      5 / 49 loss=0.748, nll_loss=0.194, ppl=1.14, wps=27577.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.409, loss_scale=32, train_wall=200, gb_free=21.6, wall=47570
2022-03-06 03:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:36:27 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 14.417 | nll_loss 14.23 | ppl 19217.3 | wps 48066.2 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 8.288
2022-03-06 03:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-06 03:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 416 @ 20244 updates, score 14.417) (writing took 1.7429695720784366 seconds)
2022-03-06 03:36:29 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:36:29 | INFO | train | epoch 416 | loss 0.746 | nll_loss 0.193 | ppl 1.14 | wps 27809.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47673
2022-03-06 03:36:29 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:38:21 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 14.435 | nll_loss 14.247 | ppl 19447.2 | wps 48087.9 | wpb 510.9 | bsz 1 | num_updates 20293 | best_loss 8.288
2022-03-06 03:38:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20293 updates
2022-03-06 03:38:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 417 @ 20293 updates, score 14.435) (writing took 1.693270995048806 seconds)
2022-03-06 03:38:23 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:38:23 | INFO | train | epoch 417 | loss 0.745 | nll_loss 0.192 | ppl 1.14 | wps 27834.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20293 | lr 0.000221987 | gnorm 0.403 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 47787
2022-03-06 03:38:23 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:38:38 | INFO | train_inner | epoch 418:      7 / 49 loss=0.746, nll_loss=0.192, ppl=1.14, wps=27854.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.405, loss_scale=64, train_wall=198, gb_free=21.6, wall=47803
2022-03-06 03:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:40:15 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 14.519 | nll_loss 14.332 | ppl 20624.8 | wps 47873.8 | wpb 510.9 | bsz 1 | num_updates 20341 | best_loss 8.288
2022-03-06 03:40:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20341 updates
2022-03-06 03:40:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:40:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:40:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 418 @ 20341 updates, score 14.519) (writing took 1.7273660751525313 seconds)
2022-03-06 03:40:17 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:40:17 | INFO | train | epoch 418 | loss 0.745 | nll_loss 0.192 | ppl 1.14 | wps 27214.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20341 | lr 0.000221725 | gnorm 0.403 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47901
2022-03-06 03:40:17 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:42:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:42:10 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 14.415 | nll_loss 14.227 | ppl 19174 | wps 47518.2 | wpb 510.9 | bsz 1 | num_updates 20390 | best_loss 8.288
2022-03-06 03:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20390 updates
2022-03-06 03:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:42:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 419 @ 20390 updates, score 14.415) (writing took 1.8802481258753687 seconds)
2022-03-06 03:42:12 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:42:12 | INFO | train | epoch 419 | loss 0.746 | nll_loss 0.192 | ppl 1.14 | wps 27768.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20390 | lr 0.000221458 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48016
2022-03-06 03:42:12 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:42:34 | INFO | train_inner | epoch 420:     10 / 49 loss=0.746, nll_loss=0.192, ppl=1.14, wps=27549.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.405, loss_scale=32, train_wall=200, gb_free=21.6, wall=48038
2022-03-06 03:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:44:04 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 14.399 | nll_loss 14.21 | ppl 18954.3 | wps 47950.5 | wpb 510.9 | bsz 1 | num_updates 20439 | best_loss 8.288
2022-03-06 03:44:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20439 updates
2022-03-06 03:44:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 420 @ 20439 updates, score 14.399) (writing took 1.7172041500452906 seconds)
2022-03-06 03:44:06 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:44:06 | INFO | train | epoch 420 | loss 0.745 | nll_loss 0.192 | ppl 1.14 | wps 27823.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20439 | lr 0.000221192 | gnorm 0.405 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 48130
2022-03-06 03:44:06 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:45:58 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 14.377 | nll_loss 14.191 | ppl 18700.4 | wps 48142.5 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 8.288
2022-03-06 03:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-06 03:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 421 @ 20487 updates, score 14.377) (writing took 1.7023101530503482 seconds)
2022-03-06 03:46:00 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:46:00 | INFO | train | epoch 421 | loss 0.744 | nll_loss 0.191 | ppl 1.14 | wps 27234.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.404 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48244
2022-03-06 03:46:00 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:46:29 | INFO | train_inner | epoch 422:     13 / 49 loss=0.745, nll_loss=0.191, ppl=1.14, wps=27582, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.404, loss_scale=32, train_wall=200, gb_free=21.6, wall=48273
2022-03-06 03:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:47:53 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 14.277 | nll_loss 14.087 | ppl 17403 | wps 48086.6 | wpb 510.9 | bsz 1 | num_updates 20536 | best_loss 8.288
2022-03-06 03:47:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20536 updates
2022-03-06 03:47:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:47:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:47:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 422 @ 20536 updates, score 14.277) (writing took 1.6962351279798895 seconds)
2022-03-06 03:47:54 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:47:54 | INFO | train | epoch 422 | loss 0.745 | nll_loss 0.192 | ppl 1.14 | wps 27830.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20536 | lr 0.000220669 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48358
2022-03-06 03:47:54 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:49:47 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 14.343 | nll_loss 14.153 | ppl 18212.6 | wps 47970.5 | wpb 510.9 | bsz 1 | num_updates 20584 | best_loss 8.288
2022-03-06 03:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20584 updates
2022-03-06 03:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 423 @ 20584 updates, score 14.343) (writing took 1.7045936610084027 seconds)
2022-03-06 03:49:48 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:49:48 | INFO | train | epoch 423 | loss 0.744 | nll_loss 0.191 | ppl 1.14 | wps 27272.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20584 | lr 0.000220412 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48473
2022-03-06 03:49:48 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:50:24 | INFO | train_inner | epoch 424:     16 / 49 loss=0.744, nll_loss=0.191, ppl=1.14, wps=27605, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.408, loss_scale=32, train_wall=200, gb_free=21.6, wall=48508
2022-03-06 03:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:51:41 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 14.376 | nll_loss 14.186 | ppl 18636.3 | wps 47782.2 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 8.288
2022-03-06 03:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-06 03:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 424 @ 20633 updates, score 14.376) (writing took 1.6977206689771265 seconds)
2022-03-06 03:51:43 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:51:43 | INFO | train | epoch 424 | loss 0.743 | nll_loss 0.19 | ppl 1.14 | wps 27808.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48587
2022-03-06 03:51:43 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:53:35 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 14.449 | nll_loss 14.26 | ppl 19617.4 | wps 47813.4 | wpb 510.9 | bsz 1 | num_updates 20682 | best_loss 8.288
2022-03-06 03:53:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20682 updates
2022-03-06 03:53:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 425 @ 20682 updates, score 14.449) (writing took 1.7829864341765642 seconds)
2022-03-06 03:53:37 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 03:53:37 | INFO | train | epoch 425 | loss 0.743 | nll_loss 0.19 | ppl 1.14 | wps 27795.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20682 | lr 0.000219889 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48701
2022-03-06 03:53:37 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 03:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:54:17 | INFO | train_inner | epoch 426:     18 / 49 loss=0.743, nll_loss=0.19, ppl=1.14, wps=27846.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.408, loss_scale=64, train_wall=198, gb_free=21.6, wall=48741
2022-03-06 03:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:55:30 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 14.446 | nll_loss 14.257 | ppl 19574.3 | wps 48066.8 | wpb 510.9 | bsz 1 | num_updates 20730 | best_loss 8.288
2022-03-06 03:55:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20730 updates
2022-03-06 03:55:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 426 @ 20730 updates, score 14.446) (writing took 1.7653263311367482 seconds)
2022-03-06 03:55:31 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 03:55:31 | INFO | train | epoch 426 | loss 0.742 | nll_loss 0.189 | ppl 1.14 | wps 27257.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20730 | lr 0.000219634 | gnorm 0.403 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48815
2022-03-06 03:55:31 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 03:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:57:24 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 14.398 | nll_loss 14.211 | ppl 18963.1 | wps 47981.8 | wpb 510.9 | bsz 1 | num_updates 20779 | best_loss 8.288
2022-03-06 03:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20779 updates
2022-03-06 03:57:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:57:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 427 @ 20779 updates, score 14.398) (writing took 1.740355856018141 seconds)
2022-03-06 03:57:26 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 03:57:26 | INFO | train | epoch 427 | loss 0.742 | nll_loss 0.189 | ppl 1.14 | wps 27824.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20779 | lr 0.000219375 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48930
2022-03-06 03:57:26 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 03:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:58:12 | INFO | train_inner | epoch 428:     21 / 49 loss=0.742, nll_loss=0.189, ppl=1.14, wps=27588.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.401, loss_scale=32, train_wall=200, gb_free=21.6, wall=48976
2022-03-06 03:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:59:18 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 14.383 | nll_loss 14.195 | ppl 18752.5 | wps 47933.3 | wpb 510.9 | bsz 1 | num_updates 20828 | best_loss 8.288
2022-03-06 03:59:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20828 updates
2022-03-06 03:59:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 03:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 428 @ 20828 updates, score 14.383) (writing took 1.7810049559921026 seconds)
2022-03-06 03:59:20 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 03:59:20 | INFO | train | epoch 428 | loss 0.742 | nll_loss 0.189 | ppl 1.14 | wps 27807.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20828 | lr 0.000219117 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49044
2022-03-06 03:59:20 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 03:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:01:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:01:12 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 14.327 | nll_loss 14.14 | ppl 18051.8 | wps 47855.4 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 8.288
2022-03-06 04:01:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-06 04:01:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:01:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 429 @ 20876 updates, score 14.327) (writing took 1.6907461490482092 seconds)
2022-03-06 04:01:14 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:01:14 | INFO | train | epoch 429 | loss 0.74 | nll_loss 0.188 | ppl 1.14 | wps 27269.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.403 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49158
2022-03-06 04:01:14 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:01:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:02:07 | INFO | train_inner | epoch 430:     24 / 49 loss=0.741, nll_loss=0.189, ppl=1.14, wps=27589.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.405, loss_scale=32, train_wall=200, gb_free=21.6, wall=49211
2022-03-06 04:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:03:06 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 14.344 | nll_loss 14.154 | ppl 18233.6 | wps 47859.6 | wpb 510.9 | bsz 1 | num_updates 20925 | best_loss 8.288
2022-03-06 04:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20925 updates
2022-03-06 04:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:03:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 430 @ 20925 updates, score 14.344) (writing took 1.7086648428812623 seconds)
2022-03-06 04:03:08 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:03:08 | INFO | train | epoch 430 | loss 0.741 | nll_loss 0.188 | ppl 1.14 | wps 27825.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20925 | lr 0.000218609 | gnorm 0.401 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49272
2022-03-06 04:03:08 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:05:01 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 14.271 | nll_loss 14.081 | ppl 17326.7 | wps 47938 | wpb 510.9 | bsz 1 | num_updates 20974 | best_loss 8.288
2022-03-06 04:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20974 updates
2022-03-06 04:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:05:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 431 @ 20974 updates, score 14.271) (writing took 1.7483214470557868 seconds)
2022-03-06 04:05:02 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:05:02 | INFO | train | epoch 431 | loss 0.74 | nll_loss 0.187 | ppl 1.14 | wps 27828.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20974 | lr 0.000218353 | gnorm 0.398 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49386
2022-03-06 04:05:02 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:06:00 | INFO | train_inner | epoch 432:     26 / 49 loss=0.739, nll_loss=0.187, ppl=1.14, wps=27870.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.396, loss_scale=64, train_wall=198, gb_free=21.6, wall=49444
2022-03-06 04:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:06:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:06:55 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 14.448 | nll_loss 14.262 | ppl 19648.8 | wps 47783.4 | wpb 510.9 | bsz 1 | num_updates 21022 | best_loss 8.288
2022-03-06 04:06:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21022 updates
2022-03-06 04:06:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:06:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:06:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 432 @ 21022 updates, score 14.448) (writing took 1.7252035262063146 seconds)
2022-03-06 04:06:56 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:06:56 | INFO | train | epoch 432 | loss 0.739 | nll_loss 0.187 | ppl 1.14 | wps 27269.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21022 | lr 0.000218104 | gnorm 0.39 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49501
2022-03-06 04:06:57 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:06:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:08:49 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 14.321 | nll_loss 14.132 | ppl 17959.5 | wps 47812.2 | wpb 510.9 | bsz 1 | num_updates 21071 | best_loss 8.288
2022-03-06 04:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21071 updates
2022-03-06 04:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:08:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:08:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 433 @ 21071 updates, score 14.321) (writing took 1.7245873410720378 seconds)
2022-03-06 04:08:51 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:08:51 | INFO | train | epoch 433 | loss 0.739 | nll_loss 0.187 | ppl 1.14 | wps 27829.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21071 | lr 0.00021785 | gnorm 0.401 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49615
2022-03-06 04:08:51 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:09:55 | INFO | train_inner | epoch 434:     29 / 49 loss=0.739, nll_loss=0.187, ppl=1.14, wps=27600, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.396, loss_scale=32, train_wall=200, gb_free=21.6, wall=49679
2022-03-06 04:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:10:43 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 14.42 | nll_loss 14.233 | ppl 19260.7 | wps 47992.1 | wpb 510.9 | bsz 1 | num_updates 21120 | best_loss 8.288
2022-03-06 04:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21120 updates
2022-03-06 04:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 434 @ 21120 updates, score 14.42) (writing took 1.7300791020970792 seconds)
2022-03-06 04:10:45 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:10:45 | INFO | train | epoch 434 | loss 0.739 | nll_loss 0.187 | ppl 1.14 | wps 27822.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21120 | lr 0.000217597 | gnorm 0.396 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49729
2022-03-06 04:10:45 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:12:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:12:37 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 14.373 | nll_loss 14.181 | ppl 18575.5 | wps 47478.9 | wpb 510.9 | bsz 1 | num_updates 21168 | best_loss 8.288
2022-03-06 04:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21168 updates
2022-03-06 04:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:12:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:12:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 435 @ 21168 updates, score 14.373) (writing took 1.6758633519057184 seconds)
2022-03-06 04:12:39 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:12:39 | INFO | train | epoch 435 | loss 0.738 | nll_loss 0.186 | ppl 1.14 | wps 27283.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21168 | lr 0.00021735 | gnorm 0.393 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49843
2022-03-06 04:12:39 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:12:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:13:50 | INFO | train_inner | epoch 436:     32 / 49 loss=0.738, nll_loss=0.187, ppl=1.14, wps=27614.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.395, loss_scale=32, train_wall=200, gb_free=21.6, wall=49914
2022-03-06 04:14:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:14:31 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 14.408 | nll_loss 14.221 | ppl 19097.5 | wps 47860 | wpb 510.9 | bsz 1 | num_updates 21217 | best_loss 8.288
2022-03-06 04:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21217 updates
2022-03-06 04:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 436 @ 21217 updates, score 14.408) (writing took 1.7060830399859697 seconds)
2022-03-06 04:14:33 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:14:33 | INFO | train | epoch 436 | loss 0.738 | nll_loss 0.186 | ppl 1.14 | wps 27847.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21217 | lr 0.000217099 | gnorm 0.399 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49957
2022-03-06 04:14:33 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:16:26 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 14.359 | nll_loss 14.171 | ppl 18447.9 | wps 47825.2 | wpb 510.9 | bsz 1 | num_updates 21266 | best_loss 8.288
2022-03-06 04:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21266 updates
2022-03-06 04:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 437 @ 21266 updates, score 14.359) (writing took 1.7575087200384587 seconds)
2022-03-06 04:16:27 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:16:27 | INFO | train | epoch 437 | loss 0.737 | nll_loss 0.186 | ppl 1.14 | wps 27834.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21266 | lr 0.000216849 | gnorm 0.394 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50071
2022-03-06 04:16:27 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:17:43 | INFO | train_inner | epoch 438:     34 / 49 loss=0.737, nll_loss=0.186, ppl=1.14, wps=27868.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.396, loss_scale=64, train_wall=198, gb_free=21.6, wall=50147
2022-03-06 04:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:18:20 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 14.416 | nll_loss 14.229 | ppl 19206.7 | wps 47919.7 | wpb 510.9 | bsz 1 | num_updates 21315 | best_loss 8.288
2022-03-06 04:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21315 updates
2022-03-06 04:18:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:18:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:18:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 438 @ 21315 updates, score 14.416) (writing took 1.7079046559520066 seconds)
2022-03-06 04:18:21 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:18:21 | INFO | train | epoch 438 | loss 0.737 | nll_loss 0.186 | ppl 1.14 | wps 27844.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21315 | lr 0.000216599 | gnorm 0.394 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 50185
2022-03-06 04:18:21 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:18:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:20:14 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 14.388 | nll_loss 14.199 | ppl 18809.6 | wps 47915.7 | wpb 510.9 | bsz 1 | num_updates 21363 | best_loss 8.288
2022-03-06 04:20:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21363 updates
2022-03-06 04:20:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 439 @ 21363 updates, score 14.388) (writing took 1.7046815960202366 seconds)
2022-03-06 04:20:16 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:20:16 | INFO | train | epoch 439 | loss 0.736 | nll_loss 0.185 | ppl 1.14 | wps 27267.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21363 | lr 0.000216356 | gnorm 0.39 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50300
2022-03-06 04:20:16 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:21:38 | INFO | train_inner | epoch 440:     37 / 49 loss=0.736, nll_loss=0.185, ppl=1.14, wps=27608.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.391, loss_scale=32, train_wall=200, gb_free=21.6, wall=50382
2022-03-06 04:22:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:22:08 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 14.38 | nll_loss 14.194 | ppl 18745.7 | wps 47926.6 | wpb 510.9 | bsz 1 | num_updates 21412 | best_loss 8.288
2022-03-06 04:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21412 updates
2022-03-06 04:22:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 440 @ 21412 updates, score 14.38) (writing took 1.7557338380720466 seconds)
2022-03-06 04:22:10 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:22:10 | INFO | train | epoch 440 | loss 0.736 | nll_loss 0.185 | ppl 1.14 | wps 27817.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21412 | lr 0.000216108 | gnorm 0.392 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50414
2022-03-06 04:22:10 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:23:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:24:02 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 14.403 | nll_loss 14.216 | ppl 19025.7 | wps 47876.5 | wpb 510.9 | bsz 1 | num_updates 21460 | best_loss 8.288
2022-03-06 04:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21460 updates
2022-03-06 04:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 441 @ 21460 updates, score 14.403) (writing took 1.6991632210556418 seconds)
2022-03-06 04:24:04 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:24:04 | INFO | train | epoch 441 | loss 0.736 | nll_loss 0.185 | ppl 1.14 | wps 27240.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21460 | lr 0.000215866 | gnorm 0.4 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50528
2022-03-06 04:24:04 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:33 | INFO | train_inner | epoch 442:     40 / 49 loss=0.736, nll_loss=0.185, ppl=1.14, wps=27583.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.395, loss_scale=32, train_wall=200, gb_free=21.6, wall=50617
2022-03-06 04:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:25:57 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 14.405 | nll_loss 14.217 | ppl 19038.3 | wps 47802.3 | wpb 510.9 | bsz 1 | num_updates 21509 | best_loss 8.288
2022-03-06 04:25:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21509 updates
2022-03-06 04:25:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:25:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 442 @ 21509 updates, score 14.405) (writing took 1.6986000561155379 seconds)
2022-03-06 04:25:58 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:25:58 | INFO | train | epoch 442 | loss 0.736 | nll_loss 0.185 | ppl 1.14 | wps 27819.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21509 | lr 0.00021562 | gnorm 0.393 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50642
2022-03-06 04:25:58 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:51 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 14.423 | nll_loss 14.236 | ppl 19300.5 | wps 47941.6 | wpb 510.9 | bsz 1 | num_updates 21558 | best_loss 8.288
2022-03-06 04:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21558 updates
2022-03-06 04:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 443 @ 21558 updates, score 14.423) (writing took 1.755344995064661 seconds)
2022-03-06 04:27:53 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:27:53 | INFO | train | epoch 443 | loss 0.735 | nll_loss 0.184 | ppl 1.14 | wps 27818.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21558 | lr 0.000215375 | gnorm 0.395 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50757
2022-03-06 04:27:53 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:29:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:29:28 | INFO | train_inner | epoch 444:     43 / 49 loss=0.735, nll_loss=0.184, ppl=1.14, wps=27589.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.395, loss_scale=32, train_wall=200, gb_free=21.6, wall=50852
2022-03-06 04:29:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:45 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 14.345 | nll_loss 14.158 | ppl 18284.7 | wps 48343.8 | wpb 510.9 | bsz 1 | num_updates 21606 | best_loss 8.288
2022-03-06 04:29:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21606 updates
2022-03-06 04:29:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 444 @ 21606 updates, score 14.345) (writing took 1.6825110549107194 seconds)
2022-03-06 04:29:47 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:29:47 | INFO | train | epoch 444 | loss 0.735 | nll_loss 0.184 | ppl 1.14 | wps 27268.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21606 | lr 0.000215136 | gnorm 0.394 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50871
2022-03-06 04:29:47 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:39 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 14.392 | nll_loss 14.206 | ppl 18899 | wps 47948.6 | wpb 510.9 | bsz 1 | num_updates 21655 | best_loss 8.288
2022-03-06 04:31:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21655 updates
2022-03-06 04:31:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:31:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 445 @ 21655 updates, score 14.392) (writing took 1.7075481149367988 seconds)
2022-03-06 04:31:41 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:31:41 | INFO | train | epoch 445 | loss 0.734 | nll_loss 0.183 | ppl 1.14 | wps 27836 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21655 | lr 0.000214892 | gnorm 0.388 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50985
2022-03-06 04:31:41 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:33:21 | INFO | train_inner | epoch 446:     45 / 49 loss=0.734, nll_loss=0.184, ppl=1.14, wps=27864.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.391, loss_scale=32, train_wall=198, gb_free=21.6, wall=51085
2022-03-06 04:33:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:33 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 14.377 | nll_loss 14.192 | ppl 18716.4 | wps 47975 | wpb 510.9 | bsz 1 | num_updates 21704 | best_loss 8.288
2022-03-06 04:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21704 updates
2022-03-06 04:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 446 @ 21704 updates, score 14.377) (writing took 1.7567167410161346 seconds)
2022-03-06 04:33:35 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:33:35 | INFO | train | epoch 446 | loss 0.734 | nll_loss 0.183 | ppl 1.14 | wps 27805.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21704 | lr 0.00021465 | gnorm 0.394 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51099
2022-03-06 04:33:35 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:34:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:28 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 14.351 | nll_loss 14.163 | ppl 18338.7 | wps 47727.2 | wpb 510.9 | bsz 1 | num_updates 21752 | best_loss 8.288
2022-03-06 04:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21752 updates
2022-03-06 04:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:35:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:35:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 447 @ 21752 updates, score 14.351) (writing took 1.682106058113277 seconds)
2022-03-06 04:35:29 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:35:29 | INFO | train | epoch 447 | loss 0.733 | nll_loss 0.183 | ppl 1.13 | wps 27248.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21752 | lr 0.000214413 | gnorm 0.391 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51213
2022-03-06 04:35:29 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:37:16 | INFO | train_inner | epoch 448:     48 / 49 loss=0.733, nll_loss=0.183, ppl=1.14, wps=27586.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.392, loss_scale=32, train_wall=200, gb_free=21.6, wall=51320
2022-03-06 04:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:37:22 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 14.376 | nll_loss 14.188 | ppl 18670.2 | wps 47347.7 | wpb 510.9 | bsz 1 | num_updates 21801 | best_loss 8.288
2022-03-06 04:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21801 updates
2022-03-06 04:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 448 @ 21801 updates, score 14.376) (writing took 1.6987392879091203 seconds)
2022-03-06 04:37:24 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:37:24 | INFO | train | epoch 448 | loss 0.733 | nll_loss 0.183 | ppl 1.13 | wps 27811.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21801 | lr 0.000214172 | gnorm 0.393 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51328
2022-03-06 04:37:24 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:39:16 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 14.397 | nll_loss 14.212 | ppl 18978.1 | wps 47906.2 | wpb 510.9 | bsz 1 | num_updates 21850 | best_loss 8.288
2022-03-06 04:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21850 updates
2022-03-06 04:39:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:39:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 449 @ 21850 updates, score 14.397) (writing took 1.7575131959747523 seconds)
2022-03-06 04:39:18 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:39:18 | INFO | train | epoch 449 | loss 0.732 | nll_loss 0.182 | ppl 1.13 | wps 27815.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21850 | lr 0.000213931 | gnorm 0.388 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51442
2022-03-06 04:39:18 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:40:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:41:10 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 14.439 | nll_loss 14.254 | ppl 19534.2 | wps 47967 | wpb 510.9 | bsz 1 | num_updates 21898 | best_loss 8.288
2022-03-06 04:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21898 updates
2022-03-06 04:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 450 @ 21898 updates, score 14.439) (writing took 1.7615789419505745 seconds)
2022-03-06 04:41:12 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:41:12 | INFO | train | epoch 450 | loss 0.733 | nll_loss 0.182 | ppl 1.13 | wps 27238.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21898 | lr 0.000213697 | gnorm 0.392 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51556
2022-03-06 04:41:12 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:41:17 | INFO | train_inner | epoch 451:      2 / 49 loss=0.732, nll_loss=0.182, ppl=1.13, wps=26825.4, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=21900, lr=0.000213687, gnorm=0.391, loss_scale=32, train_wall=199, gb_free=21.6, wall=51561
2022-03-06 04:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:43:05 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 14.308 | nll_loss 14.119 | ppl 17793.3 | wps 47439.6 | wpb 510.9 | bsz 1 | num_updates 21947 | best_loss 8.288
2022-03-06 04:43:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21947 updates
2022-03-06 04:43:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:43:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 451 @ 21947 updates, score 14.308) (writing took 1.7546619330532849 seconds)
2022-03-06 04:43:07 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:43:07 | INFO | train | epoch 451 | loss 0.731 | nll_loss 0.181 | ppl 1.13 | wps 27804.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21947 | lr 0.000213458 | gnorm 0.385 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51671
2022-03-06 04:43:07 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:43:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:59 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 14.503 | nll_loss 14.319 | ppl 20438.8 | wps 47754.8 | wpb 510.9 | bsz 1 | num_updates 21996 | best_loss 8.288
2022-03-06 04:44:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21996 updates
2022-03-06 04:44:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:45:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 452 @ 21996 updates, score 14.503) (writing took 1.6707329619675875 seconds)
2022-03-06 04:45:01 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:45:01 | INFO | train | epoch 452 | loss 0.731 | nll_loss 0.181 | ppl 1.13 | wps 27820.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21996 | lr 0.00021322 | gnorm 0.392 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51785
2022-03-06 04:45:01 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:45:10 | INFO | train_inner | epoch 453:      4 / 49 loss=0.731, nll_loss=0.181, ppl=1.13, wps=27845.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.388, loss_scale=32, train_wall=198, gb_free=21.6, wall=51794
2022-03-06 04:45:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:53 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 14.417 | nll_loss 14.233 | ppl 19257 | wps 47857.6 | wpb 510.9 | bsz 1 | num_updates 22044 | best_loss 8.288
2022-03-06 04:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22044 updates
2022-03-06 04:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 453 @ 22044 updates, score 14.417) (writing took 1.753633236978203 seconds)
2022-03-06 04:46:55 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:46:55 | INFO | train | epoch 453 | loss 0.73 | nll_loss 0.18 | ppl 1.13 | wps 27238.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22044 | lr 0.000212988 | gnorm 0.384 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51899
2022-03-06 04:46:55 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:48:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:48 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 14.495 | nll_loss 14.312 | ppl 20337.4 | wps 47899.6 | wpb 510.9 | bsz 1 | num_updates 22093 | best_loss 8.288
2022-03-06 04:48:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22093 updates
2022-03-06 04:48:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 454 @ 22093 updates, score 14.495) (writing took 1.7605822139885277 seconds)
2022-03-06 04:48:49 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:48:49 | INFO | train | epoch 454 | loss 0.731 | nll_loss 0.181 | ppl 1.13 | wps 27814.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22093 | lr 0.000212752 | gnorm 0.389 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52013
2022-03-06 04:48:49 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:49:05 | INFO | train_inner | epoch 455:      7 / 49 loss=0.73, nll_loss=0.181, ppl=1.13, wps=27581.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.387, loss_scale=32, train_wall=200, gb_free=21.6, wall=52029
2022-03-06 04:50:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:42 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 14.402 | nll_loss 14.217 | ppl 19047.8 | wps 48006 | wpb 510.9 | bsz 1 | num_updates 22142 | best_loss 8.288
2022-03-06 04:50:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22142 updates
2022-03-06 04:50:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 455 @ 22142 updates, score 14.402) (writing took 1.6793879859615117 seconds)
2022-03-06 04:50:43 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:50:43 | INFO | train | epoch 455 | loss 0.73 | nll_loss 0.181 | ppl 1.13 | wps 27835.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22142 | lr 0.000212516 | gnorm 0.389 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 52128
2022-03-06 04:50:43 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:50:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:36 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 14.366 | nll_loss 14.179 | ppl 18544.4 | wps 48021 | wpb 510.9 | bsz 1 | num_updates 22190 | best_loss 8.288
2022-03-06 04:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22190 updates
2022-03-06 04:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 456 @ 22190 updates, score 14.366) (writing took 1.7451283528935164 seconds)
2022-03-06 04:52:38 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 04:52:38 | INFO | train | epoch 456 | loss 0.73 | nll_loss 0.18 | ppl 1.13 | wps 27243.6 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 22190 | lr 0.000212286 | gnorm 0.39 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52242
2022-03-06 04:52:38 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 04:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:53:00 | INFO | train_inner | epoch 457:     10 / 49 loss=0.73, nll_loss=0.18, ppl=1.13, wps=27596.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.388, loss_scale=32, train_wall=200, gb_free=21.6, wall=52264
2022-03-06 04:54:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:30 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 14.424 | nll_loss 14.237 | ppl 19309.1 | wps 47885.8 | wpb 510.9 | bsz 1 | num_updates 22239 | best_loss 8.288
2022-03-06 04:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22239 updates
2022-03-06 04:54:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:54:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:54:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 457 @ 22239 updates, score 14.424) (writing took 1.7262441939674318 seconds)
2022-03-06 04:54:32 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 04:54:32 | INFO | train | epoch 457 | loss 0.73 | nll_loss 0.18 | ppl 1.13 | wps 27822.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22239 | lr 0.000212052 | gnorm 0.388 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52356
2022-03-06 04:54:32 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 04:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:24 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 14.236 | nll_loss 14.045 | ppl 16907 | wps 47949.2 | wpb 510.9 | bsz 1 | num_updates 22287 | best_loss 8.288
2022-03-06 04:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22287 updates
2022-03-06 04:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 458 @ 22287 updates, score 14.236) (writing took 1.6953089640010148 seconds)
2022-03-06 04:56:26 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 04:56:26 | INFO | train | epoch 458 | loss 0.729 | nll_loss 0.179 | ppl 1.13 | wps 27267.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22287 | lr 0.000211824 | gnorm 0.386 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52470
2022-03-06 04:56:26 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 04:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:55 | INFO | train_inner | epoch 459:     13 / 49 loss=0.729, nll_loss=0.18, ppl=1.13, wps=27598.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.387, loss_scale=32, train_wall=200, gb_free=21.6, wall=52499
2022-03-06 04:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:19 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 14.322 | nll_loss 14.134 | ppl 17984 | wps 47996.1 | wpb 510.9 | bsz 1 | num_updates 22336 | best_loss 8.288
2022-03-06 04:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22336 updates
2022-03-06 04:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 04:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 459 @ 22336 updates, score 14.322) (writing took 1.7707042710389942 seconds)
2022-03-06 04:58:20 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 04:58:20 | INFO | train | epoch 459 | loss 0.728 | nll_loss 0.179 | ppl 1.13 | wps 27813.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22336 | lr 0.000211591 | gnorm 0.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52584
2022-03-06 04:58:20 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 04:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:00:13 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 14.386 | nll_loss 14.201 | ppl 18832.2 | wps 47898.2 | wpb 510.9 | bsz 1 | num_updates 22385 | best_loss 8.288
2022-03-06 05:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22385 updates
2022-03-06 05:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 460 @ 22385 updates, score 14.386) (writing took 1.7169184831436723 seconds)
2022-03-06 05:00:15 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:00:15 | INFO | train | epoch 460 | loss 0.729 | nll_loss 0.179 | ppl 1.13 | wps 27810.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22385 | lr 0.000211359 | gnorm 0.392 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52699
2022-03-06 05:00:15 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:00:48 | INFO | train_inner | epoch 461:     15 / 49 loss=0.728, nll_loss=0.179, ppl=1.13, wps=27843.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.388, loss_scale=32, train_wall=198, gb_free=21.6, wall=52732
2022-03-06 05:01:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:02:07 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 14.446 | nll_loss 14.264 | ppl 19676.1 | wps 47976.3 | wpb 510.9 | bsz 1 | num_updates 22433 | best_loss 8.288
2022-03-06 05:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22433 updates
2022-03-06 05:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 461 @ 22433 updates, score 14.446) (writing took 1.6989366598427296 seconds)
2022-03-06 05:02:09 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:02:09 | INFO | train | epoch 461 | loss 0.728 | nll_loss 0.178 | ppl 1.13 | wps 27229.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22433 | lr 0.000211133 | gnorm 0.388 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52813
2022-03-06 05:02:09 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:04:01 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 14.378 | nll_loss 14.193 | ppl 18727.9 | wps 47899.4 | wpb 510.9 | bsz 1 | num_updates 22482 | best_loss 8.288
2022-03-06 05:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22482 updates
2022-03-06 05:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 462 @ 22482 updates, score 14.378) (writing took 1.7804749449715018 seconds)
2022-03-06 05:04:03 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:04:03 | INFO | train | epoch 462 | loss 0.728 | nll_loss 0.179 | ppl 1.13 | wps 27812.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22482 | lr 0.000210903 | gnorm 0.388 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52927
2022-03-06 05:04:03 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:04:43 | INFO | train_inner | epoch 463:     18 / 49 loss=0.727, nll_loss=0.178, ppl=1.13, wps=27582.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.386, loss_scale=32, train_wall=200, gb_free=21.6, wall=52967
2022-03-06 05:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:05:56 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 14.451 | nll_loss 14.268 | ppl 19729.8 | wps 47941.7 | wpb 510.9 | bsz 1 | num_updates 22531 | best_loss 8.288
2022-03-06 05:05:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22531 updates
2022-03-06 05:05:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 463 @ 22531 updates, score 14.451) (writing took 1.7205872009508312 seconds)
2022-03-06 05:05:57 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:05:57 | INFO | train | epoch 463 | loss 0.727 | nll_loss 0.178 | ppl 1.13 | wps 27830.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22531 | lr 0.000210673 | gnorm 0.38 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53041
2022-03-06 05:05:57 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:07:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:50 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 14.322 | nll_loss 14.136 | ppl 18008.7 | wps 47477.4 | wpb 510.9 | bsz 1 | num_updates 22579 | best_loss 8.288
2022-03-06 05:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22579 updates
2022-03-06 05:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 464 @ 22579 updates, score 14.322) (writing took 1.708495358005166 seconds)
2022-03-06 05:07:52 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:07:52 | INFO | train | epoch 464 | loss 0.727 | nll_loss 0.178 | ppl 1.13 | wps 27256 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22579 | lr 0.000210449 | gnorm 0.386 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53156
2022-03-06 05:07:52 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:08:38 | INFO | train_inner | epoch 465:     21 / 49 loss=0.727, nll_loss=0.178, ppl=1.13, wps=27605.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.383, loss_scale=32, train_wall=200, gb_free=21.6, wall=53202
2022-03-06 05:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:44 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 14.428 | nll_loss 14.244 | ppl 19402.8 | wps 48103.3 | wpb 510.9 | bsz 1 | num_updates 22628 | best_loss 8.288
2022-03-06 05:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22628 updates
2022-03-06 05:09:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 465 @ 22628 updates, score 14.428) (writing took 1.7365823979489505 seconds)
2022-03-06 05:09:46 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:09:46 | INFO | train | epoch 465 | loss 0.726 | nll_loss 0.177 | ppl 1.13 | wps 27856 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22628 | lr 0.000210221 | gnorm 0.382 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53270
2022-03-06 05:09:46 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:38 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 14.34 | nll_loss 14.155 | ppl 18243 | wps 48260.9 | wpb 510.9 | bsz 1 | num_updates 22677 | best_loss 8.288
2022-03-06 05:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22677 updates
2022-03-06 05:11:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 466 @ 22677 updates, score 14.34) (writing took 1.6664063958451152 seconds)
2022-03-06 05:11:40 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:11:40 | INFO | train | epoch 466 | loss 0.726 | nll_loss 0.177 | ppl 1.13 | wps 27853 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22677 | lr 0.000209994 | gnorm 0.387 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53384
2022-03-06 05:11:40 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:12:33 | INFO | train_inner | epoch 467:     24 / 49 loss=0.726, nll_loss=0.177, ppl=1.13, wps=27625.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.386, loss_scale=32, train_wall=200, gb_free=21.6, wall=53437
2022-03-06 05:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:32 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 14.507 | nll_loss 14.323 | ppl 20494.9 | wps 47538.5 | wpb 510.9 | bsz 1 | num_updates 22725 | best_loss 8.288
2022-03-06 05:13:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22725 updates
2022-03-06 05:13:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 467 @ 22725 updates, score 14.507) (writing took 1.649730680976063 seconds)
2022-03-06 05:13:34 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:13:34 | INFO | train | epoch 467 | loss 0.726 | nll_loss 0.177 | ppl 1.13 | wps 27288.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22725 | lr 0.000209772 | gnorm 0.385 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53498
2022-03-06 05:13:34 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:26 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 14.351 | nll_loss 14.164 | ppl 18357.6 | wps 48005 | wpb 510.9 | bsz 1 | num_updates 22774 | best_loss 8.288
2022-03-06 05:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22774 updates
2022-03-06 05:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 468 @ 22774 updates, score 14.351) (writing took 1.709306987002492 seconds)
2022-03-06 05:15:28 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:15:28 | INFO | train | epoch 468 | loss 0.725 | nll_loss 0.177 | ppl 1.13 | wps 27849.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22774 | lr 0.000209546 | gnorm 0.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53612
2022-03-06 05:15:28 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:26 | INFO | train_inner | epoch 469:     26 / 49 loss=0.725, nll_loss=0.177, ppl=1.13, wps=27878.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.383, loss_scale=32, train_wall=198, gb_free=21.6, wall=53670
2022-03-06 05:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:17:20 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 14.454 | nll_loss 14.27 | ppl 19756.9 | wps 47995.5 | wpb 510.9 | bsz 1 | num_updates 22823 | best_loss 8.288
2022-03-06 05:17:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22823 updates
2022-03-06 05:17:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:17:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 469 @ 22823 updates, score 14.454) (writing took 1.7078616230282933 seconds)
2022-03-06 05:17:22 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:17:22 | INFO | train | epoch 469 | loss 0.725 | nll_loss 0.177 | ppl 1.13 | wps 27836.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22823 | lr 0.000209321 | gnorm 0.383 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 53726
2022-03-06 05:17:22 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:17:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:19:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:19:15 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 14.425 | nll_loss 14.242 | ppl 19372.9 | wps 47615.3 | wpb 510.9 | bsz 1 | num_updates 22871 | best_loss 8.288
2022-03-06 05:19:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22871 updates
2022-03-06 05:19:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:19:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 470 @ 22871 updates, score 14.425) (writing took 1.671238933922723 seconds)
2022-03-06 05:19:16 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:19:16 | INFO | train | epoch 470 | loss 0.725 | nll_loss 0.176 | ppl 1.13 | wps 27280.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22871 | lr 0.000209102 | gnorm 0.384 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53840
2022-03-06 05:19:16 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:21 | INFO | train_inner | epoch 471:     29 / 49 loss=0.725, nll_loss=0.176, ppl=1.13, wps=27618.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.383, loss_scale=32, train_wall=200, gb_free=21.6, wall=53905
2022-03-06 05:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:21:09 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 14.45 | nll_loss 14.267 | ppl 19711.5 | wps 48037.9 | wpb 510.9 | bsz 1 | num_updates 22920 | best_loss 8.288
2022-03-06 05:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22920 updates
2022-03-06 05:21:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:21:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 471 @ 22920 updates, score 14.45) (writing took 1.7060381881892681 seconds)
2022-03-06 05:21:10 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:21:10 | INFO | train | epoch 471 | loss 0.724 | nll_loss 0.176 | ppl 1.13 | wps 27858.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22920 | lr 0.000208878 | gnorm 0.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53954
2022-03-06 05:21:10 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:22:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:23:03 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 14.369 | nll_loss 14.183 | ppl 18596.8 | wps 47944.2 | wpb 510.9 | bsz 1 | num_updates 22968 | best_loss 8.288
2022-03-06 05:23:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22968 updates
2022-03-06 05:23:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 472 @ 22968 updates, score 14.369) (writing took 1.691256996942684 seconds)
2022-03-06 05:23:04 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:23:04 | INFO | train | epoch 472 | loss 0.724 | nll_loss 0.176 | ppl 1.13 | wps 27268.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22968 | lr 0.00020866 | gnorm 0.386 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54068
2022-03-06 05:23:04 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:24:16 | INFO | train_inner | epoch 473:     32 / 49 loss=0.724, nll_loss=0.175, ppl=1.13, wps=27617.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.383, loss_scale=32, train_wall=200, gb_free=21.6, wall=54140
2022-03-06 05:24:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:24:57 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 14.428 | nll_loss 14.245 | ppl 19422 | wps 47670.3 | wpb 510.9 | bsz 1 | num_updates 23017 | best_loss 8.288
2022-03-06 05:24:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23017 updates
2022-03-06 05:24:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:24:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:24:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 473 @ 23017 updates, score 14.428) (writing took 1.659905670909211 seconds)
2022-03-06 05:24:58 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:24:58 | INFO | train | epoch 473 | loss 0.724 | nll_loss 0.176 | ppl 1.13 | wps 27862 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23017 | lr 0.000208437 | gnorm 0.381 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54183
2022-03-06 05:24:59 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:51 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 14.394 | nll_loss 14.209 | ppl 18935.5 | wps 48077.9 | wpb 510.9 | bsz 1 | num_updates 23066 | best_loss 8.288
2022-03-06 05:26:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23066 updates
2022-03-06 05:26:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:26:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 474 @ 23066 updates, score 14.394) (writing took 1.7268938310444355 seconds)
2022-03-06 05:26:53 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:26:53 | INFO | train | epoch 474 | loss 0.724 | nll_loss 0.176 | ppl 1.13 | wps 27849.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23066 | lr 0.000208216 | gnorm 0.383 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54297
2022-03-06 05:26:53 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:27:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:28:10 | INFO | train_inner | epoch 475:     35 / 49 loss=0.724, nll_loss=0.176, ppl=1.13, wps=27623.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.382, loss_scale=32, train_wall=200, gb_free=21.6, wall=54374
2022-03-06 05:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:45 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 14.464 | nll_loss 14.28 | ppl 19889.9 | wps 47965.1 | wpb 510.9 | bsz 1 | num_updates 23114 | best_loss 8.288
2022-03-06 05:28:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23114 updates
2022-03-06 05:28:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:28:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 475 @ 23114 updates, score 14.464) (writing took 1.6807371377944946 seconds)
2022-03-06 05:28:47 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:28:47 | INFO | train | epoch 475 | loss 0.723 | nll_loss 0.175 | ppl 1.13 | wps 27268.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23114 | lr 0.000208 | gnorm 0.379 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54411
2022-03-06 05:28:47 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:28:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:39 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 14.321 | nll_loss 14.137 | ppl 18017.6 | wps 48058.7 | wpb 510.9 | bsz 1 | num_updates 23163 | best_loss 8.288
2022-03-06 05:30:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23163 updates
2022-03-06 05:30:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:30:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:30:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 476 @ 23163 updates, score 14.321) (writing took 1.6775375818833709 seconds)
2022-03-06 05:30:41 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:30:41 | INFO | train | epoch 476 | loss 0.722 | nll_loss 0.174 | ppl 1.13 | wps 27860.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23163 | lr 0.000207779 | gnorm 0.375 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54525
2022-03-06 05:30:41 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:30:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:32:03 | INFO | train_inner | epoch 477:     37 / 49 loss=0.722, nll_loss=0.174, ppl=1.13, wps=27872.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.376, loss_scale=32, train_wall=198, gb_free=21.6, wall=54607
2022-03-06 05:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:33 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 14.305 | nll_loss 14.119 | ppl 17794.2 | wps 48073.7 | wpb 510.9 | bsz 1 | num_updates 23212 | best_loss 8.288
2022-03-06 05:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23212 updates
2022-03-06 05:32:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 477 @ 23212 updates, score 14.305) (writing took 1.7012391260359436 seconds)
2022-03-06 05:32:35 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:32:35 | INFO | train | epoch 477 | loss 0.722 | nll_loss 0.174 | ppl 1.13 | wps 27841.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23212 | lr 0.00020756 | gnorm 0.378 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54639
2022-03-06 05:32:35 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:34:27 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 14.289 | nll_loss 14.102 | ppl 17589.9 | wps 48268.3 | wpb 510.9 | bsz 1 | num_updates 23260 | best_loss 8.288
2022-03-06 05:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23260 updates
2022-03-06 05:34:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:34:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:34:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 478 @ 23260 updates, score 14.289) (writing took 1.682537472108379 seconds)
2022-03-06 05:34:29 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:34:29 | INFO | train | epoch 478 | loss 0.722 | nll_loss 0.175 | ppl 1.13 | wps 27305.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23260 | lr 0.000207346 | gnorm 0.381 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54753
2022-03-06 05:34:29 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:35:58 | INFO | train_inner | epoch 479:     40 / 49 loss=0.722, nll_loss=0.174, ppl=1.13, wps=27642.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.379, loss_scale=32, train_wall=200, gb_free=21.6, wall=54842
2022-03-06 05:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:36:21 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 14.44 | nll_loss 14.257 | ppl 19585.4 | wps 48189.9 | wpb 510.9 | bsz 1 | num_updates 23309 | best_loss 8.288
2022-03-06 05:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23309 updates
2022-03-06 05:36:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:36:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 479 @ 23309 updates, score 14.44) (writing took 1.6456296918913722 seconds)
2022-03-06 05:36:23 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:36:23 | INFO | train | epoch 479 | loss 0.721 | nll_loss 0.174 | ppl 1.13 | wps 27886.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23309 | lr 0.000207128 | gnorm 0.375 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54867
2022-03-06 05:36:23 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:37:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:38:15 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 14.337 | nll_loss 14.153 | ppl 18222.3 | wps 48119.5 | wpb 510.9 | bsz 1 | num_updates 23357 | best_loss 8.288
2022-03-06 05:38:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23357 updates
2022-03-06 05:38:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 480 @ 23357 updates, score 14.337) (writing took 1.7055979799479246 seconds)
2022-03-06 05:38:17 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:38:17 | INFO | train | epoch 480 | loss 0.721 | nll_loss 0.174 | ppl 1.13 | wps 27280.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23357 | lr 0.000206915 | gnorm 0.38 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54981
2022-03-06 05:38:17 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:53 | INFO | train_inner | epoch 481:     43 / 49 loss=0.721, nll_loss=0.174, ppl=1.13, wps=27639.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.38, loss_scale=32, train_wall=200, gb_free=21.6, wall=55077
2022-03-06 05:40:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:40:09 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 14.323 | nll_loss 14.139 | ppl 18045.7 | wps 48139.7 | wpb 510.9 | bsz 1 | num_updates 23406 | best_loss 8.288
2022-03-06 05:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23406 updates
2022-03-06 05:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 481 @ 23406 updates, score 14.323) (writing took 1.6811326339375228 seconds)
2022-03-06 05:40:11 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:40:11 | INFO | train | epoch 481 | loss 0.721 | nll_loss 0.174 | ppl 1.13 | wps 27876.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23406 | lr 0.000206698 | gnorm 0.384 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55095
2022-03-06 05:40:11 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:42:03 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 14.317 | nll_loss 14.132 | ppl 17947.9 | wps 48210.4 | wpb 510.9 | bsz 1 | num_updates 23455 | best_loss 8.288
2022-03-06 05:42:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23455 updates
2022-03-06 05:42:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:42:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:42:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 482 @ 23455 updates, score 14.317) (writing took 1.6851996961049736 seconds)
2022-03-06 05:42:05 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:42:05 | INFO | train | epoch 482 | loss 0.721 | nll_loss 0.173 | ppl 1.13 | wps 27862.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23455 | lr 0.000206482 | gnorm 0.379 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55209
2022-03-06 05:42:05 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:42:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:42:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:43:47 | INFO | train_inner | epoch 483:     46 / 49 loss=0.72, nll_loss=0.173, ppl=1.13, wps=27631.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.378, loss_scale=32, train_wall=200, gb_free=21.6, wall=55311
2022-03-06 05:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:57 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 14.359 | nll_loss 14.175 | ppl 18498.5 | wps 48243.2 | wpb 510.9 | bsz 1 | num_updates 23503 | best_loss 8.288
2022-03-06 05:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23503 updates
2022-03-06 05:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 483 @ 23503 updates, score 14.359) (writing took 1.765732360072434 seconds)
2022-03-06 05:43:59 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:43:59 | INFO | train | epoch 483 | loss 0.72 | nll_loss 0.172 | ppl 1.13 | wps 27272.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23503 | lr 0.000206271 | gnorm 0.375 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55323
2022-03-06 05:43:59 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:52 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 14.371 | nll_loss 14.187 | ppl 18647.8 | wps 48266.3 | wpb 510.9 | bsz 1 | num_updates 23552 | best_loss 8.288
2022-03-06 05:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23552 updates
2022-03-06 05:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:45:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 484 @ 23552 updates, score 14.371) (writing took 1.7800948431249708 seconds)
2022-03-06 05:45:53 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:45:53 | INFO | train | epoch 484 | loss 0.72 | nll_loss 0.173 | ppl 1.13 | wps 27843 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23552 | lr 0.000206056 | gnorm 0.382 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55437
2022-03-06 05:45:53 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:45:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:40 | INFO | train_inner | epoch 485:     48 / 49 loss=0.72, nll_loss=0.173, ppl=1.13, wps=27882.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.379, loss_scale=32, train_wall=198, gb_free=21.6, wall=55544
2022-03-06 05:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:47:46 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 14.411 | nll_loss 14.227 | ppl 19171.5 | wps 48334.2 | wpb 510.9 | bsz 1 | num_updates 23601 | best_loss 8.288
2022-03-06 05:47:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23601 updates
2022-03-06 05:47:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 485 @ 23601 updates, score 14.411) (writing took 1.711704757064581 seconds)
2022-03-06 05:47:47 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:47:47 | INFO | train | epoch 485 | loss 0.719 | nll_loss 0.172 | ppl 1.13 | wps 27872.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23601 | lr 0.000205842 | gnorm 0.375 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 55551
2022-03-06 05:47:47 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:48:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:49:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:49:40 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 14.356 | nll_loss 14.171 | ppl 18441.6 | wps 48198.6 | wpb 510.9 | bsz 1 | num_updates 23649 | best_loss 8.288
2022-03-06 05:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23649 updates
2022-03-06 05:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 486 @ 23649 updates, score 14.356) (writing took 1.7391112528275698 seconds)
2022-03-06 05:49:41 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:49:41 | INFO | train | epoch 486 | loss 0.719 | nll_loss 0.172 | ppl 1.13 | wps 27296.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23649 | lr 0.000205633 | gnorm 0.375 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55665
2022-03-06 05:49:41 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:51:34 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 14.372 | nll_loss 14.187 | ppl 18649.8 | wps 48206.7 | wpb 510.9 | bsz 1 | num_updates 23698 | best_loss 8.288
2022-03-06 05:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23698 updates
2022-03-06 05:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 487 @ 23698 updates, score 14.372) (writing took 1.7198191878851503 seconds)
2022-03-06 05:51:35 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:51:35 | INFO | train | epoch 487 | loss 0.719 | nll_loss 0.172 | ppl 1.13 | wps 27871.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23698 | lr 0.000205421 | gnorm 0.373 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55779
2022-03-06 05:51:35 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:51:40 | INFO | train_inner | epoch 488:      2 / 49 loss=0.719, nll_loss=0.172, ppl=1.13, wps=26892.5, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=23700, lr=0.000205412, gnorm=0.375, loss_scale=32, train_wall=199, gb_free=21.6, wall=55784
2022-03-06 05:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:53:28 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 14.374 | nll_loss 14.192 | ppl 18712.7 | wps 48265.3 | wpb 510.9 | bsz 1 | num_updates 23747 | best_loss 8.288
2022-03-06 05:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23747 updates
2022-03-06 05:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 488 @ 23747 updates, score 14.374) (writing took 1.7126811530906707 seconds)
2022-03-06 05:53:29 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 05:53:29 | INFO | train | epoch 488 | loss 0.718 | nll_loss 0.172 | ppl 1.13 | wps 27863.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23747 | lr 0.000205209 | gnorm 0.375 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 55894
2022-03-06 05:53:30 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 05:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:54:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:55:22 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 14.418 | nll_loss 14.234 | ppl 19265.7 | wps 48300.4 | wpb 510.9 | bsz 1 | num_updates 23795 | best_loss 8.288
2022-03-06 05:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23795 updates
2022-03-06 05:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 489 @ 23795 updates, score 14.418) (writing took 1.7193242758512497 seconds)
2022-03-06 05:55:24 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 05:55:24 | INFO | train | epoch 489 | loss 0.718 | nll_loss 0.171 | ppl 1.13 | wps 27283.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23795 | lr 0.000205002 | gnorm 0.376 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56008
2022-03-06 05:55:24 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 05:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:55:35 | INFO | train_inner | epoch 490:      5 / 49 loss=0.718, nll_loss=0.171, ppl=1.13, wps=27630.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.375, loss_scale=32, train_wall=200, gb_free=21.6, wall=56019
2022-03-06 05:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:57:16 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 14.336 | nll_loss 14.151 | ppl 18195.5 | wps 48271.5 | wpb 510.9 | bsz 1 | num_updates 23844 | best_loss 8.288
2022-03-06 05:57:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23844 updates
2022-03-06 05:57:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:57:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:57:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 490 @ 23844 updates, score 14.336) (writing took 1.717288785148412 seconds)
2022-03-06 05:57:18 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 05:57:18 | INFO | train | epoch 490 | loss 0.718 | nll_loss 0.172 | ppl 1.13 | wps 27881.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23844 | lr 0.000204791 | gnorm 0.379 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56122
2022-03-06 05:57:18 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 05:57:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:59:10 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 14.425 | nll_loss 14.243 | ppl 19389.7 | wps 47915.9 | wpb 510.9 | bsz 1 | num_updates 23893 | best_loss 8.288
2022-03-06 05:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23893 updates
2022-03-06 05:59:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:59:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 05:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 491 @ 23893 updates, score 14.425) (writing took 1.6942899920977652 seconds)
2022-03-06 05:59:12 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 05:59:12 | INFO | train | epoch 491 | loss 0.718 | nll_loss 0.171 | ppl 1.13 | wps 27877.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23893 | lr 0.000204581 | gnorm 0.374 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56236
2022-03-06 05:59:12 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 05:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:59:29 | INFO | train_inner | epoch 492:      8 / 49 loss=0.718, nll_loss=0.171, ppl=1.13, wps=27649.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.377, loss_scale=32, train_wall=200, gb_free=21.6, wall=56253
2022-03-06 06:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:01:04 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 14.314 | nll_loss 14.13 | ppl 17926.1 | wps 48145.3 | wpb 510.9 | bsz 1 | num_updates 23941 | best_loss 8.288
2022-03-06 06:01:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23941 updates
2022-03-06 06:01:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:01:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:01:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 492 @ 23941 updates, score 14.314) (writing took 1.7440475998446345 seconds)
2022-03-06 06:01:06 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:01:06 | INFO | train | epoch 492 | loss 0.718 | nll_loss 0.171 | ppl 1.13 | wps 27285.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23941 | lr 0.000204376 | gnorm 0.378 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56350
2022-03-06 06:01:06 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:58 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 14.333 | nll_loss 14.149 | ppl 18167.4 | wps 48312.9 | wpb 510.9 | bsz 1 | num_updates 23990 | best_loss 8.288
2022-03-06 06:02:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23990 updates
2022-03-06 06:02:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:02:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 493 @ 23990 updates, score 14.333) (writing took 1.696300479117781 seconds)
2022-03-06 06:03:00 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:03:00 | INFO | train | epoch 493 | loss 0.717 | nll_loss 0.17 | ppl 1.13 | wps 27897.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23990 | lr 0.000204167 | gnorm 0.373 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56464
2022-03-06 06:03:00 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:03:22 | INFO | train_inner | epoch 494:     10 / 49 loss=0.717, nll_loss=0.171, ppl=1.13, wps=27903.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.374, loss_scale=32, train_wall=198, gb_free=21.6, wall=56486
2022-03-06 06:04:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:04:52 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 14.43 | nll_loss 14.25 | ppl 19478.2 | wps 48248.6 | wpb 510.9 | bsz 1 | num_updates 24038 | best_loss 8.288
2022-03-06 06:04:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24038 updates
2022-03-06 06:04:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 494 @ 24038 updates, score 14.43) (writing took 1.69670256995596 seconds)
2022-03-06 06:04:53 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:04:53 | INFO | train | epoch 494 | loss 0.716 | nll_loss 0.17 | ppl 1.12 | wps 27322.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24038 | lr 0.000203963 | gnorm 0.372 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56578
2022-03-06 06:04:53 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:04:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:06:46 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 14.364 | nll_loss 14.178 | ppl 18530.5 | wps 48103 | wpb 510.9 | bsz 1 | num_updates 24087 | best_loss 8.288
2022-03-06 06:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24087 updates
2022-03-06 06:06:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 495 @ 24087 updates, score 14.364) (writing took 1.7527697968762368 seconds)
2022-03-06 06:06:48 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:06:48 | INFO | train | epoch 495 | loss 0.716 | nll_loss 0.169 | ppl 1.12 | wps 27861.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24087 | lr 0.000203755 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56692
2022-03-06 06:06:48 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:16 | INFO | train_inner | epoch 496:     13 / 49 loss=0.716, nll_loss=0.169, ppl=1.12, wps=27654, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.369, loss_scale=32, train_wall=200, gb_free=21.6, wall=56720
2022-03-06 06:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:40 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 14.299 | nll_loss 14.115 | ppl 17742.1 | wps 47977.8 | wpb 510.9 | bsz 1 | num_updates 24136 | best_loss 8.288
2022-03-06 06:08:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24136 updates
2022-03-06 06:08:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:08:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 496 @ 24136 updates, score 14.299) (writing took 1.7251425520516932 seconds)
2022-03-06 06:08:42 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:08:42 | INFO | train | epoch 496 | loss 0.716 | nll_loss 0.17 | ppl 1.12 | wps 27845.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24136 | lr 0.000203548 | gnorm 0.373 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56806
2022-03-06 06:08:42 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:10:34 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 14.338 | nll_loss 14.155 | ppl 18240.2 | wps 48097.6 | wpb 510.9 | bsz 1 | num_updates 24184 | best_loss 8.288
2022-03-06 06:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24184 updates
2022-03-06 06:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:10:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 497 @ 24184 updates, score 14.338) (writing took 1.7226657790597528 seconds)
2022-03-06 06:10:36 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:10:36 | INFO | train | epoch 497 | loss 0.716 | nll_loss 0.17 | ppl 1.12 | wps 27307.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24184 | lr 0.000203346 | gnorm 0.369 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56920
2022-03-06 06:10:36 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:11 | INFO | train_inner | epoch 498:     16 / 49 loss=0.716, nll_loss=0.17, ppl=1.12, wps=27618, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.373, loss_scale=32, train_wall=200, gb_free=21.6, wall=56955
2022-03-06 06:12:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:12:28 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 14.385 | nll_loss 14.201 | ppl 18832 | wps 47953.3 | wpb 510.9 | bsz 1 | num_updates 24233 | best_loss 8.288
2022-03-06 06:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24233 updates
2022-03-06 06:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 498 @ 24233 updates, score 14.385) (writing took 1.6969547239132226 seconds)
2022-03-06 06:12:30 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:12:30 | INFO | train | epoch 498 | loss 0.716 | nll_loss 0.17 | ppl 1.12 | wps 27836.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24233 | lr 0.00020314 | gnorm 0.374 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57034
2022-03-06 06:12:30 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:14:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:22 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 14.387 | nll_loss 14.204 | ppl 18878.1 | wps 47799.5 | wpb 510.9 | bsz 1 | num_updates 24282 | best_loss 8.288
2022-03-06 06:14:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24282 updates
2022-03-06 06:14:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:14:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:14:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 499 @ 24282 updates, score 14.387) (writing took 1.7121642481070012 seconds)
2022-03-06 06:14:24 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:14:24 | INFO | train | epoch 499 | loss 0.715 | nll_loss 0.169 | ppl 1.12 | wps 27845.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24282 | lr 0.000202935 | gnorm 0.371 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57148
2022-03-06 06:14:24 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:14:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:04 | INFO | train_inner | epoch 500:     18 / 49 loss=0.715, nll_loss=0.169, ppl=1.12, wps=27882.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.372, loss_scale=64, train_wall=198, gb_free=21.6, wall=57188
2022-03-06 06:15:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:16 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 14.421 | nll_loss 14.24 | ppl 19346 | wps 48038.3 | wpb 510.9 | bsz 1 | num_updates 24330 | best_loss 8.288
2022-03-06 06:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24330 updates
2022-03-06 06:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:16:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 500 @ 24330 updates, score 14.421) (writing took 1.704327107872814 seconds)
2022-03-06 06:16:18 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:16:18 | INFO | train | epoch 500 | loss 0.715 | nll_loss 0.169 | ppl 1.12 | wps 27303.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24330 | lr 0.000202735 | gnorm 0.374 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57262
2022-03-06 06:16:18 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:16:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:10 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 14.381 | nll_loss 14.201 | ppl 18832.5 | wps 47651.8 | wpb 510.9 | bsz 1 | num_updates 24379 | best_loss 8.288
2022-03-06 06:18:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24379 updates
2022-03-06 06:18:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:18:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 501 @ 24379 updates, score 14.381) (writing took 1.728812068933621 seconds)
2022-03-06 06:18:12 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:18:12 | INFO | train | epoch 501 | loss 0.714 | nll_loss 0.168 | ppl 1.12 | wps 27867.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24379 | lr 0.000202531 | gnorm 0.371 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57376
2022-03-06 06:18:12 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:59 | INFO | train_inner | epoch 502:     21 / 49 loss=0.714, nll_loss=0.169, ppl=1.12, wps=27641, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.372, loss_scale=32, train_wall=200, gb_free=21.6, wall=57423
2022-03-06 06:20:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:04 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 14.389 | nll_loss 14.205 | ppl 18883.7 | wps 47953.4 | wpb 510.9 | bsz 1 | num_updates 24428 | best_loss 8.288
2022-03-06 06:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24428 updates
2022-03-06 06:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:20:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 502 @ 24428 updates, score 14.389) (writing took 1.744761356851086 seconds)
2022-03-06 06:20:06 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:20:06 | INFO | train | epoch 502 | loss 0.715 | nll_loss 0.169 | ppl 1.12 | wps 27860.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24428 | lr 0.000202328 | gnorm 0.373 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57490
2022-03-06 06:20:06 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:21:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:21:58 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 14.428 | nll_loss 14.245 | ppl 19421.4 | wps 47972 | wpb 510.9 | bsz 1 | num_updates 24476 | best_loss 8.288
2022-03-06 06:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24476 updates
2022-03-06 06:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 503 @ 24476 updates, score 14.428) (writing took 1.6954772588796914 seconds)
2022-03-06 06:22:00 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:22:00 | INFO | train | epoch 503 | loss 0.713 | nll_loss 0.168 | ppl 1.12 | wps 27286.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24476 | lr 0.00020213 | gnorm 0.369 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57604
2022-03-06 06:22:00 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:53 | INFO | train_inner | epoch 504:     24 / 49 loss=0.714, nll_loss=0.168, ppl=1.12, wps=27630.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.37, loss_scale=32, train_wall=200, gb_free=21.6, wall=57658
2022-03-06 06:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:23:52 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 14.385 | nll_loss 14.201 | ppl 18833.4 | wps 48634.4 | wpb 510.9 | bsz 1 | num_updates 24525 | best_loss 8.288
2022-03-06 06:23:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24525 updates
2022-03-06 06:23:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 504 @ 24525 updates, score 14.385) (writing took 1.724646125920117 seconds)
2022-03-06 06:23:54 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:23:54 | INFO | train | epoch 504 | loss 0.713 | nll_loss 0.168 | ppl 1.12 | wps 27880.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24525 | lr 0.000201928 | gnorm 0.37 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57718
2022-03-06 06:23:54 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:25:46 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 14.365 | nll_loss 14.181 | ppl 18576.4 | wps 47805.7 | wpb 510.9 | bsz 1 | num_updates 24574 | best_loss 8.288
2022-03-06 06:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24574 updates
2022-03-06 06:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 505 @ 24574 updates, score 14.365) (writing took 1.6960607960354537 seconds)
2022-03-06 06:25:48 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:25:48 | INFO | train | epoch 505 | loss 0.712 | nll_loss 0.167 | ppl 1.12 | wps 27872.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24574 | lr 0.000201726 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57832
2022-03-06 06:25:48 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:46 | INFO | train_inner | epoch 506:     26 / 49 loss=0.713, nll_loss=0.168, ppl=1.12, wps=27901, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.369, loss_scale=64, train_wall=198, gb_free=21.6, wall=57890
2022-03-06 06:27:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:27:41 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 14.376 | nll_loss 14.192 | ppl 18719.5 | wps 48084.8 | wpb 510.9 | bsz 1 | num_updates 24622 | best_loss 8.288
2022-03-06 06:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24622 updates
2022-03-06 06:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 506 @ 24622 updates, score 14.376) (writing took 1.7105171920266002 seconds)
2022-03-06 06:27:42 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:27:42 | INFO | train | epoch 506 | loss 0.713 | nll_loss 0.168 | ppl 1.12 | wps 27281.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24622 | lr 0.000201529 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57946
2022-03-06 06:27:42 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:29:35 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 14.422 | nll_loss 14.24 | ppl 19343.8 | wps 48229.4 | wpb 510.9 | bsz 1 | num_updates 24671 | best_loss 8.288
2022-03-06 06:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24671 updates
2022-03-06 06:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 507 @ 24671 updates, score 14.422) (writing took 1.7444006269797683 seconds)
2022-03-06 06:29:36 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:29:36 | INFO | train | epoch 507 | loss 0.713 | nll_loss 0.168 | ppl 1.12 | wps 27866.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24671 | lr 0.000201329 | gnorm 0.371 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58060
2022-03-06 06:29:36 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:30:41 | INFO | train_inner | epoch 508:     29 / 49 loss=0.713, nll_loss=0.167, ppl=1.12, wps=27628.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.369, loss_scale=32, train_wall=200, gb_free=21.6, wall=58125
2022-03-06 06:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:31:29 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 14.361 | nll_loss 14.179 | ppl 18545.8 | wps 47843.1 | wpb 510.9 | bsz 1 | num_updates 24720 | best_loss 8.288
2022-03-06 06:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24720 updates
2022-03-06 06:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:31:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 508 @ 24720 updates, score 14.361) (writing took 1.7218779239337891 seconds)
2022-03-06 06:31:30 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:31:30 | INFO | train | epoch 508 | loss 0.712 | nll_loss 0.167 | ppl 1.12 | wps 27847.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24720 | lr 0.000201129 | gnorm 0.371 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58174
2022-03-06 06:31:30 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:32:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:33:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:33:23 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 14.413 | nll_loss 14.231 | ppl 19224.1 | wps 48182.4 | wpb 510.9 | bsz 1 | num_updates 24768 | best_loss 8.288
2022-03-06 06:33:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24768 updates
2022-03-06 06:33:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:33:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 509 @ 24768 updates, score 14.413) (writing took 1.7004033029079437 seconds)
2022-03-06 06:33:24 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:33:24 | INFO | train | epoch 509 | loss 0.712 | nll_loss 0.167 | ppl 1.12 | wps 27290.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24768 | lr 0.000200935 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58289
2022-03-06 06:33:24 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:34:35 | INFO | train_inner | epoch 510:     32 / 49 loss=0.712, nll_loss=0.167, ppl=1.12, wps=27635.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.369, loss_scale=32, train_wall=200, gb_free=21.6, wall=58360
2022-03-06 06:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:17 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 14.453 | nll_loss 14.273 | ppl 19800.3 | wps 47877.9 | wpb 510.9 | bsz 1 | num_updates 24817 | best_loss 8.288
2022-03-06 06:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24817 updates
2022-03-06 06:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:35:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 510 @ 24817 updates, score 14.453) (writing took 1.7498823220375925 seconds)
2022-03-06 06:35:18 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:35:18 | INFO | train | epoch 510 | loss 0.711 | nll_loss 0.166 | ppl 1.12 | wps 27872.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24817 | lr 0.000200736 | gnorm 0.366 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58403
2022-03-06 06:35:18 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:11 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 14.432 | nll_loss 14.25 | ppl 19486.8 | wps 48289.7 | wpb 510.9 | bsz 1 | num_updates 24866 | best_loss 8.288
2022-03-06 06:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24866 updates
2022-03-06 06:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 511 @ 24866 updates, score 14.432) (writing took 1.7464569278527051 seconds)
2022-03-06 06:37:13 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:37:13 | INFO | train | epoch 511 | loss 0.71 | nll_loss 0.165 | ppl 1.12 | wps 27851.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24866 | lr 0.000200538 | gnorm 0.363 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58517
2022-03-06 06:37:13 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:28 | INFO | train_inner | epoch 512:     34 / 49 loss=0.711, nll_loss=0.166, ppl=1.12, wps=27879.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.362, loss_scale=64, train_wall=198, gb_free=21.6, wall=58592
2022-03-06 06:38:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:05 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 14.331 | nll_loss 14.147 | ppl 18146 | wps 48126.1 | wpb 510.9 | bsz 1 | num_updates 24914 | best_loss 8.288
2022-03-06 06:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24914 updates
2022-03-06 06:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 512 @ 24914 updates, score 14.331) (writing took 1.728865098906681 seconds)
2022-03-06 06:39:07 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:39:07 | INFO | train | epoch 512 | loss 0.711 | nll_loss 0.167 | ppl 1.12 | wps 27257.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24914 | lr 0.000200345 | gnorm 0.364 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58631
2022-03-06 06:39:07 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:40:59 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 14.38 | nll_loss 14.198 | ppl 18791.2 | wps 47515.1 | wpb 510.9 | bsz 1 | num_updates 24963 | best_loss 8.288
2022-03-06 06:40:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24963 updates
2022-03-06 06:40:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 513 @ 24963 updates, score 14.38) (writing took 1.7792217920068651 seconds)
2022-03-06 06:41:01 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:41:01 | INFO | train | epoch 513 | loss 0.711 | nll_loss 0.166 | ppl 1.12 | wps 27826.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24963 | lr 0.000200148 | gnorm 0.368 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58745
2022-03-06 06:41:01 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:42:23 | INFO | train_inner | epoch 514:     37 / 49 loss=0.711, nll_loss=0.166, ppl=1.12, wps=27607.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.369, loss_scale=32, train_wall=200, gb_free=21.6, wall=58827
2022-03-06 06:42:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:42:53 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 14.401 | nll_loss 14.22 | ppl 19084.9 | wps 47776.9 | wpb 510.9 | bsz 1 | num_updates 25012 | best_loss 8.288
2022-03-06 06:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25012 updates
2022-03-06 06:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 514 @ 25012 updates, score 14.401) (writing took 1.7874987991526723 seconds)
2022-03-06 06:42:55 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:42:55 | INFO | train | epoch 514 | loss 0.711 | nll_loss 0.166 | ppl 1.12 | wps 27832.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25012 | lr 0.000199952 | gnorm 0.371 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58859
2022-03-06 06:42:55 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:43:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:44:48 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 14.444 | nll_loss 14.263 | ppl 19663.3 | wps 48132.8 | wpb 510.9 | bsz 1 | num_updates 25060 | best_loss 8.288
2022-03-06 06:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25060 updates
2022-03-06 06:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 515 @ 25060 updates, score 14.444) (writing took 1.7487520950380713 seconds)
2022-03-06 06:44:49 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:44:49 | INFO | train | epoch 515 | loss 0.71 | nll_loss 0.165 | ppl 1.12 | wps 27265.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25060 | lr 0.00019976 | gnorm 0.366 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58973
2022-03-06 06:44:49 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:46:18 | INFO | train_inner | epoch 516:     40 / 49 loss=0.71, nll_loss=0.165, ppl=1.12, wps=27605.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.367, loss_scale=32, train_wall=200, gb_free=21.6, wall=59062
2022-03-06 06:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:46:42 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 14.41 | nll_loss 14.23 | ppl 19214.2 | wps 47923.8 | wpb 510.9 | bsz 1 | num_updates 25109 | best_loss 8.288
2022-03-06 06:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25109 updates
2022-03-06 06:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:46:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:46:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 516 @ 25109 updates, score 14.41) (writing took 1.8001358658075333 seconds)
2022-03-06 06:46:43 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:46:43 | INFO | train | epoch 516 | loss 0.709 | nll_loss 0.165 | ppl 1.12 | wps 27841.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25109 | lr 0.000199565 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59088
2022-03-06 06:46:43 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:48:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:48:36 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 14.371 | nll_loss 14.19 | ppl 18694.4 | wps 48158.9 | wpb 510.9 | bsz 1 | num_updates 25158 | best_loss 8.288
2022-03-06 06:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25158 updates
2022-03-06 06:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:48:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 517 @ 25158 updates, score 14.371) (writing took 1.7544701390434057 seconds)
2022-03-06 06:48:38 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:48:38 | INFO | train | epoch 517 | loss 0.709 | nll_loss 0.164 | ppl 1.12 | wps 27855.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25158 | lr 0.000199371 | gnorm 0.362 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59202
2022-03-06 06:48:38 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:11 | INFO | train_inner | epoch 518:     42 / 49 loss=0.709, nll_loss=0.165, ppl=1.12, wps=27874.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.364, loss_scale=64, train_wall=198, gb_free=21.6, wall=59295
2022-03-06 06:50:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:30 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 14.467 | nll_loss 14.286 | ppl 19974.2 | wps 47718.8 | wpb 510.9 | bsz 1 | num_updates 25207 | best_loss 8.288
2022-03-06 06:50:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25207 updates
2022-03-06 06:50:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:50:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:50:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 518 @ 25207 updates, score 14.467) (writing took 1.7738479680847377 seconds)
2022-03-06 06:50:32 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:50:32 | INFO | train | epoch 518 | loss 0.71 | nll_loss 0.165 | ppl 1.12 | wps 27819.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25207 | lr 0.000199177 | gnorm 0.367 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 59316
2022-03-06 06:50:32 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:50:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:52:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:52:24 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 14.382 | nll_loss 14.201 | ppl 18839 | wps 48020.5 | wpb 510.9 | bsz 1 | num_updates 25255 | best_loss 8.288
2022-03-06 06:52:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25255 updates
2022-03-06 06:52:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:52:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:52:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 519 @ 25255 updates, score 14.382) (writing took 1.7771821259520948 seconds)
2022-03-06 06:52:26 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 06:52:26 | INFO | train | epoch 519 | loss 0.709 | nll_loss 0.164 | ppl 1.12 | wps 27271.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25255 | lr 0.000198988 | gnorm 0.367 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59430
2022-03-06 06:52:26 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 06:52:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:06 | INFO | train_inner | epoch 520:     45 / 49 loss=0.709, nll_loss=0.164, ppl=1.12, wps=27605.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.367, loss_scale=32, train_wall=200, gb_free=21.6, wall=59530
2022-03-06 06:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:18 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 14.359 | nll_loss 14.177 | ppl 18521.3 | wps 48087.2 | wpb 510.9 | bsz 1 | num_updates 25304 | best_loss 8.288
2022-03-06 06:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25304 updates
2022-03-06 06:54:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:54:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:54:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 520 @ 25304 updates, score 14.359) (writing took 1.7864606929942966 seconds)
2022-03-06 06:54:20 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 06:54:20 | INFO | train | epoch 520 | loss 0.708 | nll_loss 0.164 | ppl 1.12 | wps 27834.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25304 | lr 0.000198795 | gnorm 0.366 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59544
2022-03-06 06:54:20 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 06:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:13 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 14.333 | nll_loss 14.151 | ppl 18193.8 | wps 48033.5 | wpb 510.9 | bsz 1 | num_updates 25352 | best_loss 8.288
2022-03-06 06:56:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25352 updates
2022-03-06 06:56:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:56:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:56:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 521 @ 25352 updates, score 14.333) (writing took 1.7837376720272005 seconds)
2022-03-06 06:56:14 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 06:56:14 | INFO | train | epoch 521 | loss 0.707 | nll_loss 0.163 | ppl 1.12 | wps 27248.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25352 | lr 0.000198607 | gnorm 0.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59658
2022-03-06 06:56:14 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 06:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:01 | INFO | train_inner | epoch 522:     48 / 49 loss=0.708, nll_loss=0.164, ppl=1.12, wps=27594.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.365, loss_scale=32, train_wall=200, gb_free=21.6, wall=59765
2022-03-06 06:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:07 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 14.471 | nll_loss 14.293 | ppl 20073.3 | wps 47985.7 | wpb 510.9 | bsz 1 | num_updates 25401 | best_loss 8.288
2022-03-06 06:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25401 updates
2022-03-06 06:58:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:58:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 06:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 522 @ 25401 updates, score 14.471) (writing took 1.7612015248741955 seconds)
2022-03-06 06:58:09 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 06:58:09 | INFO | train | epoch 522 | loss 0.708 | nll_loss 0.164 | ppl 1.12 | wps 27834 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25401 | lr 0.000198415 | gnorm 0.368 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59773
2022-03-06 06:58:09 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 06:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:01 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 14.45 | nll_loss 14.27 | ppl 19756.7 | wps 47894.8 | wpb 510.9 | bsz 1 | num_updates 25450 | best_loss 8.288
2022-03-06 07:00:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25450 updates
2022-03-06 07:00:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 523 @ 25450 updates, score 14.45) (writing took 1.7880779718980193 seconds)
2022-03-06 07:00:03 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:00:03 | INFO | train | epoch 523 | loss 0.708 | nll_loss 0.163 | ppl 1.12 | wps 27848.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25450 | lr 0.000198224 | gnorm 0.363 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59887
2022-03-06 07:00:03 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:01:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:01:55 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 14.443 | nll_loss 14.266 | ppl 19705.4 | wps 47784.9 | wpb 510.9 | bsz 1 | num_updates 25498 | best_loss 8.288
2022-03-06 07:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25498 updates
2022-03-06 07:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:01:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 524 @ 25498 updates, score 14.443) (writing took 1.7754523120820522 seconds)
2022-03-06 07:01:57 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:01:57 | INFO | train | epoch 524 | loss 0.707 | nll_loss 0.163 | ppl 1.12 | wps 27259.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25498 | lr 0.000198037 | gnorm 0.36 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60001
2022-03-06 07:01:57 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:01 | INFO | train_inner | epoch 525:      2 / 49 loss=0.707, nll_loss=0.163, ppl=1.12, wps=26850.3, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=25500, lr=0.00019803, gnorm=0.363, loss_scale=32, train_wall=199, gb_free=21.6, wall=60005
2022-03-06 07:03:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:03:49 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 14.4 | nll_loss 14.219 | ppl 19073.4 | wps 47748.3 | wpb 510.9 | bsz 1 | num_updates 25547 | best_loss 8.288
2022-03-06 07:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25547 updates
2022-03-06 07:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:03:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 525 @ 25547 updates, score 14.4) (writing took 1.7738030110485852 seconds)
2022-03-06 07:03:51 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:03:51 | INFO | train | epoch 525 | loss 0.707 | nll_loss 0.163 | ppl 1.12 | wps 27836.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25547 | lr 0.000197847 | gnorm 0.363 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60115
2022-03-06 07:03:51 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:03:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:05:43 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 14.308 | nll_loss 14.125 | ppl 17869 | wps 48107.3 | wpb 510.9 | bsz 1 | num_updates 25596 | best_loss 8.288
2022-03-06 07:05:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25596 updates
2022-03-06 07:05:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 526 @ 25596 updates, score 14.308) (writing took 1.754192722029984 seconds)
2022-03-06 07:05:45 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:05:45 | INFO | train | epoch 526 | loss 0.707 | nll_loss 0.163 | ppl 1.12 | wps 27866.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25596 | lr 0.000197658 | gnorm 0.356 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60229
2022-03-06 07:05:45 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:54 | INFO | train_inner | epoch 527:      4 / 49 loss=0.707, nll_loss=0.163, ppl=1.12, wps=27880.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.36, loss_scale=32, train_wall=198, gb_free=21.6, wall=60238
2022-03-06 07:06:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:37 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 14.325 | nll_loss 14.143 | ppl 18087.9 | wps 48099.8 | wpb 510.9 | bsz 1 | num_updates 25644 | best_loss 8.288
2022-03-06 07:07:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25644 updates
2022-03-06 07:07:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:07:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 527 @ 25644 updates, score 14.325) (writing took 1.7592724149581045 seconds)
2022-03-06 07:07:39 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:07:39 | INFO | train | epoch 527 | loss 0.706 | nll_loss 0.162 | ppl 1.12 | wps 27281.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25644 | lr 0.000197473 | gnorm 0.355 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60343
2022-03-06 07:07:39 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:09:32 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 14.381 | nll_loss 14.202 | ppl 18841.4 | wps 47612.5 | wpb 510.9 | bsz 1 | num_updates 25693 | best_loss 8.288
2022-03-06 07:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25693 updates
2022-03-06 07:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 528 @ 25693 updates, score 14.381) (writing took 1.7979414509609342 seconds)
2022-03-06 07:09:33 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:09:33 | INFO | train | epoch 528 | loss 0.707 | nll_loss 0.164 | ppl 1.12 | wps 27797.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25693 | lr 0.000197284 | gnorm 0.366 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60458
2022-03-06 07:09:33 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:09:49 | INFO | train_inner | epoch 529:      7 / 49 loss=0.706, nll_loss=0.163, ppl=1.12, wps=27601.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.361, loss_scale=32, train_wall=200, gb_free=21.6, wall=60473
2022-03-06 07:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:11:26 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 14.333 | nll_loss 14.149 | ppl 18170.5 | wps 47727.7 | wpb 510.9 | bsz 1 | num_updates 25742 | best_loss 8.288
2022-03-06 07:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25742 updates
2022-03-06 07:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:11:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 529 @ 25742 updates, score 14.333) (writing took 1.771828634897247 seconds)
2022-03-06 07:11:28 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:11:28 | INFO | train | epoch 529 | loss 0.706 | nll_loss 0.163 | ppl 1.12 | wps 27842.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25742 | lr 0.000197096 | gnorm 0.36 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60572
2022-03-06 07:11:28 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:20 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 14.377 | nll_loss 14.196 | ppl 18771.7 | wps 47980 | wpb 510.9 | bsz 1 | num_updates 25790 | best_loss 8.288
2022-03-06 07:13:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25790 updates
2022-03-06 07:13:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 530 @ 25790 updates, score 14.377) (writing took 1.7458498061168939 seconds)
2022-03-06 07:13:22 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:13:22 | INFO | train | epoch 530 | loss 0.706 | nll_loss 0.162 | ppl 1.12 | wps 27270.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25790 | lr 0.000196913 | gnorm 0.356 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60686
2022-03-06 07:13:22 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:44 | INFO | train_inner | epoch 531:     10 / 49 loss=0.706, nll_loss=0.162, ppl=1.12, wps=27616.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.358, loss_scale=32, train_wall=200, gb_free=21.6, wall=60708
2022-03-06 07:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:15:14 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 14.404 | nll_loss 14.222 | ppl 19110 | wps 47836.5 | wpb 510.9 | bsz 1 | num_updates 25839 | best_loss 8.288
2022-03-06 07:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25839 updates
2022-03-06 07:15:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:15:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 531 @ 25839 updates, score 14.404) (writing took 1.7812108949292451 seconds)
2022-03-06 07:15:16 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:15:16 | INFO | train | epoch 531 | loss 0.706 | nll_loss 0.162 | ppl 1.12 | wps 27829 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25839 | lr 0.000196726 | gnorm 0.363 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60800
2022-03-06 07:15:16 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:17:08 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 14.446 | nll_loss 14.266 | ppl 19701.4 | wps 48066.7 | wpb 510.9 | bsz 1 | num_updates 25888 | best_loss 8.288
2022-03-06 07:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25888 updates
2022-03-06 07:17:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 532 @ 25888 updates, score 14.446) (writing took 1.7872430901043117 seconds)
2022-03-06 07:17:10 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:17:10 | INFO | train | epoch 532 | loss 0.705 | nll_loss 0.162 | ppl 1.12 | wps 27839.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25888 | lr 0.00019654 | gnorm 0.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60914
2022-03-06 07:17:10 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:17:37 | INFO | train_inner | epoch 533:     12 / 49 loss=0.705, nll_loss=0.162, ppl=1.12, wps=27859.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.362, loss_scale=32, train_wall=198, gb_free=21.6, wall=60941
2022-03-06 07:18:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:02 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 14.375 | nll_loss 14.195 | ppl 18761.6 | wps 48095.6 | wpb 510.9 | bsz 1 | num_updates 25936 | best_loss 8.288
2022-03-06 07:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25936 updates
2022-03-06 07:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 533 @ 25936 updates, score 14.375) (writing took 1.7556221298873425 seconds)
2022-03-06 07:19:04 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:19:04 | INFO | train | epoch 533 | loss 0.705 | nll_loss 0.161 | ppl 1.12 | wps 27275.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25936 | lr 0.000196358 | gnorm 0.36 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61028
2022-03-06 07:19:04 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:20:57 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 14.305 | nll_loss 14.122 | ppl 17833.5 | wps 48123 | wpb 510.9 | bsz 1 | num_updates 25985 | best_loss 8.288
2022-03-06 07:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25985 updates
2022-03-06 07:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 534 @ 25985 updates, score 14.305) (writing took 1.8033350151963532 seconds)
2022-03-06 07:20:58 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:20:58 | INFO | train | epoch 534 | loss 0.705 | nll_loss 0.162 | ppl 1.12 | wps 27809.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25985 | lr 0.000196173 | gnorm 0.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61143
2022-03-06 07:20:58 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:32 | INFO | train_inner | epoch 535:     15 / 49 loss=0.705, nll_loss=0.162, ppl=1.12, wps=27607.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.361, loss_scale=32, train_wall=200, gb_free=21.6, wall=61176
2022-03-06 07:22:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:22:51 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 14.379 | nll_loss 14.2 | ppl 18817.4 | wps 48100.9 | wpb 510.9 | bsz 1 | num_updates 26034 | best_loss 8.288
2022-03-06 07:22:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26034 updates
2022-03-06 07:22:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:22:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 535 @ 26034 updates, score 14.379) (writing took 1.7890064381062984 seconds)
2022-03-06 07:22:53 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:22:53 | INFO | train | epoch 535 | loss 0.704 | nll_loss 0.161 | ppl 1.12 | wps 27856.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26034 | lr 0.000195988 | gnorm 0.362 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61257
2022-03-06 07:22:53 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:22:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:23:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:24:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:24:45 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 14.358 | nll_loss 14.18 | ppl 18555.4 | wps 47710.8 | wpb 510.9 | bsz 1 | num_updates 26082 | best_loss 8.288
2022-03-06 07:24:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26082 updates
2022-03-06 07:24:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:24:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:24:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 536 @ 26082 updates, score 14.358) (writing took 1.7717299601063132 seconds)
2022-03-06 07:24:47 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:24:47 | INFO | train | epoch 536 | loss 0.704 | nll_loss 0.161 | ppl 1.12 | wps 27259 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26082 | lr 0.000195808 | gnorm 0.357 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61371
2022-03-06 07:24:47 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:24:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:25:27 | INFO | train_inner | epoch 537:     18 / 49 loss=0.704, nll_loss=0.161, ppl=1.12, wps=27607.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.359, loss_scale=32, train_wall=200, gb_free=21.6, wall=61411
2022-03-06 07:26:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:26:39 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 14.355 | nll_loss 14.176 | ppl 18504.6 | wps 47647.6 | wpb 510.9 | bsz 1 | num_updates 26131 | best_loss 8.288
2022-03-06 07:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26131 updates
2022-03-06 07:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:26:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 537 @ 26131 updates, score 14.355) (writing took 1.7904422290157527 seconds)
2022-03-06 07:26:41 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:26:41 | INFO | train | epoch 537 | loss 0.704 | nll_loss 0.161 | ppl 1.12 | wps 27817.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26131 | lr 0.000195624 | gnorm 0.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61485
2022-03-06 07:26:41 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:28:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:28:33 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 14.472 | nll_loss 14.29 | ppl 20036.1 | wps 47719.6 | wpb 510.9 | bsz 1 | num_updates 26180 | best_loss 8.288
2022-03-06 07:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26180 updates
2022-03-06 07:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 538 @ 26180 updates, score 14.472) (writing took 1.8120756410062313 seconds)
2022-03-06 07:28:35 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:28:35 | INFO | train | epoch 538 | loss 0.703 | nll_loss 0.16 | ppl 1.12 | wps 27819.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26180 | lr 0.000195441 | gnorm 0.36 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 61599
2022-03-06 07:28:35 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:29:20 | INFO | train_inner | epoch 539:     20 / 49 loss=0.704, nll_loss=0.161, ppl=1.12, wps=27851.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.36, loss_scale=64, train_wall=198, gb_free=21.6, wall=61644
2022-03-06 07:29:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:28 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 14.402 | nll_loss 14.224 | ppl 19136.8 | wps 48127 | wpb 510.9 | bsz 1 | num_updates 26228 | best_loss 8.288
2022-03-06 07:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26228 updates
2022-03-06 07:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 539 @ 26228 updates, score 14.402) (writing took 1.776972820982337 seconds)
2022-03-06 07:30:29 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:30:29 | INFO | train | epoch 539 | loss 0.703 | nll_loss 0.16 | ppl 1.12 | wps 27272.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26228 | lr 0.000195262 | gnorm 0.356 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61713
2022-03-06 07:30:29 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:22 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 14.489 | nll_loss 14.308 | ppl 20287.7 | wps 47560.1 | wpb 510.9 | bsz 1 | num_updates 26277 | best_loss 8.288
2022-03-06 07:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26277 updates
2022-03-06 07:32:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 540 @ 26277 updates, score 14.489) (writing took 1.8721925371792167 seconds)
2022-03-06 07:32:24 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:32:24 | INFO | train | epoch 540 | loss 0.703 | nll_loss 0.16 | ppl 1.12 | wps 27774.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26277 | lr 0.00019508 | gnorm 0.357 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61828
2022-03-06 07:32:24 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:33:15 | INFO | train_inner | epoch 541:     23 / 49 loss=0.703, nll_loss=0.16, ppl=1.12, wps=27583, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.358, loss_scale=32, train_wall=200, gb_free=21.6, wall=61879
2022-03-06 07:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:34:16 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 14.395 | nll_loss 14.214 | ppl 19004.2 | wps 48071.7 | wpb 510.9 | bsz 1 | num_updates 26326 | best_loss 8.288
2022-03-06 07:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26326 updates
2022-03-06 07:34:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:34:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 541 @ 26326 updates, score 14.395) (writing took 1.8233754199463874 seconds)
2022-03-06 07:34:18 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:34:18 | INFO | train | epoch 541 | loss 0.703 | nll_loss 0.16 | ppl 1.12 | wps 27819.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26326 | lr 0.000194898 | gnorm 0.36 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61942
2022-03-06 07:34:18 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:34:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:36:10 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 14.425 | nll_loss 14.246 | ppl 19425.8 | wps 48143.6 | wpb 510.9 | bsz 1 | num_updates 26374 | best_loss 8.288
2022-03-06 07:36:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26374 updates
2022-03-06 07:36:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 542 @ 26374 updates, score 14.425) (writing took 1.7439821981824934 seconds)
2022-03-06 07:36:12 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:36:12 | INFO | train | epoch 542 | loss 0.702 | nll_loss 0.16 | ppl 1.12 | wps 27258.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26374 | lr 0.000194721 | gnorm 0.361 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62056
2022-03-06 07:36:12 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:10 | INFO | train_inner | epoch 543:     26 / 49 loss=0.703, nll_loss=0.16, ppl=1.12, wps=27584.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.358, loss_scale=32, train_wall=200, gb_free=21.6, wall=62114
2022-03-06 07:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:38:05 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 14.435 | nll_loss 14.256 | ppl 19571.2 | wps 47799.2 | wpb 510.9 | bsz 1 | num_updates 26423 | best_loss 8.288
2022-03-06 07:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26423 updates
2022-03-06 07:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 543 @ 26423 updates, score 14.435) (writing took 1.8687068570870906 seconds)
2022-03-06 07:38:06 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:38:06 | INFO | train | epoch 543 | loss 0.702 | nll_loss 0.16 | ppl 1.12 | wps 27806.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26423 | lr 0.00019454 | gnorm 0.357 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62171
2022-03-06 07:38:07 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:38:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:39:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:39:59 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 14.33 | nll_loss 14.151 | ppl 18189.3 | wps 47931.7 | wpb 510.9 | bsz 1 | num_updates 26471 | best_loss 8.288
2022-03-06 07:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26471 updates
2022-03-06 07:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:40:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 544 @ 26471 updates, score 14.33) (writing took 1.7215099008753896 seconds)
2022-03-06 07:40:01 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:40:01 | INFO | train | epoch 544 | loss 0.701 | nll_loss 0.159 | ppl 1.12 | wps 27272.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26471 | lr 0.000194364 | gnorm 0.358 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62285
2022-03-06 07:40:01 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:05 | INFO | train_inner | epoch 545:     29 / 49 loss=0.701, nll_loss=0.159, ppl=1.12, wps=27601, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.356, loss_scale=32, train_wall=200, gb_free=21.6, wall=62349
2022-03-06 07:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:41:53 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 14.523 | nll_loss 14.345 | ppl 20817.4 | wps 47937.7 | wpb 510.9 | bsz 1 | num_updates 26520 | best_loss 8.288
2022-03-06 07:41:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26520 updates
2022-03-06 07:41:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 545 @ 26520 updates, score 14.523) (writing took 1.8221734510734677 seconds)
2022-03-06 07:41:55 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:41:55 | INFO | train | epoch 545 | loss 0.701 | nll_loss 0.159 | ppl 1.12 | wps 27814.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26520 | lr 0.000194184 | gnorm 0.353 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62399
2022-03-06 07:41:55 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:43:47 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 14.456 | nll_loss 14.277 | ppl 19853.7 | wps 47791.2 | wpb 510.9 | bsz 1 | num_updates 26569 | best_loss 8.288
2022-03-06 07:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26569 updates
2022-03-06 07:43:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 546 @ 26569 updates, score 14.456) (writing took 1.852654891088605 seconds)
2022-03-06 07:43:49 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:43:49 | INFO | train | epoch 546 | loss 0.701 | nll_loss 0.158 | ppl 1.12 | wps 27789.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26569 | lr 0.000194005 | gnorm 0.351 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62513
2022-03-06 07:43:49 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:44:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:45:00 | INFO | train_inner | epoch 547:     32 / 49 loss=0.701, nll_loss=0.159, ppl=1.12, wps=27567.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.353, loss_scale=32, train_wall=200, gb_free=21.6, wall=62584
2022-03-06 07:45:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:45:42 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 14.347 | nll_loss 14.166 | ppl 18377.4 | wps 48007.9 | wpb 510.9 | bsz 1 | num_updates 26617 | best_loss 8.288
2022-03-06 07:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26617 updates
2022-03-06 07:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:45:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:45:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 547 @ 26617 updates, score 14.347) (writing took 1.992559330072254 seconds)
2022-03-06 07:45:44 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:45:44 | INFO | train | epoch 547 | loss 0.701 | nll_loss 0.159 | ppl 1.12 | wps 27192.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26617 | lr 0.00019383 | gnorm 0.353 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62628
2022-03-06 07:45:44 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:45:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:47:36 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 14.458 | nll_loss 14.279 | ppl 19879.2 | wps 47921.9 | wpb 510.9 | bsz 1 | num_updates 26666 | best_loss 8.288
2022-03-06 07:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26666 updates
2022-03-06 07:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:47:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:47:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 548 @ 26666 updates, score 14.458) (writing took 1.9686791410204023 seconds)
2022-03-06 07:47:38 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:47:38 | INFO | train | epoch 548 | loss 0.701 | nll_loss 0.159 | ppl 1.12 | wps 27806.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26666 | lr 0.000193652 | gnorm 0.355 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62742
2022-03-06 07:47:38 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:48:53 | INFO | train_inner | epoch 549:     34 / 49 loss=0.701, nll_loss=0.159, ppl=1.12, wps=27832, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.357, loss_scale=32, train_wall=198, gb_free=21.6, wall=62818
2022-03-06 07:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:30 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 14.339 | nll_loss 14.16 | ppl 18309.8 | wps 47732 | wpb 510.9 | bsz 1 | num_updates 26715 | best_loss 8.288
2022-03-06 07:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26715 updates
2022-03-06 07:49:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:49:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:49:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 549 @ 26715 updates, score 14.339) (writing took 2.0530636799521744 seconds)
2022-03-06 07:49:32 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:49:32 | INFO | train | epoch 549 | loss 0.702 | nll_loss 0.159 | ppl 1.12 | wps 27774.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26715 | lr 0.000193474 | gnorm 0.36 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62856
2022-03-06 07:49:32 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:49:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:25 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 14.462 | nll_loss 14.285 | ppl 19960.7 | wps 47725.9 | wpb 510.9 | bsz 1 | num_updates 26763 | best_loss 8.288
2022-03-06 07:51:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26763 updates
2022-03-06 07:51:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:51:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:51:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 550 @ 26763 updates, score 14.462) (writing took 2.0061106448993087 seconds)
2022-03-06 07:51:27 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 07:51:27 | INFO | train | epoch 550 | loss 0.701 | nll_loss 0.159 | ppl 1.12 | wps 27186.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26763 | lr 0.0001933 | gnorm 0.359 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62971
2022-03-06 07:51:27 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 07:51:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:52:49 | INFO | train_inner | epoch 551:     37 / 49 loss=0.701, nll_loss=0.159, ppl=1.12, wps=27534.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.357, loss_scale=32, train_wall=200, gb_free=21.6, wall=63053
2022-03-06 07:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:19 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 14.37 | nll_loss 14.189 | ppl 18679.9 | wps 47306.3 | wpb 510.9 | bsz 1 | num_updates 26812 | best_loss 8.288
2022-03-06 07:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26812 updates
2022-03-06 07:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:53:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 551 @ 26812 updates, score 14.37) (writing took 2.0418425598181784 seconds)
2022-03-06 07:53:21 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 07:53:21 | INFO | train | epoch 551 | loss 0.7 | nll_loss 0.158 | ppl 1.12 | wps 27746.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26812 | lr 0.000193124 | gnorm 0.358 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63086
2022-03-06 07:53:21 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 07:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:14 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 14.421 | nll_loss 14.242 | ppl 19375.9 | wps 47653.1 | wpb 510.9 | bsz 1 | num_updates 26861 | best_loss 8.288
2022-03-06 07:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26861 updates
2022-03-06 07:55:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 552 @ 26861 updates, score 14.421) (writing took 2.1178808650001884 seconds)
2022-03-06 07:55:16 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 07:55:16 | INFO | train | epoch 552 | loss 0.7 | nll_loss 0.158 | ppl 1.12 | wps 27741.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26861 | lr 0.000192947 | gnorm 0.354 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 63200
2022-03-06 07:55:16 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 07:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:56:45 | INFO | train_inner | epoch 553:     40 / 49 loss=0.7, nll_loss=0.158, ppl=1.12, wps=27509.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.356, loss_scale=32, train_wall=200, gb_free=21.6, wall=63289
2022-03-06 07:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:08 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 14.435 | nll_loss 14.256 | ppl 19570.2 | wps 48045.9 | wpb 510.9 | bsz 1 | num_updates 26909 | best_loss 8.288
2022-03-06 07:57:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26909 updates
2022-03-06 07:57:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:57:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:57:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 553 @ 26909 updates, score 14.435) (writing took 1.989418925018981 seconds)
2022-03-06 07:57:10 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 07:57:10 | INFO | train | epoch 553 | loss 0.699 | nll_loss 0.157 | ppl 1.12 | wps 27199.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26909 | lr 0.000192775 | gnorm 0.354 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63314
2022-03-06 07:57:10 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 07:57:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:59:03 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 14.442 | nll_loss 14.261 | ppl 19632.7 | wps 47987.8 | wpb 510.9 | bsz 1 | num_updates 26958 | best_loss 8.288
2022-03-06 07:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26958 updates
2022-03-06 07:59:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:59:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 07:59:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 554 @ 26958 updates, score 14.442) (writing took 2.0195896641816944 seconds)
2022-03-06 07:59:05 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 07:59:05 | INFO | train | epoch 554 | loss 0.7 | nll_loss 0.158 | ppl 1.12 | wps 27777.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26958 | lr 0.0001926 | gnorm 0.352 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63429
2022-03-06 07:59:05 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 07:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:00:38 | INFO | train_inner | epoch 555:     42 / 49 loss=0.699, nll_loss=0.157, ppl=1.12, wps=27800.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.351, loss_scale=64, train_wall=198, gb_free=21.6, wall=63522
2022-03-06 08:00:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:00:57 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 14.348 | nll_loss 14.166 | ppl 18381.5 | wps 47704.1 | wpb 510.9 | bsz 1 | num_updates 27006 | best_loss 8.288
2022-03-06 08:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27006 updates
2022-03-06 08:00:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:00:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 555 @ 27006 updates, score 14.348) (writing took 2.112135861068964 seconds)
2022-03-06 08:01:00 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:01:00 | INFO | train | epoch 555 | loss 0.698 | nll_loss 0.157 | ppl 1.11 | wps 27146.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27006 | lr 0.000192429 | gnorm 0.349 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63544
2022-03-06 08:01:00 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:02:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:02:52 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 14.513 | nll_loss 14.333 | ppl 20640.3 | wps 47913.7 | wpb 510.9 | bsz 1 | num_updates 27055 | best_loss 8.288
2022-03-06 08:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27055 updates
2022-03-06 08:02:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 556 @ 27055 updates, score 14.513) (writing took 2.0671447878703475 seconds)
2022-03-06 08:02:54 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:02:54 | INFO | train | epoch 556 | loss 0.699 | nll_loss 0.157 | ppl 1.12 | wps 27761.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27055 | lr 0.000192254 | gnorm 0.356 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63658
2022-03-06 08:02:54 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:04:34 | INFO | train_inner | epoch 557:     45 / 49 loss=0.699, nll_loss=0.157, ppl=1.12, wps=27521.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.355, loss_scale=32, train_wall=200, gb_free=21.6, wall=63758
2022-03-06 08:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:04:46 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 14.442 | nll_loss 14.265 | ppl 19682.5 | wps 47860.1 | wpb 510.9 | bsz 1 | num_updates 27104 | best_loss 8.288
2022-03-06 08:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27104 updates
2022-03-06 08:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:04:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 557 @ 27104 updates, score 14.442) (writing took 2.02767229010351 seconds)
2022-03-06 08:04:48 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:04:48 | INFO | train | epoch 557 | loss 0.699 | nll_loss 0.157 | ppl 1.12 | wps 27760.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27104 | lr 0.000192081 | gnorm 0.353 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63773
2022-03-06 08:04:48 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:04:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:06:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:06:41 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 14.371 | nll_loss 14.19 | ppl 18694.9 | wps 48035.6 | wpb 510.9 | bsz 1 | num_updates 27152 | best_loss 8.288
2022-03-06 08:06:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27152 updates
2022-03-06 08:06:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 558 @ 27152 updates, score 14.371) (writing took 2.0921262218616903 seconds)
2022-03-06 08:06:43 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:06:43 | INFO | train | epoch 558 | loss 0.699 | nll_loss 0.157 | ppl 1.12 | wps 27165 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27152 | lr 0.000191911 | gnorm 0.358 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63887
2022-03-06 08:06:43 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:08:30 | INFO | train_inner | epoch 559:     48 / 49 loss=0.699, nll_loss=0.157, ppl=1.12, wps=27526.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.356, loss_scale=32, train_wall=200, gb_free=21.6, wall=63994
2022-03-06 08:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:08:35 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 14.466 | nll_loss 14.287 | ppl 19995 | wps 47920.7 | wpb 510.9 | bsz 1 | num_updates 27201 | best_loss 8.288
2022-03-06 08:08:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27201 updates
2022-03-06 08:08:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:08:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:08:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 559 @ 27201 updates, score 14.466) (writing took 2.017692784080282 seconds)
2022-03-06 08:08:37 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:08:37 | INFO | train | epoch 559 | loss 0.698 | nll_loss 0.157 | ppl 1.11 | wps 27777.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27201 | lr 0.000191738 | gnorm 0.354 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64002
2022-03-06 08:08:37 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:08:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:10:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:10:30 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 14.467 | nll_loss 14.289 | ppl 20022.4 | wps 47448.8 | wpb 510.9 | bsz 1 | num_updates 27250 | best_loss 8.288
2022-03-06 08:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27250 updates
2022-03-06 08:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:10:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:10:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 560 @ 27250 updates, score 14.467) (writing took 1.9910908399615437 seconds)
2022-03-06 08:10:32 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:10:32 | INFO | train | epoch 560 | loss 0.698 | nll_loss 0.157 | ppl 1.11 | wps 27770.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27250 | lr 0.000191565 | gnorm 0.354 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64116
2022-03-06 08:10:32 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:10:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:11:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:12:24 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 14.463 | nll_loss 14.286 | ppl 19976.8 | wps 47586.6 | wpb 510.9 | bsz 1 | num_updates 27298 | best_loss 8.288
2022-03-06 08:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27298 updates
2022-03-06 08:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:12:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 561 @ 27298 updates, score 14.463) (writing took 2.1103988089598715 seconds)
2022-03-06 08:12:26 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:12:26 | INFO | train | epoch 561 | loss 0.698 | nll_loss 0.156 | ppl 1.11 | wps 27166 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27298 | lr 0.000191397 | gnorm 0.353 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64231
2022-03-06 08:12:26 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:31 | INFO | train_inner | epoch 562:      2 / 49 loss=0.698, nll_loss=0.156, ppl=1.11, wps=26738.6, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=27300, lr=0.00019139, gnorm=0.354, loss_scale=32, train_wall=199, gb_free=21.6, wall=64235
2022-03-06 08:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:19 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 14.485 | nll_loss 14.308 | ppl 20279.1 | wps 47916.5 | wpb 510.9 | bsz 1 | num_updates 27347 | best_loss 8.288
2022-03-06 08:14:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27347 updates
2022-03-06 08:14:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 562 @ 27347 updates, score 14.485) (writing took 2.0279658751096576 seconds)
2022-03-06 08:14:21 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:14:21 | INFO | train | epoch 562 | loss 0.697 | nll_loss 0.156 | ppl 1.11 | wps 27749.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27347 | lr 0.000191225 | gnorm 0.353 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64345
2022-03-06 08:14:21 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:13 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 14.453 | nll_loss 14.273 | ppl 19795.3 | wps 47608.2 | wpb 510.9 | bsz 1 | num_updates 27396 | best_loss 8.288
2022-03-06 08:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27396 updates
2022-03-06 08:16:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 563 @ 27396 updates, score 14.453) (writing took 2.031073964200914 seconds)
2022-03-06 08:16:15 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:16:15 | INFO | train | epoch 563 | loss 0.697 | nll_loss 0.156 | ppl 1.11 | wps 27766.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27396 | lr 0.000191054 | gnorm 0.352 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64460
2022-03-06 08:16:15 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:24 | INFO | train_inner | epoch 564:      4 / 49 loss=0.697, nll_loss=0.156, ppl=1.11, wps=27792.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.352, loss_scale=32, train_wall=198, gb_free=21.6, wall=64468
2022-03-06 08:17:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:08 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 14.427 | nll_loss 14.248 | ppl 19453.7 | wps 47598.1 | wpb 510.9 | bsz 1 | num_updates 27444 | best_loss 8.288
2022-03-06 08:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27444 updates
2022-03-06 08:18:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:18:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:18:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 564 @ 27444 updates, score 14.427) (writing took 2.075205391040072 seconds)
2022-03-06 08:18:10 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:18:10 | INFO | train | epoch 564 | loss 0.696 | nll_loss 0.155 | ppl 1.11 | wps 27176.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27444 | lr 0.000190887 | gnorm 0.349 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64574
2022-03-06 08:18:10 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:18:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:02 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 14.478 | nll_loss 14.3 | ppl 20176.4 | wps 48020.1 | wpb 510.9 | bsz 1 | num_updates 27493 | best_loss 8.288
2022-03-06 08:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27493 updates
2022-03-06 08:20:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 565 @ 27493 updates, score 14.478) (writing took 1.9939662590622902 seconds)
2022-03-06 08:20:04 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:20:04 | INFO | train | epoch 565 | loss 0.697 | nll_loss 0.156 | ppl 1.11 | wps 27763.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27493 | lr 0.000190717 | gnorm 0.352 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64689
2022-03-06 08:20:04 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:20 | INFO | train_inner | epoch 566:      7 / 49 loss=0.696, nll_loss=0.155, ppl=1.11, wps=27527.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.35, loss_scale=32, train_wall=200, gb_free=21.6, wall=64704
2022-03-06 08:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:21:57 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 14.422 | nll_loss 14.243 | ppl 19391.5 | wps 48017.3 | wpb 510.9 | bsz 1 | num_updates 27542 | best_loss 8.288
2022-03-06 08:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27542 updates
2022-03-06 08:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 566 @ 27542 updates, score 14.422) (writing took 2.028867777902633 seconds)
2022-03-06 08:21:59 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:21:59 | INFO | train | epoch 566 | loss 0.696 | nll_loss 0.155 | ppl 1.11 | wps 27780.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27542 | lr 0.000190547 | gnorm 0.348 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64803
2022-03-06 08:21:59 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:23:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:23:51 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 14.412 | nll_loss 14.232 | ppl 19239 | wps 47695.4 | wpb 510.9 | bsz 1 | num_updates 27590 | best_loss 8.288
2022-03-06 08:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27590 updates
2022-03-06 08:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 567 @ 27590 updates, score 14.412) (writing took 2.075545258121565 seconds)
2022-03-06 08:23:53 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:23:53 | INFO | train | epoch 567 | loss 0.696 | nll_loss 0.155 | ppl 1.11 | wps 27169.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27590 | lr 0.000190381 | gnorm 0.35 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64917
2022-03-06 08:23:53 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:16 | INFO | train_inner | epoch 568:     10 / 49 loss=0.696, nll_loss=0.155, ppl=1.11, wps=27535, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.35, loss_scale=32, train_wall=200, gb_free=21.6, wall=64940
2022-03-06 08:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:25:46 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 14.496 | nll_loss 14.318 | ppl 20425.9 | wps 47608.7 | wpb 510.9 | bsz 1 | num_updates 27639 | best_loss 8.288
2022-03-06 08:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27639 updates
2022-03-06 08:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 568 @ 27639 updates, score 14.496) (writing took 1.9908450888469815 seconds)
2022-03-06 08:25:48 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:25:48 | INFO | train | epoch 568 | loss 0.696 | nll_loss 0.155 | ppl 1.11 | wps 27774.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27639 | lr 0.000190212 | gnorm 0.354 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65032
2022-03-06 08:25:48 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:27:40 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 14.468 | nll_loss 14.289 | ppl 20018.9 | wps 47775.6 | wpb 510.9 | bsz 1 | num_updates 27688 | best_loss 8.288
2022-03-06 08:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27688 updates
2022-03-06 08:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 569 @ 27688 updates, score 14.468) (writing took 2.0542990579269826 seconds)
2022-03-06 08:27:42 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:27:42 | INFO | train | epoch 569 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 27764.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27688 | lr 0.000190044 | gnorm 0.351 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 65146
2022-03-06 08:27:42 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:09 | INFO | train_inner | epoch 570:     12 / 49 loss=0.696, nll_loss=0.155, ppl=1.11, wps=27803.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.352, loss_scale=64, train_wall=198, gb_free=21.6, wall=65173
2022-03-06 08:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:29:35 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 14.47 | nll_loss 14.293 | ppl 20077.3 | wps 48047.5 | wpb 510.9 | bsz 1 | num_updates 27737 | best_loss 8.288
2022-03-06 08:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27737 updates
2022-03-06 08:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 570 @ 27737 updates, score 14.47) (writing took 2.027638563187793 seconds)
2022-03-06 08:29:37 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:29:37 | INFO | train | epoch 570 | loss 0.696 | nll_loss 0.156 | ppl 1.11 | wps 27773.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27737 | lr 0.000189876 | gnorm 0.355 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 65261
2022-03-06 08:29:37 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:29:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:31:29 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 14.382 | nll_loss 14.204 | ppl 18878.7 | wps 47810.6 | wpb 510.9 | bsz 1 | num_updates 27785 | best_loss 8.288
2022-03-06 08:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27785 updates
2022-03-06 08:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 571 @ 27785 updates, score 14.382) (writing took 2.011027618078515 seconds)
2022-03-06 08:31:31 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:31:31 | INFO | train | epoch 571 | loss 0.695 | nll_loss 0.155 | ppl 1.11 | wps 27184.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27785 | lr 0.000189712 | gnorm 0.351 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65375
2022-03-06 08:31:31 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:32:05 | INFO | train_inner | epoch 572:     15 / 49 loss=0.696, nll_loss=0.155, ppl=1.11, wps=27536.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.352, loss_scale=32, train_wall=200, gb_free=21.6, wall=65409
2022-03-06 08:33:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:33:24 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 14.488 | nll_loss 14.31 | ppl 20314.8 | wps 47749.3 | wpb 510.9 | bsz 1 | num_updates 27834 | best_loss 8.288
2022-03-06 08:33:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27834 updates
2022-03-06 08:33:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:33:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 572 @ 27834 updates, score 14.488) (writing took 2.0204744720831513 seconds)
2022-03-06 08:33:26 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:33:26 | INFO | train | epoch 572 | loss 0.695 | nll_loss 0.154 | ppl 1.11 | wps 27776.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27834 | lr 0.000189545 | gnorm 0.347 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65490
2022-03-06 08:33:26 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:34:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:18 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 14.494 | nll_loss 14.318 | ppl 20421.8 | wps 47765.6 | wpb 510.9 | bsz 1 | num_updates 27882 | best_loss 8.288
2022-03-06 08:35:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27882 updates
2022-03-06 08:35:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:35:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 573 @ 27882 updates, score 14.494) (writing took 2.0622149971313775 seconds)
2022-03-06 08:35:20 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:35:20 | INFO | train | epoch 573 | loss 0.695 | nll_loss 0.154 | ppl 1.11 | wps 27183.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27882 | lr 0.000189382 | gnorm 0.35 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65604
2022-03-06 08:35:20 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:36:00 | INFO | train_inner | epoch 574:     18 / 49 loss=0.695, nll_loss=0.154, ppl=1.11, wps=27538.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.348, loss_scale=32, train_wall=200, gb_free=21.6, wall=65644
2022-03-06 08:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:13 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 14.471 | nll_loss 14.292 | ppl 20065.6 | wps 47688.1 | wpb 510.9 | bsz 1 | num_updates 27931 | best_loss 8.288
2022-03-06 08:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27931 updates
2022-03-06 08:37:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:37:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:37:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 574 @ 27931 updates, score 14.471) (writing took 1.993928728858009 seconds)
2022-03-06 08:37:15 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:37:15 | INFO | train | epoch 574 | loss 0.695 | nll_loss 0.155 | ppl 1.11 | wps 27767.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27931 | lr 0.000189216 | gnorm 0.357 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65719
2022-03-06 08:37:15 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:37:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:07 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 14.458 | nll_loss 14.281 | ppl 19908.7 | wps 47752.5 | wpb 510.9 | bsz 1 | num_updates 27980 | best_loss 8.288
2022-03-06 08:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27980 updates
2022-03-06 08:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 575 @ 27980 updates, score 14.458) (writing took 2.0341602130793035 seconds)
2022-03-06 08:39:09 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:39:09 | INFO | train | epoch 575 | loss 0.694 | nll_loss 0.154 | ppl 1.11 | wps 27778 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27980 | lr 0.00018905 | gnorm 0.348 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65833
2022-03-06 08:39:09 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:53 | INFO | train_inner | epoch 576:     20 / 49 loss=0.695, nll_loss=0.154, ppl=1.11, wps=27808.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.352, loss_scale=64, train_wall=198, gb_free=21.6, wall=65878
2022-03-06 08:40:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:01 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 14.441 | nll_loss 14.264 | ppl 19673.4 | wps 48122.3 | wpb 510.9 | bsz 1 | num_updates 28028 | best_loss 8.288
2022-03-06 08:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28028 updates
2022-03-06 08:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 576 @ 28028 updates, score 14.441) (writing took 2.088413105113432 seconds)
2022-03-06 08:41:03 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:41:03 | INFO | train | epoch 576 | loss 0.694 | nll_loss 0.154 | ppl 1.11 | wps 27188.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28028 | lr 0.000188888 | gnorm 0.348 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65948
2022-03-06 08:41:03 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:42:56 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 14.456 | nll_loss 14.279 | ppl 19876.7 | wps 47595.2 | wpb 510.9 | bsz 1 | num_updates 28077 | best_loss 8.288
2022-03-06 08:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28077 updates
2022-03-06 08:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 577 @ 28077 updates, score 14.456) (writing took 2.024599608965218 seconds)
2022-03-06 08:42:58 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:42:58 | INFO | train | epoch 577 | loss 0.694 | nll_loss 0.154 | ppl 1.11 | wps 27762.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28077 | lr 0.000188723 | gnorm 0.345 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66062
2022-03-06 08:42:58 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:49 | INFO | train_inner | epoch 578:     23 / 49 loss=0.694, nll_loss=0.154, ppl=1.11, wps=27532.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.347, loss_scale=32, train_wall=200, gb_free=21.6, wall=66113
2022-03-06 08:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:44:50 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 14.447 | nll_loss 14.272 | ppl 19776.9 | wps 48088.2 | wpb 510.9 | bsz 1 | num_updates 28126 | best_loss 8.288
2022-03-06 08:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28126 updates
2022-03-06 08:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 578 @ 28126 updates, score 14.447) (writing took 2.0285050100646913 seconds)
2022-03-06 08:44:52 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:44:52 | INFO | train | epoch 578 | loss 0.694 | nll_loss 0.153 | ppl 1.11 | wps 27777.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28126 | lr 0.000188558 | gnorm 0.348 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66176
2022-03-06 08:44:52 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:46:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:46:45 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 14.337 | nll_loss 14.159 | ppl 18291.2 | wps 47749.6 | wpb 510.9 | bsz 1 | num_updates 28174 | best_loss 8.288
2022-03-06 08:46:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28174 updates
2022-03-06 08:46:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:46:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:46:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 579 @ 28174 updates, score 14.337) (writing took 2.0809672239702195 seconds)
2022-03-06 08:46:47 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-06 08:46:47 | INFO | train | epoch 579 | loss 0.693 | nll_loss 0.153 | ppl 1.11 | wps 27178.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28174 | lr 0.000188398 | gnorm 0.344 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66291
2022-03-06 08:46:47 | INFO | fairseq.trainer | begin training epoch 580
2022-03-06 08:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:47:45 | INFO | train_inner | epoch 580:     26 / 49 loss=0.693, nll_loss=0.153, ppl=1.11, wps=27534.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.346, loss_scale=32, train_wall=200, gb_free=21.6, wall=66349
2022-03-06 08:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:48:39 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 14.521 | nll_loss 14.346 | ppl 20829.7 | wps 47673.1 | wpb 510.9 | bsz 1 | num_updates 28223 | best_loss 8.288
2022-03-06 08:48:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28223 updates
2022-03-06 08:48:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 580 @ 28223 updates, score 14.521) (writing took 2.064762687077746 seconds)
2022-03-06 08:48:41 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-06 08:48:41 | INFO | train | epoch 580 | loss 0.694 | nll_loss 0.154 | ppl 1.11 | wps 27759.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28223 | lr 0.000188234 | gnorm 0.346 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66405
2022-03-06 08:48:41 | INFO | fairseq.trainer | begin training epoch 581
2022-03-06 08:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:50:34 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 14.497 | nll_loss 14.322 | ppl 20479.2 | wps 47983.2 | wpb 510.9 | bsz 1 | num_updates 28272 | best_loss 8.288
2022-03-06 08:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28272 updates
2022-03-06 08:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:50:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 581 @ 28272 updates, score 14.497) (writing took 2.0395989981479943 seconds)
2022-03-06 08:50:36 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-06 08:50:36 | INFO | train | epoch 581 | loss 0.693 | nll_loss 0.153 | ppl 1.11 | wps 27769.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28272 | lr 0.000188071 | gnorm 0.348 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66520
2022-03-06 08:50:36 | INFO | fairseq.trainer | begin training epoch 582
2022-03-06 08:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:51:38 | INFO | train_inner | epoch 582:     28 / 49 loss=0.693, nll_loss=0.153, ppl=1.11, wps=27793.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.347, loss_scale=64, train_wall=198, gb_free=21.6, wall=66582
2022-03-06 08:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:52:28 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 14.416 | nll_loss 14.239 | ppl 19329.5 | wps 48007.2 | wpb 510.9 | bsz 1 | num_updates 28321 | best_loss 8.288
2022-03-06 08:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28321 updates
2022-03-06 08:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 582 @ 28321 updates, score 14.416) (writing took 2.0547055169008672 seconds)
2022-03-06 08:52:30 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-06 08:52:30 | INFO | train | epoch 582 | loss 0.693 | nll_loss 0.153 | ppl 1.11 | wps 27766.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28321 | lr 0.000187908 | gnorm 0.349 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 66634
2022-03-06 08:52:30 | INFO | fairseq.trainer | begin training epoch 583
2022-03-06 08:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:54:23 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 14.458 | nll_loss 14.282 | ppl 19920.6 | wps 47992.2 | wpb 510.9 | bsz 1 | num_updates 28369 | best_loss 8.288
2022-03-06 08:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28369 updates
2022-03-06 08:54:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt
2022-03-06 08:54:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.02_#1/checkpoint_last.pt (epoch 583 @ 28369 updates, score 14.458) (writing took 2.0297952571418136 seconds)
2022-03-06 08:54:25 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-06 08:54:25 | INFO | train | epoch 583 | loss 0.693 | nll_loss 0.153 | ppl 1.11 | wps 27209.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28369 | lr 0.000187749 | gnorm 0.349 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66749
2022-03-06 08:54:25 | INFO | fairseq.trainer | begin training epoch 584
2022-03-06 08:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:55:34 | INFO | train_inner | epoch 584:     31 / 49 loss=0.693, nll_loss=0.153, ppl=1.11, wps=27548.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.35, loss_scale=32, train_wall=200, gb_free=21.6, wall=66818
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4216, in multi_head_attention_forward
    k = linear(key, k_proj_weight_non_opt, in_proj_bias[embed_dim:(embed_dim * 2)])
KeyboardInterrupt
