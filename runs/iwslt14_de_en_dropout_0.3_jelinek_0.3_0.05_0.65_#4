Sender: LSF System <lsfadmin@eu-g3-055>
Subject: Job 210595984: <iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:40:37 2022
Job was executed on host(s) <eu-g3-055>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:40:59 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:40:59 2022
Terminated at Wed Mar 23 12:57:46 2022
Results reported at Wed Mar 23 12:57:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.3,0.05,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4595.37 sec.
    Max Memory :                                 5202 MB
    Average Memory :                             3995.66 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14798.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4608 sec.
    Turnaround time :                            4629 sec.

The output (if any) follows:

2022-03-23 11:41:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.3,0.05,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.3,0.05,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:41:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:41:09 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1101/160239 [00:00<00:14, 11005.47it/s]  1%|▏         | 2378/160239 [00:00<00:13, 12040.53it/s]  2%|▏         | 3696/160239 [00:00<00:12, 12560.32it/s]  3%|▎         | 5012/160239 [00:00<00:12, 12796.58it/s]  4%|▍         | 6292/160239 [00:00<00:12, 12605.16it/s]  5%|▍         | 7563/160239 [00:00<00:12, 12635.42it/s]  6%|▌         | 8827/160239 [00:00<00:12, 12343.13it/s]  6%|▋         | 10136/160239 [00:00<00:11, 12575.58it/s]  7%|▋         | 11464/160239 [00:00<00:11, 12784.37it/s]  8%|▊         | 12744/160239 [00:01<00:11, 12714.41it/s]  9%|▊         | 14017/160239 [00:01<00:11, 12630.52it/s] 10%|▉         | 15281/160239 [00:01<00:11, 12556.65it/s] 10%|█         | 16538/160239 [00:01<00:11, 12225.08it/s] 11%|█         | 17763/160239 [00:01<00:11, 12157.61it/s] 12%|█▏        | 19003/160239 [00:01<00:11, 12228.36it/s] 13%|█▎        | 20400/160239 [00:01<00:10, 12741.74it/s] 14%|█▎        | 21676/160239 [00:01<00:11, 12380.34it/s] 14%|█▍        | 22918/160239 [00:01<00:11, 12381.63it/s] 15%|█▌        | 24161/160239 [00:01<00:10, 12395.58it/s] 16%|█▌        | 25419/160239 [00:02<00:10, 12448.83it/s] 17%|█▋        | 26666/160239 [00:02<00:10, 12270.02it/s] 17%|█▋        | 27978/160239 [00:02<00:10, 12519.74it/s] 18%|█▊        | 29232/160239 [00:02<00:10, 12487.08it/s] 19%|█▉        | 30482/160239 [00:02<00:10, 12156.71it/s] 20%|█▉        | 31838/160239 [00:02<00:10, 12560.21it/s] 21%|██        | 33097/160239 [00:02<00:10, 12360.68it/s] 21%|██▏       | 34336/160239 [00:02<00:10, 12132.29it/s] 22%|██▏       | 35552/160239 [00:02<00:10, 12009.28it/s] 23%|██▎       | 36866/160239 [00:02<00:10, 12336.30it/s] 24%|██▍       | 38102/160239 [00:03<00:09, 12300.05it/s] 25%|██▍       | 39356/160239 [00:03<00:09, 12369.35it/s] 25%|██▌       | 40651/160239 [00:03<00:09, 12538.50it/s] 26%|██▌       | 41906/160239 [00:03<00:09, 12282.89it/s] 27%|██▋       | 43136/160239 [00:03<00:09, 12061.42it/s] 28%|██▊       | 44344/160239 [00:03<00:09, 11823.40it/s] 28%|██▊       | 45656/160239 [00:03<00:09, 12197.52it/s] 29%|██▉       | 46925/160239 [00:03<00:09, 12340.34it/s] 30%|███       | 48187/160239 [00:03<00:09, 12420.03it/s] 31%|███       | 49435/160239 [00:03<00:08, 12436.24it/s] 32%|███▏      | 50680/160239 [00:04<00:08, 12373.70it/s] 32%|███▏      | 51923/160239 [00:04<00:08, 12386.12it/s] 33%|███▎      | 53210/160239 [00:04<00:08, 12527.01it/s] 34%|███▍      | 54464/160239 [00:04<00:08, 12467.13it/s] 35%|███▍      | 55712/160239 [00:04<00:08, 12444.74it/s] 36%|███▌      | 56957/160239 [00:04<00:08, 12443.05it/s] 36%|███▋      | 58274/160239 [00:04<00:08, 12659.30it/s] 37%|███▋      | 59550/160239 [00:04<00:07, 12689.07it/s] 38%|███▊      | 60820/160239 [00:04<00:07, 12654.11it/s] 39%|███▊      | 62086/160239 [00:05<00:07, 12456.26it/s] 40%|███▉      | 63429/160239 [00:05<00:07, 12742.82it/s] 40%|████      | 64863/160239 [00:05<00:07, 13217.04it/s] 41%|████▏     | 66186/160239 [00:05<00:07, 13193.87it/s] 42%|████▏     | 67507/160239 [00:05<00:07, 12701.09it/s] 43%|████▎     | 68782/160239 [00:05<00:07, 12486.43it/s] 44%|████▎     | 70060/160239 [00:05<00:07, 12570.78it/s] 45%|████▍     | 71366/160239 [00:05<00:06, 12711.35it/s] 45%|████▌     | 72640/160239 [00:05<00:07, 12487.09it/s] 46%|████▌     | 73891/160239 [00:05<00:06, 12415.86it/s] 47%|████▋     | 75134/160239 [00:06<00:06, 12312.76it/s] 48%|████▊     | 76367/160239 [00:06<00:06, 12269.15it/s] 49%|████▊     | 77737/160239 [00:06<00:06, 12688.78it/s] 49%|████▉     | 79012/160239 [00:06<00:06, 12703.36it/s] 50%|█████     | 80351/160239 [00:06<00:06, 12905.82it/s] 51%|█████     | 81698/160239 [00:06<00:06, 13072.71it/s] 52%|█████▏    | 83010/160239 [00:06<00:05, 13078.98it/s] 53%|█████▎    | 84319/160239 [00:06<00:05, 12782.62it/s] 53%|█████▎    | 85674/160239 [00:06<00:05, 13006.96it/s] 54%|█████▍    | 87030/160239 [00:06<00:05, 13169.01it/s] 55%|█████▌    | 88349/160239 [00:07<00:05, 12886.62it/s] 56%|█████▌    | 89717/160239 [00:07<00:05, 13112.63it/s] 57%|█████▋    | 91031/160239 [00:07<00:05, 12873.28it/s] 58%|█████▊    | 92321/160239 [00:07<00:05, 12824.87it/s] 58%|█████▊    | 93605/160239 [00:07<00:05, 12710.52it/s] 59%|█████▉    | 94878/160239 [00:07<00:05, 12426.88it/s] 60%|██████    | 96159/160239 [00:07<00:05, 12418.02it/s] 61%|██████    | 97402/160239 [00:07<00:05, 12404.57it/s] 62%|██████▏   | 98695/160239 [00:07<00:04, 12553.73it/s] 62%|██████▏   | 100021/160239 [00:07<00:04, 12761.39it/s] 63%|██████▎   | 101321/160239 [00:08<00:04, 12830.10it/s] 64%|██████▍   | 102605/160239 [00:08<00:04, 12620.72it/s] 65%|██████▍   | 103869/160239 [00:08<00:04, 12497.79it/s] 66%|██████▌   | 105242/160239 [00:08<00:04, 12859.86it/s] 66%|██████▋   | 106530/160239 [00:08<00:04, 12784.41it/s] 67%|██████▋   | 107810/160239 [00:08<00:04, 12441.10it/s] 68%|██████▊   | 109057/160239 [00:08<00:04, 12223.07it/s] 69%|██████▉   | 110290/160239 [00:08<00:04, 12253.80it/s] 70%|██████▉   | 111629/160239 [00:08<00:03, 12583.01it/s] 70%|███████   | 112890/160239 [00:09<00:03, 12434.46it/s] 71%|███████▏  | 114221/160239 [00:09<00:03, 12691.63it/s] 72%|███████▏  | 115492/160239 [00:09<00:03, 12577.38it/s] 73%|███████▎  | 116751/160239 [00:09<00:03, 12476.51it/s] 74%|███████▎  | 118012/160239 [00:09<00:03, 12515.32it/s] 74%|███████▍  | 119338/160239 [00:09<00:03, 12735.00it/s] 75%|███████▌  | 120613/160239 [00:09<00:03, 12502.24it/s] 76%|███████▌  | 121992/160239 [00:09<00:02, 12880.82it/s] 77%|███████▋  | 123290/160239 [00:09<00:02, 12907.30it/s] 78%|███████▊  | 124582/160239 [00:09<00:02, 12647.67it/s] 79%|███████▊  | 125849/160239 [00:10<00:02, 12483.15it/s] 79%|███████▉  | 127115/160239 [00:10<00:02, 12532.66it/s] 80%|████████  | 128452/160239 [00:10<00:02, 12778.70it/s] 81%|████████  | 129732/160239 [00:10<00:02, 12566.26it/s] 82%|████████▏ | 130991/160239 [00:10<00:02, 12260.81it/s] 83%|████████▎ | 132237/160239 [00:10<00:02, 12317.13it/s] 83%|████████▎ | 133471/160239 [00:10<00:02, 12147.94it/s] 84%|████████▍ | 134722/160239 [00:10<00:02, 12252.85it/s] 85%|████████▍ | 135983/160239 [00:10<00:01, 12357.10it/s] 86%|████████▌ | 137258/160239 [00:10<00:01, 12472.02it/s] 86%|████████▋ | 138573/160239 [00:11<00:01, 12672.42it/s] 87%|████████▋ | 139887/160239 [00:11<00:01, 12811.16it/s] 88%|████████▊ | 141225/160239 [00:11<00:01, 12978.71it/s] 89%|████████▉ | 142524/160239 [00:11<00:01, 12647.20it/s] 90%|████████▉ | 143791/160239 [00:11<00:01, 12631.75it/s] 91%|█████████ | 145056/160239 [00:11<00:01, 12507.18it/s] 91%|█████████▏| 146308/160239 [00:11<00:01, 12346.96it/s] 92%|█████████▏| 147544/160239 [00:11<00:01, 12306.53it/s] 93%|█████████▎| 148776/160239 [00:11<00:00, 12053.43it/s] 94%|█████████▎| 150021/160239 [00:11<00:00, 12167.97it/s] 94%|█████████▍| 151280/160239 [00:12<00:00, 12289.40it/s] 95%|█████████▌| 152510/160239 [00:12<00:00, 12259.47it/s] 96%|█████████▌| 153737/160239 [00:12<00:00, 12110.93it/s] 97%|█████████▋| 155087/160239 [00:12<00:00, 12520.41it/s] 98%|█████████▊| 156362/160239 [00:12<00:00, 12586.60it/s] 98%|█████████▊| 157637/160239 [00:12<00:00, 12632.98it/s] 99%|█████████▉| 158901/160239 [00:12<00:00, 12061.37it/s]100%|█████████▉| 160226/160239 [00:12<00:00, 12404.30it/s]100%|██████████| 160239/160239 [00:12<00:00, 12517.48it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3955/160239 [00:00<00:03, 39546.45it/s]  5%|▍         | 7917/160239 [00:00<00:03, 39587.35it/s]  7%|▋         | 11916/160239 [00:00<00:03, 39767.45it/s] 10%|▉         | 15893/160239 [00:00<00:03, 39698.04it/s] 12%|█▏        | 19899/160239 [00:00<00:03, 39827.98it/s] 15%|█▍        | 23882/160239 [00:00<00:03, 39624.30it/s] 17%|█▋        | 27845/160239 [00:00<00:03, 39620.48it/s] 20%|█▉        | 31840/160239 [00:00<00:03, 39723.26it/s] 22%|██▏       | 35813/160239 [00:00<00:03, 39172.95it/s] 25%|██▍       | 39775/160239 [00:01<00:03, 39308.83it/s] 27%|██▋       | 43708/160239 [00:01<00:02, 39060.27it/s] 30%|██▉       | 47761/160239 [00:01<00:02, 39501.45it/s] 32%|███▏      | 51713/160239 [00:01<00:02, 39465.66it/s] 35%|███▍      | 55687/160239 [00:01<00:02, 39545.95it/s] 37%|███▋      | 59836/160239 [00:01<00:02, 40127.93it/s] 40%|███▉      | 63850/160239 [00:01<00:02, 40046.50it/s] 42%|████▏     | 68036/160239 [00:01<00:02, 40587.55it/s] 45%|████▍     | 72096/160239 [00:01<00:02, 40106.89it/s] 47%|████▋     | 76109/160239 [00:01<00:02, 39771.57it/s] 50%|█████     | 80272/160239 [00:02<00:01, 40320.97it/s] 53%|█████▎    | 84354/160239 [00:02<00:01, 40465.21it/s] 55%|█████▌    | 88494/160239 [00:02<00:01, 40743.45it/s] 58%|█████▊    | 92584/160239 [00:02<00:01, 40787.49it/s] 60%|██████    | 96664/160239 [00:02<00:01, 40382.52it/s] 63%|██████▎   | 100772/160239 [00:02<00:01, 40589.17it/s] 65%|██████▌   | 104861/160239 [00:02<00:01, 40674.05it/s] 68%|██████▊   | 108930/160239 [00:02<00:01, 40089.29it/s] 70%|███████   | 112942/160239 [00:02<00:01, 40090.19it/s] 73%|███████▎  | 116953/160239 [00:02<00:01, 40069.63it/s] 76%|███████▌  | 121015/160239 [00:03<00:00, 40230.85it/s] 78%|███████▊  | 125071/160239 [00:03<00:00, 40326.24it/s] 81%|████████  | 129121/160239 [00:03<00:00, 40372.98it/s] 83%|████████▎ | 133159/160239 [00:03<00:00, 39775.16it/s] 86%|████████▌ | 137139/160239 [00:03<00:00, 39739.13it/s] 88%|████████▊ | 141279/160239 [00:03<00:00, 40231.27it/s] 91%|█████████ | 145304/160239 [00:03<00:00, 39993.17it/s] 93%|█████████▎| 149305/160239 [00:03<00:00, 39501.30it/s] 96%|█████████▌| 153266/160239 [00:03<00:00, 39532.24it/s] 98%|█████████▊| 157324/160239 [00:03<00:00, 39842.34it/s]100%|██████████| 160239/160239 [00:04<00:00, 39950.52it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2381.77it/s]2022-03-23 11:41:29 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:41:29 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:41:29 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:41:29 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:41:29 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:41:29 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:41:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:41:29 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:41:29 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:41:30 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:41:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:30 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:41:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:30 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:41:30 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:41:30 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 11:41:30 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 11:41:30 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:41:30 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:41:30 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:41:30 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:41:30 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:41:30 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:41:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:41:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:41:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:41:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:42:15 | INFO | train_inner | epoch 001:    104 / 157 loss=13.679, ppl=13117.1, wps=65009.1, ups=2.58, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=2.604, loss_scale=8, train_wall=44, gb_free=11.8, wall=45
2022-03-23 11:42:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:37 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:42:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:42:40 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:42:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:42:52 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:42:57 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:43:02 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:15 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:17 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.754 | ppl 13818.5 | bleu 0.01 | wps 4073.1 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:43:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:43:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:43:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:43:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6149922740878537 seconds)
2022-03-23 11:43:19 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:43:19 | INFO | train | epoch 001 | loss 13.301 | ppl 10095.8 | wps 37094.8 | ups 1.48 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 1.994 | loss_scale 8 | train_wall 63 | gb_free 12.1 | wall 110
KL Stats: Epoch 1 Divergences: Uniform: 0.5084172351908197 Unigram: 1.4801626833479853
2022-03-23 11:43:19 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:37 | INFO | train_inner | epoch 002:     47 / 157 loss=12.437, ppl=5546.66, wps=30226.5, ups=1.21, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=0.86, loss_scale=8, train_wall=36, gb_free=22.3, wall=128
2022-03-23 11:44:15 | INFO | train_inner | epoch 002:    147 / 157 loss=12.014, ppl=4136.39, wps=66188, ups=2.64, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.873, loss_scale=8, train_wall=37, gb_free=12.1, wall=165
2022-03-23 11:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:44:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 11:44:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i,,,,,,,.
2022-03-23 11:44:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:44:32 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:44:36 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 11:44:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:44:40 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we we we we we we we we we we we we we we.
2022-03-23 11:44:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example hypothesis: and and the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:44:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:00 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:45:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:00 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.19 | ppl 9343.96 | bleu 0.03 | wps 4253.6 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.03
2022-03-23 11:45:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:45:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.03) (writing took 1.7158752899849787 seconds)
2022-03-23 11:45:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:45:02 | INFO | train | epoch 002 | loss 12.048 | ppl 4233.78 | wps 38301.9 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.882 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 213
KL Stats: Epoch 2 Divergences: Uniform: 0.5111907538273022 Unigram: 0.46043126770063686
2022-03-23 11:45:03 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:36 | INFO | train_inner | epoch 003:     90 / 157 loss=11.819, ppl=3612.41, wps=30588.8, ups=1.23, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.932, loss_scale=8, train_wall=37, gb_free=12, wall=247
2022-03-23 11:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:05 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:46:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example hypothesis: it's's's.
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:46:13 | INFO | fairseq.tasks.translation | example hypothesis: so i i to to a a a a a a.
2022-03-23 11:46:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:46:17 | INFO | fairseq.tasks.translation | example hypothesis: so was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 11:46:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:46:22 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we, we, we we we, we we, we we, we, we we, we we, we, we, and we we we to we we we we we we we we
2022-03-23 11:46:22 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:46:27 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we to we we to we to we to the to the to the the to to the to to to the to to to to to to we we we we we we to to to to to to to to to to to to to to to to to the
2022-03-23 11:46:27 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:46:33 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, but but the, but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but the the, but the, but but but but but but but but but but but the, but but but but but but but but but but the
2022-03-23 11:46:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:39 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we the the the, and we we we the the the the the the the the the of the, and we we the the the the the the the the the the of the, and we the the the the the of the, and we we we we we we the the the the the the the the the of the of we we we we we the the the the the the the the of the of the, and we we
2022-03-23 11:46:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:47 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:46:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:49 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, the, the, we the, we the, we the, we the, we the, the, we the the the, the, the the, we the the the the the the the, the, the, the the, we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, the, and the, the the the the the the, the the the, we we we we we we we we we we we the the the, the the, the the, the the the the the the the the the, we we we we we we we we the the the the the the the the the the the the, we we we we we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 11:46:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:49 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.957 | ppl 7953.61 | bleu 0.2 | wps 3735.4 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.2
2022-03-23 11:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.2) (writing took 1.7072018900653347 seconds)
2022-03-23 11:46:51 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:46:51 | INFO | train | epoch 003 | loss 11.706 | ppl 3341.42 | wps 36403.4 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.928 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 321
KL Stats: Epoch 3 Divergences: Uniform: 0.59447886375572 Unigram: 0.46967843766082684
2022-03-23 11:46:51 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:04 | INFO | train_inner | epoch 004:     33 / 157 loss=11.551, ppl=3000.74, wps=29352.4, ups=1.15, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=0.954, loss_scale=8, train_wall=37, gb_free=12, wall=334
2022-03-23 11:47:41 | INFO | train_inner | epoch 004:    133 / 157 loss=11.365, ppl=2637.93, wps=66927.1, ups=2.65, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.03, loss_scale=8, train_wall=37, gb_free=12.4, wall=372
2022-03-23 11:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:54 | INFO | fairseq.tasks.translation | example hypothesis: so you can can can can can can can can can can can have to be.
2022-03-23 11:47:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:47:59 | INFO | fairseq.tasks.translation | example hypothesis: he's the world in the world of the world, he he's he he was in the world.
2022-03-23 11:47:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:48:05 | INFO | fairseq.tasks.translation | example hypothesis: so i'm to be a world, i'm'm'm to be to be a lot, and i'm to be to be to be to be a lot of the world,
2022-03-23 11:48:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:48:10 | INFO | fairseq.tasks.translation | example hypothesis: he was, he was he was, he was he was was, he was he was was was was was was was was he was was was was was was was was was was was was was was was a
2022-03-23 11:48:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:48:16 | INFO | fairseq.tasks.translation | example hypothesis: and we know, and we know, and we know, what we can can can know, and we know, and we can can can can can can can can can can can can can can can can can can can can can can can know
2022-03-23 11:48:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:48:22 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can can can can can or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 11:48:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:48:28 | INFO | fairseq.tasks.translation | example hypothesis: but if if you're, but you're the world, but you're the world, but you're the world, and you know, but you're the world, and you're're're're the world, and you're're the world, and they're're're're're're're the world, and they're the world, and they're the
2022-03-23 11:48:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:34 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we can can can can can can can can can can can can can can can can can can can can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the
2022-03-23 11:48:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and i said, and i said, "" "" "" "" "" "" "" "" "" you're, and you can can can can can can can can can can can can can can can can can can can can can can can have to be to be to be, "" "" "" "" "" "" "" "" it, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:44 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and we have the world, and we have the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world, and the world, and the world of the world, and it's the world, and it's the world, and it's the world, and it's the world, and it's the world of the world, and it's the world, and it's the world, and it's the world, and it's the world, and the
2022-03-23 11:48:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:44 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.69 | ppl 6607.82 | bleu 0.78 | wps 3269.5 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.78
2022-03-23 11:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.78) (writing took 1.6992968650301918 seconds)
2022-03-23 11:48:46 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:48:46 | INFO | train | epoch 004 | loss 11.449 | ppl 2795.97 | wps 34256.1 | ups 1.36 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.022 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 436
KL Stats: Epoch 4 Divergences: Uniform: 0.611027542938749 Unigram: 0.7156568701505654
2022-03-23 11:48:46 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:15 | INFO | train_inner | epoch 005:     76 / 157 loss=11.267, ppl=2464.51, wps=26797.8, ups=1.07, wpb=25097.7, bsz=1058.7, num_updates=700, lr=8.75e-05, gnorm=1.249, loss_scale=8, train_wall=37, gb_free=11.9, wall=465
2022-03-23 11:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can see that.
2022-03-23 11:49:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:49:54 | INFO | fairseq.tasks.translation | example hypothesis: he's a lot of the world.
2022-03-23 11:49:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:49:59 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to be a lot of the world, and i can be a lot of a lot of a lot of a lot of the world, i can can can be a
2022-03-23 11:49:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:50:04 | INFO | fairseq.tasks.translation | example hypothesis: he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was
2022-03-23 11:50:04 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:50:10 | INFO | fairseq.tasks.translation | example hypothesis: and what we have a lot of what we have a lot of a lot of a lot, and we're going to do, and we're going to do, and we're going to do, and we're going to do what we have
2022-03-23 11:50:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to be or or or or or or or or or or or or or or or or or or or or we can can can be, or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 11:50:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:50:22 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not a lot of the world, but it's a lot of the world, but they're not not not not not not not not a lot of the world, but it, but it, but it, but it's a lot of the world, but it's a lot of the world.
2022-03-23 11:50:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:28 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world of the world of the world of the world, and we can see the world, and we can see the world of the world, and we can see the world
2022-03-23 11:50:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" i said, "" "" "" "" i said, "i said," i said, "i said," "" "" "" "" "" "" "we said," "" i said, "" "" "" "" "" "" "" "" "" "i said," "i said," i said, "i said," "" i said, "" "" "" "" "" "" "" "" "" "" "" i said, "i said," i said, "" we said, "" "" "" "" "" "" "" "" "" "" we said, "i said," "" "" "" "" "" "" "" "" i said, "" "
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example hypothesis: and i think, we think that we have to be the world of the world of the world of the world, and we have to get the world of the world of the world of the world of the world, and we have to get the world of the world, and it's a lot of the world of the world of the world of the world of the world, and we've've've've have to be the world, which is that we have to do the world, which is that we think, and the world of the world of the world of the world of the world of the world, which is that we have to do the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.414 | ppl 5457.72 | bleu 1.26 | wps 3387.3 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.26
2022-03-23 11:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:50:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.26) (writing took 1.714132928987965 seconds)
2022-03-23 11:50:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:50:39 | INFO | train | epoch 005 | loss 11.207 | ppl 2363.98 | wps 34781.2 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.114 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 550
KL Stats: Epoch 5 Divergences: Uniform: 0.646326203760618 Unigram: 0.897786069244489
2022-03-23 11:50:40 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:47 | INFO | train_inner | epoch 006:     19 / 157 loss=11.223, ppl=2389.78, wps=27138.2, ups=1.08, wpb=25039.8, bsz=950.1, num_updates=800, lr=0.0001, gnorm=1.01, loss_scale=8, train_wall=37, gb_free=12, wall=558
2022-03-23 11:51:25 | INFO | train_inner | epoch 006:    119 / 157 loss=11.017, ppl=2072.99, wps=66689.6, ups=2.65, wpb=25126.8, bsz=945, num_updates=900, lr=0.0001125, gnorm=0.932, loss_scale=8, train_wall=37, gb_free=11.5, wall=595
2022-03-23 11:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:43 | INFO | fairseq.tasks.translation | example hypothesis: it can be a lot of this.
2022-03-23 11:51:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:51:47 | INFO | fairseq.tasks.translation | example hypothesis: he can be in the world.
2022-03-23 11:51:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:51:51 | INFO | fairseq.tasks.translation | example hypothesis: and i can see that i can see this is that i can can be a lot of the world.
2022-03-23 11:51:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:51:56 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was a lot of the time, and he was a lot of my time.
2022-03-23 11:51:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, and we're going to do what we're going to do?
2022-03-23 11:52:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to make the world, and we're going to do the world, and we're going to do the world, and we're going to do that we're going to do the world.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example hypothesis: and if you're going to be a lot of the way, but you're going to be, but you're going to be a lot of the way of the way, but they're going to be a lot of the way, and you're going to be a lot of the way.
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:18 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to see the world, we're going to see the world, and we're going to see the world, and we're going to see the world.
2022-03-23 11:52:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:25 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" we said, "" "" "we're going to say," "" "we're going to do," we're going to say, "we're going to say," we're going to say, and we're going to say, "" "" "we're going to say," "" we're going to say, and we're going to go to say, "we're going to go to say," we're going to say, "" it, and we're going to say, "" it, and we're going to say, and we're going to say, and we're going to go to say, "it's going to do, and we're going to say, and we're going to go to say," it's going to go to say, "" we're going to do, "" "
2022-03-23 11:52:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:27 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a lot of the world, and we're going to do that we're going to be a lot of the world, and we're going to make the world, and we're going to make the world, and we're going to do the world, and we're going to make the world, and we're going to do the world, and we're going to do that we're going to get to make the world, and we're going to do that we're going to make the world, and we're going to get to make the world, and we're going to make the world, and we're going to do that we're going to make the world, and we're going to do that we're going to make the world, and we're going to make the world, and we're going to do that we're going to make the world, and we're going to do the world, and we're going to make the world, and we're going to do the world, and we're going to
2022-03-23 11:52:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:27 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 12.231 | ppl 4807.87 | bleu 1.83 | wps 3729.3 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.83
2022-03-23 11:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:52:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.83) (writing took 1.7175375029910356 seconds)
2022-03-23 11:52:29 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:52:29 | INFO | train | epoch 006 | loss 11.001 | ppl 2048.86 | wps 36201.7 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.015 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 659
KL Stats: Epoch 6 Divergences: Uniform: 0.6830408527820011 Unigram: 1.0267605459221258
2022-03-23 11:52:29 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:53 | INFO | train_inner | epoch 007:     62 / 157 loss=10.978, ppl=2016.88, wps=28476.6, ups=1.14, wpb=24967.7, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.921, loss_scale=8, train_wall=37, gb_free=12.4, wall=683
2022-03-23 11:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:32 | INFO | fairseq.tasks.translation | example hypothesis: these can't have a lot of this.
2022-03-23 11:53:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:53:36 | INFO | fairseq.tasks.translation | example hypothesis: in fact, he had a year.
2022-03-23 11:53:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:53:40 | INFO | fairseq.tasks.translation | example hypothesis: so, i can make a lot of course, i can't have a lot of this.
2022-03-23 11:53:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:53:44 | INFO | fairseq.tasks.translation | example hypothesis: he was no, because he was no, because he was no, because he was no time.
2022-03-23 11:53:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:53:49 | INFO | fairseq.tasks.translation | example hypothesis: and so what we have a lot of what is what we have to do is a lot of what we've got to do with a lot of what we have to do?
2022-03-23 11:53:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to talk about our world or or or or or or or or or or or or, or we're going to talk about our things.
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example hypothesis: but if you don't have a lot of people, you're going to have a lot of people, but they're going to have a lot of the way, but they're not not not not not a lot of the way.
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make a lot of the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world, and we're going to make the world,
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:11 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:54:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:14 | INFO | fairseq.tasks.translation | example hypothesis: and if we have a lot of the world, it's a lot of the world, and we're going to be a lot of the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to be a lot of the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to get to get to get to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, and we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, and
2022-03-23 11:54:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:14 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 12.062 | ppl 4274.65 | bleu 2.45 | wps 3921.1 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.45
2022-03-23 11:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.45) (writing took 1.7051247080089524 seconds)
2022-03-23 11:54:15 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:54:15 | INFO | train | epoch 007 | loss 10.817 | ppl 1804.39 | wps 36989.9 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.892 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 766
KL Stats: Epoch 7 Divergences: Uniform: 0.7112039241921312 Unigram: 1.1225211399306925
2022-03-23 11:54:16 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:18 | INFO | train_inner | epoch 008:      5 / 157 loss=10.674, ppl=1633.71, wps=29837.6, ups=1.17, wpb=25396.2, bsz=1052.4, num_updates=1100, lr=0.0001375, gnorm=0.924, loss_scale=8, train_wall=37, gb_free=12.1, wall=768
2022-03-23 11:54:56 | INFO | train_inner | epoch 008:    105 / 157 loss=10.686, ppl=1647.5, wps=66647, ups=2.64, wpb=25204.4, bsz=1027.4, num_updates=1200, lr=0.00015, gnorm=0.84, loss_scale=8, train_wall=37, gb_free=12.3, wall=806
2022-03-23 11:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:19 | INFO | fairseq.tasks.translation | example hypothesis: these can be able.
2022-03-23 11:55:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:55:22 | INFO | fairseq.tasks.translation | example hypothesis: last year in the last year.
2022-03-23 11:55:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:55:26 | INFO | fairseq.tasks.translation | example hypothesis: so, this can be a lot of course, i can make a lot of course.
2022-03-23 11:55:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:55:30 | INFO | fairseq.tasks.translation | example hypothesis: he had had his father, because he was his father, because he was his father was his father.
2022-03-23 11:55:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my day, we had a lot of us, and what we're going to do with a lot of what we're going to do with what we're going to do with what we're going to do?
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:55:39 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about the same time or about the other other other other or or or or or the other other other other other other other or or or or or or the other other other other other other other or or or or or or or or or or or or or or
2022-03-23 11:55:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:55:44 | INFO | fairseq.tasks.translation | example hypothesis: some of them are some of them, but if you're not going to be a lot of them, but it's not not just a lot of the way, but it's not not not the way.
2022-03-23 11:55:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the way, we can see the way of the way, and we can make the way to make the way that we can make the way with the way, and then we can make the way that we can make the way with the way of the way of the way of the way, and then we can make the way, and then we can make the way with the way with the way with the way, we can make the
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of the one, we said, "we said," it's going to say, "if we're going to do it," we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it, and then we're going to do it, and we're going to do it, and we're going to do it, and we're going to do it, "it," it, and then we're going to do it, and we're going to do it, and we're going to do it, "it's going to do it, and we're going to do it's going to do it, and we're going to do it, and then we're going to do it, and we're going to do it, and then we're going to be a a
2022-03-23 11:55:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a little bit of the way that we're going to get a lot of the way.
2022-03-23 11:55:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:57 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.912 | ppl 3854.65 | bleu 3.8 | wps 4312.6 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.8
2022-03-23 11:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.8) (writing took 1.7381524699740112 seconds)
2022-03-23 11:55:58 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:55:58 | INFO | train | epoch 008 | loss 10.671 | ppl 1630.22 | wps 38286.2 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.898 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 869
KL Stats: Epoch 8 Divergences: Uniform: 0.7363698091087402 Unigram: 1.1859775231800047
2022-03-23 11:55:59 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:17 | INFO | train_inner | epoch 009:     48 / 157 loss=10.605, ppl=1557.18, wps=30734, ups=1.23, wpb=24959.6, bsz=1001.8, num_updates=1300, lr=0.0001625, gnorm=0.925, loss_scale=8, train_wall=37, gb_free=11.8, wall=887
2022-03-23 11:56:55 | INFO | train_inner | epoch 009:    148 / 157 loss=10.51, ppl=1457.73, wps=66912.5, ups=2.64, wpb=25342.7, bsz=1020.9, num_updates=1400, lr=0.000175, gnorm=0.855, loss_scale=8, train_wall=38, gb_free=11.8, wall=925
2022-03-23 11:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example hypothesis: this can't have no way.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:57:06 | INFO | fairseq.tasks.translation | example hypothesis: and the last year, he can be about the last year in the last year.
2022-03-23 11:57:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course, i can see, i can be a lot of course.
2022-03-23 11:57:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because he had his father, because she had his father, because she had his father was his father.
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i'm going to say, and what we're going to do, and we're going to do?
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:57:26 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to talk about our time, and we're going to do about about the time, or the other other things, or not about the other other other other things, or or the other other other other other other or or or the other other other other other other other or
2022-03-23 11:57:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:57:32 | INFO | fairseq.tasks.translation | example hypothesis: there are some of some of them, but if you don't know, you don't know, but if you don't look at the way, but if you don't have the way, you don't have to get it, but if you don't have the way, but they don't do it, but they don't do it, but it
2022-03-23 11:57:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information, we can see the information, and we can see the way that we can see the world, and we can see the kind of the world, and then we can see the kind of the world, and we can see that we can see the kind of the kind of the kind of the world, and then we can see the world, we can see the world, and we can see that we can see the world, and
2022-03-23 11:57:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example hypothesis: and one of the one of the question, and it's the one of the question, and it's going to say, "if we're going to say," if we're going to say, "if we're going to say," if we're going to say, "you're going to say," you're going to say, "you're going to say," if we're going to say, "you're going to say," if we're going to say, "and then we're going to say," well, "well," well, "well," if we're going to do it's going to say, "if we're going to say," if we're going to do it's going to say, "you're going to say," you're going to say, "you're going to do it's going to do it's the
2022-03-23 11:57:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:48 | INFO | fairseq.tasks.translation | example hypothesis: and it's not a lot of my mother, and the way that we're going to get a lot of the way, and if we're going to do that if we're going to get to make a lot of the world, if we're going to get to make a lot of the world, if we're going to do that we're going to make a lot of the world, if we're going to get to do that we're going to make a lot of the world, we're going to get to get to get to get to get to make a lot of the world, and then we're going to make a lot of the world, if we're going to do that we're going to do that we're going to do that we're going to get to get to get to make a lot of the world, and then we're going to do that we're going to make a lot of the world, if we're going to make a lot of the world, and then we're going to make a lot of the world, and
2022-03-23 11:57:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:48 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.748 | ppl 3438.67 | bleu 4 | wps 3545.1 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4
2022-03-23 11:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.0) (writing took 1.956283141975291 seconds)
2022-03-23 11:57:50 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:57:50 | INFO | train | epoch 009 | loss 10.533 | ppl 1482.04 | wps 35415.3 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.847 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 980
KL Stats: Epoch 9 Divergences: Uniform: 0.7610010265200021 Unigram: 1.2355594311096785
2022-03-23 11:57:50 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:25 | INFO | train_inner | epoch 010:     91 / 157 loss=10.289, ppl=1251.47, wps=28245.5, ups=1.11, wpb=25471.1, bsz=1099.8, num_updates=1500, lr=0.0001875, gnorm=0.893, loss_scale=8, train_wall=37, gb_free=11.8, wall=1015
2022-03-23 11:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:53 | INFO | fairseq.tasks.translation | example hypothesis: these can't have no.
2022-03-23 11:58:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about about about about 50 percent.
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example hypothesis: these are the way, i can also have a lot of course of course, a lot of course.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because she had his father was his father.
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a child and said, and we said, so we said, "what's good?
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example hypothesis: so our time we're talking about our time, and we don't talk about how to talk about the same things or or or the other things or not about the other or or or or or the other other other or or or or or or or the other other other other other or or or
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are in the brain, but if you don't have to get the brain, you don't need to do it, and if you don't need to do it, you don't need the energy, and you don't need to do it.
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information of information, we can see this information, and we can take a little bit of information, and then we can see the kind of information, and then we can see the kind of information, and all the kind of the kind of the kind of information, and then we can see the kind of information, and the kind of information that's all the kind of information, and all the information that's all the information, and the
2022-03-23 11:59:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:31 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the question, and it's the interesting thing, "and it's going to say," well, "well," well, "you know," you know, "you know," you know, "well," if you're going to say, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," if we've got to give you know, "you know," if you have to give you know, "you know," well, "if you know," well, "you know," you know, "it's
2022-03-23 11:59:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example hypothesis: and then, it's still still always always always always always always always a lot of course, and it's a lot of the way that we're going to get a lot of things that we're going to make a lot of the brain, or a little bit of the way that we're going to do that we're going to make a lot of the brain, or a little bit of the way that we're going to make it, or a lot of the way that we're going to do that we're going to make it, or a little bit of the brain, or a lot of the way that we're going to get a lot of the same way that we're going to do that we're going to do that we're going to get a lot of the brain, or a lot of the same way that we're going to make a lot of the brain, or a little bit that we're going to get a little bit that we're going to have a lot of the way that we're going to get a lot of the way to
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:34 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.552 | ppl 3001.96 | bleu 6.78 | wps 4056.5 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 6.78
2022-03-23 11:59:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 11:59:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 10 @ 1566 updates, score 6.78) (writing took 1.9336852870183066 seconds)
2022-03-23 11:59:36 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:59:36 | INFO | train | epoch 010 | loss 10.373 | ppl 1326.19 | wps 37397.8 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 0.866 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 1086
KL Stats: Epoch 10 Divergences: Uniform: 0.7851684226593246 Unigram: 1.2977037411673724
2022-03-23 11:59:36 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:59:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:49 | INFO | train_inner | epoch 011:     34 / 157 loss=10.406, ppl=1356.5, wps=29799.8, ups=1.19, wpb=25082.5, bsz=937.7, num_updates=1600, lr=0.0002, gnorm=0.824, loss_scale=8, train_wall=37, gb_free=12.4, wall=1099
2022-03-23 12:00:27 | INFO | train_inner | epoch 011:    134 / 157 loss=10.177, ppl=1157.96, wps=66797.1, ups=2.67, wpb=25054.1, bsz=1010.5, num_updates=1700, lr=0.0002125, gnorm=0.796, loss_scale=8, train_wall=37, gb_free=12.3, wall=1137
2022-03-23 12:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these cells.
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example hypothesis: and then he can go about about about about 30,000 miles.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example hypothesis: that's what i can also be able to be able to be able to be a lot of course of course.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:00:52 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because he had his father, because she had his mother, she had his mother.
2022-03-23 12:00:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:00:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a lot of aids, and a child has been a child, and we got a child, so what do we do?
2022-03-23 12:00:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:01:00 | INFO | fairseq.tasks.translation | example hypothesis: so, so we have our time about our time about things like things like things like things, and we don't talk about how to talk about the world.
2022-03-23 12:01:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:01:05 | INFO | fairseq.tasks.translation | example hypothesis: first first, some of you're looking at the bbc, but it's in the brain, but it doesn't like the energy, but if you don't need the energy, it doesn't need the energy.
2022-03-23 12:01:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:01:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information that we can change the information, we can get a little bit of this.
2022-03-23 12:01:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:14 | INFO | fairseq.tasks.translation | example hypothesis: second, one of one of the reasons that it's interesting interesting, and it's interesting for me, and it's interesting for me for me for me, and then i'm going to say, "you know," you know, "you know," you know, "you know," you know, "if you know, it's going to say," it's the next to say, "you know," you know, you know, "you know," you know, you know, "the next to say," it's the next to be a great great great great great great example, "the next to be the next next to be the next next to be the next to be the next to be a young young young young young people who's going to say," i'm going to say, "you know," you know, "you know," the
2022-03-23 12:01:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:16 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still always always always always the mother, and the mother, and the great thing that we have a lot of work on our work, and when we're going to see a lot of our work, and we're going to see that we're going to be able to see that we're going to see a lot of our work in a lot of our work, or a lot of our work, or a lot of the problem.
2022-03-23 12:01:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.391 | ppl 2684.89 | bleu 9.31 | wps 4464.1 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 9.31
2022-03-23 12:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 12:01:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 11 @ 1723 updates, score 9.31) (writing took 1.8878937469562516 seconds)
2022-03-23 12:01:18 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 12:01:18 | INFO | train | epoch 011 | loss 10.19 | ppl 1168.4 | wps 38702.9 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 0.782 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1188
KL Stats: Epoch 11 Divergences: Uniform: 0.8105683898029132 Unigram: 1.349455251733357
2022-03-23 12:01:18 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 12:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:47 | INFO | train_inner | epoch 012:     77 / 157 loss=9.929, ppl=975.15, wps=31693.5, ups=1.24, wpb=25654, bsz=1101.4, num_updates=1800, lr=0.000225, gnorm=0.769, loss_scale=8, train_wall=37, gb_free=12.1, wall=1218
2022-03-23 12:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:02:25 | INFO | fairseq.tasks.translation | example hypothesis: and then he can go about about 880s.
2022-03-23 12:02:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:02:29 | INFO | fairseq.tasks.translation | example hypothesis: and that's what i can also be able to be able to be able to be able to do.
2022-03-23 12:02:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:02:33 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because his father had his father, she had his father with his father.
2022-03-23 12:02:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:02:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is in fact, and a child has got a child, so we asked us to do what we do?
2022-03-23 12:02:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things, and how to talk about, or not about the world, or each other, or each other.
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:02:46 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of you're looking at, but you don't know, but if you don't want to be able to do it, if you don't need the energy, you need the energy, and you need the energy.
2022-03-23 12:02:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this process, we can start with a little bit of that we can start with a little bit of the structure, and the structure of the structure, and all the information that's all the structure of the information.
2022-03-23 12:02:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example hypothesis: 19th: one of the reasons, and it's interesting for me, for me, for me, you know, you know, you know, "you've got the best," if you're going to say, "if you're going to give the best for the best revolution."
2022-03-23 12:02:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:57 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, there is still still still the mother, and the great work of our work, and we had to see that if we had to use a large system, that we had to use that we had to use a huge system, if we had to use the system, it was a huge system, that we had to make it in a huge system, it's a huge system, or a huge system, that we had to see that we had to see that we had to use that is that we had to use to use to use to use to make a huge system, if we had to make a huge system, if we had to make a huge system, that we had to make a huge system, that is that we had to make a huge system, that we had to make a huge system, that we had to make a huge system that we had to make a huge system, that we had to see that we had to make a huge system, or a huge system, that's a huge amount of a huge system, that's the
2022-03-23 12:02:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:57 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 11.13 | ppl 2240.9 | bleu 11.88 | wps 4529.5 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 11.88
2022-03-23 12:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 12:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 12 @ 1880 updates, score 11.88) (writing took 1.776903070975095 seconds)
2022-03-23 12:02:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:02:59 | INFO | train | epoch 012 | loss 10.008 | ppl 1029.98 | wps 38968.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 0.795 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1289
KL Stats: Epoch 12 Divergences: Uniform: 0.8336852188292156 Unigram: 1.3793187357563073
2022-03-23 12:02:59 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:02:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:07 | INFO | train_inner | epoch 013:     20 / 157 loss=10.054, ppl=1062.69, wps=30919.9, ups=1.26, wpb=24602.9, bsz=954.1, num_updates=1900, lr=0.0002375, gnorm=0.792, loss_scale=8, train_wall=37, gb_free=11.8, wall=1298
2022-03-23 12:03:45 | INFO | train_inner | epoch 013:    120 / 157 loss=9.88, ppl=942.53, wps=66274.1, ups=2.64, wpb=25062.1, bsz=1044.2, num_updates=2000, lr=0.00025, gnorm=0.831, loss_scale=8, train_wall=37, gb_free=12.7, wall=1335
2022-03-23 12:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example hypothesis: this can't use materials.
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 88,000 miles.
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example hypothesis: and that's of course, i can also be able to be able to be able.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example hypothesis: he never had his father because his father had been born with his father.
2022-03-23 12:04:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example hypothesis: so, one of my grandgrandaids is a child, and we got a child, so we asked us to do what we do?
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:04:21 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend time to talk about things like this, and not talk about the food of poverty.
2022-03-23 12:04:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:04:25 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the things, but it doesn't like this, but if you don't need to be able to use their energy, and if you don't need the energy.
2022-03-23 12:04:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from a little bit of that we can start to start with the traditional traditional scale, and we can start to start through the form of information.
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:33 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting for me to be here for me, "yes, you know," yes, it's the best revolution, "if you're going to say," if you have the best revolution. "
2022-03-23 12:04:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:33 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still a big design, and we have a big work on our work, and we had to see that we had to be a little bit of the sea, and if we had to use it.
2022-03-23 12:04:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:33 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 11.076 | ppl 2158.65 | bleu 10.57 | wps 5274.2 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 11.88
2022-03-23 12:04:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 12:04:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:04:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:04:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 13 @ 2037 updates, score 10.57) (writing took 0.8060454910155386 seconds)
2022-03-23 12:04:34 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:04:34 | INFO | train | epoch 013 | loss 9.837 | ppl 914.6 | wps 41430.4 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 0.802 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 1385
KL Stats: Epoch 13 Divergences: Uniform: 0.8576266256540838 Unigram: 1.4166339043661633
2022-03-23 12:04:35 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:59 | INFO | train_inner | epoch 014:     63 / 157 loss=9.66, ppl=809.12, wps=34646.7, ups=1.36, wpb=25541.3, bsz=1062.3, num_updates=2100, lr=0.0002625, gnorm=0.77, loss_scale=8, train_wall=37, gb_free=12.3, wall=1409
2022-03-23 12:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:38 | INFO | fairseq.tasks.translation | example hypothesis: this can't use chemical chemical chemical chemical rations.
2022-03-23 12:05:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:05:42 | INFO | fairseq.tasks.translation | example hypothesis: and it can be about about 88,000 miles in the restaurant.
2022-03-23 12:05:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example hypothesis: and that's what i can also do, of course, of course, of course, of course, of course, i can also be able to be able.
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:05:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, because she had learned his mother with his mother.
2022-03-23 12:05:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:05:56 | INFO | fairseq.tasks.translation | example hypothesis: and one of my coucous has died in aids, and a child has died, so we asked us, so what do we do?
2022-03-23 12:05:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:06:00 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things like things like this, how to talk about things, and not talk about how to poverty, or without other, or every single one of poverty, or each other.
2022-03-23 12:06:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bbbbbbbbones, but some of the things that you don't like, but if you don't need to move, and so if you don't need the energy energy, you need to get the energy, and so that you need to move out of the energy, and so you need to get so
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that we can use information from this reflection, we can start to start with one of the traditional, we can start to start, and the kind of information that all the information of information, and the structure of the structure of information, and the information that all the information is all the structure of the information, and when we're all the information is all the information, and the information that all the information is all the information that we can
2022-03-23 12:06:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:16 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons it's interesting, and it's interesting for me, for me, for me, "you know, you know," the best revolution, "if you're going to tell you that the best revolution is in this revolution," and then when we're going to say, "if you're going to say," if you're going to tell you're going to tell you're going to tell you're going to tell you, "and then," the most interesting, "the most interesting revolution."
2022-03-23 12:06:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still still the mother, and the invention of the invention that we have to see a big design design design that we had to see that if we had to see all the things that we had to be able to be able to be able to be able to see, and if you're going to see that it was all of the system, and if you're going to see, and if you're going to see that it's all of the system, to see, and if you're going to see, and if you're going to see, and if you're going to see, that we're going to see, and that we're still going to see that we're still going to see that it's still in the system, that we're still going to see that we're going to see, to see, and that we're still going to see, and if you're going to see, to see, to see, to see in the system in the system, and if you're still going to see that the
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:18 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.935 | ppl 1958.34 | bleu 11.9 | wps 4056.4 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 11.9
2022-03-23 12:06:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 12:06:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 14 @ 2194 updates, score 11.9) (writing took 1.7223385480465367 seconds)
2022-03-23 12:06:20 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:06:20 | INFO | train | epoch 014 | loss 9.691 | ppl 826.53 | wps 37395.1 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 0.792 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1490
KL Stats: Epoch 14 Divergences: Uniform: 0.8846740484624164 Unigram: 1.4407729383550945
2022-03-23 12:06:20 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:23 | INFO | train_inner | epoch 015:      6 / 157 loss=9.735, ppl=852.15, wps=29483.7, ups=1.19, wpb=24782.3, bsz=960.7, num_updates=2200, lr=0.000275, gnorm=0.78, loss_scale=8, train_wall=37, gb_free=11.9, wall=1493
2022-03-23 12:07:00 | INFO | train_inner | epoch 015:    106 / 157 loss=9.545, ppl=747.17, wps=66888.7, ups=2.67, wpb=25078.1, bsz=1030.6, num_updates=2300, lr=0.0002875, gnorm=0.685, loss_scale=8, train_wall=37, gb_free=12.8, wall=1531
2022-03-23 12:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example hypothesis: this can't use chemical rays.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 times in the restaurant.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example hypothesis: that's what i can do, of course, i can also be a sense of the bible forms.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned because his father had been left with him when she was pregnant with him.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:07:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my coups is died in aids, and he died a child, so we asked us to do what do we do?
2022-03-23 12:07:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:07:44 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend time to talk about things like the equation and talk about the nuclear weapons or not talk about poverty or other weapons.
2022-03-23 12:07:44 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:07:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic of the field in the field, but it doesn't like it, if you don't want to move it, if you don't need it, and you don't need the energy energy.
2022-03-23 12:07:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:53 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional traditional view that we can start to start with a traditional form of the form of the form of the form, and that's what's going to start with it.
2022-03-23 12:07:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedtedtedtedwomen, yes, that it's the best time when someone said, "yes," if you're going to say, "and then we're going to do that."
2022-03-23 12:07:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:59 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design part of the work that we were working on our airplane, and we had to solve a unique plane that we had to solve a unique amount of problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see with the
2022-03-23 12:07:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:59 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.703 | ppl 1666.86 | bleu 15.98 | wps 4523 | wpb 17862.2 | bsz 728.3 | num_updates 2351 | best_bleu 15.98
2022-03-23 12:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2351 updates
2022-03-23 12:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 15 @ 2351 updates, score 15.98) (writing took 1.7624876840272918 seconds)
2022-03-23 12:08:01 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:08:01 | INFO | train | epoch 015 | loss 9.521 | ppl 734.82 | wps 39027.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2351 | lr 0.000293875 | gnorm 0.668 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1592
KL Stats: Epoch 15 Divergences: Uniform: 0.9082884199997411 Unigram: 1.460435827120074
2022-03-23 12:08:01 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:20 | INFO | train_inner | epoch 016:     49 / 157 loss=9.533, ppl=740.71, wps=31552, ups=1.25, wpb=25296.3, bsz=959.5, num_updates=2400, lr=0.0003, gnorm=0.652, loss_scale=8, train_wall=38, gb_free=11.8, wall=1611
2022-03-23 12:08:58 | INFO | train_inner | epoch 016:    149 / 157 loss=9.307, ppl=633.44, wps=67114.3, ups=2.68, wpb=24997.9, bsz=1067, num_updates=2500, lr=0.0003125, gnorm=0.668, loss_scale=8, train_wall=37, gb_free=22.3, wall=1648
2022-03-23 12:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical rocket.
2022-03-23 12:09:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 people in the restaurant in the restaurant.
2022-03-23 12:09:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also have a popular bible to make a bible.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:09:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother when she was pregnant.
2022-03-23 12:09:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:09:20 | INFO | fairseq.tasks.translation | example hypothesis: one of my coups died in aids, and a waisa child said, "well, what do we do?
2022-03-23 12:09:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:09:24 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender and not talk about the nuclear weapons of poverty.
2022-03-23 12:09:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:09:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines in the field, but the sususues don't move their movements, if you don't need the energy and so forth.
2022-03-23 12:09:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:32 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, we can start with a traditional face of the face of the face and the whole structure of the whole structure.
2022-03-23 12:09:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here for tedsters, "yes, the best time we started to give them a young revolution for them."
2022-03-23 12:09:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:38 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention and a great design of work that we had to solve the airplanes of a very unique substance, and we had to see that it's a unique scale of the bottom of a substance of the air.
2022-03-23 12:09:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:38 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.632 | ppl 1586.71 | bleu 16.93 | wps 4836.2 | wpb 17862.2 | bsz 728.3 | num_updates 2508 | best_bleu 16.93
2022-03-23 12:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2508 updates
2022-03-23 12:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 16 @ 2508 updates, score 16.93) (writing took 1.7693930099485442 seconds)
2022-03-23 12:09:40 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:09:40 | INFO | train | epoch 016 | loss 9.361 | ppl 657.51 | wps 39927.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2508 | lr 0.0003135 | gnorm 0.67 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 1690
KL Stats: Epoch 16 Divergences: Uniform: 0.9325344223968938 Unigram: 1.4877402523777765
2022-03-23 12:09:40 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:16 | INFO | train_inner | epoch 017:     92 / 157 loss=9.121, ppl=556.68, wps=33179.1, ups=1.28, wpb=25929.2, bsz=1019.8, num_updates=2600, lr=0.000325, gnorm=0.614, loss_scale=8, train_wall=38, gb_free=12, wall=1726
2022-03-23 12:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:43 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:10:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:10:47 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:10:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:10:52 | INFO | fairseq.tasks.translation | example hypothesis: these rings, of course, of course, i can also make a popular bible to form a bible bible.
2022-03-23 12:10:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:10:56 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his father, his mother, his mother had been pregnant when she was pregnant with him.
2022-03-23 12:10:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died on aids, and a waisised child, so we said, what do we do with her?
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:11:06 | INFO | fairseq.tasks.translation | example hypothesis: so that's why we spend our time to talk about things like the equality of gender and not talk about the nuclear weapons or nuclear weapons of poverty, or every other topic issue.
2022-03-23 12:11:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:11:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some of all, are some bold magnetic magnetic magnetic lines in the field of the field, but the susususuits don't like it, if you need your movements, you need your movements, you need your movements, and so you need your power.
2022-03-23 12:11:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection comes from the reflection of this reflection, we can start with a traditional face with a traditional face of the face of the face of the face, and the information of the information, and the whole structure of all the structure.
2022-03-23 12:11:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it's interesting, for me to be here for tedwomen in tedster, is that... yes, it was the best way to say, "somebody said," you know, when the men starts to support you, "and then we've got the truth for you're going to support the truth for you."
2022-03-23 12:11:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:22 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design part of design design design work on our plane, we had to solve a very unique result that we had to solve all the problems that we had to solve it to be connected to the ground, and that it's all of us to see that it was going to see that if you're going to see a substance to see that the air, to see that it's going to see that it is to see that it is to be a subtle, or to see that if you're going to see that the air, to see, to be a subsisisisisisisisisisisix-x--to-to-the air, or to see that it's a subtle, to see that if you're going to see that if you're going to see a mechanism, or to see that we're either to see a mechanism, or to see that it was a mechanism, or to see that it was a mechanism, to see the
2022-03-23 12:11:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:22 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.525 | ppl 1473.44 | bleu 17.78 | wps 4292.2 | wpb 17862.2 | bsz 728.3 | num_updates 2665 | best_bleu 17.78
2022-03-23 12:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2665 updates
2022-03-23 12:11:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 17 @ 2665 updates, score 17.78) (writing took 1.7707132550422102 seconds)
2022-03-23 12:11:23 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:11:23 | INFO | train | epoch 017 | loss 9.197 | ppl 587.04 | wps 38186.6 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 2665 | lr 0.000333125 | gnorm 0.612 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 1794
KL Stats: Epoch 17 Divergences: Uniform: 0.9542390030093267 Unigram: 1.5129975251846346
2022-03-23 12:11:24 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:37 | INFO | train_inner | epoch 018:     35 / 157 loss=9.207, ppl=590.84, wps=30080, ups=1.23, wpb=24435.8, bsz=1055.4, num_updates=2700, lr=0.0003375, gnorm=0.638, loss_scale=8, train_wall=36, gb_free=13.1, wall=1807
2022-03-23 12:12:15 | INFO | train_inner | epoch 018:    135 / 157 loss=9.093, ppl=546.01, wps=66988.5, ups=2.63, wpb=25460.3, bsz=996.6, num_updates=2800, lr=0.00035, gnorm=0.602, loss_scale=8, train_wall=38, gb_free=12.2, wall=1845
2022-03-23 12:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:12:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:12:31 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:12:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example hypothesis: i can also make that rwanda, of course, of course, i can also make a popular bike.
2022-03-23 12:12:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his mother, when she was pregnant.
2022-03-23 12:12:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:12:43 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousin is died in aids, and has a waisan child, so we asked, well, what do we do with her?
2022-03-23 12:12:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:12:47 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times, and not talking about the state of nuclear weapons or nuclear weapons.
2022-03-23 12:12:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:12:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic lines are starting in the inside, but the sususususuck susuits don't like it, if you move your movements, you need your energy movements, you need your energy movements, your energy, you need, and the susuitable disorders.
2022-03-23 12:12:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can start to start with a traditional facial facial face, the big, and the real shape of the facial facial form, and the information of the information is, and the whole structure of the structure, and all the structure of this structure of this structure is, and we can start to be able to be able to make a structure.
2022-03-23 12:12:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it, for me here, for tedwomen, is that... yeah, that... yeah, when it was the best, it was the best thing that someone said, "if you're going to help you're going to help you're going to support the truth," and then we're going to help you have the truth for you have a long time. "
2022-03-23 12:13:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:04 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, fortunately, the mother of the invention, and a big part of the design work on our plane was a plane, we're on the plane, a result that we had to solve the problems that we had to solve the problems that we had to be connected to the ground, to the ground, to the bottom of a system, and if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, or to the
2022-03-23 12:13:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:04 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.352 | ppl 1306.78 | bleu 20.63 | wps 4371 | wpb 17862.2 | bsz 728.3 | num_updates 2822 | best_bleu 20.63
2022-03-23 12:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2822 updates
2022-03-23 12:13:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:13:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 18 @ 2822 updates, score 20.63) (writing took 1.745619966997765 seconds)
2022-03-23 12:13:06 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:13:06 | INFO | train | epoch 018 | loss 9.097 | ppl 547.66 | wps 38429.2 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2822 | lr 0.00035275 | gnorm 0.631 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 1897
KL Stats: Epoch 18 Divergences: Uniform: 0.9699140315642083 Unigram: 1.5217506380485526
2022-03-23 12:13:07 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:36 | INFO | train_inner | epoch 019:     78 / 157 loss=9.149, ppl=567.74, wps=30206.8, ups=1.24, wpb=24457.1, bsz=980.2, num_updates=2900, lr=0.0003625, gnorm=0.589, loss_scale=8, train_wall=37, gb_free=12.2, wall=1926
2022-03-23 12:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rocket.
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:14:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example hypothesis: i can also make these rings, of course, to form a popular bible.
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:14:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left him when she was pregnant.
2022-03-23 12:14:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:14:25 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousin is died in aids, and has a wais-child, so we asked us, what do we do with?
2022-03-23 12:14:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:14:29 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about things like gender times and not talking about nuclear weapons or the subject of poverty.
2022-03-23 12:14:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a couple of bold field in the inside, but the sususususuitalalgagae doesn't like it, if you need your movements, and the sususususususususuits.
2022-03-23 12:14:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that's going to be able to put it through the face of the face of the face, and the real shape of that information, and the information is going to put it through, and the whole structure of this structure, and all the structure of the structure of the structure of the structure of the structure, and the structure, and the structure of the structure
2022-03-23 12:14:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure me here at tedwomen, is that it's been used to be -- "yes, it was the best time to say," somebody said, "and then they're going to give you a table revolution," and then we have a lot of the truth for them, "and then we have a lot of time," and then we're going to help you're going to help you know, "
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of design work that we were in the plane, was a result of it.
2022-03-23 12:14:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:44 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.293 | ppl 1254.76 | bleu 20.82 | wps 4733.5 | wpb 17862.2 | bsz 728.3 | num_updates 2979 | best_bleu 20.82
2022-03-23 12:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2979 updates
2022-03-23 12:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:14:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 19 @ 2979 updates, score 20.82) (writing took 1.7412785480264574 seconds)
2022-03-23 12:14:46 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:14:46 | INFO | train | epoch 019 | loss 8.968 | ppl 500.84 | wps 39669.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2979 | lr 0.000372375 | gnorm 0.558 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 1996
KL Stats: Epoch 19 Divergences: Uniform: 0.9830041716265863 Unigram: 1.5352293869699514
2022-03-23 12:14:46 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:54 | INFO | train_inner | epoch 020:     21 / 157 loss=8.934, ppl=489.2, wps=32347.8, ups=1.28, wpb=25270.7, bsz=1002.3, num_updates=3000, lr=0.000375, gnorm=0.541, loss_scale=8, train_wall=37, gb_free=12.7, wall=2005
2022-03-23 12:15:32 | INFO | train_inner | epoch 020:    121 / 157 loss=8.67, ppl=407.18, wps=68225.9, ups=2.61, wpb=26095.5, bsz=1089.3, num_updates=3100, lr=0.0003875, gnorm=0.516, loss_scale=8, train_wall=38, gb_free=12.5, wall=2043
2022-03-23 12:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:15:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:15:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that kind of, of course, to form a popular bias.
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:16:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his mother when she was pregnant with him.
2022-03-23 12:16:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:16:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and i asked us what do we do with?
2022-03-23 12:16:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:16:09 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not talking about nuclear weapons or poverty or poverty or any other topic.
2022-03-23 12:16:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:16:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a lot of magnetic field in the inside, but the superconductor doesn't like that, if you need your movements, and so your movements, and so the suitage of the suits of magnetic magnetic field.
2022-03-23 12:16:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:18 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that can start with a big face, which is the big configuration of the face, and the real shape and reform it through that information, which is all of that information that's going to fold out of this structure.
2022-03-23 12:16:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here at tedwomen, is that -- in fact, when it was the best time, when someone said, "when somebody said," well, "and one of the reasons that it's interesting to be interesting to be interesting to help you," the men, "and then we're going to support you know," the truth with you know, "the truth is that we've already supported to support you know," the truth for me to support you know, "the truth with that women's already supported to support you know," the truth with that there's already supported to support you know, "mosquitarian revolution."
2022-03-23 12:16:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design work that we have to use on the plane is a result that we had to solve the unique problems that we had to solve the unique problems that we had to solve it on the ground -- all the mother of a continuous variation of a continuous variation of design system that allows us to be able to use it to use it to be used to be used to be refrigergered to be refrigered to be used to be used to be a pigegegegestistion the refrigeration of a mechanism that we're either refrigeration of a mechanism that we're either refrigeration of a mechanism that allows us to use of a mechanism that we're either refugestististististion the refrigeration of a mechanism, to use in our aircraft with a mechanism that was either refrigeration of a mechanism that was either
2022-03-23 12:16:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:25 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.201 | ppl 1177.46 | bleu 23.08 | wps 4510.4 | wpb 17862.2 | bsz 728.3 | num_updates 3136 | best_bleu 23.08
2022-03-23 12:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3136 updates
2022-03-23 12:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 20 @ 3136 updates, score 23.08) (writing took 1.9345658229431137 seconds)
2022-03-23 12:16:27 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:16:27 | INFO | train | epoch 020 | loss 8.847 | ppl 460.47 | wps 38943.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3136 | lr 0.000392 | gnorm 0.537 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2098
KL Stats: Epoch 20 Divergences: Uniform: 0.9921846903235817 Unigram: 1.5539444289055584
2022-03-23 12:16:27 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:52 | INFO | train_inner | epoch 021:     64 / 157 loss=8.961, ppl=498.24, wps=30677.1, ups=1.26, wpb=24439.2, bsz=965.7, num_updates=3200, lr=0.0004, gnorm=0.564, loss_scale=8, train_wall=37, gb_free=11.3, wall=2122
2022-03-23 12:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example hypothesis: and these rough magnets, of course, i can also expand a popular bias.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:17:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and has a wash child, so we said, well, what do we do?
2022-03-23 12:17:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:17:50 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:17:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:17:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magnetic field in the inside, but the superconductor doesn't like it, if you move your movements, and so the superenergy disorder.
2022-03-23 12:17:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big conconstructions of the face and the basic form, and through the information, the entire information that drives all the structure and fold all the structure.
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:18:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting and measure for me here in tedwomen, is that... "well, when it was the best," somebody said, "] ["] ["] ["] ["] [the men and then they're going to tell you, and then they're going to help you to support the truth for you."
2022-03-23 12:18:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're at the stunt, was a result that we had to solve the unique problems that were connected to the ground -- all the continued to refrigerate from a continents and variation and variation, and that allows us to see that if you can either refrightening into our airplane.
2022-03-23 12:18:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:04 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 10.111 | ppl 1106.26 | bleu 24.29 | wps 4826.6 | wpb 17862.2 | bsz 728.3 | num_updates 3293 | best_bleu 24.29
2022-03-23 12:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3293 updates
2022-03-23 12:18:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:18:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 21 @ 3293 updates, score 24.29) (writing took 1.7762521179392934 seconds)
2022-03-23 12:18:06 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:18:06 | INFO | train | epoch 021 | loss 8.758 | ppl 432.89 | wps 39923.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3293 | lr 0.000411625 | gnorm 0.514 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 2197
KL Stats: Epoch 21 Divergences: Uniform: 1.0018399984668966 Unigram: 1.5659854379549796
2022-03-23 12:18:06 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:09 | INFO | train_inner | epoch 022:      7 / 157 loss=8.644, ppl=400.17, wps=32757.4, ups=1.29, wpb=25327, bsz=1053, num_updates=3300, lr=0.0004125, gnorm=0.49, loss_scale=8, train_wall=37, gb_free=11.6, wall=2200
2022-03-23 12:18:47 | INFO | train_inner | epoch 022:    107 / 157 loss=8.675, ppl=408.85, wps=67083.5, ups=2.66, wpb=25252.1, bsz=1027.1, num_updates=3400, lr=0.000425, gnorm=0.513, loss_scale=8, train_wall=37, gb_free=11.6, wall=2237
2022-03-23 12:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:19:17 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that rocket magnets.
2022-03-23 12:19:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:19:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:19:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:19:25 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, so we asked what do we do with her?
2022-03-23 12:19:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:19:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic field may not be caught in the inside, but the superconductor doesn't like when you move, because your movements need energy, and so the superconductor disorder.
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflective reflection, we can start with a traditional face of face and the basic form of face and the basic form, and the basic form of the face, and rerepeat it through the one of the information that includes the whole structure.
2022-03-23 12:19:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here. "
2022-03-23 12:19:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on the plane was a result that we had to solve the unique problems that we had to solve the unique problems that we had to solve the same problems that were connected to the ground.
2022-03-23 12:19:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:39 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 10.167 | ppl 1149.85 | bleu 19.45 | wps 5533 | wpb 17862.2 | bsz 728.3 | num_updates 3450 | best_bleu 24.29
2022-03-23 12:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3450 updates
2022-03-23 12:19:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 22 @ 3450 updates, score 19.45) (writing took 0.7854044800624251 seconds)
2022-03-23 12:19:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:19:40 | INFO | train | epoch 022 | loss 8.684 | ppl 411.41 | wps 42054.5 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 3450 | lr 0.00043125 | gnorm 0.507 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2290
KL Stats: Epoch 22 Divergences: Uniform: 1.0043489355362745 Unigram: 1.5744399030330836
2022-03-23 12:19:40 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:59 | INFO | train_inner | epoch 023:     50 / 157 loss=8.599, ppl=387.88, wps=34770.5, ups=1.38, wpb=25117.4, bsz=1043.1, num_updates=3500, lr=0.0004375, gnorm=0.515, loss_scale=8, train_wall=37, gb_free=12.5, wall=2310
2022-03-23 12:20:37 | INFO | train_inner | epoch 023:    150 / 157 loss=8.705, ppl=417.29, wps=65957.9, ups=2.66, wpb=24831.7, bsz=997.8, num_updates=3600, lr=0.00045, gnorm=0.459, loss_scale=8, train_wall=37, gb_free=12.9, wall=2347
2022-03-23 12:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that rough magnetic magnets to form a popular same same as it is.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids, and has a wash child back, so we asked us, well, what do we do with her?
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:21:04 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender times, and not talking about nuclear weapons or poverty or poverty or any other promising topic.
2022-03-23 12:21:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:21:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble from magnet field lines in the inside, but the superconductor doesn't like it when you're moving, because your movements need energy, and so the superconductor disorder.
2022-03-23 12:21:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:21:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection reflection, we can start with a traditional facial, which is the big configuration of the face and the basic form of the information, and by the one of the one of the constructions, the whole porting structure and all fold.
2022-03-23 12:21:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure, for me to be here at tedwomen, is that... t.t., in fact, it was the best together when someone said, "turn to the men at the table and say," if the revolution starts to support you for you're, "the truth is," we've already got a blow for you've already got "]"
2022-03-23 12:21:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on at our plane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variation and refrigering system, it allows us to use a refrigeration of the refrigeration, and it allows us to use a refrigeration of the refrigeration of the refrigeration of the refrigeration of the refrigeration, which is when you see the refrigeration, it's the restoration of it's also when you're the restoration of a right-hand, it's a right-hand, or when you're not when you have to see the restoration of it's the restoration, it's the restoration, it's the restoration, it's the restoration, it's the right-hand, it's the restoration of a right-hand, it's
2022-03-23 12:21:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:19 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.942 | ppl 983.55 | bleu 27.4 | wps 4652.1 | wpb 17862.2 | bsz 728.3 | num_updates 3607 | best_bleu 27.4
2022-03-23 12:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3607 updates
2022-03-23 12:21:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:21:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 23 @ 3607 updates, score 27.4) (writing took 1.7584482920356095 seconds)
2022-03-23 12:21:21 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:21:21 | INFO | train | epoch 023 | loss 8.602 | ppl 388.58 | wps 39257.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3607 | lr 0.000450875 | gnorm 0.472 | loss_scale 8 | train_wall 58 | gb_free 12.4 | wall 2391
KL Stats: Epoch 23 Divergences: Uniform: 1.0103383950484166 Unigram: 1.583462771237682
2022-03-23 12:21:21 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:56 | INFO | train_inner | epoch 024:     93 / 157 loss=8.491, ppl=359.9, wps=31742.2, ups=1.26, wpb=25174.1, bsz=1053.2, num_updates=3700, lr=0.0004625, gnorm=0.449, loss_scale=8, train_wall=37, gb_free=12.1, wall=2427
2022-03-23 12:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example hypothesis: these sunny can't use chemical rockets.
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:22:28 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:22:28 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example hypothesis: now, i can also expand these rings to form a popular equality.
2022-03-23 12:22:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:22:35 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 12:22:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:22:39 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has a waisena child, so we asked us, well, what do we do?
2022-03-23 12:22:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:22:43 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender times, and not about the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:22:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:22:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble of magnetic fields are caught in the inside, but the superconductor doesn't like it when you move, there's your movements, and so the superconductor disorder.
2022-03-23 12:22:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:52 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional facial can start the size of the face and the basic form of face, and the basic shape of the information that makes the whole portion structure and all the folds.
2022-03-23 12:22:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen is that... well, in the strike dinner dinner, it was the best, when somebody said, "you know, you're going to support the men on a table, and you'll say," if you're going to support the truth. "
2022-03-23 12:22:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane at the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuing system and a refrigeration system that allows us to refrigerate.
2022-03-23 12:22:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:57 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.932 | ppl 976.75 | bleu 26.99 | wps 4937.6 | wpb 17862.2 | bsz 728.3 | num_updates 3764 | best_bleu 27.4
2022-03-23 12:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3764 updates
2022-03-23 12:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 24 @ 3764 updates, score 26.99) (writing took 0.7506250250153244 seconds)
2022-03-23 12:22:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:22:58 | INFO | train | epoch 024 | loss 8.531 | ppl 369.83 | wps 40610.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3764 | lr 0.0004705 | gnorm 0.455 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 2488
KL Stats: Epoch 24 Divergences: Uniform: 1.0136329917105364 Unigram: 1.5938561916616414
2022-03-23 12:22:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:12 | INFO | train_inner | epoch 025:     36 / 157 loss=8.607, ppl=389.99, wps=32898.8, ups=1.32, wpb=24859.5, bsz=955, num_updates=3800, lr=0.000475, gnorm=0.444, loss_scale=8, train_wall=37, gb_free=12.5, wall=2502
2022-03-23 12:23:49 | INFO | train_inner | epoch 025:    136 / 157 loss=8.437, ppl=346.69, wps=67085.8, ups=2.65, wpb=25332.2, bsz=1058.5, num_updates=3900, lr=0.0004875, gnorm=0.467, loss_scale=8, train_wall=37, gb_free=12.9, wall=2540
2022-03-23 12:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 12:24:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnets, of course, to form a popular equation.
2022-03-23 12:24:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:24:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:24:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:24:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids, and has a woke child left, so we asked us what do we do with her?
2022-03-23 12:24:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:24:21 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender times, and not about genocide or poverty or any other subject.
2022-03-23 12:24:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:24:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic field lines are caught in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:24:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big configuration of the face and the basic form, and through that one of the information that refits the whole porter structure and fold a fold fold.
2022-03-23 12:24:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measures for me here at tedwomen, is that -- well, in fake dinner, it was the best summarized, as somebody said, "turn on the men of your table and say," if the revolution begins, then we're supporting you. "
2022-03-23 12:24:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane at the stest, was a result that we had to solve the unique problems that were connected to the bottom -- all of a continuous variation and a refrigeration system that allows us to use a fluid, and that it allows us to use a curriculum in the bottom of a way that is either to use the same way that we need to be able to use the same way that we need to be able to be able to use the same way that is to use the same way that we need to be able to use the same way that we need to use the same way that we have the same way that we have the same way that we have the same way that we have the same way that we have the same thing that we have the same way that we have the same thing that we have it is to see when you can use the same thing that we need to get rid of a mechanism, or
2022-03-23 12:24:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:36 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.868 | ppl 934.25 | bleu 28.27 | wps 4776 | wpb 17862.2 | bsz 728.3 | num_updates 3921 | best_bleu 28.27
2022-03-23 12:24:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3921 updates
2022-03-23 12:24:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 25 @ 3921 updates, score 28.27) (writing took 1.7634820459643379 seconds)
2022-03-23 12:24:37 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:24:37 | INFO | train | epoch 025 | loss 8.474 | ppl 355.66 | wps 39625.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3921 | lr 0.000490125 | gnorm 0.449 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 2588
KL Stats: Epoch 25 Divergences: Uniform: 1.0148571760778191 Unigram: 1.597008686851522
2022-03-23 12:24:38 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:24:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:07 | INFO | train_inner | epoch 026:     79 / 157 loss=8.358, ppl=328.06, wps=32416.4, ups=1.28, wpb=25285.9, bsz=994.7, num_updates=4000, lr=0.0005, gnorm=0.431, loss_scale=8, train_wall=37, gb_free=12.2, wall=2618
2022-03-23 12:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this rotating, of course, to form a popular equilibrium.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:25:53 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:25:53 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:25:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us what do we do with her?
2022-03-23 12:25:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:26:01 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender times, and not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:26:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:26:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnet lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 12:26:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic shape of the face, and by the threshold of the information that can fold all the porter structure and fold.
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me here at tedwomen is that... tyes, at the strikes dinner, it was the best summarized when somebody said, "turn you to a dtable, and you say," if the revolution starts. "
2022-03-23 12:26:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are on our airplane on the stones, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to be able to be able to be able to be able to use in the wheels, or if you can see the wheels, or if you can see the propelled, or you can see the propelled.
2022-03-23 12:26:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:14 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.841 | ppl 917.38 | bleu 28.43 | wps 4946.2 | wpb 17862.2 | bsz 728.3 | num_updates 4078 | best_bleu 28.43
2022-03-23 12:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4078 updates
2022-03-23 12:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 26 @ 4078 updates, score 28.43) (writing took 1.7656983439810574 seconds)
2022-03-23 12:26:16 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:26:16 | INFO | train | epoch 026 | loss 8.421 | ppl 342.86 | wps 40219.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4078 | lr 0.000495195 | gnorm 0.429 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2686
KL Stats: Epoch 26 Divergences: Uniform: 1.0157957543889529 Unigram: 1.6024892200084007
2022-03-23 12:26:16 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:24 | INFO | train_inner | epoch 027:     22 / 157 loss=8.426, ppl=343.95, wps=32784.1, ups=1.3, wpb=25215.3, bsz=1007.8, num_updates=4100, lr=0.000493865, gnorm=0.431, loss_scale=8, train_wall=37, gb_free=12.6, wall=2695
2022-03-23 12:27:02 | INFO | train_inner | epoch 027:    122 / 157 loss=8.404, ppl=338.62, wps=66380.7, ups=2.65, wpb=25044.6, bsz=1024, num_updates=4200, lr=0.00048795, gnorm=0.407, loss_scale=8, train_wall=37, gb_free=13.4, wall=2733
2022-03-23 12:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:27:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:27:23 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 12:27:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:27:27 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnets to shape a popular same same same equilibrium.
2022-03-23 12:27:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:27:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines had died of aids, and has a waisena child, so we asked us, well, what do we do with her?
2022-03-23 12:27:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:27:39 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like the gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:27:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:27:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:27:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic shape, and restores it by the one of the information that makes the whole portion structure and all folds.
2022-03-23 12:27:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, in the striking dinner, it was best summared to the men at your table and say, "if the revolution begins to you."
2022-03-23 12:27:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane is the most stumbling, a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to stop in the ground, to get rid of the propeller, to see when we see the propelled when you see it in the bottom.
2022-03-23 12:27:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:53 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.771 | ppl 873.65 | bleu 29.42 | wps 4931.3 | wpb 17862.2 | bsz 728.3 | num_updates 4235 | best_bleu 29.42
2022-03-23 12:27:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4235 updates
2022-03-23 12:27:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 27 @ 4235 updates, score 29.42) (writing took 1.7700496710604057 seconds)
2022-03-23 12:27:54 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:27:54 | INFO | train | epoch 027 | loss 8.359 | ppl 328.37 | wps 39952.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4235 | lr 0.00048593 | gnorm 0.404 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 2785
KL Stats: Epoch 27 Divergences: Uniform: 1.0167610217830272 Unigram: 1.611439675076983
2022-03-23 12:27:55 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:27:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:20 | INFO | train_inner | epoch 028:     65 / 157 loss=8.317, ppl=318.89, wps=32761, ups=1.29, wpb=25351.4, bsz=1013.6, num_updates=4300, lr=0.000482243, gnorm=0.404, loss_scale=8, train_wall=37, gb_free=12.4, wall=2810
2022-03-23 12:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:28:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnets to shape a popular equation.
2022-03-23 12:29:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:29:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a waisena child, so we asked us, well what do we do with them?
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:29:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder disorder.
2022-03-23 12:29:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructions of the face and the basic form of the information that the whole porter structure and all fold a fold.
2022-03-23 12:29:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it up and measured to me here at tedwomen is that -- tyes, the dinner was best summarized when somebody said, "turn to the men in your table and say," if the revolution begins to you. "
2022-03-23 12:29:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane is the most proud of us to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a refrigeration system that allows us to be able to use a propelled, or a propelled machine that you're going to be able to be able to get rid of.
2022-03-23 12:29:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:31 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.744 | ppl 857.69 | bleu 29.84 | wps 4862.6 | wpb 17862.2 | bsz 728.3 | num_updates 4392 | best_bleu 29.84
2022-03-23 12:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4392 updates
2022-03-23 12:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 28 @ 4392 updates, score 29.84) (writing took 1.7770714060170576 seconds)
2022-03-23 12:29:33 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:29:33 | INFO | train | epoch 028 | loss 8.321 | ppl 319.79 | wps 40037.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4392 | lr 0.000477165 | gnorm 0.403 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2884
KL Stats: Epoch 28 Divergences: Uniform: 1.0164281670828943 Unigram: 1.6150447937002925
2022-03-23 12:29:33 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:37 | INFO | train_inner | epoch 029:      8 / 157 loss=8.284, ppl=311.68, wps=32635.7, ups=1.29, wpb=25223.2, bsz=1064, num_updates=4400, lr=0.000476731, gnorm=0.376, loss_scale=8, train_wall=37, gb_free=12.5, wall=2887
2022-03-23 12:30:15 | INFO | train_inner | epoch 029:    108 / 157 loss=8.254, ppl=305.24, wps=66866.4, ups=2.65, wpb=25271.5, bsz=1000.2, num_updates=4500, lr=0.000471405, gnorm=0.399, loss_scale=8, train_wall=37, gb_free=11.9, wall=2925
2022-03-23 12:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can protect about 8,000 places in the restaurant.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this rotating magnets to form a popular equation.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:30:56 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equal wedding and not about genocide or poverty or any other promising topic.
2022-03-23 12:30:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:31:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements, and so the superconductor disorder disorder.
2022-03-23 12:31:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:31:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big contextures of the face and the basic shape, and repulates it through the whole porstructure and all fold.
2022-03-23 12:31:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting to me here at tedwomen, is that -- well, in the strikes dinner, it was the best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, we love you. "the truth, women, we've already started to give you this topic for a while," silent carchel. "
2022-03-23 12:31:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we are on on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to stop a machine in the aircraft, to go in the car, or when you see the propeller, and you can use it in the ground, and you can use it, you can use it in a vehicle, and you can see it in a car transportation, and you can use it, you can use it in the car traffic, and you can use it, you can use it in the car traffic, you can see it, you can either, you can see it, you can use it, you can use it in the car traffic, you can use it, you can use it, you can use it in the stairs.
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:11 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.738 | ppl 854.1 | bleu 29.71 | wps 4727.8 | wpb 17862.2 | bsz 728.3 | num_updates 4549 | best_bleu 29.84
2022-03-23 12:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4549 updates
2022-03-23 12:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 29 @ 4549 updates, score 29.71) (writing took 0.7898696949705482 seconds)
2022-03-23 12:31:12 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:31:12 | INFO | train | epoch 029 | loss 8.267 | ppl 307.99 | wps 39996.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4549 | lr 0.000468859 | gnorm 0.386 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 2982
KL Stats: Epoch 29 Divergences: Uniform: 1.018455746010253 Unigram: 1.621777814563194
2022-03-23 12:31:12 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:32 | INFO | train_inner | epoch 030:     51 / 157 loss=8.277, ppl=310.29, wps=32235.9, ups=1.3, wpb=24866.6, bsz=1067.6, num_updates=4600, lr=0.000466252, gnorm=0.384, loss_scale=8, train_wall=37, gb_free=11.8, wall=3002
2022-03-23 12:32:09 | INFO | train_inner | epoch 030:    151 / 157 loss=8.244, ppl=303.17, wps=67176.1, ups=2.67, wpb=25189.8, bsz=990.4, num_updates=4700, lr=0.000461266, gnorm=0.383, loss_scale=8, train_wall=37, gb_free=12.2, wall=3040
2022-03-23 12:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnets to shape any same equilibrium.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines died of aids, and has left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:32:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like the gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:32:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:32:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:32:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big contextures of the face and the basic form, and refuse it through the one of the information that refers the whole porter structure and all the fits.
2022-03-23 12:32:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured to me here at tedwomen, is that -- tyes, dinner has been summarized at the best time when someone said, "turn you to the men at your table and say," if the revolution starts to support you. "
2022-03-23 12:32:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane at the stones, was a result that we had to solve the unique problems that were connected to the ground, and we have to operate on the ground -- everything from a continuous variation and refrigeration system that allows us to use a liquid, that allows us to use an aircraft in the aircraft, to either to use it, to use it, or the propelled.
2022-03-23 12:32:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:51 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.669 | ppl 813.86 | bleu 31.33 | wps 4640.5 | wpb 17862.2 | bsz 728.3 | num_updates 4706 | best_bleu 31.33
2022-03-23 12:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4706 updates
2022-03-23 12:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 30 @ 4706 updates, score 31.33) (writing took 1.769150139996782 seconds)
2022-03-23 12:32:53 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:32:53 | INFO | train | epoch 030 | loss 8.235 | ppl 301.25 | wps 39105.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 4706 | lr 0.000460971 | gnorm 0.385 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 3083
KL Stats: Epoch 30 Divergences: Uniform: 1.0173538468404326 Unigram: 1.6262396637273737
2022-03-23 12:32:54 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:32:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:29 | INFO | train_inner | epoch 031:     94 / 157 loss=8.237, ppl=301.76, wps=31262.7, ups=1.25, wpb=25031.5, bsz=996.4, num_updates=4800, lr=0.000456435, gnorm=0.359, loss_scale=8, train_wall=37, gb_free=12.1, wall=3120
2022-03-23 12:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:57 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:33:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:34:01 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:34:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that round magnets, of course, to form any same equilibrium.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother, when she was pregnant with him.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:34:13 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left a orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:34:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:34:17 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty, or any other promising topic.
2022-03-23 12:34:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection, which gives the big contextures of the face, and the basic shape, and then recover it through the one of the information that the whole porter structure and all the fits a fold.
2022-03-23 12:34:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. '"the truth is that women love you," that we've already started this topic for a long time. "
2022-03-23 12:34:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane are the most stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation of the design work, and a refrigeration system that allows us to use a garbage, or the wheel, if you look at the wheel, you can see the wheel, you have to go down to the bottom, you can see it, you can see the rain, you can see it would have to the rain, or the wheel, it would have to the wheel, you can see it would have to the wheel, it would have to the wheel, you can see it would have to the wheel, you can see it would have to the wheel, it would have the root down, you can use it would have the wheel, or the wheel, you can see it would have to
2022-03-23 12:34:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:33 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.676 | ppl 818.14 | bleu 31.3 | wps 4551 | wpb 17862.2 | bsz 728.3 | num_updates 4863 | best_bleu 31.33
2022-03-23 12:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4863 updates
2022-03-23 12:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 31 @ 4863 updates, score 31.3) (writing took 0.7889158059842885 seconds)
2022-03-23 12:34:33 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:34:33 | INFO | train | epoch 031 | loss 8.194 | ppl 292.76 | wps 39286.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4863 | lr 0.000453469 | gnorm 0.381 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 3184
KL Stats: Epoch 31 Divergences: Uniform: 1.017628667614408 Unigram: 1.629899557734984
2022-03-23 12:34:34 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:48 | INFO | train_inner | epoch 032:     37 / 157 loss=8.109, ppl=276.05, wps=32344.2, ups=1.27, wpb=25368.2, bsz=1001.5, num_updates=4900, lr=0.000451754, gnorm=0.405, loss_scale=8, train_wall=37, gb_free=11.7, wall=3198
2022-03-23 12:35:25 | INFO | train_inner | epoch 032:    137 / 157 loss=8.132, ppl=280.46, wps=66995.8, ups=2.65, wpb=25240.1, bsz=1067.4, num_updates=5000, lr=0.000447214, gnorm=0.334, loss_scale=8, train_wall=37, gb_free=12.1, wall=3236
2022-03-23 12:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:35:44 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets, of course, to form a popular equation.
2022-03-23 12:35:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:35:49 | INFO | fairseq.tasks.translation | example hypothesis: he had never met closer to his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:35:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:35:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we said, well, what do we do?
2022-03-23 12:35:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocides or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 12:35:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught in the inside, but the superconductor doesn't like it when they're moving, and so the superconductor disorder.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big contextures of face and the basic form, and recommends it through that one information that includes the whole porter structure and all the fits a fold.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measures for me here at tedwomen is that... well, when dinner became best summarized when somebody said, "turn you to the men at your table and say," if the revolution starts to support you. "
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in the transportation, or either if you have to use the wheel, or if you have to do it, or the proper mechanism of a mechanism that we're connected to the ground -- all the way, all the way down the way, all the way -- all the way, all the way that was to the way that we have to do it's going to do it's going to the stake of a mechanism of a mechanism of a mechanism of a mechanism that was to be connected to the stairs.
2022-03-23 12:36:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:11 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.639 | ppl 797.53 | bleu 31.03 | wps 4683.2 | wpb 17862.2 | bsz 728.3 | num_updates 5020 | best_bleu 31.33
2022-03-23 12:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5020 updates
2022-03-23 12:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 32 @ 5020 updates, score 31.03) (writing took 0.7860107040032744 seconds)
2022-03-23 12:36:12 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:36:12 | INFO | train | epoch 032 | loss 8.155 | ppl 284.97 | wps 39921.7 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5020 | lr 0.000446322 | gnorm 0.351 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 3283
KL Stats: Epoch 32 Divergences: Uniform: 1.0185652447294786 Unigram: 1.6385913727095571
2022-03-23 12:36:13 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:36:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:43 | INFO | train_inner | epoch 033:     80 / 157 loss=8.192, ppl=292.42, wps=32195.4, ups=1.29, wpb=25023.8, bsz=971.1, num_updates=5100, lr=0.000442807, gnorm=0.353, loss_scale=8, train_wall=37, gb_free=12.2, wall=3314
2022-03-23 12:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rocket.
2022-03-23 12:37:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:37:24 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand that rocket magnets to shape any same equality.
2022-03-23 12:37:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:37:28 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:37:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:37:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:37:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:37:36 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or prevalence of nuclear weapons or poverty, or any other promised topic.
2022-03-23 12:37:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:37:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are trapped in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:37:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:44 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can, which gives the big contextures of the face and the basic shape, and then refers it through the information that refers the whole porstructure and all the fa fold.
2022-03-23 12:37:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me to be here at tedwomen, is that... well, in the striking dinner, it was best summarized when someone said, "turn to the men at your table and tell you, '"' when the revolution starts, we support you, "'"' "the truth, women, women," we've already started to you, "
2022-03-23 12:37:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still, the mother of invention, and a big part of the design work that we're stumbling on at our plane, was a result of it that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variables, and a refrigerator system with refrigeration, that allows us to use an aircraft in the go-go-traffic, or a passenger, or a pigeon, and if you get the credible, you can see the credible, you can see the wheel, you can get the roady, you can use the wheel, you will have to the credible, you will have a dible, you will have to the wheel, you will have to the credible, you will have to the credible, you will have to the credible, and you will have the roady, you can see the wheel, and you will have to the
2022-03-23 12:37:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:51 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.634 | ppl 794.35 | bleu 31.83 | wps 4608.6 | wpb 17862.2 | bsz 728.3 | num_updates 5177 | best_bleu 31.83
2022-03-23 12:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5177 updates
2022-03-23 12:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 33 @ 5177 updates, score 31.83) (writing took 1.7720357179641724 seconds)
2022-03-23 12:37:53 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:37:53 | INFO | train | epoch 033 | loss 8.127 | ppl 279.48 | wps 39261.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5177 | lr 0.000439502 | gnorm 0.365 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 3383
KL Stats: Epoch 33 Divergences: Uniform: 1.0190938789329111 Unigram: 1.639054280567896
2022-03-23 12:37:53 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:38:02 | INFO | train_inner | epoch 034:     23 / 157 loss=8.049, ppl=264.85, wps=32025, ups=1.27, wpb=25212.8, bsz=1113.8, num_updates=5200, lr=0.000438529, gnorm=0.371, loss_scale=8, train_wall=37, gb_free=12.4, wall=3392
2022-03-23 12:38:40 | INFO | train_inner | epoch 034:    123 / 157 loss=8.119, ppl=278, wps=66570.7, ups=2.65, wpb=25095, bsz=986.3, num_updates=5300, lr=0.000434372, gnorm=0.343, loss_scale=8, train_wall=37, gb_free=11.8, wall=3430
2022-03-23 12:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:39:00 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:39:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:39:04 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expand that round magnets to shape any same glimpse.
2022-03-23 12:39:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:39:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:39:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:39:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:39:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:39:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:39:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big contextures of the face and the basic form of information that refers the whole porter structure and all the fits.
2022-03-23 12:39:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me to be here at tedwomen, is that -- well, in the striking dinner, it was best summarized when somebody said, "turn to the men at your table and say," if the revolution starts to support you. "
2022-03-23 12:39:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the most stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground, and we're going to see it in a continuous variables and refrigeration system with refrigeration and refrigeration system that allows us to use an aircraft in the veillance of fluid, that it allows us to use an aircraft in the vehicle in the field, to use it to get rid of automatically, and use it to use it to use it to get rid of a machine in the same way, and use it to get rid of automatically, if you to use it to get rid of a car traffic traffic traffic traffic traffic and use it to see it to the stairs.
2022-03-23 12:39:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:32 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.602 | ppl 776.87 | bleu 32.06 | wps 4608.7 | wpb 17862.2 | bsz 728.3 | num_updates 5334 | best_bleu 32.06
2022-03-23 12:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5334 updates
2022-03-23 12:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:39:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 34 @ 5334 updates, score 32.06) (writing took 1.7823535760398954 seconds)
2022-03-23 12:39:33 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:39:33 | INFO | train | epoch 034 | loss 8.103 | ppl 275.03 | wps 39265.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5334 | lr 0.000432986 | gnorm 0.344 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 3484
KL Stats: Epoch 34 Divergences: Uniform: 1.0197721183053672 Unigram: 1.645417644058028
2022-03-23 12:39:34 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:59 | INFO | train_inner | epoch 035:     66 / 157 loss=8.256, ppl=305.72, wps=31324.4, ups=1.26, wpb=24869.7, bsz=979, num_updates=5400, lr=0.000430331, gnorm=0.369, loss_scale=8, train_wall=37, gb_free=11.5, wall=3509
2022-03-23 12:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:40:41 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can protect about 8,000 places in the restaurant.
2022-03-23 12:40:41 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:40:45 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnet to form any same glide.
2022-03-23 12:40:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:40:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:40:56 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other talk.
2022-03-23 12:40:56 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnet field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:41:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big contextures of the face and the basic form, and refuse it through the one information that refuses the whole porter structure and all fold.
2022-03-23 12:41:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," when the revolution begins, women love you, we've been supporting you this issue for a long time. "
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied operating and a refrigeration system that allows us to use an aircraft in traffic traffic, to be used to stop in particular, to a vehicle traffic traffic traffic, or a particular passenger, to either when you can see the propelled mechanism that drill, either the propelled mechanism that drivers that are used to the propelled by the only when you can see the propelled to the propelled to the propelled to the stairs.
2022-03-23 12:41:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:11 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.579 | ppl 764.81 | bleu 31.81 | wps 4812.9 | wpb 17862.2 | bsz 728.3 | num_updates 5491 | best_bleu 32.06
2022-03-23 12:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5491 updates
2022-03-23 12:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 35 @ 5491 updates, score 31.81) (writing took 0.7811236859997734 seconds)
2022-03-23 12:41:12 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:41:12 | INFO | train | epoch 035 | loss 8.085 | ppl 271.61 | wps 40109 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5491 | lr 0.000426751 | gnorm 0.356 | loss_scale 8 | train_wall 58 | gb_free 13.1 | wall 3582
KL Stats: Epoch 35 Divergences: Uniform: 1.0175873166757718 Unigram: 1.6477258258672132
2022-03-23 12:41:12 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:16 | INFO | train_inner | epoch 036:      9 / 157 loss=7.945, ppl=246.42, wps=33130.9, ups=1.3, wpb=25522.5, bsz=1059.3, num_updates=5500, lr=0.000426401, gnorm=0.33, loss_scale=8, train_wall=37, gb_free=12.4, wall=3586
2022-03-23 12:41:54 | INFO | train_inner | epoch 036:    109 / 157 loss=7.949, ppl=247.18, wps=67695, ups=2.64, wpb=25595, bsz=1089.2, num_updates=5600, lr=0.000422577, gnorm=0.344, loss_scale=8, train_wall=37, gb_free=12, wall=3624
2022-03-23 12:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:42:20 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 12:42:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:42:24 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnets to shape any same same same same.
2022-03-23 12:42:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:42:27 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:42:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:42:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:42:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:42:36 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:42:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:42:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of the magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, you know, because your movements use energy, and so the superconductor disorder.
2022-03-23 12:42:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big contextures of the face and the basic form, and refers it through that kind of information that refuses the whole portural structure and all the fine.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured for me to be here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn to the men at your table and tell you, 'if the revolution begins, then we support you." the truth, women, love, we already have been supporting you for this topic for a long time. "
2022-03-23 12:42:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're proud of at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the staircase of the car, or when you get the propelled, or when you look at it, or when you get rid of the ratio, or when you get rid of the railroad, or when you get rid of the propelled mechanism, or when you get rid of the staircase, or when you get rid of the ratilated, or when you get rid of the ratilated, or when you get rid of the ratilated, or when you get rid of the ratilated, or when you get rid of the ratilated, or when you get rid of the stairs of the ratilated,
2022-03-23 12:42:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:51 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.571 | ppl 760.8 | bleu 32.54 | wps 4683.5 | wpb 17862.2 | bsz 728.3 | num_updates 5648 | best_bleu 32.54
2022-03-23 12:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5648 updates
2022-03-23 12:42:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:42:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 36 @ 5648 updates, score 32.54) (writing took 1.8222793289460242 seconds)
2022-03-23 12:42:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:42:53 | INFO | train | epoch 036 | loss 8.05 | ppl 264.98 | wps 39222.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5648 | lr 0.000420778 | gnorm 0.34 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 3683
KL Stats: Epoch 36 Divergences: Uniform: 1.0199109216059392 Unigram: 1.6539052783548653
2022-03-23 12:42:53 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:43:13 | INFO | train_inner | epoch 037:     52 / 157 loss=8.176, ppl=289.18, wps=31166.2, ups=1.27, wpb=24606.2, bsz=933, num_updates=5700, lr=0.000418854, gnorm=0.319, loss_scale=8, train_wall=37, gb_free=11.8, wall=3703
2022-03-23 12:43:50 | INFO | train_inner | epoch 037:    152 / 157 loss=7.998, ppl=255.65, wps=67242.9, ups=2.67, wpb=25190.2, bsz=1011, num_updates=5800, lr=0.000415227, gnorm=0.333, loss_scale=8, train_wall=37, gb_free=12.6, wall=3741
2022-03-23 12:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:44:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand this round magnet to shape any same glider.
2022-03-23 12:44:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:44:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:44:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:44:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:44:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:44:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other promising subject.
2022-03-23 12:44:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial can that refuse the big contexts of the face and the basic form, and through the thief of information that refits the whole porn structure and all fold.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, in striking dinner, it was best summarized when somebody said, "turn to the men at your table and say," if the revolution begins, then we support you. "the truth, women, you know, we've already been supporting you this topic for a long time."
2022-03-23 12:44:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously varied operating and refrigeration system that allows us to use an aircraft in particular, or if you get the propelled, the propelled, if you run it to the ground, you can see it on the edge of a car.
2022-03-23 12:44:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:30 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.574 | ppl 762.26 | bleu 32.42 | wps 4943.7 | wpb 17862.2 | bsz 728.3 | num_updates 5805 | best_bleu 32.54
2022-03-23 12:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5805 updates
2022-03-23 12:44:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 37 @ 5805 updates, score 32.42) (writing took 0.7518770820461214 seconds)
2022-03-23 12:44:30 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:44:30 | INFO | train | epoch 037 | loss 8.02 | ppl 259.5 | wps 40430.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 5805 | lr 0.000415049 | gnorm 0.318 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 3781
KL Stats: Epoch 37 Divergences: Uniform: 1.0209413587321656 Unigram: 1.6601865271634157
2022-03-23 12:44:31 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:44:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:06 | INFO | train_inner | epoch 038:     95 / 157 loss=8.069, ppl=268.61, wps=32576.8, ups=1.31, wpb=24808.2, bsz=981.3, num_updates=5900, lr=0.000411693, gnorm=0.346, loss_scale=8, train_wall=37, gb_free=12.4, wall=3817
2022-03-23 12:45:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:45:42 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expand that round magnets to form any same glider.
2022-03-23 12:45:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:45:46 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met to know his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:45:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:45:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:45:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:45:54 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other promising topic.
2022-03-23 12:45:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of the magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:46:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big contexts of the face and the basic form, and restore it through that one of the information that refers the whole porter structure and all the fine.
2022-03-23 12:46:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when somebody said, "turn to the men at your table and say," if the revolution begins, then we support you. "'if the truth, women love you about this topic has already been supporting you for a long time."
2022-03-23 12:46:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we are most proud of at our airplane was a result of the fact that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied operating and refrigerating system that allows us to use an aircraft in the traffic traffic, to either one particular, to the propelled, or if you can see it in the ground, or if you're going to operate it in the ground, you can see it in the wheel, or if you're going to the wheel, if you're going to the wheel it's either.
2022-03-23 12:46:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.524 | ppl 736.01 | bleu 32.85 | wps 4767.1 | wpb 17862.2 | bsz 728.3 | num_updates 5962 | best_bleu 32.85
2022-03-23 12:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5962 updates
2022-03-23 12:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 38 @ 5962 updates, score 32.85) (writing took 1.764751740032807 seconds)
2022-03-23 12:46:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:46:11 | INFO | train | epoch 038 | loss 8.005 | ppl 256.95 | wps 39269.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.331 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 3881
KL Stats: Epoch 38 Divergences: Uniform: 1.019317198783126 Unigram: 1.6597009509961411
2022-03-23 12:46:12 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:26 | INFO | train_inner | epoch 039:     38 / 157 loss=7.907, ppl=239.98, wps=32038.9, ups=1.25, wpb=25574.4, bsz=1048.3, num_updates=6000, lr=0.000408248, gnorm=0.303, loss_scale=8, train_wall=37, gb_free=12.3, wall=3897
2022-03-23 12:47:04 | INFO | train_inner | epoch 039:    138 / 157 loss=8.003, ppl=256.61, wps=66473.4, ups=2.65, wpb=25084.8, bsz=991.2, num_updates=6100, lr=0.000404888, gnorm=0.33, loss_scale=8, train_wall=37, gb_free=11.8, wall=3934
2022-03-23 12:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:15 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:47:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnet to form any same glider.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:47:26 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:47:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:47:30 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:47:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:47:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:47:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorders.
2022-03-23 12:47:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big contextures of the face and the basic form, and refers it through the information that refits the whole porter structure and all the fine.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that -- well, when striking dinner, it became best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. "the truth is that we've been supporting you this topic for a long time, carchel borson's" with silent, "then we've started to have a stumber boro," and then our future stream, "to downstream," and then, "and then down stone stream," and then down the future stream, "and say," -- when the revolution, "and then we're supporting you down," and then we're supporting you're supporting you're supporting you're supporting you down. "
2022-03-23 12:47:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are proud of at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in the stop-go-traffic traffic, to one particular passenger vehicle, or either drive the propulsion, when you have to operate it to the ground, or if you move it to the stake of a prophecy, until you get rid of the ground, until you get rid of a car facility, or if you move it to the stake, until the staircase you see the stake, until the staircase you get rid of a car facility for the stake, until the stake, you see the staircase you get rid of a car facility, or if you get rid of the ground, until the stairs, you get rid of a car
2022-03-23 12:47:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:49 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.547 | ppl 747.83 | bleu 32.56 | wps 4797.5 | wpb 17862.2 | bsz 728.3 | num_updates 6119 | best_bleu 32.85
2022-03-23 12:47:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6119 updates
2022-03-23 12:47:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:47:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 39 @ 6119 updates, score 32.56) (writing took 0.7599699689308181 seconds)
2022-03-23 12:47:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:47:50 | INFO | train | epoch 039 | loss 7.98 | ppl 252.5 | wps 40016.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6119 | lr 0.000404259 | gnorm 0.32 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 3980
KL Stats: Epoch 39 Divergences: Uniform: 1.0200755205403897 Unigram: 1.665654456935694
2022-03-23 12:47:50 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:48:21 | INFO | train_inner | epoch 040:     81 / 157 loss=7.978, ppl=252.04, wps=32667.9, ups=1.29, wpb=25270.4, bsz=983.5, num_updates=6200, lr=0.00040161, gnorm=0.338, loss_scale=8, train_wall=37, gb_free=12, wall=4012
2022-03-23 12:48:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:48:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:48:57 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:48:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:49:01 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expand that round magnet to form any same glider.
2022-03-23 12:49:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:49:05 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:49:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:49:09 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, all right, what do we do with her?
2022-03-23 12:49:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:49:13 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or poverty or any other corresponding issue.
2022-03-23 12:49:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:49:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductive disorders.
2022-03-23 12:49:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic shape of it, and recommends the whole porn structure and all the fine folds.
2022-03-23 12:49:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:49:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that -- well, in striking dinner, it was best summarized when somebody said, "turn to the men at your table and tell them," if the revolution begins, then we support you. "'" the truth, women is that we've already started you with this topic for a long time. "
2022-03-23 12:49:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:49:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable operating and refrigeration system that allows us to use an aircraft in the stop traffic until a particular operating system, either the propelled, or either the propelled to be able to use it to operate on the ground for the stairs of a continuously, to see the fake of a mechanism, to the stake of a continuously, to the stake of an aircraft in the stake of an aircraft in the stakes in the stakes in the stake of a rustling system, to the stake of a rustling system, to the stake of an aircraft, to the stake of an aircraft, to the staircase, to the staircase, to the stake of an aircraft
2022-03-23 12:49:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:49:28 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.513 | ppl 730.57 | bleu 33 | wps 4778.3 | wpb 17862.2 | bsz 728.3 | num_updates 6276 | best_bleu 33
2022-03-23 12:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6276 updates
2022-03-23 12:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 40 @ 6276 updates, score 33.0) (writing took 1.8256175080314279 seconds)
2022-03-23 12:49:29 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:49:29 | INFO | train | epoch 040 | loss 7.965 | ppl 249.92 | wps 39505.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6276 | lr 0.000399171 | gnorm 0.33 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 4080
KL Stats: Epoch 40 Divergences: Uniform: 1.0201929433339558 Unigram: 1.6678938081989463
2022-03-23 12:49:30 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:39 | INFO | train_inner | epoch 041:     24 / 157 loss=8.073, ppl=269.23, wps=31238.5, ups=1.28, wpb=24389.1, bsz=1077.7, num_updates=6300, lr=0.00039841, gnorm=0.33, loss_scale=8, train_wall=37, gb_free=12.7, wall=4090
2022-03-23 12:50:17 | INFO | train_inner | epoch 041:    124 / 157 loss=7.836, ppl=228.57, wps=67592.7, ups=2.63, wpb=25662.2, bsz=1044.2, num_updates=6400, lr=0.000395285, gnorm=0.31, loss_scale=8, train_wall=38, gb_free=12.6, wall=4128
2022-03-23 12:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:50:37 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:50:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:50:41 | INFO | fairseq.tasks.translation | example hypothesis: and of course, this round magnet, i can expand to form any trait.
2022-03-23 12:50:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:50:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:50:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:50:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:50:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:50:53 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or poverty or any other promising topic.
2022-03-23 12:50:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:50:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:50:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:51:01 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial, which gives the scores of the face and the basic information that refers the whole porn structure and all the fine folds.
2022-03-23 12:51:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:51:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, in striking dinner, it was best summarized when someone said, "turn to the men at your table and say," when the revolution begins, we support you. "the truth, women is that we've already started to support you with this topic for a long time." in carchel borra, "
2022-03-23 12:51:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:51:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable gear and cooling system that allows us to use an aircraft in stop traffic until you see the propulsion, either the propellant, or the propellant, if you can see the false space, to the wrong system, the car storm, if you can see a mechanism.
2022-03-23 12:51:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:51:07 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.533 | ppl 740.79 | bleu 32.88 | wps 4923.3 | wpb 17862.2 | bsz 728.3 | num_updates 6433 | best_bleu 33
2022-03-23 12:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6433 updates
2022-03-23 12:51:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 41 @ 6433 updates, score 32.88) (writing took 0.7839815790066496 seconds)
2022-03-23 12:51:07 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:51:07 | INFO | train | epoch 041 | loss 7.943 | ppl 246.05 | wps 40366.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6433 | lr 0.00039427 | gnorm 0.32 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 4178
KL Stats: Epoch 41 Divergences: Uniform: 1.0218682240920742 Unigram: 1.6725598785109204
2022-03-23 12:51:08 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:34 | INFO | train_inner | epoch 042:     67 / 157 loss=7.797, ppl=222.42, wps=33643.1, ups=1.31, wpb=25707, bsz=1062.3, num_updates=6500, lr=0.000392232, gnorm=0.316, loss_scale=8, train_wall=37, gb_free=11.7, wall=4204
2022-03-23 12:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:52:16 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:52:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:52:20 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand this round magnet to form any trait.
2022-03-23 12:52:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:52:24 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:52:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:52:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:52:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:52:32 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or prevalence of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:52:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:52:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:52:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:41 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can, which will restore the scales of the face and the basic form, and through the information that refers the whole porous structure and all the fine wrinkles.
2022-03-23 12:52:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that -- well, at a strict dinner, it was best summarized when someone said, "turn to the men at your table and tell them," if the revolution begins, then we support you. "'" the truth, women is that we've already started you with this topic for a long time. carchel borne, "
2022-03-23 12:52:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that have been connected to operating on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft machine to stop traffic, or either drive the propeller, to the ground, to the ground, to operate it -- to operate it, to the ground.
2022-03-23 12:52:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.499 | ppl 723.51 | bleu 33.48 | wps 4828.8 | wpb 17862.2 | bsz 728.3 | num_updates 6590 | best_bleu 33.48
2022-03-23 12:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6590 updates
2022-03-23 12:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:52:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt
2022-03-23 12:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_best.pt (epoch 42 @ 6590 updates, score 33.48) (writing took 1.8341092220507562 seconds)
2022-03-23 12:52:48 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:52:48 | INFO | train | epoch 042 | loss 7.932 | ppl 244.14 | wps 39136.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6590 | lr 0.000389545 | gnorm 0.326 | loss_scale 8 | train_wall 58 | gb_free 13.2 | wall 4279
KL Stats: Epoch 42 Divergences: Uniform: 1.020186731663365 Unigram: 1.6719538264547753
2022-03-23 12:52:49 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:53 | INFO | train_inner | epoch 043:     10 / 157 loss=8.095, ppl=273.47, wps=31308.8, ups=1.27, wpb=24675.4, bsz=961.4, num_updates=6600, lr=0.000389249, gnorm=0.324, loss_scale=8, train_wall=37, gb_free=12.8, wall=4283
2022-03-23 12:53:30 | INFO | train_inner | epoch 043:    110 / 157 loss=7.945, ppl=246.51, wps=66516.4, ups=2.68, wpb=24783.4, bsz=979.9, num_updates=6700, lr=0.000386334, gnorm=0.311, loss_scale=8, train_wall=37, gb_free=12.4, wall=4320
2022-03-23 12:53:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:52 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:53:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:53:56 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:53:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:54:00 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expand this rocket to form any same glide.
2022-03-23 12:54:00 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:54:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:54:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:54:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductive disorders.
2022-03-23 12:54:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:54:19 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big contextures of the face and the basic form and refers it through the information that refers the whole portion structure and all the fine wrinkles.
2022-03-23 12:54:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:54:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. "'" the truth, women is that we've been supporting you at this topic for a long time. carchel, with ratheo borns, "it was best summarized by the future of sand," and then we've started to downstairs. "
2022-03-23 12:54:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:54:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're proud of at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuous variation and cooling system, that allows us to use an aircraft in the stop traffic and traffic, until you fit the propeller, or when you look at it, the propelled, or if you look at the bottom of a car, and you get the wrong system, and you get a refrigeration, and you get a cooling system with it allows us to see an aircraft in the stairs.
2022-03-23 12:54:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:54:26 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.51 | ppl 729.34 | bleu 32.92 | wps 4888.9 | wpb 17862.2 | bsz 728.3 | num_updates 6747 | best_bleu 33.48
2022-03-23 12:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6747 updates
2022-03-23 12:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:54:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 43 @ 6747 updates, score 32.92) (writing took 0.7886472430545837 seconds)
2022-03-23 12:54:26 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:54:26 | INFO | train | epoch 043 | loss 7.906 | ppl 239.93 | wps 40260.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6747 | lr 0.000384986 | gnorm 0.306 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 4377
KL Stats: Epoch 43 Divergences: Uniform: 1.0217541479859025 Unigram: 1.6783484176597632
2022-03-23 12:54:27 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:47 | INFO | train_inner | epoch 044:     53 / 157 loss=7.887, ppl=236.8, wps=32732.5, ups=1.3, wpb=25221.5, bsz=1062.9, num_updates=6800, lr=0.000383482, gnorm=0.315, loss_scale=8, train_wall=37, gb_free=12.1, wall=4397
2022-03-23 12:55:24 | INFO | train_inner | epoch 044:    153 / 157 loss=7.851, ppl=230.95, wps=67862.5, ups=2.66, wpb=25470, bsz=1029.1, num_updates=6900, lr=0.000380693, gnorm=0.304, loss_scale=8, train_wall=37, gb_free=12, wall=4435
2022-03-23 12:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:55:30 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:55:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:55:34 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occur about 8,000 places in the restaurant.
2022-03-23 12:55:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:55:38 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand that round magnets to form any same glide.
2022-03-23 12:55:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:55:42 | INFO | fairseq.tasks.translation | example hypothesis: he never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:55:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:55:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:55:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:55:50 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:55:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:55:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and the superconducting disorders.
2022-03-23 12:55:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeat the big contexts of the face and the basic form of the information that refits the whole porn structure and all wrinkles.
2022-03-23 12:55:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:56:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins, then we support you. '"the truth is that we've already supported you for a long time.
2022-03-23 12:56:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:56:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we stumbled on on on our plane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously varied and cooling system that allows us to use an aircraft in stop go-traffic, until a particular drill, which is either the propeller you see, or when you get the propeller on the ground, until you see it, or when you get rid of a mechanism.
2022-03-23 12:56:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:56:04 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.489 | ppl 718.71 | bleu 33.42 | wps 4915.1 | wpb 17862.2 | bsz 728.3 | num_updates 6904 | best_bleu 33.48
2022-03-23 12:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6904 updates
2022-03-23 12:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:56:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 44 @ 6904 updates, score 33.42) (writing took 0.8387422019150108 seconds)
2022-03-23 12:56:05 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:56:05 | INFO | train | epoch 044 | loss 7.893 | ppl 237.74 | wps 40207.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6904 | lr 0.000380583 | gnorm 0.312 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 4475
KL Stats: Epoch 44 Divergences: Uniform: 1.0212923884021747 Unigram: 1.680995170380719
2022-03-23 12:56:05 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:56:41 | INFO | train_inner | epoch 045:     96 / 157 loss=7.838, ppl=228.88, wps=32966.9, ups=1.3, wpb=25382, bsz=970.5, num_updates=7000, lr=0.000377964, gnorm=0.305, loss_scale=8, train_wall=37, gb_free=11.6, wall=4512
2022-03-23 12:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:57:12 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:57:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can expand this round magnet to form any same glide.
2022-03-23 12:57:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:57:20 | INFO | fairseq.tasks.translation | example hypothesis: he never had met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:57:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:57:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:57:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:57:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:57:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:57:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disturbs.
2022-03-23 12:57:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face that gives the big contexts of the face and the basic shape, and refuses it through the information that all the pores structure and all the fine wrinkles.
2022-03-23 12:57:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, at tedwomen, one of the reasons that it's been best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. '"the truth, women is that we've been supporting you at this topic for a long time. in rachel, carchel borne borne," our "and then we've started with silent borne borne borne," -- when someone said, "steady," steady borra borne, "sand borne," -- when someone said, "steady," -- when the future is that's our hoe for a stroke, "-- when the future is that's our
2022-03-23 12:57:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still is the mother of invention, and a big part of the design work that we're on our plane most stumbling on, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft in stopgo-traffic until a specially adapted vehicle that drives the propelled, either when you have to solve the propelled wheel, you have to operate it, you have to operate it, you know, you have to operate it on the propelled on the ground when you get rid of a propelled, you get rid of a prophecy when you get rid of the prophecy, you get rid of a vehicle vehicle vehicle vehicle vehicle vehicle vehicle, you get rid of a mechanism, or when you get rid of it, you get rid of it, you get rid of it, you get rid of it, you
2022-03-23 12:57:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:43 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.485 | ppl 716.39 | bleu 33.38 | wps 4677 | wpb 17862.2 | bsz 728.3 | num_updates 7061 | best_bleu 33.48
2022-03-23 12:57:43 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7061 updates
2022-03-23 12:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt
2022-03-23 12:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#4/checkpoint_last.pt (epoch 45 @ 7061 updates, score 33.38) (writing took 0.8125850529177114 seconds)
2022-03-23 12:57:44 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:57:44 | INFO | train | epoch 045 | loss 7.88 | ppl 235.64 | wps 39848.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7061 | lr 0.000376328 | gnorm 0.319 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 4574
2022-03-23 12:57:44 | INFO | fairseq_cli.train | done training in 4573.7 seconds
