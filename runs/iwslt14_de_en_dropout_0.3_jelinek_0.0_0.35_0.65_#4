Sender: LSF System <lsfadmin@eu-g3-062>
Subject: Job 210594831: <iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:32:52 2022
Job was executed on host(s) <eu-g3-062>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:33:00 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:33:00 2022
Terminated at Wed Mar 23 13:02:11 2022
Results reported at Wed Mar 23 13:02:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.0,0.35,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5338.39 sec.
    Max Memory :                                 5182 MB
    Average Memory :                             3998.40 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14818.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5360 sec.
    Turnaround time :                            5359 sec.

The output (if any) follows:

2022-03-23 11:33:06 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.0,0.35,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.0,0.35,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:33:06 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:33:06 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:33:07 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:33:07 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:33:07 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1163/160239 [00:00<00:13, 11626.57it/s]  2%|▏         | 2550/160239 [00:00<00:12, 12939.71it/s]  2%|▏         | 3979/160239 [00:00<00:11, 13550.35it/s]  3%|▎         | 5335/160239 [00:00<00:11, 13311.70it/s]  4%|▍         | 6726/160239 [00:00<00:11, 13522.78it/s]  5%|▌         | 8079/160239 [00:00<00:11, 13095.18it/s]  6%|▌         | 9392/160239 [00:00<00:11, 13086.43it/s]  7%|▋         | 10796/160239 [00:00<00:11, 13383.07it/s]  8%|▊         | 12137/160239 [00:00<00:11, 13171.02it/s]  8%|▊         | 13456/160239 [00:01<00:11, 13153.17it/s]  9%|▉         | 14773/160239 [00:01<00:11, 13085.65it/s] 10%|█         | 16083/160239 [00:01<00:11, 12975.80it/s] 11%|█         | 17382/160239 [00:01<00:11, 12630.84it/s] 12%|█▏        | 18689/160239 [00:01<00:11, 12758.31it/s] 13%|█▎        | 20127/160239 [00:01<00:10, 13235.76it/s] 13%|█▎        | 21453/160239 [00:01<00:10, 13107.85it/s] 14%|█▍        | 22766/160239 [00:01<00:10, 12884.84it/s] 15%|█▌        | 24057/160239 [00:01<00:10, 12863.69it/s] 16%|█▌        | 25363/160239 [00:01<00:10, 12919.10it/s] 17%|█▋        | 26656/160239 [00:02<00:10, 12746.25it/s] 17%|█▋        | 28037/160239 [00:02<00:10, 13058.52it/s] 18%|█▊        | 29345/160239 [00:02<00:10, 13042.81it/s] 19%|█▉        | 30651/160239 [00:02<00:10, 12566.19it/s] 20%|██        | 32060/160239 [00:02<00:09, 13005.10it/s] 21%|██        | 33365/160239 [00:02<00:09, 12787.22it/s] 22%|██▏       | 34648/160239 [00:02<00:09, 12577.77it/s] 22%|██▏       | 35964/160239 [00:02<00:09, 12746.11it/s] 23%|██▎       | 37242/160239 [00:02<00:09, 12716.63it/s] 24%|██▍       | 38569/160239 [00:02<00:09, 12879.01it/s] 25%|██▍       | 39859/160239 [00:03<00:09, 12800.74it/s] 26%|██▌       | 41196/160239 [00:03<00:09, 12967.27it/s] 27%|██▋       | 42494/160239 [00:03<00:09, 12626.03it/s] 27%|██▋       | 43759/160239 [00:03<00:09, 12578.70it/s] 28%|██▊       | 45019/160239 [00:03<00:09, 12503.77it/s] 29%|██▉       | 46374/160239 [00:03<00:08, 12810.42it/s] 30%|██▉       | 47749/160239 [00:03<00:08, 13086.94it/s] 31%|███       | 49060/160239 [00:03<00:08, 12914.55it/s] 31%|███▏      | 50353/160239 [00:03<00:08, 12794.45it/s] 32%|███▏      | 51699/160239 [00:04<00:08, 12988.89it/s] 33%|███▎      | 53014/160239 [00:04<00:08, 13034.70it/s] 34%|███▍      | 54319/160239 [00:04<00:08, 12971.56it/s] 35%|███▍      | 55617/160239 [00:04<00:08, 12938.91it/s] 36%|███▌      | 56941/160239 [00:04<00:07, 13027.82it/s] 36%|███▋      | 58323/160239 [00:04<00:07, 13261.86it/s] 37%|███▋      | 59651/160239 [00:04<00:07, 13263.33it/s] 38%|███▊      | 60978/160239 [00:04<00:07, 13127.84it/s] 39%|███▉      | 62307/160239 [00:04<00:07, 13174.93it/s] 40%|███▉      | 63625/160239 [00:04<00:07, 13159.68it/s] 41%|████      | 65158/160239 [00:05<00:06, 13806.48it/s] 42%|████▏     | 66540/160239 [00:05<00:06, 13672.77it/s] 42%|████▏     | 67908/160239 [00:05<00:06, 13340.61it/s] 43%|████▎     | 69245/160239 [00:05<00:07, 12919.43it/s] 44%|████▍     | 70586/160239 [00:05<00:06, 13059.05it/s] 45%|████▍     | 71903/160239 [00:05<00:06, 13089.72it/s] 46%|████▌     | 73215/160239 [00:05<00:06, 12939.37it/s] 46%|████▋     | 74511/160239 [00:05<00:06, 12882.42it/s] 47%|████▋     | 75807/160239 [00:05<00:06, 12903.75it/s] 48%|████▊     | 77176/160239 [00:05<00:06, 13135.93it/s] 49%|████▉     | 78541/160239 [00:06<00:06, 13286.23it/s] 50%|████▉     | 79877/160239 [00:06<00:06, 13304.70it/s] 51%|█████     | 81383/160239 [00:06<00:05, 13826.71it/s] 52%|█████▏    | 82767/160239 [00:06<00:05, 13504.76it/s] 52%|█████▏    | 84120/160239 [00:06<00:05, 13372.52it/s] 53%|█████▎    | 85483/160239 [00:06<00:05, 13447.56it/s] 54%|█████▍    | 86918/160239 [00:06<00:05, 13710.02it/s] 55%|█████▌    | 88291/160239 [00:06<00:05, 13368.89it/s] 56%|█████▌    | 89714/160239 [00:06<00:05, 13619.75it/s] 57%|█████▋    | 91079/160239 [00:06<00:05, 13368.47it/s] 58%|█████▊    | 92420/160239 [00:07<00:05, 13378.22it/s] 59%|█████▊    | 93760/160239 [00:07<00:05, 13179.40it/s] 59%|█████▉    | 95080/160239 [00:07<00:04, 13039.88it/s] 60%|██████    | 96437/160239 [00:07<00:04, 13191.82it/s] 61%|██████    | 97760/160239 [00:07<00:04, 13199.89it/s] 62%|██████▏   | 99081/160239 [00:07<00:04, 13103.32it/s] 63%|██████▎   | 100443/160239 [00:07<00:04, 13254.98it/s] 64%|██████▎   | 101774/160239 [00:07<00:04, 13269.98it/s] 64%|██████▍   | 103102/160239 [00:07<00:04, 13115.11it/s] 65%|██████▌   | 104463/160239 [00:07<00:04, 13259.14it/s] 66%|██████▌   | 105812/160239 [00:08<00:04, 13327.21it/s] 67%|██████▋   | 107146/160239 [00:08<00:04, 13180.69it/s] 68%|██████▊   | 108465/160239 [00:08<00:04, 12804.23it/s] 68%|██████▊   | 109748/160239 [00:08<00:03, 12719.18it/s] 69%|██████▉   | 111041/160239 [00:08<00:03, 12779.98it/s] 70%|███████   | 112444/160239 [00:08<00:03, 13146.06it/s] 71%|███████   | 113785/160239 [00:08<00:03, 13221.68it/s] 72%|███████▏  | 115109/160239 [00:08<00:03, 13181.16it/s] 73%|███████▎  | 116428/160239 [00:08<00:03, 13157.47it/s] 73%|███████▎  | 117745/160239 [00:09<00:03, 13070.89it/s] 74%|███████▍  | 119139/160239 [00:09<00:03, 13326.88it/s] 75%|███████▌  | 120473/160239 [00:09<00:03, 13139.11it/s] 76%|███████▌  | 121864/160239 [00:09<00:02, 13365.78it/s] 77%|███████▋  | 123239/160239 [00:09<00:02, 13478.12it/s] 78%|███████▊  | 124588/160239 [00:09<00:02, 13212.06it/s] 79%|███████▊  | 125911/160239 [00:09<00:02, 13090.73it/s] 79%|███████▉  | 127222/160239 [00:09<00:02, 13080.73it/s] 80%|████████  | 128626/160239 [00:09<00:02, 13363.14it/s] 81%|████████  | 129964/160239 [00:09<00:02, 13114.22it/s] 82%|████████▏ | 131277/160239 [00:10<00:02, 12959.63it/s] 83%|████████▎ | 132576/160239 [00:10<00:02, 12966.79it/s] 84%|████████▎ | 133874/160239 [00:10<00:02, 12753.60it/s] 84%|████████▍ | 135161/160239 [00:10<00:01, 12787.43it/s] 85%|████████▌ | 136544/160239 [00:10<00:01, 13094.59it/s] 86%|████████▌ | 137898/160239 [00:10<00:01, 13225.23it/s] 87%|████████▋ | 139290/160239 [00:10<00:01, 13430.83it/s] 88%|████████▊ | 140665/160239 [00:10<00:01, 13524.43it/s] 89%|████████▊ | 142019/160239 [00:10<00:01, 13321.78it/s] 89%|████████▉ | 143353/160239 [00:10<00:01, 13263.64it/s] 90%|█████████ | 144681/160239 [00:11<00:01, 13225.36it/s] 91%|█████████ | 146005/160239 [00:11<00:01, 12944.24it/s] 92%|█████████▏| 147301/160239 [00:11<00:01, 12886.99it/s] 93%|█████████▎| 148591/160239 [00:11<00:00, 12591.82it/s] 94%|█████████▎| 149866/160239 [00:11<00:00, 12633.53it/s] 94%|█████████▍| 151182/160239 [00:11<00:00, 12785.02it/s] 95%|█████████▌| 152511/160239 [00:11<00:00, 12933.10it/s] 96%|█████████▌| 153806/160239 [00:11<00:00, 12920.21it/s] 97%|█████████▋| 155240/160239 [00:11<00:00, 13339.06it/s] 98%|█████████▊| 156575/160239 [00:11<00:00, 13329.41it/s] 99%|█████████▊| 157909/160239 [00:12<00:00, 13265.72it/s] 99%|█████████▉| 159262/160239 [00:12<00:00, 13342.66it/s]100%|██████████| 160239/160239 [00:12<00:00, 13098.45it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3727/160239 [00:00<00:04, 37265.68it/s]  5%|▍         | 7561/160239 [00:00<00:04, 37887.85it/s]  7%|▋         | 11403/160239 [00:00<00:03, 38129.16it/s]  9%|▉         | 15216/160239 [00:00<00:03, 38026.61it/s] 12%|█▏        | 19019/160239 [00:00<00:03, 37690.32it/s] 14%|█▍        | 22845/160239 [00:00<00:03, 37881.71it/s] 17%|█▋        | 26634/160239 [00:00<00:03, 37868.26it/s] 19%|█▉        | 30431/160239 [00:00<00:03, 37897.14it/s] 21%|██▏       | 34224/160239 [00:00<00:03, 37906.35it/s] 24%|██▎       | 38015/160239 [00:01<00:03, 37862.28it/s] 26%|██▌       | 41820/160239 [00:01<00:03, 37916.59it/s] 28%|██▊       | 45612/160239 [00:01<00:03, 37542.70it/s] 31%|███       | 49439/160239 [00:01<00:02, 37759.44it/s] 33%|███▎      | 53258/160239 [00:01<00:02, 37883.95it/s] 36%|███▌      | 57158/160239 [00:01<00:02, 38217.41it/s] 38%|███▊      | 61017/160239 [00:01<00:02, 38327.14it/s] 41%|████      | 65070/160239 [00:01<00:02, 38985.18it/s] 43%|████▎     | 68969/160239 [00:01<00:02, 38447.69it/s] 45%|████▌     | 72816/160239 [00:01<00:02, 38442.40it/s] 48%|████▊     | 76662/160239 [00:02<00:02, 38212.01it/s] 50%|█████     | 80714/160239 [00:02<00:02, 38896.01it/s] 53%|█████▎    | 84637/160239 [00:02<00:01, 38993.93it/s] 55%|█████▌    | 88599/160239 [00:02<00:01, 39179.62it/s] 58%|█████▊    | 92518/160239 [00:02<00:01, 39139.76it/s] 60%|██████    | 96433/160239 [00:02<00:01, 38377.12it/s] 63%|██████▎   | 100345/160239 [00:02<00:01, 38595.73it/s] 65%|██████▌   | 104208/160239 [00:02<00:01, 38425.83it/s] 67%|██████▋   | 108053/160239 [00:02<00:01, 38293.66it/s] 70%|██████▉   | 111884/160239 [00:02<00:01, 38265.74it/s] 72%|███████▏  | 115725/160239 [00:03<00:01, 38306.27it/s] 75%|███████▍  | 119621/160239 [00:03<00:01, 38499.92it/s] 77%|███████▋  | 123499/160239 [00:03<00:00, 38581.12it/s] 79%|███████▉  | 127358/160239 [00:03<00:00, 38252.83it/s] 82%|████████▏ | 131185/160239 [00:03<00:00, 37980.32it/s] 84%|████████▍ | 134984/160239 [00:03<00:00, 37652.58it/s] 87%|████████▋ | 138810/160239 [00:03<00:00, 37832.05it/s] 89%|████████▉ | 142595/160239 [00:03<00:00, 37833.13it/s] 91%|█████████▏| 146379/160239 [00:03<00:00, 37629.46it/s] 94%|█████████▎| 150143/160239 [00:03<00:00, 37206.36it/s] 96%|█████████▌| 153865/160239 [00:04<00:00, 37113.98it/s] 98%|█████████▊| 157692/160239 [00:04<00:00, 37456.22it/s]100%|██████████| 160239/160239 [00:04<00:00, 38083.62it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2197.12it/s]2022-03-23 11:33:26 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:33:26 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:33:26 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:33:26 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:33:26 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:33:26 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:33:26 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:33:26 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:33:26 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:33:26 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:33:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:33:26 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:33:26 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:33:26 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:33:26 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:33:26 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 11:33:26 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 11:33:26 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:33:26 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:33:26 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:33:26 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:33:26 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:33:26 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:33:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:33:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:34:08 | INFO | train_inner | epoch 001:    104 / 157 loss=13.018, ppl=8297.03, wps=66912.1, ups=2.65, wpb=25206.6, bsz=1100.4, num_updates=100, lr=1.25e-05, gnorm=3.837, loss_scale=8, train_wall=41, gb_free=11.8, wall=42
2022-03-23 11:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:34:31 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:34:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:34:34 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:34:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:34:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:34:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:34:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:34:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:34:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:34:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:34:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:34:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:34:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:34:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:34:58 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:34:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:35:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:35:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:35:08 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:35:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:35:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.13 | ppl 4483.14 | bleu 0.01 | wps 4426.7 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.7532286969944835 seconds)
2022-03-23 11:35:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:35:10 | INFO | train | epoch 001 | loss 12.472 | ppl 5679.73 | wps 38652.7 | ups 1.54 | wpb 25100.3 | bsz 1012.5 | num_updates 153 | lr 1.9125e-05 | gnorm 2.927 | loss_scale 8 | train_wall 60 | gb_free 12.1 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.5890554374372151 Unigram: 1.439530746089296
2022-03-23 11:35:10 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:35:28 | INFO | train_inner | epoch 002:     47 / 157 loss=11.195, ppl=2344.19, wps=31377, ups=1.26, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.192, loss_scale=8, train_wall=36, gb_free=22.3, wall=122
2022-03-23 11:36:05 | INFO | train_inner | epoch 002:    147 / 157 loss=10.454, ppl=1402.58, wps=66797.2, ups=2.67, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.83, loss_scale=8, train_wall=37, gb_free=12.1, wall=159
2022-03-23 11:36:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:36:12 | INFO | fairseq.tasks.translation | example hypothesis: .
2022-03-23 11:36:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:36:15 | INFO | fairseq.tasks.translation | example hypothesis: the the.
2022-03-23 11:36:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:36:17 | INFO | fairseq.tasks.translation | example hypothesis: i i i.
2022-03-23 11:36:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:36:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the.
2022-03-23 11:36:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:36:24 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 11:36:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:36:28 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the the the the the the the the the the the the the the the the.
2022-03-23 11:36:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:36:33 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:36:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:36:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and
2022-03-23 11:36:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:36:47 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:36:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:36:49 | INFO | fairseq.tasks.translation | example hypothesis: and and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:36:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:36:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.133 | ppl 2245.34 | bleu 0.02 | wps 4402.2 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:36:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:36:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.870793490903452 seconds)
2022-03-23 11:36:51 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:36:51 | INFO | train | epoch 002 | loss 10.555 | ppl 1504.12 | wps 39012.4 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.935 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 205
KL Stats: Epoch 2 Divergences: Uniform: 0.9013832169006765 Unigram: 0.2909908138541117
2022-03-23 11:36:51 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:36:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:37:25 | INFO | train_inner | epoch 003:     90 / 157 loss=10.14, ppl=1128.14, wps=31157.7, ups=1.25, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.85, loss_scale=8, train_wall=37, gb_free=12, wall=239
2022-03-23 11:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:37:54 | INFO | fairseq.tasks.translation | example hypothesis: and you.
2022-03-23 11:37:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:37:58 | INFO | fairseq.tasks.translation | example hypothesis: and the the, the.
2022-03-23 11:37:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:38:02 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i, i, i, i, i to to to to to to to to to to to to to to to to
2022-03-23 11:38:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:38:07 | INFO | fairseq.tasks.translation | example hypothesis: so, i, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:38:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:38:13 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we
2022-03-23 11:38:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:38:19 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and and and we to the the to to to to to to to to to to to to to to to to to the
2022-03-23 11:38:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:38:25 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, and the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:38:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:38:31 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we the the the the, and the the, and the the the the, and and and and the the the the the the the, and and and the the, and and and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and we
2022-03-23 11:38:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:38:38 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, "" "" "the," "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:38:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:38:41 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the the the the the the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:38:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:38:41 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.947 | ppl 1974.73 | bleu 0.17 | wps 3503.8 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.17
2022-03-23 11:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:38:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.17) (writing took 1.8192077141720802 seconds)
2022-03-23 11:38:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:38:42 | INFO | train | epoch 003 | loss 10.043 | ppl 1054.63 | wps 35413.1 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.931 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 316
KL Stats: Epoch 3 Divergences: Uniform: 1.4371264673198363 Unigram: 0.14280866561052866
2022-03-23 11:38:43 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:38:55 | INFO | train_inner | epoch 004:     33 / 157 loss=9.92, ppl=968.93, wps=28353.6, ups=1.11, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=0.953, loss_scale=8, train_wall=37, gb_free=12, wall=329
2022-03-23 11:39:33 | INFO | train_inner | epoch 004:    133 / 157 loss=9.798, ppl=890.46, wps=67110.7, ups=2.66, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.137, loss_scale=8, train_wall=37, gb_free=12.4, wall=367
2022-03-23 11:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:39:46 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can see.
2022-03-23 11:39:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:39:50 | INFO | fairseq.tasks.translation | example hypothesis: and he he he he he he he he he he he.
2022-03-23 11:39:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:39:55 | INFO | fairseq.tasks.translation | example hypothesis: and i think, i think i think i'm'm'm'm to to to to to to to to to a a of the world.
2022-03-23 11:39:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:40:00 | INFO | fairseq.tasks.translation | example hypothesis: and he was was he he he was was was was he he was was was was was he he he he he he was was was was was was was he he he he was was was was was was was
2022-03-23 11:40:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:40:05 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we know, what we know, we know, and we can can can do we know, what we can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 11:40:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:40:11 | INFO | fairseq.tasks.translation | example hypothesis: and we know, and we can can can can can or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or.
2022-03-23 11:40:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:40:17 | INFO | fairseq.tasks.translation | example hypothesis: but you're, but it's the world, but you have the world, but you have the world, but it's the world, but you have the world, but but you're, but but you're're're're, and they're're're're're, but you're're, but you're're're, but you're're're're
2022-03-23 11:40:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:40:23 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we have the world of the world, and we can can can can can can can can can can can can see the world, and we have the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world of the world, and we have the world of the
2022-03-23 11:40:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | example hypothesis: and ",", ",", "" "" "," "" "", "" "" "," ",", "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:40:32 | INFO | fairseq.tasks.translation | example hypothesis: and that's the of the, and we're, and that we're, and we have the world, and that, and it's the world of the world, and it's the world, and it's the world of the world of the world, and it's the world of the world of the world of the world, and it's the world, and it's the world, and it's the world of the world, and that that that, and that that, and that that, and that, and that, and it's the world of the world of the world, and that, and that, and it's the world of the world, and it's the world of the world of the world, and that, and we can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, and that, and the
2022-03-23 11:40:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:40:32 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.73 | ppl 1698.98 | bleu 0.91 | wps 3559.3 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.91
2022-03-23 11:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:40:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:40:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.91) (writing took 1.8229131321422756 seconds)
2022-03-23 11:40:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:40:33 | INFO | train | epoch 004 | loss 9.862 | ppl 930.85 | wps 35587.1 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.02 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 427
KL Stats: Epoch 4 Divergences: Uniform: 1.641581657550214 Unigram: 0.21030570853613645
2022-03-23 11:40:34 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:41:02 | INFO | train_inner | epoch 005:     76 / 157 loss=9.702, ppl=833.13, wps=28065.1, ups=1.12, wpb=25097.7, bsz=1058.7, num_updates=700, lr=8.75e-05, gnorm=1.109, loss_scale=8, train_wall=37, gb_free=11.9, wall=456
2022-03-23 11:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:37 | INFO | fairseq.tasks.translation | example hypothesis: and they can can be a lot of the world.
2022-03-23 11:41:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example hypothesis: and he's a lot of the world, he can can be a lot.
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:41:46 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of a lot of a lot of a lot of a lot of the world, and i can can can can can can can be a lot of the
2022-03-23 11:41:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was, he was he was he was he was he was, he was, he was he was he was, he was he was he was he was a
2022-03-23 11:41:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example hypothesis: and so what we have a lot of what we have a lot of what we have a lot of what we have a lot, and we have a lot, and we have a lot of a lot, and what we're going to do we
2022-03-23 11:41:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example hypothesis: and we have a lot of the world, and we have to do that we have to do, and we have, we have to do, we have to do, and we have to do, or or or the world, and we have to do, or the world, and we're
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example hypothesis: but if you're a lot of the world, you're, but you're a lot of the world, but they're a lot of the world, but they're a lot of the world, but they're, but they're not, but they're a lot of the world, but they're not, but they're a lot of the world,
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:15 | INFO | fairseq.tasks.translation | example hypothesis: and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world of the world of the world of the world, and we can see the world, and we can see the world, and we can see the world of the world of the world, and we can see the world, and we can see the world of the world, and we can see the world, and the
2022-03-23 11:42:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:22 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "," "" "" "" "" "" we're, "," "" "" "" "" "we're," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we're," "" "we're, and we're," "" ", and we're," "," "," "" "" "," "," "," "," "," "" "," "," "" "" "" "" "", "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "the
2022-03-23 11:42:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:25 | INFO | fairseq.tasks.translation | example hypothesis: so, we have a, and we have a lot of the world of the, and we have the, and that we're, and we have a, and we have to see the world of the world of the, and the world of the world of the, and the world of the world of the world of the world of the world of the world of the world of the, and the, and that we're, and we have to, and the, and the world of the, and the world of the, and the world of the, and the, and the, and the, and the, and the, and the, and the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:42:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:25 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.53 | ppl 1478.72 | bleu 1.38 | wps 3417 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.38
2022-03-23 11:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.38) (writing took 1.8303477640729398 seconds)
2022-03-23 11:42:26 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:42:26 | INFO | train | epoch 005 | loss 9.656 | ppl 806.86 | wps 34915.7 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.04 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 540
KL Stats: Epoch 5 Divergences: Uniform: 1.793591667377626 Unigram: 0.3022320013872219
2022-03-23 11:42:27 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:34 | INFO | train_inner | epoch 006:     19 / 157 loss=9.668, ppl=813.7, wps=27258.4, ups=1.09, wpb=25039.8, bsz=950.1, num_updates=800, lr=0.0001, gnorm=0.939, loss_scale=8, train_wall=37, gb_free=12, wall=548
2022-03-23 11:43:12 | INFO | train_inner | epoch 006:    119 / 157 loss=9.497, ppl=722.49, wps=67205.7, ups=2.67, wpb=25126.8, bsz=945, num_updates=900, lr=0.0001125, gnorm=1.022, loss_scale=8, train_wall=37, gb_free=11.5, wall=586
2022-03-23 11:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:30 | INFO | fairseq.tasks.translation | example hypothesis: they can't have this.
2022-03-23 11:43:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example hypothesis: and he can be a lot of the.
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:43:37 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of this.
2022-03-23 11:43:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example hypothesis: he was, he was a, he was he was he was, and he was, he was, he was a.
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:43:45 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, and what we're going to do, and we're going to do, and what we're going to do?
2022-03-23 11:43:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:43:49 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do that we're going to do, or, or or or, or, or we're going to do, or, or or, or, or, or we're going to do.
2022-03-23 11:43:49 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:43:55 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be, but it's, but it's not, but it's, but it's not, but it's not, but they are, but they're not not, but they're going to be, but they're going to be, but they're going to be, but they're going to be.
2022-03-23 11:43:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:00 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to see the world, and we're going to get the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world.
2022-03-23 11:44:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ", and we we,", ","
2022-03-23 11:44:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:09 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's a, and we have to be, and we have to be a, and we have a, and we're going to be a, and that we're going to be, and that we're going to be a, and it's a, and that we're going to be a, and it's a lot of the world, and it's going to be a, and it's a lot of the.
2022-03-23 11:44:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:09 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.317 | ppl 1275.9 | bleu 2.32 | wps 4167.9 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 2.32
2022-03-23 11:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 6 @ 938 updates, score 2.32) (writing took 1.8502325310837477 seconds)
2022-03-23 11:44:11 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:44:11 | INFO | train | epoch 006 | loss 9.465 | ppl 706.79 | wps 37865.4 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.984 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 645
KL Stats: Epoch 6 Divergences: Uniform: 1.912550691621573 Unigram: 0.37985090705553776
2022-03-23 11:44:11 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:35 | INFO | train_inner | epoch 007:     62 / 157 loss=9.425, ppl=687.26, wps=30031.4, ups=1.2, wpb=24967.7, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.907, loss_scale=8, train_wall=37, gb_free=12.4, wall=669
2022-03-23 11:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:14 | INFO | fairseq.tasks.translation | example hypothesis: this is not no.
2022-03-23 11:45:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:45:18 | INFO | fairseq.tasks.translation | example hypothesis: this is a year.
2022-03-23 11:45:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:45:22 | INFO | fairseq.tasks.translation | example hypothesis: now, i can see this.
2022-03-23 11:45:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example hypothesis: he was, he was, because he was, he was, he was, he didn't never never never never never never never never never never never never never never never never never never never never never never had
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of what is what we're going to do, what we're going to do is what we're going to do is a lot of what we're going to do?
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to talk about this, or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're not some of the, they're going to see, but they're going to the, but they're going to, but they're going to, but they're going to the, but they're going to the, but they're going to the, but they're going to the, but they're not not not not not not
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see, if we can see, we can see the world, we can see the world, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world.
2022-03-23 11:45:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:51 | INFO | fairseq.tasks.translation | example hypothesis: "if we said," "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:45:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:53 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to see the world, we're going to see the world, it, the world, and we're going to see the world, which is, it's going to see the world, which is the world, which is the world, which is a, it's a, which is that we're going to see the world, which is that we're going to see the world, which is that we're going to see the world, which is that we're going to get a, and we're going to get a, and we're going to get a, and we're going to see the world, which is that we're going to see the world, which is that we're going to get a, and we're going to see the world, which we're going to see the world, which is that we're going to see the world, which is that we're going to see the world, which is that we're going to see the world, which is that we're going to see the world, the
2022-03-23 11:45:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:53 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.194 | ppl 1171.03 | bleu 2.65 | wps 4141.7 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.65
2022-03-23 11:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.65) (writing took 1.890339960809797 seconds)
2022-03-23 11:45:55 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:45:55 | INFO | train | epoch 007 | loss 9.295 | ppl 628.13 | wps 37768.4 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.919 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 749
KL Stats: Epoch 7 Divergences: Uniform: 1.9976826011349291 Unigram: 0.4370902250585254
2022-03-23 11:45:56 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:58 | INFO | train_inner | epoch 008:      5 / 157 loss=9.171, ppl=576.45, wps=30594.2, ups=1.2, wpb=25396.2, bsz=1052.4, num_updates=1100, lr=0.0001375, gnorm=0.898, loss_scale=8, train_wall=37, gb_free=12.1, wall=752
2022-03-23 11:46:36 | INFO | train_inner | epoch 008:    105 / 157 loss=9.154, ppl=569.83, wps=66872.1, ups=2.65, wpb=25204.4, bsz=1027.4, num_updates=1200, lr=0.00015, gnorm=0.789, loss_scale=8, train_wall=37, gb_free=12.3, wall=789
2022-03-23 11:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:58 | INFO | fairseq.tasks.translation | example hypothesis: these these are.
2022-03-23 11:46:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example hypothesis: it's a year.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example hypothesis: this is that i can make a lot of course.
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:47:09 | INFO | fairseq.tasks.translation | example hypothesis: he was his father, because he was his father.
2022-03-23 11:47:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example hypothesis: one of my life, what we're going to do with a lot of what we're going to do?
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to talk about our time, or or or or or or or or, or we're going to talk about the time.
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example hypothesis: some of course, if you're going to see, but it's a lot of the.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the.
2022-03-23 11:47:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:30 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the one of, "it's a," if you're going to say, "if we're going to say," if we're going to say, "if we're going to say," if we're going to say, "if we're going to say," it's going to say, "it's going to be a lot of a lot of a lot of," it's going to say, "it's going to say, and we're going to say," if we're going to say, "if we're going to say," if we're going to say, "it's going to say," if we're going to be going to say, and we're going to say, and we're going to say, "it's going to say," it's going to say, "if we're going to say,"
2022-03-23 11:47:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:32 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course, if we're going to see that we have a lot of the.
2022-03-23 11:47:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.028 | ppl 1044.32 | bleu 3.5 | wps 4823.1 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.5
2022-03-23 11:47:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:47:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:47:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.5) (writing took 1.8592893038876355 seconds)
2022-03-23 11:47:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:47:34 | INFO | train | epoch 008 | loss 9.14 | ppl 564.04 | wps 39890.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.825 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 848
KL Stats: Epoch 8 Divergences: Uniform: 2.0617851628029267 Unigram: 0.48631518740937246
2022-03-23 11:47:35 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:53 | INFO | train_inner | epoch 009:     48 / 157 loss=9.08, ppl=541.03, wps=32287, ups=1.29, wpb=24959.6, bsz=1001.8, num_updates=1300, lr=0.0001625, gnorm=0.88, loss_scale=8, train_wall=36, gb_free=11.8, wall=867
2022-03-23 11:48:31 | INFO | train_inner | epoch 009:    148 / 157 loss=8.959, ppl=497.71, wps=66898.8, ups=2.64, wpb=25342.7, bsz=1020.9, num_updates=1400, lr=0.000175, gnorm=0.775, loss_scale=8, train_wall=38, gb_free=11.8, wall=905
2022-03-23 11:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example hypothesis: this can't be able.
2022-03-23 11:48:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example hypothesis: and the last year, he can be about 20 years.
2022-03-23 11:48:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:48:45 | INFO | fairseq.tasks.translation | example hypothesis: so, this is a lot of course of course, i can be a lot of course, and i can make a lot of course.
2022-03-23 11:48:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:48:50 | INFO | fairseq.tasks.translation | example hypothesis: he was his father, because he was his father, because she was his father, because she was his father was his mother, because she was his father was his father was his mother, she was his mother
2022-03-23 11:48:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:48:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother, and my mother is, and we're going to say, and what we're going to do?
2022-03-23 11:48:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:48:59 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to talk about our time about our time, or how to do we're going to do it, or or or the other things, or, or or or or the other other other other other other or or or or the other other other other other other other other or
2022-03-23 11:48:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:49:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some of.
2022-03-23 11:49:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to change the information of this.
2022-03-23 11:49:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:13 | INFO | fairseq.tasks.translation | example hypothesis: one of the question, and it's a lot of the, "and there's a few years," and it's a little bit of, "if we're going to say," you're going to say, "if we're going to say," you're going to say, "you're going to say," if we're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "
2022-03-23 11:49:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's not a lot of course, and the mother, and if you're going to get a lot of the, if you're going to see that we're going to see that we're going to see that we're going to see that we're going to get a lot of the.
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.855 | ppl 926.05 | bleu 4.85 | wps 4313.1 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.85
2022-03-23 11:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:49:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.85) (writing took 1.911017854930833 seconds)
2022-03-23 11:49:18 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:49:18 | INFO | train | epoch 009 | loss 8.991 | ppl 508.84 | wps 38267.1 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.813 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 951
KL Stats: Epoch 9 Divergences: Uniform: 2.116188723466323 Unigram: 0.5256518121639455
2022-03-23 11:49:18 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:52 | INFO | train_inner | epoch 010:     91 / 157 loss=8.782, ppl=440.06, wps=31148.4, ups=1.22, wpb=25471.1, bsz=1099.8, num_updates=1500, lr=0.0001875, gnorm=0.909, loss_scale=8, train_wall=37, gb_free=11.8, wall=986
2022-03-23 11:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example hypothesis: these can't use that.
2022-03-23 11:50:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example hypothesis: in year, he can be about about about 8880,000.
2022-03-23 11:50:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:50:28 | INFO | fairseq.tasks.translation | example hypothesis: this is what i can do is a lot of course.
2022-03-23 11:50:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:50:32 | INFO | fairseq.tasks.translation | example hypothesis: he never never never never never never never never his father, because she was his mother.
2022-03-23 11:50:32 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a child, and we did a child, so what we did?
2022-03-23 11:50:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:50:39 | INFO | fairseq.tasks.translation | example hypothesis: so, we're talking about our things like things, or not about things, or other things.
2022-03-23 11:50:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of this information, we can see this.
2022-03-23 11:50:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:51 | INFO | fairseq.tasks.translation | example hypothesis: dh: one of the interesting interesting interesting thing, and it's interesting for me, "you know," you know, "you know," you know, "if you've got to say," you've got to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "for this is," for this is that, "you know," you know, "you know," you know, "you know," you know, ","
2022-03-23 11:50:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example hypothesis: now, it's still still always always always always always a mother, and when we're going to see a lot of the.
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:52 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.663 | ppl 810.91 | bleu 6.28 | wps 5239.5 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 6.28
2022-03-23 11:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 11:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 10 @ 1566 updates, score 6.28) (writing took 1.9165140890982002 seconds)
2022-03-23 11:50:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:50:54 | INFO | train | epoch 010 | loss 8.839 | ppl 458 | wps 40845.2 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 0.849 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 1048
KL Stats: Epoch 10 Divergences: Uniform: 2.1669548153574665 Unigram: 0.5655350606328332
2022-03-23 11:50:55 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:08 | INFO | train_inner | epoch 011:     34 / 157 loss=8.842, ppl=459.02, wps=33315.1, ups=1.33, wpb=25082.5, bsz=937.7, num_updates=1600, lr=0.0002, gnorm=0.75, loss_scale=8, train_wall=37, gb_free=12.4, wall=1062
2022-03-23 11:51:45 | INFO | train_inner | epoch 011:    134 / 157 loss=8.629, ppl=396.02, wps=66855.1, ups=2.67, wpb=25054.1, bsz=1010.5, num_updates=1700, lr=0.0002125, gnorm=0.776, loss_scale=8, train_wall=37, gb_free=12.3, wall=1099
2022-03-23 11:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:58 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 11:51:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:52:02 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about about about 88,000 miles.
2022-03-23 11:52:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example hypothesis: this is, of course, of course, of course, i can be able to get a lot of course.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father because his father had his father, because she had his mother, she was his mother.
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:52:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i've got a lot of aids, and a child, and so we asked us to do what we do?
2022-03-23 11:52:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:52:19 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time about our time, how to talk about things, and how to talk about the time or not talk about the world or each other.
2022-03-23 11:52:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:52:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are some of the, but in the, but it doesn't like the. but if you don't need to get the energy, and if you need the energy.
2022-03-23 11:52:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information, the information that we can start from this.
2022-03-23 11:52:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons, it's interesting interesting, and it's interesting for me for me for me, and i'm going to ask you, "if you're going to say," if you're going to say, "if you're going to say," well, "if you're going to say," the best. "
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still always always always always always always always the mother, and the
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:32 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.458 | ppl 703.26 | bleu 10.06 | wps 4736.5 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 10.06
2022-03-23 11:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 11:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 11 @ 1723 updates, score 10.06) (writing took 1.893972564022988 seconds)
2022-03-23 11:52:34 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:52:34 | INFO | train | epoch 011 | loss 8.634 | ppl 397.4 | wps 39429.1 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 0.739 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1148
KL Stats: Epoch 11 Divergences: Uniform: 2.225824500761576 Unigram: 0.6049754305499699
2022-03-23 11:52:35 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:04 | INFO | train_inner | epoch 012:     77 / 157 loss=8.376, ppl=332.23, wps=32426.3, ups=1.26, wpb=25654, bsz=1101.4, num_updates=1800, lr=0.000225, gnorm=0.724, loss_scale=8, train_wall=37, gb_free=12.1, wall=1178
2022-03-23 11:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:38 | INFO | fairseq.tasks.translation | example hypothesis: that's not going to use this chemical chemical.
2022-03-23 11:53:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:53:42 | INFO | fairseq.tasks.translation | example hypothesis: in year, he can be about 880s in the restaurant.
2022-03-23 11:53:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:53:46 | INFO | fairseq.tasks.translation | example hypothesis: and this pattern can also be able to be able to be a sense of course.
2022-03-23 11:53:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:53:50 | INFO | fairseq.tasks.translation | example hypothesis: he had never seen his father, because his father had his mother, she had his mother with him.
2022-03-23 11:53:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a lot of aids, and a child has a child, so we asked us to do what we do?
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things, how to talk about time, and not talk about poverty or other, or each other, or each other.
2022-03-23 11:53:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the, but in the. but you don't know, if you don't need to get their energy, and if you don't need the energy, you need to need the energy, and you need to need the energy.
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can start up with a
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:12 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons, and it's interesting to be interesting for me to be here for me, "yes, yes, if you said," yes, "well," if you say, "well," if you say, "if you say," if you say, "the best."
2022-03-23 11:54:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, it's still still the mother, and the invention of the work that we had a great work on our work, and if we had to use it, we had to use it, we had to use that it's a
2022-03-23 11:54:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:14 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.21 | ppl 592.42 | bleu 12.24 | wps 4543.9 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 12.24
2022-03-23 11:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 11:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 12 @ 1880 updates, score 12.24) (writing took 1.8304790270049125 seconds)
2022-03-23 11:54:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 11:54:16 | INFO | train | epoch 012 | loss 8.438 | ppl 346.93 | wps 38845 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 0.751 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1250
KL Stats: Epoch 12 Divergences: Uniform: 2.282152928885539 Unigram: 0.6327209557314181
2022-03-23 11:54:16 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 11:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:24 | INFO | train_inner | epoch 013:     20 / 157 loss=8.473, ppl=355.25, wps=30882, ups=1.26, wpb=24602.9, bsz=954.1, num_updates=1900, lr=0.0002375, gnorm=0.758, loss_scale=8, train_wall=37, gb_free=11.8, wall=1258
2022-03-23 11:55:02 | INFO | train_inner | epoch 013:    120 / 157 loss=8.286, ppl=312.1, wps=66348.6, ups=2.65, wpb=25062.1, bsz=1044.2, num_updates=2000, lr=0.00025, gnorm=0.782, loss_scale=8, train_wall=37, gb_free=12.7, wall=1296
2022-03-23 11:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:19 | INFO | fairseq.tasks.translation | example hypothesis: that's no chemical chemical chemical chemical chemical use.
2022-03-23 11:55:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:55:23 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 restaurant.
2022-03-23 11:55:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example hypothesis: and these magnets, i can also be able to make a lot of course.
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:55:30 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned with his father.
2022-03-23 11:55:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example hypothesis: so one of my couirs is died and aids, so we asked us to do a child, so we asked us what do?
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:55:37 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things.
2022-03-23 11:55:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:55:41 | INFO | fairseq.tasks.translation | example hypothesis: first of them are some of the field, but they're going to move, but if they don't like it, they don't need their energy, and they don't need their energy.
2022-03-23 11:55:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can start from this reflection.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:48 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons, and it's interesting for me. "
2022-03-23 11:55:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, the mother is still the invention of the invention, and we have a big work on our airplane, and we had to use the airplane.
2022-03-23 11:55:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:49 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.118 | ppl 555.8 | bleu 9.09 | wps 5537.1 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 12.24
2022-03-23 11:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 11:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 11:55:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 11:55:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 13 @ 2037 updates, score 9.09) (writing took 0.7896412319969386 seconds)
2022-03-23 11:55:50 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 11:55:50 | INFO | train | epoch 013 | loss 8.257 | ppl 305.82 | wps 42087.9 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 0.769 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 1344
KL Stats: Epoch 13 Divergences: Uniform: 2.3276235154969176 Unigram: 0.6585014940074227
2022-03-23 11:55:50 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 11:55:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:14 | INFO | train_inner | epoch 014:     63 / 157 loss=8.09, ppl=272.45, wps=35301.6, ups=1.38, wpb=25541.3, bsz=1062.3, num_updates=2100, lr=0.0002625, gnorm=0.747, loss_scale=8, train_wall=37, gb_free=12.3, wall=1368
2022-03-23 11:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:53 | INFO | fairseq.tasks.translation | example hypothesis: this, you can't use these chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical.
2022-03-23 11:56:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:56:58 | INFO | fairseq.tasks.translation | example hypothesis: the year, he can be about 8,000 restaurant in the restaurant.
2022-03-23 11:56:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example hypothesis: and this mass of course, i can also, of course, of course, i can also have a popular bible bible.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:57:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because he had never learned his mother, because she had his mother with him.
2022-03-23 11:57:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:57:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died of aids and aids, so we asked us a child, so what do we do?
2022-03-23 11:57:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:57:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about how we're talking about, and we don't talk about, or in the end of poverty, or each other of poverty.
2022-03-23 11:57:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:57:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic, but in the field, when they're going to move, they don't need to move their energy, and so if they need to move, and so they need to, and they need so they need to move out of the, and they need some of the.
2022-03-23 11:57:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the reflection of this reflection, we can begin to start with a traditional view of traditional structure, and the structure of the structure of the structure, and all of the structure of the structure of the structure, and so that all of the information, and so if we're all the information, the information, the information, the information, the information that all the information, the information, the information, the information
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:31 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and interesting to be interesting for me, "in tedra," yes, when we're going to say, "if we're going to say," the best revolution, "and then we're going to tell you," well, "well," well, "if we're going to," well, "well," and then we've got the most interesting for you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "the most interesting," well, "well," well, "the most interesting," the most interesting, "the most interesting of you're going to," the most interesting, "the reasons," the most interesting, "the
2022-03-23 11:57:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:33 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, it's still the mother of the invention, and the invention of the invention that we had to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that it in a, or a, or the, or the, or that we had to be able to be able to see that we had to be able to be able to be able to be able to be able to be able to use of the
2022-03-23 11:57:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.009 | ppl 515.22 | bleu 12.59 | wps 4129.6 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 12.59
2022-03-23 11:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 11:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 14 @ 2194 updates, score 12.59) (writing took 1.786117171868682 seconds)
2022-03-23 11:57:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 11:57:35 | INFO | train | epoch 014 | loss 8.101 | ppl 274.54 | wps 37630.7 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 0.782 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1449
KL Stats: Epoch 14 Divergences: Uniform: 2.3923795241258627 Unigram: 0.684422344089326
2022-03-23 11:57:35 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 11:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:38 | INFO | train_inner | epoch 015:      6 / 157 loss=8.135, ppl=281.18, wps=29727.6, ups=1.2, wpb=24782.3, bsz=960.7, num_updates=2200, lr=0.000275, gnorm=0.789, loss_scale=8, train_wall=37, gb_free=11.9, wall=1451
2022-03-23 11:58:15 | INFO | train_inner | epoch 015:    106 / 157 loss=7.953, ppl=247.83, wps=67005.9, ups=2.67, wpb=25078.1, bsz=1030.6, num_updates=2300, lr=0.0002875, gnorm=0.711, loss_scale=8, train_wall=37, gb_free=12.8, wall=1489
2022-03-23 11:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:38 | INFO | fairseq.tasks.translation | example hypothesis: it can't use this chemical chemical rays.
2022-03-23 11:58:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:58:47 | INFO | fairseq.tasks.translation | example hypothesis: and this magnetic magnets, i can also be able to make a popular bible bible.
2022-03-23 11:58:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:58:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his father, because his mother had been pregnant with him.
2022-03-23 11:58:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:58:55 | INFO | fairseq.tasks.translation | example hypothesis: so one of my couples is died in aids and died, so we said, what do we do with her child?
2022-03-23 11:58:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to spend things about things like equally, and not talking about, or the nuclear weapons of poverty, or each other or each other.
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magnetic magnetic magnetic lines, but they don't move it, but if they don't need their movements, they don't need their movements, they need their movements, and they need their movements.
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can begin to start with a traditional face of traditional face, which is going to begin to start, and the
2022-03-23 11:59:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting and measure for me, "for tedra women, is that the best time -- yes, yes," yes, it was the best time. "
2022-03-23 11:59:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of the invention, and the invention of a great design that we had to solve the plane in our plane, and that we had to solve a unique result that we had to solve the unique problems that it was connected to a unique
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:14 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.769 | ppl 436.26 | bleu 16.67 | wps 4560.5 | wpb 17862.2 | bsz 728.3 | num_updates 2351 | best_bleu 16.67
2022-03-23 11:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2351 updates
2022-03-23 11:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 15 @ 2351 updates, score 16.67) (writing took 1.7932020749431103 seconds)
2022-03-23 11:59:16 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 11:59:16 | INFO | train | epoch 015 | loss 7.931 | ppl 244.1 | wps 39079.1 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2351 | lr 0.000293875 | gnorm 0.69 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1550
KL Stats: Epoch 15 Divergences: Uniform: 2.452627480411652 Unigram: 0.7043499118039278
2022-03-23 11:59:16 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 11:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:35 | INFO | train_inner | epoch 016:     49 / 157 loss=7.921, ppl=242.34, wps=31585.8, ups=1.25, wpb=25296.3, bsz=959.5, num_updates=2400, lr=0.0003, gnorm=0.65, loss_scale=8, train_wall=37, gb_free=11.8, wall=1569
2022-03-23 12:00:12 | INFO | train_inner | epoch 016:    149 / 157 loss=7.705, ppl=208.66, wps=67500.9, ups=2.7, wpb=24997.9, bsz=1067, num_updates=2500, lr=0.0003125, gnorm=0.668, loss_scale=8, train_wall=37, gb_free=22.3, wall=1606
2022-03-23 12:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:19 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rains.
2022-03-23 12:00:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:00:23 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:00:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:00:27 | INFO | fairseq.tasks.translation | example hypothesis: these magnets, i can also, of course, to form a popular bible.
2022-03-23 12:00:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:00:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had his mother, when she was pregnant with him.
2022-03-23 12:00:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a, so we asked us good, what do we do with them?
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bbbl of magnetic lines in the field, but the susususues don't move their movements, if they don't need their movements, their movements and so forth.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face of traditional face, the big face of the face of the face of the face, the face of the face of the face, and the information, the whole structure of the information, the whole structure, the whole structure of this structure, and the whole structure, the whole structure of these reflection is all of this reflection.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:52 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measure for me here to be tedwomen, "yes, yes, yes, that it was the best, when someone said," the best revolution begins to you know, you know, you know, and then we're going to support you know, "the reasons, the reasons that the."
2022-03-23 12:00:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:54 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design that we're working on our airplane on our airplane, and we had to solve a unique result that we had to solve the unique problems that we had to solve it with a
2022-03-23 12:00:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:54 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.637 | ppl 398.18 | bleu 18.48 | wps 4644.7 | wpb 17862.2 | bsz 728.3 | num_updates 2508 | best_bleu 18.48
2022-03-23 12:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2508 updates
2022-03-23 12:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:00:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 16 @ 2508 updates, score 18.48) (writing took 1.7914363089948893 seconds)
2022-03-23 12:00:56 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:00:56 | INFO | train | epoch 016 | loss 7.755 | ppl 215.99 | wps 39498.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2508 | lr 0.0003135 | gnorm 0.66 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 1650
KL Stats: Epoch 16 Divergences: Uniform: 2.5169655312857455 Unigram: 0.7285980698014679
2022-03-23 12:00:56 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:31 | INFO | train_inner | epoch 017:     92 / 157 loss=7.543, ppl=186.52, wps=32690.4, ups=1.26, wpb=25929.2, bsz=1019.8, num_updates=2600, lr=0.000325, gnorm=0.606, loss_scale=8, train_wall=37, gb_free=12, wall=1685
2022-03-23 12:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:01:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:02:03 | INFO | fairseq.tasks.translation | example hypothesis: overwheled year, it can be about 8,000 places in the restaurant.
2022-03-23 12:02:03 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:02:07 | INFO | fairseq.tasks.translation | example hypothesis: these magnets, i can also, of course, to make a popular bible.
2022-03-23 12:02:07 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:02:11 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his father, because his mother had his mother left with him when she was pregnant with him.
2022-03-23 12:02:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a wavelal child, so we asked us good what do we do with her cousin?
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:02:20 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to spend things about things like gender, and not talking about gender or nuclear weapons, or every other topic of poverty.
2022-03-23 12:02:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:02:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic lines in the field of magnetic lines, but the susususususus may not move when they need their movements, and the susues need.
2022-03-23 12:02:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can begin to start with a traditional face of the face of the face of the face, and the information is the information through the information, and the information that all the structure is a whole structure.
2022-03-23 12:02:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:33 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measure it, for me to be here for tedwomen, "that's the best thing that the best one said," and then the men said, "if we're going to give you men in a table," and then we're going to support them a table for a table, "and then we're going to support the women," and then we have a time to support the truth for you. "
2022-03-23 12:02:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:35 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need still the mother of the invention, and a great part of design work on our plane is a unique result that we had to solve the unique problems that we had to solve everything in the ground -- it's all the way that it would be connected to a continued to a continued to a continued to the soil, and that it's a continued to a continued to a continued to us to a continued to a continuous, or a continued to a continuation of the restore, or a restore, or a, to a restore of the restore, and that if you can see that if you're going to see that if you're going to see that it's either, you can see that if you're going to see that it's a.
2022-03-23 12:02:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:35 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.546 | ppl 373.68 | bleu 19.7 | wps 4531.1 | wpb 17862.2 | bsz 728.3 | num_updates 2665 | best_bleu 19.7
2022-03-23 12:02:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2665 updates
2022-03-23 12:02:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 17 @ 2665 updates, score 19.7) (writing took 1.791381980990991 seconds)
2022-03-23 12:02:37 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:02:37 | INFO | train | epoch 017 | loss 7.594 | ppl 193.25 | wps 39166.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2665 | lr 0.000333125 | gnorm 0.61 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 1751
KL Stats: Epoch 17 Divergences: Uniform: 2.5651126642126365 Unigram: 0.7471809523344579
2022-03-23 12:02:37 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:02:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:50 | INFO | train_inner | epoch 018:     35 / 157 loss=7.584, ppl=191.87, wps=30960.5, ups=1.27, wpb=24435.8, bsz=1055.4, num_updates=2700, lr=0.0003375, gnorm=0.646, loss_scale=8, train_wall=36, gb_free=13, wall=1764
2022-03-23 12:03:28 | INFO | train_inner | epoch 018:    135 / 157 loss=7.485, ppl=179.1, wps=67118.8, ups=2.64, wpb=25460.3, bsz=996.6, num_updates=2800, lr=0.00035, gnorm=0.596, loss_scale=8, train_wall=38, gb_free=12.1, wall=1802
2022-03-23 12:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:03:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example hypothesis: in the restaurant, it can be about 8,000 places in the restaurant.
2022-03-23 12:03:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example hypothesis: and this magnets, i can also turn out to form a popular bike.
2022-03-23 12:03:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother, when she was pregnant.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:03:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and has a wavelal child, so we asked us good, what do we do with her?
2022-03-23 12:03:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talking about gender times, or nuclear weapons, or any other topic issue.
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic lines start in the inside of the inside, but the susususus may not move, if they need their energy movements, they need their energy movements, and they need, and they need the susucks.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that can start with a traditional face, and the real facial shape of the facial facial shape, and it's a whole structure, and it's a whole structure, and it's a whole structure.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measure, for me, for me, for me, for tedwomen, is that -- yes, in the best
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, the mother is still still the invention of invention, and a big part of design work that we're working on our plane at the plane, and unfortunately, we had to solve the unique problems that were connected to the ground -- it's all the variation of a refrigeration system, and it allows us to use it to go to a
2022-03-23 12:04:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:17 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.435 | ppl 346 | bleu 21.19 | wps 4482 | wpb 17862.2 | bsz 728.3 | num_updates 2822 | best_bleu 21.19
2022-03-23 12:04:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2822 updates
2022-03-23 12:04:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:04:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:04:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 18 @ 2822 updates, score 21.19) (writing took 1.8043939638882875 seconds)
2022-03-23 12:04:18 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:04:18 | INFO | train | epoch 018 | loss 7.492 | ppl 180.08 | wps 38837.4 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2822 | lr 0.00035275 | gnorm 0.642 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 1852
KL Stats: Epoch 18 Divergences: Uniform: 2.6089685132047595 Unigram: 0.7598333058325395
2022-03-23 12:04:19 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:48 | INFO | train_inner | epoch 019:     78 / 157 loss=7.527, ppl=184.48, wps=30632.1, ups=1.25, wpb=24457.1, bsz=980.2, num_updates=2900, lr=0.0003625, gnorm=0.631, loss_scale=8, train_wall=37, gb_free=12.2, wall=1882
2022-03-23 12:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:21 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:05:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:05:25 | INFO | fairseq.tasks.translation | example hypothesis: overwhelmed year, it can be about 8,000 places in the restaurant.
2022-03-23 12:05:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:05:29 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expandate a popular shapes.
2022-03-23 12:05:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and has a wavelal child, so we asked us what do we do with her?
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:05:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not about nuclear weapons.
2022-03-23 12:05:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloose of magnetic field, but the superconductor doesn't like it, if you need your movements, and the sususususususususues.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial facial facial facial facial, which can begin with the real face of the face of the face and reactor.
2022-03-23 12:05:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:52 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... "yes, you know, at the best time."
2022-03-23 12:05:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at the plane, was a result that we had to solve the problems that we had to solve.
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:54 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.37 | ppl 330.87 | bleu 20.59 | wps 4951.6 | wpb 17862.2 | bsz 728.3 | num_updates 2979 | best_bleu 21.19
2022-03-23 12:05:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2979 updates
2022-03-23 12:05:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 19 @ 2979 updates, score 20.59) (writing took 0.7846485509071499 seconds)
2022-03-23 12:05:55 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:05:55 | INFO | train | epoch 019 | loss 7.378 | ppl 166.31 | wps 40773.1 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 2979 | lr 0.000372375 | gnorm 0.578 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 1949
KL Stats: Epoch 19 Divergences: Uniform: 2.6448289373470644 Unigram: 0.7738580495593961
2022-03-23 12:05:56 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:04 | INFO | train_inner | epoch 020:     21 / 157 loss=7.348, ppl=162.93, wps=33466.9, ups=1.32, wpb=25270.7, bsz=1002.3, num_updates=3000, lr=0.000375, gnorm=0.544, loss_scale=8, train_wall=37, gb_free=12.7, wall=1958
2022-03-23 12:06:42 | INFO | train_inner | epoch 020:    121 / 157 loss=7.114, ppl=138.57, wps=68571.3, ups=2.63, wpb=26095.5, bsz=1089.3, num_updates=3100, lr=0.0003875, gnorm=0.501, loss_scale=8, train_wall=38, gb_free=12.5, wall=1996
2022-03-23 12:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:58 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical rockets.
2022-03-23 12:06:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:07:02 | INFO | fairseq.tasks.translation | example hypothesis: transmits about 8,000 places in the restaurant.
2022-03-23 12:07:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:07:06 | INFO | fairseq.tasks.translation | example hypothesis: i can also expanding this, of course, to form a popular same thing.
2022-03-23 12:07:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left when she was pregnant with him.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:07:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died in aids and has a wash child, so we said, well what do we do with your couples?
2022-03-23 12:07:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:07:18 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not about the spread or the spread of nuclear weapons or poverty.
2022-03-23 12:07:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:07:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field in the inner, but the superconductor doesn't like when they move their movements, and the superconductor.
2022-03-23 12:07:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information to reflect the reflection of this reflection, we can start with a traditional face that can start with a traditional facial face, and the real shape of the face and repeat the real form of the information, and the information through this mirror reflection.
2022-03-23 12:07:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that... "yes, when it was the best."
2022-03-23 12:07:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a big part of the design work that we're on the plane on our plane, was a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- and a big part of the invention of the invention of design work that allows us to be able to use, and a.
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:35 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.296 | ppl 314.33 | bleu 23.27 | wps 4506.2 | wpb 17862.2 | bsz 728.3 | num_updates 3136 | best_bleu 23.27
2022-03-23 12:07:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3136 updates
2022-03-23 12:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 20 @ 3136 updates, score 23.27) (writing took 1.8016291360836476 seconds)
2022-03-23 12:07:36 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:07:36 | INFO | train | epoch 020 | loss 7.259 | ppl 153.12 | wps 39020.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3136 | lr 0.000392 | gnorm 0.536 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2050
KL Stats: Epoch 20 Divergences: Uniform: 2.670189790150073 Unigram: 0.7829521041427214
2022-03-23 12:07:37 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:01 | INFO | train_inner | epoch 021:     64 / 157 loss=7.339, ppl=161.9, wps=30722.2, ups=1.26, wpb=24439.2, bsz=965.7, num_updates=3200, lr=0.0004, gnorm=0.557, loss_scale=8, train_wall=37, gb_free=11.2, wall=2075
2022-03-23 12:08:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:40 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:08:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:08:43 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:08:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example hypothesis: and these rotates, i can also expand to form a popular bike.
2022-03-23 12:08:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:08:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 12:08:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:08:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died of aids, and has a wash child back, so we asked us what do with her?
2022-03-23 12:08:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs are caught by magnetic field lines, but the superconductor doesn't like when they move their movements, their movements need movements, and so the superconductive disorder.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial face, which is the big configuration of the face and the basic shape, and through the information, which is all the ports and fold.
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:11 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's really interesting and measured for me to be here at tedwomen, is that -- yes, when someone said, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [the men] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 12:09:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our plane was a result that we had to resolve the unique problems that were connected to the soil -- everything from a continents and refrigeration and refrigeration system that allows us to use.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:12 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.22 | ppl 298.11 | bleu 24.46 | wps 5015.9 | wpb 17862.2 | bsz 728.3 | num_updates 3293 | best_bleu 24.46
2022-03-23 12:09:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3293 updates
2022-03-23 12:09:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 21 @ 3293 updates, score 24.46) (writing took 1.808103864081204 seconds)
2022-03-23 12:09:14 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:09:14 | INFO | train | epoch 021 | loss 7.163 | ppl 143.35 | wps 40410.1 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3293 | lr 0.000411625 | gnorm 0.5 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 2148
KL Stats: Epoch 21 Divergences: Uniform: 2.6980214279795356 Unigram: 0.7943312660005997
2022-03-23 12:09:15 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:09:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:18 | INFO | train_inner | epoch 022:      7 / 157 loss=7.07, ppl=134.36, wps=33144.5, ups=1.31, wpb=25327, bsz=1053, num_updates=3300, lr=0.0004125, gnorm=0.489, loss_scale=8, train_wall=37, gb_free=11.6, wall=2152
2022-03-23 12:09:55 | INFO | train_inner | epoch 022:    107 / 157 loss=7.099, ppl=137.06, wps=67178, ups=2.66, wpb=25252.1, bsz=1027.1, num_updates=3400, lr=0.000425, gnorm=0.529, loss_scale=8, train_wall=37, gb_free=11.6, wall=2189
2022-03-23 12:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:17 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 12:10:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:10:21 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:10:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:10:25 | INFO | fairseq.tasks.translation | example hypothesis: these rocks magnets i can also expand to form a popular bicycle.
2022-03-23 12:10:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:10:29 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left his mother when she was pregnant with him.
2022-03-23 12:10:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:10:33 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died in aids, and we asked us what do with her?
2022-03-23 12:10:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of magnetic field, but the superconductor doesn't like when they need their energy movements, and so the superconductor disorder.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face of face and the real shape, and the basic shape of the facial facial, and reform it through the one of these ports and fold all the structure.
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen, is that... well, when it was the best, when someone said, "you go to the men," and then we'll support the revolution. "
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on the road, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variation and a refrigeration system that allows us to refrigerate a refrigeration system, or either if you're going to get a.
2022-03-23 12:10:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:49 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.179 | ppl 289.83 | bleu 24.04 | wps 5253.3 | wpb 17862.2 | bsz 728.3 | num_updates 3450 | best_bleu 24.46
2022-03-23 12:10:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3450 updates
2022-03-23 12:10:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 22 @ 3450 updates, score 24.04) (writing took 0.8256142151076347 seconds)
2022-03-23 12:10:50 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:10:50 | INFO | train | epoch 022 | loss 7.097 | ppl 136.89 | wps 41405.3 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 3450 | lr 0.00043125 | gnorm 0.504 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2243
KL Stats: Epoch 22 Divergences: Uniform: 2.7078519246881494 Unigram: 0.7978143888806003
2022-03-23 12:10:50 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:09 | INFO | train_inner | epoch 023:     50 / 157 loss=6.998, ppl=127.85, wps=34153, ups=1.36, wpb=25117.4, bsz=1043.1, num_updates=3500, lr=0.0004375, gnorm=0.463, loss_scale=8, train_wall=37, gb_free=12.5, wall=2263
2022-03-23 12:11:46 | INFO | train_inner | epoch 023:    150 / 157 loss=7.108, ppl=137.94, wps=66271.2, ups=2.67, wpb=24831.7, bsz=997.8, num_updates=3600, lr=0.00045, gnorm=0.482, loss_scale=8, train_wall=37, gb_free=12.9, wall=2300
2022-03-23 12:11:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:11:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:11:57 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:11:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:12:01 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to shape a popular same way.
2022-03-23 12:12:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:12:05 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant with him.
2022-03-23 12:12:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:12:09 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died at aids, and has a waischild back, so we asked us, well, what do we do with her?
2022-03-23 12:12:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:12:13 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about the spread of nuclear weapons or poverty.
2022-03-23 12:12:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:12:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs are caught by magnetic field lines in the inner, but the superconductor doesn't like it when they move, their movements need, and so the superconductor disorders of disorder.
2022-03-23 12:12:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from the reflection of this reflection, we can start with a traditional face, which is the big configuration of the face and the basic shape, and through the reform of information that the whole porter structure and fold all the portion of the structure.
2022-03-23 12:12:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that the high-interesting and measured it, for me here at tedwomen, is that... well, when it was the best summared when someone said, "turn you to the men on a table and say," if the revolution starts to you, "we're going to support you," the truth is that, we've already started with you. "
2022-03-23 12:12:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on the plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually variable variation, and with a refrigeration system that it allows us to refrigerate, with a refrigeration, that we're going to be able to refrightened to be able to refrightened by a, to use it's either, to be able to refrightened by a
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:29 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.029 | ppl 261.13 | bleu 27.6 | wps 4584.2 | wpb 17862.2 | bsz 728.3 | num_updates 3607 | best_bleu 27.6
2022-03-23 12:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3607 updates
2022-03-23 12:12:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 23 @ 3607 updates, score 27.6) (writing took 1.793556333053857 seconds)
2022-03-23 12:12:31 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:12:31 | INFO | train | epoch 023 | loss 7.015 | ppl 129.38 | wps 39105.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3607 | lr 0.000450875 | gnorm 0.468 | loss_scale 8 | train_wall 58 | gb_free 12.4 | wall 2344
KL Stats: Epoch 23 Divergences: Uniform: 2.724752649413328 Unigram: 0.8005772752349825
2022-03-23 12:12:31 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:06 | INFO | train_inner | epoch 024:     93 / 157 loss=6.931, ppl=122.04, wps=31631.5, ups=1.26, wpb=25174.1, bsz=1053.2, num_updates=3700, lr=0.0004625, gnorm=0.457, loss_scale=8, train_wall=37, gb_free=12.1, wall=2380
2022-03-23 12:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example hypothesis: they can't use chemical rockets.
2022-03-23 12:13:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:13:37 | INFO | fairseq.tasks.translation | example hypothesis: he can translate about 8,000 places in the restaurant.
2022-03-23 12:13:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:13:41 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets. of course, to shape a popular equilibrium.
2022-03-23 12:13:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:13:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:13:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:13:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and we asked us, well, what do we do with her?
2022-03-23 12:13:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:13:53 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty.
2022-03-23 12:13:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:13:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught in the inner lines, but the superconductor doesn't like it when they're moving, because their movements need energy, and so the superconductive disorder.
2022-03-23 12:13:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial reflection, which is the big configuration of the face and the basic shape, and restores it through the whole structure and a fold.
2022-03-23 12:14:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and say, "well, for tedwomen, is that... tyes, when it's been the best, when someone said," turn on the men on a table, "and then we support the truth."
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continually refrigerated and a refrigeration system that we're allowed to use in the.
2022-03-23 12:14:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:06 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.023 | ppl 260.2 | bleu 27.39 | wps 5093 | wpb 17862.2 | bsz 728.3 | num_updates 3764 | best_bleu 27.6
2022-03-23 12:14:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3764 updates
2022-03-23 12:14:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 24 @ 3764 updates, score 27.39) (writing took 0.7907481589354575 seconds)
2022-03-23 12:14:06 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:14:06 | INFO | train | epoch 024 | loss 6.951 | ppl 123.7 | wps 41151.8 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 3764 | lr 0.0004705 | gnorm 0.446 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 2440
KL Stats: Epoch 24 Divergences: Uniform: 2.7370129754028762 Unigram: 0.8071550395026964
2022-03-23 12:14:07 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:20 | INFO | train_inner | epoch 025:     36 / 157 loss=6.999, ppl=127.94, wps=33379.4, ups=1.34, wpb=24859.5, bsz=955, num_updates=3800, lr=0.000475, gnorm=0.435, loss_scale=8, train_wall=37, gb_free=12.5, wall=2454
2022-03-23 12:14:58 | INFO | train_inner | epoch 025:    136 / 157 loss=6.878, ppl=117.65, wps=67234.3, ups=2.65, wpb=25332.2, bsz=1058.5, num_updates=3900, lr=0.0004875, gnorm=0.458, loss_scale=8, train_wall=37, gb_free=12.9, wall=2492
2022-03-23 12:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:10 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:15:10 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:15:14 | INFO | fairseq.tasks.translation | example hypothesis: he can occur about 8,000 places in the restaurant.
2022-03-23 12:15:14 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:15:18 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form a popular glide.
2022-03-23 12:15:18 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:15:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:15:25 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and has a waisenchild back, so we asked us, well, what do we do with her?
2022-03-23 12:15:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or poverty or any other promising topic.
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:15:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs are caught by magnetic field lines in the inner, but the superconductor doesn't like it when they move, because their movements need energy, and so the superconductor disorder.
2022-03-23 12:15:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:37 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big configuration of the facial and the basic form, and through the theast, which the whole porter structure and all fold.
2022-03-23 12:15:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate, for me here at tedwomen, is that... tyes, when they were striking dinner, it was the best summary when someone said, "turn to the men on your dtable, and they say," if the revolution starts to help you. "
2022-03-23 12:15:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the proud toes, was a result that we had to solve the unique problems that were connected to the floor -- everything from a continually variable, and a continually variable system that we're going to operate with a cooling system, and that either allows us to use it to refrigeration, either to operate in the
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:43 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.955 | ppl 248.19 | bleu 28.6 | wps 4956.5 | wpb 17862.2 | bsz 728.3 | num_updates 3921 | best_bleu 28.6
2022-03-23 12:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3921 updates
2022-03-23 12:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 25 @ 3921 updates, score 28.6) (writing took 1.8387320081237704 seconds)
2022-03-23 12:15:45 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:15:45 | INFO | train | epoch 025 | loss 6.905 | ppl 119.83 | wps 40176.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3921 | lr 0.000490125 | gnorm 0.447 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 2539
KL Stats: Epoch 25 Divergences: Uniform: 2.746443463357176 Unigram: 0.8089090955064628
2022-03-23 12:15:45 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:15:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:15 | INFO | train_inner | epoch 026:     79 / 157 loss=6.805, ppl=111.85, wps=32933, ups=1.3, wpb=25285.9, bsz=994.7, num_updates=4000, lr=0.0005, gnorm=0.434, loss_scale=8, train_wall=37, gb_free=12.2, wall=2569
2022-03-23 12:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:48 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:16:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:16:52 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:16:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:16:56 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand to form a popular same same.
2022-03-23 12:16:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:17:00 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:17:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:17:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my coussines died of aids, and has left a waisenchild, so we asked us, well, what do we do with her?
2022-03-23 12:17:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:17:08 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender high times, and not about genocide or the spread of nuclear weapons or poverty or each other.
2022-03-23 12:17:08 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inner, but the superconductor doesn't like it when they move, because their movements need, and so the superconductive disorder.
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big configuration of the face and the basic form, and through the one of the information that the whole portion structure and all folds a fold.
2022-03-23 12:17:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and appropriate for me here at tedwomen is that... tyes, it was the best, when someone said, "turn you to the men in your table and say," if the revolution starts. "
2022-03-23 12:17:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:21 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design work that we are on our plane on the stones, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to refrigerate.
2022-03-23 12:17:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:21 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.897 | ppl 238.42 | bleu 28.62 | wps 4961 | wpb 17862.2 | bsz 728.3 | num_updates 4078 | best_bleu 28.62
2022-03-23 12:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4078 updates
2022-03-23 12:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 26 @ 4078 updates, score 28.62) (writing took 1.8003684610594064 seconds)
2022-03-23 12:17:23 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:17:23 | INFO | train | epoch 026 | loss 6.856 | ppl 115.8 | wps 40318.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4078 | lr 0.000495195 | gnorm 0.436 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2637
KL Stats: Epoch 26 Divergences: Uniform: 2.7520210868899615 Unigram: 0.8082780636806233
2022-03-23 12:17:23 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:32 | INFO | train_inner | epoch 027:     22 / 157 loss=6.857, ppl=115.94, wps=32844.7, ups=1.3, wpb=25215.3, bsz=1007.8, num_updates=4100, lr=0.000493865, gnorm=0.426, loss_scale=8, train_wall=37, gb_free=12.6, wall=2645
2022-03-23 12:18:09 | INFO | train_inner | epoch 027:    122 / 157 loss=6.826, ppl=113.46, wps=66495.5, ups=2.66, wpb=25044.6, bsz=1024, num_updates=4200, lr=0.00048795, gnorm=0.397, loss_scale=8, train_wall=37, gb_free=13.3, wall=2683
2022-03-23 12:18:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:27 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:18:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:18:31 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:18:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:18:35 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these dogs magnets, of course, to form a popular glimpse.
2022-03-23 12:18:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:18:38 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:18:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:18:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and has left a waisenchild, so we asked us, well, what do we do with her?
2022-03-23 12:18:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:18:47 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:18:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:18:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it if you're moving, because your movements use energy, and so the superconducting disorder disorder disorder disorder disorder disorder disorder disorder.
2022-03-23 12:18:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:18:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that's the big configurations of the face and the basic shape, and through that one of the information that's putting all the ports structure and everybody's folding a fold.
2022-03-23 12:18:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen, is that... tyes, in the dinner of dinner, it was best summared when someone said, "turn you to the men on your table and say," if the revolution starts to you. "
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation, and a cooling system that allows us to use the, either in the
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:02 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.86 | ppl 232.26 | bleu 29.58 | wps 4621.2 | wpb 17862.2 | bsz 728.3 | num_updates 4235 | best_bleu 29.58
2022-03-23 12:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4235 updates
2022-03-23 12:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 27 @ 4235 updates, score 29.58) (writing took 1.8030658538918942 seconds)
2022-03-23 12:19:04 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:19:04 | INFO | train | epoch 027 | loss 6.792 | ppl 110.85 | wps 39063.8 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 4235 | lr 0.00048593 | gnorm 0.397 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2738
KL Stats: Epoch 27 Divergences: Uniform: 2.7625598086602436 Unigram: 0.8112092942052064
2022-03-23 12:19:04 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:29 | INFO | train_inner | epoch 028:     65 / 157 loss=6.764, ppl=108.7, wps=31849.4, ups=1.26, wpb=25351.4, bsz=1013.6, num_updates=4300, lr=0.000482243, gnorm=0.418, loss_scale=8, train_wall=37, gb_free=12.4, wall=2763
2022-03-23 12:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:07 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:20:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:20:11 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:20:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:20:15 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form a popular same.
2022-03-23 12:20:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and have a waisenchild left, so we asked us, well, what do we do with her?
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inner, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big configurations of the face and the basic form, and by the theast, the whole porter structure and a fold.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... tyes, when striking dinner was summarized when someone said, "turn you to the men in your table and say," if the revolution begins to you. "the truth is that we've been supported with you,"
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:41 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design work that we're on our airplane on the proud tower was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continually variable, and a cooling system that allows us to see in the car traffic, either in the same way, or if you get rid of the device, you're going to see the device, or you're going to see the propelled, or you're going to get rid of a mechanism of a mechanism, you're going to get rid of a device, or the device that's going to get rid of a machine, you're going to see it's going to be able to see it's going to operate it's going to be able to do it's going to be able to be able to get rid of you to operate it's going to be able to be able to get rid of us to operate in the locked in the locked in the wall, or
2022-03-23 12:20:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:41 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.845 | ppl 229.95 | bleu 29.79 | wps 4769.8 | wpb 17862.2 | bsz 728.3 | num_updates 4392 | best_bleu 29.79
2022-03-23 12:20:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4392 updates
2022-03-23 12:20:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 28 @ 4392 updates, score 29.79) (writing took 1.8267957740463316 seconds)
2022-03-23 12:20:43 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:20:43 | INFO | train | epoch 028 | loss 6.759 | ppl 108.29 | wps 39764.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4392 | lr 0.000477165 | gnorm 0.4 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2837
KL Stats: Epoch 28 Divergences: Uniform: 2.7633762792505467 Unigram: 0.815194041742917
2022-03-23 12:20:43 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:20:47 | INFO | train_inner | epoch 029:      8 / 157 loss=6.722, ppl=105.57, wps=32337, ups=1.28, wpb=25223.2, bsz=1064, num_updates=4400, lr=0.000476731, gnorm=0.365, loss_scale=8, train_wall=37, gb_free=12.5, wall=2841
2022-03-23 12:21:24 | INFO | train_inner | epoch 029:    108 / 157 loss=6.692, ppl=103.41, wps=67100.3, ups=2.66, wpb=25271.5, bsz=1000.2, num_updates=4500, lr=0.000471405, gnorm=0.385, loss_scale=8, train_wall=37, gb_free=11.9, wall=2878
2022-03-23 12:21:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:46 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:21:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:21:51 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:21:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to form any glimpse.
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father left his mother when she was pregnant.
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is aids died, and we left an orphanage, so we asked us, well, what do we do with her?
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, and not about genocide or distribution of nuclear weapons or poverty or any other topic.
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inside, but the superconductor doesn't like when they move, because their movements use, and so the superconductor disorder disorder.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big constructions of the face, and the basic shape, and it refits the whole portion structure and all wrints.
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here in tedwomen is that... tyes, when you eat it, it was best summared when someone said, "turn you to your table and say," 'if the revolution begins. "'" the truth is that we've been supporting you in this topic. "
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system, that allows us to use an aircraft, either in the ground, either passenger traffic, or a tune, or a tune.
2022-03-23 12:22:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:20 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.845 | ppl 229.96 | bleu 29.86 | wps 4800 | wpb 17862.2 | bsz 728.3 | num_updates 4549 | best_bleu 29.86
2022-03-23 12:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4549 updates
2022-03-23 12:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 29 @ 4549 updates, score 29.86) (writing took 1.8273368219379336 seconds)
2022-03-23 12:22:22 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:22:22 | INFO | train | epoch 029 | loss 6.697 | ppl 103.74 | wps 39834.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4549 | lr 0.000468859 | gnorm 0.371 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 2936
KL Stats: Epoch 29 Divergences: Uniform: 2.771096627292264 Unigram: 0.8199586211388651
2022-03-23 12:22:23 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:42 | INFO | train_inner | epoch 030:     51 / 157 loss=6.691, ppl=103.29, wps=31969.6, ups=1.29, wpb=24866.6, bsz=1067.6, num_updates=4600, lr=0.000466252, gnorm=0.358, loss_scale=8, train_wall=37, gb_free=11.8, wall=2956
2022-03-23 12:23:20 | INFO | train_inner | epoch 030:    151 / 157 loss=6.679, ppl=102.46, wps=67122.8, ups=2.66, wpb=25189.8, bsz=990.4, num_updates=4700, lr=0.000461266, gnorm=0.37, loss_scale=8, train_wall=37, gb_free=12.2, wall=2994
2022-03-23 12:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:27 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:23:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:23:31 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:23:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:23:35 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to form a popular glide.
2022-03-23 12:23:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:23:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:23:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:23:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we've left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:23:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:23:47 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:23:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:23:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are caught in the inner, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder distinguishes.
2022-03-23 12:23:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic shape, and through the theft of the information that comes from the whole porter structure and all folds.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that... tyes, when argued dinner, it was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "'the truth is that women, we've been supporting you for this topic for a long time, it's been supported by sandra:"
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane on the proud towers was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable, and a refrigeration system that allows us to look at aircraft, or a refrigeration system, to use it in a car transportation machine, or if you're either, you're going to see the
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:02 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.762 | ppl 217.09 | bleu 31.48 | wps 4605.8 | wpb 17862.2 | bsz 728.3 | num_updates 4706 | best_bleu 31.48
2022-03-23 12:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4706 updates
2022-03-23 12:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 30 @ 4706 updates, score 31.48) (writing took 1.8227650951594114 seconds)
2022-03-23 12:24:04 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:24:04 | INFO | train | epoch 030 | loss 6.666 | ppl 101.57 | wps 38766 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 4706 | lr 0.000460971 | gnorm 0.367 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 3038
KL Stats: Epoch 30 Divergences: Uniform: 2.774778588612323 Unigram: 0.8185863522109189
2022-03-23 12:24:04 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:40 | INFO | train_inner | epoch 031:     94 / 157 loss=6.667, ppl=101.62, wps=31081.9, ups=1.24, wpb=25031.5, bsz=996.4, num_updates=4800, lr=0.000456435, gnorm=0.361, loss_scale=8, train_wall=37, gb_free=12.1, wall=3074
2022-03-23 12:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:25:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:25:11 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:25:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:25:15 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form any same glider.
2022-03-23 12:25:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father left his mother when she was pregnant with him.
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:25:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wears and not about genocide or poverty or any other kind of promising topic.
2022-03-23 12:25:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:25:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements require energy, and so the superconducting.
2022-03-23 12:25:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contures of the face, and the basic shape, and through that one information that comes from the whole porter structure and all the fits.
2022-03-23 12:25:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and appropriate for me to be here at tedwomen is that... well, the truth is that we've been supporting you for that long time, when someone said, "turn you to the men in your table and say," if the revolution begins to you, we'll support you, 'if the revolution, then we're supporting you. "the truth is that we're already supporting you.' well, we're already supporting you at that time.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on at our airplane is a result that we had to solve the unique problems that were connected to it operating on the ground -- everything from a continuous variation, from a continuous variation, and a cooling system that allows us to stop us to stop a vehicle, to the floor, or if you're going to see the.
2022-03-23 12:25:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:43 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.776 | ppl 219.18 | bleu 31.46 | wps 4582.3 | wpb 17862.2 | bsz 728.3 | num_updates 4863 | best_bleu 31.48
2022-03-23 12:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4863 updates
2022-03-23 12:25:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 31 @ 4863 updates, score 31.46) (writing took 0.8225459870882332 seconds)
2022-03-23 12:25:44 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:25:44 | INFO | train | epoch 031 | loss 6.629 | ppl 98.95 | wps 39485.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4863 | lr 0.000453469 | gnorm 0.367 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 3138
KL Stats: Epoch 31 Divergences: Uniform: 2.7767137463795404 Unigram: 0.8203809435078323
2022-03-23 12:25:45 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:25:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:59 | INFO | train_inner | epoch 032:     37 / 157 loss=6.559, ppl=94.28, wps=32387, ups=1.28, wpb=25368.2, bsz=1001.5, num_updates=4900, lr=0.000451754, gnorm=0.378, loss_scale=8, train_wall=37, gb_free=11.7, wall=3153
2022-03-23 12:26:36 | INFO | train_inner | epoch 032:    137 / 157 loss=6.57, ppl=94.98, wps=66935.9, ups=2.65, wpb=25240.1, bsz=1067.4, num_updates=5000, lr=0.000447214, gnorm=0.323, loss_scale=8, train_wall=37, gb_free=12.1, wall=3190
2022-03-23 12:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:47 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:26:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:26:51 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:26:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to shape any same glide.
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father left his mother when she was pregnant with him.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder disorder.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face that repeats the big contures of the facial and the basic form, and it comes through that one information that includes the whole porter structure and all the fits wrinkles.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and appropriate for me to be here at tedwomen is that... well, when arguing dinner, it was the best summarized when someone said, "turn you to men on your table and say," if the revolution begins, we support you. "'" the truth is that we've been supporting you for that long time. "
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable and a cooling system that allows us to use a stop.
2022-03-23 12:27:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:22 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.742 | ppl 214.02 | bleu 31.68 | wps 4813.3 | wpb 17862.2 | bsz 728.3 | num_updates 5020 | best_bleu 31.68
2022-03-23 12:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5020 updates
2022-03-23 12:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 32 @ 5020 updates, score 31.68) (writing took 1.818064979976043 seconds)
2022-03-23 12:27:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:27:23 | INFO | train | epoch 032 | loss 6.589 | ppl 96.27 | wps 39800.5 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5020 | lr 0.000446322 | gnorm 0.34 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 3237
KL Stats: Epoch 32 Divergences: Uniform: 2.7828186828765356 Unigram: 0.824442910662878
2022-03-23 12:27:24 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:54 | INFO | train_inner | epoch 033:     80 / 157 loss=6.616, ppl=98.1, wps=32147.1, ups=1.28, wpb=25023.8, bsz=971.1, num_updates=5100, lr=0.000442807, gnorm=0.343, loss_scale=8, train_wall=37, gb_free=12.2, wall=3268
2022-03-23 12:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:27 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:28:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:28:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets, of course, to shape any same glide.
2022-03-23 12:28:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:28:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:28:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:28:47 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not talking about genocide or prevalence of nuclear weapons or poverty or any other kind of promising topic.
2022-03-23 12:28:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:28:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disruptions.
2022-03-23 12:28:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial configurations of the face and the baseline, and the basic shape, and through the theft of the information, which includes the whole porter structure and all the fits.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... tyes, in the arguing dinner, it was the best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins to be here, we support you. "the truth is that we've already been supporting you."
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the stump, was a result of that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable variation and a cooling system that allows us to stop in the aircraft.
2022-03-23 12:29:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:02 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.746 | ppl 214.7 | bleu 31.94 | wps 4615.9 | wpb 17862.2 | bsz 728.3 | num_updates 5177 | best_bleu 31.94
2022-03-23 12:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5177 updates
2022-03-23 12:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 33 @ 5177 updates, score 31.94) (writing took 1.7974973910022527 seconds)
2022-03-23 12:29:04 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:29:04 | INFO | train | epoch 033 | loss 6.563 | ppl 94.56 | wps 39271.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5177 | lr 0.000439502 | gnorm 0.349 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 3338
KL Stats: Epoch 33 Divergences: Uniform: 2.787150636642073 Unigram: 0.8259391005740195
2022-03-23 12:29:04 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:13 | INFO | train_inner | epoch 034:     23 / 157 loss=6.498, ppl=90.36, wps=31991.9, ups=1.27, wpb=25212.8, bsz=1113.8, num_updates=5200, lr=0.000438529, gnorm=0.35, loss_scale=8, train_wall=37, gb_free=12.4, wall=3347
2022-03-23 12:29:51 | INFO | train_inner | epoch 034:    123 / 157 loss=6.552, ppl=93.83, wps=66678.6, ups=2.66, wpb=25095, bsz=986.3, num_updates=5300, lr=0.000434372, gnorm=0.343, loss_scale=8, train_wall=37, gb_free=11.8, wall=3385
2022-03-23 12:30:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:30:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:30:12 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:30:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these circular magnets, of course, to shape any same glide.
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:30:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 12:30:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:30:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:30:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:30:28 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty or any other vulnerable topic.
2022-03-23 12:30:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:30:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the supralal disorder.
2022-03-23 12:30:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big contextures of the face and the basic form, and refers it through the one of the information that includes the whole porn structure and all the fits.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, in the arguing dinner, it was the best summarized when someone said, "turn to the men in your desk and say," 'when the revolution begins to support you. "'" '"'" '"the truth, women, love, love, is that we've already been supported for you."
2022-03-23 12:30:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is still a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and a cooling system with fluid, that allows us to use a stop-of-the-shelf machine in the
2022-03-23 12:30:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.7 | ppl 207.96 | bleu 32.3 | wps 4662.9 | wpb 17862.2 | bsz 728.3 | num_updates 5334 | best_bleu 32.3
2022-03-23 12:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5334 updates
2022-03-23 12:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 34 @ 5334 updates, score 32.3) (writing took 1.8286431208252907 seconds)
2022-03-23 12:30:45 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:30:45 | INFO | train | epoch 034 | loss 6.54 | ppl 93.03 | wps 39176 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5334 | lr 0.000432986 | gnorm 0.335 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 3439
KL Stats: Epoch 34 Divergences: Uniform: 2.7913248155584114 Unigram: 0.8261303471602452
2022-03-23 12:30:46 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:11 | INFO | train_inner | epoch 035:     66 / 157 loss=6.639, ppl=99.63, wps=31078.1, ups=1.25, wpb=24869.7, bsz=979, num_updates=5400, lr=0.000430331, gnorm=0.324, loss_scale=8, train_wall=37, gb_free=11.5, wall=3465
2022-03-23 12:31:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:48 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:31:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form any kind of glide.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:32:08 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other representative topic.
2022-03-23 12:32:08 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:32:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic rocks are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disruptions are disturbing.
2022-03-23 12:32:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which repeats the big contexts of the face and the basic form, and deploy it through the one that refers the whole porter structure and all the fits.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... tyes, when it was argued, it was best summarized when someone said, "turn you to the men at your table and say," when the revolution begins, we support you. "the truth, women, we've been supporting you for this issue."
2022-03-23 12:32:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied drive and a refrigeration system allows us to use an aircraft, either to use an aircraft in the
2022-03-23 12:32:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:23 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.688 | ppl 206.24 | bleu 31.92 | wps 4726.8 | wpb 17862.2 | bsz 728.3 | num_updates 5491 | best_bleu 32.3
2022-03-23 12:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5491 updates
2022-03-23 12:32:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 35 @ 5491 updates, score 31.92) (writing took 0.858120758086443 seconds)
2022-03-23 12:32:24 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:32:24 | INFO | train | epoch 035 | loss 6.517 | ppl 91.57 | wps 39840.5 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5491 | lr 0.000426751 | gnorm 0.343 | loss_scale 8 | train_wall 58 | gb_free 13 | wall 3538
KL Stats: Epoch 35 Divergences: Uniform: 2.7942350469510435 Unigram: 0.8268943126778425
2022-03-23 12:32:24 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:28 | INFO | train_inner | epoch 036:      9 / 157 loss=6.421, ppl=85.68, wps=33025.9, ups=1.29, wpb=25522.5, bsz=1059.3, num_updates=5500, lr=0.000426401, gnorm=0.343, loss_scale=8, train_wall=37, gb_free=12.4, wall=3542
2022-03-23 12:33:06 | INFO | train_inner | epoch 036:    109 / 157 loss=6.413, ppl=85.21, wps=67809.3, ups=2.65, wpb=25595, bsz=1089.2, num_updates=5600, lr=0.000422577, gnorm=0.342, loss_scale=8, train_wall=37, gb_free=12, wall=3580
2022-03-23 12:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:27 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:33:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:33:31 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occur about 8,000 places in the restaurant.
2022-03-23 12:33:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:33:35 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to shape any same glide.
2022-03-23 12:33:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:33:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:33:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:33:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:33:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:33:47 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, and not about genocide or spread of nuclear weapons or poverty or any other kind of promising topic.
2022-03-23 12:33:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:33:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements are using energy, and so the superconducting disorders are disrupted.
2022-03-23 12:33:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial. so, the big configuration of the face and the basic form, and we can make it through the one information that pulls the whole pore-structure and all the fine wrinkles.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be here for me here at tedwomen is that -- well, when it was argued, it was best summarized when someone said, "turn to the men at your desk and say," well, when the revolution begins to be. "'"' "the truth, women, we've been supporting you in this theme for a long time."
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable operating and a cooling system that allows us to use a computer in the aircraft, to use an aircraft in the go
2022-03-23 12:34:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:02 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.684 | ppl 205.63 | bleu 32.74 | wps 4644 | wpb 17862.2 | bsz 728.3 | num_updates 5648 | best_bleu 32.74
2022-03-23 12:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5648 updates
2022-03-23 12:34:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 36 @ 5648 updates, score 32.74) (writing took 1.8848809020128101 seconds)
2022-03-23 12:34:04 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:34:04 | INFO | train | epoch 036 | loss 6.492 | ppl 90.03 | wps 39335.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5648 | lr 0.000420778 | gnorm 0.338 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 3638
KL Stats: Epoch 36 Divergences: Uniform: 2.7970406580851526 Unigram: 0.829821144339544
2022-03-23 12:34:05 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:24 | INFO | train_inner | epoch 037:     52 / 157 loss=6.588, ppl=96.21, wps=31239.9, ups=1.27, wpb=24606.2, bsz=933, num_updates=5700, lr=0.000418854, gnorm=0.318, loss_scale=8, train_wall=37, gb_free=11.8, wall=3658
2022-03-23 12:35:02 | INFO | train_inner | epoch 037:    152 / 157 loss=6.449, ppl=87.34, wps=67250.9, ups=2.67, wpb=25190.2, bsz=1011, num_updates=5800, lr=0.000415227, gnorm=0.327, loss_scale=8, train_wall=37, gb_free=12.6, wall=3696
2022-03-23 12:35:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:35:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:35:11 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:35:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these circular magnets, of course, to shape any same glide.
2022-03-23 12:35:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:35:19 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:35:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:35:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:35:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:35:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other.
2022-03-23 12:35:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:35:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements are using energy, and so the superconductor disturbs.
2022-03-23 12:35:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that repeats the great contextures of the face and the basic form, and breaks it through the one information that refers the whole porter structure and all the fills.
2022-03-23 12:35:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when arguing dinner, it was best summarized, when someone said, "turn to the men at your table and say," if the revolution starts to be here, then we support you. "the truth, women love you about this issue for a long time."
2022-03-23 12:35:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously variable and a cooling system that allows us to use an aircraft in the go
2022-03-23 12:35:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:42 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.654 | ppl 201.45 | bleu 32.89 | wps 4762.7 | wpb 17862.2 | bsz 728.3 | num_updates 5805 | best_bleu 32.89
2022-03-23 12:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5805 updates
2022-03-23 12:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:35:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:35:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 37 @ 5805 updates, score 32.89) (writing took 1.880038795992732 seconds)
2022-03-23 12:35:44 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:35:44 | INFO | train | epoch 037 | loss 6.463 | ppl 88.22 | wps 39652.6 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5805 | lr 0.000415049 | gnorm 0.314 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 3738
KL Stats: Epoch 37 Divergences: Uniform: 2.803901900882141 Unigram: 0.8304966015796236
2022-03-23 12:35:44 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:35:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:20 | INFO | train_inner | epoch 038:     95 / 157 loss=6.503, ppl=90.72, wps=31823.6, ups=1.28, wpb=24808.2, bsz=981.3, num_updates=5900, lr=0.000411693, gnorm=0.35, loss_scale=8, train_wall=37, gb_free=12.4, wall=3774
2022-03-23 12:36:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:47 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:36:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:36:51 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant over year.
2022-03-23 12:36:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:36:55 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to shape any glide.
2022-03-23 12:36:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:37:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:37:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:37:07 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide, or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:37:07 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:37:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:37:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, which is the big contexts of the face and the basic form, and we can deploy it through the one information that includes the whole porch structure and all the fine wrinkles.
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, in arguments, it was best summarized when someone said, "turn to the men on your table and say," if the revolution begins to be here. "'"' "'" the truth, women, we've been supporting you for this long time. "
2022-03-23 12:37:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:21 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still the mother of invention, and a large part of the design work that we're on our airplane on the stages was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuously variable, and a cooling system that allows us to use an aircraft in the go-transportation system to a particular passenger, either passenger drive the propeller floor, all the way down the way down the road, all the way down the way down the way down the way down to a mechanism of a vehicle, either when you can see the way down the way down the way down the way down the road, or you can see the road, you can see the way down to operate, either passenger floor, either passenger.
2022-03-23 12:37:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:22 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.646 | ppl 200.27 | bleu 33.13 | wps 4737.7 | wpb 17862.2 | bsz 728.3 | num_updates 5962 | best_bleu 33.13
2022-03-23 12:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5962 updates
2022-03-23 12:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 38 @ 5962 updates, score 33.13) (writing took 1.9153965869918466 seconds)
2022-03-23 12:37:23 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:37:23 | INFO | train | epoch 038 | loss 6.451 | ppl 87.49 | wps 39666.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.329 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 3837
KL Stats: Epoch 38 Divergences: Uniform: 2.8015739241957447 Unigram: 0.8316340443612589
2022-03-23 12:37:24 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:38 | INFO | train_inner | epoch 039:     38 / 157 loss=6.369, ppl=82.63, wps=32627.9, ups=1.28, wpb=25574.4, bsz=1048.3, num_updates=6000, lr=0.000408248, gnorm=0.296, loss_scale=8, train_wall=37, gb_free=12.3, wall=3852
2022-03-23 12:38:16 | INFO | train_inner | epoch 039:    138 / 157 loss=6.449, ppl=87.37, wps=66619.8, ups=2.66, wpb=25084.8, bsz=991.2, num_updates=6100, lr=0.000404888, gnorm=0.332, loss_scale=8, train_wall=37, gb_free=11.8, wall=3890
2022-03-23 12:38:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:27 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:38:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:38:30 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:38:30 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form any same glider.
2022-03-23 12:38:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:38:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:38:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:38:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disturbs.
2022-03-23 12:38:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that repeats the big contexts of the face and the basic form, and bring it through the one information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:38:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that... well, when you dinner, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins to support you. "'"' the truth, women is that we've been supporting you for this long time. "
2022-03-23 12:38:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuously variable distribution and a refrigeration system that allows us to use an aircraft in go-traffic, to a specific operating system that either drives the propeller, or if you have to operate it on the ground, the automation of a mechanism, or if you're going to move it from a mechanism, or if you're going to the ground.
2022-03-23 12:39:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:00 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.668 | ppl 203.34 | bleu 32.64 | wps 4840.9 | wpb 17862.2 | bsz 728.3 | num_updates 6119 | best_bleu 33.13
2022-03-23 12:39:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6119 updates
2022-03-23 12:39:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:39:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:39:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 39 @ 6119 updates, score 32.64) (writing took 0.8339580548927188 seconds)
2022-03-23 12:39:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:39:01 | INFO | train | epoch 039 | loss 6.427 | ppl 86.02 | wps 40333.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6119 | lr 0.000404259 | gnorm 0.324 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 3935
KL Stats: Epoch 39 Divergences: Uniform: 2.8016588601445718 Unigram: 0.8346923548356727
2022-03-23 12:39:02 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:33 | INFO | train_inner | epoch 040:     81 / 157 loss=6.418, ppl=85.5, wps=32993.1, ups=1.31, wpb=25270.4, bsz=983.5, num_updates=6200, lr=0.00040161, gnorm=0.323, loss_scale=8, train_wall=37, gb_free=12, wall=3966
2022-03-23 12:40:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:04 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:40:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:40:08 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant year.
2022-03-23 12:40:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:40:12 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form any glider.
2022-03-23 12:40:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:40:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:40:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not talking about genocide or the spread of nuclear weapons or poverty or any other accordant topic.
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconducting disorders are disturbing.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which gives the big contextures of the face and the basic form, and deploy it through the information that draws the whole porter structure and all the fine folds.
2022-03-23 12:40:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins to you. "'" the truth, women, we've already been supporting you for a long time.
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane on the stumpy was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive, and a refrigeration system that allows us to use an aircraft in the go-transportation, to a specific passenger vehicle that is either to operate the ground, or when you see the propelled by the propelled by a mechanism that's the same time you see the ground.
2022-03-23 12:40:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:39 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.653 | ppl 201.3 | bleu 33.16 | wps 4722.5 | wpb 17862.2 | bsz 728.3 | num_updates 6276 | best_bleu 33.16
2022-03-23 12:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6276 updates
2022-03-23 12:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 40 @ 6276 updates, score 33.16) (writing took 1.8763112351298332 seconds)
2022-03-23 12:40:41 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:40:41 | INFO | train | epoch 040 | loss 6.408 | ppl 84.91 | wps 39593.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6276 | lr 0.000399171 | gnorm 0.314 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 4035
KL Stats: Epoch 40 Divergences: Uniform: 2.8063408020861482 Unigram: 0.8361162665858106
2022-03-23 12:40:41 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:50 | INFO | train_inner | epoch 041:     24 / 157 loss=6.487, ppl=89.67, wps=31310.8, ups=1.28, wpb=24389.1, bsz=1077.7, num_updates=6300, lr=0.00039841, gnorm=0.335, loss_scale=8, train_wall=36, gb_free=12.7, wall=4044
2022-03-23 12:41:28 | INFO | train_inner | epoch 041:    124 / 157 loss=6.309, ppl=79.29, wps=67551.5, ups=2.63, wpb=25662.2, bsz=1044.2, num_updates=6400, lr=0.000395285, gnorm=0.3, loss_scale=8, train_wall=38, gb_free=12.6, wall=4082
2022-03-23 12:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:44 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:41:44 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:41:48 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:41:48 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:41:52 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form any glide.
2022-03-23 12:41:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:41:56 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:41:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:42:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:42:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:42:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:42:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional faculty that repeats the big contexts of the face and the basic form, and refers it through the one of the information that includes the whole porter structure and all the fine wrinkles.
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that -- well, when it was argued, it was best summarized when someone said, "turn you to the men on your table and say," when the revolution begins, we support you. "'" the truth, women love you, we've already started with a stump. "
2022-03-23 12:42:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane on the stump was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and a refrigeration system that allows us to use an aircraft in the go-transportation to a specific drive that is either the propelled to the ground, or when you're driving the propelled, you can see the propelled.
2022-03-23 12:42:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:18 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.641 | ppl 199.57 | bleu 33.4 | wps 4885.4 | wpb 17862.2 | bsz 728.3 | num_updates 6433 | best_bleu 33.4
2022-03-23 12:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6433 updates
2022-03-23 12:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:42:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 41 @ 6433 updates, score 33.4) (writing took 1.8896364748943597 seconds)
2022-03-23 12:42:20 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:42:20 | INFO | train | epoch 041 | loss 6.391 | ppl 83.9 | wps 39990.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6433 | lr 0.00039427 | gnorm 0.321 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 4134
KL Stats: Epoch 41 Divergences: Uniform: 2.8087641486069517 Unigram: 0.8374235091073077
2022-03-23 12:42:20 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:46 | INFO | train_inner | epoch 042:     67 / 157 loss=6.275, ppl=77.43, wps=33255.6, ups=1.29, wpb=25707, bsz=1062.3, num_updates=6500, lr=0.000392232, gnorm=0.303, loss_scale=8, train_wall=37, gb_free=11.7, wall=4160
2022-03-23 12:43:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:23 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-23 12:43:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:43:27 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant year.
2022-03-23 12:43:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:43:31 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glimpse.
2022-03-23 12:43:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:43:35 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:43:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:43:39 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:43:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:43:43 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not talking about genocide or spreading nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:43:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:43:52 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional faculty that will restore the big contextures of the face and the basic form, and bring it through the actual information that refers the whole por-structure and all the fine wrinkling wrinkles.
2022-03-23 12:43:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me here at tedwomen is that -- well, when it was argued, it was best summarized when someone said, "turn you to the men at your desk and say," 'when the revolution begins to support you. "'" 'the truth, women, love you, that we've been supporting you at this point for a long time when we've been supporting you at chel carra borne future. "
2022-03-23 12:43:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the necessary, and a big part of the design work that we're on our airplane on the stumbling tower was a result that we needed to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drift and refrigerating system that allows us to see a stop-go-tailing machine in the ground, to use an aircraft in a specific passenger vehicle, either when we see the propelled to the walls on the ground, the ground, or when we see the propelled by a mechanism, the ground.
2022-03-23 12:43:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:58 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.646 | ppl 200.31 | bleu 33.09 | wps 4707.1 | wpb 17862.2 | bsz 728.3 | num_updates 6590 | best_bleu 33.4
2022-03-23 12:43:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6590 updates
2022-03-23 12:43:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 42 @ 6590 updates, score 33.09) (writing took 0.8151838530320674 seconds)
2022-03-23 12:43:59 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:43:59 | INFO | train | epoch 042 | loss 6.386 | ppl 83.62 | wps 39941.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6590 | lr 0.000389545 | gnorm 0.342 | loss_scale 8 | train_wall 58 | gb_free 13.2 | wall 4233
KL Stats: Epoch 42 Divergences: Uniform: 2.8088155175656313 Unigram: 0.8361433062481168
2022-03-23 12:43:59 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:03 | INFO | train_inner | epoch 043:     10 / 157 loss=6.519, ppl=91.73, wps=31872.8, ups=1.29, wpb=24675.4, bsz=961.4, num_updates=6600, lr=0.000389249, gnorm=0.363, loss_scale=8, train_wall=37, gb_free=12.8, wall=4237
2022-03-23 12:44:40 | INFO | train_inner | epoch 043:    110 / 157 loss=6.385, ppl=83.56, wps=66580.1, ups=2.69, wpb=24783.4, bsz=979.9, num_updates=6700, lr=0.000386334, gnorm=0.31, loss_scale=8, train_wall=37, gb_free=12.4, wall=4274
2022-03-23 12:44:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:45:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:45:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:45:10 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 12:45:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:45:14 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:45:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:45:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:45:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or prevalence of nuclear weapons or poverty, or any corresponding topic.
2022-03-23 12:45:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:45:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disturbs.
2022-03-23 12:45:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial configuration that replaces the big contextures of the face and the basic form, and bring it through the information that refers the whole porter structure and all the fine.
2022-03-23 12:45:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins to support you. "the truth, women, we love you, is that we've been supporting you at this point for a long time.
2022-03-23 12:45:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane on the stump was a result that we had to solve the unique problems associated with operating it on the floor -- all, from a continuously variable drift and cooling system with liquid that allows us to use an aircraft in the gavich and go-traffic, until a specially adapted vehicle that either drives the propellers to operate it on the ground -- or when you get mechanical waste, or the propelled to see the ground, or the propelled by a mechanical diarrhea, to become a mechanical waste.
2022-03-23 12:45:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:36 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.63 | ppl 198.04 | bleu 33.36 | wps 4787.8 | wpb 17862.2 | bsz 728.3 | num_updates 6747 | best_bleu 33.4
2022-03-23 12:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6747 updates
2022-03-23 12:45:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:45:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 43 @ 6747 updates, score 33.36) (writing took 0.8429209960158914 seconds)
2022-03-23 12:45:37 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:45:37 | INFO | train | epoch 043 | loss 6.357 | ppl 81.99 | wps 40140.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6747 | lr 0.000384986 | gnorm 0.306 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 4331
KL Stats: Epoch 43 Divergences: Uniform: 2.8121229444219384 Unigram: 0.8399141307471601
2022-03-23 12:45:37 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:58 | INFO | train_inner | epoch 044:     53 / 157 loss=6.34, ppl=81, wps=32638.3, ups=1.29, wpb=25221.5, bsz=1062.9, num_updates=6800, lr=0.000383482, gnorm=0.306, loss_scale=8, train_wall=37, gb_free=12.1, wall=4352
2022-03-23 12:46:35 | INFO | train_inner | epoch 044:    153 / 157 loss=6.314, ppl=79.54, wps=67884.7, ups=2.67, wpb=25470, bsz=1029.1, num_updates=6900, lr=0.000380693, gnorm=0.299, loss_scale=8, train_wall=37, gb_free=12, wall=4389
2022-03-23 12:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:40 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:46:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over the year.
2022-03-23 12:46:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:46:48 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 12:46:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:46:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:46:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:46:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:46:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:47:00 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not talking about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:47:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:47:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:47:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:09 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional faculty that will restore the great contextures of the face and the basic form, and adding it through the actual information that refers the whole porter structure and all the fine folds.
2022-03-23 12:47:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," when the revolution begins to support you. '"the truth is that we love you at this point, we've been supporting you for a long time."
2022-03-23 12:47:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane at the proud tower was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continual variation and a cooling system with liquid that allows us to use an aircraft in a stop-go-transportation, to a specific passenger vehicle vehicle, either to a vehicle that drifting on the ground.
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:14 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.611 | ppl 195.44 | bleu 33.58 | wps 4875 | wpb 17862.2 | bsz 728.3 | num_updates 6904 | best_bleu 33.58
2022-03-23 12:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6904 updates
2022-03-23 12:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 44 @ 6904 updates, score 33.58) (writing took 1.8497581470292062 seconds)
2022-03-23 12:47:16 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:47:16 | INFO | train | epoch 044 | loss 6.343 | ppl 81.18 | wps 39932.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6904 | lr 0.000380583 | gnorm 0.304 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 4430
KL Stats: Epoch 44 Divergences: Uniform: 2.812980008829283 Unigram: 0.839406804536123
2022-03-23 12:47:16 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:53 | INFO | train_inner | epoch 045:     96 / 157 loss=6.303, ppl=78.94, wps=32610.8, ups=1.28, wpb=25382, bsz=970.5, num_updates=7000, lr=0.000377964, gnorm=0.309, loss_scale=8, train_wall=37, gb_free=11.6, wall=4467
2022-03-23 12:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:48:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:48:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:48:27 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form any glide.
2022-03-23 12:48:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:48:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:48:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with it?
2022-03-23 12:48:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weddings and not talking about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that will restore the big contexts of the face and the basic form, and put it through the actual information that refers the whole pore-structure and all the fine wrinkles.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when dinner was argued, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, then we support you. '"' the truth, love, we've already been supporting you with this theme for a long time. carchel sil
2022-03-23 12:48:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessary is the mother of invention, and a big part of the design work that we're on our airplane at the proud toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable gear and a refrigerator system that allows us to use an aircraft in the stop-go-go-transportation machine to a particular passage transportation machine to operate in a particular passing vehicle vehicle vehicle vehicle vehicle vehicle, either when you have to operate in the same way that drill you can see the same way that drives the prop.
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:54 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.593 | ppl 193.01 | bleu 33.71 | wps 4703.8 | wpb 17862.2 | bsz 728.3 | num_updates 7061 | best_bleu 33.71
2022-03-23 12:48:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7061 updates
2022-03-23 12:48:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 45 @ 7061 updates, score 33.71) (writing took 1.8661546048242599 seconds)
2022-03-23 12:48:56 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:48:56 | INFO | train | epoch 045 | loss 6.33 | ppl 80.45 | wps 39443.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7061 | lr 0.000376328 | gnorm 0.309 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 4530
KL Stats: Epoch 45 Divergences: Uniform: 2.8126977258414843 Unigram: 0.8380623515681634
2022-03-23 12:48:56 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:12 | INFO | train_inner | epoch 046:     39 / 157 loss=6.336, ppl=80.79, wps=31630.5, ups=1.26, wpb=25039.8, bsz=1104.3, num_updates=7100, lr=0.000375293, gnorm=0.299, loss_scale=8, train_wall=37, gb_free=12.3, wall=4546
2022-03-23 12:49:50 | INFO | train_inner | epoch 046:    139 / 157 loss=6.376, ppl=83.03, wps=66453.5, ups=2.66, wpb=24989.3, bsz=963.8, num_updates=7200, lr=0.000372678, gnorm=0.298, loss_scale=8, train_wall=37, gb_free=12.4, wall=4584
2022-03-23 12:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:50:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:50:04 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over the year.
2022-03-23 12:50:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:50:08 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form any glide.
2022-03-23 12:50:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:50:12 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:50:12 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:50:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:50:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:50:20 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weddings and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:50:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:50:24 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconducting boxes are disturbing.
2022-03-23 12:50:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that will restore the big contents of the face and the base form of it, and add it through the actual information that refers the whole pore-structure and all the fine wrinkles.
2022-03-23 12:50:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that -- well, when i was argued, it was best summarized when someone said, "turn you to the men in your table and say," if the revolution begins to support you. "the truth, love is that we've been supporting you for a long time."
2022-03-23 12:50:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane was on the proud of a trip, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and a cooling system with liquid that allows us to use an aircraft in stop-go-traffic until a special fit that drives the prop.
2022-03-23 12:50:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:34 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.59 | ppl 192.73 | bleu 33.83 | wps 4963.3 | wpb 17862.2 | bsz 728.3 | num_updates 7218 | best_bleu 33.83
2022-03-23 12:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7218 updates
2022-03-23 12:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 46 @ 7218 updates, score 33.83) (writing took 1.8513767439872026 seconds)
2022-03-23 12:50:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:50:35 | INFO | train | epoch 046 | loss 6.314 | ppl 79.54 | wps 39774.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7218 | lr 0.000372213 | gnorm 0.295 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 4629
KL Stats: Epoch 46 Divergences: Uniform: 2.8163055049452788 Unigram: 0.8409013609866031
2022-03-23 12:50:36 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 12:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:07 | INFO | train_inner | epoch 047:     82 / 157 loss=6.207, ppl=73.88, wps=33179.8, ups=1.29, wpb=25649.2, bsz=1125.2, num_updates=7300, lr=0.000370117, gnorm=0.298, loss_scale=8, train_wall=37, gb_free=11.6, wall=4661
2022-03-23 12:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:51:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:51:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:51:43 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over year.
2022-03-23 12:51:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:51:47 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 12:51:47 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:51:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:51:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:51:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:51:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:51:59 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weddings, not about genocide or prevalence of nuclear weapons or poverty or any corresponding topic.
2022-03-23 12:51:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:52:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders are disturbing.
2022-03-23 12:52:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can restore the big contextures of the face and the basic form, and add it through the actual information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:52:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins to support you. '"the truth, love, we've already been supporting you with this theme for a long time. carchel sil."
2022-03-23 12:52:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessary is the mother of invention, and a lot of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable gear and a refrigeration system that allows us to use an aircraft in the stop-go-transportation aircraft to a specially adapted vehicle that drives the propellers either when you're driving the propelled, or the propellers that drives the prop.
2022-03-23 12:52:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:13 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.594 | ppl 193.23 | bleu 33.84 | wps 4805.9 | wpb 17862.2 | bsz 728.3 | num_updates 7375 | best_bleu 33.84
2022-03-23 12:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7375 updates
2022-03-23 12:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:52:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 47 @ 7375 updates, score 33.84) (writing took 1.9097682600840926 seconds)
2022-03-23 12:52:15 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 12:52:15 | INFO | train | epoch 047 | loss 6.302 | ppl 78.92 | wps 39493.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7375 | lr 0.00036823 | gnorm 0.303 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 4729
KL Stats: Epoch 47 Divergences: Uniform: 2.8187490185389192 Unigram: 0.8416463849800753
2022-03-23 12:52:16 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 12:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:25 | INFO | train_inner | epoch 048:     25 / 157 loss=6.362, ppl=82.24, wps=31593, ups=1.27, wpb=24786.1, bsz=936.3, num_updates=7400, lr=0.000367607, gnorm=0.315, loss_scale=8, train_wall=37, gb_free=12.8, wall=4739
2022-03-23 12:53:03 | INFO | train_inner | epoch 048:    125 / 157 loss=6.305, ppl=79.06, wps=66573.6, ups=2.64, wpb=25251.9, bsz=1049.9, num_updates=7500, lr=0.000365148, gnorm=0.297, loss_scale=8, train_wall=38, gb_free=11.8, wall=4777
2022-03-23 12:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:53:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:53:23 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 12:53:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:53:27 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 12:53:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:53:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:53:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:53:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 12:53:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:53:39 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender weddings and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:53:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:53:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are caught inside, but the superconductor doesn't like to move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:53:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:53:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial configurations of the face and the basic form, and bring it through the one information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:53:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:53:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons why it's really interesting and appropriate for me to be here at tedwomen is that... well, when you have dinner, it was best summarized when someone said, "turn you to the men at your table and tell you," if the revolution starts to support you. "'"' the truth, love, is that we've been supporting you with this theme for a long time. "
2022-03-23 12:53:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:53:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems connected to operate on the floor -- everything from a continuously variable operating and a cooling system with liquid that allows us to use an aircraft in a stop-go-traffic, to a specific passenger, either if you're running the propelled, or if you're on the floor -- all the propelled, the way down to the floor.
2022-03-23 12:53:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:53:53 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.595 | ppl 193.4 | bleu 34.02 | wps 4821.9 | wpb 17862.2 | bsz 728.3 | num_updates 7532 | best_bleu 34.02
2022-03-23 12:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7532 updates
2022-03-23 12:53:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 48 @ 7532 updates, score 34.02) (writing took 1.8081900749821216 seconds)
2022-03-23 12:53:55 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 12:53:55 | INFO | train | epoch 048 | loss 6.288 | ppl 78.15 | wps 39836 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7532 | lr 0.000364372 | gnorm 0.305 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 4828
KL Stats: Epoch 48 Divergences: Uniform: 2.820331125964712 Unigram: 0.8430902065603476
2022-03-23 12:53:55 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 12:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:21 | INFO | train_inner | epoch 049:     68 / 157 loss=6.207, ppl=73.88, wps=32712.2, ups=1.3, wpb=25234.4, bsz=1000.1, num_updates=7600, lr=0.000362738, gnorm=0.309, loss_scale=8, train_wall=36, gb_free=12.1, wall=4854
2022-03-23 12:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:54:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:54:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:55:02 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over the year.
2022-03-23 12:55:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:55:05 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 12:55:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:55:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:55:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:55:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:55:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:55:18 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender weddings and not talking about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:55:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:55:22 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of strings of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy, and so the superconductive disorder.
2022-03-23 12:55:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:26 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional facial configurations of the face and the base form, and add it through that particular information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:55:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it was best summarized when someone said, "turn you to the men at your table and say," when the revolution starts to support you. '"' the truth, love, is that we've been supporting you at this point for a long time.
2022-03-23 12:55:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable gear, and a cooling system of fluid that allows us to use an airplane in the stop-go-traffic, to a specific passage, the propellant, or when you're on the ground -- all the propelled to the ground, all the way down the ground, all the way down to a mechanism is to the ground, and you can see the floor, and you can see, and you can see, and you can see, and you can see, you can see, you can see, you can see, you know, you can see, you can see, you know, you know, you know, you know, you can see, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 12:55:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:32 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.574 | ppl 190.59 | bleu 34.04 | wps 4714.5 | wpb 17862.2 | bsz 728.3 | num_updates 7689 | best_bleu 34.04
2022-03-23 12:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7689 updates
2022-03-23 12:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 49 @ 7689 updates, score 34.04) (writing took 1.8684618570841849 seconds)
2022-03-23 12:55:34 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 12:55:34 | INFO | train | epoch 049 | loss 6.279 | ppl 77.64 | wps 39572.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 7689 | lr 0.000360633 | gnorm 0.302 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 4928
KL Stats: Epoch 49 Divergences: Uniform: 2.8229012107721503 Unigram: 0.8440308809753575
2022-03-23 12:55:35 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 12:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:55:39 | INFO | train_inner | epoch 050:     11 / 157 loss=6.318, ppl=79.78, wps=31866.1, ups=1.28, wpb=24992.7, bsz=1013.3, num_updates=7700, lr=0.000360375, gnorm=0.299, loss_scale=8, train_wall=37, gb_free=12.5, wall=4933
2022-03-23 12:56:16 | INFO | train_inner | epoch 050:    111 / 157 loss=6.276, ppl=77.47, wps=66663, ups=2.68, wpb=24864.2, bsz=1067, num_updates=7800, lr=0.000358057, gnorm=0.326, loss_scale=8, train_wall=37, gb_free=12, wall=4970
2022-03-23 12:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:56:38 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-23 12:56:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:56:42 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant over the year.
2022-03-23 12:56:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:56:45 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these circular magnets, i can also expand to form any kind of glide.
2022-03-23 12:56:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:56:49 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father left his mother when she was pregnant with him.
2022-03-23 12:56:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:56:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:56:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:56:57 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:56:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:57:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductive disorder disturbs.
2022-03-23 12:57:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that replaces the big contents of the face and the base form, and then add it through the one information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 12:57:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when contested dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins to support you. '"' the truth, women, we've been supporting you in this topic for a long time. at rael carson, with siltheo borra, and"
2022-03-23 12:57:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a lot of the design work that we're on our airplane was a result that we had to solve the unique problems associated to operate on the ground -- everything from a continuously variable gear and a cooling system with liquid that allows us to use an aircraft in the stop-go-traffic, to a specially appropriate vehicle, either when you're pushing the propellers to the ground, or if you're going to see the automated.
2022-03-23 12:57:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:12 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.557 | ppl 188.28 | bleu 34.6 | wps 4841 | wpb 17862.2 | bsz 728.3 | num_updates 7846 | best_bleu 34.6
2022-03-23 12:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7846 updates
2022-03-23 12:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:57:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt
2022-03-23 12:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_best.pt (epoch 50 @ 7846 updates, score 34.6) (writing took 1.8386084991507232 seconds)
2022-03-23 12:57:13 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 12:57:13 | INFO | train | epoch 050 | loss 6.268 | ppl 77.08 | wps 39867.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7846 | lr 0.000357006 | gnorm 0.312 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 5027
KL Stats: Epoch 50 Divergences: Uniform: 2.823281165139029 Unigram: 0.8436081919587076
2022-03-23 12:57:14 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 12:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:57:34 | INFO | train_inner | epoch 051:     54 / 157 loss=6.239, ppl=75.54, wps=32466.7, ups=1.29, wpb=25197.1, bsz=1013.2, num_updates=7900, lr=0.000355784, gnorm=0.303, loss_scale=8, train_wall=37, gb_free=12, wall=5048
2022-03-23 12:58:12 | INFO | train_inner | epoch 051:    154 / 157 loss=6.285, ppl=77.98, wps=66901.9, ups=2.65, wpb=25255.7, bsz=981.2, num_updates=8000, lr=0.000353553, gnorm=0.289, loss_scale=8, train_wall=37, gb_free=12, wall=5086
2022-03-23 12:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:58:17 | INFO | fairseq.tasks.translation | example hypothesis: this probe cannot use chemical rockets.
2022-03-23 12:58:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:58:21 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:58:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:58:24 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these circular magnets, i can also expand to form any glide.
2022-03-23 12:58:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:58:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:58:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:58:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 12:58:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:58:36 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weddings, not about genocide or prevalence of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 12:58:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:58:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:58:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:58:44 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face, which reforms the big contexts of the face and the basic form, and add it through the information that refers the whole pore-structure and all the fine wrinkles.
2022-03-23 12:58:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:58:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, arguing, it was best summarized when someone said, "turn you to the men in your table and say," when the revolution starts to support you. '"' the truth, love is that we've been supporting you at this point for a long time. at rachel carson," then stumbling down the future. "
2022-03-23 12:58:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:58:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, nevertheless, the mother of invention, and a large part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and refrigerate system that allows us to use an aircraft in stop-go-traffic until a particular fit that drives propelled, either when you're on the ground, or when you're on the ground, you're going to see automated.
2022-03-23 12:58:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:58:50 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.572 | ppl 190.29 | bleu 34.46 | wps 4968.3 | wpb 17862.2 | bsz 728.3 | num_updates 8003 | best_bleu 34.6
2022-03-23 12:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8003 updates
2022-03-23 12:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 12:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 51 @ 8003 updates, score 34.46) (writing took 0.8462398580741137 seconds)
2022-03-23 12:58:51 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 12:58:51 | INFO | train | epoch 051 | loss 6.253 | ppl 76.28 | wps 40641.1 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 8003 | lr 0.000353487 | gnorm 0.298 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 5124
KL Stats: Epoch 51 Divergences: Uniform: 2.825772368622303 Unigram: 0.8458881581257901
2022-03-23 12:58:51 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 12:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:59:28 | INFO | train_inner | epoch 052:     97 / 157 loss=6.15, ppl=71.01, wps=33839.9, ups=1.31, wpb=25826.2, bsz=1016.4, num_updates=8100, lr=0.000351364, gnorm=0.301, loss_scale=8, train_wall=37, gb_free=12, wall=5162
2022-03-23 12:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:59:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:59:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:59:58 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:59:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 13:00:02 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can also expand to form any glide.
2022-03-23 13:00:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 13:00:06 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 13:00:06 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 13:00:10 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 13:00:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 13:00:14 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender weddings and not talking about genocide or the spread of nuclear weapons or poverty or any other corresponding topic.
2022-03-23 13:00:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 13:00:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 13:00:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:00:22 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional face, which gives back the big contextures of the face and the basic form, and add it through that particular information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 13:00:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:00:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me, is that, you know, for a long time, it was best summarized when someone said, "turn you to the men in your table and say," when the revolution starts, we support you. '"' the truth, love, is that we've been supporting you with this topic for a long time." at rael carson, silcake, and then he said, "then we turn you to downstream of sand," and then we go down to
2022-03-23 13:00:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:00:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need still the mother of invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuously variable distribution and cooling system that allows us to use an aircraft in stop-go-traffic until a specially adapted vehicle that drives the propellers at the bottom of a mechanism, until you see the propelled propellers at the same time, to the safety floor, until you can see the propellers in the same time, to be driven by a mechanism, until you can see, to be driven by a mechanism, until you can see the same time, until you can see, until you can see, until you can see, to run it's in a mechanism, until you can see that you can see that you can see it's on the auto storm in a mechanism, until you can see that you can see that's a
2022-03-23 13:00:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:00:29 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.583 | ppl 191.73 | bleu 34.07 | wps 4800.7 | wpb 17862.2 | bsz 728.3 | num_updates 8160 | best_bleu 34.6
2022-03-23 13:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8160 updates
2022-03-23 13:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 13:00:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 13:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 52 @ 8160 updates, score 34.07) (writing took 0.8483243130613118 seconds)
2022-03-23 13:00:30 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 13:00:30 | INFO | train | epoch 052 | loss 6.245 | ppl 75.84 | wps 39852.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 8160 | lr 0.00035007 | gnorm 0.306 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 5224
KL Stats: Epoch 52 Divergences: Uniform: 2.828062479997754 Unigram: 0.8474239089754296
2022-03-23 13:00:30 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 13:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:00:45 | INFO | train_inner | epoch 053:     40 / 157 loss=6.325, ppl=80.15, wps=31685.5, ups=1.29, wpb=24524.2, bsz=987.3, num_updates=8200, lr=0.000349215, gnorm=0.309, loss_scale=8, train_wall=37, gb_free=12.1, wall=5239
2022-03-23 13:01:23 | INFO | train_inner | epoch 053:    140 / 157 loss=6.263, ppl=76.77, wps=66452.8, ups=2.66, wpb=24979.5, bsz=1074.3, num_updates=8300, lr=0.000347105, gnorm=0.296, loss_scale=8, train_wall=37, gb_free=12.7, wall=5277
2022-03-23 13:01:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 13:01:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 13:01:37 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 13:01:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 13:01:41 | INFO | fairseq.tasks.translation | example hypothesis: of course, these round magnets, i can also expand to form any glide.
2022-03-23 13:01:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 13:01:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 13:01:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 13:01:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 13:01:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 13:01:53 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender weddings and not talking about genocide or prevalence of nuclear weapons or poverty or any other subject.
2022-03-23 13:01:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 13:01:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disrupts.
2022-03-23 13:01:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:02:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial sscan that resurrects the rough contextures of the face and the basic form, and add it through the one information that refers the whole pore-structure and all the fine wrinkles.
2022-03-23 13:02:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:02:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me is that... well, in the dinner, it was best summarized when someone said, "turn you to the men at your table and say," when the revolution starts, we support you. '"' the truth, love, we've been supporting you with this topic for a long time."
2022-03-23 13:02:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:02:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a lot of the design work that we're on our airplane was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuously variable drive and a cooling system with liquid, allowing us to use an aircraft in the stop-go-go-transportation until a particular passage that drives the prop.
2022-03-23 13:02:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:02:07 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.579 | ppl 191.16 | bleu 33.99 | wps 4877.1 | wpb 17862.2 | bsz 728.3 | num_updates 8317 | best_bleu 34.6
2022-03-23 13:02:07 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 13:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8317 updates
2022-03-23 13:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 13:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt
2022-03-23 13:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.0_0.35_0.65_#4/checkpoint_last.pt (epoch 53 @ 8317 updates, score 33.99) (writing took 0.8563788589090109 seconds)
2022-03-23 13:02:07 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 13:02:07 | INFO | train | epoch 053 | loss 6.234 | ppl 75.25 | wps 40364.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8317 | lr 0.00034675 | gnorm 0.3 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 5321
2022-03-23 13:02:07 | INFO | fairseq_cli.train | done training in 5321.0 seconds
