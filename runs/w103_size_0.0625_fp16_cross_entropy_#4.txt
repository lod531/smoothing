Sender: LSF System <lsfadmin@eu-g3-045>
Subject: Job 207133003: <w103_size_0.0625_fp16_cross_entropy_#4> in cluster <euler> Exited

Job <w103_size_0.0625_fp16_cross_entropy_#4> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Fri Mar  4 09:35:39 2022
Job was executed on host(s) <eu-g3-045>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Mar  4 09:36:13 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Mar  4 09:36:13 2022
Terminated at Sat Mar  5 11:25:21 2022
Results reported at Sat Mar  5 11:25:21 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575614 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   92880.41 sec.
    Max Memory :                                 8124 MB
    Average Memory :                             2389.22 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11876.00 MB
    Max Swap :                                   2613 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   92948 sec.
    Turnaround time :                            92982 sec.

The output (if any) follows:

2022-03-04 09:36:19 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575614, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-04 09:36:19 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-04 09:36:21 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-04 09:36:21 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-04 09:36:21 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-04 09:36:21 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-04 09:36:21 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-04 09:36:21 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-04 09:36:21 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-04 09:36:23 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-04 09:36:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-04 09:36:23 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-04 09:36:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-04 09:36:23 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-04 09:36:23 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-04 09:36:23 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 09:36:23 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 09:36:23 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-04 09:36:23 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-04 09:36:23 | INFO | fairseq.trainer | begin training epoch 1
2022-03-04 09:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:36:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-04 09:36:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 09:36:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 09:36:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-04 09:36:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-04 09:40:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 09:40:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.373 | ppl 21216.3 | wps 45023 | wpb 510.9 | bsz 1 | num_updates 92
2022-03-04 09:40:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 92 updates
2022-03-04 09:40:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:41:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 1 @ 92 updates, score 14.373) (writing took 4.743533151224256 seconds)
2022-03-04 09:41:04 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-04 09:41:04 | INFO | train | epoch 001 | loss 15.991 | ppl 65106.2 | wps 23634.8 | ups 0.36 | wpb 65489.2 | bsz 127.9 | num_updates 92 | lr 1.15977e-05 | gnorm 3.728 | loss_scale 4 | train_wall 249 | gb_free 8.2 | wall 280
2022-03-04 09:41:04 | INFO | fairseq.trainer | begin training epoch 2
2022-03-04 09:41:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:41:25 | INFO | train_inner | epoch 002:      8 / 97 loss=15.866, ppl=59709.5, wps=23721.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.561, loss_scale=4, train_wall=268, gb_free=8.2, wall=302
2022-03-04 09:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 09:45:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.708 | ppl 6692.67 | wps 45019.2 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 12.708
2022-03-04 09:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-04 09:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:45:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 2 @ 189 updates, score 12.708) (writing took 4.769338122569025 seconds)
2022-03-04 09:45:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-04 09:45:29 | INFO | train | epoch 002 | loss 13.714 | ppl 13441.6 | wps 23901.6 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.474 | loss_scale 8 | train_wall 234 | gb_free 8.2 | wall 546
2022-03-04 09:45:29 | INFO | fairseq.trainer | begin training epoch 3
2022-03-04 09:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:45:58 | INFO | train_inner | epoch 003:     11 / 97 loss=13.542, ppl=11931, wps=23930.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.428, loss_scale=8, train_wall=241, gb_free=8.2, wall=575
2022-03-04 09:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 09:49:50 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.082 | ppl 2167.73 | wps 45061.4 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.082
2022-03-04 09:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-04 09:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:49:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.082) (writing took 4.778779252432287 seconds)
2022-03-04 09:49:55 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-04 09:49:55 | INFO | train | epoch 003 | loss 11.904 | ppl 3831.26 | wps 23906.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 0.975 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 812
2022-03-04 09:49:55 | INFO | fairseq.trainer | begin training epoch 4
2022-03-04 09:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:50:32 | INFO | train_inner | epoch 004:     14 / 97 loss=11.694, ppl=3314.08, wps=23935.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=0.917, loss_scale=16, train_wall=242, gb_free=8.2, wall=849
2022-03-04 09:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 09:54:16 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.275 | ppl 1239.16 | wps 44843.4 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.275
2022-03-04 09:54:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-04 09:54:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.275) (writing took 4.87944068480283 seconds)
2022-03-04 09:54:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-04 09:54:21 | INFO | train | epoch 004 | loss 10.608 | ppl 1560.23 | wps 23913.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.61 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 1078
2022-03-04 09:54:21 | INFO | fairseq.trainer | begin training epoch 5
2022-03-04 09:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:55:06 | INFO | train_inner | epoch 005:     17 / 97 loss=10.481, ppl=1429.35, wps=23942.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.572, loss_scale=32, train_wall=241, gb_free=8.2, wall=1122
2022-03-04 09:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 09:58:42 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.895 | ppl 952.1 | wps 44994.5 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 9.895
2022-03-04 09:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-04 09:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:58:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 09:58:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 5 @ 480 updates, score 9.895) (writing took 4.678600207902491 seconds)
2022-03-04 09:58:46 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-04 09:58:46 | INFO | train | epoch 005 | loss 10.035 | ppl 1049.1 | wps 23926.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.476 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 1343
2022-03-04 09:58:46 | INFO | fairseq.trainer | begin training epoch 6
2022-03-04 09:58:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 09:59:39 | INFO | train_inner | epoch 006:     20 / 97 loss=9.959, ppl=995.34, wps=23945.4, ups=0.37, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.491, loss_scale=32, train_wall=242, gb_free=8.2, wall=1396
2022-03-04 10:00:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:03:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:03:07 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.589 | ppl 770.32 | wps 44738.7 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 9.589
2022-03-04 10:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-04 10:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 6 @ 576 updates, score 9.589) (writing took 4.772390140220523 seconds)
2022-03-04 10:03:12 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-04 10:03:12 | INFO | train | epoch 006 | loss 9.678 | ppl 819.08 | wps 23643.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.598 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 1609
2022-03-04 10:03:12 | INFO | fairseq.trainer | begin training epoch 7
2022-03-04 10:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:04:16 | INFO | train_inner | epoch 007:     24 / 97 loss=9.608, ppl=780.37, wps=23689.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.615, loss_scale=32, train_wall=244, gb_free=8.2, wall=1672
2022-03-04 10:06:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:07:33 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.352 | ppl 653.33 | wps 44897.4 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 9.352
2022-03-04 10:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-04 10:07:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:07:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 7 @ 672 updates, score 9.352) (writing took 4.874875381588936 seconds)
2022-03-04 10:07:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-04 10:07:38 | INFO | train | epoch 007 | loss 9.379 | ppl 665.88 | wps 23644.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.669 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 1875
2022-03-04 10:07:38 | INFO | fairseq.trainer | begin training epoch 8
2022-03-04 10:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:08:52 | INFO | train_inner | epoch 008:     28 / 97 loss=9.3, ppl=630.49, wps=23687.1, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.681, loss_scale=32, train_wall=244, gb_free=8.2, wall=1949
2022-03-04 10:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:11:59 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.135 | ppl 562.17 | wps 44782 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.135
2022-03-04 10:11:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-04 10:11:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:12:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.135) (writing took 4.99476571008563 seconds)
2022-03-04 10:12:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-04 10:12:04 | INFO | train | epoch 008 | loss 9.112 | ppl 553.26 | wps 23874.6 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.75 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 2141
2022-03-04 10:12:04 | INFO | fairseq.trainer | begin training epoch 9
2022-03-04 10:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:13:29 | INFO | train_inner | epoch 009:     32 / 97 loss=9.032, ppl=523.66, wps=23668.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.764, loss_scale=32, train_wall=244, gb_free=8.2, wall=2226
2022-03-04 10:16:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:16:26 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.927 | ppl 486.63 | wps 44773.6 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 8.927
2022-03-04 10:16:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-04 10:16:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:16:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 9 @ 865 updates, score 8.927) (writing took 4.780711300671101 seconds)
2022-03-04 10:16:30 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-04 10:16:30 | INFO | train | epoch 009 | loss 8.861 | ppl 464.81 | wps 23617.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.81 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 2407
2022-03-04 10:16:30 | INFO | fairseq.trainer | begin training epoch 10
2022-03-04 10:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:18:03 | INFO | train_inner | epoch 010:     35 / 97 loss=8.773, ppl=437.55, wps=23889.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.813, loss_scale=32, train_wall=242, gb_free=8.2, wall=2500
2022-03-04 10:18:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:20:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:20:52 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.739 | ppl 427.19 | wps 45012.1 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 8.739
2022-03-04 10:20:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-04 10:20:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:20:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 10 @ 961 updates, score 8.739) (writing took 4.7687059892341495 seconds)
2022-03-04 10:20:57 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-04 10:20:57 | INFO | train | epoch 010 | loss 8.625 | ppl 394.92 | wps 23623.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.831 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 2673
2022-03-04 10:20:57 | INFO | fairseq.trainer | begin training epoch 11
2022-03-04 10:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:22:40 | INFO | train_inner | epoch 011:     39 / 97 loss=8.545, ppl=373.48, wps=23679, ups=0.36, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.904, loss_scale=32, train_wall=244, gb_free=8.2, wall=2776
2022-03-04 10:24:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:25:18 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.574 | ppl 381.02 | wps 44383.3 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 8.574
2022-03-04 10:25:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-04 10:25:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:25:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 11 @ 1057 updates, score 8.574) (writing took 4.79065344016999 seconds)
2022-03-04 10:25:22 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-04 10:25:22 | INFO | train | epoch 011 | loss 8.409 | ppl 339.92 | wps 23654.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.893 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 2939
2022-03-04 10:25:22 | INFO | fairseq.trainer | begin training epoch 12
2022-03-04 10:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:27:16 | INFO | train_inner | epoch 012:     43 / 97 loss=8.319, ppl=319.32, wps=23701.1, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.924, loss_scale=32, train_wall=244, gb_free=8.2, wall=3053
2022-03-04 10:29:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:29:43 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.41 | ppl 340.07 | wps 44903.2 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 8.41
2022-03-04 10:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-04 10:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:29:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:29:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 12 @ 1154 updates, score 8.41) (writing took 4.638383099809289 seconds)
2022-03-04 10:29:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-04 10:29:48 | INFO | train | epoch 012 | loss 8.213 | ppl 296.81 | wps 23906.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.962 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 3205
2022-03-04 10:29:48 | INFO | fairseq.trainer | begin training epoch 13
2022-03-04 10:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:30:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:31:52 | INFO | train_inner | epoch 013:     47 / 97 loss=8.125, ppl=279.26, wps=23691.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.895, loss_scale=32, train_wall=244, gb_free=8.2, wall=3329
2022-03-04 10:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:34:09 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.288 | ppl 312.67 | wps 44765.2 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 8.288
2022-03-04 10:34:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-04 10:34:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:34:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 13 @ 1250 updates, score 8.288) (writing took 4.730837148614228 seconds)
2022-03-04 10:34:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-04 10:34:14 | INFO | train | epoch 013 | loss 8.027 | ppl 260.9 | wps 23636.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.92 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 3471
2022-03-04 10:34:14 | INFO | fairseq.trainer | begin training epoch 14
2022-03-04 10:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:36:26 | INFO | train_inner | epoch 014:     50 / 97 loss=7.943, ppl=246.17, wps=23908.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.971, loss_scale=32, train_wall=242, gb_free=8.2, wall=3603
2022-03-04 10:36:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:38:35 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.158 | ppl 285.7 | wps 45035.6 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 8.158
2022-03-04 10:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-04 10:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:38:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 14 @ 1346 updates, score 8.158) (writing took 4.781549879349768 seconds)
2022-03-04 10:38:40 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-04 10:38:40 | INFO | train | epoch 014 | loss 7.852 | ppl 231.02 | wps 23642.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.978 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 3737
2022-03-04 10:38:40 | INFO | fairseq.trainer | begin training epoch 15
2022-03-04 10:38:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:41:03 | INFO | train_inner | epoch 015:     54 / 97 loss=7.752, ppl=215.62, wps=23677.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.981, loss_scale=32, train_wall=244, gb_free=8.2, wall=3880
2022-03-04 10:42:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:42:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:43:01 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.062 | ppl 267.21 | wps 44773.2 | wpb 510.9 | bsz 1 | num_updates 1442 | best_loss 8.062
2022-03-04 10:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1442 updates
2022-03-04 10:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 15 @ 1442 updates, score 8.062) (writing took 4.971222884021699 seconds)
2022-03-04 10:43:06 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-04 10:43:06 | INFO | train | epoch 015 | loss 7.681 | ppl 205.21 | wps 23617.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1442 | lr 0.000180314 | gnorm 0.972 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 4003
2022-03-04 10:43:06 | INFO | fairseq.trainer | begin training epoch 16
2022-03-04 10:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:45:39 | INFO | train_inner | epoch 016:     58 / 97 loss=7.585, ppl=192.01, wps=23675.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.979, loss_scale=32, train_wall=244, gb_free=8.2, wall=4156
2022-03-04 10:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:47:27 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.97 | ppl 250.81 | wps 44810.4 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 7.97
2022-03-04 10:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-04 10:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 16 @ 1539 updates, score 7.97) (writing took 4.742392046377063 seconds)
2022-03-04 10:47:32 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-04 10:47:32 | INFO | train | epoch 016 | loss 7.515 | ppl 182.93 | wps 23895.2 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.983 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 4269
2022-03-04 10:47:32 | INFO | fairseq.trainer | begin training epoch 17
2022-03-04 10:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:49:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:50:16 | INFO | train_inner | epoch 017:     62 / 97 loss=7.418, ppl=171.07, wps=23689.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.997, loss_scale=32, train_wall=244, gb_free=8.2, wall=4433
2022-03-04 10:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:51:53 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.876 | ppl 234.93 | wps 44950.2 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 7.876
2022-03-04 10:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-04 10:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 17 @ 1635 updates, score 7.876) (writing took 4.774820542894304 seconds)
2022-03-04 10:51:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-04 10:51:58 | INFO | train | epoch 017 | loss 7.351 | ppl 163.27 | wps 23634.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.987 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 4535
2022-03-04 10:51:58 | INFO | fairseq.trainer | begin training epoch 18
2022-03-04 10:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:54:50 | INFO | train_inner | epoch 018:     65 / 97 loss=7.242, ppl=151.35, wps=23901.7, ups=0.36, wpb=65495, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.975, loss_scale=32, train_wall=242, gb_free=8.2, wall=4707
2022-03-04 10:55:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 10:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 10:56:19 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.822 | ppl 226.23 | wps 44941.8 | wpb 510.9 | bsz 1 | num_updates 1731 | best_loss 7.822
2022-03-04 10:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1731 updates
2022-03-04 10:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 10:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 18 @ 1731 updates, score 7.822) (writing took 4.751167917624116 seconds)
2022-03-04 10:56:24 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-04 10:56:24 | INFO | train | epoch 018 | loss 7.19 | ppl 146 | wps 23638.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1731 | lr 0.000216432 | gnorm 0.99 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 4801
2022-03-04 10:56:24 | INFO | fairseq.trainer | begin training epoch 19
2022-03-04 10:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 10:59:26 | INFO | train_inner | epoch 019:     69 / 97 loss=7.082, ppl=135.46, wps=23688.7, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.979, loss_scale=32, train_wall=244, gb_free=8.2, wall=4983
2022-03-04 11:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:00:45 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.761 | ppl 216.86 | wps 44823.5 | wpb 510.9 | bsz 1 | num_updates 1828 | best_loss 7.761
2022-03-04 11:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1828 updates
2022-03-04 11:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 19 @ 1828 updates, score 7.761) (writing took 4.610748773440719 seconds)
2022-03-04 11:00:50 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-04 11:00:50 | INFO | train | epoch 019 | loss 7.034 | ppl 131.02 | wps 23895 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 1828 | lr 0.000228554 | gnorm 0.991 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 5067
2022-03-04 11:00:50 | INFO | fairseq.trainer | begin training epoch 20
2022-03-04 11:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:02:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:04:03 | INFO | train_inner | epoch 020:     73 / 97 loss=6.922, ppl=121.23, wps=23685.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.995, loss_scale=32, train_wall=244, gb_free=8.2, wall=5260
2022-03-04 11:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:05:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.704 | ppl 208.54 | wps 44830.4 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 7.704
2022-03-04 11:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-04 11:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 20 @ 1924 updates, score 7.704) (writing took 4.999573301523924 seconds)
2022-03-04 11:05:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-04 11:05:16 | INFO | train | epoch 020 | loss 6.879 | ppl 117.67 | wps 23615.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.974 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 5333
2022-03-04 11:05:16 | INFO | fairseq.trainer | begin training epoch 21
2022-03-04 11:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:08:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:08:40 | INFO | train_inner | epoch 021:     77 / 97 loss=6.764, ppl=108.69, wps=23674.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.975, loss_scale=32, train_wall=244, gb_free=8.2, wall=5536
2022-03-04 11:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:09:37 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.694 | ppl 207.05 | wps 44964.3 | wpb 510.9 | bsz 1 | num_updates 2020 | best_loss 7.694
2022-03-04 11:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2020 updates
2022-03-04 11:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:09:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 21 @ 2020 updates, score 7.694) (writing took 4.7386390352621675 seconds)
2022-03-04 11:09:42 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-04 11:09:42 | INFO | train | epoch 021 | loss 6.732 | ppl 106.31 | wps 23654.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2020 | lr 0.00025255 | gnorm 0.983 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 5599
2022-03-04 11:09:42 | INFO | fairseq.trainer | begin training epoch 22
2022-03-04 11:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:13:14 | INFO | train_inner | epoch 022:     80 / 97 loss=6.616, ppl=98.1, wps=23901.4, ups=0.36, wpb=65495, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.996, loss_scale=32, train_wall=242, gb_free=8.2, wall=5810
2022-03-04 11:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:14:03 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.643 | ppl 199.92 | wps 44663.3 | wpb 510.9 | bsz 1 | num_updates 2117 | best_loss 7.643
2022-03-04 11:14:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2117 updates
2022-03-04 11:14:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:14:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 22 @ 2117 updates, score 7.643) (writing took 4.723921759985387 seconds)
2022-03-04 11:14:08 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-04 11:14:08 | INFO | train | epoch 022 | loss 6.591 | ppl 96.37 | wps 23868.8 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 2117 | lr 0.000264672 | gnorm 1 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 5865
2022-03-04 11:14:08 | INFO | fairseq.trainer | begin training epoch 23
2022-03-04 11:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:17:50 | INFO | train_inner | epoch 023:     84 / 97 loss=6.47, ppl=88.62, wps=23678.9, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.978, loss_scale=32, train_wall=244, gb_free=8.2, wall=6087
2022-03-04 11:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:18:29 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.632 | ppl 198.35 | wps 44987.9 | wpb 510.9 | bsz 1 | num_updates 2213 | best_loss 7.632
2022-03-04 11:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2213 updates
2022-03-04 11:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:18:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt
2022-03-04 11:18:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_best.pt (epoch 23 @ 2213 updates, score 7.632) (writing took 4.765802870504558 seconds)
2022-03-04 11:18:34 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-04 11:18:34 | INFO | train | epoch 023 | loss 6.449 | ppl 87.34 | wps 23637.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2213 | lr 0.00027667 | gnorm 0.981 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 6131
2022-03-04 11:18:34 | INFO | fairseq.trainer | begin training epoch 24
2022-03-04 11:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:20:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:22:27 | INFO | train_inner | epoch 024:     88 / 97 loss=6.335, ppl=80.75, wps=23674.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=1.005, loss_scale=32, train_wall=244, gb_free=8.2, wall=6364
2022-03-04 11:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:22:55 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.667 | ppl 203.23 | wps 44874 | wpb 510.9 | bsz 1 | num_updates 2309 | best_loss 7.632
2022-03-04 11:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2309 updates
2022-03-04 11:22:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:22:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:22:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 24 @ 2309 updates, score 7.667) (writing took 2.223272727802396 seconds)
2022-03-04 11:22:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-04 11:22:58 | INFO | train | epoch 024 | loss 6.314 | ppl 79.57 | wps 23855.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2309 | lr 0.000288667 | gnorm 0.992 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 6394
2022-03-04 11:22:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-04 11:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:26:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:27:01 | INFO | train_inner | epoch 025:     92 / 97 loss=6.192, ppl=73.1, wps=23909.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.973, loss_scale=32, train_wall=244, gb_free=8.2, wall=6638
2022-03-04 11:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:27:19 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.67 | ppl 203.62 | wps 44780.9 | wpb 510.9 | bsz 1 | num_updates 2405 | best_loss 7.632
2022-03-04 11:27:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2405 updates
2022-03-04 11:27:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:27:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:27:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 25 @ 2405 updates, score 7.67) (writing took 2.239593256264925 seconds)
2022-03-04 11:27:21 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-04 11:27:21 | INFO | train | epoch 025 | loss 6.182 | ppl 72.59 | wps 23869.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2405 | lr 0.000300665 | gnorm 0.975 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 6658
2022-03-04 11:27:21 | INFO | fairseq.trainer | begin training epoch 26
2022-03-04 11:27:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:31:32 | INFO | train_inner | epoch 026:     95 / 97 loss=6.063, ppl=66.87, wps=24124.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=1.022, loss_scale=32, train_wall=242, gb_free=8.2, wall=6909
2022-03-04 11:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:31:42 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.689 | ppl 206.32 | wps 45174.7 | wpb 510.9 | bsz 1 | num_updates 2502 | best_loss 7.632
2022-03-04 11:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2502 updates
2022-03-04 11:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:31:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:31:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 26 @ 2502 updates, score 7.689) (writing took 2.229889548383653 seconds)
2022-03-04 11:31:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-04 11:31:45 | INFO | train | epoch 026 | loss 6.058 | ppl 66.62 | wps 24107.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 2502 | lr 0.000312787 | gnorm 1.03 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 6921
2022-03-04 11:31:45 | INFO | fairseq.trainer | begin training epoch 27
2022-03-04 11:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:33:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:36:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:36:06 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.751 | ppl 215.36 | wps 44863.9 | wpb 510.9 | bsz 1 | num_updates 2598 | best_loss 7.632
2022-03-04 11:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2598 updates
2022-03-04 11:36:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 27 @ 2598 updates, score 7.751) (writing took 2.27391211502254 seconds)
2022-03-04 11:36:08 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-04 11:36:08 | INFO | train | epoch 027 | loss 5.93 | ppl 60.97 | wps 23867.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2598 | lr 0.000324785 | gnorm 0.986 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 7185
2022-03-04 11:36:08 | INFO | fairseq.trainer | begin training epoch 28
2022-03-04 11:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:36:13 | INFO | train_inner | epoch 028:      2 / 97 loss=5.93, ppl=60.99, wps=23287.6, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.988, loss_scale=32, train_wall=244, gb_free=8.2, wall=7190
2022-03-04 11:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:40:29 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.881 | ppl 235.73 | wps 44860.4 | wpb 510.9 | bsz 1 | num_updates 2694 | best_loss 7.632
2022-03-04 11:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2694 updates
2022-03-04 11:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 28 @ 2694 updates, score 7.881) (writing took 2.275346296839416 seconds)
2022-03-04 11:40:31 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-04 11:40:31 | INFO | train | epoch 028 | loss 5.807 | ppl 55.97 | wps 23857 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2694 | lr 0.000336783 | gnorm 0.993 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 7448
2022-03-04 11:40:31 | INFO | fairseq.trainer | begin training epoch 29
2022-03-04 11:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:40:47 | INFO | train_inner | epoch 029:      6 / 97 loss=5.799, ppl=55.67, wps=23895.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.992, loss_scale=32, train_wall=244, gb_free=8.2, wall=7464
2022-03-04 11:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:44:53 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.868 | ppl 233.56 | wps 44831.1 | wpb 510.9 | bsz 1 | num_updates 2791 | best_loss 7.632
2022-03-04 11:44:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2791 updates
2022-03-04 11:44:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 29 @ 2791 updates, score 7.868) (writing took 2.2433960419148207 seconds)
2022-03-04 11:44:55 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-04 11:44:55 | INFO | train | epoch 029 | loss 5.686 | ppl 51.5 | wps 24099.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 2791 | lr 0.000348905 | gnorm 1.02 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 7712
2022-03-04 11:44:55 | INFO | fairseq.trainer | begin training epoch 30
2022-03-04 11:44:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:45:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:45:22 | INFO | train_inner | epoch 030:     10 / 97 loss=5.675, ppl=51.1, wps=23888.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=1.037, loss_scale=32, train_wall=244, gb_free=8.2, wall=7738
2022-03-04 11:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:49:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.01 | ppl 257.75 | wps 44999.4 | wpb 510.9 | bsz 1 | num_updates 2887 | best_loss 7.632
2022-03-04 11:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2887 updates
2022-03-04 11:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:49:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 30 @ 2887 updates, score 8.01) (writing took 2.2755240984261036 seconds)
2022-03-04 11:49:19 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-04 11:49:19 | INFO | train | epoch 030 | loss 5.567 | ppl 47.41 | wps 23863.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2887 | lr 0.000360903 | gnorm 1.031 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 7975
2022-03-04 11:49:19 | INFO | fairseq.trainer | begin training epoch 31
2022-03-04 11:49:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:49:53 | INFO | train_inner | epoch 031:     13 / 97 loss=5.548, ppl=46.78, wps=24134.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=1.005, loss_scale=32, train_wall=242, gb_free=8.2, wall=8010
2022-03-04 11:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 11:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:53:40 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.061 | ppl 267 | wps 44805.9 | wpb 510.9 | bsz 1 | num_updates 2983 | best_loss 7.632
2022-03-04 11:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2983 updates
2022-03-04 11:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 31 @ 2983 updates, score 8.061) (writing took 2.1147867450490594 seconds)
2022-03-04 11:53:42 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-04 11:53:42 | INFO | train | epoch 031 | loss 5.452 | ppl 43.76 | wps 23865 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 2983 | lr 0.0003729 | gnorm 1.042 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 8239
2022-03-04 11:53:42 | INFO | fairseq.trainer | begin training epoch 32
2022-03-04 11:53:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:54:27 | INFO | train_inner | epoch 032:     17 / 97 loss=5.43, ppl=43.12, wps=23901.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=1.039, loss_scale=32, train_wall=244, gb_free=8.2, wall=8284
2022-03-04 11:56:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 11:57:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 11:58:03 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.151 | ppl 284.17 | wps 44715.9 | wpb 510.9 | bsz 1 | num_updates 3079 | best_loss 7.632
2022-03-04 11:58:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3079 updates
2022-03-04 11:58:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 11:58:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 32 @ 3079 updates, score 8.151) (writing took 2.204022674821317 seconds)
2022-03-04 11:58:05 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-04 11:58:05 | INFO | train | epoch 032 | loss 5.337 | ppl 40.41 | wps 23875.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3079 | lr 0.000384898 | gnorm 1.024 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 8502
2022-03-04 11:58:05 | INFO | fairseq.trainer | begin training epoch 33
2022-03-04 11:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 11:59:01 | INFO | train_inner | epoch 033:     21 / 97 loss=5.314, ppl=39.77, wps=23910.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=1.06, loss_scale=16, train_wall=244, gb_free=8.2, wall=8558
2022-03-04 12:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:02:26 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.169 | ppl 287.87 | wps 45078.2 | wpb 510.9 | bsz 1 | num_updates 3176 | best_loss 7.632
2022-03-04 12:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3176 updates
2022-03-04 12:02:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:02:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:02:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 33 @ 3176 updates, score 8.169) (writing took 2.240361839532852 seconds)
2022-03-04 12:02:29 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-04 12:02:29 | INFO | train | epoch 033 | loss 5.224 | ppl 37.38 | wps 24123.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 3176 | lr 0.000397021 | gnorm 1.078 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 8765
2022-03-04 12:02:29 | INFO | fairseq.trainer | begin training epoch 34
2022-03-04 12:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:03:32 | INFO | train_inner | epoch 034:     24 / 97 loss=5.195, ppl=36.63, wps=24143.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=1.069, loss_scale=32, train_wall=242, gb_free=8.2, wall=8829
2022-03-04 12:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:06:50 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.321 | ppl 319.7 | wps 44914.5 | wpb 510.9 | bsz 1 | num_updates 3273 | best_loss 7.632
2022-03-04 12:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3273 updates
2022-03-04 12:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 34 @ 3273 updates, score 8.321) (writing took 2.2714067129418254 seconds)
2022-03-04 12:06:52 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-04 12:06:52 | INFO | train | epoch 034 | loss 5.111 | ppl 34.57 | wps 24095.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 3273 | lr 0.000409143 | gnorm 1.09 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 9029
2022-03-04 12:06:52 | INFO | fairseq.trainer | begin training epoch 35
2022-03-04 12:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:08:04 | INFO | train_inner | epoch 035:     27 / 97 loss=5.077, ppl=33.75, wps=24112.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=1.079, loss_scale=32, train_wall=242, gb_free=8.2, wall=9101
2022-03-04 12:08:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 12:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:11:13 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.382 | ppl 333.7 | wps 44724.8 | wpb 510.9 | bsz 1 | num_updates 3369 | best_loss 7.632
2022-03-04 12:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3369 updates
2022-03-04 12:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 35 @ 3369 updates, score 8.382) (writing took 2.2198760211467743 seconds)
2022-03-04 12:11:16 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-04 12:11:16 | INFO | train | epoch 035 | loss 4.997 | ppl 31.94 | wps 23876.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3369 | lr 0.000421141 | gnorm 1.074 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 9292
2022-03-04 12:11:16 | INFO | fairseq.trainer | begin training epoch 36
2022-03-04 12:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:12:38 | INFO | train_inner | epoch 036:     31 / 97 loss=4.965, ppl=31.22, wps=23906.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=1.081, loss_scale=32, train_wall=244, gb_free=8.2, wall=9375
2022-03-04 12:14:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 12:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:15:37 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.379 | ppl 332.91 | wps 44693.1 | wpb 510.9 | bsz 1 | num_updates 3465 | best_loss 7.632
2022-03-04 12:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3465 updates
2022-03-04 12:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 36 @ 3465 updates, score 8.379) (writing took 2.1890524914488196 seconds)
2022-03-04 12:15:39 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-04 12:15:39 | INFO | train | epoch 036 | loss 4.891 | ppl 29.67 | wps 23843.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3465 | lr 0.000433138 | gnorm 1.116 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 9556
2022-03-04 12:15:39 | INFO | fairseq.trainer | begin training epoch 37
2022-03-04 12:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:17:12 | INFO | train_inner | epoch 037:     35 / 97 loss=4.849, ppl=28.82, wps=23882.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=1.091, loss_scale=32, train_wall=244, gb_free=8.2, wall=9649
2022-03-04 12:17:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:20:01 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.592 | ppl 385.89 | wps 44777.3 | wpb 510.9 | bsz 1 | num_updates 3561 | best_loss 7.632
2022-03-04 12:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3561 updates
2022-03-04 12:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 37 @ 3561 updates, score 8.592) (writing took 2.1634872537106276 seconds)
2022-03-04 12:20:03 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-04 12:20:03 | INFO | train | epoch 037 | loss 4.782 | ppl 27.51 | wps 23864.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3561 | lr 0.000445136 | gnorm 1.089 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 9820
2022-03-04 12:20:03 | INFO | fairseq.trainer | begin training epoch 38
2022-03-04 12:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:21:46 | INFO | train_inner | epoch 038:     39 / 97 loss=4.744, ppl=26.8, wps=23898.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=1.164, loss_scale=16, train_wall=244, gb_free=8.2, wall=9923
2022-03-04 12:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:24:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:24:24 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.573 | ppl 380.73 | wps 45005.8 | wpb 510.9 | bsz 1 | num_updates 3657 | best_loss 7.632
2022-03-04 12:24:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3657 updates
2022-03-04 12:24:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:24:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:24:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 38 @ 3657 updates, score 8.573) (writing took 2.131908630952239 seconds)
2022-03-04 12:24:26 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-04 12:24:26 | INFO | train | epoch 038 | loss 4.687 | ppl 25.76 | wps 23870.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3657 | lr 0.000457134 | gnorm 1.158 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 10083
2022-03-04 12:24:26 | INFO | fairseq.trainer | begin training epoch 39
2022-03-04 12:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:26:20 | INFO | train_inner | epoch 039:     43 / 97 loss=4.63, ppl=24.77, wps=23892.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.117, loss_scale=16, train_wall=244, gb_free=8.2, wall=10197
2022-03-04 12:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:28:48 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.709 | ppl 418.39 | wps 44840.1 | wpb 510.9 | bsz 1 | num_updates 3754 | best_loss 7.632
2022-03-04 12:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3754 updates
2022-03-04 12:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 39 @ 3754 updates, score 8.709) (writing took 2.0523574352264404 seconds)
2022-03-04 12:28:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-04 12:28:50 | INFO | train | epoch 039 | loss 4.573 | ppl 23.81 | wps 24108.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 3754 | lr 0.000469256 | gnorm 1.112 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 10346
2022-03-04 12:28:50 | INFO | fairseq.trainer | begin training epoch 40
2022-03-04 12:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:30:51 | INFO | train_inner | epoch 040:     46 / 97 loss=4.533, ppl=23.14, wps=24149.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.12, loss_scale=32, train_wall=242, gb_free=8.2, wall=10468
2022-03-04 12:30:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:33:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:33:11 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.846 | ppl 460.21 | wps 44775 | wpb 510.9 | bsz 1 | num_updates 3850 | best_loss 7.632
2022-03-04 12:33:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3850 updates
2022-03-04 12:33:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 40 @ 3850 updates, score 8.846) (writing took 2.13910916633904 seconds)
2022-03-04 12:33:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-04 12:33:13 | INFO | train | epoch 040 | loss 4.47 | ppl 22.17 | wps 23875.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 3850 | lr 0.000481254 | gnorm 1.138 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 10610
2022-03-04 12:33:13 | INFO | fairseq.trainer | begin training epoch 41
2022-03-04 12:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:35:25 | INFO | train_inner | epoch 041:     50 / 97 loss=4.42, ppl=21.41, wps=23898.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.162, loss_scale=16, train_wall=244, gb_free=8.2, wall=10742
2022-03-04 12:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:37:34 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.919 | ppl 483.94 | wps 44662.4 | wpb 510.9 | bsz 1 | num_updates 3947 | best_loss 7.632
2022-03-04 12:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3947 updates
2022-03-04 12:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:37:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:37:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 41 @ 3947 updates, score 8.919) (writing took 2.083825923502445 seconds)
2022-03-04 12:37:37 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-04 12:37:37 | INFO | train | epoch 041 | loss 4.371 | ppl 20.69 | wps 24103.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 3947 | lr 0.000493376 | gnorm 1.177 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 10873
2022-03-04 12:37:37 | INFO | fairseq.trainer | begin training epoch 42
2022-03-04 12:37:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:39:59 | INFO | train_inner | epoch 042:     54 / 97 loss=4.311, ppl=19.86, wps=23897.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.159, loss_scale=16, train_wall=244, gb_free=8.2, wall=11016
2022-03-04 12:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:41:58 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.115 | ppl 554.62 | wps 44808.1 | wpb 510.9 | bsz 1 | num_updates 4043 | best_loss 7.632
2022-03-04 12:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4043 updates
2022-03-04 12:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 42 @ 4043 updates, score 9.115) (writing took 2.109945205040276 seconds)
2022-03-04 12:42:00 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-04 12:42:00 | INFO | train | epoch 042 | loss 4.27 | ppl 19.3 | wps 23868.5 | ups 0.36 | wpb 65493.3 | bsz 127.9 | num_updates 4043 | lr 0.000497334 | gnorm 1.171 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 11137
2022-03-04 12:42:00 | INFO | fairseq.trainer | begin training epoch 43
2022-03-04 12:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:44:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:44:33 | INFO | train_inner | epoch 043:     58 / 97 loss=4.209, ppl=18.49, wps=23914.6, ups=0.37, wpb=65495, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.173, loss_scale=16, train_wall=244, gb_free=8.2, wall=11290
2022-03-04 12:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:46:21 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.056 | ppl 532.2 | wps 44771.3 | wpb 510.9 | bsz 1 | num_updates 4139 | best_loss 7.632
2022-03-04 12:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4139 updates
2022-03-04 12:46:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:46:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 43 @ 4139 updates, score 9.056) (writing took 2.148960070684552 seconds)
2022-03-04 12:46:23 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-04 12:46:23 | INFO | train | epoch 043 | loss 4.163 | ppl 17.91 | wps 23880.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 4139 | lr 0.000491533 | gnorm 1.137 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 11400
2022-03-04 12:46:23 | INFO | fairseq.trainer | begin training epoch 44
2022-03-04 12:46:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:49:05 | INFO | train_inner | epoch 044:     61 / 97 loss=4.102, ppl=17.18, wps=24143.3, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.126, loss_scale=16, train_wall=242, gb_free=8.2, wall=11561
2022-03-04 12:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:50:44 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.09 | ppl 544.89 | wps 44901.5 | wpb 510.9 | bsz 1 | num_updates 4236 | best_loss 7.632
2022-03-04 12:50:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4236 updates
2022-03-04 12:50:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:50:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:50:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 44 @ 4236 updates, score 9.09) (writing took 2.230361589230597 seconds)
2022-03-04 12:50:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-04 12:50:47 | INFO | train | epoch 044 | loss 4.061 | ppl 16.69 | wps 24118.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 4236 | lr 0.000485872 | gnorm 1.139 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 11663
2022-03-04 12:50:47 | INFO | fairseq.trainer | begin training epoch 45
2022-03-04 12:50:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:51:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 12:53:39 | INFO | train_inner | epoch 045:     65 / 97 loss=3.997, ppl=15.96, wps=23895, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.117, loss_scale=16, train_wall=244, gb_free=8.2, wall=11835
2022-03-04 12:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:55:08 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.181 | ppl 580.5 | wps 44831.5 | wpb 510.9 | bsz 1 | num_updates 4332 | best_loss 7.632
2022-03-04 12:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4332 updates
2022-03-04 12:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 45 @ 4332 updates, score 9.181) (writing took 2.072487933561206 seconds)
2022-03-04 12:55:10 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-04 12:55:10 | INFO | train | epoch 045 | loss 3.955 | ppl 15.5 | wps 23873.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 4332 | lr 0.000480458 | gnorm 1.102 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 11927
2022-03-04 12:55:10 | INFO | fairseq.trainer | begin training epoch 46
2022-03-04 12:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 12:58:10 | INFO | train_inner | epoch 046:     68 / 97 loss=3.889, ppl=14.82, wps=24127.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.126, loss_scale=32, train_wall=242, gb_free=8.2, wall=12107
2022-03-04 12:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 12:59:31 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.358 | ppl 656.22 | wps 44801.4 | wpb 510.9 | bsz 1 | num_updates 4429 | best_loss 7.632
2022-03-04 12:59:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4429 updates
2022-03-04 12:59:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:59:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 12:59:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 46 @ 4429 updates, score 9.358) (writing took 2.117299816571176 seconds)
2022-03-04 12:59:34 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-04 12:59:34 | INFO | train | epoch 046 | loss 3.859 | ppl 14.51 | wps 24099.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 4429 | lr 0.000475168 | gnorm 1.129 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 12190
2022-03-04 12:59:34 | INFO | fairseq.trainer | begin training epoch 47
2022-03-04 12:59:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:02:41 | INFO | train_inner | epoch 047:     71 / 97 loss=3.793, ppl=13.86, wps=24146.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=1.135, loss_scale=32, train_wall=242, gb_free=8.2, wall=12378
2022-03-04 13:03:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 13:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:03:55 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.404 | ppl 677.4 | wps 44779.7 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 7.632
2022-03-04 13:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4525 updates
2022-03-04 13:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 47 @ 4525 updates, score 9.404) (writing took 2.141984734684229 seconds)
2022-03-04 13:03:57 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-04 13:03:57 | INFO | train | epoch 047 | loss 3.762 | ppl 13.57 | wps 23874 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 4525 | lr 0.0004701 | gnorm 1.126 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 12454
2022-03-04 13:03:57 | INFO | fairseq.trainer | begin training epoch 48
2022-03-04 13:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:07:16 | INFO | train_inner | epoch 048:     75 / 97 loss=3.693, ppl=12.93, wps=23883.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=1.105, loss_scale=32, train_wall=244, gb_free=8.2, wall=12652
2022-03-04 13:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:08:19 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.503 | ppl 725.5 | wps 44755.4 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 7.632
2022-03-04 13:08:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4622 updates
2022-03-04 13:08:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:08:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:08:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 48 @ 4622 updates, score 9.503) (writing took 2.1256372462958097 seconds)
2022-03-04 13:08:21 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-04 13:08:21 | INFO | train | epoch 048 | loss 3.671 | ppl 12.74 | wps 24086.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 4622 | lr 0.000465141 | gnorm 1.111 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 12718
2022-03-04 13:08:21 | INFO | fairseq.trainer | begin training epoch 49
2022-03-04 13:08:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:09:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 13:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 13:11:52 | INFO | train_inner | epoch 049:     80 / 97 loss=3.607, ppl=12.18, wps=23667.4, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.111, loss_scale=16, train_wall=247, gb_free=8.2, wall=12929
2022-03-04 13:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:12:42 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.594 | ppl 772.94 | wps 44923.4 | wpb 510.9 | bsz 1 | num_updates 4717 | best_loss 7.632
2022-03-04 13:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4717 updates
2022-03-04 13:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:12:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:12:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 49 @ 4717 updates, score 9.594) (writing took 2.2282730899751186 seconds)
2022-03-04 13:12:44 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-04 13:12:44 | INFO | train | epoch 049 | loss 3.585 | ppl 12 | wps 23618.4 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 4717 | lr 0.000460434 | gnorm 1.124 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 12981
2022-03-04 13:12:44 | INFO | fairseq.trainer | begin training epoch 50
2022-03-04 13:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:15:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 13:16:26 | INFO | train_inner | epoch 050:     84 / 97 loss=3.514, ppl=11.43, wps=23915, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=1.124, loss_scale=16, train_wall=244, gb_free=8.2, wall=13203
2022-03-04 13:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:17:05 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.654 | ppl 805.71 | wps 44749.5 | wpb 510.9 | bsz 1 | num_updates 4813 | best_loss 7.632
2022-03-04 13:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4813 updates
2022-03-04 13:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 50 @ 4813 updates, score 9.654) (writing took 2.0852390276268125 seconds)
2022-03-04 13:17:07 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-04 13:17:07 | INFO | train | epoch 050 | loss 3.497 | ppl 11.29 | wps 23885.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 4813 | lr 0.000455819 | gnorm 1.113 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 13244
2022-03-04 13:17:07 | INFO | fairseq.trainer | begin training epoch 51
2022-03-04 13:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:20:57 | INFO | train_inner | epoch 051:     87 / 97 loss=3.43, ppl=10.78, wps=24131.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=1.119, loss_scale=16, train_wall=242, gb_free=8.2, wall=13474
2022-03-04 13:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:21:29 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.932 | ppl 977.04 | wps 44719.1 | wpb 510.9 | bsz 1 | num_updates 4910 | best_loss 7.632
2022-03-04 13:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4910 updates
2022-03-04 13:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 51 @ 4910 updates, score 9.932) (writing took 2.0973561825230718 seconds)
2022-03-04 13:21:31 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-04 13:21:31 | INFO | train | epoch 051 | loss 3.42 | ppl 10.7 | wps 24108.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 4910 | lr 0.000451294 | gnorm 1.13 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 13508
2022-03-04 13:21:31 | INFO | fairseq.trainer | begin training epoch 52
2022-03-04 13:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:25:29 | INFO | train_inner | epoch 052:     90 / 97 loss=3.351, ppl=10.2, wps=24113.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.105, loss_scale=32, train_wall=242, gb_free=8.2, wall=13746
2022-03-04 13:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:25:52 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.982 | ppl 1011.5 | wps 44764.9 | wpb 510.9 | bsz 1 | num_updates 5007 | best_loss 7.632
2022-03-04 13:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5007 updates
2022-03-04 13:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:25:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:25:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 52 @ 5007 updates, score 9.982) (writing took 2.189286875538528 seconds)
2022-03-04 13:25:55 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-04 13:25:55 | INFO | train | epoch 052 | loss 3.338 | ppl 10.11 | wps 24086 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5007 | lr 0.000446901 | gnorm 1.094 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 13771
2022-03-04 13:25:55 | INFO | fairseq.trainer | begin training epoch 53
2022-03-04 13:25:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:26:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 13:30:03 | INFO | train_inner | epoch 053:     94 / 97 loss=3.269, ppl=9.64, wps=23877.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.118, loss_scale=16, train_wall=244, gb_free=8.2, wall=14020
2022-03-04 13:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:30:16 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 10.029 | ppl 1044.58 | wps 44853.5 | wpb 510.9 | bsz 1 | num_updates 5103 | best_loss 7.632
2022-03-04 13:30:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5103 updates
2022-03-04 13:30:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:30:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:30:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 53 @ 5103 updates, score 10.029) (writing took 2.2452977700158954 seconds)
2022-03-04 13:30:18 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-04 13:30:18 | INFO | train | epoch 053 | loss 3.262 | ppl 9.59 | wps 23838.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 5103 | lr 0.000442677 | gnorm 1.12 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 14035
2022-03-04 13:30:18 | INFO | fairseq.trainer | begin training epoch 54
2022-03-04 13:30:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:34:34 | INFO | train_inner | epoch 054:     97 / 97 loss=3.195, ppl=9.16, wps=24142.5, ups=0.37, wpb=65451.9, bsz=127.8, num_updates=5200, lr=0.000438529, gnorm=1.113, loss_scale=32, train_wall=241, gb_free=8.2, wall=14291
2022-03-04 13:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:34:39 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 10.206 | ppl 1180.86 | wps 45042.5 | wpb 510.9 | bsz 1 | num_updates 5200 | best_loss 7.632
2022-03-04 13:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5200 updates
2022-03-04 13:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 54 @ 5200 updates, score 10.206) (writing took 2.329749989323318 seconds)
2022-03-04 13:34:42 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-04 13:34:42 | INFO | train | epoch 054 | loss 3.189 | ppl 9.12 | wps 24118.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5200 | lr 0.000438529 | gnorm 1.112 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 14299
2022-03-04 13:34:42 | INFO | fairseq.trainer | begin training epoch 55
2022-03-04 13:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:36:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 13:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:39:03 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 10.254 | ppl 1220.81 | wps 44914 | wpb 510.9 | bsz 1 | num_updates 5296 | best_loss 7.632
2022-03-04 13:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5296 updates
2022-03-04 13:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 55 @ 5296 updates, score 10.254) (writing took 2.3414038568735123 seconds)
2022-03-04 13:39:05 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-04 13:39:05 | INFO | train | epoch 055 | loss 3.119 | ppl 8.69 | wps 23841.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 5296 | lr 0.000434536 | gnorm 1.121 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 14562
2022-03-04 13:39:05 | INFO | fairseq.trainer | begin training epoch 56
2022-03-04 13:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:39:16 | INFO | train_inner | epoch 056:      4 / 97 loss=3.112, ppl=8.65, wps=23257.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=5300, lr=0.000434372, gnorm=1.117, loss_scale=16, train_wall=244, gb_free=8.2, wall=14573
2022-03-04 13:43:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:43:27 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 10.344 | ppl 1299.35 | wps 44888.8 | wpb 510.9 | bsz 1 | num_updates 5393 | best_loss 7.632
2022-03-04 13:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5393 updates
2022-03-04 13:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 56 @ 5393 updates, score 10.344) (writing took 2.352735996246338 seconds)
2022-03-04 13:43:29 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-04 13:43:29 | INFO | train | epoch 056 | loss 3.051 | ppl 8.29 | wps 24093.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5393 | lr 0.000430611 | gnorm 1.106 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 14826
2022-03-04 13:43:29 | INFO | fairseq.trainer | begin training epoch 57
2022-03-04 13:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:43:48 | INFO | train_inner | epoch 057:      7 / 97 loss=3.043, ppl=8.24, wps=24113.3, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.107, loss_scale=32, train_wall=242, gb_free=8.2, wall=14845
2022-03-04 13:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 13:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:47:51 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 10.418 | ppl 1368.5 | wps 44812.6 | wpb 510.9 | bsz 1 | num_updates 5489 | best_loss 7.632
2022-03-04 13:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5489 updates
2022-03-04 13:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 57 @ 5489 updates, score 10.418) (writing took 2.257883323356509 seconds)
2022-03-04 13:47:53 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-04 13:47:53 | INFO | train | epoch 057 | loss 2.984 | ppl 7.91 | wps 23840 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 5489 | lr 0.000426828 | gnorm 1.12 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 15090
2022-03-04 13:47:53 | INFO | fairseq.trainer | begin training epoch 58
2022-03-04 13:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:48:22 | INFO | train_inner | epoch 058:     11 / 97 loss=2.976, ppl=7.87, wps=23870.8, ups=0.36, wpb=65495, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=1.123, loss_scale=16, train_wall=244, gb_free=8.2, wall=15119
2022-03-04 13:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:52:14 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 10.547 | ppl 1495.68 | wps 44699.5 | wpb 510.9 | bsz 1 | num_updates 5586 | best_loss 7.632
2022-03-04 13:52:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5586 updates
2022-03-04 13:52:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 58 @ 5586 updates, score 10.547) (writing took 2.303283829241991 seconds)
2022-03-04 13:52:17 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-04 13:52:17 | INFO | train | epoch 058 | loss 2.923 | ppl 7.58 | wps 24070.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5586 | lr 0.000423106 | gnorm 1.134 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 15354
2022-03-04 13:52:17 | INFO | fairseq.trainer | begin training epoch 59
2022-03-04 13:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:52:54 | INFO | train_inner | epoch 059:     14 / 97 loss=2.907, ppl=7.5, wps=24095.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.128, loss_scale=16, train_wall=242, gb_free=8.2, wall=15391
2022-03-04 13:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 13:56:38 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 10.537 | ppl 1485.47 | wps 44922.9 | wpb 510.9 | bsz 1 | num_updates 5683 | best_loss 7.632
2022-03-04 13:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5683 updates
2022-03-04 13:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 13:56:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 59 @ 5683 updates, score 10.537) (writing took 2.338205319829285 seconds)
2022-03-04 13:56:40 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-04 13:56:40 | INFO | train | epoch 059 | loss 2.86 | ppl 7.26 | wps 24086.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5683 | lr 0.00041948 | gnorm 1.123 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 15617
2022-03-04 13:56:40 | INFO | fairseq.trainer | begin training epoch 60
2022-03-04 13:56:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 13:57:26 | INFO | train_inner | epoch 060:     17 / 97 loss=2.851, ppl=7.22, wps=24102, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.125, loss_scale=32, train_wall=242, gb_free=8.2, wall=15662
2022-03-04 13:59:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 14:00:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 14:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:01:02 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 10.702 | ppl 1665.24 | wps 44775.4 | wpb 510.9 | bsz 1 | num_updates 5778 | best_loss 7.632
2022-03-04 14:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5778 updates
2022-03-04 14:01:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:01:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:01:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 60 @ 5778 updates, score 10.702) (writing took 2.462631154805422 seconds)
2022-03-04 14:01:04 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-04 14:01:04 | INFO | train | epoch 060 | loss 2.799 | ppl 6.96 | wps 23568.6 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 5778 | lr 0.000416017 | gnorm 1.128 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 15881
2022-03-04 14:01:04 | INFO | fairseq.trainer | begin training epoch 61
2022-03-04 14:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:02:03 | INFO | train_inner | epoch 061:     22 / 97 loss=2.782, ppl=6.88, wps=23633.7, ups=0.36, wpb=65495, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.126, loss_scale=16, train_wall=247, gb_free=8.2, wall=15940
2022-03-04 14:05:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:05:26 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.795 | ppl 1776.58 | wps 44974.2 | wpb 510.9 | bsz 1 | num_updates 5875 | best_loss 7.632
2022-03-04 14:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5875 updates
2022-03-04 14:05:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:05:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:05:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 61 @ 5875 updates, score 10.795) (writing took 2.3792558973655105 seconds)
2022-03-04 14:05:28 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-04 14:05:28 | INFO | train | epoch 061 | loss 2.744 | ppl 6.7 | wps 24096.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5875 | lr 0.000412568 | gnorm 1.123 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 16145
2022-03-04 14:05:28 | INFO | fairseq.trainer | begin training epoch 62
2022-03-04 14:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:06:34 | INFO | train_inner | epoch 062:     25 / 97 loss=2.732, ppl=6.65, wps=24120.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.128, loss_scale=32, train_wall=242, gb_free=8.2, wall=16211
2022-03-04 14:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:09:49 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.921 | ppl 1939.07 | wps 44867.9 | wpb 510.9 | bsz 1 | num_updates 5972 | best_loss 7.632
2022-03-04 14:09:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5972 updates
2022-03-04 14:09:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 62 @ 5972 updates, score 10.921) (writing took 2.336478221230209 seconds)
2022-03-04 14:09:52 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-04 14:09:52 | INFO | train | epoch 062 | loss 2.688 | ppl 6.45 | wps 24099.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 5972 | lr 0.000409204 | gnorm 1.114 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 16409
2022-03-04 14:09:52 | INFO | fairseq.trainer | begin training epoch 63
2022-03-04 14:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:11:06 | INFO | train_inner | epoch 063:     28 / 97 loss=2.671, ppl=6.37, wps=24115.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=1.098, loss_scale=32, train_wall=242, gb_free=8.2, wall=16483
2022-03-04 14:12:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 14:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:14:13 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.954 | ppl 1983.43 | wps 44926.8 | wpb 510.9 | bsz 1 | num_updates 6068 | best_loss 7.632
2022-03-04 14:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6068 updates
2022-03-04 14:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 63 @ 6068 updates, score 10.954) (writing took 2.310918432660401 seconds)
2022-03-04 14:14:15 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-04 14:14:15 | INFO | train | epoch 063 | loss 2.636 | ppl 6.21 | wps 23853.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 6068 | lr 0.000405954 | gnorm 1.118 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 16672
2022-03-04 14:14:15 | INFO | fairseq.trainer | begin training epoch 64
2022-03-04 14:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:15:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 14:15:43 | INFO | train_inner | epoch 064:     33 / 97 loss=2.613, ppl=6.12, wps=23657.3, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=1.127, loss_scale=16, train_wall=247, gb_free=8.2, wall=16759
2022-03-04 14:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:18:36 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 11.037 | ppl 2101.67 | wps 44905.3 | wpb 510.9 | bsz 1 | num_updates 6164 | best_loss 7.632
2022-03-04 14:18:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6164 updates
2022-03-04 14:18:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 64 @ 6164 updates, score 11.037) (writing took 2.39586725179106 seconds)
2022-03-04 14:18:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-04 14:18:39 | INFO | train | epoch 064 | loss 2.582 | ppl 5.99 | wps 23845.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 6164 | lr 0.000402781 | gnorm 1.11 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 16936
2022-03-04 14:18:39 | INFO | fairseq.trainer | begin training epoch 65
2022-03-04 14:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:20:14 | INFO | train_inner | epoch 065:     36 / 97 loss=2.567, ppl=5.92, wps=24101.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.12, loss_scale=16, train_wall=242, gb_free=8.2, wall=17031
2022-03-04 14:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:23:01 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 11.087 | ppl 2174.99 | wps 44760.6 | wpb 510.9 | bsz 1 | num_updates 6261 | best_loss 7.632
2022-03-04 14:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6261 updates
2022-03-04 14:23:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:23:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:23:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 65 @ 6261 updates, score 11.087) (writing took 2.256785647943616 seconds)
2022-03-04 14:23:03 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-04 14:23:03 | INFO | train | epoch 065 | loss 2.534 | ppl 5.79 | wps 24070.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 6261 | lr 0.000399648 | gnorm 1.127 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 17200
2022-03-04 14:23:03 | INFO | fairseq.trainer | begin training epoch 66
2022-03-04 14:23:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:24:46 | INFO | train_inner | epoch 066:     39 / 97 loss=2.513, ppl=5.71, wps=24112.6, ups=0.37, wpb=65495, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.121, loss_scale=32, train_wall=242, gb_free=8.2, wall=17303
2022-03-04 14:26:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 14:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:27:24 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 11.174 | ppl 2310.86 | wps 45194.5 | wpb 510.9 | bsz 1 | num_updates 6357 | best_loss 7.632
2022-03-04 14:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6357 updates
2022-03-04 14:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 66 @ 6357 updates, score 11.174) (writing took 2.4687964813783765 seconds)
2022-03-04 14:27:26 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-04 14:27:26 | INFO | train | epoch 066 | loss 2.486 | ppl 5.6 | wps 23844.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 6357 | lr 0.000396619 | gnorm 1.134 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 17463
2022-03-04 14:27:27 | INFO | fairseq.trainer | begin training epoch 67
2022-03-04 14:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:29:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 14:29:23 | INFO | train_inner | epoch 067:     44 / 97 loss=2.466, ppl=5.53, wps=23645.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.128, loss_scale=16, train_wall=246, gb_free=8.2, wall=17580
2022-03-04 14:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:31:48 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 11.317 | ppl 2551.32 | wps 45032.5 | wpb 510.9 | bsz 1 | num_updates 6453 | best_loss 7.632
2022-03-04 14:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6453 updates
2022-03-04 14:31:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 67 @ 6453 updates, score 11.317) (writing took 2.2331149838864803 seconds)
2022-03-04 14:31:50 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-04 14:31:50 | INFO | train | epoch 067 | loss 2.437 | ppl 5.42 | wps 23854.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 6453 | lr 0.000393658 | gnorm 1.117 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 17727
2022-03-04 14:31:50 | INFO | fairseq.trainer | begin training epoch 68
2022-03-04 14:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:33:54 | INFO | train_inner | epoch 068:     47 / 97 loss=2.416, ppl=5.34, wps=24130.8, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.116, loss_scale=16, train_wall=242, gb_free=8.2, wall=17851
2022-03-04 14:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:36:11 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 11.377 | ppl 2658.73 | wps 44864.9 | wpb 510.9 | bsz 1 | num_updates 6550 | best_loss 7.632
2022-03-04 14:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6550 updates
2022-03-04 14:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:36:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 68 @ 6550 updates, score 11.377) (writing took 2.2562013510614634 seconds)
2022-03-04 14:36:14 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-04 14:36:14 | INFO | train | epoch 068 | loss 2.394 | ppl 5.26 | wps 24113.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 6550 | lr 0.000390732 | gnorm 1.105 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 17990
2022-03-04 14:36:14 | INFO | fairseq.trainer | begin training epoch 69
2022-03-04 14:36:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:38:26 | INFO | train_inner | epoch 069:     50 / 97 loss=2.371, ppl=5.17, wps=24129.6, ups=0.37, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.118, loss_scale=32, train_wall=242, gb_free=8.2, wall=18123
2022-03-04 14:40:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:40:35 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 11.437 | ppl 2771.77 | wps 44910.7 | wpb 510.9 | bsz 1 | num_updates 6647 | best_loss 7.632
2022-03-04 14:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6647 updates
2022-03-04 14:40:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:40:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:40:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 69 @ 6647 updates, score 11.437) (writing took 2.302894330583513 seconds)
2022-03-04 14:40:37 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-04 14:40:37 | INFO | train | epoch 069 | loss 2.351 | ppl 5.1 | wps 24091.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 6647 | lr 0.000387871 | gnorm 1.122 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 18254
2022-03-04 14:40:37 | INFO | fairseq.trainer | begin training epoch 70
2022-03-04 14:40:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:40:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 14:43:00 | INFO | train_inner | epoch 070:     54 / 97 loss=2.333, ppl=5.04, wps=23873.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.141, loss_scale=32, train_wall=244, gb_free=8.2, wall=18397
2022-03-04 14:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:44:59 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 11.584 | ppl 3069.94 | wps 44998.2 | wpb 510.9 | bsz 1 | num_updates 6743 | best_loss 7.632
2022-03-04 14:44:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6743 updates
2022-03-04 14:44:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:45:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 70 @ 6743 updates, score 11.584) (writing took 2.2732739336788654 seconds)
2022-03-04 14:45:01 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-04 14:45:01 | INFO | train | epoch 070 | loss 2.309 | ppl 4.96 | wps 23848.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 6743 | lr 0.0003851 | gnorm 1.143 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 18518
2022-03-04 14:45:01 | INFO | fairseq.trainer | begin training epoch 71
2022-03-04 14:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:46:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 14:47:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 14:47:37 | INFO | train_inner | epoch 071:     59 / 97 loss=2.283, ppl=4.87, wps=23664.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.131, loss_scale=16, train_wall=246, gb_free=8.2, wall=18674
2022-03-04 14:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:49:22 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 11.708 | ppl 3345.96 | wps 44967.8 | wpb 510.9 | bsz 1 | num_updates 6838 | best_loss 7.632
2022-03-04 14:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6838 updates
2022-03-04 14:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:49:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 71 @ 6838 updates, score 11.708) (writing took 2.3784199971705675 seconds)
2022-03-04 14:49:24 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-04 14:49:24 | INFO | train | epoch 071 | loss 2.265 | ppl 4.81 | wps 23599.6 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 6838 | lr 0.000382415 | gnorm 1.14 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 18781
2022-03-04 14:49:24 | INFO | fairseq.trainer | begin training epoch 72
2022-03-04 14:49:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:52:08 | INFO | train_inner | epoch 072:     62 / 97 loss=2.244, ppl=4.74, wps=24113, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.13, loss_scale=16, train_wall=242, gb_free=8.2, wall=18945
2022-03-04 14:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:53:46 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 11.665 | ppl 3247.04 | wps 44868.1 | wpb 510.9 | bsz 1 | num_updates 6935 | best_loss 7.632
2022-03-04 14:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6935 updates
2022-03-04 14:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 72 @ 6935 updates, score 11.665) (writing took 2.360108765773475 seconds)
2022-03-04 14:53:48 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-04 14:53:48 | INFO | train | epoch 072 | loss 2.228 | ppl 4.68 | wps 24096.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 6935 | lr 0.000379732 | gnorm 1.124 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 19045
2022-03-04 14:53:48 | INFO | fairseq.trainer | begin training epoch 73
2022-03-04 14:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:56:40 | INFO | train_inner | epoch 073:     65 / 97 loss=2.202, ppl=4.6, wps=24096.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.114, loss_scale=32, train_wall=242, gb_free=8.2, wall=19217
2022-03-04 14:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 14:58:10 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 11.782 | ppl 3520.49 | wps 45196.7 | wpb 510.9 | bsz 1 | num_updates 7032 | best_loss 7.632
2022-03-04 14:58:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7032 updates
2022-03-04 14:58:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 14:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 73 @ 7032 updates, score 11.782) (writing took 2.3163820998743176 seconds)
2022-03-04 14:58:12 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-04 14:58:12 | INFO | train | epoch 073 | loss 2.189 | ppl 4.56 | wps 24075.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 7032 | lr 0.000377104 | gnorm 1.117 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 19309
2022-03-04 14:58:12 | INFO | fairseq.trainer | begin training epoch 74
2022-03-04 14:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 14:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 15:01:14 | INFO | train_inner | epoch 074:     69 / 97 loss=2.165, ppl=4.49, wps=23885.7, ups=0.36, wpb=65495, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.113, loss_scale=32, train_wall=244, gb_free=8.2, wall=19491
2022-03-04 15:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:02:33 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 11.884 | ppl 3779.94 | wps 44907.6 | wpb 510.9 | bsz 1 | num_updates 7128 | best_loss 7.632
2022-03-04 15:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7128 updates
2022-03-04 15:02:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 74 @ 7128 updates, score 11.884) (writing took 2.4236833602190018 seconds)
2022-03-04 15:02:36 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-04 15:02:36 | INFO | train | epoch 074 | loss 2.149 | ppl 4.44 | wps 23834.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 7128 | lr 0.000374555 | gnorm 1.106 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 19573
2022-03-04 15:02:36 | INFO | fairseq.trainer | begin training epoch 75
2022-03-04 15:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:03:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:05:49 | INFO | train_inner | epoch 075:     73 / 97 loss=2.126, ppl=4.37, wps=23860.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.125, loss_scale=16, train_wall=244, gb_free=8.2, wall=19766
2022-03-04 15:06:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:06:57 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.808 | ppl 3586.02 | wps 44817.6 | wpb 510.9 | bsz 1 | num_updates 7224 | best_loss 7.632
2022-03-04 15:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7224 updates
2022-03-04 15:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 75 @ 7224 updates, score 11.808) (writing took 2.265215248800814 seconds)
2022-03-04 15:06:59 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-04 15:06:59 | INFO | train | epoch 075 | loss 2.114 | ppl 4.33 | wps 23846.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 7224 | lr 0.000372058 | gnorm 1.124 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 19836
2022-03-04 15:06:59 | INFO | fairseq.trainer | begin training epoch 76
2022-03-04 15:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:10:21 | INFO | train_inner | epoch 076:     76 / 97 loss=2.089, ppl=4.25, wps=24113.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=1.132, loss_scale=32, train_wall=242, gb_free=8.2, wall=20037
2022-03-04 15:10:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:11:21 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 12.022 | ppl 4157.8 | wps 44861 | wpb 510.9 | bsz 1 | num_updates 7320 | best_loss 7.632
2022-03-04 15:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7320 updates
2022-03-04 15:11:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 76 @ 7320 updates, score 12.022) (writing took 2.3310323683544993 seconds)
2022-03-04 15:11:23 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-04 15:11:23 | INFO | train | epoch 076 | loss 2.08 | ppl 4.23 | wps 23830.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 7320 | lr 0.000369611 | gnorm 1.134 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 20100
2022-03-04 15:11:23 | INFO | fairseq.trainer | begin training epoch 77
2022-03-04 15:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:14:55 | INFO | train_inner | epoch 077:     80 / 97 loss=2.055, ppl=4.16, wps=23884.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=1.13, loss_scale=16, train_wall=244, gb_free=8.2, wall=20312
2022-03-04 15:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:15:44 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 12.024 | ppl 4165.44 | wps 44766.6 | wpb 510.9 | bsz 1 | num_updates 7417 | best_loss 7.632
2022-03-04 15:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7417 updates
2022-03-04 15:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 77 @ 7417 updates, score 12.024) (writing took 2.2977252081036568 seconds)
2022-03-04 15:15:47 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-04 15:15:47 | INFO | train | epoch 077 | loss 2.047 | ppl 4.13 | wps 24105 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 7417 | lr 0.000367186 | gnorm 1.123 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 20364
2022-03-04 15:15:47 | INFO | fairseq.trainer | begin training epoch 78
2022-03-04 15:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:19:26 | INFO | train_inner | epoch 078:     83 / 97 loss=2.021, ppl=4.06, wps=24116.5, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.118, loss_scale=32, train_wall=242, gb_free=8.2, wall=20583
2022-03-04 15:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:20:08 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 12.081 | ppl 4332.67 | wps 45278.9 | wpb 510.9 | bsz 1 | num_updates 7514 | best_loss 7.632
2022-03-04 15:20:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7514 updates
2022-03-04 15:20:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 78 @ 7514 updates, score 12.081) (writing took 2.3331476813182235 seconds)
2022-03-04 15:20:10 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-04 15:20:10 | INFO | train | epoch 078 | loss 2.014 | ppl 4.04 | wps 24092.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 7514 | lr 0.000364808 | gnorm 1.121 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 20627
2022-03-04 15:20:10 | INFO | fairseq.trainer | begin training epoch 79
2022-03-04 15:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:22:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 15:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:24:03 | INFO | train_inner | epoch 079:     88 / 97 loss=1.989, ppl=3.97, wps=23668.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.116, loss_scale=16, train_wall=246, gb_free=8.2, wall=20860
2022-03-04 15:24:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:24:32 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 12.21 | ppl 4737.12 | wps 44950.4 | wpb 510.9 | bsz 1 | num_updates 7609 | best_loss 7.632
2022-03-04 15:24:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7609 updates
2022-03-04 15:24:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 79 @ 7609 updates, score 12.21) (writing took 2.4096186319366097 seconds)
2022-03-04 15:24:34 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-04 15:24:34 | INFO | train | epoch 079 | loss 1.98 | ppl 3.95 | wps 23599.3 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 7609 | lr 0.000362524 | gnorm 1.12 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 20891
2022-03-04 15:24:34 | INFO | fairseq.trainer | begin training epoch 80
2022-03-04 15:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:28:35 | INFO | train_inner | epoch 080:     91 / 97 loss=1.956, ppl=3.88, wps=24089.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.13, loss_scale=16, train_wall=242, gb_free=8.2, wall=21132
2022-03-04 15:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:28:56 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 12.359 | ppl 5253.26 | wps 44890.7 | wpb 510.9 | bsz 1 | num_updates 7706 | best_loss 7.632
2022-03-04 15:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7706 updates
2022-03-04 15:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:28:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 80 @ 7706 updates, score 12.359) (writing took 2.2953003337606788 seconds)
2022-03-04 15:28:58 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-04 15:28:58 | INFO | train | epoch 080 | loss 1.953 | ppl 3.87 | wps 24081.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 7706 | lr 0.000360235 | gnorm 1.133 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 21155
2022-03-04 15:28:58 | INFO | fairseq.trainer | begin training epoch 81
2022-03-04 15:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:29:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:33:09 | INFO | train_inner | epoch 081:     95 / 97 loss=1.926, ppl=3.8, wps=23897, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.118, loss_scale=16, train_wall=244, gb_free=8.2, wall=21406
2022-03-04 15:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:33:19 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 12.357 | ppl 5247.75 | wps 44919.2 | wpb 510.9 | bsz 1 | num_updates 7802 | best_loss 7.632
2022-03-04 15:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7802 updates
2022-03-04 15:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:33:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:33:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 81 @ 7802 updates, score 12.357) (writing took 2.3259640224277973 seconds)
2022-03-04 15:33:21 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-04 15:33:21 | INFO | train | epoch 081 | loss 1.92 | ppl 3.78 | wps 23860 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 7802 | lr 0.000358012 | gnorm 1.116 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 21418
2022-03-04 15:33:21 | INFO | fairseq.trainer | begin training epoch 82
2022-03-04 15:33:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:37:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:37:43 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 12.427 | ppl 5505.12 | wps 44841.9 | wpb 510.9 | bsz 1 | num_updates 7899 | best_loss 7.632
2022-03-04 15:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7899 updates
2022-03-04 15:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:37:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 82 @ 7899 updates, score 12.427) (writing took 2.2976738130673766 seconds)
2022-03-04 15:37:45 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-04 15:37:45 | INFO | train | epoch 082 | loss 1.893 | ppl 3.71 | wps 24090.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 7899 | lr 0.000355807 | gnorm 1.117 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 21682
2022-03-04 15:37:45 | INFO | fairseq.trainer | begin training epoch 83
2022-03-04 15:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:37:48 | INFO | train_inner | epoch 083:      1 / 97 loss=1.893, ppl=3.71, wps=23476.4, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.118, loss_scale=32, train_wall=242, gb_free=8.2, wall=21685
2022-03-04 15:39:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:42:06 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 12.477 | ppl 5702.34 | wps 44930.2 | wpb 510.9 | bsz 1 | num_updates 7995 | best_loss 7.632
2022-03-04 15:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7995 updates
2022-03-04 15:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:42:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 83 @ 7995 updates, score 12.477) (writing took 2.282678473740816 seconds)
2022-03-04 15:42:09 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-04 15:42:09 | INFO | train | epoch 083 | loss 1.86 | ppl 3.63 | wps 23859.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 7995 | lr 0.000353664 | gnorm 1.108 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 21945
2022-03-04 15:42:09 | INFO | fairseq.trainer | begin training epoch 84
2022-03-04 15:42:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:42:22 | INFO | train_inner | epoch 084:      5 / 97 loss=1.854, ppl=3.62, wps=23894.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.109, loss_scale=16, train_wall=244, gb_free=8.2, wall=21959
2022-03-04 15:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:46:30 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 12.514 | ppl 5849.03 | wps 44865.4 | wpb 510.9 | bsz 1 | num_updates 8092 | best_loss 7.632
2022-03-04 15:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8092 updates
2022-03-04 15:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 84 @ 8092 updates, score 12.514) (writing took 2.2929087579250336 seconds)
2022-03-04 15:46:32 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-04 15:46:32 | INFO | train | epoch 084 | loss 1.837 | ppl 3.57 | wps 24075 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 8092 | lr 0.000351538 | gnorm 1.128 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 22209
2022-03-04 15:46:32 | INFO | fairseq.trainer | begin training epoch 85
2022-03-04 15:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:46:54 | INFO | train_inner | epoch 085:      8 / 97 loss=1.833, ppl=3.56, wps=24091.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.125, loss_scale=32, train_wall=242, gb_free=8.2, wall=22231
2022-03-04 15:50:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 15:50:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:50:54 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 12.593 | ppl 6176.75 | wps 44767.3 | wpb 510.9 | bsz 1 | num_updates 8188 | best_loss 7.632
2022-03-04 15:50:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8188 updates
2022-03-04 15:50:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:50:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 85 @ 8188 updates, score 12.593) (writing took 2.4345355359837413 seconds)
2022-03-04 15:50:56 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-04 15:50:56 | INFO | train | epoch 085 | loss 1.807 | ppl 3.5 | wps 23840.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 8188 | lr 0.000349471 | gnorm 1.107 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 22473
2022-03-04 15:50:56 | INFO | fairseq.trainer | begin training epoch 86
2022-03-04 15:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:51:28 | INFO | train_inner | epoch 086:     12 / 97 loss=1.805, ppl=3.49, wps=23874.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1.111, loss_scale=32, train_wall=244, gb_free=8.2, wall=22505
2022-03-04 15:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:55:18 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 12.673 | ppl 6528.98 | wps 44942.9 | wpb 510.9 | bsz 1 | num_updates 8285 | best_loss 7.632
2022-03-04 15:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8285 updates
2022-03-04 15:55:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:55:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 86 @ 8285 updates, score 12.673) (writing took 2.29216393455863 seconds)
2022-03-04 15:55:20 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-04 15:55:20 | INFO | train | epoch 086 | loss 1.783 | ppl 3.44 | wps 24079.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 8285 | lr 0.000347419 | gnorm 1.119 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 22737
2022-03-04 15:55:20 | INFO | fairseq.trainer | begin training epoch 87
2022-03-04 15:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 15:55:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 15:56:02 | INFO | train_inner | epoch 087:     16 / 97 loss=1.773, ppl=3.42, wps=23870.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.118, loss_scale=16, train_wall=244, gb_free=8.2, wall=22779
2022-03-04 15:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 15:59:42 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 12.673 | ppl 6532.64 | wps 44678.5 | wpb 510.9 | bsz 1 | num_updates 8381 | best_loss 7.632
2022-03-04 15:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8381 updates
2022-03-04 15:59:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:59:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 15:59:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 87 @ 8381 updates, score 12.673) (writing took 2.6811030134558678 seconds)
2022-03-04 15:59:44 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-04 15:59:44 | INFO | train | epoch 087 | loss 1.756 | ppl 3.38 | wps 23788.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 8381 | lr 0.000345424 | gnorm 1.121 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 23001
2022-03-04 15:59:44 | INFO | fairseq.trainer | begin training epoch 88
2022-03-04 15:59:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:00:35 | INFO | train_inner | epoch 088:     19 / 97 loss=1.75, ppl=3.36, wps=24063.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=1.112, loss_scale=16, train_wall=242, gb_free=8.2, wall=23051
2022-03-04 16:04:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:04:06 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 12.762 | ppl 6947.48 | wps 44739.3 | wpb 510.9 | bsz 1 | num_updates 8478 | best_loss 7.632
2022-03-04 16:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8478 updates
2022-03-04 16:04:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:04:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:04:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 88 @ 8478 updates, score 12.762) (writing took 2.2989996057003736 seconds)
2022-03-04 16:04:08 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-04 16:04:08 | INFO | train | epoch 088 | loss 1.733 | ppl 3.32 | wps 24072.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 8478 | lr 0.000343442 | gnorm 1.106 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 23265
2022-03-04 16:04:08 | INFO | fairseq.trainer | begin training epoch 89
2022-03-04 16:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:05:06 | INFO | train_inner | epoch 089:     22 / 97 loss=1.724, ppl=3.3, wps=24089, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.107, loss_scale=32, train_wall=242, gb_free=8.2, wall=23323
2022-03-04 16:07:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 16:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:08:30 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 12.77 | ppl 6984.97 | wps 44909.7 | wpb 510.9 | bsz 1 | num_updates 8574 | best_loss 7.632
2022-03-04 16:08:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8574 updates
2022-03-04 16:08:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 89 @ 8574 updates, score 12.77) (writing took 2.392644491046667 seconds)
2022-03-04 16:08:32 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-04 16:08:32 | INFO | train | epoch 089 | loss 1.708 | ppl 3.27 | wps 23823.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 8574 | lr 0.000341514 | gnorm 1.123 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 23529
2022-03-04 16:08:32 | INFO | fairseq.trainer | begin training epoch 90
2022-03-04 16:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:09:41 | INFO | train_inner | epoch 090:     26 / 97 loss=1.698, ppl=3.24, wps=23857.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=1.119, loss_scale=32, train_wall=244, gb_free=8.2, wall=23598
2022-03-04 16:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:12:54 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 12.846 | ppl 7362.97 | wps 44722.2 | wpb 510.9 | bsz 1 | num_updates 8671 | best_loss 7.632
2022-03-04 16:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8671 updates
2022-03-04 16:12:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:12:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:12:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 90 @ 8671 updates, score 12.846) (writing took 2.645106438547373 seconds)
2022-03-04 16:12:56 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-04 16:12:56 | INFO | train | epoch 090 | loss 1.683 | ppl 3.21 | wps 24049.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 8671 | lr 0.000339598 | gnorm 1.119 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 23793
2022-03-04 16:12:56 | INFO | fairseq.trainer | begin training epoch 91
2022-03-04 16:12:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 16:14:16 | INFO | train_inner | epoch 091:     30 / 97 loss=1.68, ppl=3.2, wps=23849.7, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.123, loss_scale=32, train_wall=244, gb_free=8.2, wall=23872
2022-03-04 16:17:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:17:18 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.949 | ppl 7905.15 | wps 44911.1 | wpb 510.9 | bsz 1 | num_updates 8767 | best_loss 7.632
2022-03-04 16:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8767 updates
2022-03-04 16:17:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:17:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 91 @ 8767 updates, score 12.949) (writing took 2.3500310303643346 seconds)
2022-03-04 16:17:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-04 16:17:20 | INFO | train | epoch 091 | loss 1.659 | ppl 3.16 | wps 23846.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 8767 | lr 0.000337734 | gnorm 1.12 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 24057
2022-03-04 16:17:20 | INFO | fairseq.trainer | begin training epoch 92
2022-03-04 16:17:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:18:47 | INFO | train_inner | epoch 092:     33 / 97 loss=1.649, ppl=3.14, wps=24104.8, ups=0.37, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.114, loss_scale=32, train_wall=242, gb_free=8.2, wall=24144
2022-03-04 16:18:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 16:19:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 16:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:21:41 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.977 | ppl 8064.45 | wps 44716.6 | wpb 510.9 | bsz 1 | num_updates 8862 | best_loss 7.632
2022-03-04 16:21:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8862 updates
2022-03-04 16:21:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 92 @ 8862 updates, score 12.977) (writing took 2.3148758821189404 seconds)
2022-03-04 16:21:44 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-04 16:21:44 | INFO | train | epoch 092 | loss 1.637 | ppl 3.11 | wps 23584.7 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 8862 | lr 0.000335919 | gnorm 1.12 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 24321
2022-03-04 16:21:44 | INFO | fairseq.trainer | begin training epoch 93
2022-03-04 16:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:23:24 | INFO | train_inner | epoch 093:     38 / 97 loss=1.631, ppl=3.1, wps=23646, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=1.123, loss_scale=16, train_wall=247, gb_free=8.2, wall=24421
2022-03-04 16:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:26:05 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 13.133 | ppl 8980.53 | wps 44579.8 | wpb 510.9 | bsz 1 | num_updates 8959 | best_loss 7.632
2022-03-04 16:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8959 updates
2022-03-04 16:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 93 @ 8959 updates, score 13.133) (writing took 2.2721263226121664 seconds)
2022-03-04 16:26:07 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-04 16:26:07 | INFO | train | epoch 093 | loss 1.618 | ppl 3.07 | wps 24090.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 8959 | lr 0.000334095 | gnorm 1.112 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 24584
2022-03-04 16:26:07 | INFO | fairseq.trainer | begin training epoch 94
2022-03-04 16:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:27:56 | INFO | train_inner | epoch 094:     41 / 97 loss=1.611, ppl=3.06, wps=24075.5, ups=0.37, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=1.106, loss_scale=32, train_wall=242, gb_free=8.2, wall=24693
2022-03-04 16:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:30:29 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 13.084 | ppl 8683.68 | wps 44933.7 | wpb 510.9 | bsz 1 | num_updates 9056 | best_loss 7.632
2022-03-04 16:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9056 updates
2022-03-04 16:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:30:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 94 @ 9056 updates, score 13.084) (writing took 2.382492294535041 seconds)
2022-03-04 16:30:31 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-04 16:30:31 | INFO | train | epoch 094 | loss 1.598 | ppl 3.03 | wps 24053.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 9056 | lr 0.000332301 | gnorm 1.111 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 24848
2022-03-04 16:30:32 | INFO | fairseq.trainer | begin training epoch 95
2022-03-04 16:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:31:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 16:32:31 | INFO | train_inner | epoch 095:     45 / 97 loss=1.581, ppl=2.99, wps=23883, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.112, loss_scale=32, train_wall=244, gb_free=8.2, wall=24967
2022-03-04 16:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:34:53 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 13.247 | ppl 9719.88 | wps 44824.9 | wpb 510.9 | bsz 1 | num_updates 9152 | best_loss 7.632
2022-03-04 16:34:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9152 updates
2022-03-04 16:34:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 95 @ 9152 updates, score 13.247) (writing took 2.286693051457405 seconds)
2022-03-04 16:34:55 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-04 16:34:55 | INFO | train | epoch 095 | loss 1.573 | ppl 2.98 | wps 23850.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9152 | lr 0.000330554 | gnorm 1.095 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 25112
2022-03-04 16:34:55 | INFO | fairseq.trainer | begin training epoch 96
2022-03-04 16:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:37:02 | INFO | train_inner | epoch 096:     48 / 97 loss=1.569, ppl=2.97, wps=24105.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=1.09, loss_scale=32, train_wall=242, gb_free=8.2, wall=25239
2022-03-04 16:37:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 16:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:39:17 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 13.213 | ppl 9498.44 | wps 44854.7 | wpb 510.9 | bsz 1 | num_updates 9248 | best_loss 7.632
2022-03-04 16:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9248 updates
2022-03-04 16:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 96 @ 9248 updates, score 13.213) (writing took 2.5631092051044106 seconds)
2022-03-04 16:39:19 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-04 16:39:19 | INFO | train | epoch 096 | loss 1.556 | ppl 2.94 | wps 23809.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9248 | lr 0.000328834 | gnorm 1.09 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 25376
2022-03-04 16:39:19 | INFO | fairseq.trainer | begin training epoch 97
2022-03-04 16:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:40:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 16:41:39 | INFO | train_inner | epoch 097:     53 / 97 loss=1.546, ppl=2.92, wps=23627.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=1.113, loss_scale=16, train_wall=247, gb_free=8.2, wall=25516
2022-03-04 16:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:43:41 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 13.273 | ppl 9900.51 | wps 44574.7 | wpb 510.9 | bsz 1 | num_updates 9344 | best_loss 7.632
2022-03-04 16:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9344 updates
2022-03-04 16:43:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 97 @ 9344 updates, score 13.273) (writing took 2.3853656966239214 seconds)
2022-03-04 16:43:43 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-04 16:43:43 | INFO | train | epoch 097 | loss 1.538 | ppl 2.9 | wps 23833.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9344 | lr 0.00032714 | gnorm 1.122 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 25640
2022-03-04 16:43:43 | INFO | fairseq.trainer | begin training epoch 98
2022-03-04 16:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:46:11 | INFO | train_inner | epoch 098:     56 / 97 loss=1.531, ppl=2.89, wps=24095, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=1.1, loss_scale=16, train_wall=242, gb_free=8.2, wall=25788
2022-03-04 16:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:48:04 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 13.329 | ppl 10288.2 | wps 44678.2 | wpb 510.9 | bsz 1 | num_updates 9441 | best_loss 7.632
2022-03-04 16:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9441 updates
2022-03-04 16:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 98 @ 9441 updates, score 13.329) (writing took 2.331953376531601 seconds)
2022-03-04 16:48:07 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-04 16:48:07 | INFO | train | epoch 098 | loss 1.519 | ppl 2.87 | wps 24080.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 9441 | lr 0.000325455 | gnorm 1.091 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 25904
2022-03-04 16:48:07 | INFO | fairseq.trainer | begin training epoch 99
2022-03-04 16:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:50:43 | INFO | train_inner | epoch 099:     59 / 97 loss=1.508, ppl=2.84, wps=24100, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=1.096, loss_scale=32, train_wall=242, gb_free=8.2, wall=26060
2022-03-04 16:50:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 16:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:52:28 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 13.438 | ppl 11101.1 | wps 43949.1 | wpb 510.9 | bsz 1 | num_updates 9537 | best_loss 7.632
2022-03-04 16:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9537 updates
2022-03-04 16:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 99 @ 9537 updates, score 13.438) (writing took 2.291425527073443 seconds)
2022-03-04 16:52:31 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-04 16:52:31 | INFO | train | epoch 099 | loss 1.501 | ppl 2.83 | wps 23837.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9537 | lr 0.000323813 | gnorm 1.115 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 26167
2022-03-04 16:52:31 | INFO | fairseq.trainer | begin training epoch 100
2022-03-04 16:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:55:17 | INFO | train_inner | epoch 100:     63 / 97 loss=1.49, ppl=2.81, wps=23876.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=1.113, loss_scale=16, train_wall=244, gb_free=8.2, wall=26334
2022-03-04 16:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 16:56:52 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 13.464 | ppl 11300.8 | wps 44831.5 | wpb 510.9 | bsz 1 | num_updates 9634 | best_loss 7.632
2022-03-04 16:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9634 updates
2022-03-04 16:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 16:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 100 @ 9634 updates, score 13.464) (writing took 2.4540441632270813 seconds)
2022-03-04 16:56:54 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-04 16:56:54 | INFO | train | epoch 100 | loss 1.481 | ppl 2.79 | wps 24074.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 9634 | lr 0.000322179 | gnorm 1.097 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 26431
2022-03-04 16:56:54 | INFO | fairseq.trainer | begin training epoch 101
2022-03-04 16:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 16:57:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 16:59:52 | INFO | train_inner | epoch 101:     67 / 97 loss=1.472, ppl=2.77, wps=23860.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=1.107, loss_scale=16, train_wall=244, gb_free=8.2, wall=26609
2022-03-04 17:01:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:01:16 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 13.496 | ppl 11551.9 | wps 45010.7 | wpb 510.9 | bsz 1 | num_updates 9730 | best_loss 7.632
2022-03-04 17:01:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9730 updates
2022-03-04 17:01:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:01:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:01:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 101 @ 9730 updates, score 13.496) (writing took 2.394247085787356 seconds)
2022-03-04 17:01:18 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-04 17:01:18 | INFO | train | epoch 101 | loss 1.465 | ppl 2.76 | wps 23827.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9730 | lr 0.000320585 | gnorm 1.113 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 26695
2022-03-04 17:01:18 | INFO | fairseq.trainer | begin training epoch 102
2022-03-04 17:01:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:03:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 17:04:26 | INFO | train_inner | epoch 102:     71 / 97 loss=1.454, ppl=2.74, wps=23863.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=1.098, loss_scale=16, train_wall=244, gb_free=8.2, wall=26883
2022-03-04 17:05:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:05:40 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 13.604 | ppl 12449.3 | wps 44812.2 | wpb 510.9 | bsz 1 | num_updates 9826 | best_loss 7.632
2022-03-04 17:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9826 updates
2022-03-04 17:05:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 102 @ 9826 updates, score 13.604) (writing took 2.4060707427561283 seconds)
2022-03-04 17:05:42 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-04 17:05:42 | INFO | train | epoch 102 | loss 1.445 | ppl 2.72 | wps 23826.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9826 | lr 0.000319015 | gnorm 1.089 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 26959
2022-03-04 17:05:42 | INFO | fairseq.trainer | begin training epoch 103
2022-03-04 17:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:08:58 | INFO | train_inner | epoch 103:     74 / 97 loss=1.434, ppl=2.7, wps=24094, ups=0.37, wpb=65495, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=1.088, loss_scale=32, train_wall=242, gb_free=8.2, wall=27155
2022-03-04 17:09:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 17:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:10:04 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 13.582 | ppl 12262.1 | wps 44977.9 | wpb 510.9 | bsz 1 | num_updates 9922 | best_loss 7.632
2022-03-04 17:10:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9922 updates
2022-03-04 17:10:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:10:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:10:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 103 @ 9922 updates, score 13.582) (writing took 2.414533579722047 seconds)
2022-03-04 17:10:06 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-04 17:10:06 | INFO | train | epoch 103 | loss 1.43 | ppl 2.69 | wps 23817.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 9922 | lr 0.000317468 | gnorm 1.095 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 27223
2022-03-04 17:10:06 | INFO | fairseq.trainer | begin training epoch 104
2022-03-04 17:10:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:13:32 | INFO | train_inner | epoch 104:     78 / 97 loss=1.418, ppl=2.67, wps=23869.9, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=1.091, loss_scale=16, train_wall=244, gb_free=8.2, wall=27429
2022-03-04 17:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:14:27 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 13.694 | ppl 13252.9 | wps 44936.3 | wpb 510.9 | bsz 1 | num_updates 10019 | best_loss 7.632
2022-03-04 17:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10019 updates
2022-03-04 17:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 104 @ 10019 updates, score 13.694) (writing took 2.3397280955687165 seconds)
2022-03-04 17:14:30 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-04 17:14:30 | INFO | train | epoch 104 | loss 1.413 | ppl 2.66 | wps 24097.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10019 | lr 0.000315928 | gnorm 1.08 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 27487
2022-03-04 17:14:30 | INFO | fairseq.trainer | begin training epoch 105
2022-03-04 17:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:16:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 17:18:07 | INFO | train_inner | epoch 105:     82 / 97 loss=1.405, ppl=2.65, wps=23890.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=1.096, loss_scale=16, train_wall=244, gb_free=8.2, wall=27703
2022-03-04 17:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:18:51 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 13.672 | ppl 13056.3 | wps 44777.5 | wpb 510.9 | bsz 1 | num_updates 10115 | best_loss 7.632
2022-03-04 17:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10115 updates
2022-03-04 17:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 105 @ 10115 updates, score 13.672) (writing took 2.3638867950066924 seconds)
2022-03-04 17:18:53 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-04 17:18:53 | INFO | train | epoch 105 | loss 1.397 | ppl 2.63 | wps 23850.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 10115 | lr 0.000314425 | gnorm 1.094 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 27750
2022-03-04 17:18:53 | INFO | fairseq.trainer | begin training epoch 106
2022-03-04 17:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:22:38 | INFO | train_inner | epoch 106:     85 / 97 loss=1.384, ppl=2.61, wps=24096.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=1.091, loss_scale=32, train_wall=242, gb_free=8.2, wall=27975
2022-03-04 17:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:23:15 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 13.776 | ppl 14025.9 | wps 44721.3 | wpb 510.9 | bsz 1 | num_updates 10212 | best_loss 7.632
2022-03-04 17:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10212 updates
2022-03-04 17:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 106 @ 10212 updates, score 13.776) (writing took 2.344482569023967 seconds)
2022-03-04 17:23:17 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-04 17:23:17 | INFO | train | epoch 106 | loss 1.382 | ppl 2.61 | wps 24069.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10212 | lr 0.000312928 | gnorm 1.093 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 28014
2022-03-04 17:23:17 | INFO | fairseq.trainer | begin training epoch 107
2022-03-04 17:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:27:10 | INFO | train_inner | epoch 107:     88 / 97 loss=1.371, ppl=2.59, wps=24130, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=1.101, loss_scale=32, train_wall=242, gb_free=8.2, wall=28247
2022-03-04 17:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:27:38 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 13.762 | ppl 13891.2 | wps 44836.5 | wpb 510.9 | bsz 1 | num_updates 10309 | best_loss 7.632
2022-03-04 17:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10309 updates
2022-03-04 17:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 107 @ 10309 updates, score 13.762) (writing took 2.6474546687677503 seconds)
2022-03-04 17:27:41 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-04 17:27:41 | INFO | train | epoch 107 | loss 1.368 | ppl 2.58 | wps 24091 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10309 | lr 0.000311452 | gnorm 1.1 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 28278
2022-03-04 17:27:41 | INFO | fairseq.trainer | begin training epoch 108
2022-03-04 17:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:28:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 17:31:44 | INFO | train_inner | epoch 108:     92 / 97 loss=1.354, ppl=2.56, wps=23875.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=1.082, loss_scale=32, train_wall=244, gb_free=8.2, wall=28521
2022-03-04 17:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:32:02 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.901 | ppl 15297.1 | wps 44889.9 | wpb 510.9 | bsz 1 | num_updates 10405 | best_loss 7.632
2022-03-04 17:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10405 updates
2022-03-04 17:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 108 @ 10405 updates, score 13.901) (writing took 2.311059530824423 seconds)
2022-03-04 17:32:04 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-04 17:32:04 | INFO | train | epoch 108 | loss 1.35 | ppl 2.55 | wps 23869.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 10405 | lr 0.000310012 | gnorm 1.082 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 28541
2022-03-04 17:32:04 | INFO | fairseq.trainer | begin training epoch 109
2022-03-04 17:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:34:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 17:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 17:36:21 | INFO | train_inner | epoch 109:     97 / 97 loss=1.341, ppl=2.53, wps=23670.4, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=10500, lr=0.000308607, gnorm=1.091, loss_scale=16, train_wall=246, gb_free=8.2, wall=28797
2022-03-04 17:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:36:26 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 13.872 | ppl 14988.6 | wps 44806.9 | wpb 510.9 | bsz 1 | num_updates 10500 | best_loss 7.632
2022-03-04 17:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10500 updates
2022-03-04 17:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:36:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:36:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 109 @ 10500 updates, score 13.872) (writing took 2.4170187478885055 seconds)
2022-03-04 17:36:28 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-04 17:36:28 | INFO | train | epoch 109 | loss 1.337 | ppl 2.53 | wps 23603.3 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 10500 | lr 0.000308607 | gnorm 1.089 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 28805
2022-03-04 17:36:28 | INFO | fairseq.trainer | begin training epoch 110
2022-03-04 17:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:40:49 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 13.953 | ppl 15857.2 | wps 43080 | wpb 510.9 | bsz 1 | num_updates 10597 | best_loss 7.632
2022-03-04 17:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10597 updates
2022-03-04 17:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 110 @ 10597 updates, score 13.953) (writing took 2.3895508479326963 seconds)
2022-03-04 17:40:52 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-04 17:40:52 | INFO | train | epoch 110 | loss 1.324 | ppl 2.5 | wps 24089 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10597 | lr 0.000307191 | gnorm 1.08 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 29069
2022-03-04 17:40:52 | INFO | fairseq.trainer | begin training epoch 111
2022-03-04 17:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:41:00 | INFO | train_inner | epoch 111:      3 / 97 loss=1.321, ppl=2.5, wps=23468.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=10600, lr=0.000307148, gnorm=1.079, loss_scale=32, train_wall=242, gb_free=8.2, wall=29077
2022-03-04 17:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:45:13 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.94 | ppl 15721.1 | wps 45249 | wpb 510.9 | bsz 1 | num_updates 10694 | best_loss 7.632
2022-03-04 17:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10694 updates
2022-03-04 17:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:45:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 111 @ 10694 updates, score 13.94) (writing took 2.444133793003857 seconds)
2022-03-04 17:45:15 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-04 17:45:15 | INFO | train | epoch 111 | loss 1.309 | ppl 2.48 | wps 24111.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10694 | lr 0.000305795 | gnorm 1.085 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 29332
2022-03-04 17:45:15 | INFO | fairseq.trainer | begin training epoch 112
2022-03-04 17:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:45:31 | INFO | train_inner | epoch 112:      6 / 97 loss=1.307, ppl=2.48, wps=24131.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=1.084, loss_scale=32, train_wall=242, gb_free=8.2, wall=29348
2022-03-04 17:46:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 17:47:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 17:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:49:36 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 14.055 | ppl 17015.8 | wps 44981.3 | wpb 510.9 | bsz 1 | num_updates 10789 | best_loss 7.632
2022-03-04 17:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10789 updates
2022-03-04 17:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 112 @ 10789 updates, score 14.055) (writing took 2.3490329440683126 seconds)
2022-03-04 17:49:38 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-04 17:49:38 | INFO | train | epoch 112 | loss 1.295 | ppl 2.45 | wps 23628.7 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 10789 | lr 0.000304445 | gnorm 1.089 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 29595
2022-03-04 17:49:38 | INFO | fairseq.trainer | begin training epoch 113
2022-03-04 17:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:50:08 | INFO | train_inner | epoch 113:     11 / 97 loss=1.289, ppl=2.44, wps=23690.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=1.086, loss_scale=16, train_wall=246, gb_free=8.2, wall=29624
2022-03-04 17:53:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:53:59 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 14.11 | ppl 17680.9 | wps 45045.3 | wpb 510.9 | bsz 1 | num_updates 10886 | best_loss 7.632
2022-03-04 17:53:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10886 updates
2022-03-04 17:53:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 113 @ 10886 updates, score 14.11) (writing took 2.588069320656359 seconds)
2022-03-04 17:54:02 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-04 17:54:02 | INFO | train | epoch 113 | loss 1.282 | ppl 2.43 | wps 24095.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10886 | lr 0.000303086 | gnorm 1.077 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 29859
2022-03-04 17:54:02 | INFO | fairseq.trainer | begin training epoch 114
2022-03-04 17:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:54:39 | INFO | train_inner | epoch 114:     14 / 97 loss=1.28, ppl=2.43, wps=24115.7, ups=0.37, wpb=65495, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=1.075, loss_scale=32, train_wall=242, gb_free=8.2, wall=29896
2022-03-04 17:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 17:58:23 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 14.101 | ppl 17569.7 | wps 44803.8 | wpb 510.9 | bsz 1 | num_updates 10983 | best_loss 7.632
2022-03-04 17:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10983 updates
2022-03-04 17:58:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:58:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 17:58:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 114 @ 10983 updates, score 14.101) (writing took 2.330312704667449 seconds)
2022-03-04 17:58:25 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-04 17:58:25 | INFO | train | epoch 114 | loss 1.268 | ppl 2.41 | wps 24125.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 10983 | lr 0.000301745 | gnorm 1.066 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 30122
2022-03-04 17:58:25 | INFO | fairseq.trainer | begin training epoch 115
2022-03-04 17:58:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 17:59:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 17:59:13 | INFO | train_inner | epoch 115:     18 / 97 loss=1.265, ppl=2.4, wps=23915.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=1.062, loss_scale=32, train_wall=244, gb_free=8.2, wall=30170
2022-03-04 18:02:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:02:46 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 14.174 | ppl 18487.1 | wps 44989.6 | wpb 510.9 | bsz 1 | num_updates 11079 | best_loss 7.632
2022-03-04 18:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11079 updates
2022-03-04 18:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 115 @ 11079 updates, score 14.174) (writing took 2.5058759413659573 seconds)
2022-03-04 18:02:49 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-04 18:02:49 | INFO | train | epoch 115 | loss 1.257 | ppl 2.39 | wps 23855.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11079 | lr 0.000300434 | gnorm 1.072 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 30386
2022-03-04 18:02:49 | INFO | fairseq.trainer | begin training epoch 116
2022-03-04 18:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:03:45 | INFO | train_inner | epoch 116:     21 / 97 loss=1.253, ppl=2.38, wps=24117.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=1.081, loss_scale=32, train_wall=242, gb_free=8.2, wall=30441
2022-03-04 18:04:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 18:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:07:10 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 14.164 | ppl 18359.5 | wps 44820.7 | wpb 510.9 | bsz 1 | num_updates 11175 | best_loss 7.632
2022-03-04 18:07:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11175 updates
2022-03-04 18:07:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 116 @ 11175 updates, score 14.164) (writing took 2.3794638384133577 seconds)
2022-03-04 18:07:13 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-04 18:07:13 | INFO | train | epoch 116 | loss 1.243 | ppl 2.37 | wps 23847.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11175 | lr 0.000299141 | gnorm 1.072 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 30649
2022-03-04 18:07:13 | INFO | fairseq.trainer | begin training epoch 117
2022-03-04 18:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:08:19 | INFO | train_inner | epoch 117:     25 / 97 loss=1.24, ppl=2.36, wps=23869.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=1.071, loss_scale=32, train_wall=244, gb_free=8.2, wall=30716
2022-03-04 18:10:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 18:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:11:34 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 14.275 | ppl 19830.9 | wps 44548.7 | wpb 510.9 | bsz 1 | num_updates 11271 | best_loss 7.632
2022-03-04 18:11:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11271 updates
2022-03-04 18:11:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:11:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:11:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 117 @ 11271 updates, score 14.275) (writing took 2.50804659165442 seconds)
2022-03-04 18:11:37 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-04 18:11:37 | INFO | train | epoch 117 | loss 1.231 | ppl 2.35 | wps 23807.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11271 | lr 0.000297865 | gnorm 1.076 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 30914
2022-03-04 18:11:37 | INFO | fairseq.trainer | begin training epoch 118
2022-03-04 18:11:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:12:54 | INFO | train_inner | epoch 118:     29 / 97 loss=1.224, ppl=2.34, wps=23846.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=1.072, loss_scale=32, train_wall=244, gb_free=8.2, wall=30990
2022-03-04 18:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 18:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:15:58 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 14.257 | ppl 19577.9 | wps 44649.1 | wpb 510.9 | bsz 1 | num_updates 11367 | best_loss 7.632
2022-03-04 18:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11367 updates
2022-03-04 18:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:16:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:16:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 118 @ 11367 updates, score 14.257) (writing took 2.3504576152190566 seconds)
2022-03-04 18:16:00 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-04 18:16:00 | INFO | train | epoch 118 | loss 1.22 | ppl 2.33 | wps 23840 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11367 | lr 0.000296604 | gnorm 1.082 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 31177
2022-03-04 18:16:00 | INFO | fairseq.trainer | begin training epoch 119
2022-03-04 18:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:17:28 | INFO | train_inner | epoch 119:     33 / 97 loss=1.216, ppl=2.32, wps=23880.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=1.078, loss_scale=16, train_wall=244, gb_free=8.2, wall=31265
2022-03-04 18:20:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:20:22 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 14.268 | ppl 19726.5 | wps 45064.1 | wpb 510.9 | bsz 1 | num_updates 11464 | best_loss 7.632
2022-03-04 18:20:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11464 updates
2022-03-04 18:20:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:20:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:20:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 119 @ 11464 updates, score 14.268) (writing took 2.349769507534802 seconds)
2022-03-04 18:20:24 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-04 18:20:24 | INFO | train | epoch 119 | loss 1.209 | ppl 2.31 | wps 24095.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 11464 | lr 0.000295347 | gnorm 1.073 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 31441
2022-03-04 18:20:24 | INFO | fairseq.trainer | begin training epoch 120
2022-03-04 18:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:21:59 | INFO | train_inner | epoch 120:     36 / 97 loss=1.203, ppl=2.3, wps=24124.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=1.067, loss_scale=32, train_wall=242, gb_free=8.2, wall=31536
2022-03-04 18:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 18:24:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:24:45 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 14.455 | ppl 22463.3 | wps 44906.5 | wpb 510.9 | bsz 1 | num_updates 11560 | best_loss 7.632
2022-03-04 18:24:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11560 updates
2022-03-04 18:24:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 120 @ 11560 updates, score 14.455) (writing took 2.3127738209441304 seconds)
2022-03-04 18:24:48 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-04 18:24:48 | INFO | train | epoch 120 | loss 1.196 | ppl 2.29 | wps 23847.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11560 | lr 0.000294118 | gnorm 1.065 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 31705
2022-03-04 18:24:48 | INFO | fairseq.trainer | begin training epoch 121
2022-03-04 18:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:26:34 | INFO | train_inner | epoch 121:     40 / 97 loss=1.193, ppl=2.29, wps=23880.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=1.071, loss_scale=16, train_wall=244, gb_free=8.2, wall=31810
2022-03-04 18:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:29:09 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 14.444 | ppl 22296 | wps 44848.3 | wpb 510.9 | bsz 1 | num_updates 11657 | best_loss 7.632
2022-03-04 18:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11657 updates
2022-03-04 18:29:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 121 @ 11657 updates, score 14.444) (writing took 2.3654736522585154 seconds)
2022-03-04 18:29:11 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-04 18:29:11 | INFO | train | epoch 121 | loss 1.186 | ppl 2.27 | wps 24104.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 11657 | lr 0.000292891 | gnorm 1.068 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 31968
2022-03-04 18:29:11 | INFO | fairseq.trainer | begin training epoch 122
2022-03-04 18:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:31:05 | INFO | train_inner | epoch 122:     43 / 97 loss=1.183, ppl=2.27, wps=24129.8, ups=0.37, wpb=65495, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=1.075, loss_scale=32, train_wall=242, gb_free=8.2, wall=32082
2022-03-04 18:32:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 18:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:33:32 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 14.511 | ppl 23341.5 | wps 44784.8 | wpb 510.9 | bsz 1 | num_updates 11753 | best_loss 7.632
2022-03-04 18:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11753 updates
2022-03-04 18:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 122 @ 11753 updates, score 14.511) (writing took 2.330533916130662 seconds)
2022-03-04 18:33:35 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-04 18:33:35 | INFO | train | epoch 122 | loss 1.174 | ppl 2.26 | wps 23854.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11753 | lr 0.000291693 | gnorm 1.072 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 32232
2022-03-04 18:33:35 | INFO | fairseq.trainer | begin training epoch 123
2022-03-04 18:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:35:39 | INFO | train_inner | epoch 123:     47 / 97 loss=1.17, ppl=2.25, wps=23884.7, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=1.062, loss_scale=16, train_wall=244, gb_free=8.2, wall=32356
2022-03-04 18:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:37:56 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 14.568 | ppl 24284.7 | wps 44733 | wpb 510.9 | bsz 1 | num_updates 11850 | best_loss 7.632
2022-03-04 18:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11850 updates
2022-03-04 18:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:37:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:37:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 123 @ 11850 updates, score 14.568) (writing took 2.469073634594679 seconds)
2022-03-04 18:37:58 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-04 18:37:58 | INFO | train | epoch 123 | loss 1.164 | ppl 2.24 | wps 24091.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 11850 | lr 0.000290496 | gnorm 1.063 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 32495
2022-03-04 18:37:58 | INFO | fairseq.trainer | begin training epoch 124
2022-03-04 18:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:40:11 | INFO | train_inner | epoch 124:     50 / 97 loss=1.155, ppl=2.23, wps=24113.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=1.06, loss_scale=32, train_wall=242, gb_free=8.2, wall=32628
2022-03-04 18:40:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 18:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:42:20 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 14.615 | ppl 25088.2 | wps 44852 | wpb 510.9 | bsz 1 | num_updates 11946 | best_loss 7.632
2022-03-04 18:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11946 updates
2022-03-04 18:42:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:42:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:42:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 124 @ 11946 updates, score 14.615) (writing took 2.4191614938899875 seconds)
2022-03-04 18:42:22 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-04 18:42:22 | INFO | train | epoch 124 | loss 1.151 | ppl 2.22 | wps 23847.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 11946 | lr 0.000289327 | gnorm 1.058 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 32759
2022-03-04 18:42:22 | INFO | fairseq.trainer | begin training epoch 125
2022-03-04 18:42:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:44:45 | INFO | train_inner | epoch 125:     54 / 97 loss=1.147, ppl=2.21, wps=23877.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=1.057, loss_scale=16, train_wall=244, gb_free=8.2, wall=32902
2022-03-04 18:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:46:43 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 14.566 | ppl 24248 | wps 44845.6 | wpb 510.9 | bsz 1 | num_updates 12043 | best_loss 7.632
2022-03-04 18:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12043 updates
2022-03-04 18:46:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 125 @ 12043 updates, score 14.566) (writing took 2.3055403353646398 seconds)
2022-03-04 18:46:46 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-04 18:46:46 | INFO | train | epoch 125 | loss 1.143 | ppl 2.21 | wps 24096.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 12043 | lr 0.000288159 | gnorm 1.061 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 33023
2022-03-04 18:46:46 | INFO | fairseq.trainer | begin training epoch 126
2022-03-04 18:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:49:17 | INFO | train_inner | epoch 126:     57 / 97 loss=1.141, ppl=2.21, wps=24123.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=1.064, loss_scale=32, train_wall=242, gb_free=8.2, wall=33173
2022-03-04 18:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:51:07 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 14.622 | ppl 25219.2 | wps 44958.3 | wpb 510.9 | bsz 1 | num_updates 12140 | best_loss 7.632
2022-03-04 18:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12140 updates
2022-03-04 18:51:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:51:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 126 @ 12140 updates, score 14.622) (writing took 2.3465994661673903 seconds)
2022-03-04 18:51:09 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-04 18:51:09 | INFO | train | epoch 126 | loss 1.133 | ppl 2.19 | wps 24100.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 12140 | lr 0.000287006 | gnorm 1.067 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 33286
2022-03-04 18:51:09 | INFO | fairseq.trainer | begin training epoch 127
2022-03-04 18:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:52:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 18:53:51 | INFO | train_inner | epoch 127:     61 / 97 loss=1.121, ppl=2.18, wps=23891.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=1.066, loss_scale=32, train_wall=244, gb_free=8.2, wall=33448
2022-03-04 18:55:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:55:31 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 14.749 | ppl 27536.2 | wps 44867.6 | wpb 510.9 | bsz 1 | num_updates 12236 | best_loss 7.632
2022-03-04 18:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12236 updates
2022-03-04 18:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:55:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 127 @ 12236 updates, score 14.749) (writing took 2.3691614056006074 seconds)
2022-03-04 18:55:33 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-04 18:55:33 | INFO | train | epoch 127 | loss 1.12 | ppl 2.17 | wps 23835.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 12236 | lr 0.000285878 | gnorm 1.057 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 33550
2022-03-04 18:55:33 | INFO | fairseq.trainer | begin training epoch 128
2022-03-04 18:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 18:58:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 18:58:25 | INFO | train_inner | epoch 128:     65 / 97 loss=1.119, ppl=2.17, wps=23885.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=1.063, loss_scale=32, train_wall=244, gb_free=8.2, wall=33722
2022-03-04 18:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 18:59:54 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 14.799 | ppl 28504.6 | wps 44929.1 | wpb 510.9 | bsz 1 | num_updates 12332 | best_loss 7.632
2022-03-04 18:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12332 updates
2022-03-04 18:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 18:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 128 @ 12332 updates, score 14.799) (writing took 2.4097371520474553 seconds)
2022-03-04 18:59:57 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-04 18:59:57 | INFO | train | epoch 128 | loss 1.114 | ppl 2.16 | wps 23861 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 12332 | lr 0.000284763 | gnorm 1.064 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 33813
2022-03-04 18:59:57 | INFO | fairseq.trainer | begin training epoch 129
2022-03-04 18:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:02:56 | INFO | train_inner | epoch 129:     68 / 97 loss=1.108, ppl=2.16, wps=24122.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=1.06, loss_scale=32, train_wall=242, gb_free=8.2, wall=33993
2022-03-04 19:03:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:04:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:04:18 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 14.799 | ppl 28507 | wps 44904.5 | wpb 510.9 | bsz 1 | num_updates 12428 | best_loss 7.632
2022-03-04 19:04:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12428 updates
2022-03-04 19:04:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:04:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:04:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 129 @ 12428 updates, score 14.799) (writing took 2.3394534662365913 seconds)
2022-03-04 19:04:20 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-04 19:04:20 | INFO | train | epoch 129 | loss 1.103 | ppl 2.15 | wps 23861.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 12428 | lr 0.000283661 | gnorm 1.059 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 34077
2022-03-04 19:04:20 | INFO | fairseq.trainer | begin training epoch 130
2022-03-04 19:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:07:31 | INFO | train_inner | epoch 130:     72 / 97 loss=1.098, ppl=2.14, wps=23884.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=1.067, loss_scale=16, train_wall=244, gb_free=8.2, wall=34267
2022-03-04 19:08:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:08:41 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 14.796 | ppl 28445.8 | wps 44800.3 | wpb 510.9 | bsz 1 | num_updates 12525 | best_loss 7.632
2022-03-04 19:08:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12525 updates
2022-03-04 19:08:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:08:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:08:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 130 @ 12525 updates, score 14.796) (writing took 2.4431362664327025 seconds)
2022-03-04 19:08:44 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-04 19:08:44 | INFO | train | epoch 130 | loss 1.093 | ppl 2.13 | wps 24085.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 12525 | lr 0.00028256 | gnorm 1.066 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 34341
2022-03-04 19:08:44 | INFO | fairseq.trainer | begin training epoch 131
2022-03-04 19:08:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:11:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:12:05 | INFO | train_inner | epoch 131:     76 / 97 loss=1.085, ppl=2.12, wps=23895.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=1.051, loss_scale=16, train_wall=244, gb_free=8.2, wall=34542
2022-03-04 19:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:13:05 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 14.827 | ppl 29074 | wps 44842.3 | wpb 510.9 | bsz 1 | num_updates 12621 | best_loss 7.632
2022-03-04 19:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12621 updates
2022-03-04 19:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 131 @ 12621 updates, score 14.827) (writing took 2.7542367167770863 seconds)
2022-03-04 19:13:08 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-04 19:13:08 | INFO | train | epoch 131 | loss 1.084 | ppl 2.12 | wps 23833.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 12621 | lr 0.000281484 | gnorm 1.052 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 34604
2022-03-04 19:13:08 | INFO | fairseq.trainer | begin training epoch 132
2022-03-04 19:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:16:37 | INFO | train_inner | epoch 132:     79 / 97 loss=1.08, ppl=2.11, wps=24074.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=1.068, loss_scale=16, train_wall=242, gb_free=8.2, wall=34814
2022-03-04 19:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:17:29 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 14.914 | ppl 30874.1 | wps 44754.3 | wpb 510.9 | bsz 1 | num_updates 12718 | best_loss 7.632
2022-03-04 19:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12718 updates
2022-03-04 19:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 132 @ 12718 updates, score 14.914) (writing took 2.4122072057798505 seconds)
2022-03-04 19:17:31 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-04 19:17:31 | INFO | train | epoch 132 | loss 1.076 | ppl 2.11 | wps 24079.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 12718 | lr 0.000280408 | gnorm 1.073 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 34868
2022-03-04 19:17:31 | INFO | fairseq.trainer | begin training epoch 133
2022-03-04 19:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:21:11 | INFO | train_inner | epoch 133:     83 / 97 loss=1.066, ppl=2.09, wps=23877.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=1.065, loss_scale=16, train_wall=244, gb_free=8.2, wall=35088
2022-03-04 19:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:21:53 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 14.983 | ppl 32388.2 | wps 44942.2 | wpb 510.9 | bsz 1 | num_updates 12814 | best_loss 7.632
2022-03-04 19:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12814 updates
2022-03-04 19:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:21:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:21:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 133 @ 12814 updates, score 14.983) (writing took 2.3219192503020167 seconds)
2022-03-04 19:21:55 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-04 19:21:55 | INFO | train | epoch 133 | loss 1.064 | ppl 2.09 | wps 23843.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 12814 | lr 0.000279356 | gnorm 1.06 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 35132
2022-03-04 19:21:55 | INFO | fairseq.trainer | begin training epoch 134
2022-03-04 19:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:25:43 | INFO | train_inner | epoch 134:     86 / 97 loss=1.058, ppl=2.08, wps=24115.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=1.054, loss_scale=32, train_wall=242, gb_free=8.2, wall=35359
2022-03-04 19:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:26:16 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 14.982 | ppl 32369 | wps 44649.5 | wpb 510.9 | bsz 1 | num_updates 12911 | best_loss 7.632
2022-03-04 19:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12911 updates
2022-03-04 19:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:26:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:26:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 134 @ 12911 updates, score 14.982) (writing took 2.374741965904832 seconds)
2022-03-04 19:26:19 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-04 19:26:19 | INFO | train | epoch 134 | loss 1.056 | ppl 2.08 | wps 24089.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 12911 | lr 0.000278304 | gnorm 1.049 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 35396
2022-03-04 19:26:19 | INFO | fairseq.trainer | begin training epoch 135
2022-03-04 19:26:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:27:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:30:17 | INFO | train_inner | epoch 135:     90 / 97 loss=1.051, ppl=2.07, wps=23874.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=1.042, loss_scale=16, train_wall=244, gb_free=8.2, wall=35634
2022-03-04 19:30:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:30:40 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 14.977 | ppl 32246.2 | wps 44824.4 | wpb 510.9 | bsz 1 | num_updates 13007 | best_loss 7.632
2022-03-04 19:30:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13007 updates
2022-03-04 19:30:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:30:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:30:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 135 @ 13007 updates, score 14.977) (writing took 2.479179727844894 seconds)
2022-03-04 19:30:43 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-04 19:30:43 | INFO | train | epoch 135 | loss 1.048 | ppl 2.07 | wps 23834.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13007 | lr 0.000277275 | gnorm 1.045 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 35660
2022-03-04 19:30:43 | INFO | fairseq.trainer | begin training epoch 136
2022-03-04 19:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:34:48 | INFO | train_inner | epoch 136:     93 / 97 loss=1.044, ppl=2.06, wps=24117.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=1.049, loss_scale=32, train_wall=242, gb_free=8.2, wall=35905
2022-03-04 19:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:35:04 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 15.078 | ppl 34585.9 | wps 44972.5 | wpb 510.9 | bsz 1 | num_updates 13104 | best_loss 7.632
2022-03-04 19:35:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13104 updates
2022-03-04 19:35:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 136 @ 13104 updates, score 15.078) (writing took 2.4382165614515543 seconds)
2022-03-04 19:35:06 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-04 19:35:06 | INFO | train | epoch 136 | loss 1.042 | ppl 2.06 | wps 24104.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 13104 | lr 0.000276247 | gnorm 1.045 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 35923
2022-03-04 19:35:06 | INFO | fairseq.trainer | begin training epoch 137
2022-03-04 19:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:39:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:39:22 | INFO | train_inner | epoch 137:     97 / 97 loss=1.033, ppl=2.05, wps=23889.9, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=13200, lr=0.000275241, gnorm=1.047, loss_scale=16, train_wall=244, gb_free=8.2, wall=36179
2022-03-04 19:39:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:39:27 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 15.112 | ppl 35411.8 | wps 44933 | wpb 510.9 | bsz 1 | num_updates 13200 | best_loss 7.632
2022-03-04 19:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13200 updates
2022-03-04 19:39:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:39:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:39:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 137 @ 13200 updates, score 15.112) (writing took 2.3286456214264035 seconds)
2022-03-04 19:39:30 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-04 19:39:30 | INFO | train | epoch 137 | loss 1.03 | ppl 2.04 | wps 23862.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13200 | lr 0.000275241 | gnorm 1.047 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 36187
2022-03-04 19:39:30 | INFO | fairseq.trainer | begin training epoch 138
2022-03-04 19:39:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:43:51 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 15.173 | ppl 36943.8 | wps 44882.7 | wpb 510.9 | bsz 1 | num_updates 13297 | best_loss 7.632
2022-03-04 19:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13297 updates
2022-03-04 19:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:43:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:43:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 138 @ 13297 updates, score 15.173) (writing took 2.377533718943596 seconds)
2022-03-04 19:43:53 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-04 19:43:53 | INFO | train | epoch 138 | loss 1.024 | ppl 2.03 | wps 24110.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 13297 | lr 0.000274235 | gnorm 1.049 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 36450
2022-03-04 19:43:53 | INFO | fairseq.trainer | begin training epoch 139
2022-03-04 19:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:44:01 | INFO | train_inner | epoch 139:      3 / 97 loss=1.023, ppl=2.03, wps=23496, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=13300, lr=0.000274204, gnorm=1.049, loss_scale=16, train_wall=242, gb_free=8.2, wall=36458
2022-03-04 19:46:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:48:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:48:14 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 15.129 | ppl 35840.4 | wps 44832 | wpb 510.9 | bsz 1 | num_updates 13393 | best_loss 7.632
2022-03-04 19:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13393 updates
2022-03-04 19:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 139 @ 13393 updates, score 15.129) (writing took 2.3344200290739536 seconds)
2022-03-04 19:48:17 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-04 19:48:17 | INFO | train | epoch 139 | loss 1.014 | ppl 2.02 | wps 23872.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13393 | lr 0.000273251 | gnorm 1.043 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 36713
2022-03-04 19:48:17 | INFO | fairseq.trainer | begin training epoch 140
2022-03-04 19:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:48:35 | INFO | train_inner | epoch 140:      7 / 97 loss=1.012, ppl=2.02, wps=23910, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=1.039, loss_scale=16, train_wall=244, gb_free=8.2, wall=36732
2022-03-04 19:52:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 19:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:52:38 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 15.214 | ppl 38003.3 | wps 44961.3 | wpb 510.9 | bsz 1 | num_updates 13489 | best_loss 7.632
2022-03-04 19:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13489 updates
2022-03-04 19:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 140 @ 13489 updates, score 15.214) (writing took 2.3487581983208656 seconds)
2022-03-04 19:52:40 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-04 19:52:40 | INFO | train | epoch 140 | loss 1.008 | ppl 2.01 | wps 23867.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13489 | lr 0.000272276 | gnorm 1.031 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 36977
2022-03-04 19:52:40 | INFO | fairseq.trainer | begin training epoch 141
2022-03-04 19:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:53:09 | INFO | train_inner | epoch 141:     11 / 97 loss=1.004, ppl=2.01, wps=23904, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=1.032, loss_scale=16, train_wall=244, gb_free=8.2, wall=37006
2022-03-04 19:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 19:57:01 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 15.132 | ppl 35896.4 | wps 44821.2 | wpb 510.9 | bsz 1 | num_updates 13586 | best_loss 7.632
2022-03-04 19:57:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13586 updates
2022-03-04 19:57:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 19:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 141 @ 13586 updates, score 15.132) (writing took 2.3593881027773023 seconds)
2022-03-04 19:57:03 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-04 19:57:03 | INFO | train | epoch 141 | loss 1.001 | ppl 2 | wps 24119.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 13586 | lr 0.000271303 | gnorm 1.041 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 37240
2022-03-04 19:57:03 | INFO | fairseq.trainer | begin training epoch 142
2022-03-04 19:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 19:57:40 | INFO | train_inner | epoch 142:     14 / 97 loss=1.002, ppl=2, wps=24130, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=1.043, loss_scale=16, train_wall=242, gb_free=8.2, wall=37277
2022-03-04 19:59:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:01:24 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 15.277 | ppl 39713.4 | wps 44819.9 | wpb 510.9 | bsz 1 | num_updates 13682 | best_loss 7.632
2022-03-04 20:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13682 updates
2022-03-04 20:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 142 @ 13682 updates, score 15.277) (writing took 2.4445051727816463 seconds)
2022-03-04 20:01:27 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-04 20:01:27 | INFO | train | epoch 142 | loss 0.991 | ppl 1.99 | wps 23854.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13682 | lr 0.000270349 | gnorm 1.047 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 37504
2022-03-04 20:01:27 | INFO | fairseq.trainer | begin training epoch 143
2022-03-04 20:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:02:15 | INFO | train_inner | epoch 143:     18 / 97 loss=0.988, ppl=1.98, wps=23892.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=1.045, loss_scale=16, train_wall=244, gb_free=8.2, wall=37551
2022-03-04 20:05:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:05:48 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 15.33 | ppl 41188.9 | wps 44816.1 | wpb 510.9 | bsz 1 | num_updates 13779 | best_loss 7.632
2022-03-04 20:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13779 updates
2022-03-04 20:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:05:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:05:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 143 @ 13779 updates, score 15.33) (writing took 2.315127095207572 seconds)
2022-03-04 20:05:51 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-04 20:05:51 | INFO | train | epoch 143 | loss 0.985 | ppl 1.98 | wps 24088.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 13779 | lr 0.000269396 | gnorm 1.03 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 37767
2022-03-04 20:05:51 | INFO | fairseq.trainer | begin training epoch 144
2022-03-04 20:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:06:46 | INFO | train_inner | epoch 144:     21 / 97 loss=0.983, ppl=1.98, wps=24113.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=1.025, loss_scale=32, train_wall=242, gb_free=8.2, wall=37823
2022-03-04 20:07:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:10:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:10:12 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 15.32 | ppl 40898.1 | wps 44934.4 | wpb 510.9 | bsz 1 | num_updates 13875 | best_loss 7.632
2022-03-04 20:10:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13875 updates
2022-03-04 20:10:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:10:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:10:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 144 @ 13875 updates, score 15.32) (writing took 2.3301583360880613 seconds)
2022-03-04 20:10:14 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-04 20:10:14 | INFO | train | epoch 144 | loss 0.978 | ppl 1.97 | wps 23837.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 13875 | lr 0.000268462 | gnorm 1.03 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 38031
2022-03-04 20:10:14 | INFO | fairseq.trainer | begin training epoch 145
2022-03-04 20:10:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:11:21 | INFO | train_inner | epoch 145:     25 / 97 loss=0.973, ppl=1.96, wps=23874.1, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=1.028, loss_scale=16, train_wall=244, gb_free=8.2, wall=38097
2022-03-04 20:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:14:36 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 15.414 | ppl 43651 | wps 44841 | wpb 510.9 | bsz 1 | num_updates 13972 | best_loss 7.632
2022-03-04 20:14:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13972 updates
2022-03-04 20:14:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 145 @ 13972 updates, score 15.414) (writing took 2.4761830354109406 seconds)
2022-03-04 20:14:38 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-04 20:14:38 | INFO | train | epoch 145 | loss 0.971 | ppl 1.96 | wps 24077.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 13972 | lr 0.000267529 | gnorm 1.031 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 38295
2022-03-04 20:14:38 | INFO | fairseq.trainer | begin training epoch 146
2022-03-04 20:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:14:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:15:55 | INFO | train_inner | epoch 146:     29 / 97 loss=0.97, ppl=1.96, wps=23862.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=1.034, loss_scale=16, train_wall=244, gb_free=8.2, wall=38372
2022-03-04 20:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:19:00 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 15.38 | ppl 42649 | wps 44966.4 | wpb 510.9 | bsz 1 | num_updates 14068 | best_loss 7.632
2022-03-04 20:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14068 updates
2022-03-04 20:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 146 @ 14068 updates, score 15.38) (writing took 2.3250496461987495 seconds)
2022-03-04 20:19:02 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-04 20:19:02 | INFO | train | epoch 146 | loss 0.963 | ppl 1.95 | wps 23819.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 14068 | lr 0.000266615 | gnorm 1.027 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 38559
2022-03-04 20:19:02 | INFO | fairseq.trainer | begin training epoch 147
2022-03-04 20:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:20:27 | INFO | train_inner | epoch 147:     32 / 97 loss=0.957, ppl=1.94, wps=24093.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=1.017, loss_scale=16, train_wall=242, gb_free=8.2, wall=38644
2022-03-04 20:21:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:23:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:23:23 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 15.348 | ppl 41712.7 | wps 44937.5 | wpb 510.9 | bsz 1 | num_updates 14164 | best_loss 7.632
2022-03-04 20:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14164 updates
2022-03-04 20:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 147 @ 14164 updates, score 15.348) (writing took 2.304361194372177 seconds)
2022-03-04 20:23:26 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-04 20:23:26 | INFO | train | epoch 147 | loss 0.957 | ppl 1.94 | wps 23863.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 14164 | lr 0.000265709 | gnorm 1.023 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 38822
2022-03-04 20:23:26 | INFO | fairseq.trainer | begin training epoch 148
2022-03-04 20:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:25:01 | INFO | train_inner | epoch 148:     36 / 97 loss=0.956, ppl=1.94, wps=23907.5, ups=0.37, wpb=65495, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=1.027, loss_scale=16, train_wall=244, gb_free=8.2, wall=38918
2022-03-04 20:27:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:27:47 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 15.343 | ppl 41569.3 | wps 44796.1 | wpb 510.9 | bsz 1 | num_updates 14261 | best_loss 7.632
2022-03-04 20:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14261 updates
2022-03-04 20:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 148 @ 14261 updates, score 15.343) (writing took 2.521462027914822 seconds)
2022-03-04 20:27:49 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-04 20:27:49 | INFO | train | epoch 148 | loss 0.951 | ppl 1.93 | wps 24091.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 14261 | lr 0.000264804 | gnorm 1.028 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 39086
2022-03-04 20:27:49 | INFO | fairseq.trainer | begin training epoch 149
2022-03-04 20:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:29:32 | INFO | train_inner | epoch 149:     39 / 97 loss=0.947, ppl=1.93, wps=24102.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=1.028, loss_scale=32, train_wall=242, gb_free=8.2, wall=39189
2022-03-04 20:31:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:32:10 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 15.393 | ppl 43031.6 | wps 44641 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 7.632
2022-03-04 20:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14357 updates
2022-03-04 20:32:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:32:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:32:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 149 @ 14357 updates, score 15.393) (writing took 2.3496248172596097 seconds)
2022-03-04 20:32:13 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-04 20:32:13 | INFO | train | epoch 149 | loss 0.942 | ppl 1.92 | wps 23857.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 14357 | lr 0.000263917 | gnorm 1.031 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 39350
2022-03-04 20:32:13 | INFO | fairseq.trainer | begin training epoch 150
2022-03-04 20:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:34:06 | INFO | train_inner | epoch 150:     43 / 97 loss=0.939, ppl=1.92, wps=23907.1, ups=0.37, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=1.026, loss_scale=16, train_wall=244, gb_free=8.2, wall=39463
2022-03-04 20:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:36:34 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 15.524 | ppl 47116.1 | wps 44932.6 | wpb 510.9 | bsz 1 | num_updates 14454 | best_loss 7.632
2022-03-04 20:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14454 updates
2022-03-04 20:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 150 @ 14454 updates, score 15.524) (writing took 2.34517824370414 seconds)
2022-03-04 20:36:36 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-04 20:36:36 | INFO | train | epoch 150 | loss 0.936 | ppl 1.91 | wps 24120.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 14454 | lr 0.00026303 | gnorm 1.02 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 39613
2022-03-04 20:36:36 | INFO | fairseq.trainer | begin training epoch 151
2022-03-04 20:36:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:38:38 | INFO | train_inner | epoch 151:     46 / 97 loss=0.933, ppl=1.91, wps=24140.4, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=1.025, loss_scale=32, train_wall=242, gb_free=8.2, wall=39735
2022-03-04 20:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:40:57 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 15.544 | ppl 47763.8 | wps 45088.5 | wpb 510.9 | bsz 1 | num_updates 14551 | best_loss 7.632
2022-03-04 20:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14551 updates
2022-03-04 20:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:41:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:41:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 151 @ 14551 updates, score 15.544) (writing took 2.5488583650439978 seconds)
2022-03-04 20:41:00 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-04 20:41:00 | INFO | train | epoch 151 | loss 0.929 | ppl 1.9 | wps 24094.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 14551 | lr 0.000262152 | gnorm 1.02 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 39877
2022-03-04 20:41:00 | INFO | fairseq.trainer | begin training epoch 152
2022-03-04 20:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:43:09 | INFO | train_inner | epoch 152:     49 / 97 loss=0.926, ppl=1.9, wps=24108.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=1.008, loss_scale=32, train_wall=242, gb_free=8.2, wall=40006
2022-03-04 20:43:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 20:43:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:45:21 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 15.619 | ppl 50312.6 | wps 45005.2 | wpb 510.9 | bsz 1 | num_updates 14646 | best_loss 7.632
2022-03-04 20:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14646 updates
2022-03-04 20:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:45:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:45:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 152 @ 14646 updates, score 15.619) (writing took 2.4592629382386804 seconds)
2022-03-04 20:45:23 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-04 20:45:23 | INFO | train | epoch 152 | loss 0.923 | ppl 1.9 | wps 23614.2 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 14646 | lr 0.000261301 | gnorm 1.02 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 40140
2022-03-04 20:45:23 | INFO | fairseq.trainer | begin training epoch 153
2022-03-04 20:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:47:46 | INFO | train_inner | epoch 153:     54 / 97 loss=0.921, ppl=1.89, wps=23664.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=1.039, loss_scale=16, train_wall=246, gb_free=8.2, wall=40283
2022-03-04 20:49:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:49:45 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 15.568 | ppl 48561 | wps 44797.3 | wpb 510.9 | bsz 1 | num_updates 14743 | best_loss 7.632
2022-03-04 20:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14743 updates
2022-03-04 20:49:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 153 @ 14743 updates, score 15.568) (writing took 2.368857555091381 seconds)
2022-03-04 20:49:47 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-04 20:49:47 | INFO | train | epoch 153 | loss 0.916 | ppl 1.89 | wps 24096 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 14743 | lr 0.00026044 | gnorm 1.033 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 40404
2022-03-04 20:49:47 | INFO | fairseq.trainer | begin training epoch 154
2022-03-04 20:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:51:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:52:21 | INFO | train_inner | epoch 154:     58 / 97 loss=0.914, ppl=1.88, wps=23866, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=1.028, loss_scale=16, train_wall=244, gb_free=8.2, wall=40557
2022-03-04 20:54:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:54:08 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 15.61 | ppl 49996.9 | wps 44697.6 | wpb 510.9 | bsz 1 | num_updates 14839 | best_loss 7.632
2022-03-04 20:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14839 updates
2022-03-04 20:54:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:54:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:54:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 154 @ 14839 updates, score 15.61) (writing took 2.5076602464541793 seconds)
2022-03-04 20:54:11 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-04 20:54:11 | INFO | train | epoch 154 | loss 0.91 | ppl 1.88 | wps 23812.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 14839 | lr 0.000259596 | gnorm 1.016 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 40668
2022-03-04 20:54:11 | INFO | fairseq.trainer | begin training epoch 155
2022-03-04 20:54:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 20:56:52 | INFO | train_inner | epoch 155:     61 / 97 loss=0.905, ppl=1.87, wps=24109.5, ups=0.37, wpb=65495, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=1.009, loss_scale=16, train_wall=242, gb_free=8.2, wall=40829
2022-03-04 20:57:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 20:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 20:58:32 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 15.619 | ppl 50340.1 | wps 44956.5 | wpb 510.9 | bsz 1 | num_updates 14935 | best_loss 7.632
2022-03-04 20:58:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14935 updates
2022-03-04 20:58:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 20:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 155 @ 14935 updates, score 15.619) (writing took 2.353732262738049 seconds)
2022-03-04 20:58:34 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-04 20:58:34 | INFO | train | epoch 155 | loss 0.904 | ppl 1.87 | wps 23861.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 14935 | lr 0.00025876 | gnorm 1.014 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 40931
2022-03-04 20:58:34 | INFO | fairseq.trainer | begin training epoch 156
2022-03-04 20:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:01:26 | INFO | train_inner | epoch 156:     65 / 97 loss=0.902, ppl=1.87, wps=23880.9, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=1.016, loss_scale=16, train_wall=244, gb_free=8.2, wall=41103
2022-03-04 21:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:02:56 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 15.642 | ppl 51137.4 | wps 44848.2 | wpb 510.9 | bsz 1 | num_updates 15032 | best_loss 7.632
2022-03-04 21:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15032 updates
2022-03-04 21:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 156 @ 15032 updates, score 15.642) (writing took 6.482175488956273 seconds)
2022-03-04 21:03:02 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-04 21:03:02 | INFO | train | epoch 156 | loss 0.899 | ppl 1.86 | wps 23718.4 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 15032 | lr 0.000257924 | gnorm 1.018 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 41199
2022-03-04 21:03:02 | INFO | fairseq.trainer | begin training epoch 157
2022-03-04 21:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:04:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:06:05 | INFO | train_inner | epoch 157:     69 / 97 loss=0.894, ppl=1.86, wps=23544.2, ups=0.36, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=1.01, loss_scale=16, train_wall=244, gb_free=8.2, wall=41382
2022-03-04 21:07:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:07:23 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 15.728 | ppl 54290.2 | wps 44869.8 | wpb 510.9 | bsz 1 | num_updates 15128 | best_loss 7.632
2022-03-04 21:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15128 updates
2022-03-04 21:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:07:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 157 @ 15128 updates, score 15.728) (writing took 2.5516283428296447 seconds)
2022-03-04 21:07:26 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-04 21:07:26 | INFO | train | epoch 157 | loss 0.893 | ppl 1.86 | wps 23849.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15128 | lr 0.000257104 | gnorm 1.014 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 41463
2022-03-04 21:07:26 | INFO | fairseq.trainer | begin training epoch 158
2022-03-04 21:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:10:36 | INFO | train_inner | epoch 158:     72 / 97 loss=0.89, ppl=1.85, wps=24108.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=1.019, loss_scale=32, train_wall=242, gb_free=8.2, wall=41653
2022-03-04 21:10:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:11:47 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 15.724 | ppl 54139.4 | wps 44842.2 | wpb 510.9 | bsz 1 | num_updates 15224 | best_loss 7.632
2022-03-04 21:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15224 updates
2022-03-04 21:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:11:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 158 @ 15224 updates, score 15.724) (writing took 2.35697968211025 seconds)
2022-03-04 21:11:50 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-04 21:11:50 | INFO | train | epoch 158 | loss 0.887 | ppl 1.85 | wps 23853 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15224 | lr 0.000256292 | gnorm 1.018 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 41726
2022-03-04 21:11:50 | INFO | fairseq.trainer | begin training epoch 159
2022-03-04 21:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:15:11 | INFO | train_inner | epoch 159:     76 / 97 loss=0.884, ppl=1.85, wps=23885.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=1.018, loss_scale=16, train_wall=244, gb_free=8.2, wall=41927
2022-03-04 21:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:16:11 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 15.706 | ppl 53436.4 | wps 44923.8 | wpb 510.9 | bsz 1 | num_updates 15321 | best_loss 7.632
2022-03-04 21:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15321 updates
2022-03-04 21:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 159 @ 15321 updates, score 15.706) (writing took 2.384222935885191 seconds)
2022-03-04 21:16:13 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-04 21:16:13 | INFO | train | epoch 159 | loss 0.881 | ppl 1.84 | wps 24100.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 15321 | lr 0.00025548 | gnorm 1.014 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 41990
2022-03-04 21:16:13 | INFO | fairseq.trainer | begin training epoch 160
2022-03-04 21:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:19:42 | INFO | train_inner | epoch 160:     79 / 97 loss=0.878, ppl=1.84, wps=24127.1, ups=0.37, wpb=65495, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=1.007, loss_scale=32, train_wall=242, gb_free=8.2, wall=42199
2022-03-04 21:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:20:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:20:34 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 15.753 | ppl 55228.5 | wps 44893.7 | wpb 510.9 | bsz 1 | num_updates 15417 | best_loss 7.632
2022-03-04 21:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15417 updates
2022-03-04 21:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 160 @ 15417 updates, score 15.753) (writing took 2.488192794844508 seconds)
2022-03-04 21:20:37 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-04 21:20:37 | INFO | train | epoch 160 | loss 0.875 | ppl 1.83 | wps 23849.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15417 | lr 0.000254683 | gnorm 1.006 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 42254
2022-03-04 21:20:37 | INFO | fairseq.trainer | begin training epoch 161
2022-03-04 21:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:24:16 | INFO | train_inner | epoch 161:     83 / 97 loss=0.872, ppl=1.83, wps=23892.4, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=1.017, loss_scale=16, train_wall=244, gb_free=8.2, wall=42473
2022-03-04 21:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:24:58 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 15.816 | ppl 57669.7 | wps 44916.6 | wpb 510.9 | bsz 1 | num_updates 15514 | best_loss 7.632
2022-03-04 21:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15514 updates
2022-03-04 21:24:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 161 @ 15514 updates, score 15.816) (writing took 2.385457999072969 seconds)
2022-03-04 21:25:00 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-04 21:25:00 | INFO | train | epoch 161 | loss 0.87 | ppl 1.83 | wps 24112.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 15514 | lr 0.000253886 | gnorm 1.013 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 42517
2022-03-04 21:25:00 | INFO | fairseq.trainer | begin training epoch 162
2022-03-04 21:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:27:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:28:50 | INFO | train_inner | epoch 162:     87 / 97 loss=0.867, ppl=1.82, wps=23901.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=1.017, loss_scale=16, train_wall=244, gb_free=8.2, wall=42747
2022-03-04 21:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:29:21 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 15.924 | ppl 62174.9 | wps 44847.4 | wpb 510.9 | bsz 1 | num_updates 15610 | best_loss 7.632
2022-03-04 21:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15610 updates
2022-03-04 21:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 162 @ 15610 updates, score 15.924) (writing took 2.33521003741771 seconds)
2022-03-04 21:29:24 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-04 21:29:24 | INFO | train | epoch 162 | loss 0.864 | ppl 1.82 | wps 23869.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15610 | lr 0.000253104 | gnorm 1.017 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 42780
2022-03-04 21:29:24 | INFO | fairseq.trainer | begin training epoch 163
2022-03-04 21:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:33:22 | INFO | train_inner | epoch 163:     90 / 97 loss=0.859, ppl=1.81, wps=24124.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=1.002, loss_scale=32, train_wall=242, gb_free=8.2, wall=43018
2022-03-04 21:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:33:45 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 15.852 | ppl 59156 | wps 44920.5 | wpb 510.9 | bsz 1 | num_updates 15707 | best_loss 7.632
2022-03-04 21:33:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15707 updates
2022-03-04 21:33:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 163 @ 15707 updates, score 15.852) (writing took 2.3315393663942814 seconds)
2022-03-04 21:33:47 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-04 21:33:47 | INFO | train | epoch 163 | loss 0.858 | ppl 1.81 | wps 24105.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 15707 | lr 0.000252321 | gnorm 1 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 43044
2022-03-04 21:33:47 | INFO | fairseq.trainer | begin training epoch 164
2022-03-04 21:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:37:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:37:55 | INFO | train_inner | epoch 164:     94 / 97 loss=0.856, ppl=1.81, wps=23912.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=15800, lr=0.000251577, gnorm=1.002, loss_scale=16, train_wall=244, gb_free=8.2, wall=43292
2022-03-04 21:38:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:38:08 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 15.913 | ppl 61698.6 | wps 45076.3 | wpb 510.9 | bsz 1 | num_updates 15803 | best_loss 7.632
2022-03-04 21:38:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15803 updates
2022-03-04 21:38:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:38:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:38:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 164 @ 15803 updates, score 15.913) (writing took 2.37654113676399 seconds)
2022-03-04 21:38:10 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-04 21:38:10 | INFO | train | epoch 164 | loss 0.853 | ppl 1.81 | wps 23873.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15803 | lr 0.000251553 | gnorm 1 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 43307
2022-03-04 21:38:10 | INFO | fairseq.trainer | begin training epoch 165
2022-03-04 21:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:42:35 | INFO | train_inner | epoch 165:     97 / 97 loss=0.849, ppl=1.8, wps=23392.2, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=15900, lr=0.000250785, gnorm=0.995, loss_scale=16, train_wall=247, gb_free=8.2, wall=43572
2022-03-04 21:42:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:42:40 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 15.935 | ppl 62639.6 | wps 43731.6 | wpb 510.9 | bsz 1 | num_updates 15900 | best_loss 7.632
2022-03-04 21:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15900 updates
2022-03-04 21:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 165 @ 15900 updates, score 15.935) (writing took 3.1314904848113656 seconds)
2022-03-04 21:42:44 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-04 21:42:44 | INFO | train | epoch 165 | loss 0.848 | ppl 1.8 | wps 23265.5 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 15900 | lr 0.000250785 | gnorm 0.994 | loss_scale 16 | train_wall 240 | gb_free 8.2 | wall 43580
2022-03-04 21:42:44 | INFO | fairseq.trainer | begin training epoch 166
2022-03-04 21:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:47:06 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 15.909 | ppl 61530.6 | wps 45181.5 | wpb 510.9 | bsz 1 | num_updates 15996 | best_loss 7.632
2022-03-04 21:47:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15996 updates
2022-03-04 21:47:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 166 @ 15996 updates, score 15.909) (writing took 2.6400967249646783 seconds)
2022-03-04 21:47:08 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-04 21:47:08 | INFO | train | epoch 166 | loss 0.845 | ppl 1.8 | wps 23742.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 15996 | lr 0.000250031 | gnorm 1.005 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 43845
2022-03-04 21:47:08 | INFO | fairseq.trainer | begin training epoch 167
2022-03-04 21:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:47:19 | INFO | train_inner | epoch 167:      4 / 97 loss=0.843, ppl=1.79, wps=23081.3, ups=0.35, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=1.004, loss_scale=16, train_wall=245, gb_free=8.2, wall=43856
2022-03-04 21:50:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 21:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:51:30 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 15.931 | ppl 62476.8 | wps 45021.6 | wpb 510.9 | bsz 1 | num_updates 16092 | best_loss 7.632
2022-03-04 21:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16092 updates
2022-03-04 21:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 167 @ 16092 updates, score 15.931) (writing took 2.7248678393661976 seconds)
2022-03-04 21:51:33 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-04 21:51:33 | INFO | train | epoch 167 | loss 0.836 | ppl 1.79 | wps 23790.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16092 | lr 0.000249284 | gnorm 0.997 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 44109
2022-03-04 21:51:33 | INFO | fairseq.trainer | begin training epoch 168
2022-03-04 21:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:51:54 | INFO | train_inner | epoch 168:      8 / 97 loss=0.835, ppl=1.78, wps=23831.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.997, loss_scale=16, train_wall=244, gb_free=8.2, wall=44131
2022-03-04 21:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 21:55:54 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 15.968 | ppl 64102.9 | wps 44988.4 | wpb 510.9 | bsz 1 | num_updates 16189 | best_loss 7.632
2022-03-04 21:55:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16189 updates
2022-03-04 21:55:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 21:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 168 @ 16189 updates, score 15.968) (writing took 2.676618072204292 seconds)
2022-03-04 21:55:56 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-04 21:55:56 | INFO | train | epoch 168 | loss 0.832 | ppl 1.78 | wps 24090 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 16189 | lr 0.000248536 | gnorm 1 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 44373
2022-03-04 21:55:56 | INFO | fairseq.trainer | begin training epoch 169
2022-03-04 21:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 21:56:25 | INFO | train_inner | epoch 169:     11 / 97 loss=0.828, ppl=1.78, wps=24112.7, ups=0.37, wpb=65495, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.996, loss_scale=32, train_wall=242, gb_free=8.2, wall=44402
2022-03-04 21:57:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:00:18 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 16.061 | ppl 68362.7 | wps 44943.3 | wpb 510.9 | bsz 1 | num_updates 16285 | best_loss 7.632
2022-03-04 22:00:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16285 updates
2022-03-04 22:00:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:00:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:00:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 169 @ 16285 updates, score 16.061) (writing took 2.7585680186748505 seconds)
2022-03-04 22:00:21 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-04 22:00:21 | INFO | train | epoch 169 | loss 0.827 | ppl 1.77 | wps 23786 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16285 | lr 0.000247803 | gnorm 0.99 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 44637
2022-03-04 22:00:21 | INFO | fairseq.trainer | begin training epoch 170
2022-03-04 22:00:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:01:00 | INFO | train_inner | epoch 170:     15 / 97 loss=0.827, ppl=1.77, wps=23819, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.991, loss_scale=16, train_wall=244, gb_free=8.2, wall=44677
2022-03-04 22:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:04:42 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 16.085 | ppl 69492.7 | wps 45128 | wpb 510.9 | bsz 1 | num_updates 16382 | best_loss 7.632
2022-03-04 22:04:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16382 updates
2022-03-04 22:04:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:04:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 170 @ 16382 updates, score 16.085) (writing took 2.7115059178322554 seconds)
2022-03-04 22:04:45 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-04 22:04:45 | INFO | train | epoch 170 | loss 0.823 | ppl 1.77 | wps 24074 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 16382 | lr 0.000247068 | gnorm 0.985 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 44901
2022-03-04 22:04:45 | INFO | fairseq.trainer | begin training epoch 171
2022-03-04 22:04:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:05:32 | INFO | train_inner | epoch 171:     18 / 97 loss=0.823, ppl=1.77, wps=24102.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.985, loss_scale=32, train_wall=242, gb_free=8.2, wall=44949
2022-03-04 22:08:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-04 22:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:09:05 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 16.022 | ppl 66564.5 | wps 45135.2 | wpb 510.9 | bsz 1 | num_updates 16478 | best_loss 7.632
2022-03-04 22:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16478 updates
2022-03-04 22:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 171 @ 16478 updates, score 16.022) (writing took 2.5704225739464164 seconds)
2022-03-04 22:09:08 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-04 22:09:08 | INFO | train | epoch 171 | loss 0.818 | ppl 1.76 | wps 23864.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16478 | lr 0.000246347 | gnorm 0.991 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 45165
2022-03-04 22:09:08 | INFO | fairseq.trainer | begin training epoch 172
2022-03-04 22:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:10:06 | INFO | train_inner | epoch 172:     22 / 97 loss=0.816, ppl=1.76, wps=23899.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.992, loss_scale=32, train_wall=244, gb_free=8.2, wall=45223
2022-03-04 22:10:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:13:29 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 16.084 | ppl 69471.4 | wps 45018.9 | wpb 510.9 | bsz 1 | num_updates 16574 | best_loss 7.632
2022-03-04 22:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16574 updates
2022-03-04 22:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 172 @ 16574 updates, score 16.084) (writing took 2.8587527070194483 seconds)
2022-03-04 22:13:32 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-04 22:13:32 | INFO | train | epoch 172 | loss 0.813 | ppl 1.76 | wps 23839.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16574 | lr 0.000245633 | gnorm 1.003 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 45429
2022-03-04 22:13:32 | INFO | fairseq.trainer | begin training epoch 173
2022-03-04 22:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:14:41 | INFO | train_inner | epoch 173:     26 / 97 loss=0.81, ppl=1.75, wps=23871.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.996, loss_scale=16, train_wall=244, gb_free=8.2, wall=45497
2022-03-04 22:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:17:53 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 16.181 | ppl 74273.5 | wps 45033.1 | wpb 510.9 | bsz 1 | num_updates 16671 | best_loss 7.632
2022-03-04 22:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16671 updates
2022-03-04 22:17:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:17:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:17:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 173 @ 16671 updates, score 16.181) (writing took 2.7799393059685826 seconds)
2022-03-04 22:17:56 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-04 22:17:56 | INFO | train | epoch 173 | loss 0.808 | ppl 1.75 | wps 24054.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 16671 | lr 0.000244917 | gnorm 0.979 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 45693
2022-03-04 22:17:56 | INFO | fairseq.trainer | begin training epoch 174
2022-03-04 22:17:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:19:12 | INFO | train_inner | epoch 174:     29 / 97 loss=0.809, ppl=1.75, wps=24085.6, ups=0.37, wpb=65495, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.979, loss_scale=32, train_wall=242, gb_free=8.2, wall=45769
2022-03-04 22:20:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:22:17 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 16.157 | ppl 73085.3 | wps 45141.9 | wpb 510.9 | bsz 1 | num_updates 16767 | best_loss 7.632
2022-03-04 22:22:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16767 updates
2022-03-04 22:22:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:22:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 174 @ 16767 updates, score 16.157) (writing took 2.6049904068931937 seconds)
2022-03-04 22:22:19 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-04 22:22:19 | INFO | train | epoch 174 | loss 0.804 | ppl 1.75 | wps 23853.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16767 | lr 0.000244215 | gnorm 0.986 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 45956
2022-03-04 22:22:19 | INFO | fairseq.trainer | begin training epoch 175
2022-03-04 22:22:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:23:47 | INFO | train_inner | epoch 175:     33 / 97 loss=0.801, ppl=1.74, wps=23886.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.992, loss_scale=16, train_wall=244, gb_free=8.2, wall=46043
2022-03-04 22:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:26:40 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 16.137 | ppl 72040.3 | wps 44950 | wpb 510.9 | bsz 1 | num_updates 16864 | best_loss 7.632
2022-03-04 22:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16864 updates
2022-03-04 22:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:26:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 175 @ 16864 updates, score 16.137) (writing took 2.6601833198219538 seconds)
2022-03-04 22:26:43 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-04 22:26:43 | INFO | train | epoch 175 | loss 0.8 | ppl 1.74 | wps 24087.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 16864 | lr 0.000243512 | gnorm 0.986 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 46220
2022-03-04 22:26:43 | INFO | fairseq.trainer | begin training epoch 176
2022-03-04 22:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:28:18 | INFO | train_inner | epoch 176:     36 / 97 loss=0.796, ppl=1.74, wps=24114.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.98, loss_scale=32, train_wall=242, gb_free=8.2, wall=46315
2022-03-04 22:28:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:31:04 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 16.222 | ppl 76429.9 | wps 44568.4 | wpb 510.9 | bsz 1 | num_updates 16960 | best_loss 7.632
2022-03-04 22:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16960 updates
2022-03-04 22:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 176 @ 16960 updates, score 16.222) (writing took 3.035612605512142 seconds)
2022-03-04 22:31:07 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-04 22:31:07 | INFO | train | epoch 176 | loss 0.794 | ppl 1.73 | wps 23808.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 16960 | lr 0.000242821 | gnorm 0.977 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 46484
2022-03-04 22:31:07 | INFO | fairseq.trainer | begin training epoch 177
2022-03-04 22:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:32:53 | INFO | train_inner | epoch 177:     40 / 97 loss=0.794, ppl=1.73, wps=23839.5, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.982, loss_scale=16, train_wall=244, gb_free=8.2, wall=46590
2022-03-04 22:35:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:35:28 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 16.202 | ppl 75373.1 | wps 45048.6 | wpb 510.9 | bsz 1 | num_updates 17057 | best_loss 7.632
2022-03-04 22:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17057 updates
2022-03-04 22:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:35:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:35:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 177 @ 17057 updates, score 16.202) (writing took 2.9889624966308475 seconds)
2022-03-04 22:35:31 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-04 22:35:31 | INFO | train | epoch 177 | loss 0.791 | ppl 1.73 | wps 24046.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 17057 | lr 0.00024213 | gnorm 0.976 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 46748
2022-03-04 22:35:31 | INFO | fairseq.trainer | begin training epoch 178
2022-03-04 22:35:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:37:25 | INFO | train_inner | epoch 178:     43 / 97 loss=0.79, ppl=1.73, wps=24066.1, ups=0.37, wpb=65495, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.967, loss_scale=32, train_wall=242, gb_free=8.2, wall=46862
2022-03-04 22:39:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:39:53 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 16.225 | ppl 76618.9 | wps 44673.5 | wpb 510.9 | bsz 1 | num_updates 17153 | best_loss 7.632
2022-03-04 22:39:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17153 updates
2022-03-04 22:39:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 178 @ 17153 updates, score 16.225) (writing took 3.1609235098585486 seconds)
2022-03-04 22:39:56 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-04 22:39:56 | INFO | train | epoch 178 | loss 0.785 | ppl 1.72 | wps 23783.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17153 | lr 0.000241452 | gnorm 0.968 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 47013
2022-03-04 22:39:56 | INFO | fairseq.trainer | begin training epoch 179
2022-03-04 22:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:42:00 | INFO | train_inner | epoch 179:     47 / 97 loss=0.783, ppl=1.72, wps=23826.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.983, loss_scale=16, train_wall=244, gb_free=8.2, wall=47137
2022-03-04 22:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:44:17 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 16.279 | ppl 79534.8 | wps 44666.7 | wpb 510.9 | bsz 1 | num_updates 17250 | best_loss 7.632
2022-03-04 22:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17250 updates
2022-03-04 22:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:44:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 179 @ 17250 updates, score 16.279) (writing took 3.1205222057178617 seconds)
2022-03-04 22:44:20 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-04 22:44:20 | INFO | train | epoch 179 | loss 0.782 | ppl 1.72 | wps 24018.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 17250 | lr 0.000240772 | gnorm 0.986 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 47277
2022-03-04 22:44:20 | INFO | fairseq.trainer | begin training epoch 180
2022-03-04 22:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:45:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:46:35 | INFO | train_inner | epoch 180:     51 / 97 loss=0.777, ppl=1.71, wps=23805.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.98, loss_scale=16, train_wall=244, gb_free=8.2, wall=47412
2022-03-04 22:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:48:41 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 16.283 | ppl 79716.7 | wps 44952.4 | wpb 510.9 | bsz 1 | num_updates 17346 | best_loss 7.632
2022-03-04 22:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17346 updates
2022-03-04 22:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 180 @ 17346 updates, score 16.283) (writing took 2.8851887304335833 seconds)
2022-03-04 22:48:44 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-04 22:48:44 | INFO | train | epoch 180 | loss 0.778 | ppl 1.71 | wps 23815.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17346 | lr 0.000240105 | gnorm 0.988 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 47541
2022-03-04 22:48:44 | INFO | fairseq.trainer | begin training epoch 181
2022-03-04 22:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:51:07 | INFO | train_inner | epoch 181:     54 / 97 loss=0.776, ppl=1.71, wps=24094.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.984, loss_scale=16, train_wall=242, gb_free=8.2, wall=47684
2022-03-04 22:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:53:05 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 16.233 | ppl 76997 | wps 44920 | wpb 510.9 | bsz 1 | num_updates 17443 | best_loss 7.632
2022-03-04 22:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17443 updates
2022-03-04 22:53:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 181 @ 17443 updates, score 16.233) (writing took 2.8302752980962396 seconds)
2022-03-04 22:53:08 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-04 22:53:08 | INFO | train | epoch 181 | loss 0.773 | ppl 1.71 | wps 24082.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 17443 | lr 0.000239436 | gnorm 0.987 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 47805
2022-03-04 22:53:08 | INFO | fairseq.trainer | begin training epoch 182
2022-03-04 22:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 22:54:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 22:55:41 | INFO | train_inner | epoch 182:     58 / 97 loss=0.77, ppl=1.7, wps=23872.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.985, loss_scale=16, train_wall=244, gb_free=8.2, wall=47958
2022-03-04 22:57:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 22:57:29 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 16.362 | ppl 84241.9 | wps 45205.9 | wpb 510.9 | bsz 1 | num_updates 17539 | best_loss 7.632
2022-03-04 22:57:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17539 updates
2022-03-04 22:57:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:57:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 22:57:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 182 @ 17539 updates, score 16.362) (writing took 2.895641479641199 seconds)
2022-03-04 22:57:32 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-04 22:57:32 | INFO | train | epoch 182 | loss 0.768 | ppl 1.7 | wps 23822.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17539 | lr 0.00023878 | gnorm 0.973 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 48069
2022-03-04 22:57:32 | INFO | fairseq.trainer | begin training epoch 183
2022-03-04 22:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:00:13 | INFO | train_inner | epoch 183:     61 / 97 loss=0.768, ppl=1.7, wps=24081.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=17600, lr=0.000238366, gnorm=0.973, loss_scale=16, train_wall=242, gb_free=8.2, wall=48230
2022-03-04 23:00:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:01:53 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 16.346 | ppl 83291 | wps 44883.3 | wpb 510.9 | bsz 1 | num_updates 17635 | best_loss 7.632
2022-03-04 23:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17635 updates
2022-03-04 23:01:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 183 @ 17635 updates, score 16.346) (writing took 2.9116173246875405 seconds)
2022-03-04 23:01:56 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-04 23:01:56 | INFO | train | epoch 183 | loss 0.765 | ppl 1.7 | wps 23811.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17635 | lr 0.000238129 | gnorm 0.975 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 48333
2022-03-04 23:01:56 | INFO | fairseq.trainer | begin training epoch 184
2022-03-04 23:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:04:48 | INFO | train_inner | epoch 184:     65 / 97 loss=0.763, ppl=1.7, wps=23869.5, ups=0.36, wpb=65495, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.977, loss_scale=16, train_wall=244, gb_free=8.2, wall=48504
2022-03-04 23:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:06:17 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 16.337 | ppl 82762.1 | wps 44975.7 | wpb 510.9 | bsz 1 | num_updates 17732 | best_loss 7.632
2022-03-04 23:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17732 updates
2022-03-04 23:06:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:06:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 184 @ 17732 updates, score 16.337) (writing took 2.7579347221180797 seconds)
2022-03-04 23:06:20 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-04 23:06:20 | INFO | train | epoch 184 | loss 0.761 | ppl 1.69 | wps 24095 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 17732 | lr 0.000237477 | gnorm 0.974 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 48596
2022-03-04 23:06:20 | INFO | fairseq.trainer | begin training epoch 185
2022-03-04 23:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:07:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:09:22 | INFO | train_inner | epoch 185:     69 / 97 loss=0.755, ppl=1.69, wps=23859.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.968, loss_scale=16, train_wall=244, gb_free=8.2, wall=48779
2022-03-04 23:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:10:41 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 16.396 | ppl 86221.7 | wps 45028.2 | wpb 510.9 | bsz 1 | num_updates 17828 | best_loss 7.632
2022-03-04 23:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17828 updates
2022-03-04 23:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:10:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:10:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 185 @ 17828 updates, score 16.396) (writing took 2.7619681572541595 seconds)
2022-03-04 23:10:43 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-04 23:10:43 | INFO | train | epoch 185 | loss 0.756 | ppl 1.69 | wps 23821.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17828 | lr 0.000236837 | gnorm 0.971 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 48860
2022-03-04 23:10:44 | INFO | fairseq.trainer | begin training epoch 186
2022-03-04 23:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:13:54 | INFO | train_inner | epoch 186:     72 / 97 loss=0.755, ppl=1.69, wps=24102.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.964, loss_scale=32, train_wall=242, gb_free=8.2, wall=49051
2022-03-04 23:13:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:15:05 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 16.405 | ppl 86757.6 | wps 45003.2 | wpb 510.9 | bsz 1 | num_updates 17924 | best_loss 7.632
2022-03-04 23:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17924 updates
2022-03-04 23:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 186 @ 17924 updates, score 16.405) (writing took 2.8440317483618855 seconds)
2022-03-04 23:15:07 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-04 23:15:07 | INFO | train | epoch 186 | loss 0.752 | ppl 1.68 | wps 23822.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 17924 | lr 0.000236201 | gnorm 0.964 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 49124
2022-03-04 23:15:07 | INFO | fairseq.trainer | begin training epoch 187
2022-03-04 23:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:18:29 | INFO | train_inner | epoch 187:     76 / 97 loss=0.751, ppl=1.68, wps=23836.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.97, loss_scale=16, train_wall=244, gb_free=8.2, wall=49325
2022-03-04 23:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:19:29 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 16.481 | ppl 91443.5 | wps 44857.5 | wpb 510.9 | bsz 1 | num_updates 18021 | best_loss 7.632
2022-03-04 23:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18021 updates
2022-03-04 23:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:19:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:19:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 187 @ 18021 updates, score 16.481) (writing took 2.811809094622731 seconds)
2022-03-04 23:19:32 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-04 23:19:32 | INFO | train | epoch 187 | loss 0.749 | ppl 1.68 | wps 24045.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 18021 | lr 0.000235565 | gnorm 0.966 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 49388
2022-03-04 23:19:32 | INFO | fairseq.trainer | begin training epoch 188
2022-03-04 23:19:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:20:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:23:03 | INFO | train_inner | epoch 188:     80 / 97 loss=0.746, ppl=1.68, wps=23862.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.968, loss_scale=16, train_wall=244, gb_free=8.2, wall=49600
2022-03-04 23:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:23:53 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 16.568 | ppl 97140.9 | wps 45379.9 | wpb 510.9 | bsz 1 | num_updates 18117 | best_loss 7.632
2022-03-04 23:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18117 updates
2022-03-04 23:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 188 @ 18117 updates, score 16.568) (writing took 2.74994111713022 seconds)
2022-03-04 23:23:55 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-04 23:23:55 | INFO | train | epoch 188 | loss 0.744 | ppl 1.68 | wps 23834.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18117 | lr 0.00023494 | gnorm 0.971 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 49652
2022-03-04 23:23:55 | INFO | fairseq.trainer | begin training epoch 189
2022-03-04 23:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:27:35 | INFO | train_inner | epoch 189:     83 / 97 loss=0.743, ppl=1.67, wps=24121, ups=0.37, wpb=65495, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.975, loss_scale=32, train_wall=242, gb_free=8.2, wall=49871
2022-03-04 23:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:28:16 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 16.562 | ppl 96722.7 | wps 44880.1 | wpb 510.9 | bsz 1 | num_updates 18214 | best_loss 7.632
2022-03-04 23:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18214 updates
2022-03-04 23:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 189 @ 18214 updates, score 16.562) (writing took 2.9147593043744564 seconds)
2022-03-04 23:28:19 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-04 23:28:19 | INFO | train | epoch 189 | loss 0.74 | ppl 1.67 | wps 24072.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 18214 | lr 0.000234314 | gnorm 0.973 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 49916
2022-03-04 23:28:19 | INFO | fairseq.trainer | begin training epoch 190
2022-03-04 23:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:29:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:32:09 | INFO | train_inner | epoch 190:     87 / 97 loss=0.738, ppl=1.67, wps=23846.9, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.972, loss_scale=16, train_wall=244, gb_free=8.2, wall=50146
2022-03-04 23:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:32:40 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 16.576 | ppl 97723.4 | wps 44848.7 | wpb 510.9 | bsz 1 | num_updates 18310 | best_loss 7.632
2022-03-04 23:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18310 updates
2022-03-04 23:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:32:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:32:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 190 @ 18310 updates, score 16.576) (writing took 2.6998677225783467 seconds)
2022-03-04 23:32:43 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-04 23:32:43 | INFO | train | epoch 190 | loss 0.736 | ppl 1.67 | wps 23837.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18310 | lr 0.000233698 | gnorm 0.969 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 50180
2022-03-04 23:32:43 | INFO | fairseq.trainer | begin training epoch 191
2022-03-04 23:32:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:36:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:36:43 | INFO | train_inner | epoch 191:     91 / 97 loss=0.735, ppl=1.66, wps=23874.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=18400, lr=0.000233126, gnorm=0.957, loss_scale=16, train_wall=244, gb_free=8.2, wall=50420
2022-03-04 23:36:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:37:04 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 16.526 | ppl 94384.7 | wps 44976.3 | wpb 510.9 | bsz 1 | num_updates 18406 | best_loss 7.632
2022-03-04 23:37:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18406 updates
2022-03-04 23:37:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:37:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:37:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 191 @ 18406 updates, score 16.526) (writing took 2.970368241891265 seconds)
2022-03-04 23:37:07 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-04 23:37:07 | INFO | train | epoch 191 | loss 0.733 | ppl 1.66 | wps 23814.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18406 | lr 0.000233088 | gnorm 0.958 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 50444
2022-03-04 23:37:07 | INFO | fairseq.trainer | begin training epoch 192
2022-03-04 23:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:41:15 | INFO | train_inner | epoch 192:     94 / 97 loss=0.731, ppl=1.66, wps=24089.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=18500, lr=0.000232495, gnorm=0.969, loss_scale=16, train_wall=242, gb_free=8.2, wall=50692
2022-03-04 23:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:41:28 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 16.58 | ppl 97947.9 | wps 44972.4 | wpb 510.9 | bsz 1 | num_updates 18503 | best_loss 7.632
2022-03-04 23:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18503 updates
2022-03-04 23:41:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:41:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 192 @ 18503 updates, score 16.58) (writing took 2.967725647613406 seconds)
2022-03-04 23:41:31 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-04 23:41:31 | INFO | train | epoch 192 | loss 0.731 | ppl 1.66 | wps 24067.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 18503 | lr 0.000232476 | gnorm 0.967 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 50708
2022-03-04 23:41:31 | INFO | fairseq.trainer | begin training epoch 193
2022-03-04 23:41:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:45:52 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 16.552 | ppl 96086.2 | wps 44804.9 | wpb 510.9 | bsz 1 | num_updates 18599 | best_loss 7.632
2022-03-04 23:45:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18599 updates
2022-03-04 23:45:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 193 @ 18599 updates, score 16.552) (writing took 2.7827417897060513 seconds)
2022-03-04 23:45:55 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-04 23:45:55 | INFO | train | epoch 193 | loss 0.726 | ppl 1.65 | wps 23840.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18599 | lr 0.000231876 | gnorm 0.961 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 50972
2022-03-04 23:45:55 | INFO | fairseq.trainer | begin training epoch 194
2022-03-04 23:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:45:57 | INFO | train_inner | epoch 194:      1 / 97 loss=0.727, ppl=1.65, wps=23204.3, ups=0.35, wpb=65451.9, bsz=127.8, num_updates=18600, lr=0.000231869, gnorm=0.961, loss_scale=16, train_wall=244, gb_free=8.2, wall=50974
2022-03-04 23:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:50:16 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 16.675 | ppl 104635 | wps 44974.8 | wpb 510.9 | bsz 1 | num_updates 18696 | best_loss 7.632
2022-03-04 23:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18696 updates
2022-03-04 23:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 194 @ 18696 updates, score 16.675) (writing took 2.906826131977141 seconds)
2022-03-04 23:50:19 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-04 23:50:19 | INFO | train | epoch 194 | loss 0.723 | ppl 1.65 | wps 24061.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 18696 | lr 0.000231273 | gnorm 0.973 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 51236
2022-03-04 23:50:19 | INFO | fairseq.trainer | begin training epoch 195
2022-03-04 23:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:50:29 | INFO | train_inner | epoch 195:      4 / 97 loss=0.722, ppl=1.65, wps=24082.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.973, loss_scale=32, train_wall=242, gb_free=8.2, wall=51246
2022-03-04 23:51:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-04 23:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:54:40 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 16.684 | ppl 105314 | wps 44781.9 | wpb 510.9 | bsz 1 | num_updates 18792 | best_loss 7.632
2022-03-04 23:54:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18792 updates
2022-03-04 23:54:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:54:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:54:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 195 @ 18792 updates, score 16.684) (writing took 2.908737640827894 seconds)
2022-03-04 23:54:43 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-04 23:54:43 | INFO | train | epoch 195 | loss 0.718 | ppl 1.65 | wps 23812.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18792 | lr 0.000230682 | gnorm 0.962 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 51500
2022-03-04 23:54:43 | INFO | fairseq.trainer | begin training epoch 196
2022-03-04 23:54:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:55:04 | INFO | train_inner | epoch 196:      8 / 97 loss=0.716, ppl=1.64, wps=23848.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.961, loss_scale=16, train_wall=244, gb_free=8.2, wall=51521
2022-03-04 23:58:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-04 23:59:04 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 16.691 | ppl 105781 | wps 44581.8 | wpb 510.9 | bsz 1 | num_updates 18889 | best_loss 7.632
2022-03-04 23:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18889 updates
2022-03-04 23:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-04 23:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 196 @ 18889 updates, score 16.691) (writing took 2.939072606153786 seconds)
2022-03-04 23:59:07 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-04 23:59:07 | INFO | train | epoch 196 | loss 0.716 | ppl 1.64 | wps 24028.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 18889 | lr 0.000230089 | gnorm 0.968 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 51764
2022-03-04 23:59:07 | INFO | fairseq.trainer | begin training epoch 197
2022-03-04 23:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-04 23:59:36 | INFO | train_inner | epoch 197:     11 / 97 loss=0.715, ppl=1.64, wps=24049, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.967, loss_scale=32, train_wall=242, gb_free=8.2, wall=51793
2022-03-05 00:03:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 00:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:03:29 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 16.676 | ppl 104741 | wps 44884.2 | wpb 510.9 | bsz 1 | num_updates 18985 | best_loss 7.632
2022-03-05 00:03:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18985 updates
2022-03-05 00:03:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 197 @ 18985 updates, score 16.676) (writing took 2.859188312664628 seconds)
2022-03-05 00:03:31 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 00:03:31 | INFO | train | epoch 197 | loss 0.71 | ppl 1.64 | wps 23782.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 18985 | lr 0.000229506 | gnorm 0.956 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 52028
2022-03-05 00:03:32 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 00:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:03:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:04:14 | INFO | train_inner | epoch 198:     16 / 97 loss=0.707, ppl=1.63, wps=23596.1, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.953, loss_scale=16, train_wall=247, gb_free=8.2, wall=52071
2022-03-05 00:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:07:53 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 16.75 | ppl 110217 | wps 44948.4 | wpb 510.9 | bsz 1 | num_updates 19081 | best_loss 7.632
2022-03-05 00:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19081 updates
2022-03-05 00:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:07:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:07:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 198 @ 19081 updates, score 16.75) (writing took 2.8360266722738743 seconds)
2022-03-05 00:07:56 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 00:07:56 | INFO | train | epoch 198 | loss 0.708 | ppl 1.63 | wps 23794.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19081 | lr 0.000228928 | gnorm 0.969 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 52293
2022-03-05 00:07:56 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 00:07:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:08:46 | INFO | train_inner | epoch 199:     19 / 97 loss=0.708, ppl=1.63, wps=24065, ups=0.37, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.971, loss_scale=16, train_wall=242, gb_free=8.2, wall=52343
2022-03-05 00:10:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:12:17 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 16.647 | ppl 102596 | wps 44923.3 | wpb 510.9 | bsz 1 | num_updates 19177 | best_loss 7.632
2022-03-05 00:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19177 updates
2022-03-05 00:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 199 @ 19177 updates, score 16.647) (writing took 3.0728168273344636 seconds)
2022-03-05 00:12:20 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 00:12:20 | INFO | train | epoch 199 | loss 0.704 | ppl 1.63 | wps 23780.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19177 | lr 0.000228355 | gnorm 0.958 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 52557
2022-03-05 00:12:20 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 00:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:13:21 | INFO | train_inner | epoch 200:     23 / 97 loss=0.703, ppl=1.63, wps=23825.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.957, loss_scale=16, train_wall=244, gb_free=8.2, wall=52618
2022-03-05 00:16:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:16:41 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 16.749 | ppl 110139 | wps 44793 | wpb 510.9 | bsz 1 | num_updates 19273 | best_loss 7.632
2022-03-05 00:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19273 updates
2022-03-05 00:16:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 200 @ 19273 updates, score 16.749) (writing took 2.9736664602532983 seconds)
2022-03-05 00:16:44 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 00:16:44 | INFO | train | epoch 200 | loss 0.701 | ppl 1.63 | wps 23804.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19273 | lr 0.000227785 | gnorm 0.958 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 52821
2022-03-05 00:16:44 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 00:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:17:56 | INFO | train_inner | epoch 201:     27 / 97 loss=0.699, ppl=1.62, wps=23836.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.956, loss_scale=16, train_wall=244, gb_free=8.2, wall=52893
2022-03-05 00:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:21:06 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 16.708 | ppl 107035 | wps 44745.1 | wpb 510.9 | bsz 1 | num_updates 19370 | best_loss 7.632
2022-03-05 00:21:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19370 updates
2022-03-05 00:21:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:21:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:21:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 201 @ 19370 updates, score 16.708) (writing took 2.9125882890075445 seconds)
2022-03-05 00:21:09 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 00:21:09 | INFO | train | epoch 201 | loss 0.698 | ppl 1.62 | wps 24024.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 19370 | lr 0.000227214 | gnorm 0.951 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 53085
2022-03-05 00:21:09 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 00:21:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:22:28 | INFO | train_inner | epoch 202:     30 / 97 loss=0.698, ppl=1.62, wps=24044.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.952, loss_scale=32, train_wall=242, gb_free=8.2, wall=53165
2022-03-05 00:24:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:25:30 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 16.723 | ppl 108150 | wps 44524 | wpb 510.9 | bsz 1 | num_updates 19466 | best_loss 7.632
2022-03-05 00:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19466 updates
2022-03-05 00:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:25:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:25:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 202 @ 19466 updates, score 16.723) (writing took 3.098491681739688 seconds)
2022-03-05 00:25:33 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 00:25:33 | INFO | train | epoch 202 | loss 0.694 | ppl 1.62 | wps 23763.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19466 | lr 0.000226653 | gnorm 0.952 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 53350
2022-03-05 00:25:33 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 00:25:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:27:03 | INFO | train_inner | epoch 203:     34 / 97 loss=0.693, ppl=1.62, wps=23810.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.954, loss_scale=16, train_wall=244, gb_free=8.2, wall=53440
2022-03-05 00:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:29:54 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 16.871 | ppl 119843 | wps 44889.6 | wpb 510.9 | bsz 1 | num_updates 19563 | best_loss 7.632
2022-03-05 00:29:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19563 updates
2022-03-05 00:29:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:29:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:29:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 203 @ 19563 updates, score 16.871) (writing took 2.9710640171542764 seconds)
2022-03-05 00:29:57 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 00:29:57 | INFO | train | epoch 203 | loss 0.691 | ppl 1.61 | wps 24047 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 19563 | lr 0.00022609 | gnorm 0.947 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 53614
2022-03-05 00:29:57 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 00:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:30:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:31:38 | INFO | train_inner | epoch 204:     38 / 97 loss=0.688, ppl=1.61, wps=23819.9, ups=0.36, wpb=65495, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.939, loss_scale=16, train_wall=244, gb_free=8.2, wall=53715
2022-03-05 00:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:34:19 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 16.804 | ppl 114438 | wps 44993.4 | wpb 510.9 | bsz 1 | num_updates 19659 | best_loss 7.632
2022-03-05 00:34:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19659 updates
2022-03-05 00:34:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:34:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:34:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 204 @ 19659 updates, score 16.804) (writing took 2.9615184841677547 seconds)
2022-03-05 00:34:22 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 00:34:22 | INFO | train | epoch 204 | loss 0.689 | ppl 1.61 | wps 23785.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19659 | lr 0.000225538 | gnorm 0.953 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 53879
2022-03-05 00:34:22 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 00:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:36:10 | INFO | train_inner | epoch 205:     41 / 97 loss=0.687, ppl=1.61, wps=24061.6, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.955, loss_scale=16, train_wall=242, gb_free=8.2, wall=53987
2022-03-05 00:36:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:38:43 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 16.794 | ppl 113636 | wps 45014.6 | wpb 510.9 | bsz 1 | num_updates 19755 | best_loss 7.632
2022-03-05 00:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19755 updates
2022-03-05 00:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 205 @ 19755 updates, score 16.794) (writing took 2.8185794008895755 seconds)
2022-03-05 00:38:46 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 00:38:46 | INFO | train | epoch 205 | loss 0.686 | ppl 1.61 | wps 23805.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19755 | lr 0.000224989 | gnorm 0.945 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 54143
2022-03-05 00:38:46 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 00:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:40:45 | INFO | train_inner | epoch 206:     45 / 97 loss=0.688, ppl=1.61, wps=23862.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.954, loss_scale=16, train_wall=244, gb_free=8.2, wall=54262
2022-03-05 00:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:43:07 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 16.902 | ppl 122475 | wps 45203.1 | wpb 510.9 | bsz 1 | num_updates 19852 | best_loss 7.632
2022-03-05 00:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19852 updates
2022-03-05 00:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 206 @ 19852 updates, score 16.902) (writing took 2.792051175609231 seconds)
2022-03-05 00:43:10 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 00:43:10 | INFO | train | epoch 206 | loss 0.684 | ppl 1.61 | wps 24070.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 19852 | lr 0.000224439 | gnorm 0.952 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 54407
2022-03-05 00:43:10 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 00:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:45:17 | INFO | train_inner | epoch 207:     48 / 97 loss=0.681, ppl=1.6, wps=24085.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.943, loss_scale=32, train_wall=242, gb_free=8.2, wall=54534
2022-03-05 00:45:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:47:31 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 16.812 | ppl 115094 | wps 44867.3 | wpb 510.9 | bsz 1 | num_updates 19948 | best_loss 7.632
2022-03-05 00:47:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19948 updates
2022-03-05 00:47:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:47:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:47:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 207 @ 19948 updates, score 16.812) (writing took 2.8434646241366863 seconds)
2022-03-05 00:47:34 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 00:47:34 | INFO | train | epoch 207 | loss 0.678 | ppl 1.6 | wps 23823.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 19948 | lr 0.000223898 | gnorm 0.943 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 54671
2022-03-05 00:47:34 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 00:47:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:49:51 | INFO | train_inner | epoch 208:     52 / 97 loss=0.675, ppl=1.6, wps=23850.4, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.938, loss_scale=16, train_wall=244, gb_free=8.2, wall=54808
2022-03-05 00:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:51:55 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 16.889 | ppl 121364 | wps 44944.9 | wpb 510.9 | bsz 1 | num_updates 20045 | best_loss 7.632
2022-03-05 00:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20045 updates
2022-03-05 00:51:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 208 @ 20045 updates, score 16.889) (writing took 2.738499680534005 seconds)
2022-03-05 00:51:58 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 00:51:58 | INFO | train | epoch 208 | loss 0.677 | ppl 1.6 | wps 24069.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 20045 | lr 0.000223356 | gnorm 0.95 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 54934
2022-03-05 00:51:58 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 00:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:54:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 00:54:26 | INFO | train_inner | epoch 209:     56 / 97 loss=0.676, ppl=1.6, wps=23840.2, ups=0.36, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.952, loss_scale=16, train_wall=244, gb_free=8.2, wall=55083
2022-03-05 00:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 00:56:19 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 16.828 | ppl 116342 | wps 45143.2 | wpb 510.9 | bsz 1 | num_updates 20141 | best_loss 7.632
2022-03-05 00:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20141 updates
2022-03-05 00:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 00:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 209 @ 20141 updates, score 16.828) (writing took 2.3670901814475656 seconds)
2022-03-05 00:56:21 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 00:56:21 | INFO | train | epoch 209 | loss 0.672 | ppl 1.59 | wps 23839.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 20141 | lr 0.000222823 | gnorm 0.94 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 55198
2022-03-05 00:56:21 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 00:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 00:58:57 | INFO | train_inner | epoch 210:     59 / 97 loss=0.671, ppl=1.59, wps=24159.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.935, loss_scale=16, train_wall=242, gb_free=8.2, wall=55354
2022-03-05 01:00:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:00:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:00:42 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 16.872 | ppl 119909 | wps 45103.5 | wpb 510.9 | bsz 1 | num_updates 20237 | best_loss 7.632
2022-03-05 01:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20237 updates
2022-03-05 01:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 210 @ 20237 updates, score 16.872) (writing took 2.196942242793739 seconds)
2022-03-05 01:00:44 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 01:00:44 | INFO | train | epoch 210 | loss 0.671 | ppl 1.59 | wps 23908.7 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 20237 | lr 0.000222294 | gnorm 0.941 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 55461
2022-03-05 01:00:44 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 01:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:03:31 | INFO | train_inner | epoch 211:     63 / 97 loss=0.671, ppl=1.59, wps=23928.6, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.947, loss_scale=16, train_wall=244, gb_free=8.2, wall=55628
2022-03-05 01:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:05:05 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 16.926 | ppl 124513 | wps 45161.2 | wpb 510.9 | bsz 1 | num_updates 20334 | best_loss 7.632
2022-03-05 01:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20334 updates
2022-03-05 01:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:05:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 211 @ 20334 updates, score 16.926) (writing took 2.127014571800828 seconds)
2022-03-05 01:05:07 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 01:05:07 | INFO | train | epoch 211 | loss 0.667 | ppl 1.59 | wps 24149.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 20334 | lr 0.000221763 | gnorm 0.937 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 55724
2022-03-05 01:05:07 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 01:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:07:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:08:04 | INFO | train_inner | epoch 212:     67 / 97 loss=0.665, ppl=1.59, wps=23957, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.936, loss_scale=16, train_wall=244, gb_free=8.2, wall=55901
2022-03-05 01:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:09:28 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 17.03 | ppl 133832 | wps 45240.5 | wpb 510.9 | bsz 1 | num_updates 20430 | best_loss 7.632
2022-03-05 01:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20430 updates
2022-03-05 01:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:09:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 212 @ 20430 updates, score 17.03) (writing took 2.167697586119175 seconds)
2022-03-05 01:09:30 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 01:09:30 | INFO | train | epoch 212 | loss 0.664 | ppl 1.58 | wps 23923.3 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 20430 | lr 0.000221241 | gnorm 0.944 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 55987
2022-03-05 01:09:30 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 01:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:12:35 | INFO | train_inner | epoch 213:     70 / 97 loss=0.663, ppl=1.58, wps=24188.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.947, loss_scale=16, train_wall=241, gb_free=8.2, wall=56172
2022-03-05 01:13:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:13:51 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 16.966 | ppl 128049 | wps 45123.4 | wpb 510.9 | bsz 1 | num_updates 20527 | best_loss 7.632
2022-03-05 01:13:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20527 updates
2022-03-05 01:13:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 213 @ 20527 updates, score 16.966) (writing took 2.193586108274758 seconds)
2022-03-05 01:13:53 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 01:13:53 | INFO | train | epoch 213 | loss 0.661 | ppl 1.58 | wps 24157.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 20527 | lr 0.000220718 | gnorm 0.937 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 56250
2022-03-05 01:13:53 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 01:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:17:06 | INFO | train_inner | epoch 214:     73 / 97 loss=0.66, ppl=1.58, wps=24170, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.926, loss_scale=32, train_wall=242, gb_free=8.2, wall=56443
2022-03-05 01:17:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:18:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:18:14 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 17.008 | ppl 131810 | wps 45057.6 | wpb 510.9 | bsz 1 | num_updates 20623 | best_loss 7.632
2022-03-05 01:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20623 updates
2022-03-05 01:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:18:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 214 @ 20623 updates, score 17.008) (writing took 2.1949016954749823 seconds)
2022-03-05 01:18:16 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 01:18:16 | INFO | train | epoch 214 | loss 0.658 | ppl 1.58 | wps 23909.5 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 20623 | lr 0.000220203 | gnorm 0.931 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 56513
2022-03-05 01:18:16 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 01:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:21:39 | INFO | train_inner | epoch 215:     77 / 97 loss=0.654, ppl=1.57, wps=23950.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.929, loss_scale=16, train_wall=244, gb_free=8.2, wall=56716
2022-03-05 01:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:22:37 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 16.952 | ppl 126824 | wps 45022.8 | wpb 510.9 | bsz 1 | num_updates 20720 | best_loss 7.632
2022-03-05 01:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20720 updates
2022-03-05 01:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 215 @ 20720 updates, score 16.952) (writing took 2.1821913588792086 seconds)
2022-03-05 01:22:39 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 01:22:39 | INFO | train | epoch 215 | loss 0.654 | ppl 1.57 | wps 24163.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 20720 | lr 0.000219687 | gnorm 0.927 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 56776
2022-03-05 01:22:39 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 01:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:24:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:26:13 | INFO | train_inner | epoch 216:     81 / 97 loss=0.655, ppl=1.57, wps=23939.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.936, loss_scale=16, train_wall=244, gb_free=8.2, wall=56990
2022-03-05 01:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:27:00 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 17.091 | ppl 139638 | wps 45045.8 | wpb 510.9 | bsz 1 | num_updates 20816 | best_loss 7.632
2022-03-05 01:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20816 updates
2022-03-05 01:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 216 @ 20816 updates, score 17.091) (writing took 2.167964377440512 seconds)
2022-03-05 01:27:02 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 01:27:02 | INFO | train | epoch 216 | loss 0.652 | ppl 1.57 | wps 23900.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 20816 | lr 0.00021918 | gnorm 0.935 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 57039
2022-03-05 01:27:02 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 01:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:30:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:30:46 | INFO | train_inner | epoch 217:     85 / 97 loss=0.65, ppl=1.57, wps=23939, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.93, loss_scale=16, train_wall=244, gb_free=8.2, wall=57263
2022-03-05 01:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:31:23 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 17.03 | ppl 133865 | wps 45183.1 | wpb 510.9 | bsz 1 | num_updates 20912 | best_loss 7.632
2022-03-05 01:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20912 updates
2022-03-05 01:31:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 217 @ 20912 updates, score 17.03) (writing took 2.1452891593798995 seconds)
2022-03-05 01:31:25 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 01:31:25 | INFO | train | epoch 217 | loss 0.65 | ppl 1.57 | wps 23908.6 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 20912 | lr 0.000218677 | gnorm 0.929 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 57302
2022-03-05 01:31:25 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 01:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:35:17 | INFO | train_inner | epoch 218:     88 / 97 loss=0.647, ppl=1.57, wps=24169.4, ups=0.37, wpb=65495, bsz=127.9, num_updates=21000, lr=0.000218218, gnorm=0.938, loss_scale=16, train_wall=242, gb_free=8.2, wall=57534
2022-03-05 01:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:35:46 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 17.152 | ppl 145640 | wps 45066.2 | wpb 510.9 | bsz 1 | num_updates 21009 | best_loss 7.632
2022-03-05 01:35:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21009 updates
2022-03-05 01:35:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 218 @ 21009 updates, score 17.152) (writing took 2.1337892496958375 seconds)
2022-03-05 01:35:48 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 01:35:48 | INFO | train | epoch 218 | loss 0.648 | ppl 1.57 | wps 24148.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 21009 | lr 0.000218171 | gnorm 0.937 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 57565
2022-03-05 01:35:48 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 01:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:39:49 | INFO | train_inner | epoch 219:     91 / 97 loss=0.647, ppl=1.57, wps=24156.3, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=21100, lr=0.0002177, gnorm=0.935, loss_scale=32, train_wall=242, gb_free=8.2, wall=57805
2022-03-05 01:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:40:09 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 17.067 | ppl 137278 | wps 44954.6 | wpb 510.9 | bsz 1 | num_updates 21106 | best_loss 7.632
2022-03-05 01:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21106 updates
2022-03-05 01:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 219 @ 21106 updates, score 17.067) (writing took 2.202143942937255 seconds)
2022-03-05 01:40:11 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 01:40:11 | INFO | train | epoch 219 | loss 0.644 | ppl 1.56 | wps 24127.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 21106 | lr 0.000217669 | gnorm 0.935 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 57828
2022-03-05 01:40:11 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 01:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:41:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:44:23 | INFO | train_inner | epoch 220:     95 / 97 loss=0.642, ppl=1.56, wps=23900.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.933, loss_scale=16, train_wall=244, gb_free=8.2, wall=58079
2022-03-05 01:44:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:44:33 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 17.071 | ppl 137681 | wps 44883.4 | wpb 510.9 | bsz 1 | num_updates 21202 | best_loss 7.632
2022-03-05 01:44:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21202 updates
2022-03-05 01:44:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 220 @ 21202 updates, score 17.071) (writing took 2.1863668700680137 seconds)
2022-03-05 01:44:35 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 01:44:35 | INFO | train | epoch 220 | loss 0.642 | ppl 1.56 | wps 23865.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21202 | lr 0.000217176 | gnorm 0.933 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 58092
2022-03-05 01:44:35 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 01:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:48:57 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 17.099 | ppl 140392 | wps 45018.8 | wpb 510.9 | bsz 1 | num_updates 21299 | best_loss 7.632
2022-03-05 01:48:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21299 updates
2022-03-05 01:48:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:48:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:48:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 221 @ 21299 updates, score 17.099) (writing took 2.116745611652732 seconds)
2022-03-05 01:48:59 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 01:48:59 | INFO | train | epoch 221 | loss 0.639 | ppl 1.56 | wps 24055.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 21299 | lr 0.000216681 | gnorm 0.924 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 58356
2022-03-05 01:48:59 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 01:48:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:49:02 | INFO | train_inner | epoch 222:      1 / 97 loss=0.64, ppl=1.56, wps=23456.9, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=21300, lr=0.000216676, gnorm=0.925, loss_scale=32, train_wall=242, gb_free=8.2, wall=58358
2022-03-05 01:50:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 01:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:53:20 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 17.188 | ppl 149267 | wps 45085.4 | wpb 510.9 | bsz 1 | num_updates 21395 | best_loss 7.632
2022-03-05 01:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21395 updates
2022-03-05 01:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 222 @ 21395 updates, score 17.188) (writing took 2.2078341618180275 seconds)
2022-03-05 01:53:22 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 01:53:22 | INFO | train | epoch 222 | loss 0.636 | ppl 1.55 | wps 23867.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21395 | lr 0.000216194 | gnorm 0.934 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 58619
2022-03-05 01:53:22 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 01:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:53:36 | INFO | train_inner | epoch 223:      5 / 97 loss=0.635, ppl=1.55, wps=23903.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.934, loss_scale=16, train_wall=244, gb_free=8.2, wall=58632
2022-03-05 01:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 01:57:44 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 17.094 | ppl 139942 | wps 44588.3 | wpb 510.9 | bsz 1 | num_updates 21492 | best_loss 7.632
2022-03-05 01:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21492 updates
2022-03-05 01:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 01:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 223 @ 21492 updates, score 17.094) (writing took 2.1664630603045225 seconds)
2022-03-05 01:57:46 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 01:57:46 | INFO | train | epoch 223 | loss 0.634 | ppl 1.55 | wps 24111.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 21492 | lr 0.000215706 | gnorm 0.928 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 58883
2022-03-05 01:57:46 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 01:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 01:58:07 | INFO | train_inner | epoch 224:      8 / 97 loss=0.633, ppl=1.55, wps=24131.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.928, loss_scale=32, train_wall=242, gb_free=8.2, wall=58904
2022-03-05 02:01:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:02:07 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 17.197 | ppl 150228 | wps 45030.7 | wpb 510.9 | bsz 1 | num_updates 21588 | best_loss 7.632
2022-03-05 02:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21588 updates
2022-03-05 02:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 224 @ 21588 updates, score 17.197) (writing took 2.182867609895766 seconds)
2022-03-05 02:02:10 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 02:02:10 | INFO | train | epoch 224 | loss 0.632 | ppl 1.55 | wps 23828.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21588 | lr 0.000215226 | gnorm 0.937 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 59146
2022-03-05 02:02:10 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 02:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:02:41 | INFO | train_inner | epoch 225:     12 / 97 loss=0.63, ppl=1.55, wps=23870.8, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.936, loss_scale=16, train_wall=244, gb_free=8.2, wall=59178
2022-03-05 02:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:06:30 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 17.166 | ppl 147045 | wps 44968.4 | wpb 510.9 | bsz 1 | num_updates 21685 | best_loss 7.632
2022-03-05 02:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21685 updates
2022-03-05 02:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 225 @ 21685 updates, score 17.166) (writing took 2.1850626450031996 seconds)
2022-03-05 02:06:33 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 02:06:33 | INFO | train | epoch 225 | loss 0.628 | ppl 1.55 | wps 24152.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 21685 | lr 0.000214744 | gnorm 0.926 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 59410
2022-03-05 02:06:33 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 02:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:07:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:07:15 | INFO | train_inner | epoch 226:     16 / 97 loss=0.628, ppl=1.54, wps=23938.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.924, loss_scale=16, train_wall=244, gb_free=8.2, wall=59452
2022-03-05 02:10:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:10:53 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 17.269 | ppl 157980 | wps 45013.5 | wpb 510.9 | bsz 1 | num_updates 21781 | best_loss 7.632
2022-03-05 02:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21781 updates
2022-03-05 02:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:10:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:10:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 226 @ 21781 updates, score 17.269) (writing took 2.1921024788171053 seconds)
2022-03-05 02:10:56 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 02:10:56 | INFO | train | epoch 226 | loss 0.626 | ppl 1.54 | wps 23902.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21781 | lr 0.00021427 | gnorm 0.924 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 59673
2022-03-05 02:10:56 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 02:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:11:46 | INFO | train_inner | epoch 227:     19 / 97 loss=0.626, ppl=1.54, wps=24169.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.924, loss_scale=16, train_wall=242, gb_free=8.2, wall=59723
2022-03-05 02:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:15:17 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 17.275 | ppl 158555 | wps 45183 | wpb 510.9 | bsz 1 | num_updates 21877 | best_loss 7.632
2022-03-05 02:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21877 updates
2022-03-05 02:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:15:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 227 @ 21877 updates, score 17.275) (writing took 2.1669376343488693 seconds)
2022-03-05 02:15:19 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 02:15:19 | INFO | train | epoch 227 | loss 0.624 | ppl 1.54 | wps 23901.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21877 | lr 0.000213799 | gnorm 0.922 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 59936
2022-03-05 02:15:19 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 02:15:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:16:20 | INFO | train_inner | epoch 228:     23 / 97 loss=0.619, ppl=1.54, wps=23930.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.916, loss_scale=16, train_wall=244, gb_free=8.2, wall=59996
2022-03-05 02:19:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:19:40 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 17.27 | ppl 158007 | wps 45131.9 | wpb 510.9 | bsz 1 | num_updates 21973 | best_loss 7.632
2022-03-05 02:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21973 updates
2022-03-05 02:19:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 228 @ 21973 updates, score 17.27) (writing took 2.178114205598831 seconds)
2022-03-05 02:19:42 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 02:19:42 | INFO | train | epoch 228 | loss 0.621 | ppl 1.54 | wps 23897.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 21973 | lr 0.000213332 | gnorm 0.917 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 60199
2022-03-05 02:19:42 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 02:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:20:53 | INFO | train_inner | epoch 229:     27 / 97 loss=0.622, ppl=1.54, wps=23934.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.919, loss_scale=16, train_wall=244, gb_free=8.2, wall=60270
2022-03-05 02:23:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:24:03 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 17.284 | ppl 159641 | wps 45073 | wpb 510.9 | bsz 1 | num_updates 22070 | best_loss 7.632
2022-03-05 02:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22070 updates
2022-03-05 02:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:24:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:24:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 229 @ 22070 updates, score 17.284) (writing took 2.2287355083972216 seconds)
2022-03-05 02:24:05 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 02:24:05 | INFO | train | epoch 229 | loss 0.618 | ppl 1.53 | wps 24129.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 22070 | lr 0.000212862 | gnorm 0.914 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 60462
2022-03-05 02:24:05 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 02:24:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:25:24 | INFO | train_inner | epoch 230:     30 / 97 loss=0.616, ppl=1.53, wps=24158.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.911, loss_scale=32, train_wall=242, gb_free=8.2, wall=60541
2022-03-05 02:25:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:28:26 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 17.298 | ppl 161124 | wps 45052.7 | wpb 510.9 | bsz 1 | num_updates 22166 | best_loss 7.632
2022-03-05 02:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22166 updates
2022-03-05 02:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 230 @ 22166 updates, score 17.298) (writing took 2.1693146135658026 seconds)
2022-03-05 02:28:28 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 02:28:28 | INFO | train | epoch 230 | loss 0.616 | ppl 1.53 | wps 23899.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 22166 | lr 0.000212401 | gnorm 0.91 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 60725
2022-03-05 02:28:28 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 02:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:29:58 | INFO | train_inner | epoch 231:     34 / 97 loss=0.616, ppl=1.53, wps=23932.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.917, loss_scale=16, train_wall=244, gb_free=8.2, wall=60815
2022-03-05 02:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:32:49 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 17.258 | ppl 156720 | wps 44535.3 | wpb 510.9 | bsz 1 | num_updates 22263 | best_loss 7.632
2022-03-05 02:32:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22263 updates
2022-03-05 02:32:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:32:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 231 @ 22263 updates, score 17.258) (writing took 2.341685675084591 seconds)
2022-03-05 02:32:52 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 02:32:52 | INFO | train | epoch 231 | loss 0.614 | ppl 1.53 | wps 24119.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 22263 | lr 0.000211938 | gnorm 0.92 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 60988
2022-03-05 02:32:52 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 02:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:34:29 | INFO | train_inner | epoch 232:     37 / 97 loss=0.614, ppl=1.53, wps=24140.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.918, loss_scale=32, train_wall=242, gb_free=8.2, wall=61086
2022-03-05 02:36:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:37:13 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 17.324 | ppl 164109 | wps 44807.8 | wpb 510.9 | bsz 1 | num_updates 22359 | best_loss 7.632
2022-03-05 02:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22359 updates
2022-03-05 02:37:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 232 @ 22359 updates, score 17.324) (writing took 3.245108760893345 seconds)
2022-03-05 02:37:16 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 02:37:16 | INFO | train | epoch 232 | loss 0.611 | ppl 1.53 | wps 23795.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 22359 | lr 0.000211482 | gnorm 0.917 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 61253
2022-03-05 02:37:16 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 02:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:39:04 | INFO | train_inner | epoch 233:     41 / 97 loss=0.608, ppl=1.52, wps=23813.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.918, loss_scale=16, train_wall=244, gb_free=8.2, wall=61361
2022-03-05 02:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:41:37 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 17.256 | ppl 156485 | wps 44957.4 | wpb 510.9 | bsz 1 | num_updates 22456 | best_loss 7.632
2022-03-05 02:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22456 updates
2022-03-05 02:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:41:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:41:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 233 @ 22456 updates, score 17.256) (writing took 2.78855044208467 seconds)
2022-03-05 02:41:40 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 02:41:40 | INFO | train | epoch 233 | loss 0.609 | ppl 1.52 | wps 24062.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 22456 | lr 0.000211025 | gnorm 0.914 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 61517
2022-03-05 02:41:40 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 02:41:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:43:36 | INFO | train_inner | epoch 234:     44 / 97 loss=0.608, ppl=1.52, wps=24112.7, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.912, loss_scale=32, train_wall=242, gb_free=8.2, wall=61633
2022-03-05 02:44:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:45:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:46:00 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 17.302 | ppl 161614 | wps 45098.4 | wpb 510.9 | bsz 1 | num_updates 22552 | best_loss 7.632
2022-03-05 02:46:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22552 updates
2022-03-05 02:46:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:46:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:46:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 234 @ 22552 updates, score 17.302) (writing took 2.64597194083035 seconds)
2022-03-05 02:46:03 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 02:46:03 | INFO | train | epoch 234 | loss 0.606 | ppl 1.52 | wps 23871 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 22552 | lr 0.000210575 | gnorm 0.914 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 61780
2022-03-05 02:46:03 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 02:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:48:10 | INFO | train_inner | epoch 235:     48 / 97 loss=0.606, ppl=1.52, wps=23893.3, ups=0.36, wpb=65495, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.91, loss_scale=16, train_wall=244, gb_free=8.2, wall=61907
2022-03-05 02:50:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:50:24 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 17.328 | ppl 164544 | wps 44988 | wpb 510.9 | bsz 1 | num_updates 22648 | best_loss 7.632
2022-03-05 02:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22648 updates
2022-03-05 02:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:50:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:50:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 235 @ 22648 updates, score 17.328) (writing took 2.9520599925890565 seconds)
2022-03-05 02:50:27 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 02:50:27 | INFO | train | epoch 235 | loss 0.604 | ppl 1.52 | wps 23821.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 22648 | lr 0.000210129 | gnorm 0.908 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 62044
2022-03-05 02:50:27 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 02:50:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:52:44 | INFO | train_inner | epoch 236:     52 / 97 loss=0.602, ppl=1.52, wps=23875.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.908, loss_scale=16, train_wall=244, gb_free=8.2, wall=62181
2022-03-05 02:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:54:48 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 17.4 | ppl 172958 | wps 44991.9 | wpb 510.9 | bsz 1 | num_updates 22745 | best_loss 7.632
2022-03-05 02:54:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22745 updates
2022-03-05 02:54:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:54:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 236 @ 22745 updates, score 17.4) (writing took 2.6925111217424273 seconds)
2022-03-05 02:54:51 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 02:54:51 | INFO | train | epoch 236 | loss 0.603 | ppl 1.52 | wps 24111.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 22745 | lr 0.00020968 | gnorm 0.915 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 62307
2022-03-05 02:54:51 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 02:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 02:57:16 | INFO | train_inner | epoch 237:     55 / 97 loss=0.601, ppl=1.52, wps=24121.6, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.923, loss_scale=32, train_wall=242, gb_free=8.2, wall=62453
2022-03-05 02:57:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 02:59:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 02:59:12 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 17.432 | ppl 176823 | wps 45028.5 | wpb 510.9 | bsz 1 | num_updates 22841 | best_loss 7.632
2022-03-05 02:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22841 updates
2022-03-05 02:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 02:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 237 @ 22841 updates, score 17.432) (writing took 2.86554788146168 seconds)
2022-03-05 02:59:14 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 02:59:14 | INFO | train | epoch 237 | loss 0.599 | ppl 1.51 | wps 23827.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 22841 | lr 0.000209239 | gnorm 0.917 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 62571
2022-03-05 02:59:14 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 02:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:01:50 | INFO | train_inner | epoch 238:     59 / 97 loss=0.599, ppl=1.51, wps=23859.8, ups=0.36, wpb=65495, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.906, loss_scale=16, train_wall=244, gb_free=8.2, wall=62727
2022-03-05 03:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:03:35 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 17.402 | ppl 173243 | wps 44793.1 | wpb 510.9 | bsz 1 | num_updates 22938 | best_loss 7.632
2022-03-05 03:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22938 updates
2022-03-05 03:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 238 @ 22938 updates, score 17.402) (writing took 2.668925916776061 seconds)
2022-03-05 03:03:38 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 03:03:38 | INFO | train | epoch 238 | loss 0.597 | ppl 1.51 | wps 24087.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 22938 | lr 0.000208796 | gnorm 0.903 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 62835
2022-03-05 03:03:38 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 03:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:06:22 | INFO | train_inner | epoch 239:     62 / 97 loss=0.595, ppl=1.51, wps=24118.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.903, loss_scale=32, train_wall=242, gb_free=8.2, wall=62999
2022-03-05 03:07:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:07:59 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 17.401 | ppl 173078 | wps 44898.7 | wpb 510.9 | bsz 1 | num_updates 23035 | best_loss 7.632
2022-03-05 03:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23035 updates
2022-03-05 03:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 239 @ 23035 updates, score 17.401) (writing took 2.9812679113820195 seconds)
2022-03-05 03:08:02 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 03:08:02 | INFO | train | epoch 239 | loss 0.596 | ppl 1.51 | wps 24074.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 23035 | lr 0.000208356 | gnorm 0.906 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 63099
2022-03-05 03:08:02 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 03:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:09:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 03:10:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:11:00 | INFO | train_inner | epoch 240:     67 / 97 loss=0.596, ppl=1.51, wps=23539.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.907, loss_scale=16, train_wall=247, gb_free=8.2, wall=63277
2022-03-05 03:12:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:12:24 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 17.453 | ppl 179374 | wps 44952.5 | wpb 510.9 | bsz 1 | num_updates 23130 | best_loss 7.632
2022-03-05 03:12:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23130 updates
2022-03-05 03:12:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 240 @ 23130 updates, score 17.453) (writing took 2.778233448974788 seconds)
2022-03-05 03:12:27 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 03:12:27 | INFO | train | epoch 240 | loss 0.593 | ppl 1.51 | wps 23476.5 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 23130 | lr 0.000207928 | gnorm 0.911 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 63364
2022-03-05 03:12:27 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 03:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:15:32 | INFO | train_inner | epoch 241:     70 / 97 loss=0.592, ppl=1.51, wps=24096, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.91, loss_scale=16, train_wall=242, gb_free=8.2, wall=63549
2022-03-05 03:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:16:48 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 17.442 | ppl 178042 | wps 44673 | wpb 510.9 | bsz 1 | num_updates 23226 | best_loss 7.632
2022-03-05 03:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23226 updates
2022-03-05 03:16:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:16:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 241 @ 23226 updates, score 17.442) (writing took 2.768071082420647 seconds)
2022-03-05 03:16:51 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 03:16:51 | INFO | train | epoch 241 | loss 0.59 | ppl 1.51 | wps 23837.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 23226 | lr 0.000207497 | gnorm 0.907 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 63628
2022-03-05 03:16:51 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 03:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:20:06 | INFO | train_inner | epoch 242:     74 / 97 loss=0.588, ppl=1.5, wps=23863.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.908, loss_scale=16, train_wall=244, gb_free=8.2, wall=63823
2022-03-05 03:21:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:21:12 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 17.465 | ppl 180891 | wps 44588.7 | wpb 510.9 | bsz 1 | num_updates 23323 | best_loss 7.632
2022-03-05 03:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23323 updates
2022-03-05 03:21:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:21:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 242 @ 23323 updates, score 17.465) (writing took 2.943502922542393 seconds)
2022-03-05 03:21:15 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 03:21:15 | INFO | train | epoch 242 | loss 0.589 | ppl 1.5 | wps 24061.5 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 23323 | lr 0.000207066 | gnorm 0.909 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 63892
2022-03-05 03:21:15 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 03:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:23:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:24:41 | INFO | train_inner | epoch 243:     78 / 97 loss=0.588, ppl=1.5, wps=23865.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.908, loss_scale=16, train_wall=244, gb_free=8.2, wall=64098
2022-03-05 03:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:25:36 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 17.488 | ppl 183792 | wps 44861.9 | wpb 510.9 | bsz 1 | num_updates 23419 | best_loss 7.632
2022-03-05 03:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23419 updates
2022-03-05 03:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:25:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:25:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 243 @ 23419 updates, score 17.488) (writing took 2.731623881496489 seconds)
2022-03-05 03:25:38 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 03:25:38 | INFO | train | epoch 243 | loss 0.586 | ppl 1.5 | wps 23850.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 23419 | lr 0.000206641 | gnorm 0.908 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 64155
2022-03-05 03:25:38 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 03:25:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:29:12 | INFO | train_inner | epoch 244:     81 / 97 loss=0.587, ppl=1.5, wps=24121.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.91, loss_scale=16, train_wall=241, gb_free=8.2, wall=64369
2022-03-05 03:29:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:29:59 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 17.463 | ppl 180695 | wps 44172.5 | wpb 510.9 | bsz 1 | num_updates 23515 | best_loss 7.632
2022-03-05 03:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23515 updates
2022-03-05 03:29:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:30:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 244 @ 23515 updates, score 17.463) (writing took 3.1048574969172478 seconds)
2022-03-05 03:30:02 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 03:30:02 | INFO | train | epoch 244 | loss 0.584 | ppl 1.5 | wps 23810.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 23515 | lr 0.000206218 | gnorm 0.904 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 64419
2022-03-05 03:30:02 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 03:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:33:47 | INFO | train_inner | epoch 245:     85 / 97 loss=0.58, ppl=1.49, wps=23850.7, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23600, lr=0.000205847, gnorm=0.905, loss_scale=16, train_wall=244, gb_free=8.2, wall=64644
2022-03-05 03:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:34:23 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 17.431 | ppl 176663 | wps 44751.5 | wpb 510.9 | bsz 1 | num_updates 23612 | best_loss 7.632
2022-03-05 03:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23612 updates
2022-03-05 03:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 245 @ 23612 updates, score 17.431) (writing took 2.6868346529081464 seconds)
2022-03-05 03:34:26 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 03:34:26 | INFO | train | epoch 245 | loss 0.582 | ppl 1.5 | wps 24097.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 23612 | lr 0.000205794 | gnorm 0.911 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 64683
2022-03-05 03:34:26 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 03:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:37:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:38:21 | INFO | train_inner | epoch 246:     89 / 97 loss=0.583, ppl=1.5, wps=23887.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.911, loss_scale=16, train_wall=244, gb_free=8.2, wall=64918
2022-03-05 03:38:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:38:47 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 17.47 | ppl 181590 | wps 44889.5 | wpb 510.9 | bsz 1 | num_updates 23708 | best_loss 7.632
2022-03-05 03:38:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23708 updates
2022-03-05 03:38:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:38:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 246 @ 23708 updates, score 17.47) (writing took 2.589056620374322 seconds)
2022-03-05 03:38:50 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 03:38:50 | INFO | train | epoch 246 | loss 0.58 | ppl 1.49 | wps 23863.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 23708 | lr 0.000205377 | gnorm 0.905 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 64946
2022-03-05 03:38:50 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 03:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:42:53 | INFO | train_inner | epoch 247:     92 / 97 loss=0.579, ppl=1.49, wps=24128.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.901, loss_scale=16, train_wall=242, gb_free=8.2, wall=65189
2022-03-05 03:43:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:43:10 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 17.511 | ppl 186824 | wps 44933.5 | wpb 510.9 | bsz 1 | num_updates 23805 | best_loss 7.632
2022-03-05 03:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23805 updates
2022-03-05 03:43:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 247 @ 23805 updates, score 17.511) (writing took 2.7471882961690426 seconds)
2022-03-05 03:43:13 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 03:43:13 | INFO | train | epoch 247 | loss 0.578 | ppl 1.49 | wps 24094.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 23805 | lr 0.000204958 | gnorm 0.9 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 65210
2022-03-05 03:43:13 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 03:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:45:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 03:47:27 | INFO | train_inner | epoch 248:     96 / 97 loss=0.576, ppl=1.49, wps=23890.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.897, loss_scale=16, train_wall=244, gb_free=8.2, wall=65464
2022-03-05 03:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:47:34 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 17.568 | ppl 194318 | wps 45048.2 | wpb 510.9 | bsz 1 | num_updates 23901 | best_loss 7.632
2022-03-05 03:47:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23901 updates
2022-03-05 03:47:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:47:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:47:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 248 @ 23901 updates, score 17.568) (writing took 2.6429565297439694 seconds)
2022-03-05 03:47:37 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 03:47:37 | INFO | train | epoch 248 | loss 0.576 | ppl 1.49 | wps 23862.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 23901 | lr 0.000204546 | gnorm 0.897 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 65474
2022-03-05 03:47:37 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 03:47:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:51:58 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 17.498 | ppl 185051 | wps 45039.8 | wpb 510.9 | bsz 1 | num_updates 23998 | best_loss 7.632
2022-03-05 03:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23998 updates
2022-03-05 03:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 249 @ 23998 updates, score 17.498) (writing took 2.741750339977443 seconds)
2022-03-05 03:52:00 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 03:52:00 | INFO | train | epoch 249 | loss 0.574 | ppl 1.49 | wps 24088.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 23998 | lr 0.000204133 | gnorm 0.892 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 65737
2022-03-05 03:52:00 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 03:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:52:06 | INFO | train_inner | epoch 250:      2 / 97 loss=0.573, ppl=1.49, wps=23450.4, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=24000, lr=0.000204124, gnorm=0.892, loss_scale=32, train_wall=242, gb_free=8.2, wall=65743
2022-03-05 03:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 03:56:21 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 17.522 | ppl 188171 | wps 45108 | wpb 510.9 | bsz 1 | num_updates 24095 | best_loss 7.632
2022-03-05 03:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24095 updates
2022-03-05 03:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:56:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 03:56:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 250 @ 24095 updates, score 17.522) (writing took 2.6025926657021046 seconds)
2022-03-05 03:56:24 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 03:56:24 | INFO | train | epoch 250 | loss 0.572 | ppl 1.49 | wps 24112.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 24095 | lr 0.000203721 | gnorm 0.896 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 66001
2022-03-05 03:56:24 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 03:56:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 03:56:37 | INFO | train_inner | epoch 251:      5 / 97 loss=0.572, ppl=1.49, wps=24135.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.896, loss_scale=32, train_wall=241, gb_free=8.2, wall=66014
2022-03-05 03:56:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 03:58:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:00:45 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 17.538 | ppl 190252 | wps 44798.9 | wpb 510.9 | bsz 1 | num_updates 24190 | best_loss 7.632
2022-03-05 04:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24190 updates
2022-03-05 04:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 251 @ 24190 updates, score 17.538) (writing took 2.640390656888485 seconds)
2022-03-05 04:00:47 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 04:00:47 | INFO | train | epoch 251 | loss 0.568 | ppl 1.48 | wps 23622.3 | ups 0.36 | wpb 65490.6 | bsz 127.9 | num_updates 24190 | lr 0.000203321 | gnorm 0.893 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 66264
2022-03-05 04:00:47 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 04:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:01:14 | INFO | train_inner | epoch 252:     10 / 97 loss=0.568, ppl=1.48, wps=23680.1, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.893, loss_scale=16, train_wall=246, gb_free=8.2, wall=66291
2022-03-05 04:04:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:05:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:05:08 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 17.509 | ppl 186476 | wps 44921.1 | wpb 510.9 | bsz 1 | num_updates 24286 | best_loss 7.632
2022-03-05 04:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24286 updates
2022-03-05 04:05:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 252 @ 24286 updates, score 17.509) (writing took 2.818664981983602 seconds)
2022-03-05 04:05:11 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 04:05:11 | INFO | train | epoch 252 | loss 0.568 | ppl 1.48 | wps 23831.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 24286 | lr 0.000202919 | gnorm 0.894 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 66528
2022-03-05 04:05:11 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 04:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:05:48 | INFO | train_inner | epoch 253:     14 / 97 loss=0.566, ppl=1.48, wps=23868, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.894, loss_scale=16, train_wall=244, gb_free=8.2, wall=66565
2022-03-05 04:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:09:32 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 17.639 | ppl 204178 | wps 44894.3 | wpb 510.9 | bsz 1 | num_updates 24383 | best_loss 7.632
2022-03-05 04:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24383 updates
2022-03-05 04:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:09:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:09:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 253 @ 24383 updates, score 17.639) (writing took 2.593638456426561 seconds)
2022-03-05 04:09:35 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 04:09:35 | INFO | train | epoch 253 | loss 0.566 | ppl 1.48 | wps 24104.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 24383 | lr 0.000202515 | gnorm 0.899 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 66791
2022-03-05 04:09:35 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 04:09:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:10:20 | INFO | train_inner | epoch 254:     17 / 97 loss=0.565, ppl=1.48, wps=24126.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.892, loss_scale=16, train_wall=242, gb_free=8.2, wall=66836
2022-03-05 04:10:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:13:56 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 17.602 | ppl 198901 | wps 44947.5 | wpb 510.9 | bsz 1 | num_updates 24479 | best_loss 7.632
2022-03-05 04:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24479 updates
2022-03-05 04:13:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 254 @ 24479 updates, score 17.602) (writing took 2.914383756928146 seconds)
2022-03-05 04:13:58 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 04:13:58 | INFO | train | epoch 254 | loss 0.565 | ppl 1.48 | wps 23830 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 24479 | lr 0.000202117 | gnorm 0.895 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 67055
2022-03-05 04:13:58 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 04:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:14:54 | INFO | train_inner | epoch 255:     21 / 97 loss=0.565, ppl=1.48, wps=23871.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.896, loss_scale=16, train_wall=244, gb_free=8.2, wall=67111
2022-03-05 04:17:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:18:19 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 17.56 | ppl 193251 | wps 45128.4 | wpb 510.9 | bsz 1 | num_updates 24575 | best_loss 7.632
2022-03-05 04:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24575 updates
2022-03-05 04:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:18:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 255 @ 24575 updates, score 17.56) (writing took 2.657126878388226 seconds)
2022-03-05 04:18:22 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 04:18:22 | INFO | train | epoch 255 | loss 0.562 | ppl 1.48 | wps 23868.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 24575 | lr 0.000201722 | gnorm 0.886 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 67319
2022-03-05 04:18:22 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 04:18:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:19:28 | INFO | train_inner | epoch 256:     25 / 97 loss=0.56, ppl=1.47, wps=23903.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.888, loss_scale=16, train_wall=244, gb_free=8.2, wall=67385
2022-03-05 04:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:22:43 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 17.66 | ppl 207137 | wps 43258.7 | wpb 510.9 | bsz 1 | num_updates 24672 | best_loss 7.632
2022-03-05 04:22:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24672 updates
2022-03-05 04:22:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:22:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:22:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 256 @ 24672 updates, score 17.66) (writing took 2.83405286911875 seconds)
2022-03-05 04:22:46 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 04:22:46 | INFO | train | epoch 256 | loss 0.56 | ppl 1.47 | wps 24064.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 24672 | lr 0.000201325 | gnorm 0.896 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 67583
2022-03-05 04:22:46 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 04:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:23:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:24:02 | INFO | train_inner | epoch 257:     29 / 97 loss=0.56, ppl=1.47, wps=23861.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.897, loss_scale=16, train_wall=244, gb_free=8.2, wall=67659
2022-03-05 04:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:27:06 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 17.64 | ppl 204198 | wps 44984 | wpb 510.9 | bsz 1 | num_updates 24768 | best_loss 7.632
2022-03-05 04:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24768 updates
2022-03-05 04:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:27:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:27:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 257 @ 24768 updates, score 17.64) (writing took 2.6538702035322785 seconds)
2022-03-05 04:27:09 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 04:27:09 | INFO | train | epoch 257 | loss 0.557 | ppl 1.47 | wps 23879.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 24768 | lr 0.000200935 | gnorm 0.893 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 67846
2022-03-05 04:27:09 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 04:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:28:34 | INFO | train_inner | epoch 258:     32 / 97 loss=0.557, ppl=1.47, wps=24146.7, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.889, loss_scale=16, train_wall=241, gb_free=8.2, wall=67930
2022-03-05 04:30:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:31:30 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 17.66 | ppl 207172 | wps 45199.6 | wpb 510.9 | bsz 1 | num_updates 24864 | best_loss 7.632
2022-03-05 04:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24864 updates
2022-03-05 04:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 258 @ 24864 updates, score 17.66) (writing took 2.6169231105595827 seconds)
2022-03-05 04:31:32 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 04:31:32 | INFO | train | epoch 258 | loss 0.555 | ppl 1.47 | wps 23880 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 24864 | lr 0.000200546 | gnorm 0.88 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 68109
2022-03-05 04:31:32 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 04:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:33:07 | INFO | train_inner | epoch 259:     36 / 97 loss=0.555, ppl=1.47, wps=23920.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.879, loss_scale=16, train_wall=244, gb_free=8.2, wall=68204
2022-03-05 04:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:35:53 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 17.742 | ppl 219238 | wps 44934 | wpb 510.9 | bsz 1 | num_updates 24961 | best_loss 7.632
2022-03-05 04:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24961 updates
2022-03-05 04:35:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:35:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 259 @ 24961 updates, score 17.742) (writing took 3.2702094120904803 seconds)
2022-03-05 04:35:57 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 04:35:57 | INFO | train | epoch 259 | loss 0.555 | ppl 1.47 | wps 24054.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 24961 | lr 0.000200156 | gnorm 0.889 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 68373
2022-03-05 04:35:57 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 04:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:37:40 | INFO | train_inner | epoch 260:     39 / 97 loss=0.553, ppl=1.47, wps=24071.3, ups=0.37, wpb=65495, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.89, loss_scale=32, train_wall=241, gb_free=8.2, wall=68476
2022-03-05 04:38:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:40:17 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 17.634 | ppl 203441 | wps 44602 | wpb 510.9 | bsz 1 | num_updates 25057 | best_loss 7.632
2022-03-05 04:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25057 updates
2022-03-05 04:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:40:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 260 @ 25057 updates, score 17.634) (writing took 2.69086323864758 seconds)
2022-03-05 04:40:20 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 04:40:20 | INFO | train | epoch 260 | loss 0.553 | ppl 1.47 | wps 23862.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25057 | lr 0.000199772 | gnorm 0.891 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 68637
2022-03-05 04:40:20 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 04:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:42:14 | INFO | train_inner | epoch 261:     43 / 97 loss=0.551, ppl=1.47, wps=23902.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.886, loss_scale=16, train_wall=244, gb_free=8.2, wall=68750
2022-03-05 04:44:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:44:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:44:41 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 17.722 | ppl 216163 | wps 45179.1 | wpb 510.9 | bsz 1 | num_updates 25153 | best_loss 7.632
2022-03-05 04:44:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25153 updates
2022-03-05 04:44:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 261 @ 25153 updates, score 17.722) (writing took 2.802941615693271 seconds)
2022-03-05 04:44:44 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 04:44:44 | INFO | train | epoch 261 | loss 0.55 | ppl 1.46 | wps 23868.8 | ups 0.36 | wpb 65533.8 | bsz 128 | num_updates 25153 | lr 0.000199391 | gnorm 0.879 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 68900
2022-03-05 04:44:44 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 04:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:46:48 | INFO | train_inner | epoch 262:     47 / 97 loss=0.55, ppl=1.46, wps=23902.8, ups=0.36, wpb=65533.9, bsz=128, num_updates=25200, lr=0.000199205, gnorm=0.885, loss_scale=16, train_wall=244, gb_free=8.2, wall=69025
2022-03-05 04:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:49:04 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 17.699 | ppl 212767 | wps 45082.5 | wpb 510.9 | bsz 1 | num_updates 25250 | best_loss 7.632
2022-03-05 04:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25250 updates
2022-03-05 04:49:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 262 @ 25250 updates, score 17.699) (writing took 2.6905615711584687 seconds)
2022-03-05 04:49:07 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 04:49:07 | INFO | train | epoch 262 | loss 0.549 | ppl 1.46 | wps 24118.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 25250 | lr 0.000199007 | gnorm 0.887 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 69164
2022-03-05 04:49:07 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 04:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:50:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 04:51:22 | INFO | train_inner | epoch 263:     51 / 97 loss=0.549, ppl=1.46, wps=23912.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.888, loss_scale=16, train_wall=244, gb_free=8.2, wall=69298
2022-03-05 04:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:53:28 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 17.752 | ppl 220725 | wps 45044.3 | wpb 510.9 | bsz 1 | num_updates 25346 | best_loss 7.632
2022-03-05 04:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25346 updates
2022-03-05 04:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 263 @ 25346 updates, score 17.752) (writing took 2.64160296600312 seconds)
2022-03-05 04:53:30 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 04:53:30 | INFO | train | epoch 263 | loss 0.547 | ppl 1.46 | wps 23881.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25346 | lr 0.00019863 | gnorm 0.889 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 69427
2022-03-05 04:53:30 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 04:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:55:53 | INFO | train_inner | epoch 264:     54 / 97 loss=0.545, ppl=1.46, wps=24142.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.882, loss_scale=16, train_wall=241, gb_free=8.2, wall=69570
2022-03-05 04:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 04:57:51 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 17.751 | ppl 220518 | wps 45059.5 | wpb 510.9 | bsz 1 | num_updates 25443 | best_loss 7.632
2022-03-05 04:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25443 updates
2022-03-05 04:57:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:57:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 04:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 264 @ 25443 updates, score 17.751) (writing took 2.6664616391062737 seconds)
2022-03-05 04:57:54 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 04:57:54 | INFO | train | epoch 264 | loss 0.545 | ppl 1.46 | wps 24111.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 25443 | lr 0.000198251 | gnorm 0.882 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 69691
2022-03-05 04:57:54 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 04:57:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 04:58:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:00:27 | INFO | train_inner | epoch 265:     58 / 97 loss=0.545, ppl=1.46, wps=23902.5, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.889, loss_scale=16, train_wall=244, gb_free=8.2, wall=69844
2022-03-05 05:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:02:15 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 17.775 | ppl 224289 | wps 45024 | wpb 510.9 | bsz 1 | num_updates 25539 | best_loss 7.632
2022-03-05 05:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25539 updates
2022-03-05 05:02:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 265 @ 25539 updates, score 17.775) (writing took 2.6926323948428035 seconds)
2022-03-05 05:02:17 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 05:02:17 | INFO | train | epoch 265 | loss 0.544 | ppl 1.46 | wps 23859.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25539 | lr 0.000197878 | gnorm 0.889 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 69954
2022-03-05 05:02:17 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 05:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:04:58 | INFO | train_inner | epoch 266:     61 / 97 loss=0.543, ppl=1.46, wps=24125.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.883, loss_scale=32, train_wall=242, gb_free=8.2, wall=70115
2022-03-05 05:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:06:38 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 17.747 | ppl 220051 | wps 44722.3 | wpb 510.9 | bsz 1 | num_updates 25635 | best_loss 7.632
2022-03-05 05:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25635 updates
2022-03-05 05:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:06:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:06:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 266 @ 25635 updates, score 17.747) (writing took 2.8908052844926715 seconds)
2022-03-05 05:06:41 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 05:06:41 | INFO | train | epoch 266 | loss 0.542 | ppl 1.46 | wps 23837.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25635 | lr 0.000197507 | gnorm 0.883 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 70218
2022-03-05 05:06:41 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 05:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:09:33 | INFO | train_inner | epoch 267:     65 / 97 loss=0.54, ppl=1.45, wps=23881.8, ups=0.36, wpb=65495, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.89, loss_scale=16, train_wall=244, gb_free=8.2, wall=70389
2022-03-05 05:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:11:02 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 17.822 | ppl 231740 | wps 45129 | wpb 510.9 | bsz 1 | num_updates 25732 | best_loss 7.632
2022-03-05 05:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25732 updates
2022-03-05 05:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 267 @ 25732 updates, score 17.822) (writing took 2.5981084387749434 seconds)
2022-03-05 05:11:04 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 05:11:04 | INFO | train | epoch 267 | loss 0.54 | ppl 1.45 | wps 24115.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 25732 | lr 0.000197135 | gnorm 0.886 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 70481
2022-03-05 05:11:04 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 05:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:13:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:14:07 | INFO | train_inner | epoch 268:     69 / 97 loss=0.538, ppl=1.45, wps=23902.6, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.875, loss_scale=16, train_wall=244, gb_free=8.2, wall=70663
2022-03-05 05:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:15:25 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 17.883 | ppl 241695 | wps 45093.9 | wpb 510.9 | bsz 1 | num_updates 25828 | best_loss 7.632
2022-03-05 05:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25828 updates
2022-03-05 05:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 268 @ 25828 updates, score 17.883) (writing took 2.7721831388771534 seconds)
2022-03-05 05:15:28 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 05:15:28 | INFO | train | epoch 268 | loss 0.537 | ppl 1.45 | wps 23850.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25828 | lr 0.000196768 | gnorm 0.878 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 70745
2022-03-05 05:15:28 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 05:15:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:18:38 | INFO | train_inner | epoch 269:     72 / 97 loss=0.537, ppl=1.45, wps=24115.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.879, loss_scale=16, train_wall=242, gb_free=8.2, wall=70935
2022-03-05 05:19:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:19:49 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 17.871 | ppl 239787 | wps 45191.9 | wpb 510.9 | bsz 1 | num_updates 25924 | best_loss 7.632
2022-03-05 05:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25924 updates
2022-03-05 05:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 269 @ 25924 updates, score 17.871) (writing took 2.635615613311529 seconds)
2022-03-05 05:19:51 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 05:19:51 | INFO | train | epoch 269 | loss 0.537 | ppl 1.45 | wps 23865.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 25924 | lr 0.000196403 | gnorm 0.878 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 71008
2022-03-05 05:19:51 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 05:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:23:12 | INFO | train_inner | epoch 270:     76 / 97 loss=0.536, ppl=1.45, wps=23908.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.887, loss_scale=16, train_wall=244, gb_free=8.2, wall=71209
2022-03-05 05:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:24:12 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 17.817 | ppl 230925 | wps 45020.8 | wpb 510.9 | bsz 1 | num_updates 26021 | best_loss 7.632
2022-03-05 05:24:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26021 updates
2022-03-05 05:24:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 270 @ 26021 updates, score 17.817) (writing took 2.656922399997711 seconds)
2022-03-05 05:24:15 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 05:24:15 | INFO | train | epoch 270 | loss 0.534 | ppl 1.45 | wps 24114.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 26021 | lr 0.000196037 | gnorm 0.881 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 71272
2022-03-05 05:24:15 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 05:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:26:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:27:46 | INFO | train_inner | epoch 271:     80 / 97 loss=0.535, ppl=1.45, wps=23892.1, ups=0.36, wpb=65495, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.871, loss_scale=16, train_wall=244, gb_free=8.2, wall=71483
2022-03-05 05:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:28:36 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 17.945 | ppl 252341 | wps 45020.5 | wpb 510.9 | bsz 1 | num_updates 26117 | best_loss 7.632
2022-03-05 05:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26117 updates
2022-03-05 05:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:28:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 271 @ 26117 updates, score 17.945) (writing took 2.7411777060478926 seconds)
2022-03-05 05:28:39 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 05:28:39 | INFO | train | epoch 271 | loss 0.534 | ppl 1.45 | wps 23842.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 26117 | lr 0.000195676 | gnorm 0.872 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 71535
2022-03-05 05:28:39 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 05:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:32:18 | INFO | train_inner | epoch 272:     83 / 97 loss=0.531, ppl=1.44, wps=24114.4, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=26200, lr=0.000195366, gnorm=0.874, loss_scale=16, train_wall=242, gb_free=8.2, wall=71755
2022-03-05 05:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:32:59 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 17.91 | ppl 246288 | wps 44961.8 | wpb 510.9 | bsz 1 | num_updates 26214 | best_loss 7.632
2022-03-05 05:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26214 updates
2022-03-05 05:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 272 @ 26214 updates, score 17.91) (writing took 2.6682405481114984 seconds)
2022-03-05 05:33:02 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 05:33:02 | INFO | train | epoch 272 | loss 0.531 | ppl 1.44 | wps 24104.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 26214 | lr 0.000195314 | gnorm 0.874 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 71799
2022-03-05 05:33:02 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 05:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:36:52 | INFO | train_inner | epoch 273:     87 / 97 loss=0.531, ppl=1.44, wps=23878.4, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.879, loss_scale=16, train_wall=244, gb_free=8.2, wall=72029
2022-03-05 05:37:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:37:23 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 17.871 | ppl 239736 | wps 45042.7 | wpb 510.9 | bsz 1 | num_updates 26310 | best_loss 7.632
2022-03-05 05:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26310 updates
2022-03-05 05:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 273 @ 26310 updates, score 17.871) (writing took 2.812891975045204 seconds)
2022-03-05 05:37:26 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 05:37:26 | INFO | train | epoch 273 | loss 0.53 | ppl 1.44 | wps 23825.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 26310 | lr 0.000194957 | gnorm 0.88 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 72063
2022-03-05 05:37:26 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 05:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:41:24 | INFO | train_inner | epoch 274:     90 / 97 loss=0.529, ppl=1.44, wps=24103.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=26400, lr=0.000194625, gnorm=0.868, loss_scale=32, train_wall=242, gb_free=8.2, wall=72301
2022-03-05 05:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:41:47 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 17.99 | ppl 260347 | wps 44984.2 | wpb 510.9 | bsz 1 | num_updates 26407 | best_loss 7.632
2022-03-05 05:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26407 updates
2022-03-05 05:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:41:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:41:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 274 @ 26407 updates, score 17.99) (writing took 2.715483591891825 seconds)
2022-03-05 05:41:50 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 05:41:50 | INFO | train | epoch 274 | loss 0.529 | ppl 1.44 | wps 24090.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 26407 | lr 0.000194599 | gnorm 0.867 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 72327
2022-03-05 05:41:50 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 05:41:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:43:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:45:58 | INFO | train_inner | epoch 275:     94 / 97 loss=0.529, ppl=1.44, wps=23888.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.876, loss_scale=16, train_wall=244, gb_free=8.2, wall=72575
2022-03-05 05:46:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:46:11 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 17.862 | ppl 238223 | wps 44956 | wpb 510.9 | bsz 1 | num_updates 26503 | best_loss 7.632
2022-03-05 05:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26503 updates
2022-03-05 05:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 275 @ 26503 updates, score 17.862) (writing took 2.6139731453731656 seconds)
2022-03-05 05:46:13 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 05:46:13 | INFO | train | epoch 275 | loss 0.527 | ppl 1.44 | wps 23860.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 26503 | lr 0.000194246 | gnorm 0.875 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 72590
2022-03-05 05:46:13 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 05:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:50:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:50:34 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 17.842 | ppl 235008 | wps 45170.4 | wpb 510.9 | bsz 1 | num_updates 26599 | best_loss 7.632
2022-03-05 05:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26599 updates
2022-03-05 05:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 276 @ 26599 updates, score 17.842) (writing took 2.7974371472373605 seconds)
2022-03-05 05:50:37 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 05:50:37 | INFO | train | epoch 276 | loss 0.525 | ppl 1.44 | wps 23842.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 26599 | lr 0.000193895 | gnorm 0.884 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 72854
2022-03-05 05:50:37 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 05:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:50:40 | INFO | train_inner | epoch 277:      1 / 97 loss=0.525, ppl=1.44, wps=23235.4, ups=0.35, wpb=65451.9, bsz=127.8, num_updates=26600, lr=0.000193892, gnorm=0.884, loss_scale=16, train_wall=244, gb_free=8.2, wall=72856
2022-03-05 05:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:54:58 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 17.986 | ppl 259664 | wps 45167.5 | wpb 510.9 | bsz 1 | num_updates 26696 | best_loss 7.632
2022-03-05 05:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26696 updates
2022-03-05 05:54:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 277 @ 26696 updates, score 17.986) (writing took 2.5999383330345154 seconds)
2022-03-05 05:55:00 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 05:55:00 | INFO | train | epoch 277 | loss 0.522 | ppl 1.44 | wps 24117.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 26696 | lr 0.000193543 | gnorm 0.875 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 73117
2022-03-05 05:55:00 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 05:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:55:11 | INFO | train_inner | epoch 278:      4 / 97 loss=0.521, ppl=1.44, wps=24140.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.874, loss_scale=16, train_wall=241, gb_free=8.2, wall=73128
2022-03-05 05:56:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 05:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 05:59:21 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 17.975 | ppl 257657 | wps 45174.7 | wpb 510.9 | bsz 1 | num_updates 26792 | best_loss 7.632
2022-03-05 05:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26792 updates
2022-03-05 05:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 05:59:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 278 @ 26792 updates, score 17.975) (writing took 2.338569422252476 seconds)
2022-03-05 05:59:23 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 05:59:23 | INFO | train | epoch 278 | loss 0.521 | ppl 1.43 | wps 23895.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 26792 | lr 0.000193196 | gnorm 0.863 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 73380
2022-03-05 05:59:23 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 05:59:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 05:59:45 | INFO | train_inner | epoch 279:      8 / 97 loss=0.52, ppl=1.43, wps=23928.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.864, loss_scale=16, train_wall=244, gb_free=8.2, wall=73401
2022-03-05 06:02:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:03:44 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 17.929 | ppl 249502 | wps 45049.6 | wpb 510.9 | bsz 1 | num_updates 26888 | best_loss 7.632
2022-03-05 06:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26888 updates
2022-03-05 06:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:03:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 279 @ 26888 updates, score 17.929) (writing took 2.3813942847773433 seconds)
2022-03-05 06:03:46 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 06:03:46 | INFO | train | epoch 279 | loss 0.52 | ppl 1.43 | wps 23904.9 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 26888 | lr 0.00019285 | gnorm 0.867 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 73643
2022-03-05 06:03:46 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 06:03:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:04:18 | INFO | train_inner | epoch 280:     12 / 97 loss=0.519, ppl=1.43, wps=23943.1, ups=0.37, wpb=65495, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.865, loss_scale=16, train_wall=244, gb_free=8.2, wall=73675
2022-03-05 06:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:08:07 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 17.924 | ppl 248756 | wps 44961.9 | wpb 510.9 | bsz 1 | num_updates 26985 | best_loss 7.632
2022-03-05 06:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26985 updates
2022-03-05 06:08:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:08:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:08:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 280 @ 26985 updates, score 17.924) (writing took 2.305064900778234 seconds)
2022-03-05 06:08:09 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 06:08:09 | INFO | train | epoch 280 | loss 0.518 | ppl 1.43 | wps 24158.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 26985 | lr 0.000192504 | gnorm 0.879 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 73906
2022-03-05 06:08:09 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 06:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:08:49 | INFO | train_inner | epoch 281:     15 / 97 loss=0.518, ppl=1.43, wps=24178.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.879, loss_scale=32, train_wall=241, gb_free=8.2, wall=73946
2022-03-05 06:10:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:12:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:12:30 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 17.963 | ppl 255576 | wps 45021.6 | wpb 510.9 | bsz 1 | num_updates 27081 | best_loss 7.632
2022-03-05 06:12:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27081 updates
2022-03-05 06:12:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:12:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:12:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 281 @ 27081 updates, score 17.963) (writing took 2.367915142327547 seconds)
2022-03-05 06:12:32 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 06:12:32 | INFO | train | epoch 281 | loss 0.516 | ppl 1.43 | wps 23903.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 27081 | lr 0.000192162 | gnorm 0.866 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 74169
2022-03-05 06:12:32 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 06:12:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:13:23 | INFO | train_inner | epoch 282:     19 / 97 loss=0.515, ppl=1.43, wps=23944.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.865, loss_scale=16, train_wall=244, gb_free=8.2, wall=74219
2022-03-05 06:16:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:16:53 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 17.898 | ppl 244242 | wps 45197.1 | wpb 510.9 | bsz 1 | num_updates 27177 | best_loss 7.632
2022-03-05 06:16:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27177 updates
2022-03-05 06:16:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 282 @ 27177 updates, score 17.898) (writing took 2.388534564524889 seconds)
2022-03-05 06:16:55 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 06:16:55 | INFO | train | epoch 282 | loss 0.515 | ppl 1.43 | wps 23915 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 27177 | lr 0.000191822 | gnorm 0.872 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 74432
2022-03-05 06:16:55 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 06:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:17:56 | INFO | train_inner | epoch 283:     23 / 97 loss=0.514, ppl=1.43, wps=23947.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.874, loss_scale=16, train_wall=244, gb_free=8.2, wall=74493
2022-03-05 06:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:21:16 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 17.891 | ppl 243121 | wps 45254.9 | wpb 510.9 | bsz 1 | num_updates 27274 | best_loss 7.632
2022-03-05 06:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27274 updates
2022-03-05 06:21:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 283 @ 27274 updates, score 17.891) (writing took 2.379522363655269 seconds)
2022-03-05 06:21:18 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 06:21:18 | INFO | train | epoch 283 | loss 0.513 | ppl 1.43 | wps 24146 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 27274 | lr 0.000191481 | gnorm 0.872 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 74695
2022-03-05 06:21:18 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 06:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:22:27 | INFO | train_inner | epoch 284:     26 / 97 loss=0.512, ppl=1.43, wps=24170.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.867, loss_scale=16, train_wall=241, gb_free=8.2, wall=74764
2022-03-05 06:23:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:25:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:25:39 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 18.022 | ppl 266146 | wps 45094.5 | wpb 510.9 | bsz 1 | num_updates 27370 | best_loss 7.632
2022-03-05 06:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27370 updates
2022-03-05 06:25:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:25:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 284 @ 27370 updates, score 18.022) (writing took 2.4145563961938024 seconds)
2022-03-05 06:25:41 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 06:25:41 | INFO | train | epoch 284 | loss 0.511 | ppl 1.43 | wps 23911.6 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 27370 | lr 0.000191145 | gnorm 0.868 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 74958
2022-03-05 06:25:41 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 06:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:27:01 | INFO | train_inner | epoch 285:     30 / 97 loss=0.51, ppl=1.42, wps=23944, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.865, loss_scale=16, train_wall=244, gb_free=8.2, wall=75037
2022-03-05 06:29:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:30:02 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 17.985 | ppl 259455 | wps 45017.3 | wpb 510.9 | bsz 1 | num_updates 27466 | best_loss 7.632
2022-03-05 06:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27466 updates
2022-03-05 06:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:30:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:30:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 285 @ 27466 updates, score 17.985) (writing took 2.2219894360750914 seconds)
2022-03-05 06:30:04 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 06:30:04 | INFO | train | epoch 285 | loss 0.51 | ppl 1.42 | wps 23900.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 27466 | lr 0.000190811 | gnorm 0.861 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 75221
2022-03-05 06:30:04 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 06:30:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:31:34 | INFO | train_inner | epoch 286:     34 / 97 loss=0.509, ppl=1.42, wps=23933.4, ups=0.37, wpb=65495, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.862, loss_scale=16, train_wall=244, gb_free=8.2, wall=75311
2022-03-05 06:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:34:25 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 17.882 | ppl 241617 | wps 45188.7 | wpb 510.9 | bsz 1 | num_updates 27563 | best_loss 7.632
2022-03-05 06:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27563 updates
2022-03-05 06:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:34:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 286 @ 27563 updates, score 17.882) (writing took 2.0539676481857896 seconds)
2022-03-05 06:34:27 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 06:34:27 | INFO | train | epoch 286 | loss 0.509 | ppl 1.42 | wps 24180 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 27563 | lr 0.000190474 | gnorm 0.864 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 75484
2022-03-05 06:34:27 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 06:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:36:05 | INFO | train_inner | epoch 287:     37 / 97 loss=0.508, ppl=1.42, wps=24203.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.862, loss_scale=32, train_wall=241, gb_free=8.2, wall=75582
2022-03-05 06:37:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:38:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:38:48 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 18.022 | ppl 266116 | wps 45187.9 | wpb 510.9 | bsz 1 | num_updates 27659 | best_loss 7.632
2022-03-05 06:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27659 updates
2022-03-05 06:38:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 287 @ 27659 updates, score 18.022) (writing took 2.1669478891417384 seconds)
2022-03-05 06:38:50 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 06:38:50 | INFO | train | epoch 287 | loss 0.507 | ppl 1.42 | wps 23937.2 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 27659 | lr 0.000190144 | gnorm 0.859 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 75747
2022-03-05 06:38:50 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 06:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:40:38 | INFO | train_inner | epoch 288:     41 / 97 loss=0.508, ppl=1.42, wps=23968.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.86, loss_scale=16, train_wall=244, gb_free=8.2, wall=75855
2022-03-05 06:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:43:10 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 18.025 | ppl 266662 | wps 45094.4 | wpb 510.9 | bsz 1 | num_updates 27756 | best_loss 7.632
2022-03-05 06:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27756 updates
2022-03-05 06:43:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 288 @ 27756 updates, score 18.025) (writing took 2.150927657261491 seconds)
2022-03-05 06:43:13 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 06:43:13 | INFO | train | epoch 288 | loss 0.506 | ppl 1.42 | wps 24175.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 27756 | lr 0.000189811 | gnorm 0.853 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 76009
2022-03-05 06:43:13 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 06:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:43:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:45:11 | INFO | train_inner | epoch 289:     45 / 97 loss=0.505, ppl=1.42, wps=23976, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.858, loss_scale=16, train_wall=244, gb_free=8.2, wall=76128
2022-03-05 06:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:47:33 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 18.054 | ppl 272102 | wps 45162.5 | wpb 510.9 | bsz 1 | num_updates 27852 | best_loss 7.632
2022-03-05 06:47:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27852 updates
2022-03-05 06:47:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:47:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:47:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 289 @ 27852 updates, score 18.054) (writing took 2.1722448328509927 seconds)
2022-03-05 06:47:35 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 06:47:35 | INFO | train | epoch 289 | loss 0.505 | ppl 1.42 | wps 23941.3 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 27852 | lr 0.000189484 | gnorm 0.864 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 76272
2022-03-05 06:47:35 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 06:47:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:49:42 | INFO | train_inner | epoch 290:     48 / 97 loss=0.503, ppl=1.42, wps=24197.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.862, loss_scale=32, train_wall=241, gb_free=8.2, wall=76399
2022-03-05 06:50:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 06:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:51:56 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 18.069 | ppl 274923 | wps 45074.7 | wpb 510.9 | bsz 1 | num_updates 27948 | best_loss 7.632
2022-03-05 06:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27948 updates
2022-03-05 06:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 290 @ 27948 updates, score 18.069) (writing took 2.1083685997873545 seconds)
2022-03-05 06:51:58 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 06:51:58 | INFO | train | epoch 290 | loss 0.504 | ppl 1.42 | wps 23929 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 27948 | lr 0.000189158 | gnorm 0.867 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 76535
2022-03-05 06:51:58 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 06:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:54:15 | INFO | train_inner | epoch 291:     52 / 97 loss=0.503, ppl=1.42, wps=23966.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.865, loss_scale=16, train_wall=244, gb_free=8.2, wall=76672
2022-03-05 06:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 06:56:18 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 18.108 | ppl 282441 | wps 45005.1 | wpb 510.9 | bsz 1 | num_updates 28045 | best_loss 7.632
2022-03-05 06:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28045 updates
2022-03-05 06:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:56:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 06:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 291 @ 28045 updates, score 18.108) (writing took 2.224537407979369 seconds)
2022-03-05 06:56:21 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 06:56:21 | INFO | train | epoch 291 | loss 0.501 | ppl 1.42 | wps 24171.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 28045 | lr 0.000188831 | gnorm 0.861 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 76798
2022-03-05 06:56:21 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 06:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 06:58:46 | INFO | train_inner | epoch 292:     55 / 97 loss=0.5, ppl=1.41, wps=24196.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.854, loss_scale=32, train_wall=241, gb_free=8.2, wall=76943
2022-03-05 07:00:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:00:41 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 18.091 | ppl 279178 | wps 45115.6 | wpb 510.9 | bsz 1 | num_updates 28142 | best_loss 7.632
2022-03-05 07:00:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28142 updates
2022-03-05 07:00:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:00:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 292 @ 28142 updates, score 18.091) (writing took 2.178260817192495 seconds)
2022-03-05 07:00:43 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 07:00:43 | INFO | train | epoch 292 | loss 0.5 | ppl 1.41 | wps 24177 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 28142 | lr 0.000188505 | gnorm 0.853 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 77060
2022-03-05 07:00:43 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 07:00:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:03:19 | INFO | train_inner | epoch 293:     59 / 97 loss=0.501, ppl=1.41, wps=23969.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.858, loss_scale=16, train_wall=244, gb_free=8.2, wall=77216
2022-03-05 07:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:05:04 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 18.073 | ppl 275711 | wps 45247.4 | wpb 510.9 | bsz 1 | num_updates 28238 | best_loss 7.632
2022-03-05 07:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28238 updates
2022-03-05 07:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 293 @ 28238 updates, score 18.073) (writing took 2.109499517828226 seconds)
2022-03-05 07:05:06 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 07:05:06 | INFO | train | epoch 293 | loss 0.498 | ppl 1.41 | wps 23944.5 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 28238 | lr 0.000188184 | gnorm 0.858 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 77323
2022-03-05 07:05:06 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 07:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:07:49 | INFO | train_inner | epoch 294:     62 / 97 loss=0.497, ppl=1.41, wps=24223.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.862, loss_scale=32, train_wall=241, gb_free=8.2, wall=77486
2022-03-05 07:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:09:26 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 18.063 | ppl 273840 | wps 45265.6 | wpb 510.9 | bsz 1 | num_updates 28335 | best_loss 7.632
2022-03-05 07:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28335 updates
2022-03-05 07:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:09:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 294 @ 28335 updates, score 18.063) (writing took 2.2413445003330708 seconds)
2022-03-05 07:09:29 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 07:09:29 | INFO | train | epoch 294 | loss 0.498 | ppl 1.41 | wps 24197.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 28335 | lr 0.000187862 | gnorm 0.864 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 77585
2022-03-05 07:09:29 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 07:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:10:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:12:23 | INFO | train_inner | epoch 295:     66 / 97 loss=0.497, ppl=1.41, wps=23931.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.862, loss_scale=16, train_wall=244, gb_free=8.2, wall=77760
2022-03-05 07:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:13:49 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 18.111 | ppl 283097 | wps 45183 | wpb 510.9 | bsz 1 | num_updates 28431 | best_loss 7.632
2022-03-05 07:13:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28431 updates
2022-03-05 07:13:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 295 @ 28431 updates, score 18.111) (writing took 2.179425021633506 seconds)
2022-03-05 07:13:52 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 07:13:52 | INFO | train | epoch 295 | loss 0.496 | ppl 1.41 | wps 23894.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 28431 | lr 0.000187544 | gnorm 0.86 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 77849
2022-03-05 07:13:52 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 07:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:16:54 | INFO | train_inner | epoch 296:     69 / 97 loss=0.495, ppl=1.41, wps=24177.9, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.853, loss_scale=32, train_wall=241, gb_free=8.2, wall=78031
2022-03-05 07:16:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:18:12 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 18.056 | ppl 272507 | wps 45298.9 | wpb 510.9 | bsz 1 | num_updates 28527 | best_loss 7.632
2022-03-05 07:18:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28527 updates
2022-03-05 07:18:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:18:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 296 @ 28527 updates, score 18.056) (writing took 2.1919251549988985 seconds)
2022-03-05 07:18:15 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 07:18:15 | INFO | train | epoch 296 | loss 0.493 | ppl 1.41 | wps 23907.5 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 28527 | lr 0.000187228 | gnorm 0.852 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 78112
2022-03-05 07:18:15 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 07:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:21:27 | INFO | train_inner | epoch 297:     73 / 97 loss=0.494, ppl=1.41, wps=23943.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.857, loss_scale=16, train_wall=244, gb_free=8.2, wall=78304
2022-03-05 07:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:22:35 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 18.105 | ppl 281993 | wps 45218.5 | wpb 510.9 | bsz 1 | num_updates 28624 | best_loss 7.632
2022-03-05 07:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28624 updates
2022-03-05 07:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:22:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 297 @ 28624 updates, score 18.105) (writing took 2.0613925410434604 seconds)
2022-03-05 07:22:38 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 07:22:38 | INFO | train | epoch 297 | loss 0.493 | ppl 1.41 | wps 24165.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 28624 | lr 0.000186911 | gnorm 0.863 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 78374
2022-03-05 07:22:38 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 07:22:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:23:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:26:01 | INFO | train_inner | epoch 298:     77 / 97 loss=0.493, ppl=1.41, wps=23956.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.87, loss_scale=16, train_wall=244, gb_free=8.2, wall=78578
2022-03-05 07:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:26:58 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 18.111 | ppl 283047 | wps 44970.2 | wpb 510.9 | bsz 1 | num_updates 28720 | best_loss 7.632
2022-03-05 07:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28720 updates
2022-03-05 07:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 298 @ 28720 updates, score 18.111) (writing took 2.2415523417294025 seconds)
2022-03-05 07:27:01 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 07:27:01 | INFO | train | epoch 298 | loss 0.492 | ppl 1.41 | wps 23896.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 28720 | lr 0.000186598 | gnorm 0.862 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 78638
2022-03-05 07:27:01 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 07:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:30:32 | INFO | train_inner | epoch 299:     80 / 97 loss=0.492, ppl=1.41, wps=24147.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=28800, lr=0.000186339, gnorm=0.853, loss_scale=32, train_wall=242, gb_free=8.2, wall=78849
2022-03-05 07:31:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:31:22 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 18.072 | ppl 275562 | wps 45161.5 | wpb 510.9 | bsz 1 | num_updates 28816 | best_loss 7.632
2022-03-05 07:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28816 updates
2022-03-05 07:31:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 299 @ 28816 updates, score 18.072) (writing took 2.204385663382709 seconds)
2022-03-05 07:31:24 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 07:31:24 | INFO | train | epoch 299 | loss 0.49 | ppl 1.4 | wps 23884.4 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 28816 | lr 0.000186287 | gnorm 0.853 | loss_scale 16 | train_wall 235 | gb_free 8.2 | wall 78901
2022-03-05 07:31:24 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 07:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:35:06 | INFO | train_inner | epoch 300:     84 / 97 loss=0.488, ppl=1.4, wps=23936.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.85, loss_scale=16, train_wall=244, gb_free=8.2, wall=79123
2022-03-05 07:35:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:35:45 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 18.169 | ppl 294797 | wps 45138 | wpb 510.9 | bsz 1 | num_updates 28913 | best_loss 7.632
2022-03-05 07:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28913 updates
2022-03-05 07:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 300 @ 28913 updates, score 18.169) (writing took 2.2088572569191456 seconds)
2022-03-05 07:35:47 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 07:35:47 | INFO | train | epoch 300 | loss 0.489 | ppl 1.4 | wps 24149 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 28913 | lr 0.000185975 | gnorm 0.85 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 79164
2022-03-05 07:35:47 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 07:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:39:37 | INFO | train_inner | epoch 301:     87 / 97 loss=0.489, ppl=1.4, wps=24176.5, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=29000, lr=0.000185695, gnorm=0.857, loss_scale=32, train_wall=241, gb_free=8.2, wall=79393
2022-03-05 07:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:40:08 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 18.214 | ppl 304104 | wps 45199 | wpb 510.9 | bsz 1 | num_updates 29010 | best_loss 7.632
2022-03-05 07:40:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 29010 updates
2022-03-05 07:40:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:40:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 301 @ 29010 updates, score 18.214) (writing took 2.197891633026302 seconds)
2022-03-05 07:40:10 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-05 07:40:10 | INFO | train | epoch 301 | loss 0.488 | ppl 1.4 | wps 24161.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 29010 | lr 0.000185663 | gnorm 0.855 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 79427
2022-03-05 07:40:10 | INFO | fairseq.trainer | begin training epoch 302
2022-03-05 07:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:42:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 07:44:10 | INFO | train_inner | epoch 302:     91 / 97 loss=0.487, ppl=1.4, wps=23956.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.847, loss_scale=32, train_wall=244, gb_free=8.2, wall=79667
2022-03-05 07:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:44:31 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 18.211 | ppl 303402 | wps 45187.9 | wpb 510.9 | bsz 1 | num_updates 29106 | best_loss 7.632
2022-03-05 07:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29106 updates
2022-03-05 07:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:44:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:44:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 302 @ 29106 updates, score 18.211) (writing took 2.16064343880862 seconds)
2022-03-05 07:44:33 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-05 07:44:33 | INFO | train | epoch 302 | loss 0.487 | ppl 1.4 | wps 23922.8 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 29106 | lr 0.000185357 | gnorm 0.846 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 79690
2022-03-05 07:44:33 | INFO | fairseq.trainer | begin training epoch 303
2022-03-05 07:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:45:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:48:43 | INFO | train_inner | epoch 303:     95 / 97 loss=0.486, ppl=1.4, wps=23947.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.854, loss_scale=16, train_wall=244, gb_free=8.2, wall=79940
2022-03-05 07:48:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:48:53 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 18.199 | ppl 300961 | wps 45125.3 | wpb 510.9 | bsz 1 | num_updates 29202 | best_loss 7.632
2022-03-05 07:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29202 updates
2022-03-05 07:48:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:48:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:48:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 303 @ 29202 updates, score 18.199) (writing took 2.2486453661695123 seconds)
2022-03-05 07:48:56 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-05 07:48:56 | INFO | train | epoch 303 | loss 0.485 | ppl 1.4 | wps 23902.7 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29202 | lr 0.000185052 | gnorm 0.853 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 79953
2022-03-05 07:48:56 | INFO | fairseq.trainer | begin training epoch 304
2022-03-05 07:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:53:18 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 18.238 | ppl 309251 | wps 44371.2 | wpb 510.9 | bsz 1 | num_updates 29299 | best_loss 7.632
2022-03-05 07:53:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29299 updates
2022-03-05 07:53:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:53:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 304 @ 29299 updates, score 18.238) (writing took 4.0024304036051035 seconds)
2022-03-05 07:53:22 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-05 07:53:22 | INFO | train | epoch 304 | loss 0.484 | ppl 1.4 | wps 23840.5 | ups 0.36 | wpb 65491.6 | bsz 127.9 | num_updates 29299 | lr 0.000184745 | gnorm 0.847 | loss_scale 32 | train_wall 235 | gb_free 8.2 | wall 80219
2022-03-05 07:53:22 | INFO | fairseq.trainer | begin training epoch 305
2022-03-05 07:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:53:25 | INFO | train_inner | epoch 305:      1 / 97 loss=0.484, ppl=1.4, wps=23243.7, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=29300, lr=0.000184742, gnorm=0.846, loss_scale=32, train_wall=242, gb_free=8.2, wall=80222
2022-03-05 07:55:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 07:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 07:57:44 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 18.247 | ppl 311107 | wps 44861.4 | wpb 510.9 | bsz 1 | num_updates 29395 | best_loss 7.632
2022-03-05 07:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29395 updates
2022-03-05 07:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 07:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 305 @ 29395 updates, score 18.247) (writing took 2.780501827597618 seconds)
2022-03-05 07:57:47 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-05 07:57:47 | INFO | train | epoch 305 | loss 0.482 | ppl 1.4 | wps 23751 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29395 | lr 0.000184443 | gnorm 0.849 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 80484
2022-03-05 07:57:47 | INFO | fairseq.trainer | begin training epoch 306
2022-03-05 07:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 07:58:00 | INFO | train_inner | epoch 306:      5 / 97 loss=0.481, ppl=1.4, wps=23804.4, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.849, loss_scale=16, train_wall=244, gb_free=8.2, wall=80497
2022-03-05 08:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:02:08 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 18.285 | ppl 319453 | wps 45058.5 | wpb 510.9 | bsz 1 | num_updates 29492 | best_loss 7.632
2022-03-05 08:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29492 updates
2022-03-05 08:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 306 @ 29492 updates, score 18.285) (writing took 2.7669389098882675 seconds)
2022-03-05 08:02:11 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-05 08:02:11 | INFO | train | epoch 306 | loss 0.481 | ppl 1.4 | wps 24098.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 29492 | lr 0.00018414 | gnorm 0.84 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 80747
2022-03-05 08:02:11 | INFO | fairseq.trainer | begin training epoch 307
2022-03-05 08:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:02:32 | INFO | train_inner | epoch 307:      8 / 97 loss=0.48, ppl=1.4, wps=24121.5, ups=0.37, wpb=65495, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.838, loss_scale=32, train_wall=242, gb_free=8.2, wall=80769
2022-03-05 08:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:06:31 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 18.243 | ppl 310247 | wps 45038.5 | wpb 510.9 | bsz 1 | num_updates 29588 | best_loss 7.632
2022-03-05 08:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29588 updates
2022-03-05 08:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 307 @ 29588 updates, score 18.243) (writing took 2.8340662214905024 seconds)
2022-03-05 08:06:34 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-05 08:06:34 | INFO | train | epoch 307 | loss 0.478 | ppl 1.39 | wps 23839.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29588 | lr 0.000183841 | gnorm 0.84 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 81011
2022-03-05 08:06:34 | INFO | fairseq.trainer | begin training epoch 308
2022-03-05 08:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:07:06 | INFO | train_inner | epoch 308:     12 / 97 loss=0.477, ppl=1.39, wps=23879.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.84, loss_scale=16, train_wall=244, gb_free=8.2, wall=81043
2022-03-05 08:08:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:10:55 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 18.242 | ppl 310021 | wps 44524.8 | wpb 510.9 | bsz 1 | num_updates 29684 | best_loss 7.632
2022-03-05 08:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29684 updates
2022-03-05 08:10:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 308 @ 29684 updates, score 18.242) (writing took 2.8427880937233567 seconds)
2022-03-05 08:10:58 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-05 08:10:58 | INFO | train | epoch 308 | loss 0.479 | ppl 1.39 | wps 23851.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29684 | lr 0.000183543 | gnorm 0.852 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 81275
2022-03-05 08:10:58 | INFO | fairseq.trainer | begin training epoch 309
2022-03-05 08:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:11:40 | INFO | train_inner | epoch 309:     16 / 97 loss=0.479, ppl=1.39, wps=23874.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.85, loss_scale=16, train_wall=244, gb_free=8.2, wall=81317
2022-03-05 08:15:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:15:19 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 18.275 | ppl 317171 | wps 45005.5 | wpb 510.9 | bsz 1 | num_updates 29781 | best_loss 7.632
2022-03-05 08:15:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29781 updates
2022-03-05 08:15:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:15:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 309 @ 29781 updates, score 18.275) (writing took 2.825396440923214 seconds)
2022-03-05 08:15:22 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-05 08:15:22 | INFO | train | epoch 309 | loss 0.477 | ppl 1.39 | wps 24076.9 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 29781 | lr 0.000183244 | gnorm 0.841 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 81539
2022-03-05 08:15:22 | INFO | fairseq.trainer | begin training epoch 310
2022-03-05 08:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:15:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:16:15 | INFO | train_inner | epoch 310:     20 / 97 loss=0.477, ppl=1.39, wps=23882.5, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.843, loss_scale=16, train_wall=244, gb_free=8.2, wall=81591
2022-03-05 08:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:19:42 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 18.178 | ppl 296532 | wps 45124.6 | wpb 510.9 | bsz 1 | num_updates 29877 | best_loss 7.632
2022-03-05 08:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29877 updates
2022-03-05 08:19:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 310 @ 29877 updates, score 18.178) (writing took 2.8520711129531264 seconds)
2022-03-05 08:19:45 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-05 08:19:45 | INFO | train | epoch 310 | loss 0.475 | ppl 1.39 | wps 23855.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29877 | lr 0.00018295 | gnorm 0.838 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 81802
2022-03-05 08:19:45 | INFO | fairseq.trainer | begin training epoch 311
2022-03-05 08:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:20:46 | INFO | train_inner | epoch 311:     23 / 97 loss=0.474, ppl=1.39, wps=24130.6, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.841, loss_scale=16, train_wall=241, gb_free=8.2, wall=81863
2022-03-05 08:23:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:24:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:24:06 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 18.297 | ppl 322080 | wps 45138.7 | wpb 510.9 | bsz 1 | num_updates 29973 | best_loss 7.632
2022-03-05 08:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29973 updates
2022-03-05 08:24:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:24:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:24:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 311 @ 29973 updates, score 18.297) (writing took 2.7737579122185707 seconds)
2022-03-05 08:24:08 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-05 08:24:08 | INFO | train | epoch 311 | loss 0.475 | ppl 1.39 | wps 23881.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 29973 | lr 0.000182656 | gnorm 0.844 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 82065
2022-03-05 08:24:09 | INFO | fairseq.trainer | begin training epoch 312
2022-03-05 08:24:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:25:20 | INFO | train_inner | epoch 312:     27 / 97 loss=0.474, ppl=1.39, wps=23903.9, ups=0.36, wpb=65495, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.839, loss_scale=16, train_wall=244, gb_free=8.2, wall=82137
2022-03-05 08:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:28:29 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 18.326 | ppl 328554 | wps 44948 | wpb 510.9 | bsz 1 | num_updates 30070 | best_loss 7.632
2022-03-05 08:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30070 updates
2022-03-05 08:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:28:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:28:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 312 @ 30070 updates, score 18.326) (writing took 2.8954657344147563 seconds)
2022-03-05 08:28:32 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-05 08:28:32 | INFO | train | epoch 312 | loss 0.474 | ppl 1.39 | wps 24095.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 30070 | lr 0.000182362 | gnorm 0.841 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 82329
2022-03-05 08:28:32 | INFO | fairseq.trainer | begin training epoch 313
2022-03-05 08:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:29:51 | INFO | train_inner | epoch 313:     30 / 97 loss=0.473, ppl=1.39, wps=24132.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.842, loss_scale=32, train_wall=241, gb_free=8.2, wall=82408
2022-03-05 08:30:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:32:53 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 18.327 | ppl 328727 | wps 45272.5 | wpb 510.9 | bsz 1 | num_updates 30166 | best_loss 7.632
2022-03-05 08:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30166 updates
2022-03-05 08:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:32:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:32:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 313 @ 30166 updates, score 18.327) (writing took 3.0540089327841997 seconds)
2022-03-05 08:32:56 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-05 08:32:56 | INFO | train | epoch 313 | loss 0.472 | ppl 1.39 | wps 23856.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 30166 | lr 0.000182071 | gnorm 0.843 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 82593
2022-03-05 08:32:56 | INFO | fairseq.trainer | begin training epoch 314
2022-03-05 08:32:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:34:25 | INFO | train_inner | epoch 314:     34 / 97 loss=0.471, ppl=1.39, wps=23886.1, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.841, loss_scale=16, train_wall=244, gb_free=8.2, wall=82682
2022-03-05 08:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:37:17 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 18.362 | ppl 336834 | wps 45163.7 | wpb 510.9 | bsz 1 | num_updates 30263 | best_loss 7.632
2022-03-05 08:37:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30263 updates
2022-03-05 08:37:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 314 @ 30263 updates, score 18.362) (writing took 3.0306210834532976 seconds)
2022-03-05 08:37:20 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-05 08:37:20 | INFO | train | epoch 314 | loss 0.471 | ppl 1.39 | wps 24072 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 30263 | lr 0.000181779 | gnorm 0.839 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 82856
2022-03-05 08:37:20 | INFO | fairseq.trainer | begin training epoch 315
2022-03-05 08:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:38:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:39:00 | INFO | train_inner | epoch 315:     38 / 97 loss=0.47, ppl=1.39, wps=23861.3, ups=0.36, wpb=65495, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.844, loss_scale=16, train_wall=244, gb_free=8.2, wall=82957
2022-03-05 08:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:41:40 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 18.312 | ppl 325322 | wps 45062.5 | wpb 510.9 | bsz 1 | num_updates 30359 | best_loss 7.632
2022-03-05 08:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30359 updates
2022-03-05 08:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:41:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 315 @ 30359 updates, score 18.312) (writing took 3.13046286534518 seconds)
2022-03-05 08:41:43 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-05 08:41:43 | INFO | train | epoch 315 | loss 0.47 | ppl 1.38 | wps 23825.2 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 30359 | lr 0.000181491 | gnorm 0.845 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 83120
2022-03-05 08:41:43 | INFO | fairseq.trainer | begin training epoch 316
2022-03-05 08:41:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:43:32 | INFO | train_inner | epoch 316:     41 / 97 loss=0.468, ppl=1.38, wps=24100.4, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.839, loss_scale=16, train_wall=241, gb_free=8.2, wall=83229
2022-03-05 08:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:46:04 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 18.386 | ppl 342469 | wps 45140.3 | wpb 510.9 | bsz 1 | num_updates 30456 | best_loss 7.632
2022-03-05 08:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30456 updates
2022-03-05 08:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:46:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:46:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 316 @ 30456 updates, score 18.386) (writing took 2.9935460295528173 seconds)
2022-03-05 08:46:07 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-05 08:46:07 | INFO | train | epoch 316 | loss 0.468 | ppl 1.38 | wps 24079.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 30456 | lr 0.000181202 | gnorm 0.84 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 83384
2022-03-05 08:46:07 | INFO | fairseq.trainer | begin training epoch 317
2022-03-05 08:46:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:46:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:48:06 | INFO | train_inner | epoch 317:     45 / 97 loss=0.469, ppl=1.38, wps=23870.9, ups=0.36, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.845, loss_scale=16, train_wall=244, gb_free=8.2, wall=83503
2022-03-05 08:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:50:28 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 18.298 | ppl 322193 | wps 45032.4 | wpb 510.9 | bsz 1 | num_updates 30552 | best_loss 7.632
2022-03-05 08:50:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30552 updates
2022-03-05 08:50:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:50:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 317 @ 30552 updates, score 18.298) (writing took 2.9133399864658713 seconds)
2022-03-05 08:50:31 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-05 08:50:31 | INFO | train | epoch 317 | loss 0.468 | ppl 1.38 | wps 23856.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 30552 | lr 0.000180917 | gnorm 0.846 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 83648
2022-03-05 08:50:31 | INFO | fairseq.trainer | begin training epoch 318
2022-03-05 08:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:52:38 | INFO | train_inner | epoch 318:     48 / 97 loss=0.467, ppl=1.38, wps=24123.8, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.84, loss_scale=32, train_wall=241, gb_free=8.2, wall=83774
2022-03-05 08:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:54:52 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 18.357 | ppl 335804 | wps 45006.7 | wpb 510.9 | bsz 1 | num_updates 30649 | best_loss 7.632
2022-03-05 08:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30649 updates
2022-03-05 08:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 318 @ 30649 updates, score 18.357) (writing took 3.1459058756008744 seconds)
2022-03-05 08:54:55 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-05 08:54:55 | INFO | train | epoch 318 | loss 0.466 | ppl 1.38 | wps 24074.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 30649 | lr 0.000180631 | gnorm 0.838 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 83912
2022-03-05 08:54:55 | INFO | fairseq.trainer | begin training epoch 319
2022-03-05 08:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 08:56:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 08:57:12 | INFO | train_inner | epoch 319:     52 / 97 loss=0.464, ppl=1.38, wps=23864.3, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.84, loss_scale=16, train_wall=244, gb_free=8.2, wall=84049
2022-03-05 08:59:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 08:59:15 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 18.405 | ppl 347208 | wps 45025.3 | wpb 510.9 | bsz 1 | num_updates 30745 | best_loss 7.632
2022-03-05 08:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30745 updates
2022-03-05 08:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 08:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 319 @ 30745 updates, score 18.405) (writing took 3.0203419663012028 seconds)
2022-03-05 08:59:18 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-05 08:59:18 | INFO | train | epoch 319 | loss 0.464 | ppl 1.38 | wps 23839 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 30745 | lr 0.000180349 | gnorm 0.841 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 84175
2022-03-05 08:59:18 | INFO | fairseq.trainer | begin training epoch 320
2022-03-05 08:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:01:44 | INFO | train_inner | epoch 320:     55 / 97 loss=0.464, ppl=1.38, wps=24109.7, ups=0.37, wpb=65495, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.842, loss_scale=16, train_wall=241, gb_free=8.2, wall=84321
2022-03-05 09:02:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:03:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:03:39 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 18.32 | ppl 327332 | wps 44987.2 | wpb 510.9 | bsz 1 | num_updates 30841 | best_loss 7.632
2022-03-05 09:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30841 updates
2022-03-05 09:03:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:03:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:03:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 320 @ 30841 updates, score 18.32) (writing took 2.9527122788131237 seconds)
2022-03-05 09:03:42 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-05 09:03:42 | INFO | train | epoch 320 | loss 0.464 | ppl 1.38 | wps 23840.1 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 30841 | lr 0.000180068 | gnorm 0.844 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 84439
2022-03-05 09:03:42 | INFO | fairseq.trainer | begin training epoch 321
2022-03-05 09:03:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:06:18 | INFO | train_inner | epoch 321:     59 / 97 loss=0.463, ppl=1.38, wps=23877.8, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.835, loss_scale=16, train_wall=244, gb_free=8.2, wall=84595
2022-03-05 09:07:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:08:03 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 18.327 | ppl 328815 | wps 45003.8 | wpb 510.9 | bsz 1 | num_updates 30938 | best_loss 7.632
2022-03-05 09:08:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30938 updates
2022-03-05 09:08:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:08:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 321 @ 30938 updates, score 18.327) (writing took 3.0434011556208134 seconds)
2022-03-05 09:08:06 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-05 09:08:06 | INFO | train | epoch 321 | loss 0.462 | ppl 1.38 | wps 24067 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 30938 | lr 0.000179785 | gnorm 0.831 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 84703
2022-03-05 09:08:06 | INFO | fairseq.trainer | begin training epoch 322
2022-03-05 09:08:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:10:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:10:52 | INFO | train_inner | epoch 322:     63 / 97 loss=0.463, ppl=1.38, wps=23864.2, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.835, loss_scale=16, train_wall=244, gb_free=8.2, wall=84869
2022-03-05 09:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:12:27 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 18.4 | ppl 345838 | wps 45035.4 | wpb 510.9 | bsz 1 | num_updates 31034 | best_loss 7.632
2022-03-05 09:12:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31034 updates
2022-03-05 09:12:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:12:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:12:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 322 @ 31034 updates, score 18.4) (writing took 2.9527320992201567 seconds)
2022-03-05 09:12:30 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-05 09:12:30 | INFO | train | epoch 322 | loss 0.461 | ppl 1.38 | wps 23842.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 31034 | lr 0.000179507 | gnorm 0.836 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 84967
2022-03-05 09:12:30 | INFO | fairseq.trainer | begin training epoch 323
2022-03-05 09:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:15:24 | INFO | train_inner | epoch 323:     66 / 97 loss=0.461, ppl=1.38, wps=24115.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.839, loss_scale=16, train_wall=241, gb_free=8.2, wall=85141
2022-03-05 09:16:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:16:50 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 18.364 | ppl 337375 | wps 44905.3 | wpb 510.9 | bsz 1 | num_updates 31131 | best_loss 7.632
2022-03-05 09:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31131 updates
2022-03-05 09:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 323 @ 31131 updates, score 18.364) (writing took 2.98750139772892 seconds)
2022-03-05 09:16:53 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-05 09:16:53 | INFO | train | epoch 323 | loss 0.46 | ppl 1.38 | wps 24096.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 31131 | lr 0.000179227 | gnorm 0.836 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 85230
2022-03-05 09:16:53 | INFO | fairseq.trainer | begin training epoch 324
2022-03-05 09:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:19:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:19:58 | INFO | train_inner | epoch 324:     70 / 97 loss=0.46, ppl=1.38, wps=23869.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.837, loss_scale=16, train_wall=244, gb_free=8.2, wall=85415
2022-03-05 09:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:21:14 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 18.411 | ppl 348510 | wps 45102.4 | wpb 510.9 | bsz 1 | num_updates 31227 | best_loss 7.632
2022-03-05 09:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31227 updates
2022-03-05 09:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:21:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:21:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 324 @ 31227 updates, score 18.411) (writing took 3.0405543437227607 seconds)
2022-03-05 09:21:17 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-05 09:21:17 | INFO | train | epoch 324 | loss 0.459 | ppl 1.37 | wps 23821.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 31227 | lr 0.000178951 | gnorm 0.838 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 85494
2022-03-05 09:21:17 | INFO | fairseq.trainer | begin training epoch 325
2022-03-05 09:21:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:24:30 | INFO | train_inner | epoch 325:     73 / 97 loss=0.458, ppl=1.37, wps=24115.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.832, loss_scale=16, train_wall=241, gb_free=8.2, wall=85687
2022-03-05 09:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:25:38 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 18.504 | ppl 371662 | wps 45123.2 | wpb 510.9 | bsz 1 | num_updates 31324 | best_loss 7.632
2022-03-05 09:25:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31324 updates
2022-03-05 09:25:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:25:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 325 @ 31324 updates, score 18.504) (writing took 3.0265465462580323 seconds)
2022-03-05 09:25:41 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-05 09:25:41 | INFO | train | epoch 325 | loss 0.458 | ppl 1.37 | wps 24096.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 31324 | lr 0.000178674 | gnorm 0.835 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 85758
2022-03-05 09:25:41 | INFO | fairseq.trainer | begin training epoch 326
2022-03-05 09:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:28:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:29:04 | INFO | train_inner | epoch 326:     77 / 97 loss=0.456, ppl=1.37, wps=23858.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=31400, lr=0.000178458, gnorm=0.836, loss_scale=16, train_wall=244, gb_free=8.2, wall=85961
2022-03-05 09:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:30:02 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 18.458 | ppl 360122 | wps 45074.8 | wpb 510.9 | bsz 1 | num_updates 31420 | best_loss 7.632
2022-03-05 09:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31420 updates
2022-03-05 09:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 326 @ 31420 updates, score 18.458) (writing took 3.096897524781525 seconds)
2022-03-05 09:30:05 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-05 09:30:05 | INFO | train | epoch 326 | loss 0.455 | ppl 1.37 | wps 23813.6 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 31420 | lr 0.000178401 | gnorm 0.833 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 86022
2022-03-05 09:30:05 | INFO | fairseq.trainer | begin training epoch 327
2022-03-05 09:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:33:36 | INFO | train_inner | epoch 327:     80 / 97 loss=0.457, ppl=1.37, wps=24097.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.835, loss_scale=16, train_wall=241, gb_free=8.2, wall=86233
2022-03-05 09:34:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:34:26 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 18.38 | ppl 341179 | wps 45089.5 | wpb 510.9 | bsz 1 | num_updates 31516 | best_loss 7.632
2022-03-05 09:34:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31516 updates
2022-03-05 09:34:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:34:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:34:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 327 @ 31516 updates, score 18.38) (writing took 3.074196457862854 seconds)
2022-03-05 09:34:29 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-05 09:34:29 | INFO | train | epoch 327 | loss 0.456 | ppl 1.37 | wps 23832.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 31516 | lr 0.000178129 | gnorm 0.836 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 86286
2022-03-05 09:34:29 | INFO | fairseq.trainer | begin training epoch 328
2022-03-05 09:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:38:11 | INFO | train_inner | epoch 328:     84 / 97 loss=0.455, ppl=1.37, wps=23867.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.834, loss_scale=16, train_wall=244, gb_free=8.2, wall=86507
2022-03-05 09:38:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:38:50 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 18.436 | ppl 354701 | wps 45002.7 | wpb 510.9 | bsz 1 | num_updates 31613 | best_loss 7.632
2022-03-05 09:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31613 updates
2022-03-05 09:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:38:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:38:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 328 @ 31613 updates, score 18.436) (writing took 3.044743448495865 seconds)
2022-03-05 09:38:53 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-05 09:38:53 | INFO | train | epoch 328 | loss 0.455 | ppl 1.37 | wps 24068.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 31613 | lr 0.000177855 | gnorm 0.831 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 86550
2022-03-05 09:38:53 | INFO | fairseq.trainer | begin training epoch 329
2022-03-05 09:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:42:45 | INFO | train_inner | epoch 329:     88 / 97 loss=0.454, ppl=1.37, wps=23872.9, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=31700, lr=0.000177611, gnorm=0.833, loss_scale=16, train_wall=244, gb_free=8.2, wall=86782
2022-03-05 09:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:43:13 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 18.449 | ppl 357769 | wps 45067.6 | wpb 510.9 | bsz 1 | num_updates 31709 | best_loss 7.632
2022-03-05 09:43:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31709 updates
2022-03-05 09:43:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:43:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 329 @ 31709 updates, score 18.449) (writing took 2.3494002763181925 seconds)
2022-03-05 09:43:16 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-05 09:43:16 | INFO | train | epoch 329 | loss 0.453 | ppl 1.37 | wps 23908.3 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 31709 | lr 0.000177586 | gnorm 0.832 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 86813
2022-03-05 09:43:16 | INFO | fairseq.trainer | begin training epoch 330
2022-03-05 09:43:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:46:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:47:18 | INFO | train_inner | epoch 330:     92 / 97 loss=0.452, ppl=1.37, wps=23950, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.832, loss_scale=16, train_wall=244, gb_free=8.2, wall=87055
2022-03-05 09:47:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:47:36 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 18.428 | ppl 352649 | wps 45012.2 | wpb 510.9 | bsz 1 | num_updates 31805 | best_loss 7.632
2022-03-05 09:47:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31805 updates
2022-03-05 09:47:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 330 @ 31805 updates, score 18.428) (writing took 2.3180985720828176 seconds)
2022-03-05 09:47:39 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-05 09:47:39 | INFO | train | epoch 330 | loss 0.452 | ppl 1.37 | wps 23914.7 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 31805 | lr 0.000177318 | gnorm 0.831 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 87075
2022-03-05 09:47:39 | INFO | fairseq.trainer | begin training epoch 331
2022-03-05 09:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:51:49 | INFO | train_inner | epoch 331:     95 / 97 loss=0.451, ppl=1.37, wps=24167.1, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.831, loss_scale=16, train_wall=241, gb_free=8.2, wall=87326
2022-03-05 09:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:51:59 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 18.516 | ppl 374957 | wps 45069.4 | wpb 510.9 | bsz 1 | num_updates 31902 | best_loss 7.632
2022-03-05 09:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31902 updates
2022-03-05 09:51:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:52:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:52:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 331 @ 31902 updates, score 18.516) (writing took 2.325303609482944 seconds)
2022-03-05 09:52:02 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-05 09:52:02 | INFO | train | epoch 331 | loss 0.451 | ppl 1.37 | wps 24147 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 31902 | lr 0.000177048 | gnorm 0.83 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 87339
2022-03-05 09:52:02 | INFO | fairseq.trainer | begin training epoch 332
2022-03-05 09:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:53:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 09:56:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 09:56:22 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 18.524 | ppl 376902 | wps 44862.3 | wpb 510.9 | bsz 1 | num_updates 31998 | best_loss 7.632
2022-03-05 09:56:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31998 updates
2022-03-05 09:56:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 09:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 332 @ 31998 updates, score 18.524) (writing took 2.4869342809543014 seconds)
2022-03-05 09:56:25 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-05 09:56:25 | INFO | train | epoch 332 | loss 0.45 | ppl 1.37 | wps 23886.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 31998 | lr 0.000176782 | gnorm 0.836 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 87602
2022-03-05 09:56:25 | INFO | fairseq.trainer | begin training epoch 333
2022-03-05 09:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 09:56:30 | INFO | train_inner | epoch 333:      2 / 97 loss=0.45, ppl=1.37, wps=23302.3, ups=0.36, wpb=65451.9, bsz=127.8, num_updates=32000, lr=0.000176777, gnorm=0.835, loss_scale=16, train_wall=244, gb_free=8.2, wall=87607
2022-03-05 10:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:00:46 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 18.497 | ppl 370030 | wps 45088 | wpb 510.9 | bsz 1 | num_updates 32095 | best_loss 7.632
2022-03-05 10:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32095 updates
2022-03-05 10:00:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 333 @ 32095 updates, score 18.497) (writing took 2.3015431659296155 seconds)
2022-03-05 10:00:48 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-05 10:00:48 | INFO | train | epoch 333 | loss 0.448 | ppl 1.36 | wps 24164.6 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 32095 | lr 0.000176515 | gnorm 0.825 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 87865
2022-03-05 10:00:48 | INFO | fairseq.trainer | begin training epoch 334
2022-03-05 10:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:01:01 | INFO | train_inner | epoch 334:      5 / 97 loss=0.447, ppl=1.36, wps=24183.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.826, loss_scale=32, train_wall=241, gb_free=8.2, wall=87878
2022-03-05 10:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:05:08 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 18.473 | ppl 363816 | wps 45087.8 | wpb 510.9 | bsz 1 | num_updates 32191 | best_loss 7.632
2022-03-05 10:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32191 updates
2022-03-05 10:05:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:05:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:05:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 334 @ 32191 updates, score 18.473) (writing took 2.3120303321629763 seconds)
2022-03-05 10:05:11 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-05 10:05:11 | INFO | train | epoch 334 | loss 0.448 | ppl 1.36 | wps 23915.5 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 32191 | lr 0.000176251 | gnorm 0.828 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 88128
2022-03-05 10:05:11 | INFO | fairseq.trainer | begin training epoch 335
2022-03-05 10:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:05:35 | INFO | train_inner | epoch 335:      9 / 97 loss=0.447, ppl=1.36, wps=23953.3, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.827, loss_scale=16, train_wall=244, gb_free=8.2, wall=88151
2022-03-05 10:08:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:09:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:09:31 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 18.559 | ppl 386336 | wps 45158.8 | wpb 510.9 | bsz 1 | num_updates 32287 | best_loss 7.632
2022-03-05 10:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32287 updates
2022-03-05 10:09:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 335 @ 32287 updates, score 18.559) (writing took 2.155685268342495 seconds)
2022-03-05 10:09:33 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-05 10:09:33 | INFO | train | epoch 335 | loss 0.446 | ppl 1.36 | wps 23946.9 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 32287 | lr 0.000175989 | gnorm 0.825 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 88390
2022-03-05 10:09:33 | INFO | fairseq.trainer | begin training epoch 336
2022-03-05 10:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:10:08 | INFO | train_inner | epoch 336:     13 / 97 loss=0.445, ppl=1.36, wps=23976.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.825, loss_scale=16, train_wall=244, gb_free=8.2, wall=88425
2022-03-05 10:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:13:54 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 18.675 | ppl 418502 | wps 45083.4 | wpb 510.9 | bsz 1 | num_updates 32384 | best_loss 7.632
2022-03-05 10:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32384 updates
2022-03-05 10:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 336 @ 32384 updates, score 18.675) (writing took 2.111388542689383 seconds)
2022-03-05 10:13:56 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-05 10:13:56 | INFO | train | epoch 336 | loss 0.446 | ppl 1.36 | wps 24183.3 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 32384 | lr 0.000175725 | gnorm 0.823 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 88653
2022-03-05 10:13:56 | INFO | fairseq.trainer | begin training epoch 337
2022-03-05 10:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:14:38 | INFO | train_inner | epoch 337:     16 / 97 loss=0.445, ppl=1.36, wps=24209.4, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.822, loss_scale=32, train_wall=241, gb_free=8.2, wall=88695
2022-03-05 10:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:18:17 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 18.576 | ppl 390914 | wps 45069.3 | wpb 510.9 | bsz 1 | num_updates 32481 | best_loss 7.632
2022-03-05 10:18:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32481 updates
2022-03-05 10:18:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:18:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 337 @ 32481 updates, score 18.576) (writing took 2.2787282411009073 seconds)
2022-03-05 10:18:19 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-05 10:18:19 | INFO | train | epoch 337 | loss 0.444 | ppl 1.36 | wps 24160.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 32481 | lr 0.000175463 | gnorm 0.82 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 88916
2022-03-05 10:18:19 | INFO | fairseq.trainer | begin training epoch 338
2022-03-05 10:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:18:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:19:12 | INFO | train_inner | epoch 338:     20 / 97 loss=0.443, ppl=1.36, wps=23940.7, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.818, loss_scale=16, train_wall=244, gb_free=8.2, wall=88969
2022-03-05 10:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:22:40 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 18.483 | ppl 366315 | wps 44968.6 | wpb 510.9 | bsz 1 | num_updates 32577 | best_loss 7.632
2022-03-05 10:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32577 updates
2022-03-05 10:22:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 338 @ 32577 updates, score 18.483) (writing took 2.2075584018602967 seconds)
2022-03-05 10:22:42 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-05 10:22:42 | INFO | train | epoch 338 | loss 0.443 | ppl 1.36 | wps 23884.8 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 32577 | lr 0.000175204 | gnorm 0.825 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 89179
2022-03-05 10:22:42 | INFO | fairseq.trainer | begin training epoch 339
2022-03-05 10:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:23:43 | INFO | train_inner | epoch 339:     23 / 97 loss=0.443, ppl=1.36, wps=24154.3, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.823, loss_scale=16, train_wall=242, gb_free=8.2, wall=89240
2022-03-05 10:25:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:27:03 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 18.538 | ppl 380696 | wps 45101.1 | wpb 510.9 | bsz 1 | num_updates 32673 | best_loss 7.632
2022-03-05 10:27:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32673 updates
2022-03-05 10:27:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:27:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 339 @ 32673 updates, score 18.538) (writing took 2.1004746053367853 seconds)
2022-03-05 10:27:05 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-05 10:27:05 | INFO | train | epoch 339 | loss 0.442 | ppl 1.36 | wps 23917 | ups 0.37 | wpb 65491.1 | bsz 127.9 | num_updates 32673 | lr 0.000174947 | gnorm 0.82 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 89442
2022-03-05 10:27:05 | INFO | fairseq.trainer | begin training epoch 340
2022-03-05 10:27:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:28:16 | INFO | train_inner | epoch 340:     27 / 97 loss=0.441, ppl=1.36, wps=23954.2, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.822, loss_scale=16, train_wall=244, gb_free=8.2, wall=89513
2022-03-05 10:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:31:26 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 18.49 | ppl 368256 | wps 45093.4 | wpb 510.9 | bsz 1 | num_updates 32770 | best_loss 7.632
2022-03-05 10:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32770 updates
2022-03-05 10:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:31:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 340 @ 32770 updates, score 18.49) (writing took 2.1857771184295416 seconds)
2022-03-05 10:31:28 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-05 10:31:28 | INFO | train | epoch 340 | loss 0.441 | ppl 1.36 | wps 24147.4 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 32770 | lr 0.000174687 | gnorm 0.824 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 89705
2022-03-05 10:31:28 | INFO | fairseq.trainer | begin training epoch 341
2022-03-05 10:31:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:32:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:32:50 | INFO | train_inner | epoch 341:     31 / 97 loss=0.442, ppl=1.36, wps=23937.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.823, loss_scale=16, train_wall=244, gb_free=8.2, wall=89787
2022-03-05 10:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:35:49 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 18.584 | ppl 392989 | wps 45041.3 | wpb 510.9 | bsz 1 | num_updates 32866 | best_loss 7.632
2022-03-05 10:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32866 updates
2022-03-05 10:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 341 @ 32866 updates, score 18.584) (writing took 2.5384884625673294 seconds)
2022-03-05 10:35:51 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-05 10:35:51 | INFO | train | epoch 341 | loss 0.44 | ppl 1.36 | wps 23875.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 32866 | lr 0.000174432 | gnorm 0.818 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 89968
2022-03-05 10:35:51 | INFO | fairseq.trainer | begin training epoch 342
2022-03-05 10:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:37:21 | INFO | train_inner | epoch 342:     34 / 97 loss=0.439, ppl=1.36, wps=24145.1, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.818, loss_scale=16, train_wall=241, gb_free=8.2, wall=90058
2022-03-05 10:38:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:40:12 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 18.582 | ppl 392502 | wps 45079.1 | wpb 510.9 | bsz 1 | num_updates 32962 | best_loss 7.632
2022-03-05 10:40:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32962 updates
2022-03-05 10:40:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 342 @ 32962 updates, score 18.582) (writing took 2.3715740917250514 seconds)
2022-03-05 10:40:15 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-05 10:40:15 | INFO | train | epoch 342 | loss 0.439 | ppl 1.36 | wps 23882.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 32962 | lr 0.000174178 | gnorm 0.819 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 90232
2022-03-05 10:40:15 | INFO | fairseq.trainer | begin training epoch 343
2022-03-05 10:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:41:55 | INFO | train_inner | epoch 343:     38 / 97 loss=0.438, ppl=1.36, wps=23896.6, ups=0.36, wpb=65492.9, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.816, loss_scale=16, train_wall=244, gb_free=8.2, wall=90332
2022-03-05 10:44:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:44:36 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 18.554 | ppl 384932 | wps 45161.3 | wpb 510.9 | bsz 1 | num_updates 33059 | best_loss 7.632
2022-03-05 10:44:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33059 updates
2022-03-05 10:44:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:44:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:44:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 343 @ 33059 updates, score 18.554) (writing took 2.2092164158821106 seconds)
2022-03-05 10:44:38 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-05 10:44:38 | INFO | train | epoch 343 | loss 0.439 | ppl 1.36 | wps 24142.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 33059 | lr 0.000173922 | gnorm 0.821 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 90495
2022-03-05 10:44:38 | INFO | fairseq.trainer | begin training epoch 344
2022-03-05 10:44:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:45:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:46:29 | INFO | train_inner | epoch 344:     42 / 97 loss=0.439, ppl=1.36, wps=23953.8, ups=0.37, wpb=65495, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.827, loss_scale=16, train_wall=244, gb_free=8.2, wall=90606
2022-03-05 10:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:48:59 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 18.566 | ppl 388108 | wps 45038 | wpb 510.9 | bsz 1 | num_updates 33155 | best_loss 7.632
2022-03-05 10:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33155 updates
2022-03-05 10:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:49:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:49:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 344 @ 33155 updates, score 18.566) (writing took 2.4650533171370625 seconds)
2022-03-05 10:49:01 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-05 10:49:01 | INFO | train | epoch 344 | loss 0.438 | ppl 1.35 | wps 23885.3 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 33155 | lr 0.00017367 | gnorm 0.829 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 90758
2022-03-05 10:49:01 | INFO | fairseq.trainer | begin training epoch 345
2022-03-05 10:49:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:51:00 | INFO | train_inner | epoch 345:     45 / 97 loss=0.436, ppl=1.35, wps=24152.3, ups=0.37, wpb=65490.8, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.818, loss_scale=16, train_wall=241, gb_free=8.2, wall=90877
2022-03-05 10:51:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 10:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:53:22 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 18.588 | ppl 393924 | wps 45017.5 | wpb 510.9 | bsz 1 | num_updates 33251 | best_loss 7.632
2022-03-05 10:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33251 updates
2022-03-05 10:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 345 @ 33251 updates, score 18.588) (writing took 2.4061470767483115 seconds)
2022-03-05 10:53:24 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-05 10:53:24 | INFO | train | epoch 345 | loss 0.435 | ppl 1.35 | wps 23891.9 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 33251 | lr 0.000173419 | gnorm 0.812 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 91021
2022-03-05 10:53:24 | INFO | fairseq.trainer | begin training epoch 346
2022-03-05 10:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 10:55:33 | INFO | train_inner | epoch 346:     49 / 97 loss=0.436, ppl=1.35, wps=23936.2, ups=0.37, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.817, loss_scale=16, train_wall=244, gb_free=8.2, wall=91150
2022-03-05 10:57:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 10:57:45 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 18.645 | ppl 409944 | wps 44647.2 | wpb 510.9 | bsz 1 | num_updates 33348 | best_loss 7.632
2022-03-05 10:57:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33348 updates
2022-03-05 10:57:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 10:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 346 @ 33348 updates, score 18.645) (writing took 2.5874557476490736 seconds)
2022-03-05 10:57:47 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-05 10:57:47 | INFO | train | epoch 346 | loss 0.435 | ppl 1.35 | wps 24141.8 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 33348 | lr 0.000173167 | gnorm 0.817 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 91284
2022-03-05 10:57:47 | INFO | fairseq.trainer | begin training epoch 347
2022-03-05 10:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:00:05 | INFO | train_inner | epoch 347:     52 / 97 loss=0.435, ppl=1.35, wps=24161.5, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.813, loss_scale=32, train_wall=241, gb_free=8.2, wall=91421
2022-03-05 11:00:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 11:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:02:08 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 18.569 | ppl 388815 | wps 44998.9 | wpb 510.9 | bsz 1 | num_updates 33444 | best_loss 7.632
2022-03-05 11:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33444 updates
2022-03-05 11:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 347 @ 33444 updates, score 18.569) (writing took 2.61331042367965 seconds)
2022-03-05 11:02:10 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-05 11:02:10 | INFO | train | epoch 347 | loss 0.435 | ppl 1.35 | wps 23888.5 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 33444 | lr 0.000172918 | gnorm 0.815 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 91547
2022-03-05 11:02:11 | INFO | fairseq.trainer | begin training epoch 348
2022-03-05 11:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:04:38 | INFO | train_inner | epoch 348:     56 / 97 loss=0.434, ppl=1.35, wps=23907.6, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.817, loss_scale=16, train_wall=244, gb_free=8.2, wall=91695
2022-03-05 11:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:06:31 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 18.771 | ppl 447444 | wps 44953.6 | wpb 510.9 | bsz 1 | num_updates 33541 | best_loss 7.632
2022-03-05 11:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33541 updates
2022-03-05 11:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 348 @ 33541 updates, score 18.771) (writing took 2.467853126116097 seconds)
2022-03-05 11:06:34 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-05 11:06:34 | INFO | train | epoch 348 | loss 0.433 | ppl 1.35 | wps 24127.2 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 33541 | lr 0.000172668 | gnorm 0.818 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 91811
2022-03-05 11:06:34 | INFO | fairseq.trainer | begin training epoch 349
2022-03-05 11:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:09:10 | INFO | train_inner | epoch 349:     59 / 97 loss=0.432, ppl=1.35, wps=24152.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.82, loss_scale=32, train_wall=241, gb_free=8.2, wall=91966
2022-03-05 11:09:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 11:10:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:10:55 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 18.705 | ppl 427480 | wps 45053.3 | wpb 510.9 | bsz 1 | num_updates 33637 | best_loss 7.632
2022-03-05 11:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33637 updates
2022-03-05 11:10:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 349 @ 33637 updates, score 18.705) (writing took 2.592848151922226 seconds)
2022-03-05 11:10:57 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-05 11:10:57 | INFO | train | epoch 349 | loss 0.432 | ppl 1.35 | wps 23860 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 33637 | lr 0.000172421 | gnorm 0.819 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 92074
2022-03-05 11:10:57 | INFO | fairseq.trainer | begin training epoch 350
2022-03-05 11:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:13:44 | INFO | train_inner | epoch 350:     63 / 97 loss=0.431, ppl=1.35, wps=23901.2, ups=0.36, wpb=65490.8, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.817, loss_scale=16, train_wall=244, gb_free=8.2, wall=92240
2022-03-05 11:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:15:18 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 18.563 | ppl 387232 | wps 45189.5 | wpb 510.9 | bsz 1 | num_updates 33734 | best_loss 7.632
2022-03-05 11:15:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33734 updates
2022-03-05 11:15:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 350 @ 33734 updates, score 18.563) (writing took 2.585685646161437 seconds)
2022-03-05 11:15:21 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-05 11:15:21 | INFO | train | epoch 350 | loss 0.431 | ppl 1.35 | wps 24124.7 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 33734 | lr 0.000172173 | gnorm 0.814 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 92337
2022-03-05 11:15:21 | INFO | fairseq.trainer | begin training epoch 351
2022-03-05 11:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:16:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 11:18:17 | INFO | train_inner | epoch 351:     67 / 97 loss=0.43, ppl=1.35, wps=23918.8, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.814, loss_scale=16, train_wall=244, gb_free=8.2, wall=92514
2022-03-05 11:19:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:19:41 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 18.673 | ppl 417923 | wps 45059.9 | wpb 510.9 | bsz 1 | num_updates 33830 | best_loss 7.632
2022-03-05 11:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33830 updates
2022-03-05 11:19:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:19:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 351 @ 33830 updates, score 18.673) (writing took 2.5613363618031144 seconds)
2022-03-05 11:19:44 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-05 11:19:44 | INFO | train | epoch 351 | loss 0.429 | ppl 1.35 | wps 23889 | ups 0.36 | wpb 65491.1 | bsz 127.9 | num_updates 33830 | lr 0.000171929 | gnorm 0.814 | loss_scale 16 | train_wall 234 | gb_free 8.2 | wall 92601
2022-03-05 11:19:44 | INFO | fairseq.trainer | begin training epoch 352
2022-03-05 11:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 11:22:49 | INFO | train_inner | epoch 352:     70 / 97 loss=0.43, ppl=1.35, wps=24158, ups=0.37, wpb=65492.9, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.814, loss_scale=32, train_wall=241, gb_free=8.2, wall=92785
2022-03-05 11:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 11:24:05 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 18.58 | ppl 391930 | wps 44996.9 | wpb 510.9 | bsz 1 | num_updates 33927 | best_loss 7.632
2022-03-05 11:24:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33927 updates
2022-03-05 11:24:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:24:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt
2022-03-05 11:24:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-cross_entropy_#4/checkpoint_last.pt (epoch 352 @ 33927 updates, score 18.58) (writing took 2.6689017778262496 seconds)
2022-03-05 11:24:07 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-05 11:24:07 | INFO | train | epoch 352 | loss 0.429 | ppl 1.35 | wps 24110.1 | ups 0.37 | wpb 65491.6 | bsz 127.9 | num_updates 33927 | lr 0.000171683 | gnorm 0.815 | loss_scale 32 | train_wall 234 | gb_free 8.2 | wall 92864
2022-03-05 11:24:07 | INFO | fairseq.trainer | begin training epoch 353
2022-03-05 11:24:07 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/cross_entropy.py", line 35, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 328, in extract_features_scriptable
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt
