Sender: LSF System <lsfadmin@eu-g3-060>
Subject: Job 210581454: <iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:24:45 2022
Job was executed on host(s) <eu-g3-060>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:24:53 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:24:53 2022
Terminated at Wed Mar 23 10:33:47 2022
Results reported at Wed Mar 23 10:33:47 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.25 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4108.87 sec.
    Max Memory :                                 5433 MB
    Average Memory :                             4240.66 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14567.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4134 sec.
    Turnaround time :                            4142 sec.

The output (if any) follows:

2022-03-23 09:25:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.25, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.25, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:25:09 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:25:09 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:25:09 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:25:09 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:25:09 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:25:09 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:25:09 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:25:09 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:25:09 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:25:18 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:25:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:18 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:25:18 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:18 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:25:18 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:25:18 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 09:25:18 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 09:25:18 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:25:18 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:25:18 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:25:18 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:25:18 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:25:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:25:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:25:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:25:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:25:56 | INFO | train_inner | epoch 001:    104 / 157 loss=12.261, nll_loss=11.858, ppl=3711.81, wps=78360, ups=3.12, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=2.792, loss_scale=8, train_wall=37, gb_free=13.6, wall=38
2022-03-23 09:26:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:15 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:26:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:26:18 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 09:26:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:26:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:26:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:26:25 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 09:26:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:26:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:26:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.921 | nll_loss 10.065 | ppl 1070.86 | bleu 0.01 | wps 4097.6 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:26:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6105318420013646 seconds)
2022-03-23 09:26:57 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:26:57 | INFO | train | epoch 001 | loss 11.927 | nll_loss 11.413 | ppl 2727.16 | wps 41217.3 | ups 1.64 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.151 | loss_scale 8 | train_wall 53 | gb_free 13.9 | wall 99
2022-03-23 09:26:57 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:12 | INFO | train_inner | epoch 002:     47 / 157 loss=11.108, nll_loss=10.325, ppl=1282.99, wps=32929.1, ups=1.32, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=0.965, loss_scale=8, train_wall=30, gb_free=22.4, wall=114
2022-03-23 09:27:43 | INFO | train_inner | epoch 002:    147 / 157 loss=10.501, nll_loss=9.465, ppl=706.7, wps=80297.9, ups=3.21, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.062, loss_scale=8, train_wall=31, gb_free=13.9, wall=145
2022-03-23 09:27:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:49 | INFO | fairseq.tasks.translation | example hypothesis: you you.
2022-03-23 09:27:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the.
2022-03-23 09:27:53 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:27:56 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i.
2022-03-23 09:27:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example hypothesis: so,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 09:28:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:28:14 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:28 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:30 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:30 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.224 | nll_loss 8.968 | ppl 500.78 | bleu 0.02 | wps 4021.3 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 09:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:28:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:28:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7426936109986855 seconds)
2022-03-23 09:28:32 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:28:32 | INFO | train | epoch 002 | loss 10.606 | nll_loss 9.617 | ppl 785.03 | wps 41571.5 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.034 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 194
2022-03-23 09:28:32 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:00 | INFO | train_inner | epoch 003:     90 / 157 loss=10.282, nll_loss=9.108, ppl=551.79, wps=32250.6, ups=1.29, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.024, loss_scale=8, train_wall=31, gb_free=13.9, wall=222
2022-03-23 09:29:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:29:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:25 | INFO | fairseq.tasks.translation | example hypothesis: it's's.
2022-03-23 09:29:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:29:29 | INFO | fairseq.tasks.translation | example hypothesis: he he he.
2022-03-23 09:29:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example hypothesis: and i i to to a a a a a a a.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example hypothesis: and he was was, he was was was was was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we we we, we, we, we we, we we, we, we, we we, we, we, we, we, we we we, we, we, we, we
2022-03-23 09:29:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:29:48 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, and we we to we to we to we to we we to to to to to to to we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:29:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:29:54 | INFO | fairseq.tasks.translation | example hypothesis: and but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but the, but but but the, but the, but the, but the, but the, but the, but the, but the, but the, but but but the, but but but but
2022-03-23 09:29:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we we, we, we, we, we we we, we, we, we, and we we, we, we, we, and we we, we, we, we, we, and we, and we, we, we, and we the, and we we we we we we we we we we we we the the the, and we the, and we, we, and we we we we
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:08 | INFO | fairseq.tasks.translation | example hypothesis: and and and we, and the, "" the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:30:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:10 | INFO | fairseq.tasks.translation | example hypothesis: and we, the, and the, the, the, and the, we we the, and the, the, and the, we the, and the, and the, and the, and the, we we we the, the, the, we we we we we, and the, the, and the, we we the, the, we we we we we the, and the, and the, and the, and the, we we we the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, we we we we we we we, the, the, and the, the, and the, we we we we we we we we we we the, the, the, we the, and the, the, and the, and the, we we we we we we we we we the, and the, the, and the, the, the, we, we, we, we
2022-03-23 09:30:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.031 | nll_loss 8.646 | ppl 400.6 | bleu 0.15 | wps 3608.8 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.15
2022-03-23 09:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.15) (writing took 1.6936123909981688 seconds)
2022-03-23 09:30:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:30:12 | INFO | train | epoch 003 | loss 10.207 | nll_loss 8.998 | ppl 511.26 | wps 39184.2 | ups 1.56 | wpb 25122.4 | bsz 1014.9 | num_updates 466 | lr 5.825e-05 | gnorm 1.066 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 294
2022-03-23 09:30:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:23 | INFO | train_inner | epoch 004:     34 / 157 loss=10.098, nll_loss=8.841, ppl=458.67, wps=30862.9, ups=1.21, wpb=25511.1, bsz=1058.2, num_updates=500, lr=6.25e-05, gnorm=1.069, loss_scale=4, train_wall=31, gb_free=14.7, wall=305
2022-03-23 09:30:54 | INFO | train_inner | epoch 004:    134 / 157 loss=9.861, nll_loss=8.505, ppl=363.23, wps=80571.9, ups=3.19, wpb=25228.8, bsz=1092.2, num_updates=600, lr=7.5e-05, gnorm=1.265, loss_scale=4, train_wall=31, gb_free=14, wall=336
2022-03-23 09:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can can can can can can can can.
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:31:10 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was the world of the world of the world of he can can can can can can can can can he he he he he.
2022-03-23 09:31:10 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example hypothesis: so i think to be a lot of this is a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot of a lot
2022-03-23 09:31:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example hypothesis: and he was was he was he was he was he was was was was was he was was was was was was was was he was he was was was was was was was he was he was was was a
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we know, and we know, what we know, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see a
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:31:33 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't or or or or or or.
2022-03-23 09:31:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:31:39 | INFO | fairseq.tasks.translation | example hypothesis: but if you're that's the world, but but you have the world, but but they have the world, but but but but they are the world, but but but they're're not not not not not not not not not not not not not not not not not not not not not not not the world, but but but but but they're the
2022-03-23 09:31:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:45 | INFO | fairseq.tasks.translation | example hypothesis: and we can have the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the the world
2022-03-23 09:31:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example hypothesis: and it's the first, and we've've've've've've've've've've've've've've've've've've've've've to to to to be to be to be to be to be to be to be to to be to be to be to be to be to be to be to be, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be
2022-03-23 09:31:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:55 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can see that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:31:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:55 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.658 | nll_loss 8.136 | ppl 281.39 | bleu 0.79 | wps 3303.9 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.79
2022-03-23 09:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:31:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.79) (writing took 1.6849090229952708 seconds)
2022-03-23 09:31:57 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:31:57 | INFO | train | epoch 004 | loss 9.908 | nll_loss 8.572 | ppl 380.63 | wps 37727.1 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.187 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 399
2022-03-23 09:31:57 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:21 | INFO | train_inner | epoch 005:     77 / 157 loss=9.672, nll_loss=8.231, ppl=300.53, wps=29000, ups=1.16, wpb=25101.8, bsz=1058.5, num_updates=700, lr=8.75e-05, gnorm=1.392, loss_scale=4, train_wall=30, gb_free=14, wall=423
2022-03-23 09:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not be a lot.
2022-03-23 09:32:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:54 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of the time.
2022-03-23 09:32:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:32:59 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to be a lot of a lot of a lot of a lot of the world.
2022-03-23 09:32:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example hypothesis: he was me, he was he was me, he was me, he was he was me, he was he was he was he was me, he was he was he was he was me.
2022-03-23 09:33:04 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of what we have a lot of what we have to do, and what we have a lot of what we have a lot of what we have a lot of what we have to do, and what we have
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example hypothesis: and we need to do or or or or or or or we have to do, or or we have to do we have to do we have to do or or or or or or or or or or or or or or or or or or or or or or or or or or we have
2022-03-23 09:33:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example hypothesis: but they're not not not not not not the world, but but they're not not not not not not not the world, but but they are not not not not the world, but but they are not not not not not not the world, but but they are the world.
2022-03-23 09:33:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:27 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and we can see the world, and we can see the world of the world, and we can see the world, and
2022-03-23 09:33:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "i said," "" "" "we said," "we said," we said, "" we said, "" "" "" "" we said, "" we said, "i said," "" "" "we said," "i said," "" "" "" "" "" "" "" "" "" "" "" "" "we said," we said, "we said," i said, "i said," i said, "i said," i said, "i said," i said, "i said," we said, "i said," we said, "i said," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:37 | INFO | fairseq.tasks.translation | example hypothesis: so, the world, we have to have the world of the world, the world, and the world, and the world, and the world, that we have to be the world of the world, the world, the world, the world, the world, the world, the world, that we have the world of the world, the world, the world, that we've've've've've've have to have to have to have to be the world of the world of the world of the world of the world of the world, and the world, and the world, and the world, and the world, and the world of the world, the world, and the world, the world, the world, the world, and the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 09:33:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.35 | nll_loss 7.676 | ppl 204.46 | bleu 1.26 | wps 3483.3 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.26
2022-03-23 09:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.26) (writing took 1.6822389629960526 seconds)
2022-03-23 09:33:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:33:39 | INFO | train | epoch 005 | loss 9.604 | nll_loss 8.132 | ppl 280.45 | wps 38656.6 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.259 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 501
2022-03-23 09:33:39 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:45 | INFO | train_inner | epoch 006:     20 / 157 loss=9.564, nll_loss=8.072, ppl=269.04, wps=29694.1, ups=1.18, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.231, loss_scale=4, train_wall=31, gb_free=14, wall=507
2022-03-23 09:34:17 | INFO | train_inner | epoch 006:    120 / 157 loss=9.409, nll_loss=7.842, ppl=229.52, wps=80169.2, ups=3.2, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.097, loss_scale=4, train_wall=31, gb_free=14, wall=539
2022-03-23 09:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example hypothesis: it can't be the world.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:34:36 | INFO | fairseq.tasks.translation | example hypothesis: he can be in the world.
2022-03-23 09:34:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example hypothesis: now, i can can be a lot of the way that i can can be a lot of the world.
2022-03-23 09:34:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been to his
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have a lot of what we have to do
2022-03-23 09:34:52 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do the world, or we're going to do the world, or our world, or we're going to do the world, and we're going to do our own own own own own own own own own own or our world.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:35:03 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of the way, you're going to get the way, and they're going to be the way, and they're going to be the way, and they're going to be the way, and they're going to be, and they're going to be the way, and they're going to be the way
2022-03-23 09:35:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see the world, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world
2022-03-23 09:35:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:17 | INFO | fairseq.tasks.translation | example hypothesis: so, "we said," "" "" "we said," "it's going to say," "we're going to say," "" we're going to say, "it's going to say," "" it's going to say, "" "" "we're going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it," it's going to say, "" it's going to say, "it," "it's going to say," it's going to say, "it's going to say," it's going to say, "" "" "" "" "" "" "" "" we're going to say, "" "" "" "" ""
2022-03-23 09:35:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to do that we're going to be a lot of the world, which is that we're going to do that we're going to be a lot of the world, which is that we're going to make the world, which we're going to make the world, which we're going to make the world, which we're going to make the world, which we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to do that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, which is that we're going to make the world, and we're going to make the world, the world, which is that we're going to make the world,
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:19 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.118 | nll_loss 7.33 | ppl 160.88 | bleu 1.57 | wps 3451.1 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.57
2022-03-23 09:35:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:35:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:35:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.57) (writing took 1.7074727720028022 seconds)
2022-03-23 09:35:21 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:35:21 | INFO | train | epoch 006 | loss 9.348 | nll_loss 7.757 | ppl 216.25 | wps 38575.5 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.192 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 603
2022-03-23 09:35:21 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:41 | INFO | train_inner | epoch 007:     63 / 157 loss=9.173, nll_loss=7.504, ppl=181.56, wps=29519.9, ups=1.18, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.035, loss_scale=4, train_wall=31, gb_free=13.8, wall=623
2022-03-23 09:36:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example hypothesis: these can't be no.
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example hypothesis: and he had a year in the year.
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:36:22 | INFO | fairseq.tasks.translation | example hypothesis: so, i can't have a lot of course.
2022-03-23 09:36:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example hypothesis: he said, because he was his father, because he was his father, because he was his father.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of us, and we have a lot of us, and what we're going to do?
2022-03-23 09:36:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:36:34 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to do this or or or or or or, or we're going to talk about the world.
2022-03-23 09:36:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example hypothesis: but there are not some of some of them, but if you're not a lot of them, but they're not not not not a lot of the way.
2022-03-23 09:36:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to find the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world,
2022-03-23 09:36:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:50 | INFO | fairseq.tasks.translation | example hypothesis: well, "if we said," "" "" "if we said," "" "" and we're going to say, "and we're going to say," and we said, "and we're going to say," and we're going to say, "" and we're going to say, "" "" and we're going to say, "and we're going to say," and we're going to say, "and we're going to say," and we're going to say, "and we're going to say," and we're going to say, "and we're going to say," and we're going to say, "and we're going to say," and we're going to say, "and we're going to say," and we're going to say, "" and we're going to say, "
2022-03-23 09:36:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, and we're going to be a lot of the world, and if we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and if we're going to get to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be able to get to be a lot of the world, and if we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to get to get to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to get
2022-03-23 09:36:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:53 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.898 | nll_loss 6.981 | ppl 126.33 | bleu 2.95 | wps 4235 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.95
2022-03-23 09:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:36:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.95) (writing took 1.695207887009019 seconds)
2022-03-23 09:36:54 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:36:54 | INFO | train | epoch 007 | loss 9.108 | nll_loss 7.41 | ppl 170.01 | wps 42309.7 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.061 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 696
2022-03-23 09:36:55 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:57 | INFO | train_inner | epoch 008:      6 / 157 loss=9.045, nll_loss=7.319, ppl=159.65, wps=33603.9, ups=1.33, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.091, loss_scale=4, train_wall=30, gb_free=15.3, wall=699
2022-03-23 09:37:28 | INFO | train_inner | epoch 008:    106 / 157 loss=8.911, nll_loss=7.126, ppl=139.64, wps=80370.2, ups=3.21, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=0.995, loss_scale=4, train_wall=31, gb_free=22.4, wall=730
2022-03-23 09:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to be able to be able.
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example hypothesis: it's a year in the last year.
2022-03-23 09:37:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example hypothesis: so, this is that i can make a lot of course, and i can make a lot of course.
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he was his father, because he was never never never never never never never never never never never never never never never never never never never never never never never never never never never been
2022-03-23 09:38:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:38:08 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a few years, and what we're going to do with us, and we're going to do what we're going to do with us, and we're going to do what we're going to do with us.
2022-03-23 09:38:08 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:38:13 | INFO | fairseq.tasks.translation | example hypothesis: so, our time, we're going to do our own time or or or or or or or or or or, or or we're going to do it.
2022-03-23 09:38:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example hypothesis: some people are some of them, but if you don't know, you don't know, but it's not like the way, but it's not not the way, but they don't have the way, but they don't get it.
2022-03-23 09:38:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see the way that we can see the world, and we can get a kind of the world, and we can get a kind of the world, and we can get a kind of the world, and then we can make it.
2022-03-23 09:38:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:28 | INFO | fairseq.tasks.translation | example hypothesis: one: it's one of the one, and it said, "if you're going to say, you're going to say, you're going to say, and you're going to say, and you're going to say, you're going to say, and you're going to say, you're going to say, and you're going to say, you're going to say, and you're going to say, you're going to say, and you're going to say, you're going to say, you're going to say, and you're going to say, and you're going to say, you're going to say, you're going to say, and you're going to say, you're going to say, and you're going to say, you're going to say, and you're going to get it's going to say, you're going to say, and you're
2022-03-23 09:38:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:31 | INFO | fairseq.tasks.translation | example hypothesis: so, the idea is, if you're going to get a lot of the way, and we're going to get it, and it's a lot of the way that we're going to get it, and we're going to get it, and we're going to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way to get it, or a lot of the way that we're going to get it, or a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way that we're going to get it, and we're going to get it, and we're going to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way that we're going to get a lot of the way, or a lot of the way that we're going to get a
2022-03-23 09:38:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:31 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.7 | nll_loss 6.7 | ppl 103.96 | bleu 3.58 | wps 3925.7 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.58
2022-03-23 09:38:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:38:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:38:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.58) (writing took 1.6807519010035321 seconds)
2022-03-23 09:38:32 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:38:32 | INFO | train | epoch 008 | loss 8.897 | nll_loss 7.105 | ppl 137.68 | wps 40372.8 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.01 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 794
2022-03-23 09:38:33 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:38:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:48 | INFO | train_inner | epoch 009:     49 / 157 loss=8.824, nll_loss=6.998, ppl=127.79, wps=31552.8, ups=1.25, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.093, loss_scale=4, train_wall=30, gb_free=13.6, wall=810
2022-03-23 09:39:19 | INFO | train_inner | epoch 009:    149 / 157 loss=8.712, nll_loss=6.836, ppl=114.25, wps=80687.2, ups=3.19, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.008, loss_scale=4, train_wall=31, gb_free=14, wall=841
2022-03-23 09:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:25 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:39:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example hypothesis: and the year can be about about about 20 years.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example hypothesis: so, this is a lot of course, i can be a lot of course, i can be able to be able to be able.
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:39:38 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because he had his father, because she had his father, because she had his father was his father.
2022-03-23 09:39:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i said, and we've got a friend, so we're going to say, so what we're going to do?
2022-03-23 09:39:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example hypothesis: and so we have our time to talk about things about things like things like things, or the other things, or not about the other things or or or or or the other other other other or or or or or or the other other other other other or or or or or or or or or
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example hypothesis: and first, some of the way of the way, but you don't know, but if you don't do it, but if you don't do it, you don't have the way, you don't have to do it, but if you don't know, you don't do it, you don't do it, you don't have the
2022-03-23 09:39:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to change the information of this information that we can see this information, and we can see the way that we can make a kind of information, and then we can see the way, and we can make a kind of information, and then we can see the kind of the way that we can see the way, and then we can see that we can see the way to create a kind of the way to make it.
2022-03-23 09:40:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example hypothesis: one: it's the one of the reason, and it's going to say, and it's going to say, "and it's going to say," if we're going to say, "if we're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "well," you're going to say, "well," you're going to do it's going to say, "well," well, "well," well, "well," well, "well," well, "well," you're going to do it's going to say, "you're going to do it's a little little bit of the first," and then we're going to do it's going to say, "you're going to say," and it's
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:10 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's not a lot of course, and it's a lot of the first time, if we're going to get a lot of the way, if we're going to get a lot of the way, if we're going to do it, if we're going to do it, if you're going to get a little bit of the way that we're going to get a little bit of the way to do that we're going to get a little bit of the way to get to get a little bit of the way to be a little bit of the way that we're going to do that we're going to do it, or if we're going to do it, if we're going to get a little bit that we're going to be a little bit of the way to get a little bit of the way to do that we're going to get a little bit of the way that we're going to be a little bit of the way to be a little bit of the way to get a little bit of the way to be a
2022-03-23 09:40:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:10 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.48 | nll_loss 6.336 | ppl 80.77 | bleu 4.64 | wps 3691.7 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.64
2022-03-23 09:40:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:40:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.64) (writing took 1.7075812530092662 seconds)
2022-03-23 09:40:11 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:40:11 | INFO | train | epoch 009 | loss 8.723 | nll_loss 6.853 | ppl 115.59 | wps 39844 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.048 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 893
2022-03-23 09:40:12 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:41 | INFO | train_inner | epoch 010:     92 / 157 loss=8.527, nll_loss=6.572, ppl=95.15, wps=31267.6, ups=1.23, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.097, loss_scale=4, train_wall=30, gb_free=12.6, wall=923
2022-03-23 09:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:04 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:41:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about about 30 years.
2022-03-23 09:41:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example hypothesis: these are the way of course, of course, i can use a lot of course.
2022-03-23 09:41:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:41:16 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, because she had had his mother with his mother.
2022-03-23 09:41:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a lot of girls and a child, and we said, so we're going to do what we're doing?
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example hypothesis: and so we started our time to talk about things about things like the time, or not about the time or every time.
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the bbbes, but if they don't need to be able to be able to be able, and if they don't need it, they don't need it.
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can use this information, and we can take a little bit of the system, and then we can take a kind of information, which is, which is all all the kind of information.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons, and the interesting interesting interesting interesting thing, "and it's going to say," "if you've got to say," you've got to say, "you've got to say," you'll say, "you know," you'll say, "you'll say," you'll say, "well," well, "well," you'll say, "you'll say," well, "well," well, "you'll say," well, "well," well, "well," well, "well," well, "you'll say," you'll say, "you'll say," well, "you'll say," you'll say, "you'll say," you'll say, "you'll say," you'll say, "you'll say," you know, "it's
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:37 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still still the mother that we had a lot of work, and if we had a lot of the way that we've got to do it, or we've got to do it.
2022-03-23 09:41:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:37 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.256 | nll_loss 6 | ppl 63.99 | bleu 7.86 | wps 5035.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.86
2022-03-23 09:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:41:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.86) (writing took 1.690236887006904 seconds)
2022-03-23 09:41:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:41:39 | INFO | train | epoch 010 | loss 8.533 | nll_loss 6.58 | ppl 95.65 | wps 45270.7 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.028 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 981
2022-03-23 09:41:39 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:41:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:50 | INFO | train_inner | epoch 011:     35 / 157 loss=8.5, nll_loss=6.53, ppl=92.44, wps=35892.6, ups=1.44, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=0.969, loss_scale=4, train_wall=30, gb_free=22.4, wall=992
2022-03-23 09:42:21 | INFO | train_inner | epoch 011:    135 / 157 loss=8.315, nll_loss=6.267, ppl=77, wps=80634.9, ups=3.19, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=0.948, loss_scale=4, train_wall=31, gb_free=14.4, wall=1023
2022-03-23 09:42:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these cells.
2022-03-23 09:42:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:42:36 | INFO | fairseq.tasks.translation | example hypothesis: and then, he can be about about about 38888,000 miles.
2022-03-23 09:42:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:42:40 | INFO | fairseq.tasks.translation | example hypothesis: so, i can use that of course, of course, of course, of course, of course, i can get a lot of course.
2022-03-23 09:42:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he never never had his father because his mother had his mother, he had his mother with his mother.
2022-03-23 09:42:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a lot of aids, and a child has been a child, so we got a child, so what do we do?
2022-03-23 09:42:49 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to our time about things like things like the same time, and we're not going to talk about all of the world.
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of you are some of the maddddddddding, but it doesn't need to be so if you need to change the energy and the energy.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the information of these information, we can see this information, we can start with a little bit of a lot of information, and then we can see the structure of the information.
2022-03-23 09:43:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:06 | INFO | fairseq.tasks.translation | example hypothesis: second: one of the reasons that it's interesting interesting, and it's interesting for me for me for me for me for me to say, "well," you know, "you know," well, "well," you know, "well," you know, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "you know," you know, "you know," well, "well," you know, "well," well, "
2022-03-23 09:43:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately,, it's always always always always always always always the mother, and the great part of the work that we have a lot of our work on our work, which is that we're going to see that we had to see a lot of the world.
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:08 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.101 | nll_loss 5.718 | ppl 52.63 | bleu 9.57 | wps 4562.8 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.57
2022-03-23 09:43:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:43:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.57) (writing took 1.714633897994645 seconds)
2022-03-23 09:43:10 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:43:10 | INFO | train | epoch 011 | loss 8.305 | nll_loss 6.254 | ppl 76.3 | wps 43422.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.951 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1072
2022-03-23 09:43:10 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:35 | INFO | train_inner | epoch 012:     78 / 157 loss=8.051, nll_loss=5.893, ppl=59.44, wps=34918.5, ups=1.36, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=0.908, loss_scale=4, train_wall=30, gb_free=14.8, wall=1097
2022-03-23 09:43:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use these materials.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about about 80,000 miles.
2022-03-23 09:44:07 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example hypothesis: this rres can also be a lot of course, of course, i can also have a lot of forms.
2022-03-23 09:44:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example hypothesis: he never had his father, because his father had his father because she had his father when she had his father with him.
2022-03-23 09:44:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a child, and a child has been a child, so we asked us, so we asked us to do what do?
2022-03-23 09:44:19 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:44:24 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about things like time, and how to talk about time to talk about time or not about poverty, or each other, or each of the end of poverty.
2022-03-23 09:44:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:44:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the mamadddes, but it doesn't like it, but if you don't need to do it, if you need your own energy, and if you need your own energy, you need to use your own energy, you need to use your own energy, you need to get your own energy,
2022-03-23 09:44:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start with this process, we can start with a huge network, and then we can start to start with one of the structure of the structure, and the structure of the structure, and the structure of the structure, which is all the information, and all the information, and all the information, and all the information that's all the information that's all the information is all the information, and all the information,
2022-03-23 09:44:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:39 | INFO | fairseq.tasks.translation | example hypothesis: second, one reasons of the reasons, and it's interesting for me to be interesting for me, for me, for me, "well," well, "let's say," well, "well," well, "if you've got the best women," well, "well," well, "if you've got the best women," well, "well," well, "well," well, "well," well, "well," well, "the best," well, "well," the best, "the best women," the best, "the best," the best, "the best," the best, "the best," the best, "let's say," the best, "the best," let's say, "the best," let's say, "let's say," the best, "
2022-03-23 09:44:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:42 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still the mother, and the great part of the work that we have a lot of work on our work on our work, and if we had to see that if we had to take a very simple system, we had to see that it, and we had to use it to take a very important system, we had to see that it's a very important system, and we had to take it to take it to take it with a very simple system, we had to see that it, we had to see that it's a huge amount of the top of the top of the top of the top of the top of the top of the top of the top of the top of the top of the top of the top of the bottom, we had to see that we had to see that we had to see that it's a large large large problems that it's a very simple system, we had to use that it's a very simple system, we had to see that we had to see that it's a very simple system,
2022-03-23 09:44:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:42 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.802 | nll_loss 5.287 | ppl 39.05 | bleu 10.62 | wps 4231.7 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.62
2022-03-23 09:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:44:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.62) (writing took 1.707049486998585 seconds)
2022-03-23 09:44:43 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:44:43 | INFO | train | epoch 012 | loss 8.102 | nll_loss 5.961 | ppl 62.31 | wps 42063.5 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.938 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1165
2022-03-23 09:44:44 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:50 | INFO | train_inner | epoch 013:     21 / 157 loss=8.111, nll_loss=5.973, ppl=62.79, wps=32493.9, ups=1.32, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=0.939, loss_scale=4, train_wall=30, gb_free=14.1, wall=1172
2022-03-23 09:45:22 | INFO | train_inner | epoch 013:    121 / 157 loss=7.893, nll_loss=5.662, ppl=50.63, wps=80324, ups=3.2, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=0.938, loss_scale=4, train_wall=31, gb_free=13.9, wall=1204
2022-03-23 09:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical amount.
2022-03-23 09:45:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8880,000 miles.
2022-03-23 09:45:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example hypothesis: these rrrres i can also have a lot of course.
2022-03-23 09:45:44 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because he had his mother.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: so one of my friends is a child, and so we got a child, so we asked us to do what do?
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:45:55 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about things, and not talk about the time, or the quality of poverty.
2022-03-23 09:45:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:45:59 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of course, you know, but it doesn't like this, but if you don't need your own energy, it doesn't need your energy and so if you need the energy.
2022-03-23 09:45:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this map, we can start with a traditional traditional network, and we can start able to start with the form of the form of the structure, which is a whole structure of information that all the information is a whole structure of information and all the information that all the information is a whole structure of information.
2022-03-23 09:46:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here. "
2022-03-23 09:46:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother that we have a big work on our work, and we had a lot of work that we had to make a little bit that if we had to use it, it was all the same system that we had to use it to use it to make it, to make a very important system that it was the same system that it was a little bit of the same system that we had to use, to use, to make it, to use that it was a huge amount of the amount of the same system that we had to make it was a very important system that it was a very important system that we had to make it was the same way that it was to use that it was to use that we had to use to make it was a huge amount of the amount of the same system that if we had to use that we had to use that it was to use that if we had to use it was to use it was a little bit of the same system that it was a little bit of the amount of the same system
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:09 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.702 | nll_loss 5.161 | ppl 35.77 | bleu 10.64 | wps 4982.9 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 10.64
2022-03-23 09:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 13 @ 2036 updates, score 10.64) (writing took 1.7049240920023294 seconds)
2022-03-23 09:46:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:46:11 | INFO | train | epoch 013 | loss 7.89 | nll_loss 5.657 | ppl 50.46 | wps 45023.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.928 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1253
2022-03-23 09:46:11 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:32 | INFO | train_inner | epoch 014:     64 / 157 loss=7.752, nll_loss=5.459, ppl=43.97, wps=36496.5, ups=1.43, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=0.923, loss_scale=4, train_wall=31, gb_free=13.9, wall=1274
2022-03-23 09:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example hypothesis: so this light can't use chemical chemical chemical chemical chemical chemical chemical chemical.
2022-03-23 09:47:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 88,000 dollars in the restaurant.
2022-03-23 09:47:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also be able to get these kinds of course, of course, of course, of course, of course, of course, of course, of course, i
2022-03-23 09:47:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his mother with his mother.
2022-03-23 09:47:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:47:22 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is a child, and a child has died a child, so we asked us, what do we do?
2022-03-23 09:47:22 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:47:26 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about things about how to talk about things, and not talk about the amount of energy of poverty or poverty.
2022-03-23 09:47:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example hypothesis: first, first, some of course, some of course, some of course, but in the field, if you don't want to move, you don't know, and if you don't need to move the power of energy, and so you don't need, and so you need to move the alalalalalalalalaly,
2022-03-23 09:47:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from these information, we can start with this particular network, and we can begin to start with a big structure, and we can start all the information of information, and the whole structure of information, and the whole structure of information, and so if we're all the whole structure, and if we're all going to use it's all the whole structure of information, and if we're all the information, and so
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:42 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting for me to be interesting to be here for tedson, "yes," yes, "when we're going to say," if we're going to say, "the best revolution," and then we're going to say, "if we're going to have a lot of course," you're going to say, "the best," the best of course, "you're going to have a lot of course," you're going to have a lot of course, "the first time," the best of course, "you're going to do it's the first," the first, "the best," the first, "the best of course," the best of course, "you're going to do you're going to have a lot of course," the best of course, "the best of course
2022-03-23 09:47:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother, and the invention of the invention of the work that we have to see a big amount of work on our air, and when we were able to see it, and we were able to use it with a lot of problems that it's all the amount of problems that we were able to use, and to use it's all of the amount of coordinate, and to use it, to use it, and to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're still able to be able to see that if we're still able to see that if we're still able to see that if we're still able to get a very important to use the amount of cocococoordinate with a huge amount of the amount of the amount of the amount of the amount of the amount of cocococoordinate with a huge amount of the amount of the amount of the amount of co
2022-03-23 09:47:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.542 | nll_loss 4.907 | ppl 30 | bleu 11.84 | wps 4101.5 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 11.84
2022-03-23 09:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 11.84) (writing took 1.727618730001268 seconds)
2022-03-23 09:47:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:47:46 | INFO | train | epoch 014 | loss 7.731 | nll_loss 5.425 | ppl 42.96 | wps 41578.1 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.95 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1348
2022-03-23 09:47:46 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:49 | INFO | train_inner | epoch 015:      7 / 157 loss=7.73, nll_loss=5.421, ppl=42.84, wps=32172.9, ups=1.3, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=0.941, loss_scale=4, train_wall=30, gb_free=14, wall=1351
2022-03-23 09:48:20 | INFO | train_inner | epoch 015:    107 / 157 loss=7.577, nll_loss=5.201, ppl=36.79, wps=80064.4, ups=3.21, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=0.853, loss_scale=4, train_wall=31, gb_free=13.8, wall=1382
2022-03-23 09:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:39 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical rays.
2022-03-23 09:48:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 feet in the restaurant.
2022-03-23 09:48:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example hypothesis: and i can also put that magnetic magnetic bible, of course, and of course, i can also have a very popular bible of forms.
2022-03-23 09:48:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother when she was pregnant with him.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my couver is died in aids, and one of aids has died, so we asked us, so what do we do?
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like the equation and not talk about the nuclear weapons or the weapons of poverty.
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:49:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic field in the field, but it doesn't like that, but if you don't want to move your movements, you don't need to move your movements, and if you don't need your movements.
2022-03-23 09:49:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional view of traditional factors, and we can start able to start with a traditional form of the face, and we can start able to start to start through the shape of the shape of the structure of the structure of the structure, and the information, which is the whole information that all the information, and the information that's a whole structure of this structure of this structure,
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedson, for me, "yes, that it's the best time," yes, when someone said, "well," if we're going to do you're going to do the best, "and then you're going to have a long time to do that," you're going to have a long time to do it, "and then you're going to do it,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 09:49:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the mother of the invention, and a big design of design that we had to see in our plane, and if we had to solve a unique plane, we had to solve a unique way to solve that if we had to solve it, to solve it was to solve a unique, to see that if you had to see the top of the top of the bottom of the bottom of the bottom of the air, to see the air, to see that if you had to see that if you had to see the bottom, to see the bottom of the air, to see that it was to see that if you had to see the air, to be a very much more, and we had to see the bottom, to see it was to see that if you had to see the bottom of the bottom, to see, to see, to see, to see, to see, and we had to be a very much more, to see, to see that if you had to be a very much more importantly, to see that the
2022-03-23 09:49:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:19 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 7.302 | nll_loss 4.515 | ppl 22.87 | bleu 14.87 | wps 4178.5 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 14.87
2022-03-23 09:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:49:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 14.87) (writing took 1.78620092899655 seconds)
2022-03-23 09:49:20 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:49:20 | INFO | train | epoch 015 | loss 7.546 | nll_loss 5.155 | ppl 35.63 | wps 41917.5 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.82 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1442
2022-03-23 09:49:21 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:37 | INFO | train_inner | epoch 016:     50 / 157 loss=7.486, nll_loss=5.066, ppl=33.5, wps=33012.7, ups=1.3, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.769, loss_scale=4, train_wall=31, gb_free=14.4, wall=1459
2022-03-23 09:50:08 | INFO | train_inner | epoch 016:    150 / 157 loss=7.28, nll_loss=4.774, ppl=27.37, wps=81222.9, ups=3.24, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.763, loss_scale=4, train_wall=30, gb_free=13.7, wall=1490
2022-03-23 09:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical chemical rays.
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example hypothesis: and i can also be able to get a sense of course to form a very popular bible forms.
2022-03-23 09:50:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:50:25 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother left his mother when she was pregnant.
2022-03-23 09:50:25 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died in aids, and a dian child, so we asked us what do we do?
2022-03-23 09:50:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:50:33 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talk about the nuclear weapons or nuclear weapons.
2022-03-23 09:50:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic field in the field, but the susususus doesn't want to move their movements.
2022-03-23 09:50:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional face that we can begin to start with a traditional face of the face of the structure of the information, and the whole structure of the whole structure of the whole structure.
2022-03-23 09:50:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here for tedwomen, is that it's the best time you're going to help you. "
2022-03-23 09:50:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:48 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big design part of the work that we have to see the aircraft of our aircraft, or that we had a unique problem that there was all the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom, and that there's a huge scale, and that we're going to see that there's a huge amount of the bottom, to see that there's a huge amount of the bottom, to see that there's a major design of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom of the bottom, to be a large design of the bottom, and that there's a major design of the bottom of the bottom, and a big design of the bottom of the bottom, to see that there's a major design of the bottom of the bottom of the bottom of the bottom, and a big design, to be a big design of the bottom of the
2022-03-23 09:50:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:48 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.165 | nll_loss 4.304 | ppl 19.75 | bleu 17.69 | wps 4713.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.69
2022-03-23 09:50:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:50:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:50:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:50:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 17.69) (writing took 1.7519122590019833 seconds)
2022-03-23 09:50:50 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:50:50 | INFO | train | epoch 016 | loss 7.338 | nll_loss 4.857 | ppl 28.97 | wps 44096.1 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.774 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1532
2022-03-23 09:50:50 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:20 | INFO | train_inner | epoch 017:     93 / 157 loss=7.182, nll_loss=4.631, ppl=24.79, wps=35723.4, ups=1.38, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.722, loss_scale=4, train_wall=31, gb_free=13.9, wall=1562
2022-03-23 09:51:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 09:51:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example hypothesis: over 8,000 places, he can do about 8,000 places in the restaurant.
2022-03-23 09:51:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example hypothesis: and that rors, of course, i can also make sure of course, of course, to form a popular bibible.
2022-03-23 09:51:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:51:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his mother, because his mother had been born with him when she was pregnant.
2022-03-23 09:51:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:52:00 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is on aids, and one of aids has died in aids, so we asked us, what do we do with her?
2022-03-23 09:52:00 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:52:05 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talking about the nuclear weapons of poverty, or any other topic of poverty.
2022-03-23 09:52:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:52:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bold magnetic magnetic lines are in the field, but the susususususususued, if you don't move your movements, you need your movements, and so you need your energy.
2022-03-23 09:52:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial face, which is the real shape of the face, and the real shape of the information, and the information, and the whole structure, and the whole structure of all the structure, the structure, and the structure of this structure.
2022-03-23 09:52:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are interesting and measure it's interesting for me here for me here for tedwomen in tedwomen, is that -- yes, in the best time, when someone said, "somebody said," you know, when the men starts to support you, "and then you're going to help you have a long time," and then you're going to help you have a lot of men, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [["
2022-03-23 09:52:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of design design work on our plane, in our plane, we've had to solve a unique problems that we had to solve all the problems that were connected to the ground -- to the ground, to the ground, to the ground, to us, and that it's all the continent, if it's all the continent, if it's all the continent, it's a continued to the continent, to the continent, to the continent, it's all of us to the continent, to the continent, if you have to the way that we have a continued to see it's all the continent, to see that if you have a continued to the continent, or to the continent, to the continent, to see the continent, to the continent, if you're either the continent, or to the continent, if you have a system, you're either the continent, to see the continent, you have a continued to see the continent, you're either the continent,
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:21 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.04 | nll_loss 4.123 | ppl 17.43 | bleu 18.37 | wps 4353 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.37
2022-03-23 09:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:52:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:52:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.37) (writing took 1.7760816119989613 seconds)
2022-03-23 09:52:23 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:52:23 | INFO | train | epoch 017 | loss 7.152 | nll_loss 4.59 | ppl 24.08 | wps 42561 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.727 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1625
2022-03-23 09:52:23 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:52:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:34 | INFO | train_inner | epoch 018:     36 / 157 loss=7.085, nll_loss=4.494, ppl=22.54, wps=32800.3, ups=1.34, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.768, loss_scale=4, train_wall=30, gb_free=14, wall=1636
2022-03-23 09:53:06 | INFO | train_inner | epoch 018:    136 / 157 loss=7.044, nll_loss=4.432, ppl=21.58, wps=81127.4, ups=3.18, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.736, loss_scale=4, train_wall=31, gb_free=13.6, wall=1668
2022-03-23 09:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical rockets.
2022-03-23 09:53:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:53:24 | INFO | fairseq.tasks.translation | example hypothesis: and i can also be able to do that, of course, of course, to form a popular bible.
2022-03-23 09:53:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 09:53:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:53:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and has a wavela child, so we asked us, well, what do we do with her?
2022-03-23 09:53:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:53:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about it or nuclear weapons.
2022-03-23 09:53:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some ble of magnetic magnetic magnetic lines are coming into the inside the inside the inside, but the sususuing susuits doesn't like it, if they move their movements, and they need their energy, and they need the suck of the disorder.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face, which can begin to start with a traditional face of the face, and the real shape of the face, and the information is the structure of all the structure.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it for me to be here in tedwomen, is that...
2022-03-23 09:53:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention is still the invention, and a big part of the design work that we're working on our plane, is a result that we had to solve the unique problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the ground, or a piece of the air, and a system system, and that is, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:53:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:52 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.859 | nll_loss 3.858 | ppl 14.5 | bleu 21.32 | wps 4536.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.32
2022-03-23 09:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:53:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:53:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.32) (writing took 1.746969754996826 seconds)
2022-03-23 09:53:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:53:54 | INFO | train | epoch 018 | loss 7.035 | nll_loss 4.42 | ppl 21.41 | wps 43245.2 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.754 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1716
2022-03-23 09:53:54 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:19 | INFO | train_inner | epoch 019:     79 / 157 loss=6.914, nll_loss=4.247, ppl=18.99, wps=33481.1, ups=1.37, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.676, loss_scale=4, train_wall=30, gb_free=13.6, wall=1741
2022-03-23 09:54:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that rors, of course, to form a popular bias.
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:54:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left him when she was pregnant.
2022-03-23 09:54:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died to aids, and has a wake child, so we said, well, what do we do?
2022-03-23 09:55:02 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:55:06 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:55:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:55:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some bull of magnetic magnetic lines are starting, but the superconductor doesn't like when they need their movements, and so they need the sucks.
2022-03-23 09:55:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face of the face of the face, and the real shape of the factors, and the consequence of the information, and you can fold it through that information, and you can fold all the structure of this structure.
2022-03-23 09:55:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:19 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that are interesting and measuring it for me to be here at tedwomen, is that -- yes, when the best one said, "somebody said," you're going to be able to support you at the table, and then you're going to help you're going to help you. "
2022-03-23 09:55:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example hypothesis: luluckily, the mother of invention, and a big part of design work that we're in our aircraft, is a result that we had to solve the unique problems so we had to solve it all the way to the ground, and it allows us to be refrigered to be refrigered to be refrigered to be able to be refrigered to be refrigered to be refrigered by a refrigered to the air system, and to be able to be able to be refrigeration of a mechanism, and to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be refrigeration of a mechanism, and to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the
2022-03-23 09:55:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:21 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.777 | nll_loss 3.733 | ppl 13.29 | bleu 21.5 | wps 4799.5 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.5
2022-03-23 09:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:55:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.5) (writing took 1.7674738700006856 seconds)
2022-03-23 09:55:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:55:23 | INFO | train | epoch 019 | loss 6.888 | nll_loss 4.21 | ppl 18.51 | wps 44496 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.677 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1805
2022-03-23 09:55:23 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:30 | INFO | train_inner | epoch 020:     22 / 157 loss=6.883, nll_loss=4.202, ppl=18.4, wps=35419, ups=1.41, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.66, loss_scale=4, train_wall=30, gb_free=14.6, wall=1812
2022-03-23 09:56:02 | INFO | train_inner | epoch 020:    122 / 157 loss=6.692, nll_loss=3.937, ppl=15.32, wps=82096.6, ups=3.17, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.631, loss_scale=4, train_wall=31, gb_free=22.4, wall=1844
2022-03-23 09:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:56:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 09:56:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example hypothesis: and i can also continue to form this rough.
2022-03-23 09:56:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 09:56:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:56:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and has a wash child, so we said, well, what do we do?
2022-03-23 09:56:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talk about annual weapons or poverty or any other topic.
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:56:39 | INFO | fairseq.tasks.translation | example hypothesis: first is some of the magnetic field in the inside the inside, but the superconductor doesn't like if you need your movements, your movements, and so the supermovements, and so the superconductor.
2022-03-23 09:56:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:44 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face, the big constructions of the face, the real shape of the face and the basic shape, and the basic form of information, and you can fold it through that information, the whole information.
2022-03-23 09:56:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it starts to be interesting for me to be here at tedwomen, is that -- yes, when it was the best, it was put it together as somebody who said, "you know, you know, the men in a table, you know, and then you're going to help you know, you know, you know, you know, you know, the men who starts to support you're going to support you're going to support you're going to support you're going to help you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, when you know, you know, you know, you know, you know, you know, you're going to support you know, you know,
2022-03-23 09:56:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of design work that we have to see in our plane, is a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- all the way -- all of a continued to a continued to a continuous system that allows us to be refrigeration with a refrifrigeration, and a refrigeration system that allows us to be refrigeration, and a refrigeration of the refrigeration, and a mechanism system that allows us to be refrigeration, if you can use it into a frigeration, it's a mechanism system that is either a frigeration, it's a frigeration, it's a frigeration, it's also a mechanism system that we can use it's a refrigeration, it's a mechanism system that we have a mechanism system that allows us to refrigeration,
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:51 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.708 | nll_loss 3.643 | ppl 12.49 | bleu 23.03 | wps 4644.7 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.03
2022-03-23 09:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:56:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:56:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.03) (writing took 1.7082179310091306 seconds)
2022-03-23 09:56:53 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:56:53 | INFO | train | epoch 020 | loss 6.748 | nll_loss 4.015 | ppl 16.16 | wps 43931.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.648 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1895
2022-03-23 09:56:53 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:56:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:13 | INFO | train_inner | epoch 021:     65 / 157 loss=6.751, nll_loss=4.019, ppl=16.21, wps=34289, ups=1.39, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.667, loss_scale=4, train_wall=30, gb_free=14.7, wall=1915
2022-03-23 09:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:46 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:57:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example hypothesis: overall year, he can protect about 8,000 places in the restaurant.
2022-03-23 09:57:49 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand to form a popular bias.
2022-03-23 09:57:53 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 09:57:57 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids and has a waisena child, so we asked us what do we do?
2022-03-23 09:58:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:58:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:58:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are starting in the inside, but the superconductor doesn't like it, if you move, your movements, and so the superconductor disorders.
2022-03-23 09:58:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which is the big constructures of the face and the basic form of the face, and through the information, the whole structure and fold all the structure.
2022-03-23 09:58:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, is that -- yes, when the best, "somebody said to you," you know, the men and then help them support you to help you to help you, and then help you to support the truth. "
2022-03-23 09:58:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we were in our aircraft was a result of the unique problems that were connected to the ground -- all of the continents, all of us need to use a continued to refrigerate the continents, and that it allows us to use it into a suburgent system.
2022-03-23 09:58:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:17 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.576 | nll_loss 3.44 | ppl 10.85 | bleu 24.78 | wps 5202.1 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.78
2022-03-23 09:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:58:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 09:58:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.78) (writing took 1.8021487740043085 seconds)
2022-03-23 09:58:19 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:58:19 | INFO | train | epoch 021 | loss 6.639 | nll_loss 3.862 | ppl 14.54 | wps 45739.2 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.601 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1981
2022-03-23 09:58:20 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:22 | INFO | train_inner | epoch 022:      8 / 157 loss=6.584, nll_loss=3.787, ppl=13.8, wps=36837.9, ups=1.45, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.572, loss_scale=4, train_wall=30, gb_free=14.3, wall=1984
2022-03-23 09:58:54 | INFO | train_inner | epoch 022:    108 / 157 loss=6.588, nll_loss=3.792, ppl=13.85, wps=80734.7, ups=3.2, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.638, loss_scale=4, train_wall=31, gb_free=13.9, wall=2016
2022-03-23 09:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:59:16 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 09:59:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 09:59:19 | INFO | fairseq.tasks.translation | example hypothesis: so i can also expanding that smoke.
2022-03-23 09:59:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father left his mother when she was pregnant.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 09:59:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and we asked a waisine child, so what do we do with her?
2022-03-23 09:59:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bble of magnetic field are starting inside the inside, but the superconductor doesn't like it when you move your movements, and your movements need, and so the superconductor disorder.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face of the face and the basic form of face, and the basic form is repeated by the information that can fold all the ports and fold.
2022-03-23 09:59:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that -- yes, it was the best summit when someone said, "she said," you know, when you're going to be able to be able to be a table and say, "if you're going to support a revolution."
2022-03-23 09:59:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on our plane's most proud, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continued to a continuous operating system, and we're going to use it from a continued to a continually refrigeration system that allows us to use it to the wheel when we're either a mechanism, if we're going to be able to be able to use it.
2022-03-23 09:59:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:45 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.59 | nll_loss 3.449 | ppl 10.92 | bleu 22.94 | wps 5043.7 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.78
2022-03-23 09:59:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:59:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 09:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 09:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 22.94) (writing took 0.8008455410017632 seconds)
2022-03-23 09:59:45 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:59:45 | INFO | train | epoch 022 | loss 6.56 | nll_loss 3.753 | ppl 13.48 | wps 45639.2 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.607 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2067
2022-03-23 09:59:46 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:02 | INFO | train_inner | epoch 023:     51 / 157 loss=6.447, nll_loss=3.597, ppl=12.1, wps=36807.6, ups=1.46, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.566, loss_scale=4, train_wall=30, gb_free=14.7, wall=2084
2022-03-23 10:00:33 | INFO | train_inner | epoch 023:    151 / 157 loss=6.499, nll_loss=3.669, ppl=12.72, wps=79708.8, ups=3.21, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.587, loss_scale=4, train_wall=31, gb_free=13.9, wall=2115
2022-03-23 10:00:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can protect about 8,000 places in the restaurant.
2022-03-23 10:00:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:00:46 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that smoke magnets to make a popular same same same thing.
2022-03-23 10:00:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:00:50 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:00:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we asked us, well, what do we do with?
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:00:58 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not talking about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:00:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:01:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it, if you're moving, you need your movements, and so the superconductor disorder.
2022-03-23 10:01:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this mirror reflection, we can start with a traditional face of the face and the basic form of the information that is recovering the whole portion of the structure and fold it into the basic form of the information that can fold all the ports and fold.
2022-03-23 10:01:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measuring it for me to be here at tedwomen, is that... well, when it was the best together than someone said, "turn you to the men in a table, and then the revolution starts to help you," you know, the truth is that we've already been supported for you, "you've already started to support you've already started to have a very long time."
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on on the tower was a result that we had to solve the unique problems that were connected to the ground -- everything from continuing to a continuing system to refrigerate with a refrigeration system that allows us to refrigerate, to be able to get into the propellyment of the propelled, or to the propellment of the propellment of a mechanism that we're either.
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:13 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.399 | nll_loss 3.203 | ppl 9.21 | bleu 27.27 | wps 4793.3 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.27
2022-03-23 10:01:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:01:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:01:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:01:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.27) (writing took 1.7409991110034753 seconds)
2022-03-23 10:01:15 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:01:15 | INFO | train | epoch 023 | loss 6.458 | nll_loss 3.612 | ppl 12.23 | wps 44191.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.572 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2157
2022-03-23 10:01:15 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:01:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:45 | INFO | train_inner | epoch 024:     94 / 157 loss=6.359, nll_loss=3.475, ppl=11.12, wps=35076.2, ups=1.39, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.543, loss_scale=4, train_wall=31, gb_free=14, wall=2187
2022-03-23 10:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:08 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:02:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:02:12 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 10:02:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:02:16 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expanding this round magnets to form a popular equality.
2022-03-23 10:02:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:02:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:02:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinis died of aids, and has a waisenena child, so we said, well, what do we do with her?
2022-03-23 10:02:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:02:27 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:02:27 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:02:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are caught inside the inner lines, but the superconductor doesn't like it when they're moving, because their movements need, and so the superconductor disorder.
2022-03-23 10:02:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big configuration of the face, and the basic form of the face, and the basic information that all the ports and fold a fold.
2022-03-23 10:02:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it starts to be highly interesting and measured for me to be here at tedwomen, is that... well, it became the best, when someone said, "turn you to the men's table and tell you," if the truth is that we're already supporting you. "
2022-03-23 10:02:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we have to solve in our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continued to a refrigeration system that allows us to refrigerate with a ridge system that allows us to refrigerate the propelled, that it's either in the propelled.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:41 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.406 | nll_loss 3.219 | ppl 9.31 | bleu 26.92 | wps 4907.6 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.27
2022-03-23 10:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 26.92) (writing took 0.8177577879978344 seconds)
2022-03-23 10:02:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:02:42 | INFO | train | epoch 024 | loss 6.379 | nll_loss 3.503 | ppl 11.34 | wps 45264.1 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.55 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2244
2022-03-23 10:02:42 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:54 | INFO | train_inner | epoch 025:     37 / 157 loss=6.377, nll_loss=3.501, ppl=11.32, wps=35879.6, ups=1.45, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.536, loss_scale=4, train_wall=30, gb_free=14.7, wall=2256
2022-03-23 10:03:25 | INFO | train_inner | epoch 025:    137 / 157 loss=6.321, nll_loss=3.424, ppl=10.73, wps=80726.3, ups=3.18, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.554, loss_scale=4, train_wall=31, gb_free=13.8, wall=2287
2022-03-23 10:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can save about 8,000 places in the restaurant.
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:03:43 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, i can expand this round magnets of course to shape a popular equation.
2022-03-23 10:03:43 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:03:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:03:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has a waisena child, so we asked us, well, what do we do with her?
2022-03-23 10:03:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender times, and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, the big contains of the face, and the basic form is repeating by the whole portion of the facial and the basic form, which is the whole portion and all the fold.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen, is that... well, when you got striking dinner, when somebody said, "turn you to the men on your table and you say," if the revolution starts to support you.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane was staggering, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use it in our plane, to get rid of the propelled, or when you get rid of the propelled, you get rid of the propelled, you can see the propelled, if you can either, you can use the propelled, you can use the propelled, you can use it, you can either, you can use it, you can use it, you can use the wheel, you can use it, you can use it, you can use it, you can use it, you can use the fare either, or you get a little bit more, you can use the wheel, you know, you can use the wheel, you know, if
2022-03-23 10:04:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:09 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.32 | nll_loss 3.075 | ppl 8.42 | bleu 28.5 | wps 4836.5 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.5
2022-03-23 10:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:04:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.5) (writing took 1.8222859599918593 seconds)
2022-03-23 10:04:11 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:04:11 | INFO | train | epoch 025 | loss 6.318 | nll_loss 3.42 | ppl 10.7 | wps 44290.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.537 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2333
2022-03-23 10:04:12 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:37 | INFO | train_inner | epoch 026:     80 / 157 loss=6.253, nll_loss=3.331, ppl=10.06, wps=35559.9, ups=1.4, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.519, loss_scale=4, train_wall=30, gb_free=14, wall=2359
2022-03-23 10:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:04 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 10:05:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:05:08 | INFO | fairseq.tasks.translation | example hypothesis: it's about 8,000 places in the restaurant.
2022-03-23 10:05:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:05:12 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these rocks to form any bias.
2022-03-23 10:05:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:05:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:05:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:05:20 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinan has died of aids, and has a waisena child, so we asked us what do we do with her?
2022-03-23 10:05:20 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:05:24 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times, not about the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:05:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:05:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:05:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, the big constructions of facial and the basic information that will fold the entire portion structure and fold a fold.
2022-03-23 10:05:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured for me to be here at tedwomen, is that... tyes, it was the best, when somebody said, "turn you to the men to a table and tell you," if the revolution starts to be here at tedwomen, the truth is that we've already supported you that women are already supported for you. "
2022-03-23 10:05:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are on our plane the stones, was a result that we had to solve the unique problems that were connected to operating on the ground -- all of a continuous variation and a refrigerator system that allows us to see if you're in the propelled, or if you can use the wheel, you can use a mechanism to use the wheel, or if you can see the mechanism in a mechanism, that allows us to use of a mechanism, and you can use to use the wheel.
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:38 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.253 | nll_loss 3.023 | ppl 8.13 | bleu 28.79 | wps 4807.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.79
2022-03-23 10:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:05:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.79) (writing took 1.7956887770124013 seconds)
2022-03-23 10:05:40 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:05:40 | INFO | train | epoch 026 | loss 6.239 | nll_loss 3.313 | ppl 9.94 | wps 44357.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.5 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2422
2022-03-23 10:05:41 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:48 | INFO | train_inner | epoch 027:     23 / 157 loss=6.233, nll_loss=3.306, ppl=9.89, wps=35294.4, ups=1.4, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.494, loss_scale=4, train_wall=31, gb_free=13.7, wall=2430
2022-03-23 10:06:19 | INFO | train_inner | epoch 027:    123 / 157 loss=6.178, nll_loss=3.23, ppl=9.38, wps=80034.9, ups=3.2, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.463, loss_scale=4, train_wall=31, gb_free=14.1, wall=2461
2022-03-23 10:06:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:06:42 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand this round magnets to shape a popular same same same thing.
2022-03-23 10:06:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and we asked us, well what do we do with her?
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equals and not about genocide or prevalence of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic shape, and the basic information that makes the whole portion structure and all fold.
2022-03-23 10:07:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen, is that... well, in striking dinner, it was the best summarized when somebody said, "turn you to the men on your table and say," if the revolution starts to help you. "
2022-03-23 10:07:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane are stumbled, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continually variable and refrigeration system that allows us to use an airplane on the edge of a propeller, either to use it to use it to make it a specialty, to a specific device that allows us to see when you see the propelled by a mechanism, or a mechanical device that allows us to use it to see it to use it to use it to use it to use it to use it to use it to use it to use it to use it to use it to make it to make it to make it to use it to use it to use it to use it to make it to make a particular, either a drill a mechanism.
2022-03-23 10:07:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:08 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.23 | nll_loss 2.987 | ppl 7.93 | bleu 29.39 | wps 4719.1 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.39
2022-03-23 10:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.39) (writing took 2.145831432004343 seconds)
2022-03-23 10:07:11 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:07:11 | INFO | train | epoch 027 | loss 6.167 | nll_loss 3.215 | ppl 9.29 | wps 43772.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.47 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2513
2022-03-23 10:07:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:32 | INFO | train_inner | epoch 028:     66 / 157 loss=6.145, nll_loss=3.188, ppl=9.11, wps=35100.1, ups=1.38, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.501, loss_scale=4, train_wall=31, gb_free=13.9, wall=2534
2022-03-23 10:08:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:08:11 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand to shape any same same same.
2022-03-23 10:08:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 10:08:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has left a waisena child, so we asked ourselves, what do we do with them?
2022-03-23 10:08:19 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which gives the big constructions of the face and the basic shape, and through the one information that draws the whole portion structure and all the folds.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and appropriate to be here at tedwomen is that... tyes, when stripped dinner, it was the best together when somebody said, "turn you to the men on your table and you say," if the revolution starts to help you. "the truth is that we've already been supporting you for that long time."
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the front of the propellment, or when you see the propellment of the propellment, if you're going to see the propelled by a mechanism, if you're going to be able to be able to be able to operate the propelled by a mechanism.
2022-03-23 10:08:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:37 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.141 | nll_loss 2.885 | ppl 7.39 | bleu 30.13 | wps 4879.4 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.13
2022-03-23 10:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:08:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.13) (writing took 1.751099343993701 seconds)
2022-03-23 10:08:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:08:39 | INFO | train | epoch 028 | loss 6.128 | nll_loss 3.164 | ppl 8.96 | wps 44665.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.479 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2601
2022-03-23 10:08:39 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:08:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:42 | INFO | train_inner | epoch 029:      9 / 157 loss=6.091, nll_loss=3.113, ppl=8.65, wps=35590.5, ups=1.41, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.434, loss_scale=4, train_wall=31, gb_free=14.1, wall=2604
2022-03-23 10:09:14 | INFO | train_inner | epoch 029:    109 / 157 loss=6.085, nll_loss=3.105, ppl=8.6, wps=80568.6, ups=3.19, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.492, loss_scale=4, train_wall=31, gb_free=14.6, wall=2636
2022-03-23 10:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:09:40 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand to form any same glimpse.
2022-03-23 10:09:40 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father left his mother when she was pregnant with him.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and he left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equals high times, and not about genocide or prevalence of nuclear weapons or poverty, or any other talk about it.
2022-03-23 10:09:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:59 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can start with the big constructions of the face and the basic shape, and restoring it by the one information that refers the whole portion structure and all fold a fold.
2022-03-23 10:09:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured to me here at tedwomen is that... well, when the men start to be here at tedwomen's dinner, it's one of the reasons that he said, "well, if the revolution begins to be here," the truth is that we have already supported you for a long time with silent carcolo, "and then a silent,"] ["] ["] ["] ["] ["] ["
2022-03-23 10:10:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're stressed on on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the aircraft until you see the propeller, or if you can see the propelled, you can see it, you can use it, you can use it, or you can use it, you can use it, you can see the propelled, or you can use it, you can use it, you can use it, you know, you know, you know, you know, if you can see it, you can see it, you can see it, either, you can see it in a mechanism.
2022-03-23 10:10:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.129 | nll_loss 2.856 | ppl 7.24 | bleu 30.29 | wps 4812.8 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.29
2022-03-23 10:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:10:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.29) (writing took 1.748604657012038 seconds)
2022-03-23 10:10:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:10:08 | INFO | train | epoch 029 | loss 6.066 | nll_loss 3.079 | ppl 8.45 | wps 44414.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.469 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2690
2022-03-23 10:10:08 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:10:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:25 | INFO | train_inner | epoch 030:     52 / 157 loss=6.015, nll_loss=3.01, ppl=8.06, wps=35099.3, ups=1.41, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.453, loss_scale=4, train_wall=30, gb_free=14.4, wall=2707
2022-03-23 10:10:56 | INFO | train_inner | epoch 030:    152 / 157 loss=6.039, nll_loss=3.044, ppl=8.25, wps=80857, ups=3.22, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.454, loss_scale=4, train_wall=31, gb_free=13.9, wall=2738
2022-03-23 10:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:11:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:11:06 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can do about 8,000 places in the restaurant.
2022-03-23 10:11:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand, to form any same same same thing.
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:11:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and we left an orphanage, so we asked us, well, what do we do with her?
2022-03-23 10:11:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal gender times, not about genocide, or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:11:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconductor disorders.
2022-03-23 10:11:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can restore the big contexts of the face and the basic shape, and by the theft information that refers the whole portion structure and all the fits.
2022-03-23 10:11:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that... tja, when stripped dinner, it became the best, when someone said, "turn you to the men at your table and say," if the revolution begins to support you. "the truth, women are already supporting you for a long time."
2022-03-23 10:11:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane was the staggering, a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in a particular way, to be able to use a specific transportation, either if you have a mechanical vehicle, or a mechanical bicycle, or if you can see the wheel.
2022-03-23 10:11:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:35 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.073 | nll_loss 2.801 | ppl 6.97 | bleu 31.48 | wps 4908.6 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.48
2022-03-23 10:11:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:11:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:11:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:11:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.48) (writing took 1.95456684299279 seconds)
2022-03-23 10:11:37 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:11:37 | INFO | train | epoch 030 | loss 6.024 | nll_loss 3.023 | ppl 8.13 | wps 44291.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.456 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2779
2022-03-23 10:11:38 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:11:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:08 | INFO | train_inner | epoch 031:     95 / 157 loss=5.966, nll_loss=2.944, ppl=7.7, wps=34916, ups=1.39, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.446, loss_scale=4, train_wall=31, gb_free=14.5, wall=2810
2022-03-23 10:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 10:12:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand these roundings to form any same same same.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and he left a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:12:51 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding up and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:12:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:12:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:12:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big constructions of the face, and the basic form of the face, which refers the whole portion structure and all fold a fold.
2022-03-23 10:12:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen, is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins to support you. "the truth, women love is that we already supported you for a long time to support you, that story is not a silent carried out of the future," and then it's going to downstream stream stream stream, "don't turn it out to be the men to be the men at the men at the men at a table," and say, "don't turn them," don't take you down to a moment, "don't want you down to your own table," don't want you down to the men to your own table, "and
2022-03-23 10:13:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are proud of at our plane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation to a continuous variation and cooling system that allows us to use a refrigerator, that it allows us to use the aircraft traffic, to either be able to use the most persuasive traffic, to use the same thing, if you see the wheel, if you're going to be able to operate the mechanism, if you're going to operate the same for a mechanism, you're going to operate the same, all the same, all the mechanism, all the mechanism, it's going to operate, all the same, all the same, all the mechanism, all the same, all the mechanism, all the mechanism, all the same, all the same thing that it's going to use it's going to be able to
2022-03-23 10:13:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:06 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.079 | nll_loss 2.807 | ppl 7 | bleu 31.4 | wps 4594.1 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.48
2022-03-23 10:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:13:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.4) (writing took 0.7750431809981819 seconds)
2022-03-23 10:13:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:13:07 | INFO | train | epoch 031 | loss 5.973 | nll_loss 2.955 | ppl 7.76 | wps 43824.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.451 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2869
2022-03-23 10:13:07 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:19 | INFO | train_inner | epoch 032:     38 / 157 loss=5.983, nll_loss=2.968, ppl=7.83, wps=35252, ups=1.4, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.464, loss_scale=4, train_wall=30, gb_free=14.9, wall=2881
2022-03-23 10:13:51 | INFO | train_inner | epoch 032:    138 / 157 loss=5.913, nll_loss=2.873, ppl=7.33, wps=80680.5, ups=3.19, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.404, loss_scale=4, train_wall=31, gb_free=14.1, wall=2913
2022-03-23 10:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:14:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, can expand to form any same equation.
2022-03-23 10:14:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:14:20 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding and not about genocide or prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:14:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:14:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:14:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that gives the big contexts of the face and the basic shape, and recovers it through the whole portion structure and all the fits a fold.
2022-03-23 10:14:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured to me here at tedwomen is that... tyes, dinner was the best summarized when someone said, "take you to the men at your table and say," if the revolution starts to support you, "the truth, women are already supporting you for a long time."
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily is still the mother of invention, and a big part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft until you see the propeller, or if you're in a mechanical transportation, or if you're going to operate it in the ground.
2022-03-23 10:14:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:34 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.027 | nll_loss 2.752 | ppl 6.74 | bleu 31.18 | wps 4793.9 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.48
2022-03-23 10:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.18) (writing took 1.2766036649991293 seconds)
2022-03-23 10:14:36 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:14:36 | INFO | train | epoch 032 | loss 5.93 | nll_loss 2.896 | ppl 7.44 | wps 44617.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.425 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2958
2022-03-23 10:14:36 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:02 | INFO | train_inner | epoch 033:     81 / 157 loss=5.907, nll_loss=2.864, ppl=7.28, wps=35348.3, ups=1.41, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.418, loss_scale=4, train_wall=31, gb_free=13.5, wall=2984
2022-03-23 10:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rocket.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand these roundings to form any same same glide.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and he left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, and not about genocides or prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:15:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and the superconductor disorder.
2022-03-23 10:15:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can, which gives the big contexts of the face and the basic shape, and by the one of the information that refers the entire portion structure and all fold.
2022-03-23 10:15:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was the best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts, then we support you. "" "the truth, women love is that we already have already started to encouraged you for a long time."
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still an invention, and a big part of the design work that we're stumbling on on on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation, and a refrigerator system that allows us to bend up on the edge of a steady varied variation and a refrigerator that allows us to stop a steady machine in the aircraft, until a gobend of a steady passage of a pipe, until a steady passage of a steady passage of a pipe, and a pipe, until you're either going to use the mechanism, until you're either going to use the mechanism, until you're either going to use the mechanism that drilling mechanism, until you're going to operate it's a mechanism, until you're going to operate it's a mechanism, it's
2022-03-23 10:16:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:04 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.018 | nll_loss 2.736 | ppl 6.66 | bleu 31.79 | wps 4707 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.79
2022-03-23 10:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:16:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.79) (writing took 2.471414970001206 seconds)
2022-03-23 10:16:06 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:16:06 | INFO | train | epoch 033 | loss 5.89 | nll_loss 2.843 | ppl 7.17 | wps 43687.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.418 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3048
2022-03-23 10:16:06 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:16:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:14 | INFO | train_inner | epoch 034:     24 / 157 loss=5.856, nll_loss=2.8, ppl=6.96, wps=34836.1, ups=1.38, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.424, loss_scale=4, train_wall=30, gb_free=14, wall=3056
2022-03-23 10:16:45 | INFO | train_inner | epoch 034:    124 / 157 loss=5.861, nll_loss=2.802, ppl=6.97, wps=80357.1, ups=3.2, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.412, loss_scale=4, train_wall=31, gb_free=14, wall=3087
2022-03-23 10:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rocks to make any glider.
2022-03-23 10:17:07 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 10:17:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:17:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:17:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:17:19 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 10:17:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:17:23 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and the superconductor disorders.
2022-03-23 10:17:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic form of the face and recover it by the one information that refits the whole portion structure and all the folds.
2022-03-23 10:17:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen, is that... well, at the dinner dinner dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins, we support you. '' "the truth, women is that we love you, women is that we've already supported you for a long time."
2022-03-23 10:17:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our plane at the proud toe, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a cooling system with liquid refrigeration that allows us to use an aircraft at the same time, to use an aircraft at the same time, to get rid of the problem that we had to be able to get rid of it, or if you get rid of a mechanized.
2022-03-23 10:17:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:34 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.996 | nll_loss 2.693 | ppl 6.47 | bleu 32.42 | wps 4680.2 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.42
2022-03-23 10:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:17:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.42) (writing took 1.7881838579924079 seconds)
2022-03-23 10:17:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:17:36 | INFO | train | epoch 034 | loss 5.864 | nll_loss 2.807 | ppl 7 | wps 43899 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.419 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3138
2022-03-23 10:17:36 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:57 | INFO | train_inner | epoch 035:     67 / 157 loss=5.868, nll_loss=2.814, ppl=7.03, wps=34301.9, ups=1.39, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.418, loss_scale=4, train_wall=31, gb_free=14.7, wall=3159
2022-03-23 10:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:18:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to form any glimpse.
2022-03-23 10:18:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:18:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:18:44 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:18:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:18:48 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equality wedding and not about genocide or prevalence of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:18:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:18:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:18:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contexts of the face and the basic shape, and recover it through the information that pulls the whole portion structure and all folds.
2022-03-23 10:18:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:19:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen, is that... well, when strict dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution starts supporting you. '"the truth, women love that we already encouraged you for a long time."
2022-03-23 10:19:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're staggering on on the plane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigeration system, that allows us to use an aircraft in the world to be in the go-to-go traffic, and use a particular mechanical vehicle, and use it was either to use it to use it to use it to be used in a particular mechanical transport.
2022-03-23 10:19:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:03 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.992 | nll_loss 2.697 | ppl 6.48 | bleu 31.75 | wps 4820 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.42
2022-03-23 10:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.75) (writing took 0.8185201820015209 seconds)
2022-03-23 10:19:04 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:19:04 | INFO | train | epoch 035 | loss 5.843 | nll_loss 2.778 | ppl 6.86 | wps 45006.3 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.437 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3226
2022-03-23 10:19:04 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:07 | INFO | train_inner | epoch 036:     10 / 157 loss=5.832, nll_loss=2.765, ppl=6.8, wps=36496.7, ups=1.43, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.44, loss_scale=4, train_wall=30, gb_free=14.2, wall=3229
2022-03-23 10:19:39 | INFO | train_inner | epoch 036:    110 / 157 loss=5.787, nll_loss=2.704, ppl=6.52, wps=81674.1, ups=3.18, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.412, loss_scale=4, train_wall=31, gb_free=13.5, wall=3261
2022-03-23 10:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, can expand to form any same glide.
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer, because his father had left his mother when she was pregnant with him.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids, and has an orphanage left, so we asked ourselves, well, what do we do with her?
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other talk.
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:20:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:20:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional face, which gives the big contexts of the face and the basic shape, and recover it through the information that includes the whole portion structure and all the fine.
2022-03-23 10:20:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins, then we support you. "the truth, women is that we love you in this topic for a long time."
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:32 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still necessary, and a large part of the design work that we're on our airplane is stumbling, a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and cooling system, that allows us to use a fluid machine in the air, that allows us to use the aircraft in the same way that you can see that it's going on the ground, or in a mechanical way that's going on.
2022-03-23 10:20:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:32 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.953 | nll_loss 2.656 | ppl 6.3 | bleu 32.92 | wps 4769.1 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.92
2022-03-23 10:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:20:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.92) (writing took 1.7647765230067307 seconds)
2022-03-23 10:20:33 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:20:33 | INFO | train | epoch 036 | loss 5.805 | nll_loss 2.728 | ppl 6.63 | wps 44015.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.408 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3315
2022-03-23 10:20:34 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:51 | INFO | train_inner | epoch 037:     53 / 157 loss=5.803, nll_loss=2.723, ppl=6.6, wps=34311.7, ups=1.4, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.381, loss_scale=4, train_wall=30, gb_free=13.6, wall=3333
2022-03-23 10:21:22 | INFO | train_inner | epoch 037:    153 / 157 loss=5.777, nll_loss=2.691, ppl=6.46, wps=81091.8, ups=3.23, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.398, loss_scale=4, train_wall=31, gb_free=14.7, wall=3364
2022-03-23 10:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:21:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet, of course, can expand to shape any glider.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:21:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:21:42 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:21:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:21:46 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 10:21:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:21:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside, but the superconductor doesn't like it when you move because your movements use energy, and so the superconductor disorder.
2022-03-23 10:21:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflective reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic shape, and recover it through the information that comes from the whole porn structure and all the folds.
2022-03-23 10:21:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it became the best summarized when someone said, "turn to the men at your table and say," if the revolution starts to support you, "the truth, women is that we've already been supporting you for a long time."
2022-03-23 10:21:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:22:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a big part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied gear and cooling system that allows us to use an aircraft machine in the gotraffic until you see the propeller, either when you're going to run it on the floor, and if you're in the same way, and you're going to be able to get the wheels, and you're going to be able to be able to run the wheels, if you're going to run, if you're going to run, and you're going to be able to run, if you're going to run, and you're going to run, if you're going to run, you're going to run, you're in a mechanism, you're going to run, and you're going to run, you're going to see, you're going to run,
2022-03-23 10:22:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:22:00 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.964 | nll_loss 2.655 | ppl 6.3 | bleu 32.81 | wps 4913.1 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.92
2022-03-23 10:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.81) (writing took 0.7895183200016618 seconds)
2022-03-23 10:22:01 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:22:01 | INFO | train | epoch 037 | loss 5.764 | nll_loss 2.673 | ppl 6.38 | wps 44996.3 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.38 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3403
2022-03-23 10:22:02 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:32 | INFO | train_inner | epoch 038:     96 / 157 loss=5.753, nll_loss=2.656, ppl=6.3, wps=35518.7, ups=1.43, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.407, loss_scale=4, train_wall=31, gb_free=13.7, wall=3434
2022-03-23 10:22:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:22:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:22:59 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:22:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, can expand, to form any same glider.
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:23:06 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:23:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:23:14 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal wedding, not about genocide or the spread of nuclear weapons or poverty or any other talk about it.
2022-03-23 10:23:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:23:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside, but the superconductor doesn't like it when you move, because your movements use, and so the superconductor disorder.
2022-03-23 10:23:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional face, which gives the big contextures of the face and the basic shape, and recovers it through the information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:23:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, at the dinner of dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution starts to support you. "the truth, women are supporting you for a long time.
2022-03-23 10:23:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we've stumbled on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied, and a refrigeration system that allows us to use an aircraft in the go-traffic, to a specific passage, either if you were able to operate the propelled, or if you're in the ground, you're going to be able to see the steady, you're going to see the propelled by a mechanism that's going to run.
2022-03-23 10:23:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:28 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.908 | nll_loss 2.61 | ppl 6.11 | bleu 32.98 | wps 4991.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.98
2022-03-23 10:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 32.98) (writing took 1.8958641210047062 seconds)
2022-03-23 10:23:30 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:23:30 | INFO | train | epoch 038 | loss 5.748 | nll_loss 2.651 | ppl 6.28 | wps 44703.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.395 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3492
2022-03-23 10:23:30 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:42 | INFO | train_inner | epoch 039:     39 / 157 loss=5.729, nll_loss=2.625, ppl=6.17, wps=36070.8, ups=1.41, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.375, loss_scale=4, train_wall=31, gb_free=13.1, wall=3504
2022-03-23 10:24:14 | INFO | train_inner | epoch 039:    139 / 157 loss=5.733, nll_loss=2.631, ppl=6.19, wps=80470.7, ups=3.2, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.389, loss_scale=4, train_wall=31, gb_free=13.9, wall=3536
2022-03-23 10:24:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, can expand to shape any same same.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding, not about genocide or spreading nuclear weapons or poverty or any other promising topic.
2022-03-23 10:24:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and the superconductor disorders.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contexts of the face and the basic shape and recover it through the information that refers the whole porter structure and all the fine folds.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution begins to support you. '"the truth, women is that we've been supporting you for a long time.
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:55 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we are proud of at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and refrigerator system that allows us to use an aircraft in the middle of the road to get rid of, either to run the propeller, or if you're in the field, or if you can see it in the wrong way, or if you can see the wheels.
2022-03-23 10:24:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:55 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.933 | nll_loss 2.621 | ppl 6.15 | bleu 32.74 | wps 5084.7 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.98
2022-03-23 10:24:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:24:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.74) (writing took 0.8648832659964683 seconds)
2022-03-23 10:24:56 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:24:56 | INFO | train | epoch 039 | loss 5.717 | nll_loss 2.609 | ppl 6.1 | wps 45540.6 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.385 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 3578
2022-03-23 10:24:57 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:24:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:23 | INFO | train_inner | epoch 040:     82 / 157 loss=5.706, nll_loss=2.593, ppl=6.03, wps=36598, ups=1.45, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.386, loss_scale=4, train_wall=30, gb_free=14.6, wall=3605
2022-03-23 10:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:50 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:25:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:25:54 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 10:25:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example hypothesis: that round magnets, of course, i can also expand to shape any same glider.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:26:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:26:09 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other corresponding topic.
2022-03-23 10:26:09 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:26:13 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:26:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can begin to restore the big contexts of the face and the basic form of it through the whole porter structure and all the fine folds.
2022-03-23 10:26:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons why it's highly interesting and appropriate for me to be here at tedwomen, is that... well, when striking dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, then we support you, 'the truth, women, that we love you for a long time.
2022-03-23 10:26:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're stumbling on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable gear and a cooling system that allows us to use an aircraft on the goodbye to a specific passage, or the propelled system, to be able to be able to get rid of the wrong, all the mechanized by a continuously varied by a continuously variables.
2022-03-23 10:26:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:23 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.912 | nll_loss 2.594 | ppl 6.04 | bleu 33.18 | wps 4872.7 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.18
2022-03-23 10:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 40 @ 6275 updates, score 33.18) (writing took 1.7999816329975147 seconds)
2022-03-23 10:26:25 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:26:25 | INFO | train | epoch 040 | loss 5.696 | nll_loss 2.58 | ppl 5.98 | wps 44357.6 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.383 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3667
2022-03-23 10:26:26 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:33 | INFO | train_inner | epoch 041:     25 / 157 loss=5.672, nll_loss=2.55, ppl=5.86, wps=34425.8, ups=1.41, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.406, loss_scale=4, train_wall=30, gb_free=13.7, wall=3675
2022-03-23 10:27:05 | INFO | train_inner | epoch 041:    125 / 157 loss=5.67, nll_loss=2.545, ppl=5.83, wps=81619.8, ups=3.19, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.387, loss_scale=4, train_wall=31, gb_free=13.9, wall=3707
2022-03-23 10:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can also expand to shape any same same same.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:27:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like identical wedding, not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:27:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:27:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which gives the big contexts of the face and the basic form, and through the information that refers the whole porous structure and all the fine wrinkles.
2022-03-23 10:27:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when constrict dinner, it was best summarized when someone said, "turn to the men at your table and say to them, 'when the revolution begins, we support you.'" the truth, women is that we have supported you for a long time. "
2022-03-23 10:27:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously varied gear and a cooling system with liquid coolness that allows us to use an aircraft in the goodbye, or if you were driving the propellant, or in the ground, if you were mechanized.
2022-03-23 10:27:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:51 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.919 | nll_loss 2.592 | ppl 6.03 | bleu 33 | wps 5046.4 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.18
2022-03-23 10:27:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:27:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:27:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.0) (writing took 0.7991179130040109 seconds)
2022-03-23 10:27:52 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:27:52 | INFO | train | epoch 041 | loss 5.678 | nll_loss 2.556 | ppl 5.88 | wps 45486.3 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.397 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3754
2022-03-23 10:27:52 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:27:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:28:14 | INFO | train_inner | epoch 042:     68 / 157 loss=5.637, nll_loss=2.501, ppl=5.66, wps=37311, ups=1.45, wpb=25777.1, bsz=1074.2, num_updates=6500, lr=0.000392232, gnorm=0.367, loss_scale=4, train_wall=30, gb_free=13.6, wall=3776
2022-03-23 10:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:45 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:28:45 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:28:53 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that round magnets to form any glider.
2022-03-23 10:28:53 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:28:57 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:28:57 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we said, well, what do we do with her?
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal marriage, not about genocide, or the spread of nuclear weapons or poverty, or any other talking about it.
2022-03-23 10:29:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bins of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disturbs.
2022-03-23 10:29:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can, which gives the big contexts of the face and the basic shape back, and then advance it through the information that refers the whole portion structure and all the folds.
2022-03-23 10:29:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was the best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, then we support you. '"the truth, women are helping you at this point for a long time.
2022-03-23 10:29:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a great part of the design work that we're stumbling on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and cooling system that allows us to use an aircraft in the go-transportation to a special passage, either the propellant, or if you get rid of the propelled, if you're going to be able to operate on the ground -- everything from a continuously varied to a continuously variable system.
2022-03-23 10:29:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:19 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.884 | nll_loss 2.57 | ppl 5.94 | bleu 33.79 | wps 4880.1 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.79
2022-03-23 10:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt
2022-03-23 10:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_best.pt (epoch 42 @ 6589 updates, score 33.79) (writing took 1.8064564670057734 seconds)
2022-03-23 10:29:21 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:29:21 | INFO | train | epoch 042 | loss 5.652 | nll_loss 2.522 | ppl 5.74 | wps 44375.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.382 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 3843
2022-03-23 10:29:21 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:25 | INFO | train_inner | epoch 043:     11 / 157 loss=5.683, nll_loss=2.563, ppl=5.91, wps=34591.8, ups=1.41, wpb=24614, bsz=951.5, num_updates=6600, lr=0.000389249, gnorm=0.388, loss_scale=4, train_wall=30, gb_free=14.3, wall=3847
2022-03-23 10:29:56 | INFO | train_inner | epoch 043:    111 / 157 loss=5.628, nll_loss=2.487, ppl=5.61, wps=80330.8, ups=3.23, wpb=24831.9, bsz=987.7, num_updates=6700, lr=0.000386334, gnorm=0.383, loss_scale=4, train_wall=30, gb_free=13.9, wall=3878
2022-03-23 10:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example hypothesis: it can occupy about 8,000 places in the restaurant.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: i can, of course, expand that round magnets to shape any same glide.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal marriage and not genocide or the spread of nuclear weapons or poverty or anything else.
2022-03-23 10:30:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:30:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:30:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big contexts of the face and the basic shape, and refers it through the information that includes the whole porn structure and all the fine folds.
2022-03-23 10:30:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when contested dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins to support you. '"the truth, women, we love you, that we've already been supporting you at this point for a long time." at the time, carchel borra, "and we've started to downstream," and say to the future of sand stream. "
2022-03-23 10:30:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a great part of the design work that we're most proud of on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously varied gear and a cooling system that allows us to use an aircraft in the stop and goodbye to a special passage, either if you're the propelled to be able to operate on the ground -- all the mechanism that we're going to be able to see in the wrong way.
2022-03-23 10:30:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:48 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.884 | nll_loss 2.557 | ppl 5.88 | bleu 33.48 | wps 4819.3 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.79
2022-03-23 10:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:30:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.48) (writing took 0.8302189909882145 seconds)
2022-03-23 10:30:49 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:30:49 | INFO | train | epoch 043 | loss 5.629 | nll_loss 2.49 | ppl 5.62 | wps 44973.9 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.375 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3931
2022-03-23 10:30:49 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:06 | INFO | train_inner | epoch 044:     54 / 157 loss=5.614, nll_loss=2.47, ppl=5.54, wps=35665.9, ups=1.42, wpb=25094.8, bsz=1059.9, num_updates=6800, lr=0.000383482, gnorm=0.38, loss_scale=4, train_wall=31, gb_free=14.7, wall=3948
2022-03-23 10:31:37 | INFO | train_inner | epoch 044:    154 / 157 loss=5.622, nll_loss=2.48, ppl=5.58, wps=82095.8, ups=3.21, wpb=25554.9, bsz=1021.8, num_updates=6900, lr=0.000380693, gnorm=0.373, loss_scale=4, train_wall=31, gb_free=13.6, wall=3979
2022-03-23 10:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:31:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:31:46 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occur about 8,000 places in the restaurant.
2022-03-23 10:31:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:31:50 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand that round magnets to form any glimpse.
2022-03-23 10:31:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:31:54 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 10:31:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:31:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we wondered, well, what do we do with her?
2022-03-23 10:31:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equal wedding, not about genocide, or the spread of nuclear weapons or poverty, or any other excuse topic.
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:32:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconducting disorder is.
2022-03-23 10:32:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:10 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can, which gives the big contexts of the face and the basic form, and adding it through that information that includes the whole porter structure and all the fine wrinkles.
2022-03-23 10:32:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to the men to your table and say to them," when the revolution begins, then we support you. '"the truth, love, women, we have supported you at this point for a long time.
2022-03-23 10:32:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we've stumbled on our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable gear and a cooling system with fluid that allows us to use an aircraft in stop and go-traffic, to a special passage, either the propelled, or the propelled, to the floor.
2022-03-23 10:32:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:15 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.88 | nll_loss 2.574 | ppl 5.95 | bleu 33.76 | wps 5009.4 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.79
2022-03-23 10:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.76) (writing took 0.8620487779990071 seconds)
2022-03-23 10:32:16 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:32:16 | INFO | train | epoch 044 | loss 5.613 | nll_loss 2.468 | ppl 5.53 | wps 45481 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.381 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4018
2022-03-23 10:32:16 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:32:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:47 | INFO | train_inner | epoch 045:     97 / 157 loss=5.598, nll_loss=2.445, ppl=5.45, wps=36682.4, ups=1.45, wpb=25370.2, bsz=970.1, num_updates=7000, lr=0.000377964, gnorm=0.368, loss_scale=4, train_wall=31, gb_free=13.7, wall=4049
2022-03-23 10:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:33:12 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 10:33:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 10:33:16 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can expand that round magnets to shape any same glide.
2022-03-23 10:33:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 10:33:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other talk.
2022-03-23 10:33:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 10:33:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:33:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional face can that refers the big contexts of the face and the basic shape, and refuse it through that kind of information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:33:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when rachel's dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, then we support you. '' "the truth, love, women, we've been supporting you at this topic for a long time. at rachel carchent's time, and then, with silent boro," cake boro, "and then it's a stle," and we've got it's all got it's the way back to have it's the future of sand stream of sand stream, "and say," and say, "when someone said," when someone said, "turn you know," when they're going to the
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're stumbling on on our plane, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuous variation and refrigeration system that allows us to use an aircraft in the goodbye to a particular passage, to a special passage, either passenger passage, either if you have to solve the unique thing that drives the propelled, or propheed, if you have to operate, if you can see the propelled, if you can see the propheed, if you can see a mechanism, if you can see a mechanism, if you can see it's going to run it's going to operate at the wrong thing, from a continuously variable system that's going to run it's going to run it at the land, from a continuously varied, from a continuously variable system,
2022-03-23 10:33:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:43 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.869 | nll_loss 2.564 | ppl 5.91 | bleu 33.69 | wps 4750.1 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.79
2022-03-23 10:33:43 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:33:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:33:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt
2022-03-23 10:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#4/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.69) (writing took 0.8441761759895599 seconds)
2022-03-23 10:33:44 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:33:44 | INFO | train | epoch 045 | loss 5.596 | nll_loss 2.444 | ppl 5.44 | wps 44736.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.385 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 4106
2022-03-23 10:33:44 | INFO | fairseq_cli.train | done training in 4105.6 seconds
