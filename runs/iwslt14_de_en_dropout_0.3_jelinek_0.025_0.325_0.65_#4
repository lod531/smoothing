Sender: LSF System <lsfadmin@eu-g3-062>
Subject: Job 210595554: <iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:36:14 2022
Job was executed on host(s) <eu-g3-062>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:36:27 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:36:27 2022
Terminated at Wed Mar 23 12:32:35 2022
Results reported at Wed Mar 23 12:32:35 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.025,0.325,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3356.72 sec.
    Max Memory :                                 4998 MB
    Average Memory :                             3883.27 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15002.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   3387 sec.
    Turnaround time :                            3381 sec.

The output (if any) follows:

2022-03-23 11:36:34 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.025,0.325,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.025,0.325,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:36:34 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:36:34 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:36:35 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:36:35 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:36:35 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1097/160239 [00:00<00:14, 10965.78it/s]  2%|▏         | 2421/160239 [00:00<00:12, 12299.31it/s]  2%|▏         | 3773/160239 [00:00<00:12, 12856.03it/s]  3%|▎         | 5091/160239 [00:00<00:11, 12978.20it/s]  4%|▍         | 6389/160239 [00:00<00:12, 12783.58it/s]  5%|▍         | 7668/160239 [00:00<00:12, 12623.23it/s]  6%|▌         | 8931/160239 [00:00<00:12, 12472.97it/s]  6%|▋         | 10252/160239 [00:00<00:11, 12702.53it/s]  7%|▋         | 11542/160239 [00:00<00:11, 12762.80it/s]  8%|▊         | 12819/160239 [00:01<00:11, 12746.24it/s]  9%|▉         | 14095/160239 [00:01<00:11, 12749.34it/s] 10%|▉         | 15371/160239 [00:01<00:11, 12550.98it/s] 10%|█         | 16627/160239 [00:01<00:11, 12342.99it/s] 11%|█         | 17863/160239 [00:01<00:11, 12244.23it/s] 12%|█▏        | 19116/160239 [00:01<00:11, 12328.03it/s] 13%|█▎        | 20506/160239 [00:01<00:10, 12791.26it/s] 14%|█▎        | 21787/160239 [00:01<00:11, 12405.79it/s] 14%|█▍        | 23031/160239 [00:01<00:11, 12348.49it/s] 15%|█▌        | 24289/160239 [00:01<00:10, 12414.26it/s] 16%|█▌        | 25595/160239 [00:02<00:10, 12602.94it/s] 17%|█▋        | 26857/160239 [00:02<00:10, 12367.54it/s] 18%|█▊        | 28208/160239 [00:02<00:10, 12701.37it/s] 18%|█▊        | 29481/160239 [00:02<00:10, 12644.56it/s] 19%|█▉        | 30747/160239 [00:02<00:10, 12244.67it/s] 20%|██        | 32134/160239 [00:02<00:10, 12713.24it/s] 21%|██        | 33410/160239 [00:02<00:10, 12475.25it/s] 22%|██▏       | 34661/160239 [00:02<00:10, 12276.13it/s] 22%|██▏       | 35948/160239 [00:02<00:09, 12448.02it/s] 23%|██▎       | 37196/160239 [00:02<00:09, 12433.78it/s] 24%|██▍       | 38494/160239 [00:03<00:09, 12588.78it/s] 25%|██▍       | 39755/160239 [00:03<00:09, 12497.00it/s] 26%|██▌       | 41080/160239 [00:03<00:09, 12719.37it/s] 26%|██▋       | 42353/160239 [00:03<00:09, 12375.41it/s] 27%|██▋       | 43594/160239 [00:03<00:09, 12293.39it/s] 28%|██▊       | 44825/160239 [00:03<00:09, 12152.18it/s] 29%|██▉       | 46170/160239 [00:03<00:09, 12530.84it/s] 30%|██▉       | 47458/160239 [00:03<00:08, 12629.18it/s] 30%|███       | 48723/160239 [00:03<00:08, 12431.46it/s] 31%|███       | 50019/160239 [00:03<00:08, 12586.54it/s] 32%|███▏      | 51309/160239 [00:04<00:08, 12677.79it/s] 33%|███▎      | 52627/160239 [00:04<00:08, 12826.78it/s] 34%|███▎      | 53911/160239 [00:04<00:08, 12678.20it/s] 34%|███▍      | 55180/160239 [00:04<00:08, 12617.29it/s] 35%|███▌      | 56443/160239 [00:04<00:08, 12578.99it/s] 36%|███▌      | 57736/160239 [00:04<00:08, 12682.32it/s] 37%|███▋      | 59066/160239 [00:04<00:07, 12863.18it/s] 38%|███▊      | 60380/160239 [00:04<00:07, 12944.61it/s] 38%|███▊      | 61675/160239 [00:04<00:07, 12522.03it/s] 39%|███▉      | 63042/160239 [00:05<00:07, 12856.60it/s] 40%|████      | 64331/160239 [00:05<00:07, 12834.49it/s] 41%|████      | 65770/160239 [00:05<00:07, 13293.92it/s] 42%|████▏     | 67102/160239 [00:05<00:07, 13084.76it/s] 43%|████▎     | 68413/160239 [00:05<00:07, 12985.25it/s] 44%|████▎     | 69713/160239 [00:05<00:07, 12495.18it/s] 44%|████▍     | 71053/160239 [00:05<00:06, 12755.23it/s] 45%|████▌     | 72333/160239 [00:05<00:06, 12622.22it/s] 46%|████▌     | 73599/160239 [00:05<00:06, 12475.55it/s] 47%|████▋     | 74849/160239 [00:05<00:06, 12415.13it/s] 47%|████▋     | 76102/160239 [00:06<00:06, 12441.13it/s] 48%|████▊     | 77463/160239 [00:06<00:06, 12783.01it/s] 49%|████▉     | 78750/160239 [00:06<00:06, 12807.56it/s] 50%|████▉     | 80086/160239 [00:06<00:06, 12970.69it/s] 51%|█████     | 81500/160239 [00:06<00:05, 13316.88it/s] 52%|█████▏    | 82833/160239 [00:06<00:05, 13148.77it/s] 53%|█████▎    | 84149/160239 [00:06<00:05, 12945.97it/s] 53%|█████▎    | 85474/160239 [00:06<00:05, 13030.94it/s] 54%|█████▍    | 86869/160239 [00:06<00:05, 13300.36it/s] 55%|█████▌    | 88201/160239 [00:06<00:05, 13027.91it/s] 56%|█████▌    | 89535/160239 [00:07<00:05, 13118.61it/s] 57%|█████▋    | 90849/160239 [00:07<00:05, 13011.39it/s] 58%|█████▊    | 92152/160239 [00:07<00:05, 12886.73it/s] 58%|█████▊    | 93459/160239 [00:07<00:05, 12938.01it/s] 59%|█████▉    | 94754/160239 [00:07<00:05, 12600.51it/s] 60%|█████▉    | 96075/160239 [00:07<00:05, 12775.87it/s] 61%|██████    | 97355/160239 [00:07<00:04, 12752.27it/s] 62%|██████▏   | 98632/160239 [00:07<00:04, 12511.96it/s] 62%|██████▏   | 99974/160239 [00:07<00:04, 12777.06it/s] 63%|██████▎   | 101305/160239 [00:07<00:04, 12934.09it/s] 64%|██████▍   | 102600/160239 [00:08<00:04, 12744.75it/s] 65%|██████▍   | 103876/160239 [00:08<00:04, 12614.89it/s] 66%|██████▌   | 105265/160239 [00:08<00:04, 12987.69it/s] 67%|██████▋   | 106566/160239 [00:08<00:04, 12938.60it/s] 67%|██████▋   | 107861/160239 [00:08<00:04, 12591.24it/s] 68%|██████▊   | 109123/160239 [00:08<00:04, 12340.34it/s] 69%|██████▉   | 110379/160239 [00:08<00:04, 12401.18it/s] 70%|██████▉   | 111748/160239 [00:08<00:03, 12775.18it/s] 71%|███████   | 113028/160239 [00:08<00:03, 12631.27it/s] 71%|███████▏  | 114346/160239 [00:09<00:03, 12791.44it/s] 72%|███████▏  | 115627/160239 [00:09<00:03, 12793.78it/s] 73%|███████▎  | 116908/160239 [00:09<00:03, 12579.83it/s] 74%|███████▍  | 118233/160239 [00:09<00:03, 12776.02it/s] 75%|███████▍  | 119563/160239 [00:09<00:03, 12930.01it/s] 75%|███████▌  | 120858/160239 [00:09<00:03, 12668.00it/s] 76%|███████▋  | 122311/160239 [00:09<00:02, 13212.96it/s] 77%|███████▋  | 123635/160239 [00:09<00:02, 12988.48it/s] 78%|███████▊  | 124937/160239 [00:09<00:02, 12705.60it/s] 79%|███████▉  | 126216/160239 [00:09<00:02, 12729.89it/s] 80%|███████▉  | 127493/160239 [00:10<00:02, 12740.44it/s] 80%|████████  | 128829/160239 [00:10<00:02, 12920.94it/s] 81%|████████  | 130123/160239 [00:10<00:02, 12472.85it/s] 82%|████████▏ | 131427/160239 [00:10<00:02, 12634.47it/s] 83%|████████▎ | 132704/160239 [00:10<00:02, 12664.34it/s] 84%|████████▎ | 133973/160239 [00:10<00:02, 12321.56it/s] 84%|████████▍ | 135229/160239 [00:10<00:02, 12386.58it/s] 85%|████████▌ | 136555/160239 [00:10<00:01, 12641.72it/s] 86%|████████▌ | 137874/160239 [00:10<00:01, 12802.81it/s] 87%|████████▋ | 139196/160239 [00:10<00:01, 12925.09it/s] 88%|████████▊ | 140557/160239 [00:11<00:01, 13126.40it/s] 89%|████████▊ | 141871/160239 [00:11<00:01, 12852.16it/s] 89%|████████▉ | 143162/160239 [00:11<00:01, 12867.28it/s] 90%|█████████ | 144451/160239 [00:11<00:01, 12750.64it/s] 91%|█████████ | 145728/160239 [00:11<00:01, 12631.37it/s] 92%|█████████▏| 146992/160239 [00:11<00:01, 12427.26it/s] 93%|█████████▎| 148248/160239 [00:11<00:00, 12461.75it/s] 93%|█████████▎| 149495/160239 [00:11<00:00, 12243.06it/s] 94%|█████████▍| 150816/160239 [00:11<00:00, 12524.33it/s] 95%|█████████▍| 152093/160239 [00:11<00:00, 12595.62it/s] 96%|█████████▌| 153354/160239 [00:12<00:00, 12597.13it/s] 97%|█████████▋| 154651/160239 [00:12<00:00, 12706.74it/s] 97%|█████████▋| 155975/160239 [00:12<00:00, 12863.81it/s] 98%|█████████▊| 157300/160239 [00:12<00:00, 12978.38it/s] 99%|█████████▉| 158599/160239 [00:12<00:00, 12636.79it/s]100%|█████████▉| 159944/160239 [00:12<00:00, 12873.73it/s]100%|██████████| 160239/160239 [00:12<00:00, 12689.59it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3792/160239 [00:00<00:04, 37915.43it/s]  5%|▍         | 7642/160239 [00:00<00:03, 38250.88it/s]  7%|▋         | 11517/160239 [00:00<00:03, 38473.83it/s] 10%|▉         | 15365/160239 [00:00<00:03, 38267.62it/s] 12%|█▏        | 19192/160239 [00:00<00:03, 38034.89it/s] 14%|█▍        | 23008/160239 [00:00<00:03, 38075.42it/s] 17%|█▋        | 26820/160239 [00:00<00:03, 38084.80it/s] 19%|█▉        | 30629/160239 [00:00<00:03, 38000.14it/s] 22%|██▏       | 34492/160239 [00:00<00:03, 38191.91it/s] 24%|██▍       | 38312/160239 [00:01<00:03, 38098.23it/s] 26%|██▋       | 42122/160239 [00:01<00:03, 38014.09it/s] 29%|██▊       | 45924/160239 [00:01<00:03, 37929.67it/s] 31%|███       | 49764/160239 [00:01<00:02, 38069.75it/s] 33%|███▎      | 53572/160239 [00:01<00:02, 36666.46it/s] 36%|███▌      | 57512/160239 [00:01<00:02, 37465.22it/s] 38%|███▊      | 61348/160239 [00:01<00:02, 37727.81it/s] 41%|████      | 65460/160239 [00:01<00:02, 38730.67it/s] 43%|████▎     | 69340/160239 [00:01<00:02, 38291.77it/s] 46%|████▌     | 73175/160239 [00:01<00:02, 38231.17it/s] 48%|████▊     | 77029/160239 [00:02<00:02, 38322.10it/s] 51%|█████     | 81101/160239 [00:02<00:02, 39035.16it/s] 53%|█████▎    | 85008/160239 [00:02<00:01, 38819.03it/s] 56%|█████▌    | 89026/160239 [00:02<00:01, 39221.62it/s] 58%|█████▊    | 92950/160239 [00:02<00:01, 38882.49it/s] 60%|██████    | 96840/160239 [00:02<00:01, 38583.30it/s] 63%|██████▎   | 100850/160239 [00:02<00:01, 39031.77it/s] 65%|██████▌   | 104755/160239 [00:02<00:01, 38939.40it/s] 68%|██████▊   | 108650/160239 [00:02<00:01, 38640.39it/s] 70%|███████   | 112516/160239 [00:02<00:01, 38561.55it/s] 73%|███████▎  | 116382/160239 [00:03<00:01, 38585.30it/s] 75%|███████▌  | 120255/160239 [00:03<00:01, 38627.80it/s] 78%|███████▊  | 124198/160239 [00:03<00:00, 38863.79it/s] 80%|███████▉  | 128085/160239 [00:03<00:00, 38826.99it/s] 82%|████████▏ | 131968/160239 [00:03<00:00, 38258.87it/s] 85%|████████▍ | 135796/160239 [00:03<00:00, 38135.28it/s] 87%|████████▋ | 139611/160239 [00:03<00:00, 37167.52it/s] 90%|████████▉ | 143507/160239 [00:03<00:00, 37687.02it/s] 92%|█████████▏| 147281/160239 [00:03<00:00, 37701.42it/s] 94%|█████████▍| 151055/160239 [00:03<00:00, 37569.98it/s] 97%|█████████▋| 154973/160239 [00:04<00:00, 38045.19it/s] 99%|█████████▉| 158825/160239 [00:04<00:00, 38185.06it/s]100%|██████████| 160239/160239 [00:04<00:00, 38273.98it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2218.03it/s]2022-03-23 11:36:54 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:36:54 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:36:54 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:36:54 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:36:54 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:36:54 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:36:54 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:36:54 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:36:54 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:36:54 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:36:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:36:54 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:36:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:36:54 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:36:54 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:36:54 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:36:54 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:36:54 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:36:54 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:36:54 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:36:54 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:36:55 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:36:55 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:36:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:36:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:36:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:37:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:37:36 | INFO | train_inner | epoch 001:    104 / 157 loss=13.09, ppl=8718.43, wps=65789.8, ups=2.62, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.739, loss_scale=8, train_wall=41, gb_free=11.8, wall=42
2022-03-23 11:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:37:59 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:37:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:38:02 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:38:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:38:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:38:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:38:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:38:09 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:38:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:38:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:38:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:38:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:38:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:38:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:38:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:38:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:38:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:38:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:38:37 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:38:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:38:37 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.274 | ppl 4953.8 | bleu 0.01 | wps 4358.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:38:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:38:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:38:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.726789693115279 seconds)
2022-03-23 11:38:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:38:38 | INFO | train | epoch 001 | loss 12.552 | ppl 6003.86 | wps 38134.2 | ups 1.52 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.85 | loss_scale 8 | train_wall 60 | gb_free 12.1 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.5832649092701596 Unigram: 1.4409332018136412
2022-03-23 11:38:39 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:38:56 | INFO | train_inner | epoch 002:     47 / 157 loss=11.304, ppl=2528.59, wps=31184.7, ups=1.25, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.16, loss_scale=8, train_wall=36, gb_free=22.3, wall=122
2022-03-23 11:39:34 | INFO | train_inner | epoch 002:    147 / 157 loss=10.599, ppl=1550.67, wps=66538, ups=2.66, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.825, loss_scale=8, train_wall=37, gb_free=12.1, wall=160
2022-03-23 11:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:39:41 | INFO | fairseq.tasks.translation | example hypothesis: .
2022-03-23 11:39:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:39:43 | INFO | fairseq.tasks.translation | example hypothesis: the the.
2022-03-23 11:39:43 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:39:46 | INFO | fairseq.tasks.translation | example hypothesis: i i i.
2022-03-23 11:39:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:39:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the.
2022-03-23 11:39:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:39:53 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we.
2022-03-23 11:39:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:39:57 | INFO | fairseq.tasks.translation | example hypothesis: and and and and the the the the the the the the the the the the the the.
2022-03-23 11:39:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:40:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:40:08 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and the the the the the the the the the the the the the the and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and
2022-03-23 11:40:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:40:15 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:40:17 | INFO | fairseq.tasks.translation | example hypothesis: and the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:40:17 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.333 | ppl 2579.06 | bleu 0.02 | wps 4445.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.8102872970048338 seconds)
2022-03-23 11:40:19 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:40:19 | INFO | train | epoch 002 | loss 10.692 | ppl 1653.96 | wps 39127 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.919 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 205
KL Stats: Epoch 2 Divergences: Uniform: 0.865238849485261 Unigram: 0.29665647518847116
2022-03-23 11:40:20 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:40:54 | INFO | train_inner | epoch 003:     90 / 157 loss=10.302, ppl=1262.77, wps=31258.9, ups=1.25, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.835, loss_scale=8, train_wall=37, gb_free=12, wall=239
2022-03-23 11:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:22 | INFO | fairseq.tasks.translation | example hypothesis: and you.
2022-03-23 11:41:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:41:26 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the.
2022-03-23 11:41:26 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:41:30 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i
2022-03-23 11:41:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:41:35 | INFO | fairseq.tasks.translation | example hypothesis: and i was, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:41:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we
2022-03-23 11:41:41 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:41:47 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, and we, we, we, we, we, and and we to to the the the the the the
2022-03-23 11:41:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:41:53 | INFO | fairseq.tasks.translation | example hypothesis: and and the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:41:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:41:59 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, and the the the the the, and the the, and and and we the the the the the the the the, and and and the the the, we, and and and the the the the the the the the the the the the the the, and and and and and and and we the the, and and and we the the the, and and we the the the, we
2022-03-23 11:41:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, "" "" "the," "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, we we we we we the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, we we we we we we we we the, the, the, the, the, the, the, the, the, the, the,
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.157 | ppl 2283.9 | bleu 0.19 | wps 3501.6 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.19
2022-03-23 11:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.19) (writing took 1.8533162579406053 seconds)
2022-03-23 11:42:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:42:11 | INFO | train | epoch 003 | loss 10.206 | ppl 1180.9 | wps 35489.6 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.92 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 316
KL Stats: Epoch 3 Divergences: Uniform: 1.314651090910886 Unigram: 0.15213764560892568
2022-03-23 11:42:11 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:24 | INFO | train_inner | epoch 004:     33 / 157 loss=10.083, ppl=1084.69, wps=28468.8, ups=1.11, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=0.95, loss_scale=8, train_wall=37, gb_free=12, wall=329
2022-03-23 11:43:01 | INFO | train_inner | epoch 004:    133 / 157 loss=9.96, ppl=996.21, wps=67259.8, ups=2.67, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.104, loss_scale=8, train_wall=37, gb_free=12.4, wall=367
2022-03-23 11:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:14 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can see.
2022-03-23 11:43:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:43:18 | INFO | fairseq.tasks.translation | example hypothesis: and he he he he he he he he he he he he he he he he he.
2022-03-23 11:43:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:43:23 | INFO | fairseq.tasks.translation | example hypothesis: and i think i'm'm to to a a of the world of a of a of a of a of a of the world of a of a of a of a of a
2022-03-23 11:43:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:43:28 | INFO | fairseq.tasks.translation | example hypothesis: and he was was was he he he was was was was he he was was was he he he was was was was was was was was was was was he he he he he was was was was was was
2022-03-23 11:43:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example hypothesis: and what we're to do, we can can do we can can can do we can can can can can can can can can can can can can can can can can can can can can can can can can can can can do that we're
2022-03-23 11:43:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:43:38 | INFO | fairseq.tasks.translation | example hypothesis: and we know, and we can can can can can can can can can can can can or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or.
2022-03-23 11:43:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example hypothesis: and it's the, but it's the world, and they're're're, and they're're're the world.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:50 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we have the world of the world, and we can can can can can can can can can can can see the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the world, and we can can can see the
2022-03-23 11:43:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:57 | INFO | fairseq.tasks.translation | example hypothesis: and we're, "" "that," "" "" "" you're, "" you're, "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" the the, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "the
2022-03-23 11:43:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:59 | INFO | fairseq.tasks.translation | example hypothesis: and we're that that's the world of the world, and we have the world of the world, and it's the world of the world of the world of the world, and it's the world of the world, and we have the world of the world, and we can can can can can can can can can can can can can can see the world of the world, and it's the world of the world, and it's the world, and that that that that that that that that, and the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and it's the world of the world of the world, and we have the world of the world, and we have the world of the world of the world, and that we have the world, and that we're're're're're're're're're're're're're're're're're're're're're're're're're're're the world, and the
2022-03-23 11:43:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:59 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.945 | ppl 1971.81 | bleu 0.99 | wps 3610.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.99
2022-03-23 11:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.99) (writing took 1.8905177968554199 seconds)
2022-03-23 11:44:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:44:01 | INFO | train | epoch 004 | loss 10.026 | ppl 1042.63 | wps 35765.6 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.005 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 427
KL Stats: Epoch 4 Divergences: Uniform: 1.4278565019429577 Unigram: 0.22456336376316893
2022-03-23 11:44:01 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:30 | INFO | train_inner | epoch 005:     76 / 157 loss=9.873, ppl=937.87, wps=28193.4, ups=1.12, wpb=25097.7, bsz=1058.7, num_updates=700, lr=8.75e-05, gnorm=1.154, loss_scale=8, train_wall=37, gb_free=11.9, wall=456
2022-03-23 11:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:04 | INFO | fairseq.tasks.translation | example hypothesis: so this is a lot.
2022-03-23 11:45:04 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example hypothesis: he's a lot of the.
2022-03-23 11:45:08 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:45:12 | INFO | fairseq.tasks.translation | example hypothesis: and i think that's a lot of a lot of a lot of a lot of a lot of the world, i can can can be a lot of the world.
2022-03-23 11:45:12 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was, he was he was he was he was he was he was he was a lot.
2022-03-23 11:45:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:45:21 | INFO | fairseq.tasks.translation | example hypothesis: and what we have a lot of what we have a lot of what we have to do, and we have a lot of a lot of the world, and we have a lot of a lot of the world, and we have a lot of
2022-03-23 11:45:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do, we have the world, and we have to do, or the world.
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:45:32 | INFO | fairseq.tasks.translation | example hypothesis: but you're a lot of the world, but they're a lot of the world, but they're a lot of the world, but they're a lot of the world.
2022-03-23 11:45:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:37 | INFO | fairseq.tasks.translation | example hypothesis: and we have a lot of the world, and we can see that we can see the world, and we can see the world, and we can see the world of the world of the world of the world, and we can see the world.
2022-03-23 11:45:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:44 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "," we have a lot, "" "" "we have to do," we're a lot of the world, ",", "" "" "" we have to do, "" "" "" "" "" "" "" "" "" "" "" "" we're the first first first first first first first first first first first first first first first first first first first first first first first first, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we're," "we're," "we're," "" we have to do, "" "" "" "" "" "" "" "" ""
2022-03-23 11:45:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:46 | INFO | fairseq.tasks.translation | example hypothesis: so, we have the world, and we have the world of the world, we have to have the world of the world, the world of the world of the world of the world, and we have the world, and we have the world of the world of the world of the world of the world of the world of the world of the world of the world, the world, the world, and the world, and we have to do the world, and we have the world, we have to do that we have the world, and the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, the world, and we have the world, and we have the world, that we're, and we have the world of the world of the world of the world of the world of the world of the world of the world of the world, and we have the world, and we have the world of the world of the world of the world, and the
2022-03-23 11:45:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.721 | ppl 1687.57 | bleu 1.78 | wps 3865.3 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.78
2022-03-23 11:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.78) (writing took 1.8762368471361697 seconds)
2022-03-23 11:45:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:45:48 | INFO | train | epoch 005 | loss 9.826 | ppl 907.74 | wps 36780 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.076 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 534
KL Stats: Epoch 5 Divergences: Uniform: 1.4998208624846916 Unigram: 0.31577067872213926
2022-03-23 11:45:49 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:45:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:56 | INFO | train_inner | epoch 006:     19 / 157 loss=9.837, ppl=914.58, wps=29094.8, ups=1.16, wpb=25039.8, bsz=950.1, num_updates=800, lr=0.0001, gnorm=0.962, loss_scale=8, train_wall=37, gb_free=12, wall=542
2022-03-23 11:46:34 | INFO | train_inner | epoch 006:    119 / 157 loss=9.655, ppl=806.39, wps=67055.2, ups=2.67, wpb=25126.8, bsz=945, num_updates=900, lr=0.0001125, gnorm=0.968, loss_scale=8, train_wall=37, gb_free=11.5, wall=579
2022-03-23 11:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:52 | INFO | fairseq.tasks.translation | example hypothesis: this is not not, these.
2022-03-23 11:46:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:46:57 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of.
2022-03-23 11:46:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example hypothesis: and i can be a lot of this, i can be a lot of this, i can be a lot of the way that i can be a lot of this.
2022-03-23 11:47:02 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:47:08 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was a lot of he was, he was a lot of he was, he was a lot of he was he was he was he was, he was a, and he was he was
2022-03-23 11:47:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, and we're going to do, what we're going to do, and we're going to do, and we're going to do, what we're going to do we're going to do we
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:47:19 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do the world, or or we're going to do the world, or or or or or we're going to do, or we're going to do, or the world, or or the world, and we're going to do we're going to do we're
2022-03-23 11:47:19 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be, you're going to be a lot of the way, you're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to be, but they're going to
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:31 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to see the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to get the world, and we're going to do, and we're going to
2022-03-23 11:47:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" "" we're going to be, "" "" "" "" "we're going to say," it's going to say, "it's going to say," it's going to say, "" "" "" "" "" "" "" "" "" "" "we're going to say," it's, "it's going to say," it's, "it's going to say," it's, "it's," it's a, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" we're, "we're going to say," "we're going to say," "" "" "" "" "" "we're
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:41 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to the world, we're going to the world, we're going to see the world, that we're going to the world, we're going to see the world, we're going to see the world of the world, and we're going to get the world, we're going to get the world of the world, and we're going to get the world, it's going to get the world, we're going to get the world, the world of the world, the world, the world, the world, the world, the world, the world, the world, the world of the world, the world, we're going to get the world, and we're going to the world, we're going to do the world, we're going to do the world, we're going to do the world, we're going to be the world, we're going to see the world, we're going to be the world, and we're going to the world, it's going to do the world of the world,
2022-03-23 11:47:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:41 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.562 | ppl 1512 | bleu 1.48 | wps 3312.1 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.78
2022-03-23 11:47:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:47:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:47:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.48) (writing took 0.8368575470522046 seconds)
2022-03-23 11:47:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:47:42 | INFO | train | epoch 006 | loss 9.627 | ppl 790.83 | wps 34666.7 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.991 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 648
KL Stats: Epoch 6 Divergences: Uniform: 1.564411146729412 Unigram: 0.3969132789331329
2022-03-23 11:47:43 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:47:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:06 | INFO | train_inner | epoch 007:     62 / 157 loss=9.6, ppl=776.12, wps=26933.1, ups=1.08, wpb=24967.7, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.918, loss_scale=8, train_wall=37, gb_free=12.4, wall=672
2022-03-23 11:48:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:45 | INFO | fairseq.tasks.translation | example hypothesis: these are.
2022-03-23 11:48:45 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:48:49 | INFO | fairseq.tasks.translation | example hypothesis: and he's going to.
2022-03-23 11:48:49 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:48:52 | INFO | fairseq.tasks.translation | example hypothesis: now, i can make this.
2022-03-23 11:48:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example hypothesis: he said, he said, he said, he was a, because he said, because he was he was he was a, he said, because he was a, he said, he had had had had
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:49:00 | INFO | fairseq.tasks.translation | example hypothesis: so what we're going to do?
2022-03-23 11:49:00 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:49:03 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 11:49:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of the, they're going to be, they're going to be, but they're going.
2022-03-23 11:49:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:11 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to do, and we're going to make the world.
2022-03-23 11:49:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example hypothesis: he said, "" "" "" "" "" "" "", "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:49:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:18 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of that we're going to be a lot of the world, which is that we're going to have a lot of the world.
2022-03-23 11:49:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:18 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.432 | ppl 1381.94 | bleu 1.96 | wps 5060.4 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.96
2022-03-23 11:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 11:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:49:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:49:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.96) (writing took 1.879984874976799 seconds)
2022-03-23 11:49:20 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:49:20 | INFO | train | epoch 007 | loss 9.491 | ppl 719.56 | wps 40236.1 | ups 1.6 | wpb 25127.3 | bsz 1014.9 | num_updates 1094 | lr 0.00013675 | gnorm 0.921 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 745
KL Stats: Epoch 7 Divergences: Uniform: 1.614132880427175 Unigram: 0.45021874437627324
2022-03-23 11:49:20 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:23 | INFO | train_inner | epoch 008:      6 / 157 loss=9.381, ppl=666.66, wps=33183.7, ups=1.31, wpb=25297.6, bsz=1035.4, num_updates=1100, lr=0.0001375, gnorm=0.937, loss_scale=4, train_wall=37, gb_free=13.8, wall=748
2022-03-23 11:50:00 | INFO | train_inner | epoch 008:    106 / 157 loss=9.331, ppl=644.09, wps=67169.2, ups=2.68, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=0.785, loss_scale=4, train_wall=37, gb_free=22.3, wall=785
2022-03-23 11:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:23 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 11:50:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:50:26 | INFO | fairseq.tasks.translation | example hypothesis: the last year.
2022-03-23 11:50:26 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example hypothesis: this is that i can make a lot of course.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:50:34 | INFO | fairseq.tasks.translation | example hypothesis: he was his father.
2022-03-23 11:50:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother, we're going to do what we're going to do, and what we're going to do.
2022-03-23 11:50:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:50:41 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to talk about the world.
2022-03-23 11:50:41 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:50:45 | INFO | fairseq.tasks.translation | example hypothesis: some of course, but they're going to go to the.
2022-03-23 11:50:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example hypothesis: one: there's a lot of, "if we're going to do it, and then we're going to go to do it."
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:53 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we have a lot of the.
2022-03-23 11:50:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:53 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.274 | ppl 1238.45 | bleu 2.74 | wps 5407.9 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.74
2022-03-23 11:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 11:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.74) (writing took 1.8978045471012592 seconds)
2022-03-23 11:50:55 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:50:55 | INFO | train | epoch 008 | loss 9.324 | ppl 640.8 | wps 41445.6 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.809 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 841
KL Stats: Epoch 8 Divergences: Uniform: 1.6555977353379794 Unigram: 0.49621017979230336
2022-03-23 11:50:55 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:14 | INFO | train_inner | epoch 009:     49 / 157 loss=9.265, ppl=615.08, wps=34116.1, ups=1.35, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=0.82, loss_scale=4, train_wall=37, gb_free=11.8, wall=859
2022-03-23 11:51:51 | INFO | train_inner | epoch 009:    149 / 157 loss=9.133, ppl=561.51, wps=67341.3, ups=2.66, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=0.776, loss_scale=4, train_wall=37, gb_free=12.1, wall=897
2022-03-23 11:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:58 | INFO | fairseq.tasks.translation | example hypothesis: this can't be able.
2022-03-23 11:51:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:52:02 | INFO | fairseq.tasks.translation | example hypothesis: and last year.
2022-03-23 11:52:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example hypothesis: and so this is a lot of course, i can see, and i can see a lot of course.
2022-03-23 11:52:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example hypothesis: he never never never never never never never never never never never seen his father, because she was his father, because she was his father was his father was his father, because she was going to his father was
2022-03-23 11:52:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:52:15 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother, and my mother is, and what we're going to say, and what we're going to do?
2022-03-23 11:52:15 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:52:20 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to talk about our time that we're talking about time, or how to talk about things, or the world, or or the world.
2022-03-23 11:52:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:52:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're looking at the, but if you don't look at the
2022-03-23 11:52:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we look at the information, we look at the information, and we can see this, we can see this, and we can see the, and then we can see that we can see the, and then we can see the and we can see that we can see the, and then we can see the and then we can see that we can see the.
2022-03-23 11:52:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:36 | INFO | fairseq.tasks.translation | example hypothesis: one of the question, it's the one, and it's the one, "and it's."
2022-03-23 11:52:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:38 | INFO | fairseq.tasks.translation | example hypothesis: and.
2022-03-23 11:52:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:38 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.072 | ppl 1076.59 | bleu 5.38 | wps 4097.9 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5.38
2022-03-23 11:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 11:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.38) (writing took 1.8634578108321875 seconds)
2022-03-23 11:52:40 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:52:40 | INFO | train | epoch 009 | loss 9.164 | ppl 573.56 | wps 37634.6 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.776 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 946
KL Stats: Epoch 9 Divergences: Uniform: 1.6975642188717766 Unigram: 0.5394423608402968
2022-03-23 11:52:40 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:15 | INFO | train_inner | epoch 010:     92 / 157 loss=8.929, ppl=487.47, wps=30403.4, ups=1.19, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=0.804, loss_scale=4, train_wall=37, gb_free=10.8, wall=981
2022-03-23 11:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:43 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these cells.
2022-03-23 11:53:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:53:47 | INFO | fairseq.tasks.translation | example hypothesis: in year, he can be about about 30s.
2022-03-23 11:53:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:53:51 | INFO | fairseq.tasks.translation | example hypothesis: this is what i can see, of course, of course, of course.
2022-03-23 11:53:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because his father was his father, his father was his father.
2022-03-23 11:53:54 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a lot of children, and what we're going to do?
2022-03-23 11:53:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example hypothesis: so, we have our time, and we don't think about things, or other things.
2022-03-23 11:54:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some of. but some of. you don't know, but if you don't need to get the energy, and you don't need to do it.
2022-03-23 11:54:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of this information, we can take a little bit of information, and then we can see the
2022-03-23 11:54:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example hypothesis: dh: one of the reasons, and it's interesting. "
2022-03-23 11:54:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:20 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's always always always the mother, and the
2022-03-23 11:54:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:20 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.883 | ppl 944.22 | bleu 7.39 | wps 4431.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.39
2022-03-23 11:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.39) (writing took 1.872664910973981 seconds)
2022-03-23 11:54:22 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:54:22 | INFO | train | epoch 010 | loss 9.007 | ppl 514.52 | wps 38765.3 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.829 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1047
KL Stats: Epoch 10 Divergences: Uniform: 1.7418743482907078 Unigram: 0.5782935615010925
2022-03-23 11:54:22 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:54:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:35 | INFO | train_inner | epoch 011:     35 / 157 loss=9.025, ppl=521.05, wps=30927.3, ups=1.24, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=0.816, loss_scale=4, train_wall=37, gb_free=22.3, wall=1061
2022-03-23 11:55:13 | INFO | train_inner | epoch 011:    135 / 157 loss=8.814, ppl=450.14, wps=67138.1, ups=2.66, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=0.772, loss_scale=4, train_wall=37, gb_free=12.5, wall=1099
2022-03-23 11:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:25 | INFO | fairseq.tasks.translation | example hypothesis: this can't use this.
2022-03-23 11:55:25 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:55:29 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about 880s.
2022-03-23 11:55:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:55:33 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course, i can also be able to get a lot of course of course.
2022-03-23 11:55:33 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example hypothesis: he had never never seen his father, because he had his father because his mother, because she had his mother with his mother.
2022-03-23 11:55:38 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:55:42 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i've got a lot of aids, and we had a child, so we asked us to do what we do?
2022-03-23 11:55:42 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:55:46 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time of our time about things about how to talk about things, and how to talk about the time, or not about each other, or every time.
2022-03-23 11:55:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:55:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are some of the, but in the. but in the. but it's not going to do it, but if you don't need the energy, and the energy.
2022-03-23 11:55:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the information of these information, we can start from this information, we can start with a little bit of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of the information, and all of
2022-03-23 11:55:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:00 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons, it's interesting interesting, and it's interesting for me for me, and i'm going to make me for me, "well, if you're going to say," well, you're going to have a lot of the world. "
2022-03-23 11:56:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:02 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still still still still still still still the mother, and the work of the work, and we're going to see that we had a lot of the way that we were going to see that we were going to make a lot of the way that we were going to see that we were going to be able to be able to be able to be able to be able to make a lot of the system, or a lot of a lot of a lot of the way that we were able to see that we were able to see that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we were able to see that we were able to see that we were able to be able to be able to see that we were able to see that we were able to see that we were able to be able to make a lot of the the
2022-03-23 11:56:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:02 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.704 | ppl 834.29 | bleu 10.2 | wps 4454.1 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.2
2022-03-23 11:56:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:56:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:56:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.2) (writing took 1.8895395188592374 seconds)
2022-03-23 11:56:04 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:56:04 | INFO | train | epoch 011 | loss 8.814 | ppl 450.16 | wps 38694.3 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.738 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1149
KL Stats: Epoch 11 Divergences: Uniform: 1.7914276123161978 Unigram: 0.6163545134877805
2022-03-23 11:56:04 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:56:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:34 | INFO | train_inner | epoch 012:     78 / 157 loss=8.555, ppl=376.15, wps=31715.7, ups=1.24, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=0.74, loss_scale=4, train_wall=37, gb_free=12.9, wall=1180
2022-03-23 11:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:07 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical chemical chemical.
2022-03-23 11:57:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:57:11 | INFO | fairseq.tasks.translation | example hypothesis: in year, he can get about 8888,000, in the restaurant.
2022-03-23 11:57:11 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example hypothesis: this pattern of course, of course, i can also be able to be able to make a sense.
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:57:19 | INFO | fairseq.tasks.translation | example hypothesis: he had never seen his father to his father because his father had his mother, she had his mother with him.
2022-03-23 11:57:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:57:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my grandgrandgrandgrand, and aids has found a child, and so we asked us to do what we asked us?
2022-03-23 11:57:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:57:28 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things, how to talk about things, and not talk about how to talk about poverty or other, or each other.
2022-03-23 11:57:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:57:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of you're looking at the, but you don't know, if you don't like it, you don't need the energy, and if you need the energy, you need to need the energy.
2022-03-23 11:57:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start from this, we can start to start with a, we can start to start with a, and we can start to start with the structure of the structure of the structure, and the structure of the structure, and the structure of the structure, and the structure of the structure, which is all the structure of the structure, and the structure of the structure of the structure, and the structure of the structure of
2022-03-23 11:57:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:41 | INFO | fairseq.tasks.translation | example hypothesis: robert th: one of the reasons that it's interesting and interesting for me to be here for me, "yes, you know," yes, you're going to say, "well," well, "if you're going to say," you're going to say, "you're going to say," the best. "
2022-03-23 11:57:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the mother of mother, and the
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:43 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.456 | ppl 702.32 | bleu 12.02 | wps 4569.2 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 12.02
2022-03-23 11:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 11:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 12.02) (writing took 1.8376355729997158 seconds)
2022-03-23 11:57:45 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 11:57:45 | INFO | train | epoch 012 | loss 8.631 | ppl 396.34 | wps 39019.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.771 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1251
KL Stats: Epoch 12 Divergences: Uniform: 1.8333675718701614 Unigram: 0.6435546503448949
2022-03-23 11:57:45 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 11:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:53 | INFO | train_inner | epoch 013:     21 / 157 loss=8.672, ppl=407.79, wps=30980.1, ups=1.26, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=0.773, loss_scale=4, train_wall=37, gb_free=12.2, wall=1259
2022-03-23 11:58:31 | INFO | train_inner | epoch 013:    121 / 157 loss=8.466, ppl=353.63, wps=66576.6, ups=2.65, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=0.789, loss_scale=4, train_wall=37, gb_free=12, wall=1297
2022-03-23 11:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:48 | INFO | fairseq.tasks.translation | example hypothesis: this can't use chemical chemical chemical.
2022-03-23 11:58:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 miles.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:58:56 | INFO | fairseq.tasks.translation | example hypothesis: this is of course, of course, i can.
2022-03-23 11:58:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had his father.
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my couirs is died and aids, so we asked us a child, so we asked what do?
2022-03-23 11:59:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:59:06 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about time, and not talk about the time.
2022-03-23 11:59:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are, but in the field, it doesn't want to move it, but if they don't need their own energy, and if they need the energy.
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can start from this reflection.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:18 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons, and it's interesting for me to make me here, "yes, yes, yes, yes, yes," yes, it's the best revolution. "
2022-03-23 11:59:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and the work that we have a great work on our work, when we had to use the plane, we had to make a little bit of the surface of the.
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:19 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.349 | ppl 652.14 | bleu 9.67 | wps 5406.6 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.02
2022-03-23 11:59:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 11:59:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:59:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 11:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 13 @ 2036 updates, score 9.67) (writing took 0.7928644011262804 seconds)
2022-03-23 11:59:19 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 11:59:19 | INFO | train | epoch 013 | loss 8.447 | ppl 348.92 | wps 41860.7 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.77 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1345
KL Stats: Epoch 13 Divergences: Uniform: 1.876451418302943 Unigram: 0.6703381146189944
2022-03-23 11:59:20 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 11:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:44 | INFO | train_inner | epoch 014:     64 / 157 loss=8.273, ppl=309.23, wps=35054.3, ups=1.37, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=0.74, loss_scale=4, train_wall=37, gb_free=12.1, wall=1370
2022-03-23 12:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:23 | INFO | fairseq.tasks.translation | example hypothesis: and this, these chemical chemical chemical chemical chemical chemical chemical chemical chemical, can't use.
2022-03-23 12:00:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:00:27 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about 888,000 restaurant in the restaurant.
2022-03-23 12:00:27 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:00:32 | INFO | fairseq.tasks.translation | example hypothesis: so i can, of course, of course, i can also also, of course, of course, of course, of course, of course, of course, of course,
2022-03-23 12:00:32 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:00:36 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, because she had his mother with him.
2022-03-23 12:00:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:00:41 | INFO | fairseq.tasks.translation | example hypothesis: one of my cou, and aids died on aids, and a child, so we said, what do we do with her child?
2022-03-23 12:00:41 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:00:45 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to spend things about how to talk about things like, and not talk about how we talk about poverty, or other weapons, or other weapons, or other weapons.
2022-03-23 12:00:45 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magic, but in the field of the field, if they don't want to move their energy, and if they don't need the energy, they need to move the energy energy, and they need to the energy energy, and the power of the power, and they're so they're so, and they're
2022-03-23 12:00:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use from this reflection, we can start from a traditional, and we can begin to start with the traditional structure of the structure, and the whole structure of the structure, and the whole structure of the structure, and so that all the structure of the structure of the structure of the structure, and so that all the information, and if we're all the structure of the information, the information, the information, the information
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:01 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons, and it's interesting for me, "for me to be interesting for tedman," well, you know, you know, the best revolution, "if you're going to say," the best revolution, "if we've got to tell you."
2022-03-23 12:01:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:03 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, fortunately, it's still still the mother, and the invention of the invention that we've had to be able to be able to see that it was a very unique
2022-03-23 12:01:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:03 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.212 | ppl 592.97 | bleu 12.56 | wps 4029 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 12.56
2022-03-23 12:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 12.56) (writing took 1.8371828789822757 seconds)
2022-03-23 12:01:05 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:01:05 | INFO | train | epoch 014 | loss 8.288 | ppl 312.49 | wps 37269.8 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.764 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1451
KL Stats: Epoch 14 Divergences: Uniform: 1.9317598948903272 Unigram: 0.6946916161680107
2022-03-23 12:01:06 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:01:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:08 | INFO | train_inner | epoch 015:      7 / 157 loss=8.31, ppl=317.26, wps=29348.1, ups=1.18, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=0.759, loss_scale=4, train_wall=37, gb_free=12.1, wall=1454
2022-03-23 12:01:46 | INFO | train_inner | epoch 015:    107 / 157 loss=8.168, ppl=287.52, wps=66759.1, ups=2.67, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=0.694, loss_scale=4, train_wall=37, gb_free=11.9, wall=1492
2022-03-23 12:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:08 | INFO | fairseq.tasks.translation | example hypothesis: it can't use these chemical chemical chemical rays.
2022-03-23 12:02:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:02:13 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 88,000, in the restaurant, in the restaurant.
2022-03-23 12:02:13 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:02:17 | INFO | fairseq.tasks.translation | example hypothesis: and this magnetic magnets, i can also, of course, of course, to make a popular bible.
2022-03-23 12:02:17 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his father had learned his mother, when she was pregnant.
2022-03-23 12:02:21 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and died a child, so we asked us, what do we do?
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender, and not talking about the nuclear weapons or nuclear weapons.
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a little bit of the magic lines in the field, but if you don't want to move it, if you don't need your movements, and you don't need your movements.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start to start with a traditional traditional face of traditional factors, and we can start looking at the visual shape of the form of the shape, and there's a real shape.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example hypothesis: keith: the reasons that we have interesting and measure it, for me, for me, is that tedman's going to be in the best time, "yes, that somebody said," well, "if someone said," somebody said, "the best revolution is," if you're going to give you a long revolution, "and then we have a long time," well, "if we have a long revolution," well, "well," well, "if we have a long time," well, "well," and then we have a lot of course, "well," if we have a lot of you're going to take you're going to take you have a long time, "and then we have a long time for you have a long time," oh, "and then you're going to take you have a lot of course," in this
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:45 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of the mother, and a big part of the design design that we had to solve our plane in our plane, and we had to solve a unique result that we had to solve a unique, and that it's a unique way to solve, to solve it's a unique, and if we had to solve it, it's a unique, it's a unique, it's to solve that if we had to solve, to solve, it is to solve, it is that if we had to solve, it's a unique, to solve the
2022-03-23 12:02:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:45 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.999 | ppl 511.59 | bleu 16.73 | wps 4493.2 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.73
2022-03-23 12:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:02:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.73) (writing took 1.838367453077808 seconds)
2022-03-23 12:02:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:02:47 | INFO | train | epoch 015 | loss 8.113 | ppl 276.81 | wps 38920.3 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.674 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1552
KL Stats: Epoch 15 Divergences: Uniform: 1.9844036669592258 Unigram: 0.7134239283501365
2022-03-23 12:02:47 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:06 | INFO | train_inner | epoch 016:     50 / 157 loss=8.098, ppl=274.04, wps=31446.9, ups=1.24, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.639, loss_scale=4, train_wall=37, gb_free=12.5, wall=1572
2022-03-23 12:03:43 | INFO | train_inner | epoch 016:    150 / 157 loss=7.878, ppl=235.26, wps=67510, ups=2.69, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.685, loss_scale=4, train_wall=37, gb_free=11.9, wall=1609
2022-03-23 12:03:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:50 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical chemical rockets.
2022-03-23 12:03:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:03:54 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about 8888888,000, in the restaurant.
2022-03-23 12:03:54 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:03:58 | INFO | fairseq.tasks.translation | example hypothesis: so, of course, of course, i can also make a popular bible.
2022-03-23 12:03:58 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother, when she was pregnant.
2022-03-23 12:04:02 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a, so we asked what do we do with her?
2022-03-23 12:04:06 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender gender and not talking about nuclear weapons or nuclear weapons.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic lines in the field, but the susususus don't move their movements, when they need their movements and so forth.
2022-03-23 12:04:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face of traditional face, and the real face of the face of the face of the information.
2022-03-23 12:04:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:22 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons, and it's interesting for me, for me, for tedman, that's the best time to help you. "
2022-03-23 12:04:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:23 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of the invention, and a great part of the design that we have to use the aircraft in our plane, when we had to get a unique
2022-03-23 12:04:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.936 | ppl 489.88 | bleu 17.06 | wps 4937.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.06
2022-03-23 12:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:04:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:04:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 17.06) (writing took 1.8486652439460158 seconds)
2022-03-23 12:04:25 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:04:25 | INFO | train | epoch 016 | loss 7.947 | ppl 246.75 | wps 40086.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.674 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1651
KL Stats: Epoch 16 Divergences: Uniform: 2.0331228595215562 Unigram: 0.7361885651188156
2022-03-23 12:04:26 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:04:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:01 | INFO | train_inner | epoch 017:     93 / 157 loss=7.745, ppl=214.56, wps=33281.7, ups=1.29, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.614, loss_scale=4, train_wall=37, gb_free=12, wall=1687
2022-03-23 12:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:29 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 12:05:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example hypothesis: transmits can be about 8,000 places in the restaurant.
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example hypothesis: these magnets are magnets, of course, of course, i can also.
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his father because his mother had been pregnant with him when she was pregnant with him.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and a wawavela child, so we asked us good what do we do with her?
2022-03-23 12:05:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to spend things about things like gender times, and not talking about nuclear weapons or nuclear weapons, or any other topics of poverty, or any other topic issue.
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:05:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bols of magnetic magnetic magnetic lines, but the sususususus don't like it, when they need their movements, their movements, their movements, their movements, and the sususues need.
2022-03-23 12:05:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial facial facial face of the face of the face, and the real shape of the shape, and the information is the structure that all the structure.
2022-03-23 12:05:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:04 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting, and measure it interesting for me to be here in tedwomen, that... yes, in the best time, somebody said, "somebody else said," you know, "and if you're going to support you're going to support a table," and then we're going to support the truth for you. "
2022-03-23 12:06:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:06 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of design design work on our plane, we were a result that we had to solve the unique problems that we had to solve the problems that we had to solve it, and that it's all of us to use it in the ground.
2022-03-23 12:06:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:06 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.798 | ppl 445.07 | bleu 19.95 | wps 4389.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.95
2022-03-23 12:06:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:06:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.95) (writing took 1.8732224400155246 seconds)
2022-03-23 12:06:08 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:06:08 | INFO | train | epoch 017 | loss 7.787 | ppl 220.8 | wps 38509 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.616 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1754
KL Stats: Epoch 17 Divergences: Uniform: 2.0734521535775197 Unigram: 0.7561242437479824
2022-03-23 12:06:08 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:06:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:22 | INFO | train_inner | epoch 018:     36 / 157 loss=7.786, ppl=220.65, wps=30329.5, ups=1.24, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.65, loss_scale=4, train_wall=36, gb_free=12.2, wall=1767
2022-03-23 12:07:00 | INFO | train_inner | epoch 018:    136 / 157 loss=7.668, ppl=203.41, wps=67331.6, ups=2.64, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.596, loss_scale=4, train_wall=38, gb_free=11.8, wall=1805
2022-03-23 12:07:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:11 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:07:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example hypothesis: overwhiss can be about 8,000 places in the restaurant.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example hypothesis: this rough magnetic magnets, i can also, of course, to make a popular bible.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother, when she was pregnant.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:07:28 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died to aids, and one of aids, so we asked us good, what do we do with her?
2022-03-23 12:07:28 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:07:32 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons or any other topic.
2022-03-23 12:07:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bl field of magnetic magnetic lines, but the susuck doesn't like it, if you don't need to move your movements, you need your movements, you need your movements, and the sususususues need to disorders.
2022-03-23 12:07:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial facial facial facial face, the big factors of the facial facial factors, and the information of the structure is all the structure.
2022-03-23 12:07:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:45 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measure it, for me, for me, for me, is that...
2022-03-23 12:07:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of invention, and a great part of the design work on our plane, and a lot of the things that we're going to be able to solve the unique problems that we had to solve it on the ground -- it's all the variation of a variable system.
2022-03-23 12:07:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:46 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.647 | ppl 400.87 | bleu 21.31 | wps 4667.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.31
2022-03-23 12:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.31) (writing took 1.8629073309712112 seconds)
2022-03-23 12:07:48 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:07:48 | INFO | train | epoch 018 | loss 7.687 | ppl 206.12 | wps 39307.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.633 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 1854
KL Stats: Epoch 18 Divergences: Uniform: 2.1058900840120924 Unigram: 0.7650386859661588
2022-03-23 12:07:49 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:18 | INFO | train_inner | epoch 019:     79 / 157 loss=7.712, ppl=209.66, wps=31063.2, ups=1.27, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.618, loss_scale=4, train_wall=36, gb_free=11.8, wall=1884
2022-03-23 12:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:52 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:08:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example hypothesis: overcome about 8,000 places in the restaurant.
2022-03-23 12:08:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand of course to form a popular bike.
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had his mother, when she was pregnant.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and has a wavel-child, so we asked, what do we do with her?
2022-03-23 12:09:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:09:11 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not about nuclear weapons or nuclear weapons.
2022-03-23 12:09:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:09:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are starting, but the susususucks doesn't like, if you're moving.
2022-03-23 12:09:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional facial facial facial facial facial facial facial facial facial facial face.
2022-03-23 12:09:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:23 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measured for me to be here for tedwomen, "yes, is that when they were."
2022-03-23 12:09:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:24 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of the invention, and a big part of the design work that we're on the plane.
2022-03-23 12:09:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:24 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.613 | ppl 391.54 | bleu 20.61 | wps 5085.1 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.31
2022-03-23 12:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:09:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:09:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 20.61) (writing took 0.7814154329244047 seconds)
2022-03-23 12:09:25 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:09:25 | INFO | train | epoch 019 | loss 7.575 | ppl 190.73 | wps 40948.4 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.587 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 1950
KL Stats: Epoch 19 Divergences: Uniform: 2.1341355134133426 Unigram: 0.7781048663725124
2022-03-23 12:09:25 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:09:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:34 | INFO | train_inner | epoch 020:     22 / 157 loss=7.572, ppl=190.26, wps=33535.2, ups=1.33, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.563, loss_scale=4, train_wall=37, gb_free=12.7, wall=1959
2022-03-23 12:10:11 | INFO | train_inner | epoch 020:    122 / 157 loss=7.292, ppl=156.72, wps=68249.8, ups=2.63, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.513, loss_scale=4, train_wall=38, gb_free=22.3, wall=1997
2022-03-23 12:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical rockets.
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example hypothesis: overwhelming about 8,000 places in the restaurant.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example hypothesis: i can also, of course, i can expanded to form a popular bike.
2022-03-23 12:10:36 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 12:10:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died and has a wash child leave, so we asked what do we do with her?
2022-03-23 12:10:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not talking about the spread of nuclear weapons or poverty.
2022-03-23 12:10:48 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:10:52 | INFO | fairseq.tasks.translation | example hypothesis: first is some of magnetic field in the inner lines, but the superconductor doesn't like when they need their energy movements, and the superconductive disorders.
2022-03-23 12:10:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial facial facial, which is the big configuration of the face, and the basic shape of the face, and the basic shape, and reviews the information, and fold all the structure and fold.
2022-03-23 12:10:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here in tedwomen, is that... "yes, in the best dinner, it was put it together as someone said," somebody said, "somebody who said to you," the men and say, "if we're going to support them," and then we've already started to support the truth for me to support you. "
2022-03-23 12:11:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:04 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the unique problems that were connected to the ground, and a big part of the design work that we're using on our plane, was a result that we had to solve the unique problems that we had to solve the unique problems that we had to solve the unique problems to the ground -- it allows us to use everything from a continents to the ground, and a continually refrigeration system that allows us to use to use it to use it to use it to use it to refrifrigeration, and the
2022-03-23 12:11:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:04 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.514 | ppl 365.6 | bleu 22.82 | wps 4633.3 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.82
2022-03-23 12:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.82) (writing took 1.8161137911956757 seconds)
2022-03-23 12:11:05 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:11:05 | INFO | train | epoch 020 | loss 7.456 | ppl 175.6 | wps 39232.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.541 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2051
KL Stats: Epoch 20 Divergences: Uniform: 2.1498882729689512 Unigram: 0.7870349271270357
2022-03-23 12:11:06 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:30 | INFO | train_inner | epoch 021:     65 / 157 loss=7.549, ppl=187.31, wps=31192.3, ups=1.27, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.552, loss_scale=4, train_wall=37, gb_free=12.8, wall=2076
2022-03-23 12:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:08 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:12:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example hypothesis: overwhelmed year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:12:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:12:16 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand this round magnets, of course, to form a popular bible.
2022-03-23 12:12:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:12:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father left his mother when she was pregnant with him.
2022-03-23 12:12:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and has a wais-child back, so we asked us what do we do with her?
2022-03-23 12:12:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:12:28 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not talking about nuclear weapons or poverty or any other topic.
2022-03-23 12:12:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:12:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field, but the superconductor doesn't like, if you move your movements, your movements need, and so the superconductive disorders.
2022-03-23 12:12:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start the big configuration of the face and the basic form of the face and the basic form, and through this one, which is the whole structure.
2022-03-23 12:12:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that -- in the dinner dinner dinner dinner dinner dinner dinner dinner dinner dinner dinner, "when someone said,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 12:12:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our plane was a result of that we had to solve the unique problems that were connected to the ground -- all the way that it allows us to use it to refrigerate everything from a continual variation and refrigerate system that allows us to use it.
2022-03-23 12:12:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:42 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.421 | ppl 342.75 | bleu 24.71 | wps 4929.2 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.71
2022-03-23 12:12:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:12:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:12:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.71) (writing took 1.8288438618183136 seconds)
2022-03-23 12:12:43 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:12:43 | INFO | train | epoch 021 | loss 7.363 | ppl 164.58 | wps 40316.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.496 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2149
KL Stats: Epoch 21 Divergences: Uniform: 2.1700220217746544 Unigram: 0.7964898703229261
2022-03-23 12:12:44 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:12:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:47 | INFO | train_inner | epoch 022:      8 / 157 loss=7.264, ppl=153.73, wps=33153.4, ups=1.31, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.478, loss_scale=4, train_wall=36, gb_free=12.4, wall=2153
2022-03-23 12:13:25 | INFO | train_inner | epoch 022:    108 / 157 loss=7.285, ppl=155.95, wps=66977.8, ups=2.65, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.51, loss_scale=4, train_wall=37, gb_free=12, wall=2190
2022-03-23 12:13:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example hypothesis: overwhelmed about 8,000 places in the restaurant.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:13:54 | INFO | fairseq.tasks.translation | example hypothesis: i can also expanding these round magnetic magnets.
2022-03-23 12:13:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:13:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother left when she was pregnant.
2022-03-23 12:13:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:14:02 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and has a waisena child, so we asked what do we do with her?
2022-03-23 12:14:02 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times and not about nuclear weapons or poverty.
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic fields start in the inside, but the superconductor doesn't like if you move your movements, because your movements need your movements, and the superpower disorder.
2022-03-23 12:14:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this mirror reflection, we can start with a traditional facial face, which is the big configuration of the face face and the basic form of face, and the basic form of face, and the basic shape, and rerepeat it.
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen, is that... yes, when dinner dinner dinner dinner dinner dinner dinner dinner dinner dinner was summared when someone said, "when someone said to you."
2022-03-23 12:14:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on our plane, was a result that we had to solve a result that we had to solve the unique problems that were connected to the ground.
2022-03-23 12:14:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:17 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.489 | ppl 359.26 | bleu 21.92 | wps 5326 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.71
2022-03-23 12:14:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:14:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 21.92) (writing took 0.8116008872166276 seconds)
2022-03-23 12:14:18 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:14:18 | INFO | train | epoch 022 | loss 7.291 | ppl 156.57 | wps 41698.7 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.502 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2244
KL Stats: Epoch 22 Divergences: Uniform: 2.1764289750172026 Unigram: 0.8018933287708325
2022-03-23 12:14:19 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:14:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:38 | INFO | train_inner | epoch 023:     51 / 157 loss=7.194, ppl=146.41, wps=34287.9, ups=1.36, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.492, loss_scale=4, train_wall=37, gb_free=12.9, wall=2264
2022-03-23 12:15:15 | INFO | train_inner | epoch 023:    151 / 157 loss=7.327, ppl=160.59, wps=66188.2, ups=2.67, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.479, loss_scale=4, train_wall=37, gb_free=12, wall=2301
2022-03-23 12:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:22 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 12:15:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:15:26 | INFO | fairseq.tasks.translation | example hypothesis: it can protect about 8,000 places in the restaurant.
2022-03-23 12:15:26 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets, of course, to shape a popular bike.
2022-03-23 12:15:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:15:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:15:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:15:38 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids, and has a waphanage, so we asked us well, what do we do with her?
2022-03-23 12:15:38 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:15:42 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not the spread of nuclear weapons or poverty.
2022-03-23 12:15:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are caught in the inner lines, but the superconductor doesn't like it when they're moving, because their movements need their movements, and the superconductive disorders.
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional face, which is the big configuration of the face, and the basic shape of the face, and by the theast of information, which is the whole porter structure and all the folding structure.
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to be here at tedwomen, is that... well, in the top dinner dinner, it was the best thing when someone said, "turn you to the men and tell them," if the revolution begins to a table, we're going to support you, "the truth is that, we've already started with you," women, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're
2022-03-23 12:15:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- all the continually, all of the continental varieties, the continuous varieties and a cooling system that it allows us to the
2022-03-23 12:15:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:57 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.265 | ppl 307.6 | bleu 27.31 | wps 4608.6 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.31
2022-03-23 12:15:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:15:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.31) (writing took 1.8346743960864842 seconds)
2022-03-23 12:15:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:15:59 | INFO | train | epoch 023 | loss 7.22 | ppl 149.05 | wps 39134.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.471 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2345
KL Stats: Epoch 23 Divergences: Uniform: 2.1880091287631087 Unigram: 0.8040100286090645
2022-03-23 12:15:59 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:35 | INFO | train_inner | epoch 024:     94 / 157 loss=7.124, ppl=139.53, wps=31670.1, ups=1.26, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.462, loss_scale=4, train_wall=37, gb_free=12.1, wall=2381
2022-03-23 12:16:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:02 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:17:02 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:17:06 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 12:17:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:17:10 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets to form a popular equation.
2022-03-23 12:17:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:17:14 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:17:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:17:18 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids and has a waisena child back, so we asked us, well, what do we do with her?
2022-03-23 12:17:18 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about the spread of nuclear weapons or poverty.
2022-03-23 12:17:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught in the inner lines, but the supraleiter doesn't like it when they use their movements, and so the superconductor disorder.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can start the big configuration of the face and the basic shape, and it restores all the portion.
2022-03-23 12:17:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are highly interesting and measured for me to be here at tedwomen, is that... tyes, in dinner dinner dinner, when someone said, "turn you to the men and say," if we get the revolution. "
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on on our airplane, was a result that we've had to solve the unique problems that were connected to the ground -- all of a continuous refrigeration system that it allows us to use.
2022-03-23 12:17:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:36 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.257 | ppl 305.85 | bleu 27.38 | wps 4971.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.38
2022-03-23 12:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.38) (writing took 1.84133864287287 seconds)
2022-03-23 12:17:37 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:17:37 | INFO | train | epoch 024 | loss 7.143 | ppl 141.33 | wps 40124 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.44 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2443
KL Stats: Epoch 24 Divergences: Uniform: 2.194874498124862 Unigram: 0.8125757938477262
2022-03-23 12:17:38 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:51 | INFO | train_inner | epoch 025:     37 / 157 loss=7.196, ppl=146.59, wps=32427, ups=1.31, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.421, loss_scale=4, train_wall=36, gb_free=12.8, wall=2457
2022-03-23 12:18:29 | INFO | train_inner | epoch 025:    137 / 157 loss=7.064, ppl=133.82, wps=67348.4, ups=2.65, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.46, loss_scale=4, train_wall=37, gb_free=11.9, wall=2495
2022-03-23 12:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:18:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 12:18:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:18:49 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form a popular glimpse.
2022-03-23 12:18:49 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:18:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:18:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died in aids, and has a waisenchild behind, so we asked us what do we do with her?
2022-03-23 12:18:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not talking about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:19:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:19:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bellull of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductive disorders.
2022-03-23 12:19:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which is the big contemplates of the face and the basic form of the face, and through the thief of information, which is the whole porter structure and all folding.
2022-03-23 12:19:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here at tedwomen, is that... tyes, when dinner was put it on the best time when someone said, "turn you to the men on your table and tell you, 'if the revolution starts to support you."] ["] ["
2022-03-23 12:19:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the stumber, was a result that we had to solve the unique problems that were connected to operating on the floor -- everything from a continuous variation and a cooling system that allows us to see that when we use it's a vehicle, or the.
2022-03-23 12:19:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:14 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.174 | ppl 288.88 | bleu 28.74 | wps 4855.7 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.74
2022-03-23 12:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:19:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.74) (writing took 1.8454352871049196 seconds)
2022-03-23 12:19:16 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:19:16 | INFO | train | epoch 025 | loss 7.094 | ppl 136.63 | wps 40077.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.45 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2542
KL Stats: Epoch 25 Divergences: Uniform: 2.1994858138745874 Unigram: 0.8119301789654011
2022-03-23 12:19:16 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:46 | INFO | train_inner | epoch 026:     80 / 157 loss=6.972, ppl=125.5, wps=32911.5, ups=1.3, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.424, loss_scale=4, train_wall=37, gb_free=12.2, wall=2572
2022-03-23 12:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:20:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 12:20:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round, of course, to shape a popular glimpse.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines is died of aids, and has a waischild left, so we asked us, well, what do we do with her?
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or poverty or any other promising topic.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught in the inside, but the superconductor doesn't like it if you're moving, because your movements use their movements, and so the superconductive disorder.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big configurations of the face and the basic shape of the information, and through the theast of the information, which is the whole porter structure and all fold.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... tyes, when dinner was the best summarized when somebody said, "turn you to the men in your table and tell you," if the revolution starts to support you. "
2022-03-23 12:20:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to use.
2022-03-23 12:20:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:53 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.135 | ppl 281.09 | bleu 28.79 | wps 4911.4 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.79
2022-03-23 12:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:20:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.79) (writing took 1.8841695040464401 seconds)
2022-03-23 12:20:55 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:20:55 | INFO | train | epoch 026 | loss 7.034 | ppl 131.01 | wps 40042.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.419 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2640
KL Stats: Epoch 26 Divergences: Uniform: 2.201478549094245 Unigram: 0.8147914761119293
2022-03-23 12:20:55 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:04 | INFO | train_inner | epoch 027:     23 / 157 loss=7.037, ppl=131.3, wps=32513.3, ups=1.29, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.422, loss_scale=4, train_wall=37, gb_free=11.8, wall=2649
2022-03-23 12:21:41 | INFO | train_inner | epoch 027:    123 / 157 loss=7.027, ppl=130.46, wps=66877.8, ups=2.68, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.389, loss_scale=4, train_wall=37, gb_free=12.3, wall=2687
2022-03-23 12:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example hypothesis: over the year it can occur about 8,000 places in the restaurant.
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form a popular glimpse of shapes.
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my couches died on aids, and a waisenchild was leaving, so we asked us, well, what do we do with her?
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:22:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are captured in the inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting disorder disorder disorders.
2022-03-23 12:22:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configuration of the face and the basic form, and through this one information, which is the whole portion structure and all folding a fold.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner was summared, it was the best one said, "turn you to the men in your table and say," if the revolution starts to you. "
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system that allows us to use an aircraft that allows us to either be the same until you see the
2022-03-23 12:22:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:33 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.082 | ppl 271.04 | bleu 29.81 | wps 4632.6 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.81
2022-03-23 12:22:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:22:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.81) (writing took 1.857513696886599 seconds)
2022-03-23 12:22:35 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:22:35 | INFO | train | epoch 027 | loss 6.977 | ppl 125.97 | wps 39358.3 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.394 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 2741
KL Stats: Epoch 27 Divergences: Uniform: 2.205014681207658 Unigram: 0.8156598750881111
2022-03-23 12:22:35 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:22:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:00 | INFO | train_inner | epoch 028:     66 / 157 loss=6.937, ppl=122.54, wps=32095.5, ups=1.26, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.42, loss_scale=4, train_wall=37, gb_free=12.1, wall=2766
2022-03-23 12:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:38 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:23:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:23:42 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:23:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:23:46 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to shape a popular glimpse.
2022-03-23 12:23:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:23:50 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:23:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:23:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died of aids, and a waisena child, so we asked us, well, what do we do with her?
2022-03-23 12:23:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:23:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder disorders.
2022-03-23 12:24:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which gives the big configuration of the face and the basic shape, and through the theft of information, which pulls the whole porter structure and all the fits.
2022-03-23 12:24:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured for me here at tedwomen is that... tyes, when dinner was summared, it was best summared when someone said, "turn you to the men on your table and say," if the revolution begins to you. "'the truth is that we've already been supporting you for a long time."
2022-03-23 12:24:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft on the wheel, and we use it to use it in the tune.
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:11 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.069 | ppl 268.59 | bleu 30.2 | wps 4902.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.2
2022-03-23 12:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.2) (writing took 1.9114497520495206 seconds)
2022-03-23 12:24:13 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:24:13 | INFO | train | epoch 028 | loss 6.949 | ppl 123.57 | wps 40169.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.405 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2839
KL Stats: Epoch 28 Divergences: Uniform: 2.2042404193693015 Unigram: 0.818733853454848
2022-03-23 12:24:14 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:17 | INFO | train_inner | epoch 029:      9 / 157 loss=6.921, ppl=121.16, wps=32592.4, ups=1.3, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.36, loss_scale=4, train_wall=37, gb_free=12.3, wall=2843
2022-03-23 12:24:55 | INFO | train_inner | epoch 029:    109 / 157 loss=6.887, ppl=118.35, wps=67369.3, ups=2.67, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.395, loss_scale=4, train_wall=37, gb_free=12.7, wall=2881
2022-03-23 12:25:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:25:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:25:25 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to form any glimpse.
2022-03-23 12:25:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:25:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my couins is died of aids, and they left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:25:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:25:36 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs, and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:25:36 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder disorders.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the grocery contures of the face and the basic shape, and the whole portion structure and all the wrinkles.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me here at tedwomen is that... tyes, when it was stripped up at dinner, it was best summarized when somebody said, "turn you to the men on your table and say," if the revolution begins, we support you. "'"' "'"' truth, women, we already encouraged you.
2022-03-23 12:25:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on on on our plane, was a result of solving the unique problems that were connected to the ground -- everything, from a continuous variation and a coolness system that allows us to use an aircraft on the ridge, or an aircraft, when you see the ground.
2022-03-23 12:25:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:52 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.078 | ppl 270.21 | bleu 29.92 | wps 4751.8 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.2
2022-03-23 12:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 29 @ 4548 updates, score 29.92) (writing took 0.8519355971366167 seconds)
2022-03-23 12:25:53 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:25:53 | INFO | train | epoch 029 | loss 6.889 | ppl 118.52 | wps 39761.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.377 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 2938
KL Stats: Epoch 29 Divergences: Uniform: 2.206983547264921 Unigram: 0.8245342417385054
2022-03-23 12:25:53 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:13 | INFO | train_inner | epoch 030:     52 / 157 loss=6.874, ppl=117.31, wps=32106.6, ups=1.29, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.372, loss_scale=4, train_wall=36, gb_free=12.5, wall=2958
2022-03-23 12:26:50 | INFO | train_inner | epoch 030:    152 / 157 loss=6.87, ppl=116.97, wps=67614, ups=2.69, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.349, loss_scale=4, train_wall=37, gb_free=12.1, wall=2995
2022-03-23 12:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets, of course, to shape a popular equation.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids, and they leave an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender high times, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:27:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can, which repeat the big configurations of the face and the basic shape, and through the theft of that information, which refuse the whole porter structure and all the folds.
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and appropriate for me to be here at tedwomen, is that... well, at the dinner dinner, it was summared, when someone said, "turn you to the men on your table and say," if the revolution begins to you. "the truth is that we support you."
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're proud of at our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- all, from a continuous variation, and a cooling system that allows us to use an aircraft in the
2022-03-23 12:27:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:31 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.98 | ppl 252.5 | bleu 31.87 | wps 4560.7 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.87
2022-03-23 12:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.87) (writing took 1.8228017480578274 seconds)
2022-03-23 12:27:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:27:33 | INFO | train | epoch 030 | loss 6.854 | ppl 115.66 | wps 39191.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.364 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3039
KL Stats: Epoch 30 Divergences: Uniform: 2.2098506919953893 Unigram: 0.8223303801327445
2022-03-23 12:27:34 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:10 | INFO | train_inner | epoch 031:     95 / 157 loss=6.837, ppl=114.35, wps=31411.6, ups=1.25, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.36, loss_scale=4, train_wall=37, gb_free=12.6, wall=3075
2022-03-23 12:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:37 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:28:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:28:41 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:28:41 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:28:45 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to form a popular equation.
2022-03-23 12:28:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:28:49 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:28:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:28:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:28:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:28:57 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender webs and not about genocide or poverty or any other promising topic.
2022-03-23 12:28:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are captured in the inner, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconduction disturbs.
2022-03-23 12:29:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which regards the big contexts of the face and the basic form of information, which refits the whole porter structure and all the wrinkles.
2022-03-23 12:29:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins to you. "the truth is that we support you." the truth is that we've already been supporting you for a long time, "and" listen to it, "and" hey, "hey," hey, "hey," hey, "hey," hey, "listen," listen, you know, "hey," listen, you know, you know, "i mean, you know, you know," listen, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, "
2022-03-23 12:29:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our airplane most proud, was a result that we had to solve the unique problems that were connected to operating it on the floor -- everything from a continuous variation of the design work, and a cooling system that allows us to use an aircraft to either if you're in the ground, or if you're going to see the same way that you're going to have to use it, if you're going to have to have to have to have to have to have to see the farming, you're going to see the ground, you're going to have to see that you're going to have to have to have to see that you're going to have to have to have to have to have to have to have to have to see that you're in the same, you're connected to see that you're going to have to have to have to have to have to have to have to have to have to have to have to see the
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:13 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.994 | ppl 255 | bleu 31.57 | wps 4541.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.87
2022-03-23 12:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.57) (writing took 0.8190676930826157 seconds)
2022-03-23 12:29:13 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:29:13 | INFO | train | epoch 031 | loss 6.815 | ppl 112.57 | wps 39428.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.369 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 3139
KL Stats: Epoch 31 Divergences: Uniform: 2.2104329664992646 Unigram: 0.8254310366476789
2022-03-23 12:29:14 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:28 | INFO | train_inner | epoch 032:     38 / 157 loss=6.764, ppl=108.68, wps=32181.1, ups=1.27, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.381, loss_scale=4, train_wall=37, gb_free=13.1, wall=3154
2022-03-23 12:30:06 | INFO | train_inner | epoch 032:    138 / 157 loss=6.753, ppl=107.83, wps=67513.1, ups=2.67, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.332, loss_scale=4, train_wall=37, gb_free=12.3, wall=3191
2022-03-23 12:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:30:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to shape any equivalent.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:30:37 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:30:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:30:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:30:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:45 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic form of information, which refers the whole porter structure and all the fine folds.
2022-03-23 12:30:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and appropriate for me to be here at tedwomen is that... tyes, at the dinner dinner, it was the best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins to support you. "'"' the truth is that we've already been supporting you for this long time. "
2022-03-23 12:30:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system that allows us to use an aircraft in the.
2022-03-23 12:30:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:51 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.977 | ppl 252.02 | bleu 31.34 | wps 4849 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.87
2022-03-23 12:30:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:30:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.34) (writing took 0.8101496340241283 seconds)
2022-03-23 12:30:52 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:30:52 | INFO | train | epoch 032 | loss 6.781 | ppl 110.01 | wps 40260.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.354 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3237
KL Stats: Epoch 32 Divergences: Uniform: 2.210870103401713 Unigram: 0.8286931286874697
2022-03-23 12:30:52 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:23 | INFO | train_inner | epoch 033:     81 / 157 loss=6.8, ppl=111.4, wps=32485.7, ups=1.29, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.355, loss_scale=4, train_wall=37, gb_free=11.6, wall=3269
2022-03-23 12:31:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these rough magnets to shape a popular glide.
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father left his mother when she was pregnant with him.
2022-03-23 12:32:07 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and has a waisenchild left, so we asked ourselves, well, what do we do with her?
2022-03-23 12:32:11 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs, and not about genocide, or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:32:15 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contures of the face, and the basic form, and through the thief, the whole portion structure and all the folds.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and measured to me here at tedwomen is that -- well, when dinner was the best summary, when someone said, "turn you to the men in your table and tell you," if the revolution begins, we'll support you. '"the truth, women, we've already been supporting you for a long time."
2022-03-23 12:32:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane was a stumbling result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable variables, and a cooling system that allows us to use a steady machine in the steady direction, or if you're in the ground, you're either going to be able to be able to operate, or if you're going to see that you're going to be able to see that you're going to operate, you're going to be operating, all connected to be able to be able to see that you're going to be operating, or you're going to be able to be able to be able to be able to be able to be able to see that you're going to operate in the ground, all, all, or you're going to operate, all, all, all the way, all the way, all the way, all the way,
2022-03-23 12:32:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.968 | ppl 250.37 | bleu 31.85 | wps 4598.4 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.87
2022-03-23 12:32:31 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:32:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:32:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt
2022-03-23 12:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.025_0.325_0.65_#4/checkpoint_last.pt (epoch 33 @ 5176 updates, score 31.85) (writing took 0.8717410550452769 seconds)
2022-03-23 12:32:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:32:32 | INFO | train | epoch 033 | loss 6.749 | ppl 107.57 | wps 39208.1 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.345 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3338
2022-03-23 12:32:32 | INFO | fairseq_cli.train | done training in 3337.6 seconds
