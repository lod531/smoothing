Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 207263903: <w103_size_0.03125_fp16_label_smoothing_0.01_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.01_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:17:56 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:15 2022
Terminated at Sat Mar  5 14:18:54 2022
Results reported at Sat Mar  5 14:18:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.01 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   28.84 sec.
    Max Memory :                                 3083 MB
    Average Memory :                             2330.50 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16917.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   39 sec.
    Turnaround time :                            58 sec.

The output (if any) follows:

2022-03-05 14:18:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.01, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:18:25 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-05 14:18:27 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-05 14:18:27 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:18:27 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:18:27 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:18:27 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-05 14:18:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:18:27 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-05 14:18:33 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:18:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:18:33 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-05 14:18:33 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:18:33 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:18:33 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:18:33 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 14:18:33 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 14:18:33 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:18:33 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-05 14:18:33 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:18:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:18:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:18:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4216, in multi_head_attention_forward
    k = linear(key, k_proj_weight_non_opt, in_proj_bias[embed_dim:(embed_dim * 2)])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 1692, in linear
    output = input.matmul(weight.t())
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 207264035: <w103_size_0.03125_fp16_label_smoothing_0.01_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.01_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:17 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:21:45 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:21:45 2022
Terminated at Sun Mar  6 08:56:03 2022
Results reported at Sun Mar  6 08:56:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.01 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66812.39 sec.
    Max Memory :                                 6717 MB
    Average Memory :                             3744.56 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13283.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66857 sec.
    Turnaround time :                            66886 sec.

The output (if any) follows:

2022-03-05 14:21:52 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.01, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:21:52 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:21:53 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:21:53 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:21:53 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:21:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:21:53 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:21:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:21:53 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:21:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:21:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-05 14:21:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:21:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:21:56 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:21:56 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 14:21:56 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 14:21:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:21:56 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:21:56 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:22:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.412 | nll_loss 15.392 | ppl 43009.5 | wps 48302.1 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:24:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.412) (writing took 4.230505939107388 seconds)
2022-03-05 14:24:11 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:11 | INFO | train | epoch 001 | loss 16.533 | nll_loss 16.525 | ppl 94281.2 | wps 27142.5 | ups 0.42 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.035 | loss_scale 4 | train_wall 115 | gb_free 21.6 | wall 135
2022-03-05 14:24:11 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:03 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.913 | nll_loss 13.878 | ppl 15058.4 | wps 47953.4 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.913
2022-03-05 14:26:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:26:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.913) (writing took 4.102488818112761 seconds)
2022-03-05 14:26:07 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:07 | INFO | train | epoch 002 | loss 14.612 | nll_loss 14.584 | ppl 24565.2 | wps 27507.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.287 | loss_scale 4 | train_wall 96 | gb_free 21.6 | wall 251
2022-03-05 14:26:07 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:22 | INFO | train_inner | epoch 003:      7 / 49 loss=15.409, nll_loss=15.39, ppl=42928.7, wps=27478.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.447, loss_scale=4, train_wall=225, gb_free=21.6, wall=266
2022-03-05 14:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:27:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.227 | nll_loss 13.186 | ppl 9316.42 | wps 47939.7 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.227
2022-03-05 14:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:27:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:28:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.227) (writing took 4.319267455022782 seconds)
2022-03-05 14:28:03 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:03 | INFO | train | epoch 003 | loss 13.648 | nll_loss 13.611 | ppl 12508.3 | wps 27391.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.52 | loss_scale 8 | train_wall 96 | gb_free 21.6 | wall 367
2022-03-05 14:28:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:29:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.36 | nll_loss 12.309 | ppl 5073.3 | wps 47938.2 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.36
2022-03-05 14:29:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:29:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:29:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.36) (writing took 4.2349978210404515 seconds)
2022-03-05 14:29:59 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:29:59 | INFO | train | epoch 004 | loss 12.863 | nll_loss 12.818 | ppl 7222.06 | wps 27413.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.306 | loss_scale 8 | train_wall 96 | gb_free 21.6 | wall 483
2022-03-05 14:29:59 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:29:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:19 | INFO | train_inner | epoch 005:      9 / 49 loss=13.122, nll_loss=13.079, ppl=8653.99, wps=27450.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.373, loss_scale=8, train_wall=196, gb_free=21.6, wall=503
2022-03-05 14:31:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:31:50 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.566 | nll_loss 11.505 | ppl 2906.13 | wps 48080.7 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.566
2022-03-05 14:31:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:31:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:31:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.566) (writing took 4.147238831967115 seconds)
2022-03-05 14:31:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:31:54 | INFO | train | epoch 005 | loss 11.983 | nll_loss 11.927 | ppl 3895.24 | wps 27477.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.996 | loss_scale 8 | train_wall 96 | gb_free 21.6 | wall 598
2022-03-05 14:31:54 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:33:46 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.928 | nll_loss 10.856 | ppl 1853.65 | wps 47992.2 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.928
2022-03-05 14:33:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:33:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:33:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.928) (writing took 4.1432922799140215 seconds)
2022-03-05 14:33:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:33:50 | INFO | train | epoch 006 | loss 11.234 | nll_loss 11.168 | ppl 2301.48 | wps 27453.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.775 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 714
2022-03-05 14:33:50 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:14 | INFO | train_inner | epoch 007:     11 / 49 loss=11.457, nll_loss=11.394, ppl=2691.88, wps=27509.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.843, loss_scale=16, train_wall=196, gb_free=21.6, wall=739
2022-03-05 14:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:35:42 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.514 | nll_loss 10.434 | ppl 1383.28 | wps 48084.3 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.514
2022-03-05 14:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:35:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:35:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.514) (writing took 4.149642049800605 seconds)
2022-03-05 14:35:46 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:35:46 | INFO | train | epoch 007 | loss 10.675 | nll_loss 10.599 | ppl 1551.07 | wps 27450.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.634 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 830
2022-03-05 14:35:46 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:37:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:37:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.261 | nll_loss 10.174 | ppl 1155.43 | wps 47882.7 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.261
2022-03-05 14:37:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:37:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:37:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.261) (writing took 4.1387631229590625 seconds)
2022-03-05 14:37:42 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:37:42 | INFO | train | epoch 008 | loss 10.325 | nll_loss 10.242 | ppl 1210.76 | wps 27474.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.482 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 946
2022-03-05 14:37:42 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:37:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:10 | INFO | train_inner | epoch 009:     13 / 49 loss=10.418, nll_loss=10.336, ppl=1292.62, wps=27504.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.531, loss_scale=32, train_wall=196, gb_free=21.6, wall=974
2022-03-05 14:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:39:33 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.079 | nll_loss 9.987 | ppl 1014.54 | wps 48037.5 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.079
2022-03-05 14:39:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:39:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:39:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:39:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.079) (writing took 4.083846490830183 seconds)
2022-03-05 14:39:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:39:37 | INFO | train | epoch 009 | loss 10.096 | nll_loss 10.006 | ppl 1027.97 | wps 27459.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.513 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1061
2022-03-05 14:39:37 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:39:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:41:29 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.914 | nll_loss 9.817 | ppl 902.26 | wps 48036.2 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.914
2022-03-05 14:41:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:41:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.914) (writing took 4.102428433019668 seconds)
2022-03-05 14:41:33 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:41:33 | INFO | train | epoch 010 | loss 9.907 | nll_loss 9.812 | ppl 898.91 | wps 27476.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.535 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1177
2022-03-05 14:41:33 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:06 | INFO | train_inner | epoch 011:     15 / 49 loss=9.949, nll_loss=9.855, ppl=926.36, wps=27508.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.543, loss_scale=32, train_wall=196, gb_free=21.6, wall=1210
2022-03-05 14:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:43:25 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.773 | nll_loss 9.674 | ppl 816.94 | wps 48171.3 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 9.773
2022-03-05 14:43:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:43:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 9.773) (writing took 4.102369945030659 seconds)
2022-03-05 14:43:29 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:43:29 | INFO | train | epoch 011 | loss 9.734 | nll_loss 9.636 | ppl 795.41 | wps 26900.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.566 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1293
2022-03-05 14:43:29 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:45:20 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.633 | nll_loss 9.53 | ppl 739.53 | wps 48038.6 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.633
2022-03-05 14:45:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:45:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:45:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.633) (writing took 4.094094182830304 seconds)
2022-03-05 14:45:24 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:45:24 | INFO | train | epoch 012 | loss 9.571 | nll_loss 9.47 | ppl 708.93 | wps 27453.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.645 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1409
2022-03-05 14:45:24 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:04 | INFO | train_inner | epoch 013:     18 / 49 loss=9.594, nll_loss=9.493, ppl=720.79, wps=27253.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.62, loss_scale=32, train_wall=198, gb_free=21.6, wall=1448
2022-03-05 14:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:47:16 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.521 | nll_loss 9.417 | ppl 683.59 | wps 48217.1 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.521
2022-03-05 14:47:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:47:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.521) (writing took 4.0912717040628195 seconds)
2022-03-05 14:47:20 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:47:20 | INFO | train | epoch 013 | loss 9.417 | nll_loss 9.313 | ppl 636.07 | wps 27508.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.719 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1524
2022-03-05 14:47:20 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:49:12 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.399 | nll_loss 9.292 | ppl 626.67 | wps 48125.3 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.399
2022-03-05 14:49:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:49:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:49:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.399) (writing took 4.088107366813347 seconds)
2022-03-05 14:49:16 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:49:16 | INFO | train | epoch 014 | loss 9.274 | nll_loss 9.167 | ppl 574.86 | wps 26911.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.748 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1640
2022-03-05 14:49:16 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:49:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:50:02 | INFO | train_inner | epoch 015:     21 / 49 loss=9.287, nll_loss=9.181, ppl=580.27, wps=27279, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.741, loss_scale=32, train_wall=198, gb_free=21.6, wall=1686
2022-03-05 14:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:51:07 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.298 | nll_loss 9.189 | ppl 583.79 | wps 48097.3 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.298
2022-03-05 14:51:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:51:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:51:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.298) (writing took 4.131665647029877 seconds)
2022-03-05 14:51:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:51:11 | INFO | train | epoch 015 | loss 9.132 | nll_loss 9.023 | ppl 520.25 | wps 27455.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.752 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 1755
2022-03-05 14:51:11 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:51:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:51:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:53:03 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.21 | nll_loss 9.099 | ppl 548.39 | wps 48189.6 | wpb 510.9 | bsz 1 | num_updates 776 | best_loss 9.21
2022-03-05 14:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 776 updates
2022-03-05 14:53:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:53:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 16 @ 776 updates, score 9.21) (writing took 4.123477584915236 seconds)
2022-03-05 14:53:07 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:53:07 | INFO | train | epoch 016 | loss 8.997 | nll_loss 8.886 | ppl 472.98 | wps 26913.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 776 | lr 9.70806e-05 | gnorm 0.908 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 1871
2022-03-05 14:53:07 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:53:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:00 | INFO | train_inner | epoch 017:     24 / 49 loss=9.004, nll_loss=8.892, ppl=475.01, wps=27254.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.856, loss_scale=16, train_wall=198, gb_free=21.6, wall=1924
2022-03-05 14:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:54:59 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.101 | nll_loss 8.988 | ppl 507.8 | wps 48041.8 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.101
2022-03-05 14:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-05 14:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.101) (writing took 4.050016865134239 seconds)
2022-03-05 14:55:03 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:55:03 | INFO | train | epoch 017 | loss 8.865 | nll_loss 8.751 | ppl 430.76 | wps 27500.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.863 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 1987
2022-03-05 14:55:03 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:56:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:56:54 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.006 | nll_loss 8.892 | ppl 474.98 | wps 48157 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.006
2022-03-05 14:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-05 14:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:56:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.006) (writing took 4.164361234987155 seconds)
2022-03-05 14:56:58 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:56:58 | INFO | train | epoch 018 | loss 8.734 | nll_loss 8.617 | ppl 392.59 | wps 27455.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.946 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 2102
2022-03-05 14:56:58 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:56 | INFO | train_inner | epoch 019:     26 / 49 loss=8.731, nll_loss=8.614, ppl=391.92, wps=27526.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.92, loss_scale=32, train_wall=196, gb_free=21.6, wall=2160
2022-03-05 14:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:58:50 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.929 | nll_loss 8.809 | ppl 448.61 | wps 48161.9 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 8.929
2022-03-05 14:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 14:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 14:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 8.929) (writing took 4.153868288034573 seconds)
2022-03-05 14:58:54 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 14:58:54 | INFO | train | epoch 019 | loss 8.607 | nll_loss 8.488 | ppl 359.08 | wps 27485.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.922 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 2218
2022-03-05 14:58:54 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 14:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:00:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:00:46 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.845 | nll_loss 8.724 | ppl 422.96 | wps 48076.3 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 8.845
2022-03-05 15:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-05 15:00:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 20 @ 971 updates, score 8.845) (writing took 4.1528336689807475 seconds)
2022-03-05 15:00:50 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:00:50 | INFO | train | epoch 020 | loss 8.485 | nll_loss 8.364 | ppl 329.42 | wps 26900.3 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.901 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 2334
2022-03-05 15:00:50 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:54 | INFO | train_inner | epoch 021:     29 / 49 loss=8.479, nll_loss=8.357, ppl=327.88, wps=27254.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.922, loss_scale=16, train_wall=198, gb_free=21.6, wall=2398
2022-03-05 15:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:02:41 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.772 | nll_loss 8.65 | ppl 401.62 | wps 48121.5 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.772
2022-03-05 15:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 15:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.772) (writing took 4.074208765057847 seconds)
2022-03-05 15:02:45 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:02:45 | INFO | train | epoch 021 | loss 8.369 | nll_loss 8.245 | ppl 303.45 | wps 27470.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.955 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 2449
2022-03-05 15:02:45 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:04:37 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.708 | nll_loss 8.584 | ppl 383.61 | wps 48003.6 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.708
2022-03-05 15:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:04:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:04:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:04:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.708) (writing took 4.101805500918999 seconds)
2022-03-05 15:04:41 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:04:41 | INFO | train | epoch 022 | loss 8.253 | nll_loss 8.127 | ppl 279.61 | wps 27450 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.891 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 2565
2022-03-05 15:04:41 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:04:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:05:50 | INFO | train_inner | epoch 023:     31 / 49 loss=8.243, nll_loss=8.117, ppl=277.67, wps=27499.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.964, loss_scale=32, train_wall=196, gb_free=21.6, wall=2634
2022-03-05 15:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:06:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.653 | nll_loss 8.53 | ppl 369.54 | wps 48095.8 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 8.653
2022-03-05 15:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 8.653) (writing took 4.126046017045155 seconds)
2022-03-05 15:06:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:06:37 | INFO | train | epoch 023 | loss 8.15 | nll_loss 8.022 | ppl 260.02 | wps 27444.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 1.089 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 2681
2022-03-05 15:06:37 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:08:29 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.613 | nll_loss 8.487 | ppl 358.82 | wps 48116.4 | wpb 510.9 | bsz 1 | num_updates 1167 | best_loss 8.613
2022-03-05 15:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1167 updates
2022-03-05 15:08:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:08:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 24 @ 1167 updates, score 8.613) (writing took 4.067185275023803 seconds)
2022-03-05 15:08:33 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:08:33 | INFO | train | epoch 024 | loss 8.04 | nll_loss 7.91 | ppl 240.48 | wps 27459.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1167 | lr 0.000145946 | gnorm 0.936 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 2797
2022-03-05 15:08:33 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:09:45 | INFO | train_inner | epoch 025:     33 / 49 loss=8.023, nll_loss=7.892, ppl=237.58, wps=27503.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.98, loss_scale=32, train_wall=196, gb_free=21.6, wall=2870
2022-03-05 15:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:10:24 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.551 | nll_loss 8.423 | ppl 343.33 | wps 47987.3 | wpb 510.9 | bsz 1 | num_updates 1216 | best_loss 8.551
2022-03-05 15:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1216 updates
2022-03-05 15:10:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:10:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 25 @ 1216 updates, score 8.551) (writing took 4.1291556970681995 seconds)
2022-03-05 15:10:28 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:10:28 | INFO | train | epoch 025 | loss 7.934 | nll_loss 7.802 | ppl 223.25 | wps 27461.2 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1216 | lr 0.00015207 | gnorm 0.949 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 2913
2022-03-05 15:10:28 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:10:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:12:20 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.507 | nll_loss 8.378 | ppl 332.74 | wps 48037.6 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 8.507
2022-03-05 15:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:12:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:12:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:12:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 8.507) (writing took 4.112208804115653 seconds)
2022-03-05 15:12:24 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:12:24 | INFO | train | epoch 026 | loss 7.832 | nll_loss 7.698 | ppl 207.71 | wps 26941.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 1.04 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 3028
2022-03-05 15:12:24 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:13:43 | INFO | train_inner | epoch 027:     36 / 49 loss=7.813, nll_loss=7.679, ppl=204.89, wps=27269.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=1.004, loss_scale=32, train_wall=198, gb_free=21.6, wall=3107
2022-03-05 15:14:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:14:16 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.469 | nll_loss 8.339 | ppl 323.71 | wps 48167.8 | wpb 510.9 | bsz 1 | num_updates 1313 | best_loss 8.469
2022-03-05 15:14:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1313 updates
2022-03-05 15:14:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:14:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:14:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 27 @ 1313 updates, score 8.469) (writing took 4.149953620042652 seconds)
2022-03-05 15:14:20 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:14:20 | INFO | train | epoch 027 | loss 7.731 | nll_loss 7.596 | ppl 193.41 | wps 27458.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1313 | lr 0.000164192 | gnorm 0.999 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 3144
2022-03-05 15:14:20 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:16:11 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.433 | nll_loss 8.302 | ppl 315.62 | wps 48165.1 | wpb 510.9 | bsz 1 | num_updates 1362 | best_loss 8.433
2022-03-05 15:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1362 updates
2022-03-05 15:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 28 @ 1362 updates, score 8.433) (writing took 4.091160804033279 seconds)
2022-03-05 15:16:15 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:16:15 | INFO | train | epoch 028 | loss 7.629 | nll_loss 7.492 | ppl 179.97 | wps 27467.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1362 | lr 0.000170316 | gnorm 1.029 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 3259
2022-03-05 15:16:15 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:16:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:17:41 | INFO | train_inner | epoch 029:     39 / 49 loss=7.6, nll_loss=7.462, ppl=176.28, wps=27252.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1.038, loss_scale=32, train_wall=198, gb_free=21.6, wall=3345
2022-03-05 15:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:18:07 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.4 | nll_loss 8.267 | ppl 308.08 | wps 47992.4 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 8.4
2022-03-05 15:18:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:18:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 8.4) (writing took 4.094680469948798 seconds)
2022-03-05 15:18:11 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:18:11 | INFO | train | epoch 029 | loss 7.527 | nll_loss 7.387 | ppl 167.38 | wps 26899.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 1.058 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 3375
2022-03-05 15:18:11 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:19:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:20:03 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.391 | nll_loss 8.258 | ppl 306.05 | wps 48262.8 | wpb 510.9 | bsz 1 | num_updates 1459 | best_loss 8.391
2022-03-05 15:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1459 updates
2022-03-05 15:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 30 @ 1459 updates, score 8.391) (writing took 4.089477682020515 seconds)
2022-03-05 15:20:07 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:20:07 | INFO | train | epoch 030 | loss 7.425 | nll_loss 7.283 | ppl 155.77 | wps 27489.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1459 | lr 0.000182439 | gnorm 1.028 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 3491
2022-03-05 15:20:07 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:21:37 | INFO | train_inner | epoch 031:     41 / 49 loss=7.393, nll_loss=7.251, ppl=152.27, wps=27515.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.039, loss_scale=32, train_wall=196, gb_free=21.6, wall=3581
2022-03-05 15:21:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:58 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.323 | nll_loss 8.186 | ppl 291.13 | wps 48118.3 | wpb 510.9 | bsz 1 | num_updates 1508 | best_loss 8.323
2022-03-05 15:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1508 updates
2022-03-05 15:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 31 @ 1508 updates, score 8.323) (writing took 4.093905072892085 seconds)
2022-03-05 15:22:02 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:22:02 | INFO | train | epoch 031 | loss 7.323 | nll_loss 7.18 | ppl 144.96 | wps 27460.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1508 | lr 0.000188562 | gnorm 1.036 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 3607
2022-03-05 15:22:02 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:54 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.32 | nll_loss 8.184 | ppl 290.83 | wps 48263.2 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 8.32
2022-03-05 15:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:23:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:23:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 8.32) (writing took 4.105959265027195 seconds)
2022-03-05 15:23:58 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:23:58 | INFO | train | epoch 032 | loss 7.218 | nll_loss 7.073 | ppl 134.63 | wps 26854.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 1.054 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 3722
2022-03-05 15:23:58 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:24:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:25:38 | INFO | train_inner | epoch 033:     45 / 49 loss=7.181, nll_loss=7.035, ppl=131.11, wps=26978.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.051, loss_scale=16, train_wall=200, gb_free=21.6, wall=3822
2022-03-05 15:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:50 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.276 | nll_loss 8.137 | ppl 281.58 | wps 48312.3 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.276
2022-03-05 15:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-05 15:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.276) (writing took 4.137987150112167 seconds)
2022-03-05 15:25:54 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:25:54 | INFO | train | epoch 033 | loss 7.119 | nll_loss 6.972 | ppl 125.53 | wps 26893.8 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 1.059 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 3838
2022-03-05 15:25:54 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:46 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.267 | nll_loss 8.128 | ppl 279.85 | wps 48436.6 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.267
2022-03-05 15:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:27:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:27:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:27:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.267) (writing took 4.124511855887249 seconds)
2022-03-05 15:27:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:27:50 | INFO | train | epoch 034 | loss 7.02 | nll_loss 6.871 | ppl 117.08 | wps 27462.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 1.06 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 3954
2022-03-05 15:27:50 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:27:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:29:33 | INFO | train_inner | epoch 035:     47 / 49 loss=6.977, nll_loss=6.827, ppl=113.55, wps=27509.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.071, loss_scale=32, train_wall=196, gb_free=21.6, wall=4058
2022-03-05 15:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:29:41 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.261 | nll_loss 8.122 | ppl 278.56 | wps 48126.9 | wpb 510.9 | bsz 1 | num_updates 1702 | best_loss 8.261
2022-03-05 15:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1702 updates
2022-03-05 15:29:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 35 @ 1702 updates, score 8.261) (writing took 4.032100037904456 seconds)
2022-03-05 15:29:45 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:29:45 | INFO | train | epoch 035 | loss 6.921 | nll_loss 6.77 | ppl 109.1 | wps 27487.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1702 | lr 0.000212807 | gnorm 1.099 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4070
2022-03-05 15:29:45 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:31:37 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.245 | nll_loss 8.104 | ppl 275.19 | wps 48256.8 | wpb 510.9 | bsz 1 | num_updates 1751 | best_loss 8.245
2022-03-05 15:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1751 updates
2022-03-05 15:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 36 @ 1751 updates, score 8.245) (writing took 4.07357679400593 seconds)
2022-03-05 15:31:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:31:41 | INFO | train | epoch 036 | loss 6.82 | nll_loss 6.667 | ppl 101.65 | wps 27484.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1751 | lr 0.000218931 | gnorm 1.086 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4185
2022-03-05 15:31:41 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:31:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:33:28 | INFO | train_inner | epoch 037:     49 / 49 loss=6.773, nll_loss=6.62, ppl=98.33, wps=27512.8, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.109, loss_scale=32, train_wall=195, gb_free=21.6, wall=4292
2022-03-05 15:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:33:33 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.225 | nll_loss 8.084 | ppl 271.35 | wps 48173.9 | wpb 510.9 | bsz 1 | num_updates 1800 | best_loss 8.225
2022-03-05 15:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1800 updates
2022-03-05 15:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 37 @ 1800 updates, score 8.225) (writing took 4.044241752009839 seconds)
2022-03-05 15:33:37 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:33:37 | INFO | train | epoch 037 | loss 6.722 | nll_loss 6.567 | ppl 94.8 | wps 27488 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1800 | lr 0.000225055 | gnorm 1.125 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4301
2022-03-05 15:33:37 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:35:28 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.204 | nll_loss 8.059 | ppl 266.6 | wps 48132.6 | wpb 510.9 | bsz 1 | num_updates 1848 | best_loss 8.204
2022-03-05 15:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1848 updates
2022-03-05 15:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:35:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt
2022-03-05 15:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_best.pt (epoch 38 @ 1848 updates, score 8.204) (writing took 4.076155188027769 seconds)
2022-03-05 15:35:32 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:35:32 | INFO | train | epoch 038 | loss 6.621 | nll_loss 6.464 | ppl 88.3 | wps 26909.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1848 | lr 0.000231054 | gnorm 1.097 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4416
2022-03-05 15:35:32 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:37:24 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.219 | nll_loss 8.074 | ppl 269.55 | wps 48250 | wpb 510.9 | bsz 1 | num_updates 1897 | best_loss 8.204
2022-03-05 15:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1897 updates
2022-03-05 15:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:37:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:37:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 39 @ 1897 updates, score 8.219) (writing took 1.7988958461210132 seconds)
2022-03-05 15:37:26 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:37:26 | INFO | train | epoch 039 | loss 6.526 | nll_loss 6.368 | ppl 82.57 | wps 28043.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1897 | lr 0.000237178 | gnorm 1.125 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4530
2022-03-05 15:37:26 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:37:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:37:32 | INFO | train_inner | epoch 040:      3 / 49 loss=6.568, nll_loss=6.41, ppl=85.04, wps=26549, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.107, loss_scale=32, train_wall=198, gb_free=21.6, wall=4536
2022-03-05 15:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:39:17 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.244 | nll_loss 8.1 | ppl 274.37 | wps 48106.1 | wpb 510.9 | bsz 1 | num_updates 1946 | best_loss 8.204
2022-03-05 15:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1946 updates
2022-03-05 15:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 40 @ 1946 updates, score 8.244) (writing took 1.95796166989021 seconds)
2022-03-05 15:39:19 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:39:19 | INFO | train | epoch 040 | loss 6.428 | nll_loss 6.267 | ppl 77.01 | wps 27965.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1946 | lr 0.000243301 | gnorm 1.116 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4643
2022-03-05 15:39:19 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:39:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:41:11 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.233 | nll_loss 8.089 | ppl 272.2 | wps 48133.6 | wpb 510.9 | bsz 1 | num_updates 1994 | best_loss 8.204
2022-03-05 15:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1994 updates
2022-03-05 15:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 41 @ 1994 updates, score 8.233) (writing took 1.9534028850030154 seconds)
2022-03-05 15:41:13 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:41:13 | INFO | train | epoch 041 | loss 6.334 | nll_loss 6.171 | ppl 72.07 | wps 27406.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1994 | lr 0.0002493 | gnorm 1.136 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4757
2022-03-05 15:41:13 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:41:26 | INFO | train_inner | epoch 042:      6 / 49 loss=6.37, nll_loss=6.208, ppl=73.94, wps=27745.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.135, loss_scale=32, train_wall=198, gb_free=21.6, wall=4770
2022-03-05 15:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:43:04 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.261 | nll_loss 8.114 | ppl 276.99 | wps 48101.1 | wpb 510.9 | bsz 1 | num_updates 2043 | best_loss 8.204
2022-03-05 15:43:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2043 updates
2022-03-05 15:43:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 42 @ 2043 updates, score 8.261) (writing took 1.9297704240307212 seconds)
2022-03-05 15:43:06 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:43:06 | INFO | train | epoch 042 | loss 6.239 | nll_loss 6.075 | ppl 67.39 | wps 28002.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2043 | lr 0.000255424 | gnorm 1.156 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 4870
2022-03-05 15:43:06 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:58 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.276 | nll_loss 8.129 | ppl 279.92 | wps 48182.4 | wpb 510.9 | bsz 1 | num_updates 2092 | best_loss 8.204
2022-03-05 15:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2092 updates
2022-03-05 15:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:45:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:45:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 43 @ 2092 updates, score 8.276) (writing took 1.9603408840484917 seconds)
2022-03-05 15:45:00 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:45:00 | INFO | train | epoch 043 | loss 6.147 | nll_loss 5.981 | ppl 63.16 | wps 28011 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2092 | lr 0.000261548 | gnorm 1.2 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 4984
2022-03-05 15:45:00 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:45:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:45:18 | INFO | train_inner | epoch 044:      8 / 49 loss=6.177, nll_loss=6.011, ppl=64.5, wps=28041.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.162, loss_scale=64, train_wall=196, gb_free=21.6, wall=5002
2022-03-05 15:45:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:51 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.299 | nll_loss 8.149 | ppl 283.89 | wps 48150.2 | wpb 510.9 | bsz 1 | num_updates 2140 | best_loss 8.204
2022-03-05 15:46:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2140 updates
2022-03-05 15:46:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:46:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:46:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 44 @ 2140 updates, score 8.299) (writing took 1.9781447139102966 seconds)
2022-03-05 15:46:53 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:46:53 | INFO | train | epoch 044 | loss 6.047 | nll_loss 5.879 | ppl 58.84 | wps 27430.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2140 | lr 0.000267547 | gnorm 1.152 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 5097
2022-03-05 15:46:53 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:46:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:45 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.324 | nll_loss 8.176 | ppl 289.15 | wps 48228.3 | wpb 510.9 | bsz 1 | num_updates 2189 | best_loss 8.204
2022-03-05 15:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2189 updates
2022-03-05 15:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 45 @ 2189 updates, score 8.324) (writing took 1.897667130222544 seconds)
2022-03-05 15:48:47 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:48:47 | INFO | train | epoch 045 | loss 5.958 | nll_loss 5.788 | ppl 55.25 | wps 28039.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2189 | lr 0.00027367 | gnorm 1.193 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 5211
2022-03-05 15:48:47 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:49:11 | INFO | train_inner | epoch 046:     11 / 49 loss=5.984, nll_loss=5.814, ppl=56.26, wps=27788.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.179, loss_scale=32, train_wall=198, gb_free=21.6, wall=5235
2022-03-05 15:50:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:38 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.373 | nll_loss 8.224 | ppl 298.95 | wps 48021.2 | wpb 510.9 | bsz 1 | num_updates 2237 | best_loss 8.204
2022-03-05 15:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2237 updates
2022-03-05 15:50:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:50:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 46 @ 2237 updates, score 8.373) (writing took 1.9289351259358227 seconds)
2022-03-05 15:50:40 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:50:40 | INFO | train | epoch 046 | loss 5.867 | nll_loss 5.695 | ppl 51.81 | wps 27429.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2237 | lr 0.000279669 | gnorm 1.262 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 5324
2022-03-05 15:50:40 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:50:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:51:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:32 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.367 | nll_loss 8.218 | ppl 297.79 | wps 47951.5 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.204
2022-03-05 15:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-05 15:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:52:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.367) (writing took 1.9209090298973024 seconds)
2022-03-05 15:52:34 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:52:34 | INFO | train | epoch 047 | loss 5.773 | nll_loss 5.599 | ppl 48.46 | wps 27405.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.227 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 5438
2022-03-05 15:52:34 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:53:07 | INFO | train_inner | epoch 048:     15 / 49 loss=5.794, nll_loss=5.62, ppl=49.17, wps=27512.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.24, loss_scale=16, train_wall=200, gb_free=21.6, wall=5471
2022-03-05 15:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:25 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.424 | nll_loss 8.274 | ppl 309.56 | wps 47628.5 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.204
2022-03-05 15:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-05 15:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 48 @ 2334 updates, score 8.424) (writing took 1.8225020528770983 seconds)
2022-03-05 15:54:27 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:54:27 | INFO | train | epoch 048 | loss 5.679 | nll_loss 5.503 | ppl 45.34 | wps 28051.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.206 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 5551
2022-03-05 15:54:27 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:19 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.478 | nll_loss 8.328 | ppl 321.36 | wps 48176.9 | wpb 510.9 | bsz 1 | num_updates 2383 | best_loss 8.204
2022-03-05 15:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2383 updates
2022-03-05 15:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:56:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 49 @ 2383 updates, score 8.478) (writing took 1.9091340489685535 seconds)
2022-03-05 15:56:20 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:56:20 | INFO | train | epoch 049 | loss 5.587 | nll_loss 5.409 | ppl 42.49 | wps 28003.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2383 | lr 0.000297915 | gnorm 1.266 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 5665
2022-03-05 15:56:20 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:56:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:56:58 | INFO | train_inner | epoch 050:     17 / 49 loss=5.605, nll_loss=5.427, ppl=43.03, wps=28056.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.246, loss_scale=32, train_wall=196, gb_free=21.6, wall=5702
2022-03-05 15:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:58:12 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.544 | nll_loss 8.392 | ppl 335.82 | wps 48056 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.204
2022-03-05 15:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 15:58:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:58:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 15:58:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 8.544) (writing took 1.8400095801334828 seconds)
2022-03-05 15:58:14 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 15:58:14 | INFO | train | epoch 050 | loss 5.495 | nll_loss 5.314 | ppl 39.79 | wps 28024.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.239 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 5778
2022-03-05 15:58:14 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 15:58:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:00:05 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 8.562 | nll_loss 8.409 | ppl 339.96 | wps 47798.7 | wpb 510.9 | bsz 1 | num_updates 2481 | best_loss 8.204
2022-03-05 16:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2481 updates
2022-03-05 16:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 51 @ 2481 updates, score 8.562) (writing took 1.821239473996684 seconds)
2022-03-05 16:00:07 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:00:07 | INFO | train | epoch 051 | loss 5.407 | nll_loss 5.224 | ppl 37.38 | wps 28012.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2481 | lr 0.000310163 | gnorm 1.344 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 5891
2022-03-05 16:00:07 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:00:49 | INFO | train_inner | epoch 052:     19 / 49 loss=5.409, nll_loss=5.226, ppl=37.44, wps=28050.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.288, loss_scale=32, train_wall=196, gb_free=21.6, wall=5933
2022-03-05 16:01:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:01:59 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 8.617 | nll_loss 8.468 | ppl 354.04 | wps 48088.1 | wpb 510.9 | bsz 1 | num_updates 2529 | best_loss 8.204
2022-03-05 16:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2529 updates
2022-03-05 16:01:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 52 @ 2529 updates, score 8.617) (writing took 1.860529127996415 seconds)
2022-03-05 16:02:01 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:02:01 | INFO | train | epoch 052 | loss 5.308 | nll_loss 5.124 | ppl 34.87 | wps 27461 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2529 | lr 0.000316162 | gnorm 1.262 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6005
2022-03-05 16:02:01 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:03:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:03:52 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 8.648 | nll_loss 8.497 | ppl 361.16 | wps 48215.1 | wpb 510.9 | bsz 1 | num_updates 2578 | best_loss 8.204
2022-03-05 16:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2578 updates
2022-03-05 16:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 53 @ 2578 updates, score 8.648) (writing took 1.8483502520248294 seconds)
2022-03-05 16:03:54 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:03:54 | INFO | train | epoch 053 | loss 5.223 | nll_loss 5.036 | ppl 32.82 | wps 28026.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2578 | lr 0.000322286 | gnorm 1.301 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6118
2022-03-05 16:03:54 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:04:43 | INFO | train_inner | epoch 054:     22 / 49 loss=5.231, nll_loss=5.045, ppl=33.01, wps=27801.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.33, loss_scale=16, train_wall=198, gb_free=21.6, wall=6167
2022-03-05 16:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:05:46 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 8.695 | nll_loss 8.544 | ppl 373.33 | wps 48330.1 | wpb 510.9 | bsz 1 | num_updates 2627 | best_loss 8.204
2022-03-05 16:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2627 updates
2022-03-05 16:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 54 @ 2627 updates, score 8.695) (writing took 1.9163734370376915 seconds)
2022-03-05 16:05:47 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:05:47 | INFO | train | epoch 054 | loss 5.135 | nll_loss 4.947 | ppl 30.84 | wps 28016.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2627 | lr 0.000328409 | gnorm 1.391 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6232
2022-03-05 16:05:48 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:05:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:07:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:07:39 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 8.757 | nll_loss 8.604 | ppl 389 | wps 47710.9 | wpb 510.9 | bsz 1 | num_updates 2676 | best_loss 8.204
2022-03-05 16:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2676 updates
2022-03-05 16:07:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:07:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 55 @ 2676 updates, score 8.757) (writing took 1.9066495399456471 seconds)
2022-03-05 16:07:41 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:07:41 | INFO | train | epoch 055 | loss 5.045 | nll_loss 4.855 | ppl 28.94 | wps 28014.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2676 | lr 0.000334533 | gnorm 1.371 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 6345
2022-03-05 16:07:41 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:07:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:08:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:08:36 | INFO | train_inner | epoch 056:     25 / 49 loss=5.043, nll_loss=4.853, ppl=28.9, wps=27785.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.347, loss_scale=16, train_wall=198, gb_free=21.6, wall=6400
2022-03-05 16:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:09:32 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 8.81 | nll_loss 8.658 | ppl 403.87 | wps 48106.7 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.204
2022-03-05 16:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 8.81) (writing took 1.8511847299523652 seconds)
2022-03-05 16:09:34 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:09:34 | INFO | train | epoch 056 | loss 4.952 | nll_loss 4.759 | ppl 27.08 | wps 27461.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.361 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6458
2022-03-05 16:09:34 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:26 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 8.876 | nll_loss 8.719 | ppl 421.28 | wps 48127.2 | wpb 510.9 | bsz 1 | num_updates 2773 | best_loss 8.204
2022-03-05 16:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2773 updates
2022-03-05 16:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:11:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:11:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 57 @ 2773 updates, score 8.876) (writing took 1.8073502730112523 seconds)
2022-03-05 16:11:28 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:11:28 | INFO | train | epoch 057 | loss 4.865 | nll_loss 4.67 | ppl 25.46 | wps 28018.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2773 | lr 0.000346656 | gnorm 1.409 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6572
2022-03-05 16:11:28 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:11:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:12:27 | INFO | train_inner | epoch 058:     27 / 49 loss=4.863, nll_loss=4.668, ppl=25.43, wps=28066.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.384, loss_scale=16, train_wall=196, gb_free=21.6, wall=6631
2022-03-05 16:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:19 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 8.871 | nll_loss 8.711 | ppl 419.15 | wps 48251 | wpb 510.9 | bsz 1 | num_updates 2822 | best_loss 8.204
2022-03-05 16:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2822 updates
2022-03-05 16:13:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:13:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 58 @ 2822 updates, score 8.871) (writing took 1.882696112850681 seconds)
2022-03-05 16:13:21 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:13:21 | INFO | train | epoch 058 | loss 4.775 | nll_loss 4.578 | ppl 23.89 | wps 28038.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2822 | lr 0.000352779 | gnorm 1.334 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6685
2022-03-05 16:13:21 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:15:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:12 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 8.922 | nll_loss 8.765 | ppl 435.08 | wps 48000.5 | wpb 510.9 | bsz 1 | num_updates 2870 | best_loss 8.204
2022-03-05 16:15:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2870 updates
2022-03-05 16:15:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 59 @ 2870 updates, score 8.922) (writing took 1.8753826599568129 seconds)
2022-03-05 16:15:14 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:15:14 | INFO | train | epoch 059 | loss 4.693 | nll_loss 4.495 | ppl 22.54 | wps 27473 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2870 | lr 0.000358778 | gnorm 1.455 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6798
2022-03-05 16:15:14 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:16:20 | INFO | train_inner | epoch 060:     30 / 49 loss=4.686, nll_loss=4.487, ppl=22.42, wps=27807.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.444, loss_scale=16, train_wall=198, gb_free=21.6, wall=6865
2022-03-05 16:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:06 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 8.988 | nll_loss 8.833 | ppl 455.99 | wps 48231.3 | wpb 510.9 | bsz 1 | num_updates 2919 | best_loss 8.204
2022-03-05 16:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2919 updates
2022-03-05 16:17:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 60 @ 2919 updates, score 8.988) (writing took 1.889468187931925 seconds)
2022-03-05 16:17:08 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:17:08 | INFO | train | epoch 060 | loss 4.599 | nll_loss 4.398 | ppl 21.08 | wps 28026.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2919 | lr 0.000364902 | gnorm 1.387 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 6912
2022-03-05 16:17:08 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:18:59 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.046 | nll_loss 8.888 | ppl 473.85 | wps 47591 | wpb 510.9 | bsz 1 | num_updates 2968 | best_loss 8.204
2022-03-05 16:18:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2968 updates
2022-03-05 16:18:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 61 @ 2968 updates, score 9.046) (writing took 1.8418382869567722 seconds)
2022-03-05 16:19:01 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:19:01 | INFO | train | epoch 061 | loss 4.521 | nll_loss 4.318 | ppl 19.94 | wps 28036.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2968 | lr 0.000371026 | gnorm 1.527 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 7025
2022-03-05 16:19:01 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:19:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:20:12 | INFO | train_inner | epoch 062:     32 / 49 loss=4.499, nll_loss=4.296, ppl=19.64, wps=28061.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.433, loss_scale=32, train_wall=196, gb_free=21.6, wall=7096
2022-03-05 16:20:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:20:53 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.099 | nll_loss 8.94 | ppl 490.98 | wps 48217.5 | wpb 510.9 | bsz 1 | num_updates 3017 | best_loss 8.204
2022-03-05 16:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3017 updates
2022-03-05 16:20:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 62 @ 3017 updates, score 9.099) (writing took 1.8429401491302997 seconds)
2022-03-05 16:20:55 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:20:55 | INFO | train | epoch 062 | loss 4.422 | nll_loss 4.217 | ppl 18.59 | wps 28020.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3017 | lr 0.00037715 | gnorm 1.411 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 7139
2022-03-05 16:20:55 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:22:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:22:46 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.181 | nll_loss 9.021 | ppl 519.45 | wps 48297.2 | wpb 510.9 | bsz 1 | num_updates 3066 | best_loss 8.204
2022-03-05 16:22:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3066 updates
2022-03-05 16:22:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:22:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:22:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 63 @ 3066 updates, score 9.181) (writing took 1.7765642288140953 seconds)
2022-03-05 16:22:48 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:22:48 | INFO | train | epoch 063 | loss 4.341 | nll_loss 4.134 | ppl 17.55 | wps 28055.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3066 | lr 0.000383273 | gnorm 1.505 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 7252
2022-03-05 16:22:48 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:24:05 | INFO | train_inner | epoch 064:     35 / 49 loss=4.321, nll_loss=4.113, ppl=17.3, wps=27804.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.441, loss_scale=32, train_wall=198, gb_free=21.6, wall=7329
2022-03-05 16:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:24:39 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.228 | nll_loss 9.071 | ppl 537.66 | wps 48181.3 | wpb 510.9 | bsz 1 | num_updates 3114 | best_loss 8.204
2022-03-05 16:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3114 updates
2022-03-05 16:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 64 @ 3114 updates, score 9.228) (writing took 1.8768728671129793 seconds)
2022-03-05 16:24:41 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:24:41 | INFO | train | epoch 064 | loss 4.253 | nll_loss 4.043 | ppl 16.49 | wps 27437.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3114 | lr 0.000389272 | gnorm 1.487 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 7365
2022-03-05 16:24:41 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:26:33 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.256 | nll_loss 9.094 | ppl 546.28 | wps 48187.3 | wpb 510.9 | bsz 1 | num_updates 3162 | best_loss 8.204
2022-03-05 16:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3162 updates
2022-03-05 16:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:26:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:26:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 65 @ 3162 updates, score 9.256) (writing took 1.8534164391458035 seconds)
2022-03-05 16:26:35 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:26:35 | INFO | train | epoch 065 | loss 4.167 | nll_loss 3.955 | ppl 15.51 | wps 27456.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3162 | lr 0.000395271 | gnorm 1.427 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 7479
2022-03-05 16:26:35 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:27:58 | INFO | train_inner | epoch 066:     38 / 49 loss=4.156, nll_loss=3.944, ppl=15.39, wps=27797, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.526, loss_scale=16, train_wall=198, gb_free=21.6, wall=7562
2022-03-05 16:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:28:26 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.262 | nll_loss 9.101 | ppl 549.28 | wps 48185.3 | wpb 510.9 | bsz 1 | num_updates 3211 | best_loss 8.204
2022-03-05 16:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3211 updates
2022-03-05 16:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 66 @ 3211 updates, score 9.262) (writing took 1.8295243340544403 seconds)
2022-03-05 16:28:28 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:28:28 | INFO | train | epoch 066 | loss 4.09 | nll_loss 3.877 | ppl 14.69 | wps 28028.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3211 | lr 0.000401395 | gnorm 1.537 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 7592
2022-03-05 16:28:28 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:30:19 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.368 | nll_loss 9.207 | ppl 590.85 | wps 48033.4 | wpb 510.9 | bsz 1 | num_updates 3260 | best_loss 8.204
2022-03-05 16:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3260 updates
2022-03-05 16:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 67 @ 3260 updates, score 9.368) (writing took 1.8556320942007005 seconds)
2022-03-05 16:30:21 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:30:21 | INFO | train | epoch 067 | loss 4.009 | nll_loss 3.793 | ppl 13.86 | wps 28034.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3260 | lr 0.000407519 | gnorm 1.566 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 7705
2022-03-05 16:30:21 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:31:49 | INFO | train_inner | epoch 068:     40 / 49 loss=3.98, nll_loss=3.763, ppl=13.57, wps=28069.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.511, loss_scale=32, train_wall=196, gb_free=21.6, wall=7794
2022-03-05 16:32:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:13 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.486 | nll_loss 9.331 | ppl 644.15 | wps 48033.3 | wpb 510.9 | bsz 1 | num_updates 3309 | best_loss 8.204
2022-03-05 16:32:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3309 updates
2022-03-05 16:32:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 68 @ 3309 updates, score 9.486) (writing took 1.8919842371251434 seconds)
2022-03-05 16:32:15 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:32:15 | INFO | train | epoch 068 | loss 3.921 | nll_loss 3.702 | ppl 13.02 | wps 28031.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3309 | lr 0.000413642 | gnorm 1.48 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 7819
2022-03-05 16:32:15 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:32:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:34:06 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.488 | nll_loss 9.329 | ppl 643.29 | wps 48052.4 | wpb 510.9 | bsz 1 | num_updates 3357 | best_loss 8.204
2022-03-05 16:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3357 updates
2022-03-05 16:34:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:34:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:34:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 69 @ 3357 updates, score 9.488) (writing took 1.8130614599213004 seconds)
2022-03-05 16:34:08 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:34:08 | INFO | train | epoch 069 | loss 3.844 | nll_loss 3.623 | ppl 12.32 | wps 27484.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3357 | lr 0.000419641 | gnorm 1.54 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 7932
2022-03-05 16:34:08 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:35:43 | INFO | train_inner | epoch 070:     43 / 49 loss=3.819, nll_loss=3.598, ppl=12.11, wps=27814, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.588, loss_scale=16, train_wall=198, gb_free=21.6, wall=8027
2022-03-05 16:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:35:59 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.613 | nll_loss 9.45 | ppl 699.48 | wps 48333.9 | wpb 510.9 | bsz 1 | num_updates 3406 | best_loss 8.204
2022-03-05 16:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3406 updates
2022-03-05 16:35:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 70 @ 3406 updates, score 9.613) (writing took 1.9272488481365144 seconds)
2022-03-05 16:36:01 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:36:01 | INFO | train | epoch 070 | loss 3.765 | nll_loss 3.542 | ppl 11.65 | wps 28026 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3406 | lr 0.000425765 | gnorm 1.584 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8045
2022-03-05 16:36:01 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:37:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:37:53 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.642 | nll_loss 9.482 | ppl 715.08 | wps 48116.1 | wpb 510.9 | bsz 1 | num_updates 3454 | best_loss 8.204
2022-03-05 16:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3454 updates
2022-03-05 16:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 71 @ 3454 updates, score 9.642) (writing took 1.8773244321346283 seconds)
2022-03-05 16:37:55 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:37:55 | INFO | train | epoch 071 | loss 3.707 | nll_loss 3.483 | ppl 11.18 | wps 27455 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3454 | lr 0.000431764 | gnorm 1.764 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8159
2022-03-05 16:37:55 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:39:36 | INFO | train_inner | epoch 072:     46 / 49 loss=3.66, nll_loss=3.434, ppl=10.81, wps=27806.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.557, loss_scale=16, train_wall=198, gb_free=21.6, wall=8260
2022-03-05 16:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:39:46 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.711 | nll_loss 9.549 | ppl 748.87 | wps 48206.5 | wpb 510.9 | bsz 1 | num_updates 3503 | best_loss 8.204
2022-03-05 16:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3503 updates
2022-03-05 16:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 72 @ 3503 updates, score 9.711) (writing took 1.807090331800282 seconds)
2022-03-05 16:39:48 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:39:48 | INFO | train | epoch 072 | loss 3.599 | nll_loss 3.372 | ppl 10.35 | wps 28066.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3503 | lr 0.000437887 | gnorm 1.387 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8272
2022-03-05 16:39:48 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:41:39 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.745 | nll_loss 9.584 | ppl 767.71 | wps 48081.3 | wpb 510.9 | bsz 1 | num_updates 3552 | best_loss 8.204
2022-03-05 16:41:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3552 updates
2022-03-05 16:41:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 73 @ 3552 updates, score 9.745) (writing took 1.8684435728937387 seconds)
2022-03-05 16:41:41 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:41:41 | INFO | train | epoch 073 | loss 3.525 | nll_loss 3.295 | ppl 9.82 | wps 28026.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3552 | lr 0.000444011 | gnorm 1.537 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8385
2022-03-05 16:41:41 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:41:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:42:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:43:28 | INFO | train_inner | epoch 074:     49 / 49 loss=3.499, nll_loss=3.268, ppl=9.63, wps=27788.5, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.592, loss_scale=16, train_wall=197, gb_free=21.6, wall=8492
2022-03-05 16:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:43:33 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.867 | nll_loss 9.704 | ppl 833.91 | wps 48144.6 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.204
2022-03-05 16:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-05 16:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 74 @ 3600 updates, score 9.867) (writing took 1.8374682839494199 seconds)
2022-03-05 16:43:35 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:43:35 | INFO | train | epoch 074 | loss 3.463 | nll_loss 3.231 | ppl 9.39 | wps 27463.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.645 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8499
2022-03-05 16:43:35 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:45:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:45:26 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.916 | nll_loss 9.755 | ppl 864.12 | wps 48094.6 | wpb 510.9 | bsz 1 | num_updates 3649 | best_loss 8.204
2022-03-05 16:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3649 updates
2022-03-05 16:45:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:45:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:45:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 75 @ 3649 updates, score 9.916) (writing took 1.8150222098920494 seconds)
2022-03-05 16:45:28 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:45:28 | INFO | train | epoch 075 | loss 3.377 | nll_loss 3.143 | ppl 8.84 | wps 28014.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3649 | lr 0.000456134 | gnorm 1.558 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8612
2022-03-05 16:45:28 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:47:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:47:20 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.973 | nll_loss 9.81 | ppl 897.87 | wps 48120.9 | wpb 510.9 | bsz 1 | num_updates 3698 | best_loss 8.204
2022-03-05 16:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3698 updates
2022-03-05 16:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:47:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 76 @ 3698 updates, score 9.973) (writing took 1.843249096069485 seconds)
2022-03-05 16:47:21 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:47:21 | INFO | train | epoch 076 | loss 3.306 | nll_loss 3.07 | ppl 8.4 | wps 28055 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3698 | lr 0.000462258 | gnorm 1.587 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8726
2022-03-05 16:47:21 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:47:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:47:26 | INFO | train_inner | epoch 077:      2 / 49 loss=3.339, nll_loss=3.104, ppl=8.6, wps=27295, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.571, loss_scale=16, train_wall=196, gb_free=21.6, wall=8730
2022-03-05 16:48:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:49:13 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.066 | nll_loss 9.896 | ppl 953.05 | wps 48033.3 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.204
2022-03-05 16:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-05 16:49:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:49:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 77 @ 3746 updates, score 10.066) (writing took 1.8567762169986963 seconds)
2022-03-05 16:49:15 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:49:15 | INFO | train | epoch 077 | loss 3.229 | nll_loss 2.991 | ppl 7.95 | wps 27462.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.563 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8839
2022-03-05 16:49:15 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:51:06 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.162 | nll_loss 9.993 | ppl 1019.14 | wps 48099.6 | wpb 510.9 | bsz 1 | num_updates 3795 | best_loss 8.204
2022-03-05 16:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3795 updates
2022-03-05 16:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:51:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 78 @ 3795 updates, score 10.162) (writing took 1.794532960979268 seconds)
2022-03-05 16:51:08 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:51:08 | INFO | train | epoch 078 | loss 3.167 | nll_loss 2.926 | ppl 7.6 | wps 28061.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3795 | lr 0.00047438 | gnorm 1.621 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 8952
2022-03-05 16:51:08 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:51:19 | INFO | train_inner | epoch 079:      5 / 49 loss=3.19, nll_loss=2.95, ppl=7.73, wps=27820.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.586, loss_scale=16, train_wall=198, gb_free=21.6, wall=8963
2022-03-05 16:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:53:00 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.215 | nll_loss 10.048 | ppl 1058.98 | wps 48234 | wpb 510.9 | bsz 1 | num_updates 3844 | best_loss 8.204
2022-03-05 16:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3844 updates
2022-03-05 16:53:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:53:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:53:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 79 @ 3844 updates, score 10.215) (writing took 1.859483210137114 seconds)
2022-03-05 16:53:01 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:53:01 | INFO | train | epoch 079 | loss 3.09 | nll_loss 2.847 | ppl 7.2 | wps 28018.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3844 | lr 0.000480504 | gnorm 1.578 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9066
2022-03-05 16:53:01 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:53:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:54:53 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 10.315 | nll_loss 10.143 | ppl 1131.02 | wps 48067.6 | wpb 510.9 | bsz 1 | num_updates 3893 | best_loss 8.204
2022-03-05 16:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3893 updates
2022-03-05 16:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 80 @ 3893 updates, score 10.315) (writing took 1.8089872568380088 seconds)
2022-03-05 16:54:55 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:54:55 | INFO | train | epoch 080 | loss 3.019 | nll_loss 2.774 | ppl 6.84 | wps 28032.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3893 | lr 0.000486628 | gnorm 1.594 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 9179
2022-03-05 16:54:55 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:55:10 | INFO | train_inner | epoch 081:      7 / 49 loss=3.043, nll_loss=2.799, ppl=6.96, wps=28058.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.594, loss_scale=32, train_wall=196, gb_free=21.6, wall=9194
2022-03-05 16:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:56:46 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.408 | nll_loss 10.241 | ppl 1209.83 | wps 48323.2 | wpb 510.9 | bsz 1 | num_updates 3941 | best_loss 8.204
2022-03-05 16:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3941 updates
2022-03-05 16:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:56:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 81 @ 3941 updates, score 10.408) (writing took 1.7661312830168754 seconds)
2022-03-05 16:56:48 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 16:56:48 | INFO | train | epoch 081 | loss 2.951 | nll_loss 2.703 | ppl 6.51 | wps 27513 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3941 | lr 0.000492626 | gnorm 1.599 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9292
2022-03-05 16:56:48 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 16:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:58:39 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 10.474 | nll_loss 10.304 | ppl 1264.47 | wps 48258.8 | wpb 510.9 | bsz 1 | num_updates 3990 | best_loss 8.204
2022-03-05 16:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3990 updates
2022-03-05 16:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 16:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 82 @ 3990 updates, score 10.474) (writing took 1.8099645979236811 seconds)
2022-03-05 16:58:41 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 16:58:41 | INFO | train | epoch 082 | loss 2.89 | nll_loss 2.64 | ppl 6.23 | wps 28040.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3990 | lr 0.00049875 | gnorm 1.654 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9405
2022-03-05 16:58:41 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 16:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:59:03 | INFO | train_inner | epoch 083:     10 / 49 loss=2.906, nll_loss=2.657, ppl=6.31, wps=27837.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.615, loss_scale=16, train_wall=198, gb_free=21.6, wall=9427
2022-03-05 17:00:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:00:33 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 10.579 | nll_loss 10.412 | ppl 1362.76 | wps 48203 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.204
2022-03-05 17:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-05 17:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 83 @ 4038 updates, score 10.579) (writing took 1.7781221410259604 seconds)
2022-03-05 17:00:34 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:00:34 | INFO | train | epoch 083 | loss 2.805 | nll_loss 2.553 | ppl 5.87 | wps 27501.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.476 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9519
2022-03-05 17:00:34 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:02:26 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 10.628 | nll_loss 10.459 | ppl 1407.72 | wps 48303.9 | wpb 510.9 | bsz 1 | num_updates 4087 | best_loss 8.204
2022-03-05 17:02:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4087 updates
2022-03-05 17:02:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 84 @ 4087 updates, score 10.628) (writing took 1.9638931488152593 seconds)
2022-03-05 17:02:28 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:02:28 | INFO | train | epoch 084 | loss 2.752 | nll_loss 2.498 | ppl 5.65 | wps 28001.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4087 | lr 0.00049465 | gnorm 1.568 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9632
2022-03-05 17:02:28 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:02:57 | INFO | train_inner | epoch 085:     13 / 49 loss=2.762, nll_loss=2.509, ppl=5.69, wps=27809.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.518, loss_scale=16, train_wall=198, gb_free=21.6, wall=9661
2022-03-05 17:04:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:04:19 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.756 | nll_loss 10.588 | ppl 1538.81 | wps 48358.2 | wpb 510.9 | bsz 1 | num_updates 4136 | best_loss 8.204
2022-03-05 17:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4136 updates
2022-03-05 17:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:04:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 85 @ 4136 updates, score 10.756) (writing took 1.8526484759058803 seconds)
2022-03-05 17:04:21 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:04:21 | INFO | train | epoch 085 | loss 2.685 | nll_loss 2.429 | ppl 5.38 | wps 28062.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4136 | lr 0.000491711 | gnorm 1.559 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9745
2022-03-05 17:04:21 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:06:13 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 10.858 | nll_loss 10.688 | ppl 1650.23 | wps 48158.7 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.204
2022-03-05 17:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-05 17:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 86 @ 4184 updates, score 10.858) (writing took 1.7730540970806032 seconds)
2022-03-05 17:06:14 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:06:14 | INFO | train | epoch 086 | loss 2.612 | nll_loss 2.353 | ppl 5.11 | wps 27482.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.48 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9859
2022-03-05 17:06:14 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:06:50 | INFO | train_inner | epoch 087:     16 / 49 loss=2.627, nll_loss=2.369, ppl=5.16, wps=27822.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.525, loss_scale=16, train_wall=198, gb_free=21.6, wall=9894
2022-03-05 17:08:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:08:06 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 10.877 | nll_loss 10.707 | ppl 1671.72 | wps 48304.6 | wpb 510.9 | bsz 1 | num_updates 4233 | best_loss 8.204
2022-03-05 17:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4233 updates
2022-03-05 17:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 87 @ 4233 updates, score 10.877) (writing took 1.7457339819520712 seconds)
2022-03-05 17:08:08 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:08:08 | INFO | train | epoch 087 | loss 2.551 | nll_loss 2.29 | ppl 4.89 | wps 28076.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4233 | lr 0.000486044 | gnorm 1.487 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 9972
2022-03-05 17:08:08 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:09:59 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.006 | nll_loss 10.835 | ppl 1826.27 | wps 48296.4 | wpb 510.9 | bsz 1 | num_updates 4282 | best_loss 8.204
2022-03-05 17:09:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4282 updates
2022-03-05 17:09:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:10:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 88 @ 4282 updates, score 11.006) (writing took 1.7824010029435158 seconds)
2022-03-05 17:10:01 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:10:01 | INFO | train | epoch 088 | loss 2.489 | nll_loss 2.226 | ppl 4.68 | wps 28061.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4282 | lr 0.000483255 | gnorm 1.511 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10085
2022-03-05 17:10:01 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:10:41 | INFO | train_inner | epoch 089:     18 / 49 loss=2.498, nll_loss=2.235, ppl=4.71, wps=28100.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.485, loss_scale=16, train_wall=196, gb_free=21.6, wall=10125
2022-03-05 17:11:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:11:52 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.08 | nll_loss 10.907 | ppl 1920.36 | wps 48330.8 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.204
2022-03-05 17:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-05 17:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 89 @ 4330 updates, score 11.08) (writing took 1.7754472659435123 seconds)
2022-03-05 17:11:54 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:11:54 | INFO | train | epoch 089 | loss 2.425 | nll_loss 2.16 | ppl 4.47 | wps 27478.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.452 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10198
2022-03-05 17:11:54 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:13:46 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.202 | nll_loss 11.031 | ppl 2092.52 | wps 48085 | wpb 510.9 | bsz 1 | num_updates 4379 | best_loss 8.204
2022-03-05 17:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4379 updates
2022-03-05 17:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 90 @ 4379 updates, score 11.202) (writing took 1.743009313941002 seconds)
2022-03-05 17:13:47 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:13:47 | INFO | train | epoch 090 | loss 2.365 | nll_loss 2.097 | ppl 4.28 | wps 28077.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4379 | lr 0.000477873 | gnorm 1.427 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10311
2022-03-05 17:13:47 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:14:34 | INFO | train_inner | epoch 091:     21 / 49 loss=2.372, nll_loss=2.104, ppl=4.3, wps=27835.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.437, loss_scale=16, train_wall=198, gb_free=21.6, wall=10358
2022-03-05 17:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:15:39 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.259 | nll_loss 11.09 | ppl 2179.29 | wps 48266.9 | wpb 510.9 | bsz 1 | num_updates 4428 | best_loss 8.204
2022-03-05 17:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4428 updates
2022-03-05 17:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 91 @ 4428 updates, score 11.259) (writing took 1.850475671933964 seconds)
2022-03-05 17:15:41 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:15:41 | INFO | train | epoch 091 | loss 2.314 | nll_loss 2.045 | ppl 4.13 | wps 28039.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4428 | lr 0.000475222 | gnorm 1.459 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10425
2022-03-05 17:15:41 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:17:32 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.397 | nll_loss 11.23 | ppl 2401.27 | wps 48072.6 | wpb 510.9 | bsz 1 | num_updates 4477 | best_loss 8.204
2022-03-05 17:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4477 updates
2022-03-05 17:17:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 92 @ 4477 updates, score 11.397) (writing took 1.752585788955912 seconds)
2022-03-05 17:17:34 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:17:34 | INFO | train | epoch 092 | loss 2.253 | nll_loss 1.981 | ppl 3.95 | wps 28046.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4477 | lr 0.000472614 | gnorm 1.385 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 10538
2022-03-05 17:17:34 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:17:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:18:27 | INFO | train_inner | epoch 093:     24 / 49 loss=2.258, nll_loss=1.987, ppl=3.96, wps=27818.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.427, loss_scale=16, train_wall=198, gb_free=21.6, wall=10591
2022-03-05 17:19:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:19:25 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.455 | nll_loss 11.286 | ppl 2497.23 | wps 48206.5 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.204
2022-03-05 17:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4525 updates
2022-03-05 17:19:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 93 @ 4525 updates, score 11.455) (writing took 1.7490231399424374 seconds)
2022-03-05 17:19:27 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:19:27 | INFO | train | epoch 093 | loss 2.199 | nll_loss 1.926 | ppl 3.8 | wps 27506 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4525 | lr 0.0004701 | gnorm 1.388 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10651
2022-03-05 17:19:27 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:21:19 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.534 | nll_loss 11.366 | ppl 2638.77 | wps 48180.3 | wpb 510.9 | bsz 1 | num_updates 4574 | best_loss 8.204
2022-03-05 17:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4574 updates
2022-03-05 17:21:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:21:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 94 @ 4574 updates, score 11.534) (writing took 1.7693916861899197 seconds)
2022-03-05 17:21:20 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:21:20 | INFO | train | epoch 094 | loss 2.158 | nll_loss 1.882 | ppl 3.69 | wps 28075.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4574 | lr 0.000467576 | gnorm 1.461 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10764
2022-03-05 17:21:20 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:22:18 | INFO | train_inner | epoch 095:     26 / 49 loss=2.153, nll_loss=1.877, ppl=3.67, wps=28103.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.411, loss_scale=16, train_wall=196, gb_free=21.6, wall=10822
2022-03-05 17:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:23:12 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.667 | nll_loss 11.499 | ppl 2893.99 | wps 48199.6 | wpb 510.9 | bsz 1 | num_updates 4623 | best_loss 8.204
2022-03-05 17:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4623 updates
2022-03-05 17:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 95 @ 4623 updates, score 11.667) (writing took 1.7220772879663855 seconds)
2022-03-05 17:23:14 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:23:14 | INFO | train | epoch 095 | loss 2.104 | nll_loss 1.827 | ppl 3.55 | wps 28073 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4623 | lr 0.000465091 | gnorm 1.39 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 10878
2022-03-05 17:23:14 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:23:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:25:05 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.67 | nll_loss 11.502 | ppl 2900.56 | wps 47692.6 | wpb 510.9 | bsz 1 | num_updates 4671 | best_loss 8.204
2022-03-05 17:25:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4671 updates
2022-03-05 17:25:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 96 @ 4671 updates, score 11.67) (writing took 1.7042666098568588 seconds)
2022-03-05 17:25:07 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:25:07 | INFO | train | epoch 096 | loss 2.055 | nll_loss 1.776 | ppl 3.43 | wps 27501.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4671 | lr 0.000462695 | gnorm 1.413 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 10991
2022-03-05 17:25:07 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:26:11 | INFO | train_inner | epoch 097:     29 / 49 loss=2.052, nll_loss=1.773, ppl=3.42, wps=27851.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.388, loss_scale=16, train_wall=198, gb_free=21.6, wall=11055
2022-03-05 17:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:26:58 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.773 | nll_loss 11.603 | ppl 3109.73 | wps 48319.4 | wpb 510.9 | bsz 1 | num_updates 4720 | best_loss 8.204
2022-03-05 17:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4720 updates
2022-03-05 17:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 97 @ 4720 updates, score 11.773) (writing took 1.7143417340703309 seconds)
2022-03-05 17:27:00 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:27:00 | INFO | train | epoch 097 | loss 2.009 | nll_loss 1.728 | ppl 3.31 | wps 28094.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4720 | lr 0.000460287 | gnorm 1.348 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 11104
2022-03-05 17:27:00 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:28:51 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.867 | nll_loss 11.697 | ppl 3320.86 | wps 48276.7 | wpb 510.9 | bsz 1 | num_updates 4769 | best_loss 8.204
2022-03-05 17:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4769 updates
2022-03-05 17:28:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:28:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:28:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 98 @ 4769 updates, score 11.867) (writing took 1.66416572406888 seconds)
2022-03-05 17:28:53 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:28:53 | INFO | train | epoch 098 | loss 1.963 | nll_loss 1.681 | ppl 3.21 | wps 28095.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4769 | lr 0.000457917 | gnorm 1.339 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 11217
2022-03-05 17:28:53 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:28:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:29:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:30:03 | INFO | train_inner | epoch 099:     32 / 49 loss=1.964, nll_loss=1.681, ppl=3.21, wps=27864, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.35, loss_scale=16, train_wall=198, gb_free=21.6, wall=11288
2022-03-05 17:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:30:44 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.93 | nll_loss 11.757 | ppl 3460.89 | wps 48101.7 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.204
2022-03-05 17:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-05 17:30:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 99 @ 4817 updates, score 11.93) (writing took 1.6671274830587208 seconds)
2022-03-05 17:30:46 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:30:46 | INFO | train | epoch 099 | loss 1.923 | nll_loss 1.638 | ppl 3.11 | wps 27521.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.347 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 11330
2022-03-05 17:30:46 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:32:38 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.072 | nll_loss 11.897 | ppl 3814.05 | wps 48195.6 | wpb 510.9 | bsz 1 | num_updates 4866 | best_loss 8.204
2022-03-05 17:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4866 updates
2022-03-05 17:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 100 @ 4866 updates, score 12.072) (writing took 1.7778418569359928 seconds)
2022-03-05 17:32:39 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:32:39 | INFO | train | epoch 100 | loss 1.886 | nll_loss 1.599 | ppl 3.03 | wps 28047.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4866 | lr 0.000453329 | gnorm 1.345 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 11443
2022-03-05 17:32:39 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:33:54 | INFO | train_inner | epoch 101:     34 / 49 loss=1.875, nll_loss=1.589, ppl=3.01, wps=28089.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.326, loss_scale=16, train_wall=196, gb_free=21.6, wall=11518
2022-03-05 17:34:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:34:31 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.107 | nll_loss 11.933 | ppl 3909.27 | wps 48245.4 | wpb 510.9 | bsz 1 | num_updates 4915 | best_loss 8.204
2022-03-05 17:34:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4915 updates
2022-03-05 17:34:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:34:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 101 @ 4915 updates, score 12.107) (writing took 1.8135831039398909 seconds)
2022-03-05 17:34:33 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:34:33 | INFO | train | epoch 101 | loss 1.843 | nll_loss 1.555 | ppl 2.94 | wps 28032.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4915 | lr 0.000451064 | gnorm 1.311 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 11557
2022-03-05 17:34:33 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:34:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:36:24 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.176 | nll_loss 12.002 | ppl 4100.75 | wps 48040.1 | wpb 510.9 | bsz 1 | num_updates 4964 | best_loss 8.204
2022-03-05 17:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4964 updates
2022-03-05 17:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 102 @ 4964 updates, score 12.176) (writing took 1.7742899230215698 seconds)
2022-03-05 17:36:26 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:36:26 | INFO | train | epoch 102 | loss 1.807 | nll_loss 1.517 | ppl 2.86 | wps 28046.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4964 | lr 0.000448832 | gnorm 1.32 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 11670
2022-03-05 17:36:26 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:37:45 | INFO | train_inner | epoch 103:     36 / 49 loss=1.797, nll_loss=1.507, ppl=2.84, wps=28085.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.316, loss_scale=32, train_wall=196, gb_free=21.6, wall=11749
2022-03-05 17:38:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:38:17 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.264 | nll_loss 12.092 | ppl 4365.31 | wps 48323.2 | wpb 510.9 | bsz 1 | num_updates 5013 | best_loss 8.204
2022-03-05 17:38:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5013 updates
2022-03-05 17:38:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:38:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:38:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 103 @ 5013 updates, score 12.264) (writing took 1.74893653485924 seconds)
2022-03-05 17:38:19 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:38:19 | INFO | train | epoch 103 | loss 1.77 | nll_loss 1.479 | ppl 2.79 | wps 28087.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5013 | lr 0.000446633 | gnorm 1.319 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 11783
2022-03-05 17:38:19 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:40:11 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.383 | nll_loss 12.211 | ppl 4739.93 | wps 48191.9 | wpb 510.9 | bsz 1 | num_updates 5061 | best_loss 8.204
2022-03-05 17:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5061 updates
2022-03-05 17:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 104 @ 5061 updates, score 12.383) (writing took 1.7373234471306205 seconds)
2022-03-05 17:40:12 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:40:12 | INFO | train | epoch 104 | loss 1.731 | nll_loss 1.438 | ppl 2.71 | wps 27483.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5061 | lr 0.00044451 | gnorm 1.286 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 11897
2022-03-05 17:40:12 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:41:39 | INFO | train_inner | epoch 105:     39 / 49 loss=1.726, nll_loss=1.433, ppl=2.7, wps=27824.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.284, loss_scale=32, train_wall=198, gb_free=21.6, wall=11983
2022-03-05 17:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:42:04 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.414 | nll_loss 12.243 | ppl 4846.18 | wps 48321.8 | wpb 510.9 | bsz 1 | num_updates 5110 | best_loss 8.204
2022-03-05 17:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5110 updates
2022-03-05 17:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 105 @ 5110 updates, score 12.414) (writing took 1.745793059002608 seconds)
2022-03-05 17:42:06 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:42:06 | INFO | train | epoch 105 | loss 1.7 | nll_loss 1.405 | ppl 2.65 | wps 28043 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5110 | lr 0.000442374 | gnorm 1.258 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12010
2022-03-05 17:42:06 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:43:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:43:57 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.518 | nll_loss 12.349 | ppl 5215.45 | wps 48135 | wpb 510.9 | bsz 1 | num_updates 5158 | best_loss 8.204
2022-03-05 17:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5158 updates
2022-03-05 17:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 106 @ 5158 updates, score 12.518) (writing took 1.7122100328560919 seconds)
2022-03-05 17:43:59 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:43:59 | INFO | train | epoch 106 | loss 1.664 | nll_loss 1.368 | ppl 2.58 | wps 27480 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5158 | lr 0.000440311 | gnorm 1.271 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 12123
2022-03-05 17:43:59 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:45:32 | INFO | train_inner | epoch 107:     42 / 49 loss=1.658, nll_loss=1.362, ppl=2.57, wps=27843.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.254, loss_scale=16, train_wall=198, gb_free=21.6, wall=12216
2022-03-05 17:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:45:50 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.572 | nll_loss 12.401 | ppl 5407.88 | wps 48339.1 | wpb 510.9 | bsz 1 | num_updates 5207 | best_loss 8.204
2022-03-05 17:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5207 updates
2022-03-05 17:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 107 @ 5207 updates, score 12.572) (writing took 1.740002600941807 seconds)
2022-03-05 17:45:52 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:45:52 | INFO | train | epoch 107 | loss 1.637 | nll_loss 1.34 | ppl 2.53 | wps 28104.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5207 | lr 0.000438234 | gnorm 1.248 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 12236
2022-03-05 17:45:52 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:47:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:47:44 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.642 | nll_loss 12.469 | ppl 5668.75 | wps 48287.6 | wpb 510.9 | bsz 1 | num_updates 5256 | best_loss 8.204
2022-03-05 17:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5256 updates
2022-03-05 17:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 108 @ 5256 updates, score 12.642) (writing took 1.7028254379983991 seconds)
2022-03-05 17:47:45 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:47:45 | INFO | train | epoch 108 | loss 1.607 | nll_loss 1.308 | ppl 2.48 | wps 28088.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5256 | lr 0.000436187 | gnorm 1.256 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 12349
2022-03-05 17:47:45 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:49:22 | INFO | train_inner | epoch 109:     44 / 49 loss=1.596, nll_loss=1.297, ppl=2.46, wps=28107.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.249, loss_scale=32, train_wall=196, gb_free=21.6, wall=12446
2022-03-05 17:49:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:49:37 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.714 | nll_loss 12.54 | ppl 5956.06 | wps 48156.6 | wpb 510.9 | bsz 1 | num_updates 5305 | best_loss 8.204
2022-03-05 17:49:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5305 updates
2022-03-05 17:49:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:49:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:49:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 109 @ 5305 updates, score 12.714) (writing took 1.6964445179328322 seconds)
2022-03-05 17:49:39 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:49:39 | INFO | train | epoch 109 | loss 1.576 | nll_loss 1.276 | ppl 2.42 | wps 28055 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5305 | lr 0.000434167 | gnorm 1.239 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12463
2022-03-05 17:49:39 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:51:30 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.806 | nll_loss 12.634 | ppl 6354.96 | wps 48197.3 | wpb 510.9 | bsz 1 | num_updates 5354 | best_loss 8.204
2022-03-05 17:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5354 updates
2022-03-05 17:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:51:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:51:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 110 @ 5354 updates, score 12.806) (writing took 1.6855111760087311 seconds)
2022-03-05 17:51:32 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:51:32 | INFO | train | epoch 110 | loss 1.549 | nll_loss 1.248 | ppl 2.37 | wps 28075.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5354 | lr 0.000432176 | gnorm 1.247 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12576
2022-03-05 17:51:32 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:51:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:53:13 | INFO | train_inner | epoch 111:     46 / 49 loss=1.537, nll_loss=1.234, ppl=2.35, wps=28095.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.228, loss_scale=32, train_wall=196, gb_free=21.6, wall=12677
2022-03-05 17:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:53:23 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.875 | nll_loss 12.708 | ppl 6693.15 | wps 48451.3 | wpb 510.9 | bsz 1 | num_updates 5403 | best_loss 8.204
2022-03-05 17:53:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5403 updates
2022-03-05 17:53:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:53:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:53:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 111 @ 5403 updates, score 12.875) (writing took 1.7361052378546447 seconds)
2022-03-05 17:53:25 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:53:25 | INFO | train | epoch 111 | loss 1.518 | nll_loss 1.215 | ppl 2.32 | wps 28057 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5403 | lr 0.000430212 | gnorm 1.206 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12689
2022-03-05 17:53:25 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:53:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:53:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:55:17 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.906 | nll_loss 12.735 | ppl 6818.89 | wps 48074.2 | wpb 510.9 | bsz 1 | num_updates 5451 | best_loss 8.204
2022-03-05 17:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5451 updates
2022-03-05 17:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:55:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:55:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 112 @ 5451 updates, score 12.906) (writing took 1.7318609429057688 seconds)
2022-03-05 17:55:18 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:55:18 | INFO | train | epoch 112 | loss 1.494 | nll_loss 1.189 | ppl 2.28 | wps 27484.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5451 | lr 0.000428314 | gnorm 1.214 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12802
2022-03-05 17:55:18 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:57:05 | INFO | train_inner | epoch 113:     49 / 49 loss=1.483, nll_loss=1.178, ppl=2.26, wps=27822.2, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.213, loss_scale=32, train_wall=197, gb_free=21.6, wall=12909
2022-03-05 17:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:57:10 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.997 | nll_loss 12.829 | ppl 7275.42 | wps 48233.5 | wpb 510.9 | bsz 1 | num_updates 5500 | best_loss 8.204
2022-03-05 17:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5500 updates
2022-03-05 17:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 113 @ 5500 updates, score 12.997) (writing took 1.6586853328626603 seconds)
2022-03-05 17:57:11 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 17:57:11 | INFO | train | epoch 113 | loss 1.467 | nll_loss 1.161 | ppl 2.24 | wps 28090.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5500 | lr 0.000426401 | gnorm 1.203 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 12916
2022-03-05 17:57:11 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 17:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:58:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:59:03 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.099 | nll_loss 12.926 | ppl 7781.11 | wps 48239.2 | wpb 510.9 | bsz 1 | num_updates 5548 | best_loss 8.204
2022-03-05 17:59:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5548 updates
2022-03-05 17:59:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:59:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 17:59:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 114 @ 5548 updates, score 13.099) (writing took 1.7029076849576086 seconds)
2022-03-05 17:59:05 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 17:59:05 | INFO | train | epoch 114 | loss 1.443 | nll_loss 1.137 | ppl 2.2 | wps 27480.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5548 | lr 0.000424553 | gnorm 1.189 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13029
2022-03-05 17:59:05 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 17:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:59:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 18:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:00:56 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.176 | nll_loss 13.004 | ppl 8212.62 | wps 48352.8 | wpb 510.9 | bsz 1 | num_updates 5596 | best_loss 8.204
2022-03-05 18:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5596 updates
2022-03-05 18:00:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 115 @ 5596 updates, score 13.176) (writing took 1.7056690049357712 seconds)
2022-03-05 18:00:58 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:00:58 | INFO | train | epoch 115 | loss 1.419 | nll_loss 1.111 | ppl 2.16 | wps 27483.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5596 | lr 0.000422728 | gnorm 1.171 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 13142
2022-03-05 18:00:58 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:01:07 | INFO | train_inner | epoch 116:      4 / 49 loss=1.428, nll_loss=1.121, ppl=2.18, wps=26846.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.18, loss_scale=16, train_wall=200, gb_free=21.6, wall=13151
2022-03-05 18:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:02:49 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.215 | nll_loss 13.042 | ppl 8431.81 | wps 48346.8 | wpb 510.9 | bsz 1 | num_updates 5645 | best_loss 8.204
2022-03-05 18:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5645 updates
2022-03-05 18:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:02:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 116 @ 5645 updates, score 13.215) (writing took 1.7106711219530553 seconds)
2022-03-05 18:02:51 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:02:51 | INFO | train | epoch 116 | loss 1.398 | nll_loss 1.089 | ppl 2.13 | wps 28086.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5645 | lr 0.000420889 | gnorm 1.158 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 13255
2022-03-05 18:02:51 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:04:43 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.272 | nll_loss 13.101 | ppl 8784.53 | wps 48202.4 | wpb 510.9 | bsz 1 | num_updates 5694 | best_loss 8.204
2022-03-05 18:04:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5694 updates
2022-03-05 18:04:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:04:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 117 @ 5694 updates, score 13.272) (writing took 1.6948220019694418 seconds)
2022-03-05 18:04:44 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:04:44 | INFO | train | epoch 117 | loss 1.378 | nll_loss 1.068 | ppl 2.1 | wps 28064 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5694 | lr 0.000419075 | gnorm 1.153 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 13368
2022-03-05 18:04:44 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:58 | INFO | train_inner | epoch 118:      6 / 49 loss=1.385, nll_loss=1.076, ppl=2.11, wps=28108.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.155, loss_scale=32, train_wall=196, gb_free=21.6, wall=13382
2022-03-05 18:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:06:36 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.337 | nll_loss 13.168 | ppl 9203.4 | wps 48169 | wpb 510.9 | bsz 1 | num_updates 5743 | best_loss 8.204
2022-03-05 18:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5743 updates
2022-03-05 18:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 118 @ 5743 updates, score 13.337) (writing took 1.6796061280183494 seconds)
2022-03-05 18:06:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:06:38 | INFO | train | epoch 118 | loss 1.354 | nll_loss 1.043 | ppl 2.06 | wps 28076.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5743 | lr 0.000417283 | gnorm 1.14 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13482
2022-03-05 18:06:38 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:06:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:08:29 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.347 | nll_loss 13.176 | ppl 9252.62 | wps 48045.4 | wpb 510.9 | bsz 1 | num_updates 5792 | best_loss 8.204
2022-03-05 18:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5792 updates
2022-03-05 18:08:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:08:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:08:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 119 @ 5792 updates, score 13.347) (writing took 1.7304003979079425 seconds)
2022-03-05 18:08:31 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:08:31 | INFO | train | epoch 119 | loss 1.336 | nll_loss 1.024 | ppl 2.03 | wps 28017.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5792 | lr 0.000415514 | gnorm 1.141 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13595
2022-03-05 18:08:31 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:49 | INFO | train_inner | epoch 120:      8 / 49 loss=1.342, nll_loss=1.03, ppl=2.04, wps=28068.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.139, loss_scale=32, train_wall=196, gb_free=21.6, wall=13613
2022-03-05 18:09:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:10:23 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.413 | nll_loss 13.242 | ppl 9690.62 | wps 47808 | wpb 510.9 | bsz 1 | num_updates 5840 | best_loss 8.204
2022-03-05 18:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5840 updates
2022-03-05 18:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:10:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:10:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 120 @ 5840 updates, score 13.413) (writing took 1.692146104061976 seconds)
2022-03-05 18:10:25 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:10:25 | INFO | train | epoch 120 | loss 1.316 | nll_loss 1.002 | ppl 2 | wps 27391.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5840 | lr 0.000413803 | gnorm 1.138 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13709
2022-03-05 18:10:25 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:10:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:12:16 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.508 | nll_loss 13.336 | ppl 10341.9 | wps 48429.3 | wpb 510.9 | bsz 1 | num_updates 5889 | best_loss 8.204
2022-03-05 18:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5889 updates
2022-03-05 18:12:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:12:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:12:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 121 @ 5889 updates, score 13.508) (writing took 1.7284049179870635 seconds)
2022-03-05 18:12:18 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:12:18 | INFO | train | epoch 121 | loss 1.297 | nll_loss 0.982 | ppl 1.98 | wps 28060.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5889 | lr 0.000412078 | gnorm 1.136 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13822
2022-03-05 18:12:18 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:12:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:12:42 | INFO | train_inner | epoch 122:     11 / 49 loss=1.301, nll_loss=0.987, ppl=1.98, wps=27794, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.134, loss_scale=32, train_wall=198, gb_free=21.6, wall=13846
2022-03-05 18:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:14:09 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.599 | nll_loss 13.429 | ppl 11026 | wps 47895.1 | wpb 510.9 | bsz 1 | num_updates 5938 | best_loss 8.204
2022-03-05 18:14:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5938 updates
2022-03-05 18:14:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 122 @ 5938 updates, score 13.599) (writing took 1.7102385740727186 seconds)
2022-03-05 18:14:11 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:14:11 | INFO | train | epoch 122 | loss 1.28 | nll_loss 0.964 | ppl 1.95 | wps 28045.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5938 | lr 0.000410374 | gnorm 1.132 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 13935
2022-03-05 18:14:11 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:16:03 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.662 | nll_loss 13.492 | ppl 11521.8 | wps 48293.9 | wpb 510.9 | bsz 1 | num_updates 5986 | best_loss 8.204
2022-03-05 18:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5986 updates
2022-03-05 18:16:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:16:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:16:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 123 @ 5986 updates, score 13.662) (writing took 1.7006639640312642 seconds)
2022-03-05 18:16:04 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:16:04 | INFO | train | epoch 123 | loss 1.257 | nll_loss 0.941 | ppl 1.92 | wps 27493.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5986 | lr 0.000408725 | gnorm 1.094 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14048
2022-03-05 18:16:04 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:16:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:16:35 | INFO | train_inner | epoch 124:     14 / 49 loss=1.265, nll_loss=0.949, ppl=1.93, wps=27828, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.11, loss_scale=32, train_wall=198, gb_free=21.6, wall=14079
2022-03-05 18:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:56 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.658 | nll_loss 13.488 | ppl 11487.5 | wps 48417.2 | wpb 510.9 | bsz 1 | num_updates 6035 | best_loss 8.204
2022-03-05 18:17:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6035 updates
2022-03-05 18:17:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:17:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 124 @ 6035 updates, score 13.658) (writing took 1.6889267091173679 seconds)
2022-03-05 18:17:58 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:17:58 | INFO | train | epoch 124 | loss 1.246 | nll_loss 0.929 | ppl 1.9 | wps 28075.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6035 | lr 0.000407063 | gnorm 1.102 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14162
2022-03-05 18:17:58 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:17:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:49 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.737 | nll_loss 13.566 | ppl 12129.2 | wps 48197.7 | wpb 510.9 | bsz 1 | num_updates 6084 | best_loss 8.204
2022-03-05 18:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6084 updates
2022-03-05 18:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 125 @ 6084 updates, score 13.737) (writing took 1.6817453629337251 seconds)
2022-03-05 18:19:51 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:19:51 | INFO | train | epoch 125 | loss 1.226 | nll_loss 0.908 | ppl 1.88 | wps 28101 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6084 | lr 0.00040542 | gnorm 1.091 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 14275
2022-03-05 18:19:51 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:20:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:20:28 | INFO | train_inner | epoch 126:     17 / 49 loss=1.229, nll_loss=0.911, ppl=1.88, wps=27849, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.093, loss_scale=32, train_wall=198, gb_free=21.6, wall=14312
2022-03-05 18:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:21:42 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.79 | nll_loss 13.62 | ppl 12587.8 | wps 48435.6 | wpb 510.9 | bsz 1 | num_updates 6132 | best_loss 8.204
2022-03-05 18:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6132 updates
2022-03-05 18:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 126 @ 6132 updates, score 13.79) (writing took 1.6761223580688238 seconds)
2022-03-05 18:21:44 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:21:44 | INFO | train | epoch 126 | loss 1.211 | nll_loss 0.892 | ppl 1.86 | wps 27520.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6132 | lr 0.00040383 | gnorm 1.084 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14388
2022-03-05 18:21:44 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:35 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.835 | nll_loss 13.667 | ppl 13004.1 | wps 48254.5 | wpb 510.9 | bsz 1 | num_updates 6181 | best_loss 8.204
2022-03-05 18:23:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6181 updates
2022-03-05 18:23:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:23:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:23:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 127 @ 6181 updates, score 13.835) (writing took 1.686609529191628 seconds)
2022-03-05 18:23:37 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:23:37 | INFO | train | epoch 127 | loss 1.197 | nll_loss 0.877 | ppl 1.84 | wps 28085.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6181 | lr 0.000402226 | gnorm 1.056 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14501
2022-03-05 18:23:37 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:24:19 | INFO | train_inner | epoch 128:     19 / 49 loss=1.199, nll_loss=0.879, ppl=1.84, wps=28130.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.071, loss_scale=32, train_wall=196, gb_free=21.6, wall=14543
2022-03-05 18:24:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:28 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.822 | nll_loss 13.654 | ppl 12888.3 | wps 48401.1 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.204
2022-03-05 18:25:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-05 18:25:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:25:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:25:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 128 @ 6229 updates, score 13.822) (writing took 1.6743709440343082 seconds)
2022-03-05 18:25:30 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:25:30 | INFO | train | epoch 128 | loss 1.183 | nll_loss 0.863 | ppl 1.82 | wps 27518.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 1.073 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14614
2022-03-05 18:25:30 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:25:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:21 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.92 | nll_loss 13.752 | ppl 13800.6 | wps 48156.8 | wpb 510.9 | bsz 1 | num_updates 6278 | best_loss 8.204
2022-03-05 18:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6278 updates
2022-03-05 18:27:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 129 @ 6278 updates, score 13.92) (writing took 1.711614933097735 seconds)
2022-03-05 18:27:23 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:27:23 | INFO | train | epoch 129 | loss 1.169 | nll_loss 0.848 | ppl 1.8 | wps 28106.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6278 | lr 0.000399107 | gnorm 1.07 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14727
2022-03-05 18:27:23 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:28:12 | INFO | train_inner | epoch 130:     22 / 49 loss=1.169, nll_loss=0.848, ppl=1.8, wps=27871, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.06, loss_scale=32, train_wall=198, gb_free=21.6, wall=14776
2022-03-05 18:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:14 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 14.001 | nll_loss 13.834 | ppl 14603.6 | wps 48258.4 | wpb 510.9 | bsz 1 | num_updates 6327 | best_loss 8.204
2022-03-05 18:29:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6327 updates
2022-03-05 18:29:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 130 @ 6327 updates, score 14.001) (writing took 1.688400591025129 seconds)
2022-03-05 18:29:16 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:29:16 | INFO | train | epoch 130 | loss 1.152 | nll_loss 0.83 | ppl 1.78 | wps 28122.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6327 | lr 0.000397559 | gnorm 1.03 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14840
2022-03-05 18:29:16 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:29:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:31:07 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 14.028 | nll_loss 13.858 | ppl 14850 | wps 48361 | wpb 510.9 | bsz 1 | num_updates 6375 | best_loss 8.204
2022-03-05 18:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6375 updates
2022-03-05 18:31:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:31:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:31:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 131 @ 6375 updates, score 14.028) (writing took 1.767005171859637 seconds)
2022-03-05 18:31:09 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:31:09 | INFO | train | epoch 131 | loss 1.138 | nll_loss 0.815 | ppl 1.76 | wps 27523.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6375 | lr 0.000396059 | gnorm 1.026 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 14953
2022-03-05 18:31:09 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:31:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:32:04 | INFO | train_inner | epoch 132:     25 / 49 loss=1.138, nll_loss=0.815, ppl=1.76, wps=27880.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=1.021, loss_scale=32, train_wall=198, gb_free=21.6, wall=15008
2022-03-05 18:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:33:01 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 14.021 | nll_loss 13.852 | ppl 14784.3 | wps 48200.7 | wpb 510.9 | bsz 1 | num_updates 6424 | best_loss 8.204
2022-03-05 18:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6424 updates
2022-03-05 18:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 132 @ 6424 updates, score 14.021) (writing took 1.7105905648786575 seconds)
2022-03-05 18:33:02 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:33:02 | INFO | train | epoch 132 | loss 1.127 | nll_loss 0.803 | ppl 1.74 | wps 28112.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6424 | lr 0.000394546 | gnorm 1.025 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15066
2022-03-05 18:33:02 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:34:54 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 14.188 | nll_loss 14.018 | ppl 16594.1 | wps 48174.4 | wpb 510.9 | bsz 1 | num_updates 6473 | best_loss 8.204
2022-03-05 18:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6473 updates
2022-03-05 18:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 133 @ 6473 updates, score 14.188) (writing took 1.6690725309308618 seconds)
2022-03-05 18:34:55 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:34:55 | INFO | train | epoch 133 | loss 1.116 | nll_loss 0.792 | ppl 1.73 | wps 28108.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6473 | lr 0.000393049 | gnorm 1.036 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 15179
2022-03-05 18:34:55 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:34:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:35:57 | INFO | train_inner | epoch 134:     28 / 49 loss=1.115, nll_loss=0.79, ppl=1.73, wps=27875.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=1.029, loss_scale=32, train_wall=198, gb_free=21.6, wall=15241
2022-03-05 18:36:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:36:47 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 14.176 | nll_loss 14.011 | ppl 16504.9 | wps 48302.6 | wpb 510.9 | bsz 1 | num_updates 6521 | best_loss 8.204
2022-03-05 18:36:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6521 updates
2022-03-05 18:36:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:36:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:36:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 134 @ 6521 updates, score 14.176) (writing took 1.745505137136206 seconds)
2022-03-05 18:36:48 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:36:48 | INFO | train | epoch 134 | loss 1.1 | nll_loss 0.775 | ppl 1.71 | wps 27524.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6521 | lr 0.0003916 | gnorm 1.001 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15292
2022-03-05 18:36:48 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:38:40 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 14.204 | nll_loss 14.036 | ppl 16802.7 | wps 48259.8 | wpb 510.9 | bsz 1 | num_updates 6570 | best_loss 8.204
2022-03-05 18:38:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6570 updates
2022-03-05 18:38:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:38:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 135 @ 6570 updates, score 14.204) (writing took 1.724109283881262 seconds)
2022-03-05 18:38:42 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:38:42 | INFO | train | epoch 135 | loss 1.09 | nll_loss 0.764 | ppl 1.7 | wps 28096.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6570 | lr 0.000390137 | gnorm 0.989 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15406
2022-03-05 18:38:42 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:39:48 | INFO | train_inner | epoch 136:     30 / 49 loss=1.09, nll_loss=0.764, ppl=1.7, wps=28135.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.995, loss_scale=32, train_wall=196, gb_free=21.6, wall=15472
2022-03-05 18:40:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:40:33 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 14.255 | nll_loss 14.087 | ppl 17403.6 | wps 48222.8 | wpb 510.9 | bsz 1 | num_updates 6618 | best_loss 8.204
2022-03-05 18:40:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6618 updates
2022-03-05 18:40:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:40:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:40:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 136 @ 6618 updates, score 14.255) (writing took 1.6992200741078705 seconds)
2022-03-05 18:40:35 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:40:35 | INFO | train | epoch 136 | loss 1.078 | nll_loss 0.752 | ppl 1.68 | wps 27541.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6618 | lr 0.00038872 | gnorm 0.989 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15519
2022-03-05 18:40:35 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:40:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:42:26 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 14.309 | nll_loss 14.14 | ppl 18057.8 | wps 48218 | wpb 510.9 | bsz 1 | num_updates 6667 | best_loss 8.204
2022-03-05 18:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6667 updates
2022-03-05 18:42:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:42:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 137 @ 6667 updates, score 14.309) (writing took 1.7168093188665807 seconds)
2022-03-05 18:42:28 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:42:28 | INFO | train | epoch 137 | loss 1.069 | nll_loss 0.742 | ppl 1.67 | wps 28093.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6667 | lr 0.000387289 | gnorm 0.995 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15632
2022-03-05 18:42:28 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:43:40 | INFO | train_inner | epoch 138:     33 / 49 loss=1.067, nll_loss=0.74, ppl=1.67, wps=27862.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.989, loss_scale=32, train_wall=198, gb_free=21.6, wall=15704
2022-03-05 18:44:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:44:19 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 14.373 | nll_loss 14.205 | ppl 18891.5 | wps 48362.6 | wpb 510.9 | bsz 1 | num_updates 6716 | best_loss 8.204
2022-03-05 18:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6716 updates
2022-03-05 18:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:44:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 138 @ 6716 updates, score 14.373) (writing took 1.7063735988922417 seconds)
2022-03-05 18:44:21 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:44:21 | INFO | train | epoch 138 | loss 1.057 | nll_loss 0.729 | ppl 1.66 | wps 28100.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6716 | lr 0.000385873 | gnorm 0.987 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15745
2022-03-05 18:44:21 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:45:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:46:12 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 14.41 | nll_loss 14.244 | ppl 19409 | wps 48234.1 | wpb 510.9 | bsz 1 | num_updates 6764 | best_loss 8.204
2022-03-05 18:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6764 updates
2022-03-05 18:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 139 @ 6764 updates, score 14.41) (writing took 1.701893035089597 seconds)
2022-03-05 18:46:14 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:46:14 | INFO | train | epoch 139 | loss 1.048 | nll_loss 0.719 | ppl 1.65 | wps 27553.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6764 | lr 0.000384502 | gnorm 0.976 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15858
2022-03-05 18:46:14 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:47:33 | INFO | train_inner | epoch 140:     36 / 49 loss=1.046, nll_loss=0.717, ppl=1.64, wps=27891.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.977, loss_scale=32, train_wall=198, gb_free=21.6, wall=15937
2022-03-05 18:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:48:05 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 14.391 | nll_loss 14.225 | ppl 19150.2 | wps 48330.2 | wpb 510.9 | bsz 1 | num_updates 6813 | best_loss 8.204
2022-03-05 18:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6813 updates
2022-03-05 18:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 140 @ 6813 updates, score 14.391) (writing took 1.7180766090750694 seconds)
2022-03-05 18:48:07 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:48:07 | INFO | train | epoch 140 | loss 1.038 | nll_loss 0.709 | ppl 1.64 | wps 28098.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6813 | lr 0.000383116 | gnorm 0.98 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 15971
2022-03-05 18:48:07 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:49:58 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 14.425 | nll_loss 14.259 | ppl 19611 | wps 48259.9 | wpb 510.9 | bsz 1 | num_updates 6862 | best_loss 8.204
2022-03-05 18:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6862 updates
2022-03-05 18:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 141 @ 6862 updates, score 14.425) (writing took 1.7275598738342524 seconds)
2022-03-05 18:50:00 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:50:00 | INFO | train | epoch 141 | loss 1.027 | nll_loss 0.698 | ppl 1.62 | wps 28072.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6862 | lr 0.000381746 | gnorm 0.97 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16084
2022-03-05 18:50:00 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:50:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:51:26 | INFO | train_inner | epoch 142:     39 / 49 loss=1.024, nll_loss=0.695, ppl=1.62, wps=27856.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.959, loss_scale=32, train_wall=198, gb_free=21.6, wall=16170
2022-03-05 18:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:51:51 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 14.424 | nll_loss 14.258 | ppl 19588.1 | wps 48254.3 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.204
2022-03-05 18:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-05 18:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 142 @ 6910 updates, score 14.424) (writing took 1.7082214560359716 seconds)
2022-03-05 18:51:53 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:51:53 | INFO | train | epoch 142 | loss 1.014 | nll_loss 0.685 | ppl 1.61 | wps 27531.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.93 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16197
2022-03-05 18:51:53 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:53:44 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 14.466 | nll_loss 14.301 | ppl 20184.1 | wps 48279.4 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.204
2022-03-05 18:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-05 18:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 143 @ 6959 updates, score 14.466) (writing took 1.7284285931382328 seconds)
2022-03-05 18:53:46 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:53:46 | INFO | train | epoch 143 | loss 1.009 | nll_loss 0.679 | ppl 1.6 | wps 28102.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.95 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16310
2022-03-05 18:53:46 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:55:16 | INFO | train_inner | epoch 144:     41 / 49 loss=1.007, nll_loss=0.677, ppl=1.6, wps=28133.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.945, loss_scale=64, train_wall=196, gb_free=21.6, wall=16401
2022-03-05 18:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:55:38 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 14.547 | nll_loss 14.381 | ppl 21340.2 | wps 47737.7 | wpb 510.9 | bsz 1 | num_updates 7007 | best_loss 8.204
2022-03-05 18:55:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7007 updates
2022-03-05 18:55:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 144 @ 7007 updates, score 14.547) (writing took 1.7082401311490685 seconds)
2022-03-05 18:55:39 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 18:55:39 | INFO | train | epoch 144 | loss 1 | nll_loss 0.669 | ppl 1.59 | wps 27514.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7007 | lr 0.000377776 | gnorm 0.949 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16423
2022-03-05 18:55:39 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 18:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:57:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:57:31 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 14.551 | nll_loss 14.384 | ppl 21386 | wps 48236 | wpb 510.9 | bsz 1 | num_updates 7056 | best_loss 8.204
2022-03-05 18:57:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7056 updates
2022-03-05 18:57:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:57:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:57:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 145 @ 7056 updates, score 14.551) (writing took 1.713497675023973 seconds)
2022-03-05 18:57:32 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 18:57:32 | INFO | train | epoch 145 | loss 0.991 | nll_loss 0.66 | ppl 1.58 | wps 28101.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7056 | lr 0.000376462 | gnorm 0.931 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16536
2022-03-05 18:57:32 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 18:57:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:59:09 | INFO | train_inner | epoch 146:     44 / 49 loss=0.988, nll_loss=0.657, ppl=1.58, wps=27872.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.93, loss_scale=32, train_wall=198, gb_free=21.6, wall=16633
2022-03-05 18:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:59:24 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 14.568 | nll_loss 14.404 | ppl 21683.7 | wps 48126.3 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.204
2022-03-05 18:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-05 18:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 18:59:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 146 @ 7105 updates, score 14.568) (writing took 1.74215504899621 seconds)
2022-03-05 18:59:25 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 18:59:25 | INFO | train | epoch 146 | loss 0.983 | nll_loss 0.651 | ppl 1.57 | wps 28107.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.93 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16650
2022-03-05 18:59:25 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 18:59:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:00:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:01:17 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 14.637 | nll_loss 14.472 | ppl 22731 | wps 47943.9 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 8.204
2022-03-05 19:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-05 19:01:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:01:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:01:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 147 @ 7153 updates, score 14.637) (writing took 1.7346987470518798 seconds)
2022-03-05 19:01:19 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:01:19 | INFO | train | epoch 147 | loss 0.971 | nll_loss 0.639 | ppl 1.56 | wps 27517.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.906 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16763
2022-03-05 19:01:19 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:01:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:03:02 | INFO | train_inner | epoch 148:     47 / 49 loss=0.971, nll_loss=0.639, ppl=1.56, wps=27868.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.921, loss_scale=32, train_wall=198, gb_free=21.6, wall=16866
2022-03-05 19:03:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:03:10 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 14.645 | nll_loss 14.481 | ppl 22867.2 | wps 48254.5 | wpb 510.9 | bsz 1 | num_updates 7202 | best_loss 8.204
2022-03-05 19:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7202 updates
2022-03-05 19:03:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 148 @ 7202 updates, score 14.645) (writing took 1.7248143118340522 seconds)
2022-03-05 19:03:12 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:03:12 | INFO | train | epoch 148 | loss 0.967 | nll_loss 0.634 | ppl 1.55 | wps 28113.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7202 | lr 0.000372626 | gnorm 0.925 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16876
2022-03-05 19:03:12 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:04:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:03 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 14.655 | nll_loss 14.491 | ppl 23033 | wps 48426 | wpb 510.9 | bsz 1 | num_updates 7251 | best_loss 8.204
2022-03-05 19:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7251 updates
2022-03-05 19:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:05:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 149 @ 7251 updates, score 14.655) (writing took 1.7023390480317175 seconds)
2022-03-05 19:05:05 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:05:05 | INFO | train | epoch 149 | loss 0.958 | nll_loss 0.626 | ppl 1.54 | wps 28144.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7251 | lr 0.000371365 | gnorm 0.904 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 16989
2022-03-05 19:05:05 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:05:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:06:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:06:56 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 14.739 | nll_loss 14.578 | ppl 24457.3 | wps 48337.7 | wpb 510.9 | bsz 1 | num_updates 7299 | best_loss 8.204
2022-03-05 19:06:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7299 updates
2022-03-05 19:06:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:06:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:06:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 150 @ 7299 updates, score 14.739) (writing took 1.6994471980724484 seconds)
2022-03-05 19:06:58 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:06:58 | INFO | train | epoch 150 | loss 0.949 | nll_loss 0.616 | ppl 1.53 | wps 27536.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7299 | lr 0.000370142 | gnorm 0.91 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 17102
2022-03-05 19:06:58 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:07:00 | INFO | train_inner | epoch 151:      1 / 49 loss=0.954, nll_loss=0.621, ppl=1.54, wps=27130.8, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.908, loss_scale=32, train_wall=197, gb_free=21.6, wall=17104
2022-03-05 19:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:08:49 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 14.734 | nll_loss 14.573 | ppl 24374.3 | wps 48336.4 | wpb 510.9 | bsz 1 | num_updates 7348 | best_loss 8.204
2022-03-05 19:08:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7348 updates
2022-03-05 19:08:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:08:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:08:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 151 @ 7348 updates, score 14.734) (writing took 1.719716747989878 seconds)
2022-03-05 19:08:50 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:08:50 | INFO | train | epoch 151 | loss 0.942 | nll_loss 0.609 | ppl 1.52 | wps 28139.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7348 | lr 0.000368906 | gnorm 0.903 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 17215
2022-03-05 19:08:50 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:10:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:10:42 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 14.724 | nll_loss 14.562 | ppl 24185.8 | wps 48207.6 | wpb 510.9 | bsz 1 | num_updates 7396 | best_loss 8.204
2022-03-05 19:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7396 updates
2022-03-05 19:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:10:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 152 @ 7396 updates, score 14.724) (writing took 1.7090878270100802 seconds)
2022-03-05 19:10:44 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:10:44 | INFO | train | epoch 152 | loss 0.933 | nll_loss 0.599 | ppl 1.51 | wps 27529.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7396 | lr 0.000367707 | gnorm 0.893 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 17328
2022-03-05 19:10:44 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:10:52 | INFO | train_inner | epoch 153:      4 / 49 loss=0.936, nll_loss=0.602, ppl=1.52, wps=27890.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.896, loss_scale=32, train_wall=197, gb_free=21.6, wall=17337
2022-03-05 19:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:12:35 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 14.794 | nll_loss 14.632 | ppl 25391.6 | wps 48159.7 | wpb 510.9 | bsz 1 | num_updates 7445 | best_loss 8.204
2022-03-05 19:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7445 updates
2022-03-05 19:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:12:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:12:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 153 @ 7445 updates, score 14.794) (writing took 1.7216251059435308 seconds)
2022-03-05 19:12:37 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:12:37 | INFO | train | epoch 153 | loss 0.928 | nll_loss 0.594 | ppl 1.51 | wps 28093.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7445 | lr 0.000366495 | gnorm 0.884 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 17441
2022-03-05 19:12:37 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:14:28 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 14.885 | nll_loss 14.724 | ppl 27058.5 | wps 48145.2 | wpb 510.9 | bsz 1 | num_updates 7493 | best_loss 8.204
2022-03-05 19:14:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7493 updates
2022-03-05 19:14:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 154 @ 7493 updates, score 14.885) (writing took 1.7366132391616702 seconds)
2022-03-05 19:14:30 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:14:30 | INFO | train | epoch 154 | loss 0.921 | nll_loss 0.587 | ppl 1.5 | wps 27511.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7493 | lr 0.000365319 | gnorm 0.888 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 17554
2022-03-05 19:14:30 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:14:45 | INFO | train_inner | epoch 155:      7 / 49 loss=0.923, nll_loss=0.589, ppl=1.5, wps=27862.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.887, loss_scale=16, train_wall=198, gb_free=21.6, wall=17569
2022-03-05 19:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:16:21 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 14.885 | nll_loss 14.725 | ppl 27077.9 | wps 48337.6 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 8.204
2022-03-05 19:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-05 19:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 155 @ 7542 updates, score 14.885) (writing took 1.707974286051467 seconds)
2022-03-05 19:16:23 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:16:23 | INFO | train | epoch 155 | loss 0.913 | nll_loss 0.578 | ppl 1.49 | wps 28128.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.868 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 17667
2022-03-05 19:16:23 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:18:14 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 14.892 | nll_loss 14.731 | ppl 27186.7 | wps 48268.7 | wpb 510.9 | bsz 1 | num_updates 7591 | best_loss 8.204
2022-03-05 19:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7591 updates
2022-03-05 19:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:18:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 156 @ 7591 updates, score 14.892) (writing took 1.7199194880668074 seconds)
2022-03-05 19:18:16 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:18:16 | INFO | train | epoch 156 | loss 0.908 | nll_loss 0.573 | ppl 1.49 | wps 28091.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7591 | lr 0.000362953 | gnorm 0.865 | loss_scale 16 | train_wall 96 | gb_free 21.6 | wall 17780
2022-03-05 19:18:16 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:36 | INFO | train_inner | epoch 157:      9 / 49 loss=0.909, nll_loss=0.574, ppl=1.49, wps=28141.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.863, loss_scale=16, train_wall=196, gb_free=21.6, wall=17800
2022-03-05 19:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:20:07 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 14.904 | nll_loss 14.741 | ppl 27373.8 | wps 48228.3 | wpb 510.9 | bsz 1 | num_updates 7640 | best_loss 8.204
2022-03-05 19:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7640 updates
2022-03-05 19:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:20:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 157 @ 7640 updates, score 14.904) (writing took 1.7266224450431764 seconds)
2022-03-05 19:20:09 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:20:09 | INFO | train | epoch 157 | loss 0.902 | nll_loss 0.567 | ppl 1.48 | wps 28108 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7640 | lr 0.000361787 | gnorm 0.858 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 17893
2022-03-05 19:20:09 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:22:00 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 14.9 | nll_loss 14.74 | ppl 27359.4 | wps 48302.6 | wpb 510.9 | bsz 1 | num_updates 7689 | best_loss 8.204
2022-03-05 19:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7689 updates
2022-03-05 19:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:22:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 158 @ 7689 updates, score 14.9) (writing took 1.7204255869146436 seconds)
2022-03-05 19:22:02 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:22:02 | INFO | train | epoch 158 | loss 0.896 | nll_loss 0.56 | ppl 1.47 | wps 28088.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7689 | lr 0.000360633 | gnorm 0.857 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18006
2022-03-05 19:22:02 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:22:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:22:26 | INFO | train_inner | epoch 159:     11 / 49 loss=0.897, nll_loss=0.562, ppl=1.48, wps=28131.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.856, loss_scale=32, train_wall=196, gb_free=21.6, wall=18030
2022-03-05 19:23:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:23:53 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 14.957 | nll_loss 14.799 | ppl 28500 | wps 48203.8 | wpb 510.9 | bsz 1 | num_updates 7738 | best_loss 8.204
2022-03-05 19:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7738 updates
2022-03-05 19:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:23:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 159 @ 7738 updates, score 14.957) (writing took 1.7294315490871668 seconds)
2022-03-05 19:23:55 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:23:55 | INFO | train | epoch 159 | loss 0.889 | nll_loss 0.553 | ppl 1.47 | wps 28120.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7738 | lr 0.000359489 | gnorm 0.848 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18119
2022-03-05 19:23:55 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:23:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:24:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:25:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:25:46 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 15.053 | nll_loss 14.895 | ppl 30464.7 | wps 47607.3 | wpb 510.9 | bsz 1 | num_updates 7786 | best_loss 8.204
2022-03-05 19:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7786 updates
2022-03-05 19:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 160 @ 7786 updates, score 15.053) (writing took 1.6853846649173647 seconds)
2022-03-05 19:25:48 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:25:48 | INFO | train | epoch 160 | loss 0.881 | nll_loss 0.546 | ppl 1.46 | wps 27559.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 7786 | lr 0.000358379 | gnorm 0.84 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18232
2022-03-05 19:25:48 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:19 | INFO | train_inner | epoch 161:     14 / 49 loss=0.884, nll_loss=0.548, ppl=1.46, wps=27894.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.84, loss_scale=32, train_wall=197, gb_free=21.6, wall=18263
2022-03-05 19:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:27:39 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 14.936 | nll_loss 14.777 | ppl 28067.5 | wps 48146.4 | wpb 510.9 | bsz 1 | num_updates 7835 | best_loss 8.204
2022-03-05 19:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7835 updates
2022-03-05 19:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 161 @ 7835 updates, score 14.936) (writing took 1.7324382101651281 seconds)
2022-03-05 19:27:41 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:27:41 | INFO | train | epoch 161 | loss 0.877 | nll_loss 0.541 | ppl 1.46 | wps 28104.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7835 | lr 0.000357257 | gnorm 0.836 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18345
2022-03-05 19:27:41 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:29:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:29:32 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 14.991 | nll_loss 14.833 | ppl 29187.8 | wps 48367.2 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 8.204
2022-03-05 19:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-05 19:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:29:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:29:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 162 @ 7883 updates, score 14.991) (writing took 1.691083270125091 seconds)
2022-03-05 19:29:34 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:29:34 | INFO | train | epoch 162 | loss 0.872 | nll_loss 0.536 | ppl 1.45 | wps 27547.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.849 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18458
2022-03-05 19:29:34 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:12 | INFO | train_inner | epoch 163:     17 / 49 loss=0.873, nll_loss=0.537, ppl=1.45, wps=27886.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.849, loss_scale=32, train_wall=197, gb_free=21.6, wall=18496
2022-03-05 19:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:31:26 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 15.049 | nll_loss 14.89 | ppl 30367.6 | wps 47576.4 | wpb 510.9 | bsz 1 | num_updates 7932 | best_loss 8.204
2022-03-05 19:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7932 updates
2022-03-05 19:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 163 @ 7932 updates, score 15.049) (writing took 1.7259233130607754 seconds)
2022-03-05 19:31:27 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:31:27 | INFO | train | epoch 163 | loss 0.867 | nll_loss 0.53 | ppl 1.44 | wps 28100.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7932 | lr 0.000355066 | gnorm 0.837 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18571
2022-03-05 19:31:27 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:33:18 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 15.019 | nll_loss 14.859 | ppl 29726.7 | wps 48361.6 | wpb 510.9 | bsz 1 | num_updates 7981 | best_loss 8.204
2022-03-05 19:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7981 updates
2022-03-05 19:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 164 @ 7981 updates, score 15.019) (writing took 1.735040765022859 seconds)
2022-03-05 19:33:20 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:33:20 | INFO | train | epoch 164 | loss 0.861 | nll_loss 0.524 | ppl 1.44 | wps 28135.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7981 | lr 0.000353974 | gnorm 0.824 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18684
2022-03-05 19:33:20 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:34:02 | INFO | train_inner | epoch 165:     19 / 49 loss=0.86, nll_loss=0.524, ppl=1.44, wps=28148, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.82, loss_scale=32, train_wall=195, gb_free=21.6, wall=18726
2022-03-05 19:34:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:12 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 15.086 | nll_loss 14.926 | ppl 31138.8 | wps 48465.2 | wpb 510.9 | bsz 1 | num_updates 8029 | best_loss 8.204
2022-03-05 19:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8029 updates
2022-03-05 19:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:35:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:35:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 165 @ 8029 updates, score 15.086) (writing took 1.691617086995393 seconds)
2022-03-05 19:35:13 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:35:13 | INFO | train | epoch 165 | loss 0.854 | nll_loss 0.518 | ppl 1.43 | wps 27539.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8029 | lr 0.000352914 | gnorm 0.815 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18797
2022-03-05 19:35:13 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:37:05 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 15.12 | nll_loss 14.964 | ppl 31955.3 | wps 48275.6 | wpb 510.9 | bsz 1 | num_updates 8078 | best_loss 8.204
2022-03-05 19:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8078 updates
2022-03-05 19:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 166 @ 8078 updates, score 15.12) (writing took 1.7418820010498166 seconds)
2022-03-05 19:37:06 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:37:06 | INFO | train | epoch 166 | loss 0.848 | nll_loss 0.511 | ppl 1.42 | wps 28102.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8078 | lr 0.000351842 | gnorm 0.804 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 18910
2022-03-05 19:37:06 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:55 | INFO | train_inner | epoch 167:     22 / 49 loss=0.849, nll_loss=0.512, ppl=1.43, wps=27875.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.812, loss_scale=32, train_wall=198, gb_free=21.6, wall=18959
2022-03-05 19:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:38:58 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 15.127 | nll_loss 14.974 | ppl 32173 | wps 47909.7 | wpb 510.9 | bsz 1 | num_updates 8127 | best_loss 8.204
2022-03-05 19:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8127 updates
2022-03-05 19:38:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:38:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:38:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 167 @ 8127 updates, score 15.127) (writing took 1.7225645270664245 seconds)
2022-03-05 19:38:59 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:38:59 | INFO | train | epoch 167 | loss 0.845 | nll_loss 0.508 | ppl 1.42 | wps 28103.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8127 | lr 0.00035078 | gnorm 0.818 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19023
2022-03-05 19:38:59 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:38:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:39:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:40:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:40:51 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 15.149 | nll_loss 14.995 | ppl 32665.9 | wps 48269.4 | wpb 510.9 | bsz 1 | num_updates 8175 | best_loss 8.204
2022-03-05 19:40:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8175 updates
2022-03-05 19:40:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 168 @ 8175 updates, score 15.149) (writing took 1.7265914019662887 seconds)
2022-03-05 19:40:52 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:40:52 | INFO | train | epoch 168 | loss 0.84 | nll_loss 0.503 | ppl 1.42 | wps 27539.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8175 | lr 0.000349749 | gnorm 0.822 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19137
2022-03-05 19:40:52 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:41:48 | INFO | train_inner | epoch 169:     25 / 49 loss=0.84, nll_loss=0.503, ppl=1.42, wps=27872.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.812, loss_scale=32, train_wall=198, gb_free=21.6, wall=19192
2022-03-05 19:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:42:44 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 15.255 | nll_loss 15.101 | ppl 35145.8 | wps 48053.4 | wpb 510.9 | bsz 1 | num_updates 8224 | best_loss 8.204
2022-03-05 19:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8224 updates
2022-03-05 19:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:42:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 169 @ 8224 updates, score 15.255) (writing took 1.7321196051780134 seconds)
2022-03-05 19:42:46 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:42:46 | INFO | train | epoch 169 | loss 0.832 | nll_loss 0.495 | ppl 1.41 | wps 28065.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8224 | lr 0.000348705 | gnorm 0.793 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19250
2022-03-05 19:42:46 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:44:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:44:37 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 15.191 | nll_loss 15.035 | ppl 33564.8 | wps 48183.9 | wpb 510.9 | bsz 1 | num_updates 8272 | best_loss 8.204
2022-03-05 19:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8272 updates
2022-03-05 19:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:44:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:44:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 170 @ 8272 updates, score 15.191) (writing took 1.6916598691605031 seconds)
2022-03-05 19:44:39 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:44:39 | INFO | train | epoch 170 | loss 0.828 | nll_loss 0.49 | ppl 1.4 | wps 27529.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8272 | lr 0.000347692 | gnorm 0.797 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19363
2022-03-05 19:44:39 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:45:40 | INFO | train_inner | epoch 171:     28 / 49 loss=0.829, nll_loss=0.491, ppl=1.41, wps=27849.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.804, loss_scale=32, train_wall=198, gb_free=21.6, wall=19425
2022-03-05 19:46:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:46:30 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 15.204 | nll_loss 15.048 | ppl 33884.9 | wps 48231.9 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.204
2022-03-05 19:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-05 19:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:46:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:46:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 171 @ 8321 updates, score 15.204) (writing took 1.723644251935184 seconds)
2022-03-05 19:46:32 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:46:32 | INFO | train | epoch 171 | loss 0.826 | nll_loss 0.488 | ppl 1.4 | wps 28074.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.812 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19476
2022-03-05 19:46:32 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:48:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:48:23 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 15.198 | nll_loss 15.042 | ppl 33730.5 | wps 48272.5 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.204
2022-03-05 19:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-05 19:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:48:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:48:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 172 @ 8370 updates, score 15.198) (writing took 1.7272060080431402 seconds)
2022-03-05 19:48:25 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:48:25 | INFO | train | epoch 172 | loss 0.82 | nll_loss 0.482 | ppl 1.4 | wps 28078.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.787 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19589
2022-03-05 19:48:25 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:49:33 | INFO | train_inner | epoch 173:     31 / 49 loss=0.818, nll_loss=0.48, ppl=1.4, wps=27858, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.786, loss_scale=32, train_wall=198, gb_free=21.6, wall=19657
2022-03-05 19:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:50:16 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 15.266 | nll_loss 15.112 | ppl 35422.9 | wps 48284.5 | wpb 510.9 | bsz 1 | num_updates 8418 | best_loss 8.204
2022-03-05 19:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8418 updates
2022-03-05 19:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 173 @ 8418 updates, score 15.266) (writing took 1.7039186900947243 seconds)
2022-03-05 19:50:18 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:50:18 | INFO | train | epoch 173 | loss 0.813 | nll_loss 0.475 | ppl 1.39 | wps 27534.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8418 | lr 0.000344664 | gnorm 0.78 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19702
2022-03-05 19:50:18 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:52:09 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 15.193 | nll_loss 15.037 | ppl 33618 | wps 48312.5 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 8.204
2022-03-05 19:52:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-05 19:52:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:52:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:52:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 174 @ 8467 updates, score 15.193) (writing took 1.7369756260886788 seconds)
2022-03-05 19:52:11 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:52:11 | INFO | train | epoch 174 | loss 0.812 | nll_loss 0.474 | ppl 1.39 | wps 28115.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.784 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 19815
2022-03-05 19:52:11 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:52:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:53:24 | INFO | train_inner | epoch 175:     33 / 49 loss=0.81, nll_loss=0.472, ppl=1.39, wps=28143.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.776, loss_scale=32, train_wall=196, gb_free=21.6, wall=19888
2022-03-05 19:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:54:03 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 15.166 | nll_loss 15.014 | ppl 33076.1 | wps 48274.6 | wpb 510.9 | bsz 1 | num_updates 8516 | best_loss 8.204
2022-03-05 19:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8516 updates
2022-03-05 19:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 175 @ 8516 updates, score 15.166) (writing took 1.7203118740580976 seconds)
2022-03-05 19:54:04 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 19:54:04 | INFO | train | epoch 175 | loss 0.805 | nll_loss 0.467 | ppl 1.38 | wps 28109.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8516 | lr 0.000342675 | gnorm 0.761 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 19928
2022-03-05 19:54:04 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 19:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:54:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:55:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:55:56 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 15.237 | nll_loss 15.085 | ppl 34754.9 | wps 48160 | wpb 510.9 | bsz 1 | num_updates 8564 | best_loss 8.204
2022-03-05 19:55:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8564 updates
2022-03-05 19:55:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 176 @ 8564 updates, score 15.237) (writing took 1.7127499950584024 seconds)
2022-03-05 19:55:57 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 19:55:57 | INFO | train | epoch 176 | loss 0.804 | nll_loss 0.466 | ppl 1.38 | wps 27510.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8564 | lr 0.000341713 | gnorm 0.78 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20041
2022-03-05 19:55:57 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 19:55:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:57:17 | INFO | train_inner | epoch 177:     36 / 49 loss=0.803, nll_loss=0.465, ppl=1.38, wps=27866.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.775, loss_scale=32, train_wall=198, gb_free=21.6, wall=20121
2022-03-05 19:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:57:49 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 15.271 | nll_loss 15.117 | ppl 35548.3 | wps 48370.5 | wpb 510.9 | bsz 1 | num_updates 8613 | best_loss 8.204
2022-03-05 19:57:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8613 updates
2022-03-05 19:57:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 177 @ 8613 updates, score 15.271) (writing took 1.7283231040928513 seconds)
2022-03-05 19:57:50 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 19:57:50 | INFO | train | epoch 177 | loss 0.798 | nll_loss 0.46 | ppl 1.38 | wps 28117.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8613 | lr 0.00034074 | gnorm 0.772 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20154
2022-03-05 19:57:50 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 19:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:59:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:59:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:59:42 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 15.303 | nll_loss 15.147 | ppl 36283.4 | wps 48292.5 | wpb 510.9 | bsz 1 | num_updates 8661 | best_loss 8.204
2022-03-05 19:59:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8661 updates
2022-03-05 19:59:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:59:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 19:59:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 178 @ 8661 updates, score 15.303) (writing took 1.7415047278627753 seconds)
2022-03-05 19:59:43 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 19:59:43 | INFO | train | epoch 178 | loss 0.794 | nll_loss 0.455 | ppl 1.37 | wps 27531.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8661 | lr 0.000339794 | gnorm 0.773 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20268
2022-03-05 19:59:43 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 19:59:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:01:09 | INFO | train_inner | epoch 179:     39 / 49 loss=0.793, nll_loss=0.455, ppl=1.37, wps=27885.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.768, loss_scale=32, train_wall=198, gb_free=21.6, wall=20353
2022-03-05 20:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:01:35 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 15.264 | nll_loss 15.111 | ppl 35385 | wps 47630.5 | wpb 510.9 | bsz 1 | num_updates 8710 | best_loss 8.204
2022-03-05 20:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8710 updates
2022-03-05 20:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:01:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 179 @ 8710 updates, score 15.264) (writing took 1.735466738929972 seconds)
2022-03-05 20:01:37 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:01:37 | INFO | train | epoch 179 | loss 0.79 | nll_loss 0.452 | ppl 1.37 | wps 28100.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8710 | lr 0.000338837 | gnorm 0.762 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20381
2022-03-05 20:01:37 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:03:28 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 15.33 | nll_loss 15.177 | ppl 37051.3 | wps 48300.2 | wpb 510.9 | bsz 1 | num_updates 8759 | best_loss 8.204
2022-03-05 20:03:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8759 updates
2022-03-05 20:03:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:03:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 180 @ 8759 updates, score 15.33) (writing took 1.7399201791267842 seconds)
2022-03-05 20:03:30 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:03:30 | INFO | train | epoch 180 | loss 0.785 | nll_loss 0.446 | ppl 1.36 | wps 28121.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8759 | lr 0.000337888 | gnorm 0.758 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20494
2022-03-05 20:03:30 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:03:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:04:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:05:02 | INFO | train_inner | epoch 181:     42 / 49 loss=0.784, nll_loss=0.446, ppl=1.36, wps=27875.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.757, loss_scale=32, train_wall=198, gb_free=21.6, wall=20586
2022-03-05 20:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:05:21 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 15.308 | nll_loss 15.157 | ppl 36546.2 | wps 48279.4 | wpb 510.9 | bsz 1 | num_updates 8807 | best_loss 8.204
2022-03-05 20:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8807 updates
2022-03-05 20:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 181 @ 8807 updates, score 15.308) (writing took 1.7115829528775066 seconds)
2022-03-05 20:05:23 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:05:23 | INFO | train | epoch 181 | loss 0.781 | nll_loss 0.443 | ppl 1.36 | wps 27543 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8807 | lr 0.000336966 | gnorm 0.753 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20607
2022-03-05 20:05:23 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:07:14 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 15.386 | nll_loss 15.234 | ppl 38544.1 | wps 48232.7 | wpb 510.9 | bsz 1 | num_updates 8856 | best_loss 8.204
2022-03-05 20:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8856 updates
2022-03-05 20:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:07:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:07:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 182 @ 8856 updates, score 15.386) (writing took 1.6831560479477048 seconds)
2022-03-05 20:07:16 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:07:16 | INFO | train | epoch 182 | loss 0.778 | nll_loss 0.439 | ppl 1.36 | wps 28132.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8856 | lr 0.000336032 | gnorm 0.743 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20720
2022-03-05 20:07:16 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:08:52 | INFO | train_inner | epoch 183:     44 / 49 loss=0.776, nll_loss=0.438, ppl=1.35, wps=28149.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.746, loss_scale=32, train_wall=196, gb_free=21.6, wall=20817
2022-03-05 20:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:09:07 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 15.42 | nll_loss 15.268 | ppl 39462.4 | wps 47394.8 | wpb 510.9 | bsz 1 | num_updates 8905 | best_loss 8.204
2022-03-05 20:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8905 updates
2022-03-05 20:09:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 183 @ 8905 updates, score 15.42) (writing took 1.761126842815429 seconds)
2022-03-05 20:09:09 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:09:09 | INFO | train | epoch 183 | loss 0.774 | nll_loss 0.435 | ppl 1.35 | wps 28066 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8905 | lr 0.000335107 | gnorm 0.748 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 20833
2022-03-05 20:09:09 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:09:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:11:00 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 15.416 | nll_loss 15.266 | ppl 39394.9 | wps 48638 | wpb 510.9 | bsz 1 | num_updates 8953 | best_loss 8.204
2022-03-05 20:11:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8953 updates
2022-03-05 20:11:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 184 @ 8953 updates, score 15.416) (writing took 1.7913185481447726 seconds)
2022-03-05 20:11:02 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:11:02 | INFO | train | epoch 184 | loss 0.771 | nll_loss 0.433 | ppl 1.35 | wps 27516.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8953 | lr 0.000334207 | gnorm 0.753 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 20946
2022-03-05 20:11:02 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:45 | INFO | train_inner | epoch 185:     47 / 49 loss=0.769, nll_loss=0.431, ppl=1.35, wps=27851.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.746, loss_scale=32, train_wall=198, gb_free=21.6, wall=21049
2022-03-05 20:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:53 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 15.357 | nll_loss 15.208 | ppl 37851.6 | wps 48224.1 | wpb 510.9 | bsz 1 | num_updates 9002 | best_loss 8.204
2022-03-05 20:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9002 updates
2022-03-05 20:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:12:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 185 @ 9002 updates, score 15.357) (writing took 1.7244649559725076 seconds)
2022-03-05 20:12:55 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:12:55 | INFO | train | epoch 185 | loss 0.766 | nll_loss 0.427 | ppl 1.34 | wps 28096.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9002 | lr 0.000333296 | gnorm 0.736 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21059
2022-03-05 20:12:55 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:12:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:14:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:14:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:47 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 15.424 | nll_loss 15.275 | ppl 39640.2 | wps 47606 | wpb 510.9 | bsz 1 | num_updates 9050 | best_loss 8.204
2022-03-05 20:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9050 updates
2022-03-05 20:14:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 186 @ 9050 updates, score 15.424) (writing took 1.74162806593813 seconds)
2022-03-05 20:14:48 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:14:48 | INFO | train | epoch 186 | loss 0.762 | nll_loss 0.424 | ppl 1.34 | wps 27473.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9050 | lr 0.000332411 | gnorm 0.734 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21172
2022-03-05 20:14:48 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:40 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 15.438 | nll_loss 15.289 | ppl 40039.6 | wps 48159.1 | wpb 510.9 | bsz 1 | num_updates 9099 | best_loss 8.204
2022-03-05 20:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9099 updates
2022-03-05 20:16:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:16:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 187 @ 9099 updates, score 15.438) (writing took 1.751001775963232 seconds)
2022-03-05 20:16:41 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:16:41 | INFO | train | epoch 187 | loss 0.759 | nll_loss 0.421 | ppl 1.34 | wps 28079.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9099 | lr 0.000331515 | gnorm 0.735 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21286
2022-03-05 20:16:41 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:16:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:44 | INFO | train_inner | epoch 188:      1 / 49 loss=0.761, nll_loss=0.422, ppl=1.34, wps=27069.2, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=9100, lr=0.000331497, gnorm=0.736, loss_scale=32, train_wall=197, gb_free=21.6, wall=21288
2022-03-05 20:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:18:33 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 15.504 | nll_loss 15.357 | ppl 41973.4 | wps 48330 | wpb 510.9 | bsz 1 | num_updates 9148 | best_loss 8.204
2022-03-05 20:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9148 updates
2022-03-05 20:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 188 @ 9148 updates, score 15.504) (writing took 1.725019816076383 seconds)
2022-03-05 20:18:35 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:18:35 | INFO | train | epoch 188 | loss 0.758 | nll_loss 0.419 | ppl 1.34 | wps 28083.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9148 | lr 0.000330626 | gnorm 0.744 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21399
2022-03-05 20:18:35 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:19:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:20:26 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 15.493 | nll_loss 15.343 | ppl 41565 | wps 48105 | wpb 510.9 | bsz 1 | num_updates 9196 | best_loss 8.204
2022-03-05 20:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9196 updates
2022-03-05 20:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 189 @ 9196 updates, score 15.493) (writing took 1.742399713024497 seconds)
2022-03-05 20:20:28 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:20:28 | INFO | train | epoch 189 | loss 0.751 | nll_loss 0.413 | ppl 1.33 | wps 27539.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9196 | lr 0.000329762 | gnorm 0.716 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21512
2022-03-05 20:20:28 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:20:37 | INFO | train_inner | epoch 190:      4 / 49 loss=0.754, nll_loss=0.415, ppl=1.33, wps=27869.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9200, lr=0.00032969, gnorm=0.729, loss_scale=32, train_wall=198, gb_free=21.6, wall=21521
2022-03-05 20:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:22:19 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 15.381 | nll_loss 15.232 | ppl 38484.2 | wps 48111 | wpb 510.9 | bsz 1 | num_updates 9245 | best_loss 8.204
2022-03-05 20:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9245 updates
2022-03-05 20:22:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 190 @ 9245 updates, score 15.381) (writing took 1.728112017037347 seconds)
2022-03-05 20:22:21 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:22:21 | INFO | train | epoch 190 | loss 0.749 | nll_loss 0.411 | ppl 1.33 | wps 28089.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9245 | lr 0.000328887 | gnorm 0.728 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21625
2022-03-05 20:22:21 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:24:12 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 15.482 | nll_loss 15.334 | ppl 41314.8 | wps 47957.3 | wpb 510.9 | bsz 1 | num_updates 9294 | best_loss 8.204
2022-03-05 20:24:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9294 updates
2022-03-05 20:24:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:24:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:24:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 191 @ 9294 updates, score 15.482) (writing took 1.7227092641405761 seconds)
2022-03-05 20:24:14 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:24:14 | INFO | train | epoch 191 | loss 0.746 | nll_loss 0.407 | ppl 1.33 | wps 28114.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9294 | lr 0.000328019 | gnorm 0.722 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21738
2022-03-05 20:24:14 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:24:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:24:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:24:29 | INFO | train_inner | epoch 192:      7 / 49 loss=0.747, nll_loss=0.408, ppl=1.33, wps=27871.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.725, loss_scale=32, train_wall=198, gb_free=21.6, wall=21753
2022-03-05 20:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:26:05 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 15.544 | nll_loss 15.397 | ppl 43154.6 | wps 48212.5 | wpb 510.9 | bsz 1 | num_updates 9342 | best_loss 8.204
2022-03-05 20:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9342 updates
2022-03-05 20:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 192 @ 9342 updates, score 15.544) (writing took 1.7266976891551167 seconds)
2022-03-05 20:26:07 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:26:07 | INFO | train | epoch 192 | loss 0.743 | nll_loss 0.404 | ppl 1.32 | wps 27519.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9342 | lr 0.000327175 | gnorm 0.714 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21851
2022-03-05 20:26:07 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:27:58 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 15.423 | nll_loss 15.276 | ppl 39668.6 | wps 48371.8 | wpb 510.9 | bsz 1 | num_updates 9391 | best_loss 8.204
2022-03-05 20:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9391 updates
2022-03-05 20:27:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 193 @ 9391 updates, score 15.423) (writing took 1.762066629016772 seconds)
2022-03-05 20:28:00 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:28:00 | INFO | train | epoch 193 | loss 0.738 | nll_loss 0.4 | ppl 1.32 | wps 28112.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9391 | lr 0.00032632 | gnorm 0.697 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 21964
2022-03-05 20:28:00 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:28:20 | INFO | train_inner | epoch 194:      9 / 49 loss=0.74, nll_loss=0.401, ppl=1.32, wps=28139.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.704, loss_scale=32, train_wall=196, gb_free=21.6, wall=21984
2022-03-05 20:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:29:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:51 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 15.635 | nll_loss 15.49 | ppl 46031.2 | wps 48134 | wpb 510.9 | bsz 1 | num_updates 9439 | best_loss 8.204
2022-03-05 20:29:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9439 updates
2022-03-05 20:29:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:29:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:29:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 194 @ 9439 updates, score 15.635) (writing took 1.7105055558495224 seconds)
2022-03-05 20:29:53 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:29:53 | INFO | train | epoch 194 | loss 0.736 | nll_loss 0.398 | ppl 1.32 | wps 27552.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9439 | lr 0.00032549 | gnorm 0.709 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22077
2022-03-05 20:29:53 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:31:44 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 15.62 | nll_loss 15.477 | ppl 45595.6 | wps 48118.2 | wpb 510.9 | bsz 1 | num_updates 9488 | best_loss 8.204
2022-03-05 20:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9488 updates
2022-03-05 20:31:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:31:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:31:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 195 @ 9488 updates, score 15.62) (writing took 1.7533261280041188 seconds)
2022-03-05 20:31:46 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:31:46 | INFO | train | epoch 195 | loss 0.734 | nll_loss 0.395 | ppl 1.32 | wps 28096.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9488 | lr 0.000324648 | gnorm 0.702 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22190
2022-03-05 20:31:46 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:31:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:32:13 | INFO | train_inner | epoch 196:     12 / 49 loss=0.734, nll_loss=0.396, ppl=1.32, wps=27872.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.707, loss_scale=32, train_wall=198, gb_free=21.6, wall=22217
2022-03-05 20:33:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:33:38 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 15.524 | nll_loss 15.378 | ppl 42589.8 | wps 48045.9 | wpb 510.9 | bsz 1 | num_updates 9537 | best_loss 8.204
2022-03-05 20:33:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9537 updates
2022-03-05 20:33:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:33:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 196 @ 9537 updates, score 15.524) (writing took 1.6424375618807971 seconds)
2022-03-05 20:33:39 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:33:39 | INFO | train | epoch 196 | loss 0.731 | nll_loss 0.393 | ppl 1.31 | wps 28093.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9537 | lr 0.000323813 | gnorm 0.704 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22303
2022-03-05 20:33:39 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:34:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:35:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:31 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 15.564 | nll_loss 15.419 | ppl 43817.8 | wps 48112.8 | wpb 510.9 | bsz 1 | num_updates 9585 | best_loss 8.204
2022-03-05 20:35:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9585 updates
2022-03-05 20:35:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:35:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:35:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 197 @ 9585 updates, score 15.564) (writing took 1.7417012359946966 seconds)
2022-03-05 20:35:32 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:35:32 | INFO | train | epoch 197 | loss 0.725 | nll_loss 0.387 | ppl 1.31 | wps 27518.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9585 | lr 0.000323001 | gnorm 0.697 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22416
2022-03-05 20:35:32 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:35:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:36:05 | INFO | train_inner | epoch 198:     15 / 49 loss=0.727, nll_loss=0.389, ppl=1.31, wps=27866.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.697, loss_scale=32, train_wall=198, gb_free=21.6, wall=22449
2022-03-05 20:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:24 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 15.544 | nll_loss 15.398 | ppl 43181.3 | wps 48081.3 | wpb 510.9 | bsz 1 | num_updates 9634 | best_loss 8.204
2022-03-05 20:37:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9634 updates
2022-03-05 20:37:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 198 @ 9634 updates, score 15.544) (writing took 1.7046137279830873 seconds)
2022-03-05 20:37:25 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:37:25 | INFO | train | epoch 198 | loss 0.722 | nll_loss 0.384 | ppl 1.3 | wps 28084.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9634 | lr 0.000322179 | gnorm 0.691 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22530
2022-03-05 20:37:25 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:39:17 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 15.536 | nll_loss 15.389 | ppl 42909.4 | wps 48278.4 | wpb 510.9 | bsz 1 | num_updates 9683 | best_loss 8.204
2022-03-05 20:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9683 updates
2022-03-05 20:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 199 @ 9683 updates, score 15.536) (writing took 1.846279236022383 seconds)
2022-03-05 20:39:19 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:39:19 | INFO | train | epoch 199 | loss 0.722 | nll_loss 0.384 | ppl 1.3 | wps 28081.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9683 | lr 0.000321362 | gnorm 0.689 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22643
2022-03-05 20:39:19 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:39:58 | INFO | train_inner | epoch 200:     18 / 49 loss=0.721, nll_loss=0.383, ppl=1.3, wps=27849.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.686, loss_scale=32, train_wall=198, gb_free=21.6, wall=22682
2022-03-05 20:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:41:10 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 15.574 | nll_loss 15.426 | ppl 44038.6 | wps 48059.7 | wpb 510.9 | bsz 1 | num_updates 9731 | best_loss 8.204
2022-03-05 20:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9731 updates
2022-03-05 20:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 200 @ 9731 updates, score 15.574) (writing took 1.696375812869519 seconds)
2022-03-05 20:41:12 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:41:12 | INFO | train | epoch 200 | loss 0.717 | nll_loss 0.379 | ppl 1.3 | wps 27521.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9731 | lr 0.000320569 | gnorm 0.671 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22756
2022-03-05 20:41:12 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:43:03 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 15.636 | nll_loss 15.493 | ppl 46108.6 | wps 48302.5 | wpb 510.9 | bsz 1 | num_updates 9780 | best_loss 8.204
2022-03-05 20:43:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9780 updates
2022-03-05 20:43:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 201 @ 9780 updates, score 15.636) (writing took 1.7595154920127243 seconds)
2022-03-05 20:43:05 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:43:05 | INFO | train | epoch 201 | loss 0.715 | nll_loss 0.377 | ppl 1.3 | wps 28111.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9780 | lr 0.000319765 | gnorm 0.68 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22869
2022-03-05 20:43:05 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:43:49 | INFO | train_inner | epoch 202:     20 / 49 loss=0.715, nll_loss=0.377, ppl=1.3, wps=28143.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.676, loss_scale=32, train_wall=196, gb_free=21.6, wall=22913
2022-03-05 20:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:44:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:44:56 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 15.611 | nll_loss 15.465 | ppl 45227.9 | wps 48109.2 | wpb 510.9 | bsz 1 | num_updates 9828 | best_loss 8.204
2022-03-05 20:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9828 updates
2022-03-05 20:44:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:44:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:44:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 202 @ 9828 updates, score 15.611) (writing took 1.6929407468996942 seconds)
2022-03-05 20:44:58 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:44:58 | INFO | train | epoch 202 | loss 0.714 | nll_loss 0.376 | ppl 1.3 | wps 27528.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9828 | lr 0.000318983 | gnorm 0.676 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 22982
2022-03-05 20:44:58 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:44:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:46:49 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 15.566 | nll_loss 15.421 | ppl 43881.8 | wps 48240.3 | wpb 510.9 | bsz 1 | num_updates 9877 | best_loss 8.204
2022-03-05 20:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9877 updates
2022-03-05 20:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 203 @ 9877 updates, score 15.566) (writing took 1.7079656841233373 seconds)
2022-03-05 20:46:51 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:46:51 | INFO | train | epoch 203 | loss 0.711 | nll_loss 0.373 | ppl 1.3 | wps 28111.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9877 | lr 0.000318191 | gnorm 0.677 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23095
2022-03-05 20:46:51 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:47:42 | INFO | train_inner | epoch 204:     23 / 49 loss=0.711, nll_loss=0.373, ppl=1.29, wps=27878.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.679, loss_scale=32, train_wall=198, gb_free=21.6, wall=23146
2022-03-05 20:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:48:42 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 15.547 | nll_loss 15.402 | ppl 43291.6 | wps 48185.9 | wpb 510.9 | bsz 1 | num_updates 9926 | best_loss 8.204
2022-03-05 20:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9926 updates
2022-03-05 20:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 204 @ 9926 updates, score 15.547) (writing took 1.6609361660666764 seconds)
2022-03-05 20:48:44 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:48:44 | INFO | train | epoch 204 | loss 0.708 | nll_loss 0.37 | ppl 1.29 | wps 28116.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9926 | lr 0.000317404 | gnorm 0.692 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23208
2022-03-05 20:48:44 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:50:35 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 15.632 | nll_loss 15.488 | ppl 45959.2 | wps 48125.3 | wpb 510.9 | bsz 1 | num_updates 9974 | best_loss 8.204
2022-03-05 20:50:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9974 updates
2022-03-05 20:50:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 205 @ 9974 updates, score 15.632) (writing took 1.7177690649405122 seconds)
2022-03-05 20:50:37 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:50:37 | INFO | train | epoch 205 | loss 0.705 | nll_loss 0.367 | ppl 1.29 | wps 27530.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9974 | lr 0.00031664 | gnorm 0.684 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23321
2022-03-05 20:50:37 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:51:34 | INFO | train_inner | epoch 206:     26 / 49 loss=0.705, nll_loss=0.367, ppl=1.29, wps=27876.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.685, loss_scale=32, train_wall=198, gb_free=21.6, wall=23378
2022-03-05 20:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:52:28 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 15.538 | nll_loss 15.393 | ppl 43029.8 | wps 48147.5 | wpb 510.9 | bsz 1 | num_updates 10023 | best_loss 8.204
2022-03-05 20:52:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10023 updates
2022-03-05 20:52:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:52:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:52:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 206 @ 10023 updates, score 15.538) (writing took 1.7383878910914063 seconds)
2022-03-05 20:52:30 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:52:30 | INFO | train | epoch 206 | loss 0.702 | nll_loss 0.364 | ppl 1.29 | wps 28095.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10023 | lr 0.000315865 | gnorm 0.687 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23434
2022-03-05 20:52:30 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:52:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:54:21 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 15.557 | nll_loss 15.415 | ppl 43686.9 | wps 48143.2 | wpb 510.9 | bsz 1 | num_updates 10072 | best_loss 8.204
2022-03-05 20:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10072 updates
2022-03-05 20:54:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 207 @ 10072 updates, score 15.557) (writing took 1.6798274700995535 seconds)
2022-03-05 20:54:23 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 20:54:23 | INFO | train | epoch 207 | loss 0.699 | nll_loss 0.361 | ppl 1.28 | wps 28128.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10072 | lr 0.000315095 | gnorm 0.678 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23547
2022-03-05 20:54:23 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 20:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:55:27 | INFO | train_inner | epoch 208:     29 / 49 loss=0.699, nll_loss=0.361, ppl=1.28, wps=27882.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.677, loss_scale=32, train_wall=198, gb_free=21.6, wall=23611
2022-03-05 20:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:56:14 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 15.57 | nll_loss 15.427 | ppl 44057.8 | wps 48152.8 | wpb 510.9 | bsz 1 | num_updates 10120 | best_loss 8.204
2022-03-05 20:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10120 updates
2022-03-05 20:56:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:56:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 208 @ 10120 updates, score 15.57) (writing took 1.7585810429882258 seconds)
2022-03-05 20:56:16 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 20:56:16 | INFO | train | epoch 208 | loss 0.694 | nll_loss 0.356 | ppl 1.28 | wps 27506 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10120 | lr 0.000314347 | gnorm 0.65 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23660
2022-03-05 20:56:16 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 20:56:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:58:08 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 15.606 | nll_loss 15.464 | ppl 45198.7 | wps 48239 | wpb 510.9 | bsz 1 | num_updates 10169 | best_loss 8.204
2022-03-05 20:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10169 updates
2022-03-05 20:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 20:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 209 @ 10169 updates, score 15.606) (writing took 1.7210547330323607 seconds)
2022-03-05 20:58:09 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 20:58:09 | INFO | train | epoch 209 | loss 0.693 | nll_loss 0.356 | ppl 1.28 | wps 28122.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10169 | lr 0.000313589 | gnorm 0.661 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23773
2022-03-05 20:58:09 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 20:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:59:18 | INFO | train_inner | epoch 210:     31 / 49 loss=0.693, nll_loss=0.356, ppl=1.28, wps=28128.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.666, loss_scale=32, train_wall=196, gb_free=21.6, wall=23842
2022-03-05 20:59:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 20:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:00:01 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 15.553 | nll_loss 15.409 | ppl 43498.6 | wps 48328.6 | wpb 510.9 | bsz 1 | num_updates 10217 | best_loss 8.204
2022-03-05 21:00:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10217 updates
2022-03-05 21:00:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:00:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:00:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 210 @ 10217 updates, score 15.553) (writing took 1.6796820489689708 seconds)
2022-03-05 21:00:02 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:00:02 | INFO | train | epoch 210 | loss 0.693 | nll_loss 0.355 | ppl 1.28 | wps 27537.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10217 | lr 0.000312852 | gnorm 0.683 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23886
2022-03-05 21:00:02 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:00:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:01:53 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 15.599 | nll_loss 15.457 | ppl 44984 | wps 48428.3 | wpb 510.9 | bsz 1 | num_updates 10266 | best_loss 8.204
2022-03-05 21:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10266 updates
2022-03-05 21:01:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:01:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 211 @ 10266 updates, score 15.599) (writing took 1.7281068621668965 seconds)
2022-03-05 21:01:55 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:01:55 | INFO | train | epoch 211 | loss 0.688 | nll_loss 0.351 | ppl 1.28 | wps 28139.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10266 | lr 0.000312104 | gnorm 0.649 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 23999
2022-03-05 21:01:55 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:03:10 | INFO | train_inner | epoch 212:     34 / 49 loss=0.688, nll_loss=0.35, ppl=1.27, wps=27908.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.654, loss_scale=32, train_wall=197, gb_free=21.6, wall=24074
2022-03-05 21:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:03:46 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 15.637 | nll_loss 15.496 | ppl 46212.2 | wps 48243.6 | wpb 510.9 | bsz 1 | num_updates 10315 | best_loss 8.204
2022-03-05 21:03:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10315 updates
2022-03-05 21:03:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 212 @ 10315 updates, score 15.637) (writing took 1.7447061880957335 seconds)
2022-03-05 21:03:48 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:03:48 | INFO | train | epoch 212 | loss 0.686 | nll_loss 0.349 | ppl 1.27 | wps 28116.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10315 | lr 0.000311362 | gnorm 0.652 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24112
2022-03-05 21:03:48 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:04:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:05:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:40 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 15.566 | nll_loss 15.424 | ppl 43950.6 | wps 48169.2 | wpb 510.9 | bsz 1 | num_updates 10363 | best_loss 8.204
2022-03-05 21:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10363 updates
2022-03-05 21:05:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 213 @ 10363 updates, score 15.566) (writing took 1.669580953195691 seconds)
2022-03-05 21:05:41 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:05:41 | INFO | train | epoch 213 | loss 0.685 | nll_loss 0.347 | ppl 1.27 | wps 27558.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10363 | lr 0.00031064 | gnorm 0.654 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24225
2022-03-05 21:05:41 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:07:03 | INFO | train_inner | epoch 214:     37 / 49 loss=0.685, nll_loss=0.347, ppl=1.27, wps=27894.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.651, loss_scale=32, train_wall=197, gb_free=21.6, wall=24307
2022-03-05 21:07:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:07:32 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 15.603 | nll_loss 15.462 | ppl 45136.1 | wps 48156.7 | wpb 510.9 | bsz 1 | num_updates 10412 | best_loss 8.204
2022-03-05 21:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10412 updates
2022-03-05 21:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 214 @ 10412 updates, score 15.603) (writing took 1.7285054170060903 seconds)
2022-03-05 21:07:34 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:07:34 | INFO | train | epoch 214 | loss 0.682 | nll_loss 0.345 | ppl 1.27 | wps 28123.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10412 | lr 0.000309908 | gnorm 0.646 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24338
2022-03-05 21:07:34 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:09:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:09:26 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 15.643 | nll_loss 15.504 | ppl 46455 | wps 48271 | wpb 510.9 | bsz 1 | num_updates 10461 | best_loss 8.204
2022-03-05 21:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10461 updates
2022-03-05 21:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 215 @ 10461 updates, score 15.643) (writing took 1.7472815150395036 seconds)
2022-03-05 21:09:27 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:09:27 | INFO | train | epoch 215 | loss 0.681 | nll_loss 0.344 | ppl 1.27 | wps 28103.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10461 | lr 0.000309181 | gnorm 0.65 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24451
2022-03-05 21:09:27 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:09:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:10:55 | INFO | train_inner | epoch 216:     40 / 49 loss=0.679, nll_loss=0.342, ppl=1.27, wps=27863.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.645, loss_scale=32, train_wall=198, gb_free=21.6, wall=24539
2022-03-05 21:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:19 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 15.639 | nll_loss 15.498 | ppl 46289.1 | wps 48220.2 | wpb 510.9 | bsz 1 | num_updates 10509 | best_loss 8.204
2022-03-05 21:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10509 updates
2022-03-05 21:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 216 @ 10509 updates, score 15.639) (writing took 1.686693634139374 seconds)
2022-03-05 21:11:20 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:11:20 | INFO | train | epoch 216 | loss 0.677 | nll_loss 0.34 | ppl 1.27 | wps 27517.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10509 | lr 0.000308475 | gnorm 0.642 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24564
2022-03-05 21:11:20 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:13:12 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 15.627 | nll_loss 15.486 | ppl 45882.4 | wps 48213 | wpb 510.9 | bsz 1 | num_updates 10558 | best_loss 8.204
2022-03-05 21:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10558 updates
2022-03-05 21:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 217 @ 10558 updates, score 15.627) (writing took 1.7208480110857636 seconds)
2022-03-05 21:13:14 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:13:14 | INFO | train | epoch 217 | loss 0.675 | nll_loss 0.338 | ppl 1.26 | wps 28085.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10558 | lr 0.000307758 | gnorm 0.644 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24678
2022-03-05 21:13:14 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:14:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:14:48 | INFO | train_inner | epoch 218:     43 / 49 loss=0.674, nll_loss=0.337, ppl=1.26, wps=27866.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.642, loss_scale=32, train_wall=198, gb_free=21.6, wall=24772
2022-03-05 21:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:15:05 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 15.621 | nll_loss 15.48 | ppl 45707.8 | wps 48127.1 | wpb 510.9 | bsz 1 | num_updates 10606 | best_loss 8.204
2022-03-05 21:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10606 updates
2022-03-05 21:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 218 @ 10606 updates, score 15.621) (writing took 1.756033182144165 seconds)
2022-03-05 21:15:07 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:15:07 | INFO | train | epoch 218 | loss 0.673 | nll_loss 0.336 | ppl 1.26 | wps 27513.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10606 | lr 0.000307061 | gnorm 0.641 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24791
2022-03-05 21:15:07 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:16:58 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 15.571 | nll_loss 15.429 | ppl 44110.9 | wps 48176.8 | wpb 510.9 | bsz 1 | num_updates 10655 | best_loss 8.204
2022-03-05 21:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10655 updates
2022-03-05 21:16:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 219 @ 10655 updates, score 15.571) (writing took 1.6853478068951517 seconds)
2022-03-05 21:17:00 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:17:00 | INFO | train | epoch 219 | loss 0.67 | nll_loss 0.333 | ppl 1.26 | wps 28120.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10655 | lr 0.000306354 | gnorm 0.643 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 24904
2022-03-05 21:17:00 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:18:39 | INFO | train_inner | epoch 220:     45 / 49 loss=0.67, nll_loss=0.334, ppl=1.26, wps=28133.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.643, loss_scale=32, train_wall=196, gb_free=21.6, wall=25003
2022-03-05 21:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:18:51 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 15.572 | nll_loss 15.431 | ppl 44162.3 | wps 48127.3 | wpb 510.9 | bsz 1 | num_updates 10704 | best_loss 8.204
2022-03-05 21:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10704 updates
2022-03-05 21:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 220 @ 10704 updates, score 15.572) (writing took 1.7206666448619217 seconds)
2022-03-05 21:18:53 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:18:53 | INFO | train | epoch 220 | loss 0.669 | nll_loss 0.333 | ppl 1.26 | wps 28098.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10704 | lr 0.000305652 | gnorm 0.64 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25017
2022-03-05 21:18:53 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:19:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:20:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:20:44 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 15.613 | nll_loss 15.473 | ppl 45487.4 | wps 48247.5 | wpb 510.9 | bsz 1 | num_updates 10752 | best_loss 8.204
2022-03-05 21:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10752 updates
2022-03-05 21:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 221 @ 10752 updates, score 15.613) (writing took 1.7757348259910941 seconds)
2022-03-05 21:20:46 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:20:46 | INFO | train | epoch 221 | loss 0.666 | nll_loss 0.329 | ppl 1.26 | wps 27515.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10752 | lr 0.000304969 | gnorm 0.623 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25130
2022-03-05 21:20:46 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:22:31 | INFO | train_inner | epoch 222:     48 / 49 loss=0.666, nll_loss=0.329, ppl=1.26, wps=27884, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.628, loss_scale=32, train_wall=197, gb_free=21.6, wall=25235
2022-03-05 21:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:22:37 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 15.58 | nll_loss 15.437 | ppl 44364.8 | wps 48585 | wpb 510.9 | bsz 1 | num_updates 10801 | best_loss 8.204
2022-03-05 21:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10801 updates
2022-03-05 21:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 222 @ 10801 updates, score 15.58) (writing took 1.6638719800394028 seconds)
2022-03-05 21:22:39 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:22:39 | INFO | train | epoch 222 | loss 0.665 | nll_loss 0.329 | ppl 1.26 | wps 28168.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10801 | lr 0.000304276 | gnorm 0.632 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25243
2022-03-05 21:22:39 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:24:30 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 15.612 | nll_loss 15.47 | ppl 45398.2 | wps 48113.5 | wpb 510.9 | bsz 1 | num_updates 10850 | best_loss 8.204
2022-03-05 21:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10850 updates
2022-03-05 21:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:24:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 223 @ 10850 updates, score 15.612) (writing took 1.7519896640442312 seconds)
2022-03-05 21:24:32 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:24:32 | INFO | train | epoch 223 | loss 0.662 | nll_loss 0.326 | ppl 1.25 | wps 28112.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10850 | lr 0.000303588 | gnorm 0.622 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25356
2022-03-05 21:24:32 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:24:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:26:23 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 15.632 | nll_loss 15.49 | ppl 46011.9 | wps 48232.7 | wpb 510.9 | bsz 1 | num_updates 10898 | best_loss 8.204
2022-03-05 21:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10898 updates
2022-03-05 21:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 224 @ 10898 updates, score 15.632) (writing took 1.7200733739882708 seconds)
2022-03-05 21:26:25 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:26:25 | INFO | train | epoch 224 | loss 0.66 | nll_loss 0.324 | ppl 1.25 | wps 27558.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10898 | lr 0.000302919 | gnorm 0.622 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25469
2022-03-05 21:26:25 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:26:29 | INFO | train_inner | epoch 225:      2 / 49 loss=0.661, nll_loss=0.324, ppl=1.25, wps=27136.5, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=10900, lr=0.000302891, gnorm=0.624, loss_scale=32, train_wall=197, gb_free=21.6, wall=25473
2022-03-05 21:28:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:28:16 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 15.709 | nll_loss 15.572 | ppl 48703.8 | wps 48167.2 | wpb 510.9 | bsz 1 | num_updates 10947 | best_loss 8.204
2022-03-05 21:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10947 updates
2022-03-05 21:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 225 @ 10947 updates, score 15.709) (writing took 1.6939419759437442 seconds)
2022-03-05 21:28:18 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:28:18 | INFO | train | epoch 225 | loss 0.659 | nll_loss 0.323 | ppl 1.25 | wps 28102.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10947 | lr 0.00030224 | gnorm 0.62 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25582
2022-03-05 21:28:18 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:29:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:30:09 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 15.742 | nll_loss 15.605 | ppl 49824.3 | wps 48035.6 | wpb 510.9 | bsz 1 | num_updates 10995 | best_loss 8.204
2022-03-05 21:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10995 updates
2022-03-05 21:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:30:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:30:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 226 @ 10995 updates, score 15.742) (writing took 1.7476053850259632 seconds)
2022-03-05 21:30:11 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:30:11 | INFO | train | epoch 226 | loss 0.656 | nll_loss 0.32 | ppl 1.25 | wps 27504.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10995 | lr 0.00030158 | gnorm 0.616 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25695
2022-03-05 21:30:11 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:30:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:30:22 | INFO | train_inner | epoch 227:      5 / 49 loss=0.657, nll_loss=0.321, ppl=1.25, wps=27861.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.617, loss_scale=32, train_wall=198, gb_free=21.6, wall=25706
2022-03-05 21:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:32:02 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 15.565 | nll_loss 15.425 | ppl 43989.6 | wps 47961.1 | wpb 510.9 | bsz 1 | num_updates 11044 | best_loss 8.204
2022-03-05 21:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11044 updates
2022-03-05 21:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:32:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:32:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 227 @ 11044 updates, score 15.565) (writing took 1.7454610101412982 seconds)
2022-03-05 21:32:04 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:32:04 | INFO | train | epoch 227 | loss 0.654 | nll_loss 0.318 | ppl 1.25 | wps 28107.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11044 | lr 0.00030091 | gnorm 0.618 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25808
2022-03-05 21:32:04 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:33:55 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 15.644 | nll_loss 15.505 | ppl 46515.5 | wps 48161.1 | wpb 510.9 | bsz 1 | num_updates 11093 | best_loss 8.204
2022-03-05 21:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11093 updates
2022-03-05 21:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 228 @ 11093 updates, score 15.644) (writing took 1.6719010828528553 seconds)
2022-03-05 21:33:57 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:33:57 | INFO | train | epoch 228 | loss 0.653 | nll_loss 0.317 | ppl 1.25 | wps 28111.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11093 | lr 0.000300245 | gnorm 0.616 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 25921
2022-03-05 21:33:57 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:34:13 | INFO | train_inner | epoch 229:      7 / 49 loss=0.654, nll_loss=0.318, ppl=1.25, wps=28142.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.618, loss_scale=32, train_wall=196, gb_free=21.6, wall=25937
2022-03-05 21:34:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:35:48 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 15.649 | nll_loss 15.513 | ppl 46749.6 | wps 48250.5 | wpb 510.9 | bsz 1 | num_updates 11141 | best_loss 8.204
2022-03-05 21:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11141 updates
2022-03-05 21:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 229 @ 11141 updates, score 15.649) (writing took 1.731847520917654 seconds)
2022-03-05 21:35:50 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:35:50 | INFO | train | epoch 229 | loss 0.65 | nll_loss 0.314 | ppl 1.24 | wps 27544.8 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 11141 | lr 0.000299597 | gnorm 0.618 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26034
2022-03-05 21:35:50 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:37:41 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 15.652 | nll_loss 15.512 | ppl 46729.5 | wps 48297.7 | wpb 510.9 | bsz 1 | num_updates 11190 | best_loss 8.204
2022-03-05 21:37:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11190 updates
2022-03-05 21:37:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:37:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 230 @ 11190 updates, score 15.652) (writing took 1.7673404579982162 seconds)
2022-03-05 21:37:43 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:37:43 | INFO | train | epoch 230 | loss 0.648 | nll_loss 0.312 | ppl 1.24 | wps 28132.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11190 | lr 0.000298941 | gnorm 0.607 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26147
2022-03-05 21:37:43 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:38:05 | INFO | train_inner | epoch 231:     10 / 49 loss=0.648, nll_loss=0.313, ppl=1.24, wps=27888.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.615, loss_scale=32, train_wall=197, gb_free=21.6, wall=26169
2022-03-05 21:39:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:39:34 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 15.653 | nll_loss 15.516 | ppl 46851.5 | wps 48201.8 | wpb 510.9 | bsz 1 | num_updates 11239 | best_loss 8.204
2022-03-05 21:39:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11239 updates
2022-03-05 21:39:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:39:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 231 @ 11239 updates, score 15.653) (writing took 1.719468223163858 seconds)
2022-03-05 21:39:36 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:39:36 | INFO | train | epoch 231 | loss 0.648 | nll_loss 0.312 | ppl 1.24 | wps 28090.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11239 | lr 0.000298288 | gnorm 0.624 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26260
2022-03-05 21:39:36 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:39:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:41:28 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 15.626 | nll_loss 15.489 | ppl 45982.9 | wps 48296.5 | wpb 510.9 | bsz 1 | num_updates 11287 | best_loss 8.204
2022-03-05 21:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11287 updates
2022-03-05 21:41:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:41:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:41:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 232 @ 11287 updates, score 15.626) (writing took 1.7162354460451752 seconds)
2022-03-05 21:41:29 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:41:29 | INFO | train | epoch 232 | loss 0.644 | nll_loss 0.308 | ppl 1.24 | wps 27527.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11287 | lr 0.000297653 | gnorm 0.6 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26373
2022-03-05 21:41:29 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:41:58 | INFO | train_inner | epoch 233:     13 / 49 loss=0.645, nll_loss=0.309, ppl=1.24, wps=27866.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.607, loss_scale=32, train_wall=198, gb_free=21.6, wall=26402
2022-03-05 21:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:43:21 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 15.641 | nll_loss 15.504 | ppl 46483.1 | wps 48545.2 | wpb 510.9 | bsz 1 | num_updates 11336 | best_loss 8.204
2022-03-05 21:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11336 updates
2022-03-05 21:43:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:43:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:43:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 233 @ 11336 updates, score 15.641) (writing took 1.7457144430372864 seconds)
2022-03-05 21:43:22 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:43:22 | INFO | train | epoch 233 | loss 0.642 | nll_loss 0.307 | ppl 1.24 | wps 28075 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11336 | lr 0.000297009 | gnorm 0.602 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26487
2022-03-05 21:43:22 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:43:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:44:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:45:14 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 15.754 | nll_loss 15.618 | ppl 50286.3 | wps 48275.7 | wpb 510.9 | bsz 1 | num_updates 11384 | best_loss 8.204
2022-03-05 21:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11384 updates
2022-03-05 21:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:45:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 234 @ 11384 updates, score 15.754) (writing took 1.6885521011427045 seconds)
2022-03-05 21:45:16 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:45:16 | INFO | train | epoch 234 | loss 0.641 | nll_loss 0.306 | ppl 1.24 | wps 27531.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11384 | lr 0.000296382 | gnorm 0.604 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26600
2022-03-05 21:45:16 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:51 | INFO | train_inner | epoch 235:     16 / 49 loss=0.641, nll_loss=0.306, ppl=1.24, wps=27864.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.602, loss_scale=32, train_wall=198, gb_free=21.6, wall=26635
2022-03-05 21:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:07 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 15.647 | nll_loss 15.51 | ppl 46670.4 | wps 48072.4 | wpb 510.9 | bsz 1 | num_updates 11433 | best_loss 8.204
2022-03-05 21:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11433 updates
2022-03-05 21:47:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:47:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 235 @ 11433 updates, score 15.647) (writing took 1.7252433898393065 seconds)
2022-03-05 21:47:09 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:47:09 | INFO | train | epoch 235 | loss 0.639 | nll_loss 0.304 | ppl 1.23 | wps 28101.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11433 | lr 0.000295747 | gnorm 0.6 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26713
2022-03-05 21:47:09 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:48:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:49:00 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 15.731 | nll_loss 15.595 | ppl 49498.6 | wps 48298.9 | wpb 510.9 | bsz 1 | num_updates 11482 | best_loss 8.204
2022-03-05 21:49:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11482 updates
2022-03-05 21:49:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 236 @ 11482 updates, score 15.731) (writing took 1.7353817450348288 seconds)
2022-03-05 21:49:02 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:49:02 | INFO | train | epoch 236 | loss 0.637 | nll_loss 0.302 | ppl 1.23 | wps 28108.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11482 | lr 0.000295115 | gnorm 0.592 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26826
2022-03-05 21:49:02 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:49:41 | INFO | train_inner | epoch 237:     18 / 49 loss=0.638, nll_loss=0.302, ppl=1.23, wps=28137.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.596, loss_scale=32, train_wall=196, gb_free=21.6, wall=26865
2022-03-05 21:49:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:50:53 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 15.656 | nll_loss 15.519 | ppl 46952.3 | wps 48233.5 | wpb 510.9 | bsz 1 | num_updates 11530 | best_loss 8.204
2022-03-05 21:50:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11530 updates
2022-03-05 21:50:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:50:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 237 @ 11530 updates, score 15.656) (writing took 1.6835999260656536 seconds)
2022-03-05 21:50:55 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:50:55 | INFO | train | epoch 237 | loss 0.636 | nll_loss 0.301 | ppl 1.23 | wps 27550.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11530 | lr 0.0002945 | gnorm 0.599 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 26939
2022-03-05 21:50:55 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:50:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:52:46 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 15.702 | nll_loss 15.566 | ppl 48512.7 | wps 48140.7 | wpb 510.9 | bsz 1 | num_updates 11579 | best_loss 8.204
2022-03-05 21:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11579 updates
2022-03-05 21:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 238 @ 11579 updates, score 15.702) (writing took 1.7387678939849138 seconds)
2022-03-05 21:52:48 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 21:52:48 | INFO | train | epoch 238 | loss 0.634 | nll_loss 0.299 | ppl 1.23 | wps 28098 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11579 | lr 0.000293876 | gnorm 0.6 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27052
2022-03-05 21:52:48 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 21:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:53:34 | INFO | train_inner | epoch 239:     21 / 49 loss=0.635, nll_loss=0.3, ppl=1.23, wps=27887, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.597, loss_scale=32, train_wall=198, gb_free=21.6, wall=27098
2022-03-05 21:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:54:39 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 15.762 | nll_loss 15.627 | ppl 50588.8 | wps 48286 | wpb 510.9 | bsz 1 | num_updates 11628 | best_loss 8.204
2022-03-05 21:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11628 updates
2022-03-05 21:54:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:54:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 239 @ 11628 updates, score 15.762) (writing took 1.7550973389297724 seconds)
2022-03-05 21:54:41 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 21:54:41 | INFO | train | epoch 239 | loss 0.633 | nll_loss 0.298 | ppl 1.23 | wps 28110.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11628 | lr 0.000293256 | gnorm 0.598 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27165
2022-03-05 21:54:41 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 21:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:55:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:56:32 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 15.62 | nll_loss 15.484 | ppl 45827.4 | wps 48245.5 | wpb 510.9 | bsz 1 | num_updates 11676 | best_loss 8.204
2022-03-05 21:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11676 updates
2022-03-05 21:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 240 @ 11676 updates, score 15.62) (writing took 1.6704220359679312 seconds)
2022-03-05 21:56:34 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 21:56:34 | INFO | train | epoch 240 | loss 0.629 | nll_loss 0.294 | ppl 1.23 | wps 27567 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 11676 | lr 0.000292653 | gnorm 0.583 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27278
2022-03-05 21:56:34 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 21:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:57:27 | INFO | train_inner | epoch 241:     24 / 49 loss=0.63, nll_loss=0.295, ppl=1.23, wps=27886.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.595, loss_scale=32, train_wall=197, gb_free=21.6, wall=27331
2022-03-05 21:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:58:25 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 15.615 | nll_loss 15.479 | ppl 45666.1 | wps 48246.2 | wpb 510.9 | bsz 1 | num_updates 11725 | best_loss 8.204
2022-03-05 21:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11725 updates
2022-03-05 21:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:58:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 21:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 241 @ 11725 updates, score 15.615) (writing took 1.744360730983317 seconds)
2022-03-05 21:58:27 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 21:58:27 | INFO | train | epoch 241 | loss 0.63 | nll_loss 0.295 | ppl 1.23 | wps 28106.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11725 | lr 0.000292041 | gnorm 0.599 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27391
2022-03-05 21:58:27 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 21:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:59:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:00:18 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 15.69 | nll_loss 15.555 | ppl 48137.7 | wps 48329.7 | wpb 510.9 | bsz 1 | num_updates 11773 | best_loss 8.204
2022-03-05 22:00:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11773 updates
2022-03-05 22:00:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:00:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:00:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 242 @ 11773 updates, score 15.69) (writing took 1.7235426581464708 seconds)
2022-03-05 22:00:20 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:00:20 | INFO | train | epoch 242 | loss 0.626 | nll_loss 0.292 | ppl 1.22 | wps 27534.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11773 | lr 0.000291445 | gnorm 0.577 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27504
2022-03-05 22:00:20 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:00:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:01:19 | INFO | train_inner | epoch 243:     27 / 49 loss=0.627, nll_loss=0.293, ppl=1.22, wps=27881, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.584, loss_scale=32, train_wall=198, gb_free=21.6, wall=27563
2022-03-05 22:02:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:02:11 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 15.793 | nll_loss 15.661 | ppl 51801.5 | wps 48219.4 | wpb 510.9 | bsz 1 | num_updates 11822 | best_loss 8.204
2022-03-05 22:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11822 updates
2022-03-05 22:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 243 @ 11822 updates, score 15.793) (writing took 1.6896058910060674 seconds)
2022-03-05 22:02:13 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:02:13 | INFO | train | epoch 243 | loss 0.626 | nll_loss 0.292 | ppl 1.22 | wps 28131.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11822 | lr 0.00029084 | gnorm 0.584 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27617
2022-03-05 22:02:13 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:04:04 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 15.673 | nll_loss 15.539 | ppl 47623.3 | wps 48301.9 | wpb 510.9 | bsz 1 | num_updates 11871 | best_loss 8.204
2022-03-05 22:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11871 updates
2022-03-05 22:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 244 @ 11871 updates, score 15.673) (writing took 1.7142219501547515 seconds)
2022-03-05 22:04:06 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:04:06 | INFO | train | epoch 244 | loss 0.624 | nll_loss 0.29 | ppl 1.22 | wps 28089.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11871 | lr 0.000290239 | gnorm 0.584 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27730
2022-03-05 22:04:06 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:05:10 | INFO | train_inner | epoch 245:     29 / 49 loss=0.624, nll_loss=0.29, ppl=1.22, wps=28142.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.582, loss_scale=64, train_wall=196, gb_free=21.6, wall=27794
2022-03-05 22:05:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:57 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 15.696 | nll_loss 15.563 | ppl 48415.9 | wps 48220.6 | wpb 510.9 | bsz 1 | num_updates 11919 | best_loss 8.204
2022-03-05 22:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11919 updates
2022-03-05 22:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 245 @ 11919 updates, score 15.696) (writing took 1.7373241679742932 seconds)
2022-03-05 22:05:59 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:05:59 | INFO | train | epoch 245 | loss 0.622 | nll_loss 0.288 | ppl 1.22 | wps 27526.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11919 | lr 0.000289654 | gnorm 0.585 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27843
2022-03-05 22:05:59 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:07:50 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 15.658 | nll_loss 15.522 | ppl 47065.5 | wps 48310.2 | wpb 510.9 | bsz 1 | num_updates 11968 | best_loss 8.204
2022-03-05 22:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11968 updates
2022-03-05 22:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 246 @ 11968 updates, score 15.658) (writing took 1.7002446020487696 seconds)
2022-03-05 22:07:52 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:07:52 | INFO | train | epoch 246 | loss 0.621 | nll_loss 0.287 | ppl 1.22 | wps 28129.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11968 | lr 0.000289061 | gnorm 0.578 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 27956
2022-03-05 22:07:52 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:09:02 | INFO | train_inner | epoch 247:     32 / 49 loss=0.62, nll_loss=0.286, ppl=1.22, wps=27877.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.578, loss_scale=32, train_wall=198, gb_free=21.6, wall=28027
2022-03-05 22:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:09:43 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 15.785 | nll_loss 15.653 | ppl 51533.9 | wps 48105.9 | wpb 510.9 | bsz 1 | num_updates 12017 | best_loss 8.204
2022-03-05 22:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12017 updates
2022-03-05 22:09:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:09:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 247 @ 12017 updates, score 15.785) (writing took 1.837502992944792 seconds)
2022-03-05 22:09:45 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:09:45 | INFO | train | epoch 247 | loss 0.618 | nll_loss 0.284 | ppl 1.22 | wps 28070.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12017 | lr 0.000288471 | gnorm 0.57 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28069
2022-03-05 22:09:45 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:09:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:10:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:11:37 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 15.769 | nll_loss 15.636 | ppl 50919 | wps 48185.3 | wpb 510.9 | bsz 1 | num_updates 12065 | best_loss 8.204
2022-03-05 22:11:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12065 updates
2022-03-05 22:11:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:11:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:11:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 248 @ 12065 updates, score 15.769) (writing took 1.7930402050260454 seconds)
2022-03-05 22:11:38 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:11:38 | INFO | train | epoch 248 | loss 0.617 | nll_loss 0.284 | ppl 1.22 | wps 27528.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12065 | lr 0.000287896 | gnorm 0.576 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28182
2022-03-05 22:11:38 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:11:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:12:55 | INFO | train_inner | epoch 249:     35 / 49 loss=0.617, nll_loss=0.284, ppl=1.22, wps=27863.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.574, loss_scale=32, train_wall=198, gb_free=21.6, wall=28259
2022-03-05 22:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:13:30 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 15.709 | nll_loss 15.576 | ppl 48849.5 | wps 48216.5 | wpb 510.9 | bsz 1 | num_updates 12114 | best_loss 8.204
2022-03-05 22:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12114 updates
2022-03-05 22:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 249 @ 12114 updates, score 15.709) (writing took 1.734998265048489 seconds)
2022-03-05 22:13:31 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:13:31 | INFO | train | epoch 249 | loss 0.617 | nll_loss 0.284 | ppl 1.22 | wps 28095.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12114 | lr 0.000287314 | gnorm 0.573 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28296
2022-03-05 22:13:31 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:15:23 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 15.655 | nll_loss 15.521 | ppl 47027.3 | wps 48306.5 | wpb 510.9 | bsz 1 | num_updates 12162 | best_loss 8.204
2022-03-05 22:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12162 updates
2022-03-05 22:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 250 @ 12162 updates, score 15.655) (writing took 1.7300533780362457 seconds)
2022-03-05 22:15:25 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:15:25 | INFO | train | epoch 250 | loss 0.615 | nll_loss 0.281 | ppl 1.22 | wps 27519.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12162 | lr 0.000286746 | gnorm 0.577 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28409
2022-03-05 22:15:25 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:16:48 | INFO | train_inner | epoch 251:     38 / 49 loss=0.615, nll_loss=0.281, ppl=1.22, wps=27854.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.573, loss_scale=32, train_wall=198, gb_free=21.6, wall=28492
2022-03-05 22:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:17:16 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 15.696 | nll_loss 15.565 | ppl 48474.8 | wps 48202.7 | wpb 510.9 | bsz 1 | num_updates 12211 | best_loss 8.204
2022-03-05 22:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12211 updates
2022-03-05 22:17:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:17:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:17:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 251 @ 12211 updates, score 15.696) (writing took 1.7637272968422621 seconds)
2022-03-05 22:17:18 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:17:18 | INFO | train | epoch 251 | loss 0.613 | nll_loss 0.279 | ppl 1.21 | wps 28077.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12211 | lr 0.00028617 | gnorm 0.567 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28522
2022-03-05 22:17:18 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:19:09 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 15.766 | nll_loss 15.636 | ppl 50908.2 | wps 48229.4 | wpb 510.9 | bsz 1 | num_updates 12260 | best_loss 8.204
2022-03-05 22:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12260 updates
2022-03-05 22:19:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:19:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 252 @ 12260 updates, score 15.766) (writing took 1.7192444901447743 seconds)
2022-03-05 22:19:11 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:19:11 | INFO | train | epoch 252 | loss 0.612 | nll_loss 0.279 | ppl 1.21 | wps 28074.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12260 | lr 0.000285598 | gnorm 0.573 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28635
2022-03-05 22:19:11 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:20:41 | INFO | train_inner | epoch 253:     41 / 49 loss=0.611, nll_loss=0.278, ppl=1.21, wps=27846.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.568, loss_scale=32, train_wall=198, gb_free=21.6, wall=28725
2022-03-05 22:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:21:02 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 15.761 | nll_loss 15.63 | ppl 50718.4 | wps 48328.8 | wpb 510.9 | bsz 1 | num_updates 12308 | best_loss 8.204
2022-03-05 22:21:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12308 updates
2022-03-05 22:21:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:21:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:21:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 253 @ 12308 updates, score 15.761) (writing took 1.736405077856034 seconds)
2022-03-05 22:21:04 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:21:04 | INFO | train | epoch 253 | loss 0.609 | nll_loss 0.276 | ppl 1.21 | wps 27520 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12308 | lr 0.00028504 | gnorm 0.564 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28748
2022-03-05 22:21:04 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:22:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:55 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 15.596 | nll_loss 15.464 | ppl 45189.9 | wps 48083.2 | wpb 510.9 | bsz 1 | num_updates 12357 | best_loss 8.204
2022-03-05 22:22:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12357 updates
2022-03-05 22:22:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:22:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:22:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 254 @ 12357 updates, score 15.596) (writing took 1.7406832198612392 seconds)
2022-03-05 22:22:57 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:22:57 | INFO | train | epoch 254 | loss 0.608 | nll_loss 0.275 | ppl 1.21 | wps 28116.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12357 | lr 0.000284475 | gnorm 0.564 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28861
2022-03-05 22:22:57 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:24:32 | INFO | train_inner | epoch 255:     43 / 49 loss=0.608, nll_loss=0.275, ppl=1.21, wps=28146.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.564, loss_scale=32, train_wall=196, gb_free=21.6, wall=28956
2022-03-05 22:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:24:48 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 15.717 | nll_loss 15.584 | ppl 49128.8 | wps 48143.6 | wpb 510.9 | bsz 1 | num_updates 12406 | best_loss 8.204
2022-03-05 22:24:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12406 updates
2022-03-05 22:24:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:24:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:24:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 255 @ 12406 updates, score 15.717) (writing took 1.6958365440368652 seconds)
2022-03-05 22:24:50 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:24:50 | INFO | train | epoch 255 | loss 0.607 | nll_loss 0.274 | ppl 1.21 | wps 28118.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12406 | lr 0.000283912 | gnorm 0.564 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 28974
2022-03-05 22:24:50 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:25:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:26:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:26:41 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 15.682 | nll_loss 15.55 | ppl 47963 | wps 47741 | wpb 510.9 | bsz 1 | num_updates 12454 | best_loss 8.204
2022-03-05 22:26:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12454 updates
2022-03-05 22:26:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:26:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:26:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 256 @ 12454 updates, score 15.682) (writing took 1.7327736020088196 seconds)
2022-03-05 22:26:43 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:26:43 | INFO | train | epoch 256 | loss 0.606 | nll_loss 0.273 | ppl 1.21 | wps 27512.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12454 | lr 0.000283365 | gnorm 0.559 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29087
2022-03-05 22:26:43 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:24 | INFO | train_inner | epoch 257:     46 / 49 loss=0.605, nll_loss=0.273, ppl=1.21, wps=27878.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.556, loss_scale=32, train_wall=198, gb_free=21.6, wall=29188
2022-03-05 22:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:28:34 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 15.734 | nll_loss 15.603 | ppl 49766.9 | wps 48210.9 | wpb 510.9 | bsz 1 | num_updates 12503 | best_loss 8.204
2022-03-05 22:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12503 updates
2022-03-05 22:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:28:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:28:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 257 @ 12503 updates, score 15.734) (writing took 1.7360742210876197 seconds)
2022-03-05 22:28:36 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:28:36 | INFO | train | epoch 257 | loss 0.604 | nll_loss 0.271 | ppl 1.21 | wps 28118.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12503 | lr 0.000282809 | gnorm 0.551 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29200
2022-03-05 22:28:36 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:28:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:30:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:30:28 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 15.637 | nll_loss 15.505 | ppl 46487.7 | wps 48340.2 | wpb 510.9 | bsz 1 | num_updates 12551 | best_loss 8.204
2022-03-05 22:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12551 updates
2022-03-05 22:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 258 @ 12551 updates, score 15.637) (writing took 1.7025281412061304 seconds)
2022-03-05 22:30:29 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:30:29 | INFO | train | epoch 258 | loss 0.603 | nll_loss 0.27 | ppl 1.21 | wps 27532.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12551 | lr 0.000282267 | gnorm 0.553 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29313
2022-03-05 22:30:29 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:32:16 | INFO | train_inner | epoch 259:     49 / 49 loss=0.602, nll_loss=0.27, ppl=1.21, wps=27867.5, ups=0.43, wpb=64539.7, bsz=126.1, num_updates=12600, lr=0.000281718, gnorm=0.557, loss_scale=32, train_wall=197, gb_free=21.6, wall=29420
2022-03-05 22:32:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:32:21 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 15.636 | nll_loss 15.504 | ppl 46466.1 | wps 47873.2 | wpb 510.9 | bsz 1 | num_updates 12600 | best_loss 8.204
2022-03-05 22:32:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12600 updates
2022-03-05 22:32:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:32:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 259 @ 12600 updates, score 15.636) (writing took 1.732598930830136 seconds)
2022-03-05 22:32:22 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:32:22 | INFO | train | epoch 259 | loss 0.601 | nll_loss 0.269 | ppl 1.2 | wps 28118.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12600 | lr 0.000281718 | gnorm 0.559 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29426
2022-03-05 22:32:22 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:34:13 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 15.648 | nll_loss 15.518 | ppl 46918.2 | wps 48254.2 | wpb 510.9 | bsz 1 | num_updates 12649 | best_loss 8.204
2022-03-05 22:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12649 updates
2022-03-05 22:34:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:34:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 260 @ 12649 updates, score 15.648) (writing took 1.7474079050589353 seconds)
2022-03-05 22:34:15 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:34:15 | INFO | train | epoch 260 | loss 0.6 | nll_loss 0.268 | ppl 1.2 | wps 28136 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12649 | lr 0.000281172 | gnorm 0.554 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29539
2022-03-05 22:34:15 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:35:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:36:07 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 15.706 | nll_loss 15.577 | ppl 48868.2 | wps 48173.9 | wpb 510.9 | bsz 1 | num_updates 12697 | best_loss 8.204
2022-03-05 22:36:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12697 updates
2022-03-05 22:36:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 261 @ 12697 updates, score 15.706) (writing took 1.6851315079256892 seconds)
2022-03-05 22:36:08 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:36:08 | INFO | train | epoch 261 | loss 0.6 | nll_loss 0.268 | ppl 1.2 | wps 27548.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12697 | lr 0.00028064 | gnorm 0.559 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29652
2022-03-05 22:36:08 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:15 | INFO | train_inner | epoch 262:      3 / 49 loss=0.599, nll_loss=0.267, ppl=1.2, wps=27144.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.556, loss_scale=32, train_wall=197, gb_free=21.6, wall=29659
2022-03-05 22:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:38:00 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 15.74 | nll_loss 15.61 | ppl 50004.9 | wps 48182.5 | wpb 510.9 | bsz 1 | num_updates 12746 | best_loss 8.204
2022-03-05 22:38:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12746 updates
2022-03-05 22:38:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:38:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 262 @ 12746 updates, score 15.74) (writing took 1.7463946249336004 seconds)
2022-03-05 22:38:01 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:38:01 | INFO | train | epoch 262 | loss 0.597 | nll_loss 0.265 | ppl 1.2 | wps 28096.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12746 | lr 0.0002801 | gnorm 0.554 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29765
2022-03-05 22:38:01 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:38:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:39:53 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 15.708 | nll_loss 15.577 | ppl 48895.2 | wps 48324.1 | wpb 510.9 | bsz 1 | num_updates 12795 | best_loss 8.204
2022-03-05 22:39:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12795 updates
2022-03-05 22:39:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:39:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 263 @ 12795 updates, score 15.708) (writing took 1.7635426640044898 seconds)
2022-03-05 22:39:54 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:39:54 | INFO | train | epoch 263 | loss 0.596 | nll_loss 0.264 | ppl 1.2 | wps 28115.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12795 | lr 0.000279563 | gnorm 0.545 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29878
2022-03-05 22:39:54 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:40:06 | INFO | train_inner | epoch 264:      5 / 49 loss=0.596, nll_loss=0.264, ppl=1.2, wps=28134.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.549, loss_scale=32, train_wall=196, gb_free=21.6, wall=29890
2022-03-05 22:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:41:46 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 15.665 | nll_loss 15.535 | ppl 47468.1 | wps 48279.6 | wpb 510.9 | bsz 1 | num_updates 12843 | best_loss 8.204
2022-03-05 22:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12843 updates
2022-03-05 22:41:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:41:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:41:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 264 @ 12843 updates, score 15.665) (writing took 1.6651597749441862 seconds)
2022-03-05 22:41:47 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:41:47 | INFO | train | epoch 264 | loss 0.594 | nll_loss 0.262 | ppl 1.2 | wps 27549 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12843 | lr 0.00027904 | gnorm 0.545 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 29991
2022-03-05 22:41:47 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:41:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:43:39 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 15.702 | nll_loss 15.572 | ppl 48724.7 | wps 48067.2 | wpb 510.9 | bsz 1 | num_updates 12892 | best_loss 8.204
2022-03-05 22:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12892 updates
2022-03-05 22:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 265 @ 12892 updates, score 15.702) (writing took 1.748724655015394 seconds)
2022-03-05 22:43:40 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:43:40 | INFO | train | epoch 265 | loss 0.592 | nll_loss 0.261 | ppl 1.2 | wps 28094.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12892 | lr 0.000278509 | gnorm 0.545 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30105
2022-03-05 22:43:40 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:58 | INFO | train_inner | epoch 266:      8 / 49 loss=0.593, nll_loss=0.261, ppl=1.2, wps=27882.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12900, lr=0.000278423, gnorm=0.545, loss_scale=32, train_wall=197, gb_free=21.6, wall=30122
2022-03-05 22:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:45:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:45:32 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 15.747 | nll_loss 15.621 | ppl 50401.6 | wps 48257.1 | wpb 510.9 | bsz 1 | num_updates 12940 | best_loss 8.204
2022-03-05 22:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12940 updates
2022-03-05 22:45:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 266 @ 12940 updates, score 15.747) (writing took 1.7354096141643822 seconds)
2022-03-05 22:45:34 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:45:34 | INFO | train | epoch 266 | loss 0.592 | nll_loss 0.261 | ppl 1.2 | wps 27521.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12940 | lr 0.000277992 | gnorm 0.545 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30218
2022-03-05 22:45:34 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:47:25 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 15.7 | nll_loss 15.57 | ppl 48640.2 | wps 48096.8 | wpb 510.9 | bsz 1 | num_updates 12989 | best_loss 8.204
2022-03-05 22:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12989 updates
2022-03-05 22:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 267 @ 12989 updates, score 15.7) (writing took 1.682863222900778 seconds)
2022-03-05 22:47:27 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:47:27 | INFO | train | epoch 267 | loss 0.591 | nll_loss 0.26 | ppl 1.2 | wps 28133.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12989 | lr 0.000277468 | gnorm 0.553 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30331
2022-03-05 22:47:27 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:47:51 | INFO | train_inner | epoch 268:     11 / 49 loss=0.591, nll_loss=0.26, ppl=1.2, wps=27883.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.549, loss_scale=32, train_wall=197, gb_free=21.6, wall=30355
2022-03-05 22:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:49:18 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 15.718 | nll_loss 15.587 | ppl 49216.2 | wps 48338.7 | wpb 510.9 | bsz 1 | num_updates 13038 | best_loss 8.204
2022-03-05 22:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13038 updates
2022-03-05 22:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:49:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:49:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 268 @ 13038 updates, score 15.718) (writing took 1.7527255830354989 seconds)
2022-03-05 22:49:20 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:49:20 | INFO | train | epoch 268 | loss 0.59 | nll_loss 0.259 | ppl 1.2 | wps 28102.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13038 | lr 0.000276946 | gnorm 0.543 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30444
2022-03-05 22:49:20 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:50:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:51:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:51:11 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 15.795 | nll_loss 15.668 | ppl 52047 | wps 48237.7 | wpb 510.9 | bsz 1 | num_updates 13086 | best_loss 8.204
2022-03-05 22:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13086 updates
2022-03-05 22:51:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:51:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:51:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 269 @ 13086 updates, score 15.795) (writing took 1.7292287689633667 seconds)
2022-03-05 22:51:13 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 22:51:13 | INFO | train | epoch 269 | loss 0.587 | nll_loss 0.256 | ppl 1.19 | wps 27535.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13086 | lr 0.000276437 | gnorm 0.537 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30557
2022-03-05 22:51:13 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 22:51:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:51:44 | INFO | train_inner | epoch 270:     14 / 49 loss=0.588, nll_loss=0.257, ppl=1.19, wps=27879.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.538, loss_scale=32, train_wall=198, gb_free=21.6, wall=30588
2022-03-05 22:52:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:53:04 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 15.76 | nll_loss 15.632 | ppl 50795.1 | wps 48282.1 | wpb 510.9 | bsz 1 | num_updates 13135 | best_loss 8.204
2022-03-05 22:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13135 updates
2022-03-05 22:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:53:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 270 @ 13135 updates, score 15.76) (writing took 1.7255944351200014 seconds)
2022-03-05 22:53:06 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 22:53:06 | INFO | train | epoch 270 | loss 0.587 | nll_loss 0.256 | ppl 1.19 | wps 28139.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13135 | lr 0.000275921 | gnorm 0.537 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30670
2022-03-05 22:53:06 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 22:53:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:54:57 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 15.74 | nll_loss 15.612 | ppl 50070.5 | wps 47776.4 | wpb 510.9 | bsz 1 | num_updates 13184 | best_loss 8.204
2022-03-05 22:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13184 updates
2022-03-05 22:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 271 @ 13184 updates, score 15.74) (writing took 1.7362419660203159 seconds)
2022-03-05 22:54:59 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 22:54:59 | INFO | train | epoch 271 | loss 0.586 | nll_loss 0.255 | ppl 1.19 | wps 28084.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13184 | lr 0.000275408 | gnorm 0.539 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30783
2022-03-05 22:54:59 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 22:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:55:36 | INFO | train_inner | epoch 272:     17 / 49 loss=0.586, nll_loss=0.255, ppl=1.19, wps=27874.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.537, loss_scale=32, train_wall=198, gb_free=21.6, wall=30820
2022-03-05 22:56:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:56:50 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 15.673 | nll_loss 15.545 | ppl 47802.6 | wps 48207.4 | wpb 510.9 | bsz 1 | num_updates 13232 | best_loss 8.204
2022-03-05 22:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13232 updates
2022-03-05 22:56:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:56:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:56:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 272 @ 13232 updates, score 15.673) (writing took 1.7312912899069488 seconds)
2022-03-05 22:56:52 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 22:56:52 | INFO | train | epoch 272 | loss 0.584 | nll_loss 0.254 | ppl 1.19 | wps 27527.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13232 | lr 0.000274908 | gnorm 0.537 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 30896
2022-03-05 22:56:52 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 22:56:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:58:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:43 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 15.58 | nll_loss 15.449 | ppl 44735.1 | wps 48132.6 | wpb 510.9 | bsz 1 | num_updates 13281 | best_loss 8.204
2022-03-05 22:58:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13281 updates
2022-03-05 22:58:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 22:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 273 @ 13281 updates, score 15.58) (writing took 1.7019357150420547 seconds)
2022-03-05 22:58:45 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 22:58:45 | INFO | train | epoch 273 | loss 0.582 | nll_loss 0.252 | ppl 1.19 | wps 28062.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13281 | lr 0.0002744 | gnorm 0.533 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31009
2022-03-05 22:58:45 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 22:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:59:27 | INFO | train_inner | epoch 274:     19 / 49 loss=0.583, nll_loss=0.253, ppl=1.19, wps=28116.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.534, loss_scale=32, train_wall=196, gb_free=21.6, wall=31051
2022-03-05 23:00:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:00:36 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 15.649 | nll_loss 15.521 | ppl 47033.3 | wps 48233.6 | wpb 510.9 | bsz 1 | num_updates 13329 | best_loss 8.204
2022-03-05 23:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13329 updates
2022-03-05 23:00:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:00:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 274 @ 13329 updates, score 15.649) (writing took 1.7206675428897142 seconds)
2022-03-05 23:00:38 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:00:38 | INFO | train | epoch 274 | loss 0.581 | nll_loss 0.251 | ppl 1.19 | wps 27513.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13329 | lr 0.000273906 | gnorm 0.533 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31122
2022-03-05 23:00:38 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:02:30 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 15.646 | nll_loss 15.519 | ppl 46939.8 | wps 48147.4 | wpb 510.9 | bsz 1 | num_updates 13378 | best_loss 8.204
2022-03-05 23:02:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13378 updates
2022-03-05 23:02:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:02:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 275 @ 13378 updates, score 15.646) (writing took 1.7176104239188135 seconds)
2022-03-05 23:02:31 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:02:31 | INFO | train | epoch 275 | loss 0.58 | nll_loss 0.25 | ppl 1.19 | wps 28101.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13378 | lr 0.000273404 | gnorm 0.527 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31235
2022-03-05 23:02:31 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:03:20 | INFO | train_inner | epoch 276:     22 / 49 loss=0.581, nll_loss=0.251, ppl=1.19, wps=27861, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.529, loss_scale=32, train_wall=198, gb_free=21.6, wall=31284
2022-03-05 23:04:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:23 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 15.638 | nll_loss 15.51 | ppl 46677.9 | wps 48496.7 | wpb 510.9 | bsz 1 | num_updates 13427 | best_loss 8.204
2022-03-05 23:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13427 updates
2022-03-05 23:04:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:04:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:04:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 276 @ 13427 updates, score 15.638) (writing took 1.6541430929210037 seconds)
2022-03-05 23:04:24 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:04:24 | INFO | train | epoch 276 | loss 0.58 | nll_loss 0.25 | ppl 1.19 | wps 28106.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13427 | lr 0.000272904 | gnorm 0.536 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31348
2022-03-05 23:04:24 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:05:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:06:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:06:16 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 15.72 | nll_loss 15.593 | ppl 49427.9 | wps 47683.7 | wpb 510.9 | bsz 1 | num_updates 13475 | best_loss 8.204
2022-03-05 23:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13475 updates
2022-03-05 23:06:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:06:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 277 @ 13475 updates, score 15.72) (writing took 1.7329098638147116 seconds)
2022-03-05 23:06:17 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:06:17 | INFO | train | epoch 277 | loss 0.578 | nll_loss 0.248 | ppl 1.19 | wps 27525 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13475 | lr 0.000272418 | gnorm 0.527 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31462
2022-03-05 23:06:17 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:06:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:07:12 | INFO | train_inner | epoch 278:     25 / 49 loss=0.578, nll_loss=0.248, ppl=1.19, wps=27882.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.53, loss_scale=32, train_wall=198, gb_free=21.6, wall=31517
2022-03-05 23:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:08:09 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 15.63 | nll_loss 15.502 | ppl 46412.9 | wps 48417 | wpb 510.9 | bsz 1 | num_updates 13524 | best_loss 8.204
2022-03-05 23:08:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13524 updates
2022-03-05 23:08:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:08:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:08:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 278 @ 13524 updates, score 15.63) (writing took 1.711266377940774 seconds)
2022-03-05 23:08:10 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:08:10 | INFO | train | epoch 278 | loss 0.577 | nll_loss 0.247 | ppl 1.19 | wps 28131.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13524 | lr 0.000271924 | gnorm 0.522 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31575
2022-03-05 23:08:10 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:09:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:10:02 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 15.548 | nll_loss 15.419 | ppl 43823.1 | wps 48306.8 | wpb 510.9 | bsz 1 | num_updates 13573 | best_loss 8.204
2022-03-05 23:10:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13573 updates
2022-03-05 23:10:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:10:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:10:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 279 @ 13573 updates, score 15.548) (writing took 1.6806779720354825 seconds)
2022-03-05 23:10:03 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:10:03 | INFO | train | epoch 279 | loss 0.575 | nll_loss 0.246 | ppl 1.19 | wps 28106.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13573 | lr 0.000271433 | gnorm 0.52 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31688
2022-03-05 23:10:04 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:10:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:10:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:11:05 | INFO | train_inner | epoch 280:     28 / 49 loss=0.575, nll_loss=0.246, ppl=1.19, wps=27877.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.521, loss_scale=32, train_wall=198, gb_free=21.6, wall=31749
2022-03-05 23:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:55 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 15.625 | nll_loss 15.499 | ppl 46299.9 | wps 48318.1 | wpb 510.9 | bsz 1 | num_updates 13621 | best_loss 8.204
2022-03-05 23:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13621 updates
2022-03-05 23:11:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 280 @ 13621 updates, score 15.625) (writing took 1.76051827496849 seconds)
2022-03-05 23:11:57 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:11:57 | INFO | train | epoch 280 | loss 0.574 | nll_loss 0.244 | ppl 1.18 | wps 27504.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13621 | lr 0.000270954 | gnorm 0.518 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31801
2022-03-05 23:11:57 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:13:48 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 15.577 | nll_loss 15.448 | ppl 44713.2 | wps 48240 | wpb 510.9 | bsz 1 | num_updates 13670 | best_loss 8.204
2022-03-05 23:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13670 updates
2022-03-05 23:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:13:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:13:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 281 @ 13670 updates, score 15.577) (writing took 1.7281539619434625 seconds)
2022-03-05 23:13:50 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:13:50 | INFO | train | epoch 281 | loss 0.574 | nll_loss 0.245 | ppl 1.18 | wps 27997.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13670 | lr 0.000270468 | gnorm 0.524 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 31914
2022-03-05 23:13:50 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:14:56 | INFO | train_inner | epoch 282:     30 / 49 loss=0.574, nll_loss=0.244, ppl=1.18, wps=28048.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.521, loss_scale=32, train_wall=196, gb_free=21.6, wall=31981
2022-03-05 23:15:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:15:42 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 15.701 | nll_loss 15.576 | ppl 48838.3 | wps 48153.9 | wpb 510.9 | bsz 1 | num_updates 13718 | best_loss 8.204
2022-03-05 23:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13718 updates
2022-03-05 23:15:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:15:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 282 @ 13718 updates, score 15.701) (writing took 1.6781706339679658 seconds)
2022-03-05 23:15:44 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:15:44 | INFO | train | epoch 282 | loss 0.573 | nll_loss 0.244 | ppl 1.18 | wps 27446.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13718 | lr 0.000269994 | gnorm 0.522 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32028
2022-03-05 23:15:44 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:17:35 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 15.646 | nll_loss 15.52 | ppl 46995.8 | wps 48173.4 | wpb 510.9 | bsz 1 | num_updates 13767 | best_loss 8.204
2022-03-05 23:17:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13767 updates
2022-03-05 23:17:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:17:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:17:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 283 @ 13767 updates, score 15.646) (writing took 1.7430790450889617 seconds)
2022-03-05 23:17:37 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:17:37 | INFO | train | epoch 283 | loss 0.572 | nll_loss 0.243 | ppl 1.18 | wps 28001.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13767 | lr 0.000269513 | gnorm 0.52 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32141
2022-03-05 23:17:37 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:18:50 | INFO | train_inner | epoch 284:     33 / 49 loss=0.571, nll_loss=0.242, ppl=1.18, wps=27772.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.517, loss_scale=32, train_wall=198, gb_free=21.6, wall=32214
2022-03-05 23:19:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:19:29 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 15.591 | nll_loss 15.465 | ppl 45227.2 | wps 48258.2 | wpb 510.9 | bsz 1 | num_updates 13816 | best_loss 8.204
2022-03-05 23:19:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13816 updates
2022-03-05 23:19:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:19:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:19:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 284 @ 13816 updates, score 15.591) (writing took 1.8889731911476701 seconds)
2022-03-05 23:19:31 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:19:31 | INFO | train | epoch 284 | loss 0.569 | nll_loss 0.24 | ppl 1.18 | wps 28003.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13816 | lr 0.000269035 | gnorm 0.509 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32255
2022-03-05 23:19:31 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:20:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:21:22 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 15.571 | nll_loss 15.445 | ppl 44604 | wps 48404.6 | wpb 510.9 | bsz 1 | num_updates 13864 | best_loss 8.204
2022-03-05 23:21:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13864 updates
2022-03-05 23:21:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:21:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 285 @ 13864 updates, score 15.571) (writing took 1.9444701350294054 seconds)
2022-03-05 23:21:24 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:21:24 | INFO | train | epoch 285 | loss 0.569 | nll_loss 0.24 | ppl 1.18 | wps 27548.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13864 | lr 0.000268569 | gnorm 0.513 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32368
2022-03-05 23:21:24 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:21:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:22:42 | INFO | train_inner | epoch 286:     36 / 49 loss=0.568, nll_loss=0.24, ppl=1.18, wps=27905.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.512, loss_scale=32, train_wall=197, gb_free=21.6, wall=32447
2022-03-05 23:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:23:15 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 15.588 | nll_loss 15.462 | ppl 45134.7 | wps 48461.2 | wpb 510.9 | bsz 1 | num_updates 13913 | best_loss 8.204
2022-03-05 23:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13913 updates
2022-03-05 23:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 286 @ 13913 updates, score 15.588) (writing took 1.9173177268821746 seconds)
2022-03-05 23:23:16 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:23:16 | INFO | train | epoch 286 | loss 0.568 | nll_loss 0.239 | ppl 1.18 | wps 28147.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13913 | lr 0.000268096 | gnorm 0.515 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32481
2022-03-05 23:23:16 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:25:07 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 15.665 | nll_loss 15.54 | ppl 47634.2 | wps 48366.9 | wpb 510.9 | bsz 1 | num_updates 13962 | best_loss 8.204
2022-03-05 23:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13962 updates
2022-03-05 23:25:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 287 @ 13962 updates, score 15.665) (writing took 1.9246437097899616 seconds)
2022-03-05 23:25:09 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:25:09 | INFO | train | epoch 287 | loss 0.566 | nll_loss 0.238 | ppl 1.18 | wps 28134.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13962 | lr 0.000267625 | gnorm 0.512 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32594
2022-03-05 23:25:09 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:25:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:26:35 | INFO | train_inner | epoch 288:     39 / 49 loss=0.567, nll_loss=0.238, ppl=1.18, wps=27902.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.516, loss_scale=32, train_wall=197, gb_free=21.6, wall=32679
2022-03-05 23:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:27:00 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 15.614 | nll_loss 15.487 | ppl 45936 | wps 48348.1 | wpb 510.9 | bsz 1 | num_updates 14010 | best_loss 8.204
2022-03-05 23:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14010 updates
2022-03-05 23:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 288 @ 14010 updates, score 15.614) (writing took 2.037405685056001 seconds)
2022-03-05 23:27:02 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:27:02 | INFO | train | epoch 288 | loss 0.567 | nll_loss 0.239 | ppl 1.18 | wps 27536.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14010 | lr 0.000267166 | gnorm 0.519 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32707
2022-03-05 23:27:02 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:28:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:28:53 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 15.654 | nll_loss 15.529 | ppl 47296 | wps 48418.8 | wpb 510.9 | bsz 1 | num_updates 14059 | best_loss 8.204
2022-03-05 23:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14059 updates
2022-03-05 23:28:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:28:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 289 @ 14059 updates, score 15.654) (writing took 1.9260668428614736 seconds)
2022-03-05 23:28:55 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:28:55 | INFO | train | epoch 289 | loss 0.564 | nll_loss 0.236 | ppl 1.18 | wps 28139.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14059 | lr 0.0002667 | gnorm 0.508 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 32819
2022-03-05 23:28:55 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:25 | INFO | train_inner | epoch 290:     41 / 49 loss=0.565, nll_loss=0.237, ppl=1.18, wps=28146.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.51, loss_scale=64, train_wall=195, gb_free=21.6, wall=32910
2022-03-05 23:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:30:47 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 15.7 | nll_loss 15.574 | ppl 48788.6 | wps 48353.1 | wpb 510.9 | bsz 1 | num_updates 14108 | best_loss 8.204
2022-03-05 23:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14108 updates
2022-03-05 23:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:30:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 290 @ 14108 updates, score 15.7) (writing took 1.9855258108582348 seconds)
2022-03-05 23:30:49 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:30:49 | INFO | train | epoch 290 | loss 0.565 | nll_loss 0.237 | ppl 1.18 | wps 28090.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14108 | lr 0.000266236 | gnorm 0.509 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 32933
2022-03-05 23:30:49 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:30:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:39 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 15.711 | nll_loss 15.586 | ppl 49190.3 | wps 48406.7 | wpb 510.9 | bsz 1 | num_updates 14156 | best_loss 8.204
2022-03-05 23:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14156 updates
2022-03-05 23:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:32:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 291 @ 14156 updates, score 15.711) (writing took 1.9170339859556407 seconds)
2022-03-05 23:32:41 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:32:41 | INFO | train | epoch 291 | loss 0.562 | nll_loss 0.234 | ppl 1.18 | wps 27577.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14156 | lr 0.000265785 | gnorm 0.508 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33045
2022-03-05 23:32:41 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:34:18 | INFO | train_inner | epoch 292:     44 / 49 loss=0.562, nll_loss=0.235, ppl=1.18, wps=27912.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.51, loss_scale=32, train_wall=197, gb_free=21.6, wall=33142
2022-03-05 23:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:32 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 15.628 | nll_loss 15.503 | ppl 46432.2 | wps 48640.9 | wpb 510.9 | bsz 1 | num_updates 14205 | best_loss 8.204
2022-03-05 23:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14205 updates
2022-03-05 23:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 292 @ 14205 updates, score 15.628) (writing took 1.971429767087102 seconds)
2022-03-05 23:34:34 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:34:34 | INFO | train | epoch 292 | loss 0.562 | nll_loss 0.234 | ppl 1.18 | wps 28134.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14205 | lr 0.000265326 | gnorm 0.512 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33158
2022-03-05 23:34:34 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:35:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:36:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:36:25 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 15.573 | nll_loss 15.446 | ppl 44635.1 | wps 48441.4 | wpb 510.9 | bsz 1 | num_updates 14253 | best_loss 8.204
2022-03-05 23:36:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14253 updates
2022-03-05 23:36:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:36:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:36:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 293 @ 14253 updates, score 15.573) (writing took 1.9003925579600036 seconds)
2022-03-05 23:36:27 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:36:27 | INFO | train | epoch 293 | loss 0.56 | nll_loss 0.232 | ppl 1.17 | wps 27566.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14253 | lr 0.000264879 | gnorm 0.506 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33271
2022-03-05 23:36:27 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:38:10 | INFO | train_inner | epoch 294:     47 / 49 loss=0.559, nll_loss=0.232, ppl=1.17, wps=27893.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.503, loss_scale=32, train_wall=197, gb_free=21.6, wall=33375
2022-03-05 23:38:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:38:18 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 15.648 | nll_loss 15.523 | ppl 47099.9 | wps 48579.3 | wpb 510.9 | bsz 1 | num_updates 14302 | best_loss 8.204
2022-03-05 23:38:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14302 updates
2022-03-05 23:38:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:38:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:38:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 294 @ 14302 updates, score 15.648) (writing took 1.9485783509444445 seconds)
2022-03-05 23:38:20 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:38:20 | INFO | train | epoch 294 | loss 0.558 | nll_loss 0.231 | ppl 1.17 | wps 28120.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14302 | lr 0.000264424 | gnorm 0.498 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33384
2022-03-05 23:38:20 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:11 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 15.619 | nll_loss 15.495 | ppl 46171.7 | wps 48350.4 | wpb 510.9 | bsz 1 | num_updates 14351 | best_loss 8.204
2022-03-05 23:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14351 updates
2022-03-05 23:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 295 @ 14351 updates, score 15.619) (writing took 1.878687143791467 seconds)
2022-03-05 23:40:13 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:40:13 | INFO | train | epoch 295 | loss 0.558 | nll_loss 0.231 | ppl 1.17 | wps 28143.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14351 | lr 0.000263973 | gnorm 0.5 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33497
2022-03-05 23:40:13 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:42:04 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 15.629 | nll_loss 15.504 | ppl 46483.2 | wps 48664.4 | wpb 510.9 | bsz 1 | num_updates 14399 | best_loss 8.204
2022-03-05 23:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14399 updates
2022-03-05 23:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 296 @ 14399 updates, score 15.629) (writing took 1.8021835929248482 seconds)
2022-03-05 23:42:06 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:42:06 | INFO | train | epoch 296 | loss 0.558 | nll_loss 0.231 | ppl 1.17 | wps 27597.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14399 | lr 0.000263532 | gnorm 0.503 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33610
2022-03-05 23:42:06 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:42:08 | INFO | train_inner | epoch 297:      1 / 49 loss=0.558, nll_loss=0.231, ppl=1.17, wps=27140.4, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=14400, lr=0.000263523, gnorm=0.503, loss_scale=32, train_wall=196, gb_free=21.6, wall=33612
2022-03-05 23:43:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:43:57 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 15.66 | nll_loss 15.535 | ppl 47480.1 | wps 48443 | wpb 510.9 | bsz 1 | num_updates 14448 | best_loss 8.204
2022-03-05 23:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14448 updates
2022-03-05 23:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 297 @ 14448 updates, score 15.66) (writing took 1.9656036118976772 seconds)
2022-03-05 23:43:59 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:43:59 | INFO | train | epoch 297 | loss 0.557 | nll_loss 0.23 | ppl 1.17 | wps 28106.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14448 | lr 0.000263085 | gnorm 0.498 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33723
2022-03-05 23:43:59 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:45:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:45:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:45:50 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 15.621 | nll_loss 15.497 | ppl 46252 | wps 48698.2 | wpb 510.9 | bsz 1 | num_updates 14496 | best_loss 8.204
2022-03-05 23:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14496 updates
2022-03-05 23:45:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:45:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 298 @ 14496 updates, score 15.621) (writing took 1.779531672829762 seconds)
2022-03-05 23:45:52 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:45:52 | INFO | train | epoch 298 | loss 0.555 | nll_loss 0.228 | ppl 1.17 | wps 27586 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14496 | lr 0.000262649 | gnorm 0.498 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33836
2022-03-05 23:45:52 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:45:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:46:01 | INFO | train_inner | epoch 299:      4 / 49 loss=0.556, nll_loss=0.229, ppl=1.17, wps=27903.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.498, loss_scale=32, train_wall=197, gb_free=21.6, wall=33845
2022-03-05 23:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:47:43 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 15.558 | nll_loss 15.433 | ppl 44235.9 | wps 48553.3 | wpb 510.9 | bsz 1 | num_updates 14545 | best_loss 8.204
2022-03-05 23:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14545 updates
2022-03-05 23:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:47:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:47:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 299 @ 14545 updates, score 15.558) (writing took 1.802477273158729 seconds)
2022-03-05 23:47:45 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:47:45 | INFO | train | epoch 299 | loss 0.555 | nll_loss 0.228 | ppl 1.17 | wps 28171.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14545 | lr 0.000262206 | gnorm 0.492 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 33949
2022-03-05 23:47:45 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:47:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:49:36 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 15.577 | nll_loss 15.452 | ppl 44833.7 | wps 48524.6 | wpb 510.9 | bsz 1 | num_updates 14594 | best_loss 8.204
2022-03-05 23:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14594 updates
2022-03-05 23:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 300 @ 14594 updates, score 15.577) (writing took 1.8701855628751218 seconds)
2022-03-05 23:49:38 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:49:38 | INFO | train | epoch 300 | loss 0.554 | nll_loss 0.228 | ppl 1.17 | wps 28139 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14594 | lr 0.000261766 | gnorm 0.498 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34062
2022-03-05 23:49:38 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:51 | INFO | train_inner | epoch 301:      6 / 49 loss=0.554, nll_loss=0.228, ppl=1.17, wps=28189.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.496, loss_scale=32, train_wall=195, gb_free=21.6, wall=34075
2022-03-05 23:50:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:51:29 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 15.659 | nll_loss 15.536 | ppl 47500.9 | wps 48478.3 | wpb 510.9 | bsz 1 | num_updates 14642 | best_loss 8.204
2022-03-05 23:51:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14642 updates
2022-03-05 23:51:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:51:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:51:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 301 @ 14642 updates, score 15.659) (writing took 1.7692789810243994 seconds)
2022-03-05 23:51:30 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-05 23:51:30 | INFO | train | epoch 301 | loss 0.552 | nll_loss 0.226 | ppl 1.17 | wps 27599.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14642 | lr 0.000261336 | gnorm 0.498 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34174
2022-03-05 23:51:30 | INFO | fairseq.trainer | begin training epoch 302
2022-03-05 23:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:53:22 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 15.682 | nll_loss 15.561 | ppl 48335.8 | wps 48436.9 | wpb 510.9 | bsz 1 | num_updates 14691 | best_loss 8.204
2022-03-05 23:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14691 updates
2022-03-05 23:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 302 @ 14691 updates, score 15.682) (writing took 1.7601181159261614 seconds)
2022-03-05 23:53:23 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-05 23:53:23 | INFO | train | epoch 302 | loss 0.552 | nll_loss 0.226 | ppl 1.17 | wps 28156.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14691 | lr 0.0002609 | gnorm 0.5 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34287
2022-03-05 23:53:23 | INFO | fairseq.trainer | begin training epoch 303
2022-03-05 23:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:43 | INFO | train_inner | epoch 303:      9 / 49 loss=0.552, nll_loss=0.225, ppl=1.17, wps=27934.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.496, loss_scale=32, train_wall=197, gb_free=21.6, wall=34307
2022-03-05 23:55:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:14 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 15.746 | nll_loss 15.625 | ppl 50535.2 | wps 48456 | wpb 510.9 | bsz 1 | num_updates 14740 | best_loss 8.204
2022-03-05 23:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14740 updates
2022-03-05 23:55:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 303 @ 14740 updates, score 15.746) (writing took 1.8039085259661078 seconds)
2022-03-05 23:55:16 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-05 23:55:16 | INFO | train | epoch 303 | loss 0.551 | nll_loss 0.225 | ppl 1.17 | wps 28161.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14740 | lr 0.000260466 | gnorm 0.497 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34400
2022-03-05 23:55:16 | INFO | fairseq.trainer | begin training epoch 304
2022-03-05 23:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:56:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:07 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 15.652 | nll_loss 15.53 | ppl 47309 | wps 48528.7 | wpb 510.9 | bsz 1 | num_updates 14788 | best_loss 8.204
2022-03-05 23:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14788 updates
2022-03-05 23:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:57:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:57:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 304 @ 14788 updates, score 15.652) (writing took 1.714309639064595 seconds)
2022-03-05 23:57:09 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-05 23:57:09 | INFO | train | epoch 304 | loss 0.55 | nll_loss 0.224 | ppl 1.17 | wps 27600 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14788 | lr 0.000260043 | gnorm 0.493 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34513
2022-03-05 23:57:09 | INFO | fairseq.trainer | begin training epoch 305
2022-03-05 23:57:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:57:35 | INFO | train_inner | epoch 305:     12 / 49 loss=0.551, nll_loss=0.225, ppl=1.17, wps=27939.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.496, loss_scale=32, train_wall=197, gb_free=21.6, wall=34539
2022-03-05 23:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:59:00 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 15.632 | nll_loss 15.51 | ppl 46665.7 | wps 48496.7 | wpb 510.9 | bsz 1 | num_updates 14837 | best_loss 8.204
2022-03-05 23:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14837 updates
2022-03-05 23:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:59:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-05 23:59:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 305 @ 14837 updates, score 15.632) (writing took 1.7533456201199442 seconds)
2022-03-05 23:59:02 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-05 23:59:02 | INFO | train | epoch 305 | loss 0.549 | nll_loss 0.223 | ppl 1.17 | wps 28182 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14837 | lr 0.000259613 | gnorm 0.495 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34626
2022-03-05 23:59:02 | INFO | fairseq.trainer | begin training epoch 306
2022-03-05 23:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:00:53 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 15.665 | nll_loss 15.543 | ppl 47729.8 | wps 48463.5 | wpb 510.9 | bsz 1 | num_updates 14886 | best_loss 8.204
2022-03-06 00:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14886 updates
2022-03-06 00:00:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:00:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 306 @ 14886 updates, score 15.665) (writing took 1.7967726830393076 seconds)
2022-03-06 00:00:55 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:00:55 | INFO | train | epoch 306 | loss 0.548 | nll_loss 0.222 | ppl 1.17 | wps 28156.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14886 | lr 0.000259186 | gnorm 0.496 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34739
2022-03-06 00:00:55 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:00:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:01:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:01:28 | INFO | train_inner | epoch 307:     15 / 49 loss=0.549, nll_loss=0.223, ppl=1.17, wps=27933.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.499, loss_scale=32, train_wall=197, gb_free=21.6, wall=34772
2022-03-06 00:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:02:46 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 15.567 | nll_loss 15.445 | ppl 44606.1 | wps 48417.5 | wpb 510.9 | bsz 1 | num_updates 14934 | best_loss 8.204
2022-03-06 00:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14934 updates
2022-03-06 00:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 307 @ 14934 updates, score 15.567) (writing took 1.7207832941785455 seconds)
2022-03-06 00:02:47 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:02:47 | INFO | train | epoch 307 | loss 0.547 | nll_loss 0.221 | ppl 1.17 | wps 27580.3 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 14934 | lr 0.000258769 | gnorm 0.496 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34851
2022-03-06 00:02:47 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:04:38 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 15.613 | nll_loss 15.489 | ppl 46003 | wps 48463.1 | wpb 510.9 | bsz 1 | num_updates 14983 | best_loss 8.204
2022-03-06 00:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14983 updates
2022-03-06 00:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 308 @ 14983 updates, score 15.613) (writing took 1.7445781379938126 seconds)
2022-03-06 00:04:40 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:04:40 | INFO | train | epoch 308 | loss 0.545 | nll_loss 0.22 | ppl 1.16 | wps 28185.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14983 | lr 0.000258345 | gnorm 0.491 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 34964
2022-03-06 00:04:40 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:18 | INFO | train_inner | epoch 309:     17 / 49 loss=0.545, nll_loss=0.22, ppl=1.16, wps=28196.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.49, loss_scale=32, train_wall=195, gb_free=21.6, wall=35002
2022-03-06 00:06:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:06:31 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 15.617 | nll_loss 15.495 | ppl 46174.1 | wps 48635.9 | wpb 510.9 | bsz 1 | num_updates 15031 | best_loss 8.204
2022-03-06 00:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15031 updates
2022-03-06 00:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:06:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:06:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 309 @ 15031 updates, score 15.617) (writing took 1.7883326790761203 seconds)
2022-03-06 00:06:33 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:06:33 | INFO | train | epoch 309 | loss 0.545 | nll_loss 0.219 | ppl 1.16 | wps 27565.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 15031 | lr 0.000257932 | gnorm 0.491 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35077
2022-03-06 00:06:33 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:06:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:08:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:08:24 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 15.596 | nll_loss 15.474 | ppl 45498.1 | wps 48563.9 | wpb 510.9 | bsz 1 | num_updates 15080 | best_loss 8.204
2022-03-06 00:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15080 updates
2022-03-06 00:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:08:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 310 @ 15080 updates, score 15.596) (writing took 1.7265930231660604 seconds)
2022-03-06 00:08:26 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:08:26 | INFO | train | epoch 310 | loss 0.543 | nll_loss 0.218 | ppl 1.16 | wps 28164.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15080 | lr 0.000257513 | gnorm 0.481 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35190
2022-03-06 00:08:26 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:10 | INFO | train_inner | epoch 311:     20 / 49 loss=0.544, nll_loss=0.219, ppl=1.16, wps=27926.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.487, loss_scale=32, train_wall=197, gb_free=21.6, wall=35234
2022-03-06 00:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:10:17 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 15.566 | nll_loss 15.445 | ppl 44599.2 | wps 48489.8 | wpb 510.9 | bsz 1 | num_updates 15129 | best_loss 8.204
2022-03-06 00:10:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15129 updates
2022-03-06 00:10:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 311 @ 15129 updates, score 15.566) (writing took 1.7197305208537728 seconds)
2022-03-06 00:10:19 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:10:19 | INFO | train | epoch 311 | loss 0.543 | nll_loss 0.218 | ppl 1.16 | wps 28153.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15129 | lr 0.000257096 | gnorm 0.492 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35303
2022-03-06 00:10:19 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:10:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:11:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:12:10 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 15.621 | nll_loss 15.5 | ppl 46351.7 | wps 48508.5 | wpb 510.9 | bsz 1 | num_updates 15177 | best_loss 8.204
2022-03-06 00:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15177 updates
2022-03-06 00:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 312 @ 15177 updates, score 15.621) (writing took 1.8818296710960567 seconds)
2022-03-06 00:12:12 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:12:12 | INFO | train | epoch 312 | loss 0.542 | nll_loss 0.217 | ppl 1.16 | wps 27513.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15177 | lr 0.000256689 | gnorm 0.481 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35416
2022-03-06 00:12:12 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:12:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:13:03 | INFO | train_inner | epoch 313:     23 / 49 loss=0.542, nll_loss=0.217, ppl=1.16, wps=27874.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.482, loss_scale=32, train_wall=197, gb_free=21.6, wall=35467
2022-03-06 00:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:14:03 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 15.466 | nll_loss 15.344 | ppl 41588.1 | wps 48498.3 | wpb 510.9 | bsz 1 | num_updates 15226 | best_loss 8.204
2022-03-06 00:14:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15226 updates
2022-03-06 00:14:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:14:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 313 @ 15226 updates, score 15.466) (writing took 1.771892478922382 seconds)
2022-03-06 00:14:05 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:14:05 | INFO | train | epoch 313 | loss 0.541 | nll_loss 0.216 | ppl 1.16 | wps 28085.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15226 | lr 0.000256275 | gnorm 0.476 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35529
2022-03-06 00:14:05 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:15:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:15:56 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 15.617 | nll_loss 15.495 | ppl 46174.6 | wps 48480.2 | wpb 510.9 | bsz 1 | num_updates 15275 | best_loss 8.204
2022-03-06 00:15:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15275 updates
2022-03-06 00:15:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 314 @ 15275 updates, score 15.617) (writing took 1.7995852760504931 seconds)
2022-03-06 00:15:58 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:15:58 | INFO | train | epoch 314 | loss 0.541 | nll_loss 0.217 | ppl 1.16 | wps 28117.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15275 | lr 0.000255864 | gnorm 0.482 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35642
2022-03-06 00:15:58 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:16:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:16:55 | INFO | train_inner | epoch 315:     26 / 49 loss=0.541, nll_loss=0.216, ppl=1.16, wps=27889.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.48, loss_scale=32, train_wall=197, gb_free=21.6, wall=35699
2022-03-06 00:17:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:17:49 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 15.586 | nll_loss 15.464 | ppl 45213.9 | wps 48631.6 | wpb 510.9 | bsz 1 | num_updates 15323 | best_loss 8.204
2022-03-06 00:17:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15323 updates
2022-03-06 00:17:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:17:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 315 @ 15323 updates, score 15.586) (writing took 1.6868216451257467 seconds)
2022-03-06 00:17:51 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:17:51 | INFO | train | epoch 315 | loss 0.54 | nll_loss 0.215 | ppl 1.16 | wps 27605.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 15323 | lr 0.000255463 | gnorm 0.477 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35755
2022-03-06 00:17:51 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:19:42 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 15.527 | nll_loss 15.405 | ppl 43382.8 | wps 48349 | wpb 510.9 | bsz 1 | num_updates 15372 | best_loss 8.204
2022-03-06 00:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15372 updates
2022-03-06 00:19:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:19:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:19:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 316 @ 15372 updates, score 15.527) (writing took 1.853506488027051 seconds)
2022-03-06 00:19:44 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:19:44 | INFO | train | epoch 316 | loss 0.539 | nll_loss 0.215 | ppl 1.16 | wps 28118.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15372 | lr 0.000255056 | gnorm 0.482 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 35868
2022-03-06 00:19:44 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:20:45 | INFO | train_inner | epoch 317:     28 / 49 loss=0.539, nll_loss=0.215, ppl=1.16, wps=28181.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.478, loss_scale=32, train_wall=195, gb_free=21.6, wall=35929
2022-03-06 00:21:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:21:35 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 15.643 | nll_loss 15.522 | ppl 47051.4 | wps 47923 | wpb 510.9 | bsz 1 | num_updates 15421 | best_loss 8.204
2022-03-06 00:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15421 updates
2022-03-06 00:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:21:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 317 @ 15421 updates, score 15.643) (writing took 1.7227998389862478 seconds)
2022-03-06 00:21:37 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:21:37 | INFO | train | epoch 317 | loss 0.539 | nll_loss 0.215 | ppl 1.16 | wps 28160.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15421 | lr 0.00025465 | gnorm 0.477 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 35981
2022-03-06 00:21:37 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:21:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:23:28 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 15.513 | nll_loss 15.391 | ppl 42966.7 | wps 48585.6 | wpb 510.9 | bsz 1 | num_updates 15469 | best_loss 8.204
2022-03-06 00:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15469 updates
2022-03-06 00:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:23:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 318 @ 15469 updates, score 15.513) (writing took 1.923954631201923 seconds)
2022-03-06 00:23:30 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:23:30 | INFO | train | epoch 318 | loss 0.538 | nll_loss 0.214 | ppl 1.16 | wps 27532.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15469 | lr 0.000254255 | gnorm 0.484 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36094
2022-03-06 00:23:30 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:24:38 | INFO | train_inner | epoch 319:     31 / 49 loss=0.538, nll_loss=0.214, ppl=1.16, wps=27895.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.48, loss_scale=32, train_wall=197, gb_free=21.6, wall=36162
2022-03-06 00:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:25:21 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 15.535 | nll_loss 15.415 | ppl 43675.9 | wps 48265.1 | wpb 510.9 | bsz 1 | num_updates 15518 | best_loss 8.204
2022-03-06 00:25:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15518 updates
2022-03-06 00:25:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:25:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 319 @ 15518 updates, score 15.535) (writing took 1.8729710360057652 seconds)
2022-03-06 00:25:23 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:25:23 | INFO | train | epoch 319 | loss 0.537 | nll_loss 0.213 | ppl 1.16 | wps 28110 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15518 | lr 0.000253853 | gnorm 0.475 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36207
2022-03-06 00:25:23 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:26:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:27:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:27:14 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 15.535 | nll_loss 15.414 | ppl 43650.2 | wps 48571 | wpb 510.9 | bsz 1 | num_updates 15566 | best_loss 8.204
2022-03-06 00:27:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15566 updates
2022-03-06 00:27:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:27:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 320 @ 15566 updates, score 15.535) (writing took 1.887295083142817 seconds)
2022-03-06 00:27:16 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:27:16 | INFO | train | epoch 320 | loss 0.535 | nll_loss 0.211 | ppl 1.16 | wps 27544.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15566 | lr 0.000253461 | gnorm 0.473 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36320
2022-03-06 00:27:16 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:28:30 | INFO | train_inner | epoch 321:     34 / 49 loss=0.535, nll_loss=0.211, ppl=1.16, wps=27902.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.472, loss_scale=32, train_wall=197, gb_free=21.6, wall=36395
2022-03-06 00:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:29:07 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 15.572 | nll_loss 15.45 | ppl 44775.8 | wps 48340.3 | wpb 510.9 | bsz 1 | num_updates 15615 | best_loss 8.204
2022-03-06 00:29:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15615 updates
2022-03-06 00:29:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:29:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 321 @ 15615 updates, score 15.572) (writing took 1.9402137999422848 seconds)
2022-03-06 00:29:09 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:29:09 | INFO | train | epoch 321 | loss 0.535 | nll_loss 0.211 | ppl 1.16 | wps 28136.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15615 | lr 0.000253063 | gnorm 0.471 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36433
2022-03-06 00:29:09 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:30:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:31:00 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 15.603 | nll_loss 15.484 | ppl 45843.9 | wps 48561.3 | wpb 510.9 | bsz 1 | num_updates 15664 | best_loss 8.204
2022-03-06 00:31:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15664 updates
2022-03-06 00:31:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 322 @ 15664 updates, score 15.603) (writing took 1.9357831818051636 seconds)
2022-03-06 00:31:02 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:31:02 | INFO | train | epoch 322 | loss 0.534 | nll_loss 0.21 | ppl 1.16 | wps 28125 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15664 | lr 0.000252667 | gnorm 0.471 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36546
2022-03-06 00:31:02 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:31:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:32:23 | INFO | train_inner | epoch 323:     37 / 49 loss=0.534, nll_loss=0.211, ppl=1.16, wps=27895.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.472, loss_scale=32, train_wall=197, gb_free=21.6, wall=36627
2022-03-06 00:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:32:53 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 15.554 | nll_loss 15.434 | ppl 44269.6 | wps 48457.5 | wpb 510.9 | bsz 1 | num_updates 15712 | best_loss 8.204
2022-03-06 00:32:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15712 updates
2022-03-06 00:32:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:32:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:32:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 323 @ 15712 updates, score 15.554) (writing took 1.9930538299959153 seconds)
2022-03-06 00:32:55 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:32:55 | INFO | train | epoch 323 | loss 0.534 | nll_loss 0.211 | ppl 1.16 | wps 27535.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15712 | lr 0.000252281 | gnorm 0.474 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36659
2022-03-06 00:32:55 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:32:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:46 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 15.585 | nll_loss 15.467 | ppl 45287 | wps 48406 | wpb 510.9 | bsz 1 | num_updates 15761 | best_loss 8.204
2022-03-06 00:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15761 updates
2022-03-06 00:34:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:34:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 324 @ 15761 updates, score 15.585) (writing took 1.9421518337912858 seconds)
2022-03-06 00:34:48 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:34:48 | INFO | train | epoch 324 | loss 0.532 | nll_loss 0.209 | ppl 1.16 | wps 28144.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15761 | lr 0.000251888 | gnorm 0.468 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36772
2022-03-06 00:34:48 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:36:13 | INFO | train_inner | epoch 325:     39 / 49 loss=0.533, nll_loss=0.209, ppl=1.16, wps=28161.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.472, loss_scale=32, train_wall=195, gb_free=21.6, wall=36857
2022-03-06 00:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:36:39 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 15.616 | nll_loss 15.497 | ppl 46229.4 | wps 48485.1 | wpb 510.9 | bsz 1 | num_updates 15810 | best_loss 8.204
2022-03-06 00:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15810 updates
2022-03-06 00:36:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 325 @ 15810 updates, score 15.616) (writing took 2.006584544898942 seconds)
2022-03-06 00:36:41 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:36:41 | INFO | train | epoch 325 | loss 0.533 | nll_loss 0.209 | ppl 1.16 | wps 28105.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15810 | lr 0.000251498 | gnorm 0.474 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 36885
2022-03-06 00:36:41 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:36:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:38:32 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 15.55 | nll_loss 15.431 | ppl 44179.1 | wps 48360.3 | wpb 510.9 | bsz 1 | num_updates 15858 | best_loss 8.204
2022-03-06 00:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15858 updates
2022-03-06 00:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 326 @ 15858 updates, score 15.55) (writing took 1.9937611939385533 seconds)
2022-03-06 00:38:34 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:38:34 | INFO | train | epoch 326 | loss 0.531 | nll_loss 0.208 | ppl 1.15 | wps 27526.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15858 | lr 0.000251117 | gnorm 0.468 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 36998
2022-03-06 00:38:34 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:40:06 | INFO | train_inner | epoch 327:     42 / 49 loss=0.531, nll_loss=0.208, ppl=1.15, wps=27879.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.469, loss_scale=32, train_wall=197, gb_free=21.6, wall=37090
2022-03-06 00:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:40:25 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 15.668 | nll_loss 15.55 | ppl 47959.5 | wps 48489.8 | wpb 510.9 | bsz 1 | num_updates 15907 | best_loss 8.204
2022-03-06 00:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15907 updates
2022-03-06 00:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:40:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 327 @ 15907 updates, score 15.668) (writing took 1.930703089106828 seconds)
2022-03-06 00:40:27 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:40:27 | INFO | train | epoch 327 | loss 0.53 | nll_loss 0.207 | ppl 1.15 | wps 28130 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15907 | lr 0.00025073 | gnorm 0.468 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37111
2022-03-06 00:40:27 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:42:18 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 15.557 | nll_loss 15.437 | ppl 44374.2 | wps 48435.1 | wpb 510.9 | bsz 1 | num_updates 15956 | best_loss 8.204
2022-03-06 00:42:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15956 updates
2022-03-06 00:42:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:42:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 328 @ 15956 updates, score 15.557) (writing took 1.9688303761649877 seconds)
2022-03-06 00:42:20 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:42:20 | INFO | train | epoch 328 | loss 0.529 | nll_loss 0.206 | ppl 1.15 | wps 28102.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15956 | lr 0.000250344 | gnorm 0.465 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 37224
2022-03-06 00:42:20 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:43:59 | INFO | train_inner | epoch 329:     45 / 49 loss=0.529, nll_loss=0.206, ppl=1.15, wps=27885.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.464, loss_scale=32, train_wall=197, gb_free=21.6, wall=37323
2022-03-06 00:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:44:11 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 15.572 | nll_loss 15.451 | ppl 44798.8 | wps 48515 | wpb 510.9 | bsz 1 | num_updates 16004 | best_loss 8.204
2022-03-06 00:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16004 updates
2022-03-06 00:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 329 @ 16004 updates, score 15.572) (writing took 1.9490572400391102 seconds)
2022-03-06 00:44:13 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:44:13 | INFO | train | epoch 329 | loss 0.528 | nll_loss 0.205 | ppl 1.15 | wps 27550.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16004 | lr 0.000249969 | gnorm 0.463 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37337
2022-03-06 00:44:13 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:46:04 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 15.564 | nll_loss 15.444 | ppl 44566.4 | wps 48434.7 | wpb 510.9 | bsz 1 | num_updates 16053 | best_loss 8.204
2022-03-06 00:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16053 updates
2022-03-06 00:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 330 @ 16053 updates, score 15.564) (writing took 1.9232575150672346 seconds)
2022-03-06 00:46:06 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:46:06 | INFO | train | epoch 330 | loss 0.528 | nll_loss 0.205 | ppl 1.15 | wps 28135 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16053 | lr 0.000249587 | gnorm 0.464 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37450
2022-03-06 00:46:06 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:47:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:47:51 | INFO | train_inner | epoch 331:     48 / 49 loss=0.528, nll_loss=0.205, ppl=1.15, wps=27896.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.466, loss_scale=32, train_wall=197, gb_free=21.6, wall=37555
2022-03-06 00:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:47:57 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 15.648 | nll_loss 15.53 | ppl 47315.3 | wps 48472.4 | wpb 510.9 | bsz 1 | num_updates 16101 | best_loss 8.204
2022-03-06 00:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16101 updates
2022-03-06 00:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 331 @ 16101 updates, score 15.648) (writing took 1.9424380280543119 seconds)
2022-03-06 00:47:59 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:47:59 | INFO | train | epoch 331 | loss 0.528 | nll_loss 0.205 | ppl 1.15 | wps 27541.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16101 | lr 0.000249215 | gnorm 0.468 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37563
2022-03-06 00:47:59 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:49:50 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 15.539 | nll_loss 15.421 | ppl 43869 | wps 48448.2 | wpb 510.9 | bsz 1 | num_updates 16150 | best_loss 8.204
2022-03-06 00:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16150 updates
2022-03-06 00:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 332 @ 16150 updates, score 15.539) (writing took 1.8983681357931346 seconds)
2022-03-06 00:49:52 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 00:49:52 | INFO | train | epoch 332 | loss 0.526 | nll_loss 0.204 | ppl 1.15 | wps 28129 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16150 | lr 0.000248836 | gnorm 0.463 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37676
2022-03-06 00:49:52 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 00:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:51:43 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 15.597 | nll_loss 15.479 | ppl 45662.2 | wps 48352.8 | wpb 510.9 | bsz 1 | num_updates 16199 | best_loss 8.204
2022-03-06 00:51:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16199 updates
2022-03-06 00:51:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:51:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 333 @ 16199 updates, score 15.597) (writing took 1.8648536179680377 seconds)
2022-03-06 00:51:45 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 00:51:45 | INFO | train | epoch 333 | loss 0.525 | nll_loss 0.203 | ppl 1.15 | wps 28138 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16199 | lr 0.00024846 | gnorm 0.459 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37789
2022-03-06 00:51:45 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 00:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:51:47 | INFO | train_inner | epoch 334:      1 / 49 loss=0.526, nll_loss=0.203, ppl=1.15, wps=27361.6, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=16200, lr=0.000248452, gnorm=0.463, loss_scale=32, train_wall=194, gb_free=21.6, wall=37791
2022-03-06 00:52:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:53:36 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 15.601 | nll_loss 15.483 | ppl 45807.6 | wps 48497.3 | wpb 510.9 | bsz 1 | num_updates 16247 | best_loss 8.204
2022-03-06 00:53:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16247 updates
2022-03-06 00:53:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:53:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:53:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 334 @ 16247 updates, score 15.601) (writing took 1.9168417791370302 seconds)
2022-03-06 00:53:38 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 00:53:38 | INFO | train | epoch 334 | loss 0.524 | nll_loss 0.202 | ppl 1.15 | wps 27546.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16247 | lr 0.000248092 | gnorm 0.454 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 37902
2022-03-06 00:53:38 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 00:53:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:55:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:55:29 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 15.554 | nll_loss 15.436 | ppl 44324.6 | wps 48372.4 | wpb 510.9 | bsz 1 | num_updates 16296 | best_loss 8.204
2022-03-06 00:55:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16296 updates
2022-03-06 00:55:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 335 @ 16296 updates, score 15.554) (writing took 1.8281059151049703 seconds)
2022-03-06 00:55:31 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 00:55:31 | INFO | train | epoch 335 | loss 0.525 | nll_loss 0.202 | ppl 1.15 | wps 28129 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16296 | lr 0.000247719 | gnorm 0.459 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38015
2022-03-06 00:55:31 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 00:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:55:40 | INFO | train_inner | epoch 336:      4 / 49 loss=0.524, nll_loss=0.202, ppl=1.15, wps=27898.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.457, loss_scale=32, train_wall=197, gb_free=21.6, wall=38024
2022-03-06 00:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:57:22 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 15.557 | nll_loss 15.439 | ppl 44425.5 | wps 48539.5 | wpb 510.9 | bsz 1 | num_updates 16345 | best_loss 8.204
2022-03-06 00:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16345 updates
2022-03-06 00:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 336 @ 16345 updates, score 15.557) (writing took 1.833737756125629 seconds)
2022-03-06 00:57:24 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 00:57:24 | INFO | train | epoch 336 | loss 0.523 | nll_loss 0.201 | ppl 1.15 | wps 28169.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16345 | lr 0.000247348 | gnorm 0.458 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38128
2022-03-06 00:57:24 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 00:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:57:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:59:15 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 15.56 | nll_loss 15.441 | ppl 44490.6 | wps 48586.6 | wpb 510.9 | bsz 1 | num_updates 16393 | best_loss 8.204
2022-03-06 00:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16393 updates
2022-03-06 00:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 00:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 337 @ 16393 updates, score 15.56) (writing took 1.8547640319447964 seconds)
2022-03-06 00:59:17 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 00:59:17 | INFO | train | epoch 337 | loss 0.522 | nll_loss 0.2 | ppl 1.15 | wps 27554.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16393 | lr 0.000246985 | gnorm 0.453 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38241
2022-03-06 00:59:17 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 00:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:59:32 | INFO | train_inner | epoch 338:      7 / 49 loss=0.522, nll_loss=0.2, ppl=1.15, wps=27919.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.455, loss_scale=32, train_wall=197, gb_free=21.6, wall=38256
2022-03-06 01:01:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:01:08 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 15.599 | nll_loss 15.482 | ppl 45762.1 | wps 48421.1 | wpb 510.9 | bsz 1 | num_updates 16442 | best_loss 8.204
2022-03-06 01:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16442 updates
2022-03-06 01:01:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 338 @ 16442 updates, score 15.599) (writing took 1.82977169402875 seconds)
2022-03-06 01:01:09 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:01:09 | INFO | train | epoch 338 | loss 0.521 | nll_loss 0.199 | ppl 1.15 | wps 28157.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16442 | lr 0.000246617 | gnorm 0.453 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38354
2022-03-06 01:01:09 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:02:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:03:00 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 15.67 | nll_loss 15.553 | ppl 48090.4 | wps 48349.5 | wpb 510.9 | bsz 1 | num_updates 16490 | best_loss 8.204
2022-03-06 01:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16490 updates
2022-03-06 01:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:03:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 339 @ 16490 updates, score 15.67) (writing took 1.8440778509248048 seconds)
2022-03-06 01:03:02 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:03:02 | INFO | train | epoch 339 | loss 0.521 | nll_loss 0.199 | ppl 1.15 | wps 27571.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 16490 | lr 0.000246258 | gnorm 0.457 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38466
2022-03-06 01:03:02 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:03:24 | INFO | train_inner | epoch 340:     10 / 49 loss=0.521, nll_loss=0.199, ppl=1.15, wps=27921, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.456, loss_scale=32, train_wall=197, gb_free=21.6, wall=38488
2022-03-06 01:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:53 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 15.577 | nll_loss 15.46 | ppl 45072.2 | wps 48448.4 | wpb 510.9 | bsz 1 | num_updates 16539 | best_loss 8.204
2022-03-06 01:04:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16539 updates
2022-03-06 01:04:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:04:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 340 @ 16539 updates, score 15.577) (writing took 1.886505682952702 seconds)
2022-03-06 01:04:55 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:04:55 | INFO | train | epoch 340 | loss 0.521 | nll_loss 0.199 | ppl 1.15 | wps 28132.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16539 | lr 0.000245893 | gnorm 0.459 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38579
2022-03-06 01:04:55 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:06:46 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 15.627 | nll_loss 15.509 | ppl 46641.6 | wps 48376.5 | wpb 510.9 | bsz 1 | num_updates 16588 | best_loss 8.204
2022-03-06 01:06:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16588 updates
2022-03-06 01:06:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:06:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:06:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 341 @ 16588 updates, score 15.627) (writing took 1.820278514875099 seconds)
2022-03-06 01:06:48 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:06:48 | INFO | train | epoch 341 | loss 0.519 | nll_loss 0.198 | ppl 1.15 | wps 28161.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16588 | lr 0.000245529 | gnorm 0.452 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38692
2022-03-06 01:06:48 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:06:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:07:15 | INFO | train_inner | epoch 342:     12 / 49 loss=0.52, nll_loss=0.198, ppl=1.15, wps=28182.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.455, loss_scale=32, train_wall=195, gb_free=21.6, wall=38719
2022-03-06 01:07:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:08:39 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 15.631 | nll_loss 15.516 | ppl 46847.8 | wps 48494 | wpb 510.9 | bsz 1 | num_updates 16636 | best_loss 8.204
2022-03-06 01:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16636 updates
2022-03-06 01:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:08:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 342 @ 16636 updates, score 15.631) (writing took 1.8475693659856915 seconds)
2022-03-06 01:08:41 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:08:41 | INFO | train | epoch 342 | loss 0.519 | nll_loss 0.198 | ppl 1.15 | wps 27585.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 16636 | lr 0.000245175 | gnorm 0.457 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 38805
2022-03-06 01:08:41 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:10:32 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 15.566 | nll_loss 15.45 | ppl 44750 | wps 48448.8 | wpb 510.9 | bsz 1 | num_updates 16685 | best_loss 8.204
2022-03-06 01:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16685 updates
2022-03-06 01:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 343 @ 16685 updates, score 15.566) (writing took 1.8628327520564198 seconds)
2022-03-06 01:10:34 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:10:34 | INFO | train | epoch 343 | loss 0.519 | nll_loss 0.198 | ppl 1.15 | wps 28139.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16685 | lr 0.000244814 | gnorm 0.453 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 38918
2022-03-06 01:10:34 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:10:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:11:07 | INFO | train_inner | epoch 344:     15 / 49 loss=0.519, nll_loss=0.198, ppl=1.15, wps=27920.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.455, loss_scale=32, train_wall=197, gb_free=21.6, wall=38951
2022-03-06 01:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:12:25 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 15.489 | nll_loss 15.371 | ppl 42375.3 | wps 48563.9 | wpb 510.9 | bsz 1 | num_updates 16734 | best_loss 8.204
2022-03-06 01:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16734 updates
2022-03-06 01:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 344 @ 16734 updates, score 15.489) (writing took 1.836052763974294 seconds)
2022-03-06 01:12:27 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:12:27 | INFO | train | epoch 344 | loss 0.518 | nll_loss 0.196 | ppl 1.15 | wps 28153.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16734 | lr 0.000244456 | gnorm 0.452 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 39031
2022-03-06 01:12:27 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:14:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:14:18 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 15.564 | nll_loss 15.446 | ppl 44648.3 | wps 48381.6 | wpb 510.9 | bsz 1 | num_updates 16782 | best_loss 8.204
2022-03-06 01:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16782 updates
2022-03-06 01:14:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:14:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:14:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 345 @ 16782 updates, score 15.564) (writing took 1.8331096910405904 seconds)
2022-03-06 01:14:20 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:14:20 | INFO | train | epoch 345 | loss 0.517 | nll_loss 0.196 | ppl 1.15 | wps 27576 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 16782 | lr 0.000244106 | gnorm 0.454 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39144
2022-03-06 01:14:20 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:14:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:14:59 | INFO | train_inner | epoch 346:     18 / 49 loss=0.516, nll_loss=0.195, ppl=1.15, wps=27913.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.451, loss_scale=32, train_wall=197, gb_free=21.6, wall=39183
2022-03-06 01:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:16:11 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 15.525 | nll_loss 15.409 | ppl 43500.5 | wps 48448.6 | wpb 510.9 | bsz 1 | num_updates 16831 | best_loss 8.204
2022-03-06 01:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16831 updates
2022-03-06 01:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 346 @ 16831 updates, score 15.525) (writing took 1.8705275929532945 seconds)
2022-03-06 01:16:13 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:16:13 | INFO | train | epoch 346 | loss 0.516 | nll_loss 0.195 | ppl 1.14 | wps 28123.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16831 | lr 0.00024375 | gnorm 0.452 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39257
2022-03-06 01:16:13 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:18:04 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 15.705 | nll_loss 15.59 | ppl 49315.9 | wps 48306.1 | wpb 510.9 | bsz 1 | num_updates 16880 | best_loss 8.204
2022-03-06 01:18:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16880 updates
2022-03-06 01:18:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:18:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:18:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 347 @ 16880 updates, score 15.705) (writing took 1.825480748899281 seconds)
2022-03-06 01:18:06 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:18:06 | INFO | train | epoch 347 | loss 0.515 | nll_loss 0.194 | ppl 1.14 | wps 28148.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16880 | lr 0.000243396 | gnorm 0.447 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 39370
2022-03-06 01:18:06 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:18:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:18:52 | INFO | train_inner | epoch 348:     21 / 49 loss=0.515, nll_loss=0.194, ppl=1.14, wps=27915.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.449, loss_scale=32, train_wall=197, gb_free=21.6, wall=39416
2022-03-06 01:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:19:57 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 15.527 | nll_loss 15.41 | ppl 43544.6 | wps 48374.4 | wpb 510.9 | bsz 1 | num_updates 16928 | best_loss 8.204
2022-03-06 01:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16928 updates
2022-03-06 01:19:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 348 @ 16928 updates, score 15.527) (writing took 1.8101408940274268 seconds)
2022-03-06 01:19:58 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:19:58 | INFO | train | epoch 348 | loss 0.515 | nll_loss 0.194 | ppl 1.14 | wps 27591.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 16928 | lr 0.000243051 | gnorm 0.447 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39482
2022-03-06 01:19:58 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:21:50 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 15.524 | nll_loss 15.406 | ppl 43410.7 | wps 48401.2 | wpb 510.9 | bsz 1 | num_updates 16977 | best_loss 8.204
2022-03-06 01:21:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16977 updates
2022-03-06 01:21:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:21:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 349 @ 16977 updates, score 15.524) (writing took 1.8388322701212019 seconds)
2022-03-06 01:21:51 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:21:51 | INFO | train | epoch 349 | loss 0.514 | nll_loss 0.194 | ppl 1.14 | wps 28112 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16977 | lr 0.0002427 | gnorm 0.449 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39596
2022-03-06 01:21:51 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:22:42 | INFO | train_inner | epoch 350:     23 / 49 loss=0.514, nll_loss=0.194, ppl=1.14, wps=28170.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.448, loss_scale=32, train_wall=195, gb_free=21.6, wall=39646
2022-03-06 01:23:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:42 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 15.483 | nll_loss 15.366 | ppl 42218.6 | wps 48488.2 | wpb 510.9 | bsz 1 | num_updates 17025 | best_loss 8.204
2022-03-06 01:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17025 updates
2022-03-06 01:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 350 @ 17025 updates, score 15.483) (writing took 1.7998267519287765 seconds)
2022-03-06 01:23:44 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:23:44 | INFO | train | epoch 350 | loss 0.514 | nll_loss 0.194 | ppl 1.14 | wps 27577.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17025 | lr 0.000242357 | gnorm 0.448 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39708
2022-03-06 01:23:44 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:25:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:25:36 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 15.497 | nll_loss 15.382 | ppl 42703.8 | wps 48438.9 | wpb 510.9 | bsz 1 | num_updates 17074 | best_loss 8.204
2022-03-06 01:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17074 updates
2022-03-06 01:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:25:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 351 @ 17074 updates, score 15.497) (writing took 1.7796131300274283 seconds)
2022-03-06 01:25:37 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:25:37 | INFO | train | epoch 351 | loss 0.513 | nll_loss 0.192 | ppl 1.14 | wps 28113.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17074 | lr 0.000242009 | gnorm 0.445 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39821
2022-03-06 01:25:37 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:26:34 | INFO | train_inner | epoch 352:     26 / 49 loss=0.513, nll_loss=0.192, ppl=1.14, wps=27906.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.446, loss_scale=32, train_wall=197, gb_free=21.6, wall=39879
2022-03-06 01:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:27:28 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 15.575 | nll_loss 15.46 | ppl 45059.1 | wps 48329.4 | wpb 510.9 | bsz 1 | num_updates 17123 | best_loss 8.204
2022-03-06 01:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17123 updates
2022-03-06 01:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 352 @ 17123 updates, score 15.575) (writing took 1.8308031968772411 seconds)
2022-03-06 01:27:30 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:27:30 | INFO | train | epoch 352 | loss 0.512 | nll_loss 0.192 | ppl 1.14 | wps 28160.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17123 | lr 0.000241663 | gnorm 0.449 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 39934
2022-03-06 01:27:30 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:29:21 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 15.595 | nll_loss 15.481 | ppl 45722.6 | wps 48371.5 | wpb 510.9 | bsz 1 | num_updates 17171 | best_loss 8.204
2022-03-06 01:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17171 updates
2022-03-06 01:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:29:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 353 @ 17171 updates, score 15.595) (writing took 1.7890550401061773 seconds)
2022-03-06 01:29:23 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:29:23 | INFO | train | epoch 353 | loss 0.512 | nll_loss 0.192 | ppl 1.14 | wps 27574.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17171 | lr 0.000241325 | gnorm 0.447 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40047
2022-03-06 01:29:23 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:30:27 | INFO | train_inner | epoch 354:     29 / 49 loss=0.512, nll_loss=0.192, ppl=1.14, wps=27914.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.447, loss_scale=32, train_wall=197, gb_free=21.6, wall=40111
2022-03-06 01:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:31:14 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 15.554 | nll_loss 15.439 | ppl 44430.9 | wps 48318.8 | wpb 510.9 | bsz 1 | num_updates 17220 | best_loss 8.204
2022-03-06 01:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17220 updates
2022-03-06 01:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:31:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:31:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 354 @ 17220 updates, score 15.554) (writing took 1.8317866390570998 seconds)
2022-03-06 01:31:16 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:31:16 | INFO | train | epoch 354 | loss 0.51 | nll_loss 0.19 | ppl 1.14 | wps 28141.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17220 | lr 0.000240981 | gnorm 0.444 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40160
2022-03-06 01:31:16 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:31:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:33:07 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 15.608 | nll_loss 15.494 | ppl 46139.9 | wps 48470.3 | wpb 510.9 | bsz 1 | num_updates 17269 | best_loss 8.204
2022-03-06 01:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17269 updates
2022-03-06 01:33:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:33:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 355 @ 17269 updates, score 15.608) (writing took 1.8442302469629794 seconds)
2022-03-06 01:33:09 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:33:09 | INFO | train | epoch 355 | loss 0.51 | nll_loss 0.19 | ppl 1.14 | wps 28133.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17269 | lr 0.000240639 | gnorm 0.443 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40273
2022-03-06 01:33:09 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:33:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:34:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:34:19 | INFO | train_inner | epoch 356:     32 / 49 loss=0.51, nll_loss=0.19, ppl=1.14, wps=27911.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.44, loss_scale=32, train_wall=197, gb_free=21.6, wall=40343
2022-03-06 01:34:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:35:00 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 15.515 | nll_loss 15.399 | ppl 43200.8 | wps 48454.7 | wpb 510.9 | bsz 1 | num_updates 17317 | best_loss 8.204
2022-03-06 01:35:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17317 updates
2022-03-06 01:35:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:35:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:35:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 356 @ 17317 updates, score 15.515) (writing took 1.772750415140763 seconds)
2022-03-06 01:35:02 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:35:02 | INFO | train | epoch 356 | loss 0.509 | nll_loss 0.189 | ppl 1.14 | wps 27574.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17317 | lr 0.000240305 | gnorm 0.434 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40386
2022-03-06 01:35:02 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:36:53 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 15.601 | nll_loss 15.485 | ppl 45846.2 | wps 48443.7 | wpb 510.9 | bsz 1 | num_updates 17366 | best_loss 8.204
2022-03-06 01:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17366 updates
2022-03-06 01:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 357 @ 17366 updates, score 15.601) (writing took 1.775451443856582 seconds)
2022-03-06 01:36:55 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:36:55 | INFO | train | epoch 357 | loss 0.509 | nll_loss 0.19 | ppl 1.14 | wps 28173.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17366 | lr 0.000239966 | gnorm 0.445 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40499
2022-03-06 01:36:55 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:38:09 | INFO | train_inner | epoch 358:     34 / 49 loss=0.509, nll_loss=0.19, ppl=1.14, wps=28194.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.441, loss_scale=32, train_wall=195, gb_free=21.6, wall=40573
2022-03-06 01:38:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:38:46 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 15.565 | nll_loss 15.449 | ppl 44744.8 | wps 48495.3 | wpb 510.9 | bsz 1 | num_updates 17415 | best_loss 8.204
2022-03-06 01:38:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17415 updates
2022-03-06 01:38:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 358 @ 17415 updates, score 15.565) (writing took 1.7802711899857968 seconds)
2022-03-06 01:38:47 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:38:47 | INFO | train | epoch 358 | loss 0.509 | nll_loss 0.19 | ppl 1.14 | wps 28163.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17415 | lr 0.000239628 | gnorm 0.443 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40612
2022-03-06 01:38:47 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:40:38 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 15.479 | nll_loss 15.363 | ppl 42144.7 | wps 48507.4 | wpb 510.9 | bsz 1 | num_updates 17463 | best_loss 8.204
2022-03-06 01:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17463 updates
2022-03-06 01:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 359 @ 17463 updates, score 15.479) (writing took 1.7200877910945565 seconds)
2022-03-06 01:40:40 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:40:40 | INFO | train | epoch 359 | loss 0.508 | nll_loss 0.188 | ppl 1.14 | wps 27610.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17463 | lr 0.000239299 | gnorm 0.443 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 40724
2022-03-06 01:40:40 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:42:01 | INFO | train_inner | epoch 360:     37 / 49 loss=0.508, nll_loss=0.189, ppl=1.14, wps=27954.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.442, loss_scale=32, train_wall=197, gb_free=21.6, wall=40805
2022-03-06 01:42:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:42:31 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 15.56 | nll_loss 15.446 | ppl 44626 | wps 48336.1 | wpb 510.9 | bsz 1 | num_updates 17512 | best_loss 8.204
2022-03-06 01:42:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17512 updates
2022-03-06 01:42:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:42:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 360 @ 17512 updates, score 15.56) (writing took 1.73901537200436 seconds)
2022-03-06 01:42:33 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:42:33 | INFO | train | epoch 360 | loss 0.507 | nll_loss 0.188 | ppl 1.14 | wps 28194.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17512 | lr 0.000238964 | gnorm 0.437 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 40837
2022-03-06 01:42:33 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:44:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:44:24 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 15.55 | nll_loss 15.436 | ppl 44340.8 | wps 48502.4 | wpb 510.9 | bsz 1 | num_updates 17560 | best_loss 8.204
2022-03-06 01:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17560 updates
2022-03-06 01:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 361 @ 17560 updates, score 15.55) (writing took 1.8017196899745613 seconds)
2022-03-06 01:44:26 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:44:26 | INFO | train | epoch 361 | loss 0.506 | nll_loss 0.187 | ppl 1.14 | wps 27596.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17560 | lr 0.000238637 | gnorm 0.436 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 40950
2022-03-06 01:44:26 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:45:54 | INFO | train_inner | epoch 362:     40 / 49 loss=0.506, nll_loss=0.187, ppl=1.14, wps=27939.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.438, loss_scale=32, train_wall=197, gb_free=21.6, wall=41038
2022-03-06 01:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:46:17 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 15.487 | nll_loss 15.371 | ppl 42371.3 | wps 48357.1 | wpb 510.9 | bsz 1 | num_updates 17609 | best_loss 8.204
2022-03-06 01:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17609 updates
2022-03-06 01:46:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:46:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:46:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 362 @ 17609 updates, score 15.487) (writing took 1.7272123619914055 seconds)
2022-03-06 01:46:19 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:46:19 | INFO | train | epoch 362 | loss 0.506 | nll_loss 0.187 | ppl 1.14 | wps 28166.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17609 | lr 0.000238305 | gnorm 0.443 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41063
2022-03-06 01:46:19 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:46:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:48:10 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 15.536 | nll_loss 15.42 | ppl 43853.2 | wps 48200.5 | wpb 510.9 | bsz 1 | num_updates 17658 | best_loss 8.204
2022-03-06 01:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17658 updates
2022-03-06 01:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 363 @ 17658 updates, score 15.536) (writing took 1.7192549661267549 seconds)
2022-03-06 01:48:11 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 01:48:11 | INFO | train | epoch 363 | loss 0.505 | nll_loss 0.186 | ppl 1.14 | wps 28162.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17658 | lr 0.000237974 | gnorm 0.431 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41175
2022-03-06 01:48:11 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 01:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:49:46 | INFO | train_inner | epoch 364:     43 / 49 loss=0.505, nll_loss=0.186, ppl=1.14, wps=27929.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.434, loss_scale=32, train_wall=197, gb_free=21.6, wall=41270
2022-03-06 01:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:50:02 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 15.478 | nll_loss 15.364 | ppl 42172.7 | wps 48634.7 | wpb 510.9 | bsz 1 | num_updates 17706 | best_loss 8.204
2022-03-06 01:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17706 updates
2022-03-06 01:50:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:50:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:50:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 364 @ 17706 updates, score 15.478) (writing took 1.7660824039485306 seconds)
2022-03-06 01:50:04 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 01:50:04 | INFO | train | epoch 364 | loss 0.504 | nll_loss 0.185 | ppl 1.14 | wps 27583.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17706 | lr 0.000237651 | gnorm 0.434 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41288
2022-03-06 01:50:04 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 01:50:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:51:55 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 15.539 | nll_loss 15.425 | ppl 43978.3 | wps 48308.6 | wpb 510.9 | bsz 1 | num_updates 17755 | best_loss 8.204
2022-03-06 01:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17755 updates
2022-03-06 01:51:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:51:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:51:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 365 @ 17755 updates, score 15.539) (writing took 1.7041840590536594 seconds)
2022-03-06 01:51:57 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 01:51:57 | INFO | train | epoch 365 | loss 0.504 | nll_loss 0.185 | ppl 1.14 | wps 28180 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17755 | lr 0.000237323 | gnorm 0.437 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41401
2022-03-06 01:51:57 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 01:51:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:53:36 | INFO | train_inner | epoch 366:     45 / 49 loss=0.504, nll_loss=0.185, ppl=1.14, wps=28215.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.437, loss_scale=32, train_wall=195, gb_free=21.6, wall=41500
2022-03-06 01:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:53:48 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 15.631 | nll_loss 15.518 | ppl 46937.2 | wps 48507.6 | wpb 510.9 | bsz 1 | num_updates 17804 | best_loss 8.204
2022-03-06 01:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17804 updates
2022-03-06 01:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 366 @ 17804 updates, score 15.631) (writing took 1.721678006928414 seconds)
2022-03-06 01:53:50 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 01:53:50 | INFO | train | epoch 366 | loss 0.504 | nll_loss 0.185 | ppl 1.14 | wps 28191.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17804 | lr 0.000236996 | gnorm 0.436 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41514
2022-03-06 01:53:50 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 01:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:54:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:55:41 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 15.558 | nll_loss 15.444 | ppl 44574.7 | wps 48468.6 | wpb 510.9 | bsz 1 | num_updates 17852 | best_loss 8.204
2022-03-06 01:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17852 updates
2022-03-06 01:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 367 @ 17852 updates, score 15.558) (writing took 1.7421848569065332 seconds)
2022-03-06 01:55:42 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 01:55:42 | INFO | train | epoch 367 | loss 0.503 | nll_loss 0.184 | ppl 1.14 | wps 27606.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17852 | lr 0.000236677 | gnorm 0.434 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 41627
2022-03-06 01:55:43 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 01:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:57:28 | INFO | train_inner | epoch 368:     48 / 49 loss=0.503, nll_loss=0.184, ppl=1.14, wps=27960.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.433, loss_scale=32, train_wall=197, gb_free=21.6, wall=41732
2022-03-06 01:57:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:33 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 15.573 | nll_loss 15.459 | ppl 45049.9 | wps 48255.6 | wpb 510.9 | bsz 1 | num_updates 17901 | best_loss 8.204
2022-03-06 01:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17901 updates
2022-03-06 01:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:57:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:57:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 368 @ 17901 updates, score 15.573) (writing took 1.700854177121073 seconds)
2022-03-06 01:57:35 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 01:57:35 | INFO | train | epoch 368 | loss 0.502 | nll_loss 0.184 | ppl 1.14 | wps 28204.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17901 | lr 0.000236353 | gnorm 0.431 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41739
2022-03-06 01:57:35 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 01:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:59:26 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 15.569 | nll_loss 15.456 | ppl 44941.6 | wps 48453.2 | wpb 510.9 | bsz 1 | num_updates 17950 | best_loss 8.204
2022-03-06 01:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17950 updates
2022-03-06 01:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 01:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 369 @ 17950 updates, score 15.569) (writing took 1.7143939789384604 seconds)
2022-03-06 01:59:28 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 01:59:28 | INFO | train | epoch 369 | loss 0.502 | nll_loss 0.184 | ppl 1.14 | wps 28173.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17950 | lr 0.00023603 | gnorm 0.431 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 41852
2022-03-06 01:59:28 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 01:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:59:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:01:19 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 15.538 | nll_loss 15.425 | ppl 43989.1 | wps 48491.8 | wpb 510.9 | bsz 1 | num_updates 17998 | best_loss 8.204
2022-03-06 02:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 17998 updates
2022-03-06 02:01:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:01:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 370 @ 17998 updates, score 15.538) (writing took 1.7562826259527355 seconds)
2022-03-06 02:01:21 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:01:21 | INFO | train | epoch 370 | loss 0.5 | nll_loss 0.182 | ppl 1.13 | wps 27590.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 17998 | lr 0.000235715 | gnorm 0.431 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 41965
2022-03-06 02:01:21 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:01:25 | INFO | train_inner | epoch 371:      2 / 49 loss=0.501, nll_loss=0.183, ppl=1.13, wps=27171.3, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=18000, lr=0.000235702, gnorm=0.432, loss_scale=32, train_wall=196, gb_free=21.6, wall=41969
2022-03-06 02:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:12 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 15.438 | nll_loss 15.324 | ppl 41008.6 | wps 48434.7 | wpb 510.9 | bsz 1 | num_updates 18047 | best_loss 8.204
2022-03-06 02:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18047 updates
2022-03-06 02:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:03:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 371 @ 18047 updates, score 15.438) (writing took 1.696481745922938 seconds)
2022-03-06 02:03:14 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:03:14 | INFO | train | epoch 371 | loss 0.501 | nll_loss 0.182 | ppl 1.13 | wps 28184.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18047 | lr 0.000235395 | gnorm 0.431 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42078
2022-03-06 02:03:14 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:05 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 15.495 | nll_loss 15.381 | ppl 42673.3 | wps 48396.4 | wpb 510.9 | bsz 1 | num_updates 18096 | best_loss 8.204
2022-03-06 02:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18096 updates
2022-03-06 02:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 372 @ 18096 updates, score 15.495) (writing took 1.6583803920075297 seconds)
2022-03-06 02:05:06 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:05:06 | INFO | train | epoch 372 | loss 0.501 | nll_loss 0.182 | ppl 1.13 | wps 28191.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18096 | lr 0.000235076 | gnorm 0.435 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 42190
2022-03-06 02:05:06 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:05:15 | INFO | train_inner | epoch 373:      4 / 49 loss=0.501, nll_loss=0.182, ppl=1.13, wps=28221, ups=0.44, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.434, loss_scale=64, train_wall=195, gb_free=21.6, wall=42199
2022-03-06 02:05:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:06:57 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 15.478 | nll_loss 15.365 | ppl 42187.2 | wps 48551 | wpb 510.9 | bsz 1 | num_updates 18144 | best_loss 8.204
2022-03-06 02:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18144 updates
2022-03-06 02:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 373 @ 18144 updates, score 15.478) (writing took 1.7262574769556522 seconds)
2022-03-06 02:06:59 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:06:59 | INFO | train | epoch 373 | loss 0.499 | nll_loss 0.181 | ppl 1.13 | wps 27594.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18144 | lr 0.000234765 | gnorm 0.433 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42303
2022-03-06 02:06:59 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:08:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:08:50 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 15.543 | nll_loss 15.43 | ppl 44153.3 | wps 48480.1 | wpb 510.9 | bsz 1 | num_updates 18193 | best_loss 8.204
2022-03-06 02:08:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18193 updates
2022-03-06 02:08:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:08:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:08:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 374 @ 18193 updates, score 15.543) (writing took 1.711771494941786 seconds)
2022-03-06 02:08:52 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:08:52 | INFO | train | epoch 374 | loss 0.499 | nll_loss 0.181 | ppl 1.13 | wps 28172 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18193 | lr 0.000234449 | gnorm 0.428 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42416
2022-03-06 02:08:52 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:08:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:09:07 | INFO | train_inner | epoch 375:      7 / 49 loss=0.499, nll_loss=0.18, ppl=1.13, wps=27942.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.43, loss_scale=32, train_wall=197, gb_free=21.6, wall=42431
2022-03-06 02:10:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:10:43 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 15.601 | nll_loss 15.488 | ppl 45941.6 | wps 48428 | wpb 510.9 | bsz 1 | num_updates 18241 | best_loss 8.204
2022-03-06 02:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18241 updates
2022-03-06 02:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 375 @ 18241 updates, score 15.601) (writing took 1.7970686869230121 seconds)
2022-03-06 02:10:45 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:10:45 | INFO | train | epoch 375 | loss 0.498 | nll_loss 0.18 | ppl 1.13 | wps 27595.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18241 | lr 0.00023414 | gnorm 0.428 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 42529
2022-03-06 02:10:45 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:12:36 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 15.574 | nll_loss 15.462 | ppl 45136.3 | wps 48449 | wpb 510.9 | bsz 1 | num_updates 18290 | best_loss 8.204
2022-03-06 02:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18290 updates
2022-03-06 02:12:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:12:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:12:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 376 @ 18290 updates, score 15.574) (writing took 1.7156278199981898 seconds)
2022-03-06 02:12:37 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:12:37 | INFO | train | epoch 376 | loss 0.498 | nll_loss 0.18 | ppl 1.13 | wps 28170.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18290 | lr 0.000233826 | gnorm 0.426 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42642
2022-03-06 02:12:37 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:13:00 | INFO | train_inner | epoch 377:     10 / 49 loss=0.498, nll_loss=0.18, ppl=1.13, wps=27938.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.429, loss_scale=32, train_wall=197, gb_free=21.6, wall=42664
2022-03-06 02:14:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:14:29 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 15.58 | nll_loss 15.467 | ppl 45301.3 | wps 48286.5 | wpb 510.9 | bsz 1 | num_updates 18339 | best_loss 8.204
2022-03-06 02:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18339 updates
2022-03-06 02:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 377 @ 18339 updates, score 15.58) (writing took 1.7553546100389212 seconds)
2022-03-06 02:14:30 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:14:30 | INFO | train | epoch 377 | loss 0.497 | nll_loss 0.179 | ppl 1.13 | wps 28152 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18339 | lr 0.000233514 | gnorm 0.433 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42754
2022-03-06 02:14:30 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:15:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:16:21 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 15.522 | nll_loss 15.41 | ppl 43524.6 | wps 48409.7 | wpb 510.9 | bsz 1 | num_updates 18387 | best_loss 8.204
2022-03-06 02:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18387 updates
2022-03-06 02:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 378 @ 18387 updates, score 15.522) (writing took 1.6930417520925403 seconds)
2022-03-06 02:16:23 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:16:23 | INFO | train | epoch 378 | loss 0.495 | nll_loss 0.178 | ppl 1.13 | wps 27612.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18387 | lr 0.000233209 | gnorm 0.418 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42867
2022-03-06 02:16:23 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:16:52 | INFO | train_inner | epoch 379:     13 / 49 loss=0.496, nll_loss=0.178, ppl=1.13, wps=27938.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.423, loss_scale=32, train_wall=197, gb_free=21.6, wall=42896
2022-03-06 02:18:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:18:14 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 15.474 | nll_loss 15.362 | ppl 42101.2 | wps 48365.3 | wpb 510.9 | bsz 1 | num_updates 18436 | best_loss 8.204
2022-03-06 02:18:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18436 updates
2022-03-06 02:18:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:18:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 379 @ 18436 updates, score 15.474) (writing took 1.702538063051179 seconds)
2022-03-06 02:18:16 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:18:16 | INFO | train | epoch 379 | loss 0.496 | nll_loss 0.178 | ppl 1.13 | wps 28189.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18436 | lr 0.000232898 | gnorm 0.424 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 42980
2022-03-06 02:18:16 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:20:07 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 15.559 | nll_loss 15.447 | ppl 44670.9 | wps 48470.1 | wpb 510.9 | bsz 1 | num_updates 18485 | best_loss 8.204
2022-03-06 02:20:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18485 updates
2022-03-06 02:20:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:20:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 380 @ 18485 updates, score 15.559) (writing took 1.7499061040580273 seconds)
2022-03-06 02:20:09 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:20:09 | INFO | train | epoch 380 | loss 0.495 | nll_loss 0.177 | ppl 1.13 | wps 28162.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18485 | lr 0.00023259 | gnorm 0.422 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43093
2022-03-06 02:20:09 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:42 | INFO | train_inner | epoch 381:     15 / 49 loss=0.495, nll_loss=0.177, ppl=1.13, wps=28208.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.423, loss_scale=64, train_wall=195, gb_free=21.6, wall=43126
2022-03-06 02:21:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:21:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:22:00 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 15.376 | nll_loss 15.263 | ppl 39324 | wps 48472.1 | wpb 510.9 | bsz 1 | num_updates 18533 | best_loss 8.204
2022-03-06 02:22:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18533 updates
2022-03-06 02:22:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:22:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:22:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 381 @ 18533 updates, score 15.376) (writing took 1.6802497010212392 seconds)
2022-03-06 02:22:01 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:22:01 | INFO | train | epoch 381 | loss 0.495 | nll_loss 0.177 | ppl 1.13 | wps 27625.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18533 | lr 0.000232288 | gnorm 0.427 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 43205
2022-03-06 02:22:01 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:22:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:23:53 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 15.567 | nll_loss 15.456 | ppl 44934.8 | wps 48286.7 | wpb 510.9 | bsz 1 | num_updates 18582 | best_loss 8.204
2022-03-06 02:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18582 updates
2022-03-06 02:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 382 @ 18582 updates, score 15.567) (writing took 1.745638769119978 seconds)
2022-03-06 02:23:54 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:23:54 | INFO | train | epoch 382 | loss 0.494 | nll_loss 0.177 | ppl 1.13 | wps 28137.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18582 | lr 0.000231982 | gnorm 0.425 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43318
2022-03-06 02:23:54 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:34 | INFO | train_inner | epoch 383:     18 / 49 loss=0.494, nll_loss=0.177, ppl=1.13, wps=27933.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.424, loss_scale=32, train_wall=197, gb_free=21.6, wall=43358
2022-03-06 02:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:25:45 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 15.501 | nll_loss 15.388 | ppl 42877.9 | wps 48439.1 | wpb 510.9 | bsz 1 | num_updates 18631 | best_loss 8.204
2022-03-06 02:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18631 updates
2022-03-06 02:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 383 @ 18631 updates, score 15.501) (writing took 1.7586350559722632 seconds)
2022-03-06 02:25:47 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:25:47 | INFO | train | epoch 383 | loss 0.493 | nll_loss 0.176 | ppl 1.13 | wps 28146.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18631 | lr 0.000231676 | gnorm 0.42 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43431
2022-03-06 02:25:47 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:26:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:38 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 15.564 | nll_loss 15.453 | ppl 44854.6 | wps 48516.6 | wpb 510.9 | bsz 1 | num_updates 18679 | best_loss 8.204
2022-03-06 02:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18679 updates
2022-03-06 02:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 384 @ 18679 updates, score 15.564) (writing took 1.6793608309235424 seconds)
2022-03-06 02:27:40 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:27:40 | INFO | train | epoch 384 | loss 0.494 | nll_loss 0.176 | ppl 1.13 | wps 27617.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18679 | lr 0.000231379 | gnorm 0.416 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43544
2022-03-06 02:27:40 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:26 | INFO | train_inner | epoch 385:     21 / 49 loss=0.493, nll_loss=0.176, ppl=1.13, wps=27941.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.418, loss_scale=32, train_wall=197, gb_free=21.6, wall=43590
2022-03-06 02:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:29:31 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 15.474 | nll_loss 15.361 | ppl 42079.7 | wps 48540.9 | wpb 510.9 | bsz 1 | num_updates 18728 | best_loss 8.204
2022-03-06 02:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18728 updates
2022-03-06 02:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:29:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:29:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 385 @ 18728 updates, score 15.474) (writing took 1.674105908954516 seconds)
2022-03-06 02:29:33 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:29:33 | INFO | train | epoch 385 | loss 0.493 | nll_loss 0.176 | ppl 1.13 | wps 28165.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18728 | lr 0.000231076 | gnorm 0.418 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43657
2022-03-06 02:29:33 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:29:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:31:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:31:24 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 15.526 | nll_loss 15.415 | ppl 43680.1 | wps 48347.6 | wpb 510.9 | bsz 1 | num_updates 18777 | best_loss 8.204
2022-03-06 02:31:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18777 updates
2022-03-06 02:31:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:31:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:31:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 386 @ 18777 updates, score 15.526) (writing took 1.7516492379363626 seconds)
2022-03-06 02:31:26 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:31:26 | INFO | train | epoch 386 | loss 0.492 | nll_loss 0.175 | ppl 1.13 | wps 28163.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18777 | lr 0.000230774 | gnorm 0.413 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43770
2022-03-06 02:31:26 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:31:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:32:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:32:18 | INFO | train_inner | epoch 387:     24 / 49 loss=0.492, nll_loss=0.175, ppl=1.13, wps=27939.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.414, loss_scale=32, train_wall=197, gb_free=21.6, wall=43822
2022-03-06 02:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:33:17 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 15.483 | nll_loss 15.37 | ppl 42341.8 | wps 48441 | wpb 510.9 | bsz 1 | num_updates 18825 | best_loss 8.204
2022-03-06 02:33:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18825 updates
2022-03-06 02:33:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:33:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 387 @ 18825 updates, score 15.483) (writing took 1.6876592240296304 seconds)
2022-03-06 02:33:18 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:33:18 | INFO | train | epoch 387 | loss 0.491 | nll_loss 0.174 | ppl 1.13 | wps 27613.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18825 | lr 0.00023048 | gnorm 0.411 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43882
2022-03-06 02:33:18 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:35:09 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 15.559 | nll_loss 15.447 | ppl 44677.1 | wps 48371.4 | wpb 510.9 | bsz 1 | num_updates 18874 | best_loss 8.204
2022-03-06 02:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18874 updates
2022-03-06 02:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:35:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:35:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 388 @ 18874 updates, score 15.559) (writing took 1.6696120761334896 seconds)
2022-03-06 02:35:11 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:35:11 | INFO | train | epoch 388 | loss 0.491 | nll_loss 0.175 | ppl 1.13 | wps 28176.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18874 | lr 0.00023018 | gnorm 0.421 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 43995
2022-03-06 02:35:11 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:36:08 | INFO | train_inner | epoch 389:     26 / 49 loss=0.491, nll_loss=0.174, ppl=1.13, wps=28210.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.419, loss_scale=32, train_wall=195, gb_free=21.6, wall=44052
2022-03-06 02:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:37:02 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 15.473 | nll_loss 15.361 | ppl 42088.1 | wps 48297.6 | wpb 510.9 | bsz 1 | num_updates 18923 | best_loss 8.204
2022-03-06 02:37:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18923 updates
2022-03-06 02:37:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:37:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 389 @ 18923 updates, score 15.473) (writing took 1.745188195956871 seconds)
2022-03-06 02:37:04 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:37:04 | INFO | train | epoch 389 | loss 0.491 | nll_loss 0.175 | ppl 1.13 | wps 28159 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18923 | lr 0.000229882 | gnorm 0.422 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 44108
2022-03-06 02:37:04 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:37:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:38:55 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 15.509 | nll_loss 15.397 | ppl 43136.7 | wps 48452.9 | wpb 510.9 | bsz 1 | num_updates 18971 | best_loss 8.204
2022-03-06 02:38:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18971 updates
2022-03-06 02:38:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 390 @ 18971 updates, score 15.509) (writing took 1.683127423049882 seconds)
2022-03-06 02:38:57 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:38:57 | INFO | train | epoch 390 | loss 0.49 | nll_loss 0.174 | ppl 1.13 | wps 27585.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 18971 | lr 0.000229591 | gnorm 0.42 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44221
2022-03-06 02:38:57 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:40:00 | INFO | train_inner | epoch 391:     29 / 49 loss=0.49, nll_loss=0.174, ppl=1.13, wps=27930.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.42, loss_scale=32, train_wall=197, gb_free=21.6, wall=44285
2022-03-06 02:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:40:48 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 15.56 | nll_loss 15.451 | ppl 44790.8 | wps 48465.8 | wpb 510.9 | bsz 1 | num_updates 19020 | best_loss 8.204
2022-03-06 02:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19020 updates
2022-03-06 02:40:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:40:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 391 @ 19020 updates, score 15.56) (writing took 1.692427023081109 seconds)
2022-03-06 02:40:50 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:40:50 | INFO | train | epoch 391 | loss 0.491 | nll_loss 0.174 | ppl 1.13 | wps 28170.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19020 | lr 0.000229295 | gnorm 0.423 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44334
2022-03-06 02:40:50 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:42:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:42:41 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 15.418 | nll_loss 15.304 | ppl 40464.4 | wps 48462.8 | wpb 510.9 | bsz 1 | num_updates 19068 | best_loss 8.204
2022-03-06 02:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19068 updates
2022-03-06 02:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 392 @ 19068 updates, score 15.418) (writing took 1.7642809329554439 seconds)
2022-03-06 02:42:42 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:42:42 | INFO | train | epoch 392 | loss 0.489 | nll_loss 0.172 | ppl 1.13 | wps 27576.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19068 | lr 0.000229006 | gnorm 0.42 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44447
2022-03-06 02:42:42 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:43:53 | INFO | train_inner | epoch 393:     32 / 49 loss=0.489, nll_loss=0.173, ppl=1.13, wps=27926, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.42, loss_scale=32, train_wall=197, gb_free=21.6, wall=44517
2022-03-06 02:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:44:34 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 15.505 | nll_loss 15.395 | ppl 43076.9 | wps 48392.5 | wpb 510.9 | bsz 1 | num_updates 19117 | best_loss 8.204
2022-03-06 02:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19117 updates
2022-03-06 02:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 393 @ 19117 updates, score 15.505) (writing took 1.684903142042458 seconds)
2022-03-06 02:44:35 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:44:35 | INFO | train | epoch 393 | loss 0.489 | nll_loss 0.172 | ppl 1.13 | wps 28162.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19117 | lr 0.000228713 | gnorm 0.413 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44559
2022-03-06 02:44:35 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:46:26 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 15.492 | nll_loss 15.381 | ppl 42663.4 | wps 48526.1 | wpb 510.9 | bsz 1 | num_updates 19166 | best_loss 8.204
2022-03-06 02:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19166 updates
2022-03-06 02:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:46:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 394 @ 19166 updates, score 15.492) (writing took 1.6728811629582196 seconds)
2022-03-06 02:46:28 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 02:46:28 | INFO | train | epoch 394 | loss 0.488 | nll_loss 0.172 | ppl 1.13 | wps 28195.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19166 | lr 0.00022842 | gnorm 0.416 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44672
2022-03-06 02:46:28 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 02:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:47:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:47:45 | INFO | train_inner | epoch 395:     35 / 49 loss=0.488, nll_loss=0.172, ppl=1.13, wps=27946.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.415, loss_scale=32, train_wall=197, gb_free=21.6, wall=44749
2022-03-06 02:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:48:19 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 15.459 | nll_loss 15.346 | ppl 41655.3 | wps 48508.2 | wpb 510.9 | bsz 1 | num_updates 19214 | best_loss 8.204
2022-03-06 02:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19214 updates
2022-03-06 02:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:48:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 395 @ 19214 updates, score 15.459) (writing took 1.7612065291032195 seconds)
2022-03-06 02:48:21 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 02:48:21 | INFO | train | epoch 395 | loss 0.487 | nll_loss 0.171 | ppl 1.13 | wps 27584.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19214 | lr 0.000228135 | gnorm 0.415 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44785
2022-03-06 02:48:21 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 02:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:50:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:50:12 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 15.447 | nll_loss 15.335 | ppl 41332.1 | wps 49185.8 | wpb 510.9 | bsz 1 | num_updates 19263 | best_loss 8.204
2022-03-06 02:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19263 updates
2022-03-06 02:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:50:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:50:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 396 @ 19263 updates, score 15.447) (writing took 1.7266956178937107 seconds)
2022-03-06 02:50:14 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 02:50:14 | INFO | train | epoch 396 | loss 0.487 | nll_loss 0.171 | ppl 1.13 | wps 28165 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19263 | lr 0.000227844 | gnorm 0.416 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 44898
2022-03-06 02:50:14 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 02:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:51:35 | INFO | train_inner | epoch 397:     37 / 49 loss=0.487, nll_loss=0.171, ppl=1.13, wps=28206.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.412, loss_scale=32, train_wall=195, gb_free=21.6, wall=44979
2022-03-06 02:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:52:05 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 15.464 | nll_loss 15.352 | ppl 41813.8 | wps 48632.5 | wpb 510.9 | bsz 1 | num_updates 19312 | best_loss 8.204
2022-03-06 02:52:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19312 updates
2022-03-06 02:52:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:52:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:52:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 397 @ 19312 updates, score 15.464) (writing took 1.6980739950668067 seconds)
2022-03-06 02:52:06 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 02:52:06 | INFO | train | epoch 397 | loss 0.486 | nll_loss 0.17 | ppl 1.13 | wps 28199 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19312 | lr 0.000227555 | gnorm 0.409 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 45010
2022-03-06 02:52:06 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 02:52:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:52:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:53:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:53:57 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 15.481 | nll_loss 15.371 | ppl 42368.2 | wps 48528.1 | wpb 510.9 | bsz 1 | num_updates 19360 | best_loss 8.204
2022-03-06 02:53:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19360 updates
2022-03-06 02:53:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:53:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 398 @ 19360 updates, score 15.481) (writing took 1.7204390440601856 seconds)
2022-03-06 02:53:59 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 02:53:59 | INFO | train | epoch 398 | loss 0.486 | nll_loss 0.17 | ppl 1.12 | wps 27601.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19360 | lr 0.000227273 | gnorm 0.408 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45123
2022-03-06 02:53:59 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 02:53:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:55:27 | INFO | train_inner | epoch 399:     40 / 49 loss=0.486, nll_loss=0.17, ppl=1.12, wps=27952.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.41, loss_scale=32, train_wall=197, gb_free=21.6, wall=45211
2022-03-06 02:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:55:50 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 15.512 | nll_loss 15.401 | ppl 43262.8 | wps 48511.6 | wpb 510.9 | bsz 1 | num_updates 19409 | best_loss 8.204
2022-03-06 02:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19409 updates
2022-03-06 02:55:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:55:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 399 @ 19409 updates, score 15.512) (writing took 1.6990649218205363 seconds)
2022-03-06 02:55:52 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 02:55:52 | INFO | train | epoch 399 | loss 0.485 | nll_loss 0.169 | ppl 1.12 | wps 28167.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19409 | lr 0.000226986 | gnorm 0.409 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45236
2022-03-06 02:55:52 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 02:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:57:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:43 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 15.424 | nll_loss 15.311 | ppl 40641 | wps 48286.7 | wpb 510.9 | bsz 1 | num_updates 19458 | best_loss 8.204
2022-03-06 02:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19458 updates
2022-03-06 02:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 400 @ 19458 updates, score 15.424) (writing took 1.6916808139067143 seconds)
2022-03-06 02:57:45 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 02:57:45 | INFO | train | epoch 400 | loss 0.485 | nll_loss 0.17 | ppl 1.12 | wps 28178.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19458 | lr 0.0002267 | gnorm 0.416 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 45349
2022-03-06 02:57:45 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 02:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:57:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:59:19 | INFO | train_inner | epoch 401:     43 / 49 loss=0.485, nll_loss=0.169, ppl=1.12, wps=27932.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.412, loss_scale=32, train_wall=197, gb_free=21.6, wall=45443
2022-03-06 02:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:59:36 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 15.532 | nll_loss 15.421 | ppl 43856.5 | wps 48397 | wpb 510.9 | bsz 1 | num_updates 19506 | best_loss 8.204
2022-03-06 02:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19506 updates
2022-03-06 02:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 02:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 401 @ 19506 updates, score 15.532) (writing took 1.7761191301979125 seconds)
2022-03-06 02:59:38 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 02:59:38 | INFO | train | epoch 401 | loss 0.484 | nll_loss 0.169 | ppl 1.12 | wps 27563.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19506 | lr 0.000226421 | gnorm 0.411 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45462
2022-03-06 02:59:38 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 02:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:01:29 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 15.552 | nll_loss 15.441 | ppl 44490.9 | wps 48671.4 | wpb 510.9 | bsz 1 | num_updates 19555 | best_loss 8.204
2022-03-06 03:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19555 updates
2022-03-06 03:01:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 402 @ 19555 updates, score 15.552) (writing took 1.716821453999728 seconds)
2022-03-06 03:01:30 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:01:30 | INFO | train | epoch 402 | loss 0.484 | nll_loss 0.168 | ppl 1.12 | wps 28179 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19555 | lr 0.000226137 | gnorm 0.403 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45575
2022-03-06 03:01:30 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:03:11 | INFO | train_inner | epoch 403:     46 / 49 loss=0.484, nll_loss=0.168, ppl=1.12, wps=27936.4, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.408, loss_scale=32, train_wall=197, gb_free=21.6, wall=45676
2022-03-06 03:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:03:22 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 15.475 | nll_loss 15.363 | ppl 42155.1 | wps 48581.6 | wpb 510.9 | bsz 1 | num_updates 19603 | best_loss 8.204
2022-03-06 03:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19603 updates
2022-03-06 03:03:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 403 @ 19603 updates, score 15.475) (writing took 1.7224467468913645 seconds)
2022-03-06 03:03:23 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:03:23 | INFO | train | epoch 403 | loss 0.484 | nll_loss 0.168 | ppl 1.12 | wps 27594.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19603 | lr 0.00022586 | gnorm 0.412 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45687
2022-03-06 03:03:23 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:05:14 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 15.446 | nll_loss 15.336 | ppl 41347.5 | wps 48464.5 | wpb 510.9 | bsz 1 | num_updates 19652 | best_loss 8.204
2022-03-06 03:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19652 updates
2022-03-06 03:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:05:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:05:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 404 @ 19652 updates, score 15.446) (writing took 1.747847842052579 seconds)
2022-03-06 03:05:16 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:05:16 | INFO | train | epoch 404 | loss 0.483 | nll_loss 0.168 | ppl 1.12 | wps 28161.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19652 | lr 0.000225578 | gnorm 0.407 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45800
2022-03-06 03:05:16 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:05:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:07:02 | INFO | train_inner | epoch 405:     48 / 49 loss=0.483, nll_loss=0.168, ppl=1.12, wps=28196.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.408, loss_scale=32, train_wall=195, gb_free=21.6, wall=45906
2022-03-06 03:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:07:07 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 15.648 | nll_loss 15.539 | ppl 47623.7 | wps 48456.3 | wpb 510.9 | bsz 1 | num_updates 19701 | best_loss 8.204
2022-03-06 03:07:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19701 updates
2022-03-06 03:07:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 405 @ 19701 updates, score 15.648) (writing took 1.7005867939442396 seconds)
2022-03-06 03:07:09 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:07:09 | INFO | train | epoch 405 | loss 0.483 | nll_loss 0.167 | ppl 1.12 | wps 28173.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19701 | lr 0.000225297 | gnorm 0.41 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 45913
2022-03-06 03:07:09 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:08:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:00 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 15.498 | nll_loss 15.389 | ppl 42902.4 | wps 48515.4 | wpb 510.9 | bsz 1 | num_updates 19749 | best_loss 8.204
2022-03-06 03:09:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19749 updates
2022-03-06 03:09:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 406 @ 19749 updates, score 15.498) (writing took 1.7232958441600204 seconds)
2022-03-06 03:09:02 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:09:02 | INFO | train | epoch 406 | loss 0.482 | nll_loss 0.167 | ppl 1.12 | wps 27616.2 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19749 | lr 0.000225023 | gnorm 0.408 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 46026
2022-03-06 03:09:02 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:10:53 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 15.412 | nll_loss 15.301 | ppl 40356.2 | wps 48298.6 | wpb 510.9 | bsz 1 | num_updates 19798 | best_loss 8.204
2022-03-06 03:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19798 updates
2022-03-06 03:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:10:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 407 @ 19798 updates, score 15.412) (writing took 1.7486016310285777 seconds)
2022-03-06 03:10:54 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:10:54 | INFO | train | epoch 407 | loss 0.482 | nll_loss 0.167 | ppl 1.12 | wps 28159.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19798 | lr 0.000224745 | gnorm 0.41 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46139
2022-03-06 03:10:55 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:10:59 | INFO | train_inner | epoch 408:      2 / 49 loss=0.482, nll_loss=0.167, ppl=1.12, wps=27180, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=19800, lr=0.000224733, gnorm=0.41, loss_scale=32, train_wall=196, gb_free=21.6, wall=46143
2022-03-06 03:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:12:46 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 15.378 | nll_loss 15.266 | ppl 39395 | wps 48507 | wpb 510.9 | bsz 1 | num_updates 19847 | best_loss 8.204
2022-03-06 03:12:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19847 updates
2022-03-06 03:12:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:12:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:12:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 408 @ 19847 updates, score 15.378) (writing took 1.692240150878206 seconds)
2022-03-06 03:12:47 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:12:47 | INFO | train | epoch 408 | loss 0.481 | nll_loss 0.166 | ppl 1.12 | wps 28164.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19847 | lr 0.000224467 | gnorm 0.406 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46251
2022-03-06 03:12:47 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:13:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:14:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:14:38 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 15.503 | nll_loss 15.392 | ppl 43010.3 | wps 48447.3 | wpb 510.9 | bsz 1 | num_updates 19895 | best_loss 8.204
2022-03-06 03:14:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19895 updates
2022-03-06 03:14:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:14:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 409 @ 19895 updates, score 15.503) (writing took 1.6875779209658504 seconds)
2022-03-06 03:14:40 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:14:40 | INFO | train | epoch 409 | loss 0.481 | nll_loss 0.166 | ppl 1.12 | wps 27609 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19895 | lr 0.000224196 | gnorm 0.412 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46364
2022-03-06 03:14:40 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:14:51 | INFO | train_inner | epoch 410:      5 / 49 loss=0.481, nll_loss=0.166, ppl=1.12, wps=27945.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.408, loss_scale=32, train_wall=197, gb_free=21.6, wall=46375
2022-03-06 03:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:16:31 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 15.397 | nll_loss 15.287 | ppl 39981.9 | wps 48427.4 | wpb 510.9 | bsz 1 | num_updates 19944 | best_loss 8.204
2022-03-06 03:16:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19944 updates
2022-03-06 03:16:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:16:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:16:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 410 @ 19944 updates, score 15.397) (writing took 1.762332079000771 seconds)
2022-03-06 03:16:33 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:16:33 | INFO | train | epoch 410 | loss 0.48 | nll_loss 0.165 | ppl 1.12 | wps 28184.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19944 | lr 0.000223921 | gnorm 0.404 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46477
2022-03-06 03:16:33 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:16:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:18:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:18:24 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 15.436 | nll_loss 15.327 | ppl 41096.6 | wps 48501.9 | wpb 510.9 | bsz 1 | num_updates 19992 | best_loss 8.204
2022-03-06 03:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 19992 updates
2022-03-06 03:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:18:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:18:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 411 @ 19992 updates, score 15.436) (writing took 1.6889335529413074 seconds)
2022-03-06 03:18:25 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:18:25 | INFO | train | epoch 411 | loss 0.48 | nll_loss 0.165 | ppl 1.12 | wps 27628.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 19992 | lr 0.000223652 | gnorm 0.408 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 46590
2022-03-06 03:18:25 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:18:43 | INFO | train_inner | epoch 412:      8 / 49 loss=0.48, nll_loss=0.165, ppl=1.12, wps=27961.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.405, loss_scale=32, train_wall=197, gb_free=21.6, wall=46607
2022-03-06 03:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:20:16 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 15.47 | nll_loss 15.361 | ppl 42072.5 | wps 48511.7 | wpb 510.9 | bsz 1 | num_updates 20041 | best_loss 8.204
2022-03-06 03:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20041 updates
2022-03-06 03:20:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:20:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 412 @ 20041 updates, score 15.47) (writing took 1.6951069061178714 seconds)
2022-03-06 03:20:18 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:20:18 | INFO | train | epoch 412 | loss 0.48 | nll_loss 0.165 | ppl 1.12 | wps 28210.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20041 | lr 0.000223378 | gnorm 0.401 | loss_scale 32 | train_wall 95 | gb_free 21.6 | wall 46702
2022-03-06 03:20:18 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:22:09 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 15.537 | nll_loss 15.428 | ppl 44081.8 | wps 48449.7 | wpb 510.9 | bsz 1 | num_updates 20090 | best_loss 8.204
2022-03-06 03:22:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20090 updates
2022-03-06 03:22:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 413 @ 20090 updates, score 15.537) (writing took 1.7686709391418844 seconds)
2022-03-06 03:22:11 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:22:11 | INFO | train | epoch 413 | loss 0.479 | nll_loss 0.165 | ppl 1.12 | wps 28174.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20090 | lr 0.000223105 | gnorm 0.398 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46815
2022-03-06 03:22:11 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:22:33 | INFO | train_inner | epoch 414:     10 / 49 loss=0.479, nll_loss=0.165, ppl=1.12, wps=28228, ups=0.44, wpb=64876.2, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.399, loss_scale=32, train_wall=195, gb_free=21.6, wall=46837
2022-03-06 03:23:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:24:02 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 15.483 | nll_loss 15.375 | ppl 42489 | wps 48672.4 | wpb 510.9 | bsz 1 | num_updates 20138 | best_loss 8.204
2022-03-06 03:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20138 updates
2022-03-06 03:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 414 @ 20138 updates, score 15.483) (writing took 1.6899449359625578 seconds)
2022-03-06 03:24:04 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:24:04 | INFO | train | epoch 414 | loss 0.479 | nll_loss 0.164 | ppl 1.12 | wps 27631 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 20138 | lr 0.000222839 | gnorm 0.402 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 46928
2022-03-06 03:24:04 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:25:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:25:55 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 15.511 | nll_loss 15.401 | ppl 43263.1 | wps 48525.9 | wpb 510.9 | bsz 1 | num_updates 20187 | best_loss 8.204
2022-03-06 03:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20187 updates
2022-03-06 03:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:25:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 415 @ 20187 updates, score 15.511) (writing took 1.7160602889489383 seconds)
2022-03-06 03:25:56 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:25:56 | INFO | train | epoch 415 | loss 0.479 | nll_loss 0.164 | ppl 1.12 | wps 28178.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20187 | lr 0.000222569 | gnorm 0.402 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47040
2022-03-06 03:25:56 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:26:25 | INFO | train_inner | epoch 416:     13 / 49 loss=0.479, nll_loss=0.164, ppl=1.12, wps=27957.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.402, loss_scale=32, train_wall=197, gb_free=21.6, wall=47069
2022-03-06 03:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:27:47 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 15.438 | nll_loss 15.328 | ppl 41132.3 | wps 48458.2 | wpb 510.9 | bsz 1 | num_updates 20236 | best_loss 8.204
2022-03-06 03:27:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20236 updates
2022-03-06 03:27:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 416 @ 20236 updates, score 15.438) (writing took 1.756860082037747 seconds)
2022-03-06 03:27:49 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:27:49 | INFO | train | epoch 416 | loss 0.478 | nll_loss 0.164 | ppl 1.12 | wps 28160.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20236 | lr 0.000222299 | gnorm 0.402 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47153
2022-03-06 03:27:49 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:29:40 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 15.592 | nll_loss 15.484 | ppl 45829.2 | wps 48451.6 | wpb 510.9 | bsz 1 | num_updates 20284 | best_loss 8.204
2022-03-06 03:29:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20284 updates
2022-03-06 03:29:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:29:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:29:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 417 @ 20284 updates, score 15.592) (writing took 1.726319036912173 seconds)
2022-03-06 03:29:42 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:29:42 | INFO | train | epoch 417 | loss 0.478 | nll_loss 0.163 | ppl 1.12 | wps 27612.2 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 20284 | lr 0.000222036 | gnorm 0.402 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47266
2022-03-06 03:29:42 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:30:17 | INFO | train_inner | epoch 418:     16 / 49 loss=0.478, nll_loss=0.163, ppl=1.12, wps=27943.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.402, loss_scale=32, train_wall=197, gb_free=21.6, wall=47301
2022-03-06 03:31:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:31:33 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 15.431 | nll_loss 15.32 | ppl 40912.7 | wps 48519.5 | wpb 510.9 | bsz 1 | num_updates 20333 | best_loss 8.204
2022-03-06 03:31:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20333 updates
2022-03-06 03:31:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 418 @ 20333 updates, score 15.431) (writing took 1.701623119879514 seconds)
2022-03-06 03:31:35 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:31:35 | INFO | train | epoch 418 | loss 0.477 | nll_loss 0.163 | ppl 1.12 | wps 28205.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20333 | lr 0.000221768 | gnorm 0.401 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47379
2022-03-06 03:31:35 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:26 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 15.445 | nll_loss 15.337 | ppl 41382.5 | wps 48457.8 | wpb 510.9 | bsz 1 | num_updates 20382 | best_loss 8.204
2022-03-06 03:33:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20382 updates
2022-03-06 03:33:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:33:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:33:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 419 @ 20382 updates, score 15.445) (writing took 1.7590159808751196 seconds)
2022-03-06 03:33:27 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:33:27 | INFO | train | epoch 419 | loss 0.477 | nll_loss 0.162 | ppl 1.12 | wps 28178.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20382 | lr 0.000221501 | gnorm 0.399 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47491
2022-03-06 03:33:27 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:34:09 | INFO | train_inner | epoch 420:     19 / 49 loss=0.477, nll_loss=0.162, ppl=1.12, wps=27958.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.398, loss_scale=32, train_wall=197, gb_free=21.6, wall=47533
2022-03-06 03:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:35:18 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 15.464 | nll_loss 15.355 | ppl 41911.8 | wps 48353.7 | wpb 510.9 | bsz 1 | num_updates 20430 | best_loss 8.204
2022-03-06 03:35:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20430 updates
2022-03-06 03:35:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:35:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 420 @ 20430 updates, score 15.464) (writing took 1.7207746310159564 seconds)
2022-03-06 03:35:20 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:35:20 | INFO | train | epoch 420 | loss 0.476 | nll_loss 0.162 | ppl 1.12 | wps 27600.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 20430 | lr 0.000221241 | gnorm 0.393 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47604
2022-03-06 03:35:20 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:35:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:37:11 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 15.386 | nll_loss 15.276 | ppl 39670 | wps 48478.9 | wpb 510.9 | bsz 1 | num_updates 20479 | best_loss 8.204
2022-03-06 03:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20479 updates
2022-03-06 03:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 421 @ 20479 updates, score 15.386) (writing took 1.7424775490071625 seconds)
2022-03-06 03:37:13 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:37:13 | INFO | train | epoch 421 | loss 0.475 | nll_loss 0.161 | ppl 1.12 | wps 28168.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20479 | lr 0.000220976 | gnorm 0.397 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47717
2022-03-06 03:37:13 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:37:59 | INFO | train_inner | epoch 422:     21 / 49 loss=0.476, nll_loss=0.162, ppl=1.12, wps=28206.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.397, loss_scale=32, train_wall=195, gb_free=21.6, wall=47763
2022-03-06 03:38:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:04 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 15.407 | nll_loss 15.299 | ppl 40304.1 | wps 48420.7 | wpb 510.9 | bsz 1 | num_updates 20527 | best_loss 8.204
2022-03-06 03:39:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20527 updates
2022-03-06 03:39:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 422 @ 20527 updates, score 15.407) (writing took 1.744760894915089 seconds)
2022-03-06 03:39:06 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:39:06 | INFO | train | epoch 422 | loss 0.475 | nll_loss 0.161 | ppl 1.12 | wps 27583.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 20527 | lr 0.000220718 | gnorm 0.401 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47830
2022-03-06 03:39:06 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:40:57 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 15.456 | nll_loss 15.347 | ppl 41688.4 | wps 48324.2 | wpb 510.9 | bsz 1 | num_updates 20576 | best_loss 8.204
2022-03-06 03:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20576 updates
2022-03-06 03:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 423 @ 20576 updates, score 15.456) (writing took 1.70332201407291 seconds)
2022-03-06 03:40:59 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:40:59 | INFO | train | epoch 423 | loss 0.474 | nll_loss 0.16 | ppl 1.12 | wps 28184.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20576 | lr 0.000220455 | gnorm 0.393 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 47943
2022-03-06 03:40:59 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:41:51 | INFO | train_inner | epoch 424:     24 / 49 loss=0.474, nll_loss=0.16, ppl=1.12, wps=27930.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.396, loss_scale=32, train_wall=197, gb_free=21.6, wall=47995
2022-03-06 03:42:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:42:50 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 15.492 | nll_loss 15.384 | ppl 42749.9 | wps 48373 | wpb 510.9 | bsz 1 | num_updates 20625 | best_loss 8.204
2022-03-06 03:42:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20625 updates
2022-03-06 03:42:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:42:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:42:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 424 @ 20625 updates, score 15.492) (writing took 1.7844161340035498 seconds)
2022-03-06 03:42:52 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:42:52 | INFO | train | epoch 424 | loss 0.474 | nll_loss 0.161 | ppl 1.12 | wps 28142.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20625 | lr 0.000220193 | gnorm 0.399 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48056
2022-03-06 03:42:52 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:42:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:44:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:44:43 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 15.366 | nll_loss 15.257 | ppl 39162.8 | wps 48114.7 | wpb 510.9 | bsz 1 | num_updates 20673 | best_loss 8.204
2022-03-06 03:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20673 updates
2022-03-06 03:44:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 425 @ 20673 updates, score 15.366) (writing took 1.785610897000879 seconds)
2022-03-06 03:44:45 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 03:44:45 | INFO | train | epoch 425 | loss 0.474 | nll_loss 0.16 | ppl 1.12 | wps 27530.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20673 | lr 0.000219937 | gnorm 0.398 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48169
2022-03-06 03:44:45 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 03:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:45:44 | INFO | train_inner | epoch 426:     27 / 49 loss=0.474, nll_loss=0.16, ppl=1.12, wps=27902.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.402, loss_scale=32, train_wall=197, gb_free=21.6, wall=48228
2022-03-06 03:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:46:36 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 15.414 | nll_loss 15.305 | ppl 40494.8 | wps 47659.8 | wpb 510.9 | bsz 1 | num_updates 20722 | best_loss 8.204
2022-03-06 03:46:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20722 updates
2022-03-06 03:46:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 426 @ 20722 updates, score 15.414) (writing took 1.6926878329832107 seconds)
2022-03-06 03:46:37 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 03:46:37 | INFO | train | epoch 426 | loss 0.475 | nll_loss 0.161 | ppl 1.12 | wps 28155.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20722 | lr 0.000219677 | gnorm 0.406 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48282
2022-03-06 03:46:37 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 03:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:48:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:48:29 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 15.375 | nll_loss 15.266 | ppl 39391.9 | wps 48142.4 | wpb 510.9 | bsz 1 | num_updates 20771 | best_loss 8.204
2022-03-06 03:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20771 updates
2022-03-06 03:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:48:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 427 @ 20771 updates, score 15.375) (writing took 1.7009364878758788 seconds)
2022-03-06 03:48:31 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 03:48:31 | INFO | train | epoch 427 | loss 0.473 | nll_loss 0.16 | ppl 1.12 | wps 28099.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20771 | lr 0.000219418 | gnorm 0.395 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48395
2022-03-06 03:48:31 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 03:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:49:34 | INFO | train_inner | epoch 428:     29 / 49 loss=0.473, nll_loss=0.16, ppl=1.12, wps=28135.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.394, loss_scale=64, train_wall=196, gb_free=21.6, wall=48459
2022-03-06 03:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:50:22 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 15.409 | nll_loss 15.3 | ppl 40352.1 | wps 48305.1 | wpb 510.9 | bsz 1 | num_updates 20819 | best_loss 8.204
2022-03-06 03:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20819 updates
2022-03-06 03:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 428 @ 20819 updates, score 15.409) (writing took 1.7790291239507496 seconds)
2022-03-06 03:50:24 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 03:50:24 | INFO | train | epoch 428 | loss 0.472 | nll_loss 0.159 | ppl 1.12 | wps 27519.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20819 | lr 0.000219164 | gnorm 0.386 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48508
2022-03-06 03:50:24 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 03:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:52:15 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 15.458 | nll_loss 15.349 | ppl 41739.2 | wps 48230.1 | wpb 510.9 | bsz 1 | num_updates 20868 | best_loss 8.204
2022-03-06 03:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20868 updates
2022-03-06 03:52:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 429 @ 20868 updates, score 15.458) (writing took 1.8207592370454222 seconds)
2022-03-06 03:52:17 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 03:52:17 | INFO | train | epoch 429 | loss 0.472 | nll_loss 0.159 | ppl 1.12 | wps 28112.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20868 | lr 0.000218907 | gnorm 0.396 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48621
2022-03-06 03:52:17 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 03:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:53:27 | INFO | train_inner | epoch 430:     32 / 49 loss=0.472, nll_loss=0.158, ppl=1.12, wps=27895.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.392, loss_scale=32, train_wall=197, gb_free=21.6, wall=48691
2022-03-06 03:54:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:54:08 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 15.457 | nll_loss 15.349 | ppl 41740.3 | wps 48240.5 | wpb 510.9 | bsz 1 | num_updates 20917 | best_loss 8.204
2022-03-06 03:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20917 updates
2022-03-06 03:54:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:54:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:54:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 430 @ 20917 updates, score 15.457) (writing took 1.7876971948426217 seconds)
2022-03-06 03:54:10 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 03:54:10 | INFO | train | epoch 430 | loss 0.472 | nll_loss 0.158 | ppl 1.12 | wps 28139.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20917 | lr 0.00021865 | gnorm 0.393 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48734
2022-03-06 03:54:10 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 03:54:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:55:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:56:01 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 15.556 | nll_loss 15.449 | ppl 44717.9 | wps 48170.6 | wpb 510.9 | bsz 1 | num_updates 20965 | best_loss 8.204
2022-03-06 03:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20965 updates
2022-03-06 03:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 431 @ 20965 updates, score 15.556) (writing took 1.793653533095494 seconds)
2022-03-06 03:56:03 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 03:56:03 | INFO | train | epoch 431 | loss 0.472 | nll_loss 0.159 | ppl 1.12 | wps 27547.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20965 | lr 0.0002184 | gnorm 0.399 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48847
2022-03-06 03:56:03 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 03:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:20 | INFO | train_inner | epoch 432:     35 / 49 loss=0.472, nll_loss=0.158, ppl=1.12, wps=27902.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.396, loss_scale=32, train_wall=197, gb_free=21.6, wall=48924
2022-03-06 03:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:57:54 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 15.485 | nll_loss 15.377 | ppl 42550.9 | wps 48121 | wpb 510.9 | bsz 1 | num_updates 21014 | best_loss 8.204
2022-03-06 03:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21014 updates
2022-03-06 03:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:57:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:57:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 432 @ 21014 updates, score 15.485) (writing took 1.7230316090863198 seconds)
2022-03-06 03:57:56 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 03:57:56 | INFO | train | epoch 432 | loss 0.471 | nll_loss 0.158 | ppl 1.12 | wps 28138.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21014 | lr 0.000218145 | gnorm 0.391 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 48960
2022-03-06 03:57:56 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 03:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:59:47 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 15.435 | nll_loss 15.327 | ppl 41117.9 | wps 48158.5 | wpb 510.9 | bsz 1 | num_updates 21063 | best_loss 8.204
2022-03-06 03:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21063 updates
2022-03-06 03:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 03:59:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 433 @ 21063 updates, score 15.435) (writing took 1.7363145269919187 seconds)
2022-03-06 03:59:48 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 03:59:48 | INFO | train | epoch 433 | loss 0.471 | nll_loss 0.158 | ppl 1.12 | wps 28147.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21063 | lr 0.000217891 | gnorm 0.394 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49073
2022-03-06 03:59:49 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 03:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:00:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:01:12 | INFO | train_inner | epoch 434:     38 / 49 loss=0.471, nll_loss=0.158, ppl=1.12, wps=27908.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.394, loss_scale=32, train_wall=197, gb_free=21.6, wall=49156
2022-03-06 04:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:01:40 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 15.451 | nll_loss 15.343 | ppl 41552.3 | wps 48272.7 | wpb 510.9 | bsz 1 | num_updates 21111 | best_loss 8.204
2022-03-06 04:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21111 updates
2022-03-06 04:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:01:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 434 @ 21111 updates, score 15.451) (writing took 1.7785307869780809 seconds)
2022-03-06 04:01:41 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:01:41 | INFO | train | epoch 434 | loss 0.471 | nll_loss 0.158 | ppl 1.12 | wps 27561.3 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 21111 | lr 0.000217643 | gnorm 0.396 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49186
2022-03-06 04:01:41 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:03:33 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 15.34 | nll_loss 15.232 | ppl 38471.6 | wps 48124.8 | wpb 510.9 | bsz 1 | num_updates 21160 | best_loss 8.204
2022-03-06 04:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21160 updates
2022-03-06 04:03:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:03:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 435 @ 21160 updates, score 15.34) (writing took 1.7057527569122612 seconds)
2022-03-06 04:03:34 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:03:34 | INFO | train | epoch 435 | loss 0.469 | nll_loss 0.156 | ppl 1.11 | wps 28154.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21160 | lr 0.000217391 | gnorm 0.384 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49298
2022-03-06 04:03:34 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:02 | INFO | train_inner | epoch 436:     40 / 49 loss=0.47, nll_loss=0.157, ppl=1.11, wps=28186.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.387, loss_scale=32, train_wall=195, gb_free=21.6, wall=49386
2022-03-06 04:05:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:05:25 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 15.435 | nll_loss 15.327 | ppl 41115.9 | wps 48260.3 | wpb 510.9 | bsz 1 | num_updates 21209 | best_loss 8.204
2022-03-06 04:05:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21209 updates
2022-03-06 04:05:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 436 @ 21209 updates, score 15.435) (writing took 1.7385162389837205 seconds)
2022-03-06 04:05:27 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:05:27 | INFO | train | epoch 436 | loss 0.469 | nll_loss 0.157 | ppl 1.11 | wps 28160.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21209 | lr 0.00021714 | gnorm 0.389 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 49411
2022-03-06 04:05:27 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:07:18 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 15.406 | nll_loss 15.298 | ppl 40290.3 | wps 48849.8 | wpb 510.9 | bsz 1 | num_updates 21257 | best_loss 8.204
2022-03-06 04:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21257 updates
2022-03-06 04:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 437 @ 21257 updates, score 15.406) (writing took 1.786051519913599 seconds)
2022-03-06 04:07:20 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:07:20 | INFO | train | epoch 437 | loss 0.469 | nll_loss 0.156 | ppl 1.11 | wps 27565.3 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 21257 | lr 0.000216895 | gnorm 0.392 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49524
2022-03-06 04:07:20 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:55 | INFO | train_inner | epoch 438:     43 / 49 loss=0.469, nll_loss=0.156, ppl=1.11, wps=27908.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.395, loss_scale=32, train_wall=197, gb_free=21.6, wall=49619
2022-03-06 04:09:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:09:11 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 15.313 | nll_loss 15.204 | ppl 37749.3 | wps 48064.9 | wpb 510.9 | bsz 1 | num_updates 21306 | best_loss 8.204
2022-03-06 04:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21306 updates
2022-03-06 04:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:09:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 438 @ 21306 updates, score 15.313) (writing took 1.7084073179867119 seconds)
2022-03-06 04:09:13 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:09:13 | INFO | train | epoch 438 | loss 0.469 | nll_loss 0.156 | ppl 1.11 | wps 28144.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21306 | lr 0.000216645 | gnorm 0.4 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49637
2022-03-06 04:09:13 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:10:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:11:04 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 15.401 | nll_loss 15.292 | ppl 40120.6 | wps 48168.1 | wpb 510.9 | bsz 1 | num_updates 21354 | best_loss 8.204
2022-03-06 04:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21354 updates
2022-03-06 04:11:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 439 @ 21354 updates, score 15.401) (writing took 1.6859834229107946 seconds)
2022-03-06 04:11:06 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:11:06 | INFO | train | epoch 439 | loss 0.468 | nll_loss 0.155 | ppl 1.11 | wps 27580.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 21354 | lr 0.000216402 | gnorm 0.387 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49750
2022-03-06 04:11:06 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:12:47 | INFO | train_inner | epoch 440:     46 / 49 loss=0.468, nll_loss=0.156, ppl=1.11, wps=27937.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.389, loss_scale=32, train_wall=197, gb_free=21.6, wall=49851
2022-03-06 04:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:12:57 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 15.327 | nll_loss 15.217 | ppl 38076 | wps 48083.4 | wpb 510.9 | bsz 1 | num_updates 21403 | best_loss 8.204
2022-03-06 04:12:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21403 updates
2022-03-06 04:12:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 440 @ 21403 updates, score 15.327) (writing took 1.748743690084666 seconds)
2022-03-06 04:12:59 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:12:59 | INFO | train | epoch 440 | loss 0.468 | nll_loss 0.155 | ppl 1.11 | wps 28171.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21403 | lr 0.000216154 | gnorm 0.388 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49863
2022-03-06 04:12:59 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:14:50 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 15.419 | nll_loss 15.309 | ppl 40608.1 | wps 48208.4 | wpb 510.9 | bsz 1 | num_updates 21452 | best_loss 8.204
2022-03-06 04:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21452 updates
2022-03-06 04:14:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 441 @ 21452 updates, score 15.419) (writing took 1.6956466960255057 seconds)
2022-03-06 04:14:51 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:14:51 | INFO | train | epoch 441 | loss 0.467 | nll_loss 0.155 | ppl 1.11 | wps 28176 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21452 | lr 0.000215907 | gnorm 0.39 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 49976
2022-03-06 04:14:51 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:16:37 | INFO | train_inner | epoch 442:     48 / 49 loss=0.467, nll_loss=0.154, ppl=1.11, wps=28196.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.387, loss_scale=64, train_wall=195, gb_free=21.6, wall=50081
2022-03-06 04:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:16:43 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 15.36 | nll_loss 15.25 | ppl 38966.8 | wps 48211.1 | wpb 510.9 | bsz 1 | num_updates 21501 | best_loss 8.204
2022-03-06 04:16:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21501 updates
2022-03-06 04:16:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 442 @ 21501 updates, score 15.36) (writing took 1.687955570872873 seconds)
2022-03-06 04:16:44 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:16:44 | INFO | train | epoch 442 | loss 0.466 | nll_loss 0.154 | ppl 1.11 | wps 28169.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21501 | lr 0.000215661 | gnorm 0.385 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 50088
2022-03-06 04:16:44 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:16:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:18:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:18:35 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 15.445 | nll_loss 15.336 | ppl 41372.8 | wps 48230.2 | wpb 510.9 | bsz 1 | num_updates 21549 | best_loss 8.204
2022-03-06 04:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21549 updates
2022-03-06 04:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 443 @ 21549 updates, score 15.445) (writing took 1.7407946628518403 seconds)
2022-03-06 04:18:37 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:18:37 | INFO | train | epoch 443 | loss 0.467 | nll_loss 0.155 | ppl 1.11 | wps 27584.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 21549 | lr 0.00021542 | gnorm 0.391 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50201
2022-03-06 04:18:37 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:20:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:20:28 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 15.467 | nll_loss 15.361 | ppl 42078 | wps 48288.8 | wpb 510.9 | bsz 1 | num_updates 21598 | best_loss 8.204
2022-03-06 04:20:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21598 updates
2022-03-06 04:20:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:20:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:20:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 444 @ 21598 updates, score 15.467) (writing took 1.692607332020998 seconds)
2022-03-06 04:20:30 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:20:30 | INFO | train | epoch 444 | loss 0.466 | nll_loss 0.154 | ppl 1.11 | wps 28169.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21598 | lr 0.000215176 | gnorm 0.389 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50314
2022-03-06 04:20:30 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:20:34 | INFO | train_inner | epoch 445:      2 / 49 loss=0.467, nll_loss=0.154, ppl=1.11, wps=27166.2, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=21600, lr=0.000215166, gnorm=0.391, loss_scale=32, train_wall=196, gb_free=21.6, wall=50319
2022-03-06 04:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:22:21 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 15.421 | nll_loss 15.314 | ppl 40739.6 | wps 48022.5 | wpb 510.9 | bsz 1 | num_updates 21647 | best_loss 8.204
2022-03-06 04:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21647 updates
2022-03-06 04:22:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:22:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 445 @ 21647 updates, score 15.421) (writing took 1.716112616006285 seconds)
2022-03-06 04:22:23 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:22:23 | INFO | train | epoch 445 | loss 0.466 | nll_loss 0.154 | ppl 1.11 | wps 28123.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21647 | lr 0.000214932 | gnorm 0.385 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 50427
2022-03-06 04:22:23 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:23:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:24:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:24:14 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 15.426 | nll_loss 15.319 | ppl 40865.4 | wps 48237.7 | wpb 510.9 | bsz 1 | num_updates 21695 | best_loss 8.204
2022-03-06 04:24:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21695 updates
2022-03-06 04:24:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:24:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:24:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 446 @ 21695 updates, score 15.426) (writing took 1.7958241689484566 seconds)
2022-03-06 04:24:16 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:24:16 | INFO | train | epoch 446 | loss 0.466 | nll_loss 0.153 | ppl 1.11 | wps 27533.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21695 | lr 0.000214694 | gnorm 0.386 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50540
2022-03-06 04:24:16 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:24:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:24:27 | INFO | train_inner | epoch 447:      5 / 49 loss=0.466, nll_loss=0.153, ppl=1.11, wps=27886.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.386, loss_scale=32, train_wall=197, gb_free=21.6, wall=50551
2022-03-06 04:26:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:26:07 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 15.333 | nll_loss 15.225 | ppl 38305.7 | wps 48136.2 | wpb 510.9 | bsz 1 | num_updates 21744 | best_loss 8.204
2022-03-06 04:26:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21744 updates
2022-03-06 04:26:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:26:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:26:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 447 @ 21744 updates, score 15.333) (writing took 1.7242136730346829 seconds)
2022-03-06 04:26:09 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:26:09 | INFO | train | epoch 447 | loss 0.465 | nll_loss 0.153 | ppl 1.11 | wps 28123.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21744 | lr 0.000214452 | gnorm 0.382 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50653
2022-03-06 04:26:09 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:26:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:28:00 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 15.447 | nll_loss 15.339 | ppl 41440.5 | wps 48171.4 | wpb 510.9 | bsz 1 | num_updates 21793 | best_loss 8.204
2022-03-06 04:28:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21793 updates
2022-03-06 04:28:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:28:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:28:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 448 @ 21793 updates, score 15.447) (writing took 1.6917556300759315 seconds)
2022-03-06 04:28:02 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:28:02 | INFO | train | epoch 448 | loss 0.465 | nll_loss 0.153 | ppl 1.11 | wps 28129.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21793 | lr 0.000214211 | gnorm 0.38 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50766
2022-03-06 04:28:02 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:28:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:28:17 | INFO | train_inner | epoch 449:      7 / 49 loss=0.465, nll_loss=0.153, ppl=1.11, wps=28159.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21800, lr=0.000214176, gnorm=0.38, loss_scale=32, train_wall=196, gb_free=21.6, wall=50782
2022-03-06 04:28:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:29:53 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 15.412 | nll_loss 15.305 | ppl 40479.1 | wps 48080 | wpb 510.9 | bsz 1 | num_updates 21841 | best_loss 8.204
2022-03-06 04:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21841 updates
2022-03-06 04:29:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:29:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:29:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 449 @ 21841 updates, score 15.412) (writing took 1.7659773041959852 seconds)
2022-03-06 04:29:55 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:29:55 | INFO | train | epoch 449 | loss 0.464 | nll_loss 0.152 | ppl 1.11 | wps 27518.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21841 | lr 0.000213975 | gnorm 0.382 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50879
2022-03-06 04:29:55 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:29:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:31:46 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 15.375 | nll_loss 15.267 | ppl 39439.1 | wps 48291.1 | wpb 510.9 | bsz 1 | num_updates 21890 | best_loss 8.204
2022-03-06 04:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21890 updates
2022-03-06 04:31:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 450 @ 21890 updates, score 15.375) (writing took 1.6813571229577065 seconds)
2022-03-06 04:31:48 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:31:48 | INFO | train | epoch 450 | loss 0.464 | nll_loss 0.152 | ppl 1.11 | wps 28137.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21890 | lr 0.000213736 | gnorm 0.384 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 50992
2022-03-06 04:31:48 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:10 | INFO | train_inner | epoch 451:     10 / 49 loss=0.464, nll_loss=0.152, ppl=1.11, wps=27885.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.384, loss_scale=32, train_wall=197, gb_free=21.6, wall=51014
2022-03-06 04:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:33:39 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 15.385 | nll_loss 15.277 | ppl 39702.3 | wps 48190.8 | wpb 510.9 | bsz 1 | num_updates 21939 | best_loss 8.204
2022-03-06 04:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21939 updates
2022-03-06 04:33:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 451 @ 21939 updates, score 15.385) (writing took 1.665817097062245 seconds)
2022-03-06 04:33:41 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:33:41 | INFO | train | epoch 451 | loss 0.465 | nll_loss 0.153 | ppl 1.11 | wps 28119.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21939 | lr 0.000213497 | gnorm 0.388 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51105
2022-03-06 04:33:41 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:34:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:35:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:35:32 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 15.298 | nll_loss 15.189 | ppl 37352.5 | wps 48345.7 | wpb 510.9 | bsz 1 | num_updates 21987 | best_loss 8.204
2022-03-06 04:35:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21987 updates
2022-03-06 04:35:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 452 @ 21987 updates, score 15.298) (writing took 1.7766590830869973 seconds)
2022-03-06 04:35:34 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:35:34 | INFO | train | epoch 452 | loss 0.464 | nll_loss 0.152 | ppl 1.11 | wps 27553.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21987 | lr 0.000213264 | gnorm 0.38 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51218
2022-03-06 04:35:34 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:36:03 | INFO | train_inner | epoch 453:     13 / 49 loss=0.464, nll_loss=0.152, ppl=1.11, wps=27885.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.383, loss_scale=32, train_wall=198, gb_free=21.6, wall=51247
2022-03-06 04:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:37:25 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 15.457 | nll_loss 15.349 | ppl 41741.6 | wps 48514.5 | wpb 510.9 | bsz 1 | num_updates 22036 | best_loss 8.204
2022-03-06 04:37:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22036 updates
2022-03-06 04:37:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:37:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:37:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 453 @ 22036 updates, score 15.457) (writing took 1.7128881339449435 seconds)
2022-03-06 04:37:27 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:37:27 | INFO | train | epoch 453 | loss 0.463 | nll_loss 0.151 | ppl 1.11 | wps 28131.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22036 | lr 0.000213026 | gnorm 0.384 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51331
2022-03-06 04:37:27 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:37:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:39:18 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 15.353 | nll_loss 15.246 | ppl 38847.4 | wps 48181.8 | wpb 510.9 | bsz 1 | num_updates 22085 | best_loss 8.204
2022-03-06 04:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22085 updates
2022-03-06 04:39:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 454 @ 22085 updates, score 15.353) (writing took 1.696872560074553 seconds)
2022-03-06 04:39:20 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:39:20 | INFO | train | epoch 454 | loss 0.463 | nll_loss 0.151 | ppl 1.11 | wps 28143.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22085 | lr 0.00021279 | gnorm 0.382 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 51444
2022-03-06 04:39:20 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:39:53 | INFO | train_inner | epoch 455:     15 / 49 loss=0.463, nll_loss=0.151, ppl=1.11, wps=28178, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.382, loss_scale=64, train_wall=195, gb_free=21.6, wall=51477
2022-03-06 04:39:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:41:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:41:11 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 15.465 | nll_loss 15.357 | ppl 41966.9 | wps 48291.5 | wpb 510.9 | bsz 1 | num_updates 22133 | best_loss 8.204
2022-03-06 04:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22133 updates
2022-03-06 04:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 455 @ 22133 updates, score 15.465) (writing took 1.7371138578746468 seconds)
2022-03-06 04:41:13 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:41:13 | INFO | train | epoch 455 | loss 0.462 | nll_loss 0.15 | ppl 1.11 | wps 27537.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22133 | lr 0.000212559 | gnorm 0.381 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51557
2022-03-06 04:41:13 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:43:04 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 15.408 | nll_loss 15.3 | ppl 40343.2 | wps 48188.6 | wpb 510.9 | bsz 1 | num_updates 22182 | best_loss 8.204
2022-03-06 04:43:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22182 updates
2022-03-06 04:43:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:43:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:43:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 456 @ 22182 updates, score 15.408) (writing took 1.8088563601486385 seconds)
2022-03-06 04:43:06 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 04:43:06 | INFO | train | epoch 456 | loss 0.462 | nll_loss 0.15 | ppl 1.11 | wps 28080.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22182 | lr 0.000212324 | gnorm 0.38 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51670
2022-03-06 04:43:06 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 04:43:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:43:46 | INFO | train_inner | epoch 457:     18 / 49 loss=0.462, nll_loss=0.15, ppl=1.11, wps=27869.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.38, loss_scale=32, train_wall=197, gb_free=21.6, wall=51710
2022-03-06 04:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:57 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 15.373 | nll_loss 15.266 | ppl 39396.3 | wps 48177.6 | wpb 510.9 | bsz 1 | num_updates 22231 | best_loss 8.204
2022-03-06 04:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22231 updates
2022-03-06 04:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 457 @ 22231 updates, score 15.373) (writing took 1.6948863179422915 seconds)
2022-03-06 04:44:59 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 04:44:59 | INFO | train | epoch 457 | loss 0.462 | nll_loss 0.151 | ppl 1.11 | wps 28142.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22231 | lr 0.00021209 | gnorm 0.378 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 51783
2022-03-06 04:44:59 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 04:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:46:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:50 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 15.37 | nll_loss 15.264 | ppl 39343.2 | wps 48257.3 | wpb 510.9 | bsz 1 | num_updates 22279 | best_loss 8.204
2022-03-06 04:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22279 updates
2022-03-06 04:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:46:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 458 @ 22279 updates, score 15.37) (writing took 1.7762277929577976 seconds)
2022-03-06 04:46:52 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 04:46:52 | INFO | train | epoch 458 | loss 0.461 | nll_loss 0.15 | ppl 1.11 | wps 27537.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22279 | lr 0.000211862 | gnorm 0.378 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 51896
2022-03-06 04:46:52 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 04:46:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:47:38 | INFO | train_inner | epoch 459:     21 / 49 loss=0.461, nll_loss=0.15, ppl=1.11, wps=27898.3, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.378, loss_scale=32, train_wall=197, gb_free=21.6, wall=51942
2022-03-06 04:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:43 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 15.367 | nll_loss 15.26 | ppl 39241.8 | wps 48327.3 | wpb 510.9 | bsz 1 | num_updates 22328 | best_loss 8.204
2022-03-06 04:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22328 updates
2022-03-06 04:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 459 @ 22328 updates, score 15.367) (writing took 1.6972142818849534 seconds)
2022-03-06 04:48:45 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 04:48:45 | INFO | train | epoch 459 | loss 0.461 | nll_loss 0.15 | ppl 1.11 | wps 28155 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22328 | lr 0.000211629 | gnorm 0.375 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52009
2022-03-06 04:48:45 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 04:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:50:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:50:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:36 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 15.273 | nll_loss 15.165 | ppl 36746.1 | wps 48347.8 | wpb 510.9 | bsz 1 | num_updates 22376 | best_loss 8.204
2022-03-06 04:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22376 updates
2022-03-06 04:50:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:50:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 460 @ 22376 updates, score 15.273) (writing took 1.7407055210787803 seconds)
2022-03-06 04:50:38 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 04:50:38 | INFO | train | epoch 460 | loss 0.461 | nll_loss 0.15 | ppl 1.11 | wps 27535 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22376 | lr 0.000211402 | gnorm 0.382 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52122
2022-03-06 04:50:38 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 04:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:51:31 | INFO | train_inner | epoch 461:     24 / 49 loss=0.461, nll_loss=0.15, ppl=1.11, wps=27896.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.379, loss_scale=32, train_wall=197, gb_free=21.6, wall=52175
2022-03-06 04:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:52:29 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 15.374 | nll_loss 15.269 | ppl 39480.9 | wps 48212.3 | wpb 510.9 | bsz 1 | num_updates 22425 | best_loss 8.204
2022-03-06 04:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22425 updates
2022-03-06 04:52:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 461 @ 22425 updates, score 15.374) (writing took 1.7211650449316949 seconds)
2022-03-06 04:52:31 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 04:52:31 | INFO | train | epoch 461 | loss 0.46 | nll_loss 0.149 | ppl 1.11 | wps 28106.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22425 | lr 0.000211171 | gnorm 0.378 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52235
2022-03-06 04:52:31 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 04:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:54:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:54:23 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 15.373 | nll_loss 15.266 | ppl 39409 | wps 47650.4 | wpb 510.9 | bsz 1 | num_updates 22474 | best_loss 8.204
2022-03-06 04:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22474 updates
2022-03-06 04:54:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:54:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 462 @ 22474 updates, score 15.373) (writing took 1.724921170156449 seconds)
2022-03-06 04:54:24 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 04:54:24 | INFO | train | epoch 462 | loss 0.46 | nll_loss 0.148 | ppl 1.11 | wps 28068 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22474 | lr 0.00021094 | gnorm 0.373 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52348
2022-03-06 04:54:24 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 04:54:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:55:22 | INFO | train_inner | epoch 463:     26 / 49 loss=0.46, nll_loss=0.149, ppl=1.11, wps=28104.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.374, loss_scale=32, train_wall=196, gb_free=21.6, wall=52406
2022-03-06 04:55:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:16 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 15.359 | nll_loss 15.252 | ppl 39010.5 | wps 48164.9 | wpb 510.9 | bsz 1 | num_updates 22522 | best_loss 8.204
2022-03-06 04:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22522 updates
2022-03-06 04:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 463 @ 22522 updates, score 15.359) (writing took 1.7245053912047297 seconds)
2022-03-06 04:56:17 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 04:56:17 | INFO | train | epoch 463 | loss 0.46 | nll_loss 0.149 | ppl 1.11 | wps 27509.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22522 | lr 0.000210716 | gnorm 0.378 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52461
2022-03-06 04:56:17 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 04:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:58:09 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 15.382 | nll_loss 15.275 | ppl 39658.5 | wps 48108 | wpb 510.9 | bsz 1 | num_updates 22571 | best_loss 8.204
2022-03-06 04:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22571 updates
2022-03-06 04:58:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 04:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 464 @ 22571 updates, score 15.382) (writing took 1.7373071960173547 seconds)
2022-03-06 04:58:10 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 04:58:10 | INFO | train | epoch 464 | loss 0.459 | nll_loss 0.148 | ppl 1.11 | wps 28112.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22571 | lr 0.000210487 | gnorm 0.38 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52575
2022-03-06 04:58:10 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 04:58:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:59:14 | INFO | train_inner | epoch 465:     29 / 49 loss=0.459, nll_loss=0.148, ppl=1.11, wps=27889.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.379, loss_scale=32, train_wall=197, gb_free=21.6, wall=52638
2022-03-06 04:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:00:02 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 15.335 | nll_loss 15.227 | ppl 38351.1 | wps 48160.6 | wpb 510.9 | bsz 1 | num_updates 22620 | best_loss 8.204
2022-03-06 05:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22620 updates
2022-03-06 05:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:00:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 465 @ 22620 updates, score 15.335) (writing took 1.7163204341195524 seconds)
2022-03-06 05:00:03 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:00:03 | INFO | train | epoch 465 | loss 0.459 | nll_loss 0.148 | ppl 1.11 | wps 28131.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22620 | lr 0.000210259 | gnorm 0.377 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52688
2022-03-06 05:00:03 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:00:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:01:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:01:55 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 15.382 | nll_loss 15.277 | ppl 39699.8 | wps 48153.3 | wpb 510.9 | bsz 1 | num_updates 22668 | best_loss 8.204
2022-03-06 05:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22668 updates
2022-03-06 05:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 466 @ 22668 updates, score 15.382) (writing took 1.7323927818797529 seconds)
2022-03-06 05:01:56 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:01:56 | INFO | train | epoch 466 | loss 0.458 | nll_loss 0.147 | ppl 1.11 | wps 27553.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22668 | lr 0.000210036 | gnorm 0.377 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52800
2022-03-06 05:01:56 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:07 | INFO | train_inner | epoch 467:     32 / 49 loss=0.458, nll_loss=0.148, ppl=1.11, wps=27896.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.377, loss_scale=32, train_wall=197, gb_free=21.6, wall=52871
2022-03-06 05:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:03:48 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 15.383 | nll_loss 15.277 | ppl 39703.9 | wps 48310.1 | wpb 510.9 | bsz 1 | num_updates 22717 | best_loss 8.204
2022-03-06 05:03:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22717 updates
2022-03-06 05:03:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:03:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:03:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 467 @ 22717 updates, score 15.383) (writing took 1.7300197081640363 seconds)
2022-03-06 05:03:49 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:03:49 | INFO | train | epoch 467 | loss 0.458 | nll_loss 0.147 | ppl 1.11 | wps 28139.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22717 | lr 0.000209809 | gnorm 0.376 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 52913
2022-03-06 05:03:49 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:03:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:05:41 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 15.421 | nll_loss 15.314 | ppl 40723.6 | wps 48161.4 | wpb 510.9 | bsz 1 | num_updates 22766 | best_loss 8.204
2022-03-06 05:05:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22766 updates
2022-03-06 05:05:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 468 @ 22766 updates, score 15.421) (writing took 1.6925102600362152 seconds)
2022-03-06 05:05:42 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:05:42 | INFO | train | epoch 468 | loss 0.458 | nll_loss 0.147 | ppl 1.11 | wps 28111.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22766 | lr 0.000209583 | gnorm 0.372 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53026
2022-03-06 05:05:42 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:06:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:06:59 | INFO | train_inner | epoch 469:     35 / 49 loss=0.458, nll_loss=0.147, ppl=1.11, wps=27891.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.373, loss_scale=32, train_wall=197, gb_free=21.6, wall=53103
2022-03-06 05:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:34 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 15.406 | nll_loss 15.299 | ppl 40324.6 | wps 48287.9 | wpb 510.9 | bsz 1 | num_updates 22814 | best_loss 8.204
2022-03-06 05:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22814 updates
2022-03-06 05:07:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 469 @ 22814 updates, score 15.406) (writing took 1.6868000261019915 seconds)
2022-03-06 05:07:35 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:07:35 | INFO | train | epoch 469 | loss 0.457 | nll_loss 0.146 | ppl 1.11 | wps 27563.7 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 22814 | lr 0.000209363 | gnorm 0.373 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53139
2022-03-06 05:07:35 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:09:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:26 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 15.431 | nll_loss 15.325 | ppl 41055.2 | wps 48374.5 | wpb 510.9 | bsz 1 | num_updates 22863 | best_loss 8.204
2022-03-06 05:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22863 updates
2022-03-06 05:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 470 @ 22863 updates, score 15.431) (writing took 1.6481463930103928 seconds)
2022-03-06 05:09:28 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:09:28 | INFO | train | epoch 470 | loss 0.457 | nll_loss 0.147 | ppl 1.11 | wps 28163.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22863 | lr 0.000209138 | gnorm 0.375 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53252
2022-03-06 05:09:28 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:10:50 | INFO | train_inner | epoch 471:     37 / 49 loss=0.457, nll_loss=0.147, ppl=1.11, wps=28181.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.374, loss_scale=32, train_wall=196, gb_free=21.6, wall=53334
2022-03-06 05:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:19 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 15.48 | nll_loss 15.375 | ppl 42485.2 | wps 48348.7 | wpb 510.9 | bsz 1 | num_updates 22912 | best_loss 8.204
2022-03-06 05:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22912 updates
2022-03-06 05:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 471 @ 22912 updates, score 15.48) (writing took 1.6484732190147042 seconds)
2022-03-06 05:11:21 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:11:21 | INFO | train | epoch 471 | loss 0.457 | nll_loss 0.147 | ppl 1.11 | wps 28152.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22912 | lr 0.000208914 | gnorm 0.373 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53365
2022-03-06 05:11:21 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:11:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:13:12 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 15.363 | nll_loss 15.258 | ppl 39175.2 | wps 48425.9 | wpb 510.9 | bsz 1 | num_updates 22960 | best_loss 8.204
2022-03-06 05:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22960 updates
2022-03-06 05:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:13:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:13:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 472 @ 22960 updates, score 15.363) (writing took 1.7150215301662683 seconds)
2022-03-06 05:13:14 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:13:14 | INFO | train | epoch 472 | loss 0.456 | nll_loss 0.146 | ppl 1.11 | wps 27544.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22960 | lr 0.000208696 | gnorm 0.372 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53478
2022-03-06 05:13:14 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:13:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:14:42 | INFO | train_inner | epoch 473:     40 / 49 loss=0.456, nll_loss=0.146, ppl=1.11, wps=27905.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.374, loss_scale=32, train_wall=197, gb_free=21.6, wall=53566
2022-03-06 05:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:15:05 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 15.461 | nll_loss 15.355 | ppl 41919 | wps 48403.9 | wpb 510.9 | bsz 1 | num_updates 23009 | best_loss 8.204
2022-03-06 05:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23009 updates
2022-03-06 05:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 473 @ 23009 updates, score 15.461) (writing took 1.6715333249885589 seconds)
2022-03-06 05:15:07 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:15:07 | INFO | train | epoch 473 | loss 0.457 | nll_loss 0.146 | ppl 1.11 | wps 28146.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23009 | lr 0.000208474 | gnorm 0.377 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53591
2022-03-06 05:15:07 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:16:58 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 15.373 | nll_loss 15.267 | ppl 39425.3 | wps 48235.6 | wpb 510.9 | bsz 1 | num_updates 23058 | best_loss 8.204
2022-03-06 05:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23058 updates
2022-03-06 05:16:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 474 @ 23058 updates, score 15.373) (writing took 1.6562409289181232 seconds)
2022-03-06 05:17:00 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:17:00 | INFO | train | epoch 474 | loss 0.457 | nll_loss 0.146 | ppl 1.11 | wps 28133.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23058 | lr 0.000208252 | gnorm 0.373 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 53704
2022-03-06 05:17:00 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:18:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:18:34 | INFO | train_inner | epoch 475:     43 / 49 loss=0.456, nll_loss=0.146, ppl=1.11, wps=27913.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.372, loss_scale=32, train_wall=197, gb_free=21.6, wall=53798
2022-03-06 05:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:18:51 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 15.411 | nll_loss 15.305 | ppl 40493.3 | wps 48282.5 | wpb 510.9 | bsz 1 | num_updates 23106 | best_loss 8.204
2022-03-06 05:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23106 updates
2022-03-06 05:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 475 @ 23106 updates, score 15.411) (writing took 1.7007250820752233 seconds)
2022-03-06 05:18:53 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:18:53 | INFO | train | epoch 475 | loss 0.455 | nll_loss 0.145 | ppl 1.11 | wps 27561.1 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23106 | lr 0.000208036 | gnorm 0.37 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53817
2022-03-06 05:18:53 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:20:44 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 15.345 | nll_loss 15.239 | ppl 38667.2 | wps 48324.7 | wpb 510.9 | bsz 1 | num_updates 23155 | best_loss 8.204
2022-03-06 05:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23155 updates
2022-03-06 05:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 476 @ 23155 updates, score 15.345) (writing took 1.6783738499507308 seconds)
2022-03-06 05:20:46 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:20:46 | INFO | train | epoch 476 | loss 0.455 | nll_loss 0.145 | ppl 1.11 | wps 28158.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23155 | lr 0.000207815 | gnorm 0.373 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 53930
2022-03-06 05:20:46 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:22:25 | INFO | train_inner | epoch 477:     45 / 49 loss=0.454, nll_loss=0.144, ppl=1.11, wps=28173.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.371, loss_scale=32, train_wall=195, gb_free=21.6, wall=54029
2022-03-06 05:22:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:22:37 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 15.292 | nll_loss 15.186 | ppl 37284.3 | wps 48170.3 | wpb 510.9 | bsz 1 | num_updates 23204 | best_loss 8.204
2022-03-06 05:22:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23204 updates
2022-03-06 05:22:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:22:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 477 @ 23204 updates, score 15.292) (writing took 1.6461942899040878 seconds)
2022-03-06 05:22:39 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:22:39 | INFO | train | epoch 477 | loss 0.454 | nll_loss 0.144 | ppl 1.11 | wps 28149.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23204 | lr 0.000207596 | gnorm 0.368 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54043
2022-03-06 05:22:39 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:22:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:23:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:24:30 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 15.413 | nll_loss 15.308 | ppl 40564.6 | wps 48410.2 | wpb 510.9 | bsz 1 | num_updates 23252 | best_loss 8.204
2022-03-06 05:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23252 updates
2022-03-06 05:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 478 @ 23252 updates, score 15.413) (writing took 1.7038213398773223 seconds)
2022-03-06 05:24:31 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:24:31 | INFO | train | epoch 478 | loss 0.454 | nll_loss 0.144 | ppl 1.11 | wps 27568.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23252 | lr 0.000207381 | gnorm 0.368 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54156
2022-03-06 05:24:32 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:17 | INFO | train_inner | epoch 479:     48 / 49 loss=0.454, nll_loss=0.144, ppl=1.11, wps=27913.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.369, loss_scale=32, train_wall=197, gb_free=21.6, wall=54261
2022-03-06 05:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:23 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 15.416 | nll_loss 15.312 | ppl 40672.9 | wps 48304.1 | wpb 510.9 | bsz 1 | num_updates 23301 | best_loss 8.204
2022-03-06 05:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23301 updates
2022-03-06 05:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 479 @ 23301 updates, score 15.416) (writing took 1.6986028661485761 seconds)
2022-03-06 05:26:24 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:26:24 | INFO | train | epoch 479 | loss 0.454 | nll_loss 0.144 | ppl 1.11 | wps 28135.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23301 | lr 0.000207163 | gnorm 0.369 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54269
2022-03-06 05:26:24 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:16 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 15.427 | nll_loss 15.323 | ppl 40990 | wps 48582.3 | wpb 510.9 | bsz 1 | num_updates 23350 | best_loss 8.204
2022-03-06 05:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23350 updates
2022-03-06 05:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 480 @ 23350 updates, score 15.427) (writing took 1.658479035133496 seconds)
2022-03-06 05:28:17 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:28:17 | INFO | train | epoch 480 | loss 0.453 | nll_loss 0.144 | ppl 1.1 | wps 28157.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23350 | lr 0.000206946 | gnorm 0.364 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 54381
2022-03-06 05:28:17 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:29:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:30:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:09 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 15.426 | nll_loss 15.32 | ppl 40917.7 | wps 48395.2 | wpb 510.9 | bsz 1 | num_updates 23398 | best_loss 8.204
2022-03-06 05:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23398 updates
2022-03-06 05:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:30:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 481 @ 23398 updates, score 15.426) (writing took 1.7020388739183545 seconds)
2022-03-06 05:30:10 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:30:10 | INFO | train | epoch 481 | loss 0.454 | nll_loss 0.144 | ppl 1.11 | wps 27545.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23398 | lr 0.000206733 | gnorm 0.372 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54494
2022-03-06 05:30:10 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:30:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:30:15 | INFO | train_inner | epoch 482:      2 / 49 loss=0.454, nll_loss=0.144, ppl=1.1, wps=27146.8, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=23400, lr=0.000206725, gnorm=0.369, loss_scale=32, train_wall=197, gb_free=21.6, wall=54499
2022-03-06 05:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:02 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 15.37 | nll_loss 15.265 | ppl 39366.6 | wps 48213.5 | wpb 510.9 | bsz 1 | num_updates 23447 | best_loss 8.204
2022-03-06 05:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23447 updates
2022-03-06 05:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 482 @ 23447 updates, score 15.37) (writing took 1.6811745890881866 seconds)
2022-03-06 05:32:03 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:32:03 | INFO | train | epoch 482 | loss 0.454 | nll_loss 0.144 | ppl 1.11 | wps 28111.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23447 | lr 0.000206517 | gnorm 0.368 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54607
2022-03-06 05:32:03 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:33:54 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 15.389 | nll_loss 15.282 | ppl 39844.9 | wps 48331.1 | wpb 510.9 | bsz 1 | num_updates 23496 | best_loss 8.204
2022-03-06 05:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23496 updates
2022-03-06 05:33:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 483 @ 23496 updates, score 15.389) (writing took 1.6398642230778933 seconds)
2022-03-06 05:33:56 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:33:56 | INFO | train | epoch 483 | loss 0.453 | nll_loss 0.144 | ppl 1.1 | wps 28204.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23496 | lr 0.000206302 | gnorm 0.368 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54720
2022-03-06 05:33:56 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:34:05 | INFO | train_inner | epoch 484:      4 / 49 loss=0.454, nll_loss=0.144, ppl=1.1, wps=28192.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.368, loss_scale=64, train_wall=195, gb_free=21.6, wall=54729
2022-03-06 05:34:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:35:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:35:47 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 15.536 | nll_loss 15.432 | ppl 44203.8 | wps 48517.4 | wpb 510.9 | bsz 1 | num_updates 23544 | best_loss 8.204
2022-03-06 05:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23544 updates
2022-03-06 05:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 484 @ 23544 updates, score 15.536) (writing took 1.6797561659477651 seconds)
2022-03-06 05:35:49 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:35:49 | INFO | train | epoch 484 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 27615.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23544 | lr 0.000206091 | gnorm 0.37 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54833
2022-03-06 05:35:49 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:37:40 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 15.449 | nll_loss 15.345 | ppl 41606.8 | wps 48279 | wpb 510.9 | bsz 1 | num_updates 23593 | best_loss 8.204
2022-03-06 05:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23593 updates
2022-03-06 05:37:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 485 @ 23593 updates, score 15.449) (writing took 1.6805971211288124 seconds)
2022-03-06 05:37:41 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:37:41 | INFO | train | epoch 485 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 28214.4 | ups 0.44 | wpb 64858.2 | bsz 126.7 | num_updates 23593 | lr 0.000205877 | gnorm 0.369 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 54945
2022-03-06 05:37:41 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:37:57 | INFO | train_inner | epoch 486:      7 / 49 loss=0.452, nll_loss=0.142, ppl=1.1, wps=27973.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.369, loss_scale=32, train_wall=197, gb_free=21.6, wall=54961
2022-03-06 05:39:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:39:32 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 15.424 | nll_loss 15.32 | ppl 40892 | wps 48611.9 | wpb 510.9 | bsz 1 | num_updates 23642 | best_loss 8.204
2022-03-06 05:39:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23642 updates
2022-03-06 05:39:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:39:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 486 @ 23642 updates, score 15.424) (writing took 1.687282646074891 seconds)
2022-03-06 05:39:34 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:39:34 | INFO | train | epoch 486 | loss 0.452 | nll_loss 0.143 | ppl 1.1 | wps 28205 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23642 | lr 0.000205664 | gnorm 0.369 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 55058
2022-03-06 05:39:34 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:40:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:41:25 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 15.438 | nll_loss 15.334 | ppl 41291.9 | wps 48374.9 | wpb 510.9 | bsz 1 | num_updates 23690 | best_loss 8.204
2022-03-06 05:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23690 updates
2022-03-06 05:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 487 @ 23690 updates, score 15.438) (writing took 1.6937091930303723 seconds)
2022-03-06 05:41:27 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:41:27 | INFO | train | epoch 487 | loss 0.451 | nll_loss 0.142 | ppl 1.1 | wps 27632.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23690 | lr 0.000205455 | gnorm 0.364 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55171
2022-03-06 05:41:27 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:41:49 | INFO | train_inner | epoch 488:     10 / 49 loss=0.452, nll_loss=0.142, ppl=1.1, wps=27966.5, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.367, loss_scale=32, train_wall=197, gb_free=21.6, wall=55193
2022-03-06 05:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:18 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 15.417 | nll_loss 15.313 | ppl 40693.5 | wps 48430 | wpb 510.9 | bsz 1 | num_updates 23739 | best_loss 8.204
2022-03-06 05:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23739 updates
2022-03-06 05:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:43:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:43:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 488 @ 23739 updates, score 15.417) (writing took 1.7836359129287302 seconds)
2022-03-06 05:43:20 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 05:43:20 | INFO | train | epoch 488 | loss 0.452 | nll_loss 0.142 | ppl 1.1 | wps 28159.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23739 | lr 0.000205243 | gnorm 0.371 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55284
2022-03-06 05:43:20 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 05:43:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:11 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 15.4 | nll_loss 15.295 | ppl 40191.1 | wps 48435.8 | wpb 510.9 | bsz 1 | num_updates 23788 | best_loss 8.204
2022-03-06 05:45:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23788 updates
2022-03-06 05:45:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 489 @ 23788 updates, score 15.4) (writing took 1.7022880848962814 seconds)
2022-03-06 05:45:12 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 05:45:12 | INFO | train | epoch 489 | loss 0.451 | nll_loss 0.142 | ppl 1.1 | wps 28181.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23788 | lr 0.000205032 | gnorm 0.367 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55396
2022-03-06 05:45:12 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 05:45:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:39 | INFO | train_inner | epoch 490:     12 / 49 loss=0.451, nll_loss=0.142, ppl=1.1, wps=28211.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.368, loss_scale=64, train_wall=195, gb_free=21.6, wall=55423
2022-03-06 05:46:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:47:03 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 15.376 | nll_loss 15.272 | ppl 39555.3 | wps 48432 | wpb 510.9 | bsz 1 | num_updates 23836 | best_loss 8.204
2022-03-06 05:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23836 updates
2022-03-06 05:47:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 490 @ 23836 updates, score 15.376) (writing took 1.7542551970109344 seconds)
2022-03-06 05:47:05 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 05:47:05 | INFO | train | epoch 490 | loss 0.451 | nll_loss 0.141 | ppl 1.1 | wps 27595.1 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23836 | lr 0.000204825 | gnorm 0.364 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55509
2022-03-06 05:47:05 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 05:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:48:56 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 15.405 | nll_loss 15.3 | ppl 40340.5 | wps 48296.3 | wpb 510.9 | bsz 1 | num_updates 23885 | best_loss 8.204
2022-03-06 05:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23885 updates
2022-03-06 05:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:48:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 491 @ 23885 updates, score 15.405) (writing took 1.696027701953426 seconds)
2022-03-06 05:48:58 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 05:48:58 | INFO | train | epoch 491 | loss 0.45 | nll_loss 0.141 | ppl 1.1 | wps 28187.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23885 | lr 0.000204615 | gnorm 0.366 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55622
2022-03-06 05:48:58 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 05:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:49:31 | INFO | train_inner | epoch 492:     15 / 49 loss=0.45, nll_loss=0.141, ppl=1.1, wps=27942.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.365, loss_scale=32, train_wall=197, gb_free=21.6, wall=55655
2022-03-06 05:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:50:49 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 15.379 | nll_loss 15.273 | ppl 39582.8 | wps 48171.1 | wpb 510.9 | bsz 1 | num_updates 23934 | best_loss 8.204
2022-03-06 05:50:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23934 updates
2022-03-06 05:50:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:50:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:50:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 492 @ 23934 updates, score 15.379) (writing took 1.6976343891583383 seconds)
2022-03-06 05:50:51 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 05:50:51 | INFO | train | epoch 492 | loss 0.45 | nll_loss 0.141 | ppl 1.1 | wps 28179.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23934 | lr 0.000204405 | gnorm 0.367 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55735
2022-03-06 05:50:51 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 05:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:52:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:52:42 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 15.434 | nll_loss 15.33 | ppl 41197.4 | wps 47997.1 | wpb 510.9 | bsz 1 | num_updates 23982 | best_loss 8.204
2022-03-06 05:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23982 updates
2022-03-06 05:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:52:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 493 @ 23982 updates, score 15.434) (writing took 1.7495206920430064 seconds)
2022-03-06 05:52:43 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 05:52:43 | INFO | train | epoch 493 | loss 0.45 | nll_loss 0.141 | ppl 1.1 | wps 27591.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 23982 | lr 0.000204201 | gnorm 0.37 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55848
2022-03-06 05:52:43 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 05:52:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:53:23 | INFO | train_inner | epoch 494:     18 / 49 loss=0.45, nll_loss=0.141, ppl=1.1, wps=27940.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.369, loss_scale=32, train_wall=197, gb_free=21.6, wall=55887
2022-03-06 05:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:54:35 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 15.346 | nll_loss 15.241 | ppl 38727.6 | wps 48123.1 | wpb 510.9 | bsz 1 | num_updates 24031 | best_loss 8.204
2022-03-06 05:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24031 updates
2022-03-06 05:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 494 @ 24031 updates, score 15.346) (writing took 1.7180856380145997 seconds)
2022-03-06 05:54:36 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 05:54:36 | INFO | train | epoch 494 | loss 0.45 | nll_loss 0.141 | ppl 1.1 | wps 28160.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24031 | lr 0.000203992 | gnorm 0.362 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 55960
2022-03-06 05:54:36 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 05:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:56:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:56:27 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 15.444 | nll_loss 15.341 | ppl 41491.3 | wps 48639.8 | wpb 510.9 | bsz 1 | num_updates 24080 | best_loss 8.204
2022-03-06 05:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24080 updates
2022-03-06 05:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:56:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 495 @ 24080 updates, score 15.444) (writing took 1.7115027969703078 seconds)
2022-03-06 05:56:29 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 05:56:29 | INFO | train | epoch 495 | loss 0.449 | nll_loss 0.14 | ppl 1.1 | wps 28194.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24080 | lr 0.000203785 | gnorm 0.36 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56073
2022-03-06 05:56:29 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 05:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:57:13 | INFO | train_inner | epoch 496:     20 / 49 loss=0.449, nll_loss=0.14, ppl=1.1, wps=28212.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.361, loss_scale=64, train_wall=195, gb_free=21.6, wall=56117
2022-03-06 05:57:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:58:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:58:20 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 15.309 | nll_loss 15.203 | ppl 37716.1 | wps 48699.5 | wpb 510.9 | bsz 1 | num_updates 24128 | best_loss 8.204
2022-03-06 05:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24128 updates
2022-03-06 05:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 05:58:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 496 @ 24128 updates, score 15.309) (writing took 1.7820521180983633 seconds)
2022-03-06 05:58:22 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 05:58:22 | INFO | train | epoch 496 | loss 0.449 | nll_loss 0.14 | ppl 1.1 | wps 27592 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 24128 | lr 0.000203582 | gnorm 0.366 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56186
2022-03-06 05:58:22 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 05:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:00:13 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 15.448 | nll_loss 15.344 | ppl 41588.8 | wps 48150.3 | wpb 510.9 | bsz 1 | num_updates 24177 | best_loss 8.204
2022-03-06 06:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24177 updates
2022-03-06 06:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 497 @ 24177 updates, score 15.448) (writing took 1.7226313140708953 seconds)
2022-03-06 06:00:15 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:00:15 | INFO | train | epoch 497 | loss 0.448 | nll_loss 0.14 | ppl 1.1 | wps 28183.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24177 | lr 0.000203376 | gnorm 0.363 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56299
2022-03-06 06:00:15 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:01:05 | INFO | train_inner | epoch 498:     23 / 49 loss=0.449, nll_loss=0.14, ppl=1.1, wps=27940.6, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.363, loss_scale=32, train_wall=197, gb_free=21.6, wall=56349
2022-03-06 06:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:06 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 15.393 | nll_loss 15.29 | ppl 40056.1 | wps 48349.2 | wpb 510.9 | bsz 1 | num_updates 24226 | best_loss 8.204
2022-03-06 06:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24226 updates
2022-03-06 06:02:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 498 @ 24226 updates, score 15.393) (writing took 1.711002625990659 seconds)
2022-03-06 06:02:07 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:02:07 | INFO | train | epoch 498 | loss 0.448 | nll_loss 0.139 | ppl 1.1 | wps 28184 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24226 | lr 0.00020317 | gnorm 0.361 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56411
2022-03-06 06:02:07 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:02:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:03:59 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 15.426 | nll_loss 15.322 | ppl 40950.1 | wps 48305.5 | wpb 510.9 | bsz 1 | num_updates 24274 | best_loss 8.204
2022-03-06 06:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24274 updates
2022-03-06 06:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 499 @ 24274 updates, score 15.426) (writing took 1.7464813580736518 seconds)
2022-03-06 06:04:00 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:04:00 | INFO | train | epoch 499 | loss 0.447 | nll_loss 0.139 | ppl 1.1 | wps 27556.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24274 | lr 0.000202969 | gnorm 0.36 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56524
2022-03-06 06:04:00 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:04:57 | INFO | train_inner | epoch 500:     26 / 49 loss=0.448, nll_loss=0.139, ppl=1.1, wps=27930.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.361, loss_scale=32, train_wall=197, gb_free=21.6, wall=56582
2022-03-06 06:05:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:05:51 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 15.411 | nll_loss 15.307 | ppl 40524.8 | wps 48181.6 | wpb 510.9 | bsz 1 | num_updates 24323 | best_loss 8.204
2022-03-06 06:05:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24323 updates
2022-03-06 06:05:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:05:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:05:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 500 @ 24323 updates, score 15.411) (writing took 1.7163598991464823 seconds)
2022-03-06 06:05:53 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:05:53 | INFO | train | epoch 500 | loss 0.448 | nll_loss 0.14 | ppl 1.1 | wps 28159.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24323 | lr 0.000202764 | gnorm 0.362 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56637
2022-03-06 06:05:53 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:05:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:07:44 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 15.433 | nll_loss 15.33 | ppl 41194.2 | wps 48036.3 | wpb 510.9 | bsz 1 | num_updates 24372 | best_loss 8.204
2022-03-06 06:07:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24372 updates
2022-03-06 06:07:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:07:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 501 @ 24372 updates, score 15.433) (writing took 1.7060649709310383 seconds)
2022-03-06 06:07:46 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:07:46 | INFO | train | epoch 501 | loss 0.447 | nll_loss 0.138 | ppl 1.1 | wps 28163.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24372 | lr 0.00020256 | gnorm 0.359 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 56750
2022-03-06 06:07:46 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:07:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:08:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:08:50 | INFO | train_inner | epoch 502:     29 / 49 loss=0.447, nll_loss=0.139, ppl=1.1, wps=27916.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.36, loss_scale=32, train_wall=197, gb_free=21.6, wall=56814
2022-03-06 06:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:09:37 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 15.29 | nll_loss 15.184 | ppl 37231.2 | wps 48395.4 | wpb 510.9 | bsz 1 | num_updates 24420 | best_loss 8.204
2022-03-06 06:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24420 updates
2022-03-06 06:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 502 @ 24420 updates, score 15.29) (writing took 1.756527045974508 seconds)
2022-03-06 06:09:39 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:09:39 | INFO | train | epoch 502 | loss 0.447 | nll_loss 0.139 | ppl 1.1 | wps 27563.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 24420 | lr 0.000202361 | gnorm 0.367 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56863
2022-03-06 06:09:39 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:11:30 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 15.405 | nll_loss 15.301 | ppl 40358.9 | wps 47635.5 | wpb 510.9 | bsz 1 | num_updates 24469 | best_loss 8.204
2022-03-06 06:11:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24469 updates
2022-03-06 06:11:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:11:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:11:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 503 @ 24469 updates, score 15.405) (writing took 1.7280448011588305 seconds)
2022-03-06 06:11:32 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:11:32 | INFO | train | epoch 503 | loss 0.447 | nll_loss 0.138 | ppl 1.1 | wps 28140.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24469 | lr 0.000202158 | gnorm 0.361 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 56976
2022-03-06 06:11:32 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:12:40 | INFO | train_inner | epoch 504:     31 / 49 loss=0.447, nll_loss=0.139, ppl=1.1, wps=28179.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.363, loss_scale=32, train_wall=195, gb_free=21.6, wall=57044
2022-03-06 06:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:13:23 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 15.472 | nll_loss 15.369 | ppl 42315.6 | wps 48212.8 | wpb 510.9 | bsz 1 | num_updates 24518 | best_loss 8.204
2022-03-06 06:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24518 updates
2022-03-06 06:13:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:13:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 504 @ 24518 updates, score 15.472) (writing took 1.705549234058708 seconds)
2022-03-06 06:13:25 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:13:25 | INFO | train | epoch 504 | loss 0.447 | nll_loss 0.138 | ppl 1.1 | wps 28153 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24518 | lr 0.000201956 | gnorm 0.359 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57089
2022-03-06 06:13:25 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:15:16 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 15.426 | nll_loss 15.322 | ppl 40975.1 | wps 48312.3 | wpb 510.9 | bsz 1 | num_updates 24566 | best_loss 8.204
2022-03-06 06:15:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24566 updates
2022-03-06 06:15:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 505 @ 24566 updates, score 15.426) (writing took 1.7212235641200095 seconds)
2022-03-06 06:15:18 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:15:18 | INFO | train | epoch 505 | loss 0.446 | nll_loss 0.137 | ppl 1.1 | wps 27542.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24566 | lr 0.000201759 | gnorm 0.358 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57202
2022-03-06 06:15:18 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:16:32 | INFO | train_inner | epoch 506:     34 / 49 loss=0.446, nll_loss=0.138, ppl=1.1, wps=27909.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.358, loss_scale=32, train_wall=197, gb_free=21.6, wall=57277
2022-03-06 06:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:17:09 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 15.379 | nll_loss 15.274 | ppl 39634.4 | wps 48573.2 | wpb 510.9 | bsz 1 | num_updates 24615 | best_loss 8.204
2022-03-06 06:17:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24615 updates
2022-03-06 06:17:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:17:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:17:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 506 @ 24615 updates, score 15.379) (writing took 1.7080064020119607 seconds)
2022-03-06 06:17:11 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:17:11 | INFO | train | epoch 506 | loss 0.446 | nll_loss 0.138 | ppl 1.1 | wps 28176.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24615 | lr 0.000201558 | gnorm 0.357 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57315
2022-03-06 06:17:11 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:17:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:19:02 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 15.374 | nll_loss 15.269 | ppl 39477.9 | wps 48573.1 | wpb 510.9 | bsz 1 | num_updates 24664 | best_loss 8.204
2022-03-06 06:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24664 updates
2022-03-06 06:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:19:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 507 @ 24664 updates, score 15.374) (writing took 1.7044587021227926 seconds)
2022-03-06 06:19:03 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:19:03 | INFO | train | epoch 507 | loss 0.446 | nll_loss 0.138 | ppl 1.1 | wps 28201.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24664 | lr 0.000201358 | gnorm 0.363 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 57427
2022-03-06 06:19:03 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:19:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:20:24 | INFO | train_inner | epoch 508:     37 / 49 loss=0.446, nll_loss=0.137, ppl=1.1, wps=27958.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.359, loss_scale=32, train_wall=197, gb_free=21.6, wall=57509
2022-03-06 06:20:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:54 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 15.308 | nll_loss 15.202 | ppl 37701.6 | wps 48394.1 | wpb 510.9 | bsz 1 | num_updates 24712 | best_loss 8.204
2022-03-06 06:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24712 updates
2022-03-06 06:20:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 508 @ 24712 updates, score 15.308) (writing took 1.7568686010781676 seconds)
2022-03-06 06:20:56 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:20:56 | INFO | train | epoch 508 | loss 0.445 | nll_loss 0.137 | ppl 1.1 | wps 27592.3 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 24712 | lr 0.000201162 | gnorm 0.357 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57540
2022-03-06 06:20:56 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:22:47 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 15.286 | nll_loss 15.182 | ppl 37183.2 | wps 48334.3 | wpb 510.9 | bsz 1 | num_updates 24761 | best_loss 8.204
2022-03-06 06:22:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24761 updates
2022-03-06 06:22:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:22:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:22:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 509 @ 24761 updates, score 15.286) (writing took 1.7269899500533938 seconds)
2022-03-06 06:22:49 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:22:49 | INFO | train | epoch 509 | loss 0.445 | nll_loss 0.137 | ppl 1.1 | wps 28188.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24761 | lr 0.000200963 | gnorm 0.358 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57653
2022-03-06 06:22:49 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:22:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:24:14 | INFO | train_inner | epoch 510:     39 / 49 loss=0.445, nll_loss=0.137, ppl=1.1, wps=28212.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.36, loss_scale=32, train_wall=195, gb_free=21.6, wall=57739
2022-03-06 06:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:24:40 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 15.291 | nll_loss 15.186 | ppl 37271.1 | wps 48380.5 | wpb 510.9 | bsz 1 | num_updates 24810 | best_loss 8.204
2022-03-06 06:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24810 updates
2022-03-06 06:24:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:24:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:24:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 510 @ 24810 updates, score 15.291) (writing took 1.6964406841434538 seconds)
2022-03-06 06:24:42 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:24:42 | INFO | train | epoch 510 | loss 0.445 | nll_loss 0.137 | ppl 1.1 | wps 28183 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24810 | lr 0.000200764 | gnorm 0.363 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 57766
2022-03-06 06:24:42 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:24:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:26:33 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 15.349 | nll_loss 15.245 | ppl 38823.2 | wps 48580.6 | wpb 510.9 | bsz 1 | num_updates 24858 | best_loss 8.204
2022-03-06 06:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24858 updates
2022-03-06 06:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 511 @ 24858 updates, score 15.349) (writing took 1.7297634021379054 seconds)
2022-03-06 06:26:34 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:26:34 | INFO | train | epoch 511 | loss 0.444 | nll_loss 0.136 | ppl 1.1 | wps 27612.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 24858 | lr 0.00020057 | gnorm 0.357 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57878
2022-03-06 06:26:34 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:28:06 | INFO | train_inner | epoch 512:     42 / 49 loss=0.445, nll_loss=0.137, ppl=1.1, wps=27958.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.358, loss_scale=32, train_wall=197, gb_free=21.6, wall=57971
2022-03-06 06:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:28:25 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 15.326 | nll_loss 15.223 | ppl 38243.9 | wps 48537 | wpb 510.9 | bsz 1 | num_updates 24907 | best_loss 8.204
2022-03-06 06:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24907 updates
2022-03-06 06:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:28:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 512 @ 24907 updates, score 15.326) (writing took 1.7275820220820606 seconds)
2022-03-06 06:28:27 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:28:27 | INFO | train | epoch 512 | loss 0.445 | nll_loss 0.137 | ppl 1.1 | wps 28188.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24907 | lr 0.000200373 | gnorm 0.358 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 57991
2022-03-06 06:28:27 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:29:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:30:18 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 15.233 | nll_loss 15.127 | ppl 35794.1 | wps 48165 | wpb 510.9 | bsz 1 | num_updates 24955 | best_loss 8.204
2022-03-06 06:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24955 updates
2022-03-06 06:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:30:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:30:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 513 @ 24955 updates, score 15.233) (writing took 1.7154896080028266 seconds)
2022-03-06 06:30:20 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:30:20 | INFO | train | epoch 513 | loss 0.444 | nll_loss 0.136 | ppl 1.1 | wps 27603.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 24955 | lr 0.00020018 | gnorm 0.356 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58104
2022-03-06 06:30:20 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:30:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:31:59 | INFO | train_inner | epoch 514:     45 / 49 loss=0.444, nll_loss=0.136, ppl=1.1, wps=27951.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.357, loss_scale=32, train_wall=197, gb_free=21.6, wall=58203
2022-03-06 06:32:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:32:11 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 15.29 | nll_loss 15.186 | ppl 37267.1 | wps 48309.2 | wpb 510.9 | bsz 1 | num_updates 25004 | best_loss 8.204
2022-03-06 06:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25004 updates
2022-03-06 06:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:32:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:32:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 514 @ 25004 updates, score 15.29) (writing took 1.7283460749313235 seconds)
2022-03-06 06:32:13 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:32:13 | INFO | train | epoch 514 | loss 0.444 | nll_loss 0.136 | ppl 1.1 | wps 28181.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25004 | lr 0.000199984 | gnorm 0.357 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58217
2022-03-06 06:32:13 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:33:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:34:04 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 15.218 | nll_loss 15.112 | ppl 35423.2 | wps 47950.1 | wpb 510.9 | bsz 1 | num_updates 25053 | best_loss 8.204
2022-03-06 06:34:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25053 updates
2022-03-06 06:34:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 515 @ 25053 updates, score 15.218) (writing took 1.7288084151223302 seconds)
2022-03-06 06:34:05 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:34:05 | INFO | train | epoch 515 | loss 0.444 | nll_loss 0.136 | ppl 1.1 | wps 28161.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25053 | lr 0.000199788 | gnorm 0.355 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58330
2022-03-06 06:34:05 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:35:49 | INFO | train_inner | epoch 516:     47 / 49 loss=0.443, nll_loss=0.136, ppl=1.1, wps=28209.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.354, loss_scale=64, train_wall=195, gb_free=21.6, wall=58433
2022-03-06 06:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:56 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 15.286 | nll_loss 15.181 | ppl 37151.4 | wps 47799.7 | wpb 510.9 | bsz 1 | num_updates 25102 | best_loss 8.204
2022-03-06 06:35:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25102 updates
2022-03-06 06:35:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 516 @ 25102 updates, score 15.286) (writing took 1.712044602027163 seconds)
2022-03-06 06:35:58 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:35:58 | INFO | train | epoch 516 | loss 0.443 | nll_loss 0.135 | ppl 1.1 | wps 28186 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25102 | lr 0.000199593 | gnorm 0.353 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 58442
2022-03-06 06:35:58 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:49 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 15.257 | nll_loss 15.152 | ppl 36406.2 | wps 48308.2 | wpb 510.9 | bsz 1 | num_updates 25151 | best_loss 8.204
2022-03-06 06:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25151 updates
2022-03-06 06:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 517 @ 25151 updates, score 15.257) (writing took 1.7505273050628603 seconds)
2022-03-06 06:37:51 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:37:51 | INFO | train | epoch 517 | loss 0.443 | nll_loss 0.136 | ppl 1.1 | wps 28177.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25151 | lr 0.000199399 | gnorm 0.355 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 58555
2022-03-06 06:37:51 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:39:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:42 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 15.282 | nll_loss 15.178 | ppl 37066.2 | wps 48052.1 | wpb 510.9 | bsz 1 | num_updates 25199 | best_loss 8.204
2022-03-06 06:39:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25199 updates
2022-03-06 06:39:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 518 @ 25199 updates, score 15.282) (writing took 1.777950522955507 seconds)
2022-03-06 06:39:44 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:39:44 | INFO | train | epoch 518 | loss 0.443 | nll_loss 0.135 | ppl 1.1 | wps 27567 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 25199 | lr 0.000199209 | gnorm 0.358 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58668
2022-03-06 06:39:44 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:39:46 | INFO | train_inner | epoch 519:      1 / 49 loss=0.443, nll_loss=0.136, ppl=1.1, wps=27158.5, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=25200, lr=0.000199205, gnorm=0.358, loss_scale=32, train_wall=196, gb_free=21.6, wall=58670
2022-03-06 06:41:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:35 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 15.315 | nll_loss 15.21 | ppl 37912.7 | wps 48223.1 | wpb 510.9 | bsz 1 | num_updates 25248 | best_loss 8.204
2022-03-06 06:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25248 updates
2022-03-06 06:41:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 519 @ 25248 updates, score 15.315) (writing took 1.76988902897574 seconds)
2022-03-06 06:41:37 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 06:41:37 | INFO | train | epoch 519 | loss 0.442 | nll_loss 0.134 | ppl 1.1 | wps 28159.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25248 | lr 0.000199015 | gnorm 0.35 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58781
2022-03-06 06:41:37 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 06:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:43:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:43:28 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 15.272 | nll_loss 15.168 | ppl 36809.2 | wps 48258.6 | wpb 510.9 | bsz 1 | num_updates 25296 | best_loss 8.204
2022-03-06 06:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25296 updates
2022-03-06 06:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 520 @ 25296 updates, score 15.272) (writing took 1.8134634990710765 seconds)
2022-03-06 06:43:30 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 06:43:30 | INFO | train | epoch 520 | loss 0.442 | nll_loss 0.135 | ppl 1.1 | wps 27554.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25296 | lr 0.000198826 | gnorm 0.354 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 58894
2022-03-06 06:43:30 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 06:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:43:39 | INFO | train_inner | epoch 521:      4 / 49 loss=0.442, nll_loss=0.135, ppl=1.1, wps=27917.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.352, loss_scale=32, train_wall=197, gb_free=21.6, wall=58903
2022-03-06 06:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:45:21 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 15.241 | nll_loss 15.137 | ppl 36027.8 | wps 47909.4 | wpb 510.9 | bsz 1 | num_updates 25345 | best_loss 8.204
2022-03-06 06:45:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25345 updates
2022-03-06 06:45:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:45:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:45:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 521 @ 25345 updates, score 15.241) (writing took 1.796783679863438 seconds)
2022-03-06 06:45:23 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 06:45:23 | INFO | train | epoch 521 | loss 0.442 | nll_loss 0.134 | ppl 1.1 | wps 28144.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25345 | lr 0.000198634 | gnorm 0.354 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59007
2022-03-06 06:45:23 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 06:45:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:47:14 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 15.236 | nll_loss 15.131 | ppl 35894.2 | wps 48388.5 | wpb 510.9 | bsz 1 | num_updates 25394 | best_loss 8.204
2022-03-06 06:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25394 updates
2022-03-06 06:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 522 @ 25394 updates, score 15.236) (writing took 1.756753624882549 seconds)
2022-03-06 06:47:15 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 06:47:15 | INFO | train | epoch 522 | loss 0.442 | nll_loss 0.135 | ppl 1.1 | wps 28165.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25394 | lr 0.000198442 | gnorm 0.352 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59120
2022-03-06 06:47:15 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 06:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:47:29 | INFO | train_inner | epoch 523:      6 / 49 loss=0.442, nll_loss=0.134, ppl=1.1, wps=28185.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25400, lr=0.000198419, gnorm=0.353, loss_scale=32, train_wall=195, gb_free=21.6, wall=59133
2022-03-06 06:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:49:06 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 15.331 | nll_loss 15.228 | ppl 38385.4 | wps 48245.1 | wpb 510.9 | bsz 1 | num_updates 25443 | best_loss 8.204
2022-03-06 06:49:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25443 updates
2022-03-06 06:49:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:49:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:49:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 523 @ 25443 updates, score 15.331) (writing took 1.8032813179306686 seconds)
2022-03-06 06:49:08 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 06:49:08 | INFO | train | epoch 523 | loss 0.441 | nll_loss 0.134 | ppl 1.1 | wps 28165.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25443 | lr 0.000198251 | gnorm 0.353 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 59232
2022-03-06 06:49:08 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 06:49:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:49:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:59 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 15.306 | nll_loss 15.201 | ppl 37656.1 | wps 48180.2 | wpb 510.9 | bsz 1 | num_updates 25491 | best_loss 8.204
2022-03-06 06:50:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25491 updates
2022-03-06 06:50:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:51:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 524 @ 25491 updates, score 15.306) (writing took 1.7981462150346488 seconds)
2022-03-06 06:51:01 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 06:51:01 | INFO | train | epoch 524 | loss 0.442 | nll_loss 0.135 | ppl 1.1 | wps 27569.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 25491 | lr 0.000198064 | gnorm 0.354 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59345
2022-03-06 06:51:01 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 06:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:51:21 | INFO | train_inner | epoch 525:      9 / 49 loss=0.441, nll_loss=0.134, ppl=1.1, wps=27926, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.354, loss_scale=32, train_wall=197, gb_free=21.6, wall=59365
2022-03-06 06:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:52:52 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 15.221 | nll_loss 15.116 | ppl 35514.1 | wps 48252.7 | wpb 510.9 | bsz 1 | num_updates 25540 | best_loss 8.204
2022-03-06 06:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25540 updates
2022-03-06 06:52:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 525 @ 25540 updates, score 15.221) (writing took 1.7834314350038767 seconds)
2022-03-06 06:52:54 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 06:52:54 | INFO | train | epoch 525 | loss 0.441 | nll_loss 0.134 | ppl 1.1 | wps 28165.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25540 | lr 0.000197874 | gnorm 0.354 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59458
2022-03-06 06:52:54 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 06:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:45 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 15.349 | nll_loss 15.246 | ppl 38850.3 | wps 47931.7 | wpb 510.9 | bsz 1 | num_updates 25589 | best_loss 8.204
2022-03-06 06:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25589 updates
2022-03-06 06:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:54:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:54:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 526 @ 25589 updates, score 15.349) (writing took 1.8241244789678603 seconds)
2022-03-06 06:54:47 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 06:54:47 | INFO | train | epoch 526 | loss 0.441 | nll_loss 0.134 | ppl 1.1 | wps 28143.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25589 | lr 0.000197685 | gnorm 0.351 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 59571
2022-03-06 06:54:47 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 06:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:54:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:55:13 | INFO | train_inner | epoch 527:     12 / 49 loss=0.441, nll_loss=0.134, ppl=1.1, wps=27921.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.352, loss_scale=32, train_wall=197, gb_free=21.6, wall=59597
2022-03-06 06:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:38 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 15.341 | nll_loss 15.238 | ppl 38641.9 | wps 48229.4 | wpb 510.9 | bsz 1 | num_updates 25637 | best_loss 8.204
2022-03-06 06:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25637 updates
2022-03-06 06:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:56:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:56:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 527 @ 25637 updates, score 15.341) (writing took 1.8263620340730995 seconds)
2022-03-06 06:56:40 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 06:56:40 | INFO | train | epoch 527 | loss 0.441 | nll_loss 0.134 | ppl 1.1 | wps 27551.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25637 | lr 0.0001975 | gnorm 0.354 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59684
2022-03-06 06:56:40 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 06:56:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:31 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 15.324 | nll_loss 15.221 | ppl 38184.6 | wps 48393.4 | wpb 510.9 | bsz 1 | num_updates 25686 | best_loss 8.204
2022-03-06 06:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25686 updates
2022-03-06 06:58:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 06:58:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 528 @ 25686 updates, score 15.324) (writing took 1.760035075014457 seconds)
2022-03-06 06:58:33 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 06:58:33 | INFO | train | epoch 528 | loss 0.44 | nll_loss 0.133 | ppl 1.1 | wps 28176.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25686 | lr 0.000197311 | gnorm 0.352 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59797
2022-03-06 06:58:33 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 06:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:59:03 | INFO | train_inner | epoch 529:     14 / 49 loss=0.44, nll_loss=0.133, ppl=1.1, wps=28182.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.352, loss_scale=32, train_wall=195, gb_free=21.6, wall=59828
2022-03-06 07:00:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:24 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 15.22 | nll_loss 15.117 | ppl 35542.7 | wps 48304.6 | wpb 510.9 | bsz 1 | num_updates 25734 | best_loss 8.204
2022-03-06 07:00:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25734 updates
2022-03-06 07:00:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:00:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 529 @ 25734 updates, score 15.22) (writing took 1.8103153018746525 seconds)
2022-03-06 07:00:26 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:00:26 | INFO | train | epoch 529 | loss 0.439 | nll_loss 0.132 | ppl 1.1 | wps 27571.8 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 25734 | lr 0.000197127 | gnorm 0.348 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 59910
2022-03-06 07:00:26 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:00:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:02:17 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 15.274 | nll_loss 15.17 | ppl 36855.9 | wps 48375.2 | wpb 510.9 | bsz 1 | num_updates 25783 | best_loss 8.204
2022-03-06 07:02:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25783 updates
2022-03-06 07:02:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:02:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 530 @ 25783 updates, score 15.274) (writing took 1.7760254801250994 seconds)
2022-03-06 07:02:18 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:02:18 | INFO | train | epoch 530 | loss 0.44 | nll_loss 0.133 | ppl 1.1 | wps 28156.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25783 | lr 0.00019694 | gnorm 0.359 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60023
2022-03-06 07:02:18 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:02:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:02:56 | INFO | train_inner | epoch 531:     17 / 49 loss=0.44, nll_loss=0.133, ppl=1.1, wps=27928.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.354, loss_scale=32, train_wall=197, gb_free=21.6, wall=60060
2022-03-06 07:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:04:10 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 15.265 | nll_loss 15.162 | ppl 36656 | wps 47789.9 | wpb 510.9 | bsz 1 | num_updates 25832 | best_loss 8.204
2022-03-06 07:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25832 updates
2022-03-06 07:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 531 @ 25832 updates, score 15.265) (writing took 1.7519112108275294 seconds)
2022-03-06 07:04:11 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:04:11 | INFO | train | epoch 531 | loss 0.439 | nll_loss 0.132 | ppl 1.1 | wps 28157.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25832 | lr 0.000196753 | gnorm 0.353 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60135
2022-03-06 07:04:11 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:04:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:06:02 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 15.31 | nll_loss 15.207 | ppl 37818.5 | wps 48162.4 | wpb 510.9 | bsz 1 | num_updates 25881 | best_loss 8.204
2022-03-06 07:06:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25881 updates
2022-03-06 07:06:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:06:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 532 @ 25881 updates, score 15.31) (writing took 1.7666653690394014 seconds)
2022-03-06 07:06:04 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:06:04 | INFO | train | epoch 532 | loss 0.439 | nll_loss 0.132 | ppl 1.1 | wps 28177.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25881 | lr 0.000196566 | gnorm 0.353 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 60248
2022-03-06 07:06:04 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:06:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:06:48 | INFO | train_inner | epoch 533:     20 / 49 loss=0.439, nll_loss=0.132, ppl=1.1, wps=27928.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.352, loss_scale=32, train_wall=197, gb_free=21.6, wall=60292
2022-03-06 07:07:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:55 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 15.217 | nll_loss 15.113 | ppl 35433.1 | wps 48104.8 | wpb 510.9 | bsz 1 | num_updates 25929 | best_loss 8.204
2022-03-06 07:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25929 updates
2022-03-06 07:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:07:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 533 @ 25929 updates, score 15.217) (writing took 1.8016846789978445 seconds)
2022-03-06 07:07:57 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:07:57 | INFO | train | epoch 533 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 27572.5 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 25929 | lr 0.000196384 | gnorm 0.346 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60361
2022-03-06 07:07:57 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:09:48 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 15.268 | nll_loss 15.164 | ppl 36712.7 | wps 48283.2 | wpb 510.9 | bsz 1 | num_updates 25978 | best_loss 8.204
2022-03-06 07:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25978 updates
2022-03-06 07:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 534 @ 25978 updates, score 15.268) (writing took 1.7576064839959145 seconds)
2022-03-06 07:09:50 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:09:50 | INFO | train | epoch 534 | loss 0.439 | nll_loss 0.132 | ppl 1.1 | wps 28133.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25978 | lr 0.000196199 | gnorm 0.349 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60474
2022-03-06 07:09:50 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:10:38 | INFO | train_inner | epoch 535:     22 / 49 loss=0.439, nll_loss=0.132, ppl=1.1, wps=28179.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.347, loss_scale=32, train_wall=195, gb_free=21.6, wall=60522
2022-03-06 07:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:11:41 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 15.284 | nll_loss 15.181 | ppl 37139.7 | wps 48137.7 | wpb 510.9 | bsz 1 | num_updates 26027 | best_loss 8.204
2022-03-06 07:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26027 updates
2022-03-06 07:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 535 @ 26027 updates, score 15.284) (writing took 1.770752901909873 seconds)
2022-03-06 07:11:43 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:11:43 | INFO | train | epoch 535 | loss 0.438 | nll_loss 0.132 | ppl 1.1 | wps 28157.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26027 | lr 0.000196014 | gnorm 0.347 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 60587
2022-03-06 07:11:43 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:11:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:34 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 15.25 | nll_loss 15.147 | ppl 36291.4 | wps 48297.5 | wpb 510.9 | bsz 1 | num_updates 26075 | best_loss 8.204
2022-03-06 07:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26075 updates
2022-03-06 07:13:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 536 @ 26075 updates, score 15.25) (writing took 1.7716313228011131 seconds)
2022-03-06 07:13:36 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:13:36 | INFO | train | epoch 536 | loss 0.438 | nll_loss 0.131 | ppl 1.1 | wps 27596.3 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 26075 | lr 0.000195834 | gnorm 0.348 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60700
2022-03-06 07:13:36 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:31 | INFO | train_inner | epoch 537:     25 / 49 loss=0.438, nll_loss=0.132, ppl=1.1, wps=27933.1, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.349, loss_scale=32, train_wall=197, gb_free=21.6, wall=60755
2022-03-06 07:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:15:27 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 15.179 | nll_loss 15.075 | ppl 34516.1 | wps 48222.6 | wpb 510.9 | bsz 1 | num_updates 26124 | best_loss 8.204
2022-03-06 07:15:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26124 updates
2022-03-06 07:15:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:15:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:15:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 537 @ 26124 updates, score 15.179) (writing took 1.7500075460411608 seconds)
2022-03-06 07:15:28 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:15:28 | INFO | train | epoch 537 | loss 0.438 | nll_loss 0.131 | ppl 1.1 | wps 28150.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26124 | lr 0.00019565 | gnorm 0.351 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60813
2022-03-06 07:15:29 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:17:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:17:20 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 15.222 | nll_loss 15.118 | ppl 35548.6 | wps 48348.1 | wpb 510.9 | bsz 1 | num_updates 26172 | best_loss 8.204
2022-03-06 07:17:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26172 updates
2022-03-06 07:17:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:17:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:17:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 538 @ 26172 updates, score 15.222) (writing took 1.7886535809375346 seconds)
2022-03-06 07:17:21 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:17:21 | INFO | train | epoch 538 | loss 0.437 | nll_loss 0.131 | ppl 1.09 | wps 27578.6 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 26172 | lr 0.000195471 | gnorm 0.347 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 60925
2022-03-06 07:17:21 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:18:23 | INFO | train_inner | epoch 539:     28 / 49 loss=0.437, nll_loss=0.131, ppl=1.09, wps=27922.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.348, loss_scale=32, train_wall=197, gb_free=21.6, wall=60987
2022-03-06 07:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:12 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 15.273 | nll_loss 15.17 | ppl 36867.7 | wps 47910.8 | wpb 510.9 | bsz 1 | num_updates 26221 | best_loss 8.204
2022-03-06 07:19:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26221 updates
2022-03-06 07:19:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:19:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:19:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 539 @ 26221 updates, score 15.273) (writing took 1.7919196460861713 seconds)
2022-03-06 07:19:14 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:19:14 | INFO | train | epoch 539 | loss 0.437 | nll_loss 0.131 | ppl 1.1 | wps 28159.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26221 | lr 0.000195288 | gnorm 0.35 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61038
2022-03-06 07:19:14 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:21:05 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 15.278 | nll_loss 15.175 | ppl 36984.6 | wps 48147.8 | wpb 510.9 | bsz 1 | num_updates 26270 | best_loss 8.204
2022-03-06 07:21:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26270 updates
2022-03-06 07:21:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:21:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:21:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 540 @ 26270 updates, score 15.278) (writing took 1.7742608410771936 seconds)
2022-03-06 07:21:07 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:21:07 | INFO | train | epoch 540 | loss 0.437 | nll_loss 0.131 | ppl 1.1 | wps 28139.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26270 | lr 0.000195106 | gnorm 0.348 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61151
2022-03-06 07:21:07 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:21:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:22:13 | INFO | train_inner | epoch 541:     30 / 49 loss=0.437, nll_loss=0.131, ppl=1.1, wps=28182.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.35, loss_scale=64, train_wall=195, gb_free=21.6, wall=61217
2022-03-06 07:22:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:22:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:22:58 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 15.413 | nll_loss 15.311 | ppl 40662.7 | wps 48176.6 | wpb 510.9 | bsz 1 | num_updates 26318 | best_loss 8.204
2022-03-06 07:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26318 updates
2022-03-06 07:22:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:23:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:23:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 541 @ 26318 updates, score 15.413) (writing took 1.8222294750157744 seconds)
2022-03-06 07:23:00 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:23:00 | INFO | train | epoch 541 | loss 0.437 | nll_loss 0.131 | ppl 1.1 | wps 27564.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 26318 | lr 0.000194928 | gnorm 0.349 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61264
2022-03-06 07:23:00 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:23:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:24:51 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 15.233 | nll_loss 15.129 | ppl 35843.5 | wps 47930.3 | wpb 510.9 | bsz 1 | num_updates 26367 | best_loss 8.204
2022-03-06 07:24:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26367 updates
2022-03-06 07:24:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 542 @ 26367 updates, score 15.233) (writing took 1.7806021410506219 seconds)
2022-03-06 07:24:53 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:24:53 | INFO | train | epoch 542 | loss 0.436 | nll_loss 0.13 | ppl 1.09 | wps 28146.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26367 | lr 0.000194746 | gnorm 0.346 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61377
2022-03-06 07:24:53 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:26:05 | INFO | train_inner | epoch 543:     33 / 49 loss=0.437, nll_loss=0.13, ppl=1.09, wps=27907.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.347, loss_scale=32, train_wall=197, gb_free=21.6, wall=61450
2022-03-06 07:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:26:44 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 15.25 | nll_loss 15.148 | ppl 36296.2 | wps 48162.5 | wpb 510.9 | bsz 1 | num_updates 26416 | best_loss 8.204
2022-03-06 07:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26416 updates
2022-03-06 07:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:26:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:26:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 543 @ 26416 updates, score 15.25) (writing took 1.795391745865345 seconds)
2022-03-06 07:26:46 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:26:46 | INFO | train | epoch 543 | loss 0.437 | nll_loss 0.131 | ppl 1.09 | wps 28135.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26416 | lr 0.000194566 | gnorm 0.349 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61490
2022-03-06 07:26:46 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:28:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:28:37 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 15.355 | nll_loss 15.253 | ppl 39053.8 | wps 48181.5 | wpb 510.9 | bsz 1 | num_updates 26464 | best_loss 8.204
2022-03-06 07:28:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26464 updates
2022-03-06 07:28:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 544 @ 26464 updates, score 15.355) (writing took 1.8892024019733071 seconds)
2022-03-06 07:28:39 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:28:39 | INFO | train | epoch 544 | loss 0.436 | nll_loss 0.13 | ppl 1.09 | wps 27551 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26464 | lr 0.000194389 | gnorm 0.344 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61603
2022-03-06 07:28:39 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:29:58 | INFO | train_inner | epoch 545:     36 / 49 loss=0.436, nll_loss=0.13, ppl=1.09, wps=27906.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.345, loss_scale=32, train_wall=197, gb_free=21.6, wall=61682
2022-03-06 07:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:30 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 15.283 | nll_loss 15.18 | ppl 37109.7 | wps 48351.3 | wpb 510.9 | bsz 1 | num_updates 26513 | best_loss 8.204
2022-03-06 07:30:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26513 updates
2022-03-06 07:30:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:30:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:30:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 545 @ 26513 updates, score 15.283) (writing took 1.7399795691017061 seconds)
2022-03-06 07:30:32 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:30:32 | INFO | train | epoch 545 | loss 0.435 | nll_loss 0.13 | ppl 1.09 | wps 28174 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26513 | lr 0.00019421 | gnorm 0.343 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61716
2022-03-06 07:30:32 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:23 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 15.271 | nll_loss 15.169 | ppl 36834.1 | wps 47858.2 | wpb 510.9 | bsz 1 | num_updates 26562 | best_loss 8.204
2022-03-06 07:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26562 updates
2022-03-06 07:32:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:32:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:32:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 546 @ 26562 updates, score 15.271) (writing took 1.8074213520158082 seconds)
2022-03-06 07:32:25 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:32:25 | INFO | train | epoch 546 | loss 0.436 | nll_loss 0.13 | ppl 1.09 | wps 28138.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26562 | lr 0.00019403 | gnorm 0.341 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61829
2022-03-06 07:32:25 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:33:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:33:50 | INFO | train_inner | epoch 547:     39 / 49 loss=0.436, nll_loss=0.13, ppl=1.09, wps=27919.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.344, loss_scale=32, train_wall=197, gb_free=21.6, wall=61914
2022-03-06 07:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:34:16 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 15.401 | nll_loss 15.298 | ppl 40299.7 | wps 48472.9 | wpb 510.9 | bsz 1 | num_updates 26610 | best_loss 8.204
2022-03-06 07:34:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26610 updates
2022-03-06 07:34:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:34:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:34:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 547 @ 26610 updates, score 15.401) (writing took 1.794315205188468 seconds)
2022-03-06 07:34:18 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:34:18 | INFO | train | epoch 547 | loss 0.436 | nll_loss 0.13 | ppl 1.09 | wps 27574.9 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 26610 | lr 0.000193855 | gnorm 0.349 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 61942
2022-03-06 07:34:18 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:34:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:36:09 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 15.317 | nll_loss 15.216 | ppl 38052.2 | wps 48431.8 | wpb 510.9 | bsz 1 | num_updates 26659 | best_loss 8.204
2022-03-06 07:36:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26659 updates
2022-03-06 07:36:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 548 @ 26659 updates, score 15.317) (writing took 1.8288205179851502 seconds)
2022-03-06 07:36:11 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:36:11 | INFO | train | epoch 548 | loss 0.435 | nll_loss 0.129 | ppl 1.09 | wps 28123.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26659 | lr 0.000193677 | gnorm 0.34 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62055
2022-03-06 07:36:11 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:36:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:41 | INFO | train_inner | epoch 549:     41 / 49 loss=0.435, nll_loss=0.129, ppl=1.09, wps=28174.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.343, loss_scale=32, train_wall=195, gb_free=21.6, wall=62145
2022-03-06 07:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:38:02 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 15.346 | nll_loss 15.245 | ppl 38824.9 | wps 47985.3 | wpb 510.9 | bsz 1 | num_updates 26708 | best_loss 8.204
2022-03-06 07:38:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26708 updates
2022-03-06 07:38:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:38:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 549 @ 26708 updates, score 15.346) (writing took 1.757817996898666 seconds)
2022-03-06 07:38:03 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:38:03 | INFO | train | epoch 549 | loss 0.435 | nll_loss 0.13 | ppl 1.09 | wps 28153.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26708 | lr 0.000193499 | gnorm 0.345 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62168
2022-03-06 07:38:03 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:38:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:39:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:39:55 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 15.275 | nll_loss 15.172 | ppl 36925.5 | wps 47993.4 | wpb 510.9 | bsz 1 | num_updates 26756 | best_loss 8.204
2022-03-06 07:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26756 updates
2022-03-06 07:39:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 550 @ 26756 updates, score 15.275) (writing took 1.7511413230095059 seconds)
2022-03-06 07:39:56 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 07:39:56 | INFO | train | epoch 550 | loss 0.435 | nll_loss 0.129 | ppl 1.09 | wps 27579.4 | ups 0.43 | wpb 64844.1 | bsz 126.7 | num_updates 26756 | lr 0.000193326 | gnorm 0.343 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62280
2022-03-06 07:39:56 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 07:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:33 | INFO | train_inner | epoch 551:     44 / 49 loss=0.435, nll_loss=0.129, ppl=1.09, wps=27910.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.342, loss_scale=32, train_wall=197, gb_free=21.6, wall=62377
2022-03-06 07:41:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:41:47 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 15.275 | nll_loss 15.172 | ppl 36928 | wps 48244.8 | wpb 510.9 | bsz 1 | num_updates 26805 | best_loss 8.204
2022-03-06 07:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26805 updates
2022-03-06 07:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 551 @ 26805 updates, score 15.275) (writing took 1.8673623299691826 seconds)
2022-03-06 07:41:49 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 07:41:49 | INFO | train | epoch 551 | loss 0.434 | nll_loss 0.129 | ppl 1.09 | wps 28110.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26805 | lr 0.000193149 | gnorm 0.341 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62393
2022-03-06 07:41:49 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 07:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:43:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:43:41 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 15.336 | nll_loss 15.235 | ppl 38557 | wps 48103.1 | wpb 510.9 | bsz 1 | num_updates 26854 | best_loss 8.204
2022-03-06 07:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26854 updates
2022-03-06 07:43:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 552 @ 26854 updates, score 15.336) (writing took 1.7273677261546254 seconds)
2022-03-06 07:43:42 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 07:43:42 | INFO | train | epoch 552 | loss 0.434 | nll_loss 0.128 | ppl 1.09 | wps 28133.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26854 | lr 0.000192973 | gnorm 0.343 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62506
2022-03-06 07:43:42 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 07:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:44:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:45:25 | INFO | train_inner | epoch 553:     47 / 49 loss=0.434, nll_loss=0.129, ppl=1.09, wps=27897.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.345, loss_scale=32, train_wall=197, gb_free=21.6, wall=62610
2022-03-06 07:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:45:33 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 15.289 | nll_loss 15.186 | ppl 37288 | wps 48338.6 | wpb 510.9 | bsz 1 | num_updates 26902 | best_loss 8.204
2022-03-06 07:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26902 updates
2022-03-06 07:45:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:45:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:45:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 553 @ 26902 updates, score 15.289) (writing took 1.9470106130465865 seconds)
2022-03-06 07:45:35 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 07:45:35 | INFO | train | epoch 553 | loss 0.435 | nll_loss 0.129 | ppl 1.09 | wps 27523 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26902 | lr 0.0001928 | gnorm 0.348 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62619
2022-03-06 07:45:35 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 07:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:47:27 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 15.277 | nll_loss 15.174 | ppl 36963.8 | wps 48214.7 | wpb 510.9 | bsz 1 | num_updates 26951 | best_loss 8.204
2022-03-06 07:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26951 updates
2022-03-06 07:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 554 @ 26951 updates, score 15.277) (writing took 2.0381094079930335 seconds)
2022-03-06 07:47:29 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 07:47:29 | INFO | train | epoch 554 | loss 0.434 | nll_loss 0.128 | ppl 1.09 | wps 28074.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26951 | lr 0.000192625 | gnorm 0.345 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62733
2022-03-06 07:47:29 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 07:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:49:15 | INFO | train_inner | epoch 555:     49 / 49 loss=0.434, nll_loss=0.128, ppl=1.09, wps=28109.7, ups=0.44, wpb=64544.1, bsz=126.1, num_updates=27000, lr=0.00019245, gnorm=0.345, loss_scale=64, train_wall=194, gb_free=21.6, wall=62839
2022-03-06 07:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:20 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 15.174 | nll_loss 15.071 | ppl 34426.9 | wps 47821.5 | wpb 510.9 | bsz 1 | num_updates 27000 | best_loss 8.204
2022-03-06 07:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27000 updates
2022-03-06 07:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:49:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:49:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 555 @ 27000 updates, score 15.174) (writing took 1.9650523168966174 seconds)
2022-03-06 07:49:22 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 07:49:22 | INFO | train | epoch 555 | loss 0.433 | nll_loss 0.128 | ppl 1.09 | wps 28095.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27000 | lr 0.00019245 | gnorm 0.343 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 62846
2022-03-06 07:49:22 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 07:49:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:50:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:51:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:13 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 15.342 | nll_loss 15.24 | ppl 38706.7 | wps 48120.7 | wpb 510.9 | bsz 1 | num_updates 27048 | best_loss 8.204
2022-03-06 07:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27048 updates
2022-03-06 07:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 556 @ 27048 updates, score 15.342) (writing took 2.0067744709085673 seconds)
2022-03-06 07:51:15 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 07:51:15 | INFO | train | epoch 556 | loss 0.433 | nll_loss 0.128 | ppl 1.09 | wps 27495 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27048 | lr 0.000192279 | gnorm 0.346 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 62959
2022-03-06 07:51:15 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 07:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:06 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 15.243 | nll_loss 15.141 | ppl 36143.1 | wps 48078.8 | wpb 510.9 | bsz 1 | num_updates 27097 | best_loss 8.204
2022-03-06 07:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27097 updates
2022-03-06 07:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 557 @ 27097 updates, score 15.243) (writing took 2.0664602348115295 seconds)
2022-03-06 07:53:08 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 07:53:08 | INFO | train | epoch 557 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 28054.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27097 | lr 0.000192105 | gnorm 0.338 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63072
2022-03-06 07:53:08 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 07:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:15 | INFO | train_inner | epoch 558:      3 / 49 loss=0.433, nll_loss=0.127, ppl=1.09, wps=27054.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.342, loss_scale=32, train_wall=197, gb_free=21.6, wall=63079
2022-03-06 07:54:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:54:59 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 15.284 | nll_loss 15.182 | ppl 37171.3 | wps 48225.8 | wpb 510.9 | bsz 1 | num_updates 27146 | best_loss 8.204
2022-03-06 07:54:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27146 updates
2022-03-06 07:54:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:55:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:55:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 558 @ 27146 updates, score 15.284) (writing took 2.004246077965945 seconds)
2022-03-06 07:55:01 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 07:55:01 | INFO | train | epoch 558 | loss 0.433 | nll_loss 0.128 | ppl 1.09 | wps 28091.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27146 | lr 0.000191932 | gnorm 0.342 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63185
2022-03-06 07:55:01 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 07:55:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:56:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:56:52 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 15.263 | nll_loss 15.162 | ppl 36658.9 | wps 48178.5 | wpb 510.9 | bsz 1 | num_updates 27194 | best_loss 8.204
2022-03-06 07:56:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27194 updates
2022-03-06 07:56:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 559 @ 27194 updates, score 15.263) (writing took 2.005722766974941 seconds)
2022-03-06 07:56:54 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 07:56:54 | INFO | train | epoch 559 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 27505.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27194 | lr 0.000191762 | gnorm 0.34 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63299
2022-03-06 07:56:54 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 07:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:57:08 | INFO | train_inner | epoch 560:      6 / 49 loss=0.433, nll_loss=0.128, ppl=1.09, wps=27858.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.34, loss_scale=32, train_wall=197, gb_free=21.6, wall=63312
2022-03-06 07:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:58:46 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 15.259 | nll_loss 15.157 | ppl 36527 | wps 48246.7 | wpb 510.9 | bsz 1 | num_updates 27243 | best_loss 8.204
2022-03-06 07:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27243 updates
2022-03-06 07:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 07:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 560 @ 27243 updates, score 15.259) (writing took 2.0455887329299003 seconds)
2022-03-06 07:58:48 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 07:58:48 | INFO | train | epoch 560 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 28055.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27243 | lr 0.00019159 | gnorm 0.339 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63412
2022-03-06 07:58:48 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 07:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:00:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:00:39 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 15.294 | nll_loss 15.191 | ppl 37418.3 | wps 47867.8 | wpb 510.9 | bsz 1 | num_updates 27292 | best_loss 8.204
2022-03-06 08:00:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27292 updates
2022-03-06 08:00:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:00:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 561 @ 27292 updates, score 15.294) (writing took 1.991490330081433 seconds)
2022-03-06 08:00:41 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:00:41 | INFO | train | epoch 561 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 28069.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27292 | lr 0.000191418 | gnorm 0.339 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63525
2022-03-06 08:00:41 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:00:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:00:59 | INFO | train_inner | epoch 562:      8 / 49 loss=0.432, nll_loss=0.127, ppl=1.09, wps=28098.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.339, loss_scale=32, train_wall=195, gb_free=21.6, wall=63543
2022-03-06 08:01:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:02:32 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 15.39 | nll_loss 15.289 | ppl 40049.1 | wps 48104.1 | wpb 510.9 | bsz 1 | num_updates 27340 | best_loss 8.204
2022-03-06 08:02:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27340 updates
2022-03-06 08:02:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:02:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 562 @ 27340 updates, score 15.39) (writing took 1.9998377549927682 seconds)
2022-03-06 08:02:34 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:02:34 | INFO | train | epoch 562 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 27524.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27340 | lr 0.00019125 | gnorm 0.342 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63638
2022-03-06 08:02:34 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:02:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:04:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:04:25 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 15.355 | nll_loss 15.255 | ppl 39092.2 | wps 48213.7 | wpb 510.9 | bsz 1 | num_updates 27389 | best_loss 8.204
2022-03-06 08:04:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27389 updates
2022-03-06 08:04:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:04:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 563 @ 27389 updates, score 15.355) (writing took 2.0332674430683255 seconds)
2022-03-06 08:04:27 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:04:27 | INFO | train | epoch 563 | loss 0.431 | nll_loss 0.126 | ppl 1.09 | wps 28057.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27389 | lr 0.000191079 | gnorm 0.334 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63751
2022-03-06 08:04:27 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:04:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:04:52 | INFO | train_inner | epoch 564:     11 / 49 loss=0.431, nll_loss=0.127, ppl=1.09, wps=27849.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.337, loss_scale=32, train_wall=197, gb_free=21.6, wall=63776
2022-03-06 08:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:06:19 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 15.262 | nll_loss 15.159 | ppl 36574.8 | wps 48170.9 | wpb 510.9 | bsz 1 | num_updates 27438 | best_loss 8.204
2022-03-06 08:06:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27438 updates
2022-03-06 08:06:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:06:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 564 @ 27438 updates, score 15.262) (writing took 2.019379284000024 seconds)
2022-03-06 08:06:21 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:06:21 | INFO | train | epoch 564 | loss 0.432 | nll_loss 0.127 | ppl 1.09 | wps 28060.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27438 | lr 0.000190908 | gnorm 0.34 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 63865
2022-03-06 08:06:21 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:06:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:08:12 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 15.246 | nll_loss 15.143 | ppl 36194.7 | wps 48407.4 | wpb 510.9 | bsz 1 | num_updates 27486 | best_loss 8.204
2022-03-06 08:08:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27486 updates
2022-03-06 08:08:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:08:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:08:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 565 @ 27486 updates, score 15.246) (writing took 2.0122793009504676 seconds)
2022-03-06 08:08:14 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:08:14 | INFO | train | epoch 565 | loss 0.431 | nll_loss 0.126 | ppl 1.09 | wps 27533.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27486 | lr 0.000190741 | gnorm 0.342 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 63978
2022-03-06 08:08:14 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:08:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:08:44 | INFO | train_inner | epoch 566:     14 / 49 loss=0.431, nll_loss=0.126, ppl=1.09, wps=27858.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.342, loss_scale=32, train_wall=197, gb_free=21.6, wall=64009
2022-03-06 08:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:10:05 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 15.328 | nll_loss 15.227 | ppl 38355.6 | wps 47970.6 | wpb 510.9 | bsz 1 | num_updates 27535 | best_loss 8.204
2022-03-06 08:10:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27535 updates
2022-03-06 08:10:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 566 @ 27535 updates, score 15.328) (writing took 2.063928697956726 seconds)
2022-03-06 08:10:07 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:10:07 | INFO | train | epoch 566 | loss 0.431 | nll_loss 0.126 | ppl 1.09 | wps 28065.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27535 | lr 0.000190571 | gnorm 0.34 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 64091
2022-03-06 08:10:07 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:11:58 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 15.253 | nll_loss 15.151 | ppl 36371.3 | wps 48071.2 | wpb 510.9 | bsz 1 | num_updates 27584 | best_loss 8.204
2022-03-06 08:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27584 updates
2022-03-06 08:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 567 @ 27584 updates, score 15.253) (writing took 2.035987871931866 seconds)
2022-03-06 08:12:00 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:12:00 | INFO | train | epoch 567 | loss 0.431 | nll_loss 0.126 | ppl 1.09 | wps 28082.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27584 | lr 0.000190402 | gnorm 0.34 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 64204
2022-03-06 08:12:00 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:37 | INFO | train_inner | epoch 568:     17 / 49 loss=0.431, nll_loss=0.126, ppl=1.09, wps=27842.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.339, loss_scale=32, train_wall=197, gb_free=21.6, wall=64242
2022-03-06 08:13:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:13:51 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 15.267 | nll_loss 15.167 | ppl 36792.4 | wps 47993.2 | wpb 510.9 | bsz 1 | num_updates 27632 | best_loss 8.204
2022-03-06 08:13:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27632 updates
2022-03-06 08:13:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 568 @ 27632 updates, score 15.267) (writing took 2.0154507781844586 seconds)
2022-03-06 08:13:53 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:13:53 | INFO | train | epoch 568 | loss 0.431 | nll_loss 0.126 | ppl 1.09 | wps 27501.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27632 | lr 0.000190236 | gnorm 0.338 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 64317
2022-03-06 08:13:53 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:15:45 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 15.21 | nll_loss 15.107 | ppl 35296.4 | wps 47782.9 | wpb 510.9 | bsz 1 | num_updates 27681 | best_loss 8.204
2022-03-06 08:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27681 updates
2022-03-06 08:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 569 @ 27681 updates, score 15.21) (writing took 2.079816940939054 seconds)
2022-03-06 08:15:47 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:15:47 | INFO | train | epoch 569 | loss 0.43 | nll_loss 0.126 | ppl 1.09 | wps 28030.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27681 | lr 0.000190068 | gnorm 0.337 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 64431
2022-03-06 08:15:47 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:28 | INFO | train_inner | epoch 570:     19 / 49 loss=0.43, nll_loss=0.126, ppl=1.09, wps=28087.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.338, loss_scale=32, train_wall=195, gb_free=21.6, wall=64472
2022-03-06 08:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:17:38 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 15.251 | nll_loss 15.149 | ppl 36335.5 | wps 47984.4 | wpb 510.9 | bsz 1 | num_updates 27730 | best_loss 8.204
2022-03-06 08:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27730 updates
2022-03-06 08:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 570 @ 27730 updates, score 15.251) (writing took 1.994572265073657 seconds)
2022-03-06 08:17:40 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:17:40 | INFO | train | epoch 570 | loss 0.43 | nll_loss 0.126 | ppl 1.09 | wps 28082.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27730 | lr 0.0001899 | gnorm 0.336 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 64544
2022-03-06 08:17:40 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:18:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:19:31 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 15.298 | nll_loss 15.197 | ppl 37562.7 | wps 48060.8 | wpb 510.9 | bsz 1 | num_updates 27778 | best_loss 8.204
2022-03-06 08:19:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27778 updates
2022-03-06 08:19:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:19:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 571 @ 27778 updates, score 15.298) (writing took 2.001507448963821 seconds)
2022-03-06 08:19:33 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:19:33 | INFO | train | epoch 571 | loss 0.429 | nll_loss 0.125 | ppl 1.09 | wps 27510.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27778 | lr 0.000189736 | gnorm 0.336 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 64657
2022-03-06 08:19:33 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:19:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:21 | INFO | train_inner | epoch 572:     22 / 49 loss=0.43, nll_loss=0.125, ppl=1.09, wps=27848.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.336, loss_scale=32, train_wall=197, gb_free=21.6, wall=64705
2022-03-06 08:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:21:24 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 15.352 | nll_loss 15.253 | ppl 39047.5 | wps 48239 | wpb 510.9 | bsz 1 | num_updates 27827 | best_loss 8.204
2022-03-06 08:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27827 updates
2022-03-06 08:21:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:21:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 572 @ 27827 updates, score 15.352) (writing took 2.0748766530305147 seconds)
2022-03-06 08:21:26 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:21:26 | INFO | train | epoch 572 | loss 0.429 | nll_loss 0.125 | ppl 1.09 | wps 28047.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27827 | lr 0.000189569 | gnorm 0.336 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 64770
2022-03-06 08:21:26 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:23:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:23:17 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 15.343 | nll_loss 15.243 | ppl 38770.6 | wps 48159.5 | wpb 510.9 | bsz 1 | num_updates 27876 | best_loss 8.204
2022-03-06 08:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27876 updates
2022-03-06 08:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:23:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:23:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 573 @ 27876 updates, score 15.343) (writing took 1.9943533258046955 seconds)
2022-03-06 08:23:19 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:23:19 | INFO | train | epoch 573 | loss 0.429 | nll_loss 0.124 | ppl 1.09 | wps 28086.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27876 | lr 0.000189402 | gnorm 0.336 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 64883
2022-03-06 08:23:19 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:24:12 | INFO | train_inner | epoch 574:     24 / 49 loss=0.429, nll_loss=0.124, ppl=1.09, wps=28114.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.336, loss_scale=64, train_wall=195, gb_free=21.6, wall=64936
2022-03-06 08:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:25:10 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 15.313 | nll_loss 15.211 | ppl 37920.4 | wps 48302.1 | wpb 510.9 | bsz 1 | num_updates 27925 | best_loss 8.204
2022-03-06 08:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27925 updates
2022-03-06 08:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 574 @ 27925 updates, score 15.313) (writing took 2.0194450998678803 seconds)
2022-03-06 08:25:12 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:25:12 | INFO | train | epoch 574 | loss 0.429 | nll_loss 0.125 | ppl 1.09 | wps 28109.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27925 | lr 0.000189236 | gnorm 0.337 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 64997
2022-03-06 08:25:12 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:27:04 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 15.3 | nll_loss 15.2 | ppl 37634.5 | wps 48217.7 | wpb 510.9 | bsz 1 | num_updates 27973 | best_loss 8.204
2022-03-06 08:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27973 updates
2022-03-06 08:27:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:27:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:27:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 575 @ 27973 updates, score 15.3) (writing took 2.0810082408133894 seconds)
2022-03-06 08:27:06 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:27:06 | INFO | train | epoch 575 | loss 0.428 | nll_loss 0.124 | ppl 1.09 | wps 27488.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27973 | lr 0.000189073 | gnorm 0.333 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65110
2022-03-06 08:27:06 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:27:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:28:05 | INFO | train_inner | epoch 576:     27 / 49 loss=0.429, nll_loss=0.124, ppl=1.09, wps=27852.6, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.336, loss_scale=32, train_wall=197, gb_free=21.6, wall=65169
2022-03-06 08:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:28:57 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 15.321 | nll_loss 15.22 | ppl 38161.5 | wps 48133.8 | wpb 510.9 | bsz 1 | num_updates 28022 | best_loss 8.204
2022-03-06 08:28:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28022 updates
2022-03-06 08:28:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 576 @ 28022 updates, score 15.321) (writing took 2.0105720469728112 seconds)
2022-03-06 08:28:59 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:28:59 | INFO | train | epoch 576 | loss 0.429 | nll_loss 0.125 | ppl 1.09 | wps 28060.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28022 | lr 0.000188908 | gnorm 0.338 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65223
2022-03-06 08:28:59 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:30:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:30:50 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 15.294 | nll_loss 15.193 | ppl 37459.5 | wps 48433.2 | wpb 510.9 | bsz 1 | num_updates 28070 | best_loss 8.204
2022-03-06 08:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28070 updates
2022-03-06 08:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 577 @ 28070 updates, score 15.294) (writing took 2.0174212779384106 seconds)
2022-03-06 08:30:52 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:30:52 | INFO | train | epoch 577 | loss 0.429 | nll_loss 0.124 | ppl 1.09 | wps 27543.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28070 | lr 0.000188746 | gnorm 0.334 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65336
2022-03-06 08:30:52 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:31:58 | INFO | train_inner | epoch 578:     30 / 49 loss=0.428, nll_loss=0.124, ppl=1.09, wps=27863.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.335, loss_scale=32, train_wall=197, gb_free=21.6, wall=65402
2022-03-06 08:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:32:43 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 15.24 | nll_loss 15.138 | ppl 36067.7 | wps 48212.5 | wpb 510.9 | bsz 1 | num_updates 28119 | best_loss 8.204
2022-03-06 08:32:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28119 updates
2022-03-06 08:32:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:32:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 578 @ 28119 updates, score 15.24) (writing took 2.0565969981253147 seconds)
2022-03-06 08:32:45 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:32:45 | INFO | train | epoch 578 | loss 0.428 | nll_loss 0.124 | ppl 1.09 | wps 28090.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28119 | lr 0.000188582 | gnorm 0.335 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65449
2022-03-06 08:32:45 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:34:36 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 15.318 | nll_loss 15.217 | ppl 38095.3 | wps 48050.5 | wpb 510.9 | bsz 1 | num_updates 28168 | best_loss 8.204
2022-03-06 08:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28168 updates
2022-03-06 08:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:34:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 579 @ 28168 updates, score 15.318) (writing took 2.015676881885156 seconds)
2022-03-06 08:34:38 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-06 08:34:38 | INFO | train | epoch 579 | loss 0.428 | nll_loss 0.123 | ppl 1.09 | wps 28094 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28168 | lr 0.000188418 | gnorm 0.333 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65562
2022-03-06 08:34:38 | INFO | fairseq.trainer | begin training epoch 580
2022-03-06 08:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:35:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:35:51 | INFO | train_inner | epoch 580:     33 / 49 loss=0.428, nll_loss=0.124, ppl=1.09, wps=27865.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.333, loss_scale=32, train_wall=197, gb_free=21.6, wall=65635
2022-03-06 08:36:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:36:29 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 15.253 | nll_loss 15.152 | ppl 36413.9 | wps 48083.1 | wpb 510.9 | bsz 1 | num_updates 28216 | best_loss 8.204
2022-03-06 08:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28216 updates
2022-03-06 08:36:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 580 @ 28216 updates, score 15.253) (writing took 2.0281045369338244 seconds)
2022-03-06 08:36:31 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-06 08:36:31 | INFO | train | epoch 580 | loss 0.428 | nll_loss 0.124 | ppl 1.09 | wps 27524.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28216 | lr 0.000188257 | gnorm 0.333 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65675
2022-03-06 08:36:31 | INFO | fairseq.trainer | begin training epoch 581
2022-03-06 08:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:38:22 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 15.307 | nll_loss 15.205 | ppl 37769.3 | wps 48510.1 | wpb 510.9 | bsz 1 | num_updates 28265 | best_loss 8.204
2022-03-06 08:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28265 updates
2022-03-06 08:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 581 @ 28265 updates, score 15.307) (writing took 2.074747729115188 seconds)
2022-03-06 08:38:24 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-06 08:38:24 | INFO | train | epoch 581 | loss 0.427 | nll_loss 0.123 | ppl 1.09 | wps 28068.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28265 | lr 0.000188094 | gnorm 0.329 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65789
2022-03-06 08:38:25 | INFO | fairseq.trainer | begin training epoch 582
2022-03-06 08:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:39:41 | INFO | train_inner | epoch 582:     35 / 49 loss=0.427, nll_loss=0.123, ppl=1.09, wps=28112.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.331, loss_scale=32, train_wall=195, gb_free=21.6, wall=65865
2022-03-06 08:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:40:16 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 15.194 | nll_loss 15.093 | ppl 34950.9 | wps 48161.2 | wpb 510.9 | bsz 1 | num_updates 28314 | best_loss 8.204
2022-03-06 08:40:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28314 updates
2022-03-06 08:40:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:40:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:40:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 582 @ 28314 updates, score 15.194) (writing took 2.005816536024213 seconds)
2022-03-06 08:40:18 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-06 08:40:18 | INFO | train | epoch 582 | loss 0.428 | nll_loss 0.124 | ppl 1.09 | wps 28097.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28314 | lr 0.000187931 | gnorm 0.334 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 65902
2022-03-06 08:40:18 | INFO | fairseq.trainer | begin training epoch 583
2022-03-06 08:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:40:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:42:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:42:09 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 15.266 | nll_loss 15.166 | ppl 36756.7 | wps 47965.5 | wpb 510.9 | bsz 1 | num_updates 28362 | best_loss 8.204
2022-03-06 08:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28362 updates
2022-03-06 08:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:42:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 583 @ 28362 updates, score 15.266) (writing took 2.0239937941078097 seconds)
2022-03-06 08:42:11 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-06 08:42:11 | INFO | train | epoch 583 | loss 0.427 | nll_loss 0.123 | ppl 1.09 | wps 27529.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28362 | lr 0.000187772 | gnorm 0.335 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66015
2022-03-06 08:42:11 | INFO | fairseq.trainer | begin training epoch 584
2022-03-06 08:42:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:34 | INFO | train_inner | epoch 584:     38 / 49 loss=0.427, nll_loss=0.123, ppl=1.09, wps=27865.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.333, loss_scale=32, train_wall=197, gb_free=21.6, wall=66098
2022-03-06 08:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:44:02 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 15.189 | nll_loss 15.088 | ppl 34824.3 | wps 48122.8 | wpb 510.9 | bsz 1 | num_updates 28411 | best_loss 8.204
2022-03-06 08:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28411 updates
2022-03-06 08:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:44:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 584 @ 28411 updates, score 15.189) (writing took 2.076328347902745 seconds)
2022-03-06 08:44:04 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-06 08:44:04 | INFO | train | epoch 584 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 28059.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28411 | lr 0.00018761 | gnorm 0.33 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66128
2022-03-06 08:44:04 | INFO | fairseq.trainer | begin training epoch 585
2022-03-06 08:44:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:45:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:45:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:55 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 15.271 | nll_loss 15.17 | ppl 36866.3 | wps 48185 | wpb 510.9 | bsz 1 | num_updates 28459 | best_loss 8.204
2022-03-06 08:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28459 updates
2022-03-06 08:45:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 585 @ 28459 updates, score 15.271) (writing took 1.995781792094931 seconds)
2022-03-06 08:45:57 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-06 08:45:57 | INFO | train | epoch 585 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 27514.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28459 | lr 0.000187452 | gnorm 0.333 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66241
2022-03-06 08:45:57 | INFO | fairseq.trainer | begin training epoch 586
2022-03-06 08:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:47:27 | INFO | train_inner | epoch 586:     41 / 49 loss=0.427, nll_loss=0.123, ppl=1.09, wps=27862, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.333, loss_scale=32, train_wall=197, gb_free=21.6, wall=66331
2022-03-06 08:47:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:48 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 15.283 | nll_loss 15.182 | ppl 37175.6 | wps 47834.2 | wpb 510.9 | bsz 1 | num_updates 28508 | best_loss 8.204
2022-03-06 08:47:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28508 updates
2022-03-06 08:47:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:47:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:47:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 586 @ 28508 updates, score 15.283) (writing took 2.0117815150879323 seconds)
2022-03-06 08:47:50 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-06 08:47:50 | INFO | train | epoch 586 | loss 0.427 | nll_loss 0.123 | ppl 1.09 | wps 28085.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28508 | lr 0.000187291 | gnorm 0.335 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66354
2022-03-06 08:47:50 | INFO | fairseq.trainer | begin training epoch 587
2022-03-06 08:47:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:41 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 15.205 | nll_loss 15.103 | ppl 35181.9 | wps 47846.9 | wpb 510.9 | bsz 1 | num_updates 28557 | best_loss 8.204
2022-03-06 08:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28557 updates
2022-03-06 08:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 587 @ 28557 updates, score 15.205) (writing took 2.064161299029365 seconds)
2022-03-06 08:49:43 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-06 08:49:43 | INFO | train | epoch 587 | loss 0.427 | nll_loss 0.123 | ppl 1.09 | wps 28087.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28557 | lr 0.00018713 | gnorm 0.34 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66467
2022-03-06 08:49:43 | INFO | fairseq.trainer | begin training epoch 588
2022-03-06 08:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:51:18 | INFO | train_inner | epoch 588:     43 / 49 loss=0.427, nll_loss=0.123, ppl=1.09, wps=28115.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.338, loss_scale=64, train_wall=195, gb_free=21.6, wall=66562
2022-03-06 08:51:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:51:34 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 15.259 | nll_loss 15.158 | ppl 36552.1 | wps 48348.4 | wpb 510.9 | bsz 1 | num_updates 28606 | best_loss 8.204
2022-03-06 08:51:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28606 updates
2022-03-06 08:51:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:51:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:51:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 588 @ 28606 updates, score 15.259) (writing took 2.0074094070587307 seconds)
2022-03-06 08:51:36 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-06 08:51:36 | INFO | train | epoch 588 | loss 0.426 | nll_loss 0.123 | ppl 1.09 | wps 28103.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28606 | lr 0.00018697 | gnorm 0.335 | loss_scale 64 | train_wall 96 | gb_free 21.6 | wall 66581
2022-03-06 08:51:36 | INFO | fairseq.trainer | begin training epoch 589
2022-03-06 08:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:52:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:53:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:53:28 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 15.261 | nll_loss 15.162 | ppl 36666.7 | wps 47517.4 | wpb 510.9 | bsz 1 | num_updates 28654 | best_loss 8.204
2022-03-06 08:53:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28654 updates
2022-03-06 08:53:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:53:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 589 @ 28654 updates, score 15.261) (writing took 2.0077081420458853 seconds)
2022-03-06 08:53:30 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-06 08:53:30 | INFO | train | epoch 589 | loss 0.426 | nll_loss 0.122 | ppl 1.09 | wps 27497.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28654 | lr 0.000186813 | gnorm 0.334 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66694
2022-03-06 08:53:30 | INFO | fairseq.trainer | begin training epoch 590
2022-03-06 08:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:55:11 | INFO | train_inner | epoch 590:     46 / 49 loss=0.426, nll_loss=0.122, ppl=1.09, wps=27862, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.333, loss_scale=32, train_wall=197, gb_free=21.6, wall=66795
2022-03-06 08:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:21 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 15.2 | nll_loss 15.098 | ppl 35077 | wps 48079.3 | wpb 510.9 | bsz 1 | num_updates 28703 | best_loss 8.204
2022-03-06 08:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28703 updates
2022-03-06 08:55:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:55:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt
2022-03-06 08:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.01_#1/checkpoint_last.pt (epoch 590 @ 28703 updates, score 15.2) (writing took 2.0577023930381984 seconds)
2022-03-06 08:55:23 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-06 08:55:23 | INFO | train | epoch 590 | loss 0.426 | nll_loss 0.122 | ppl 1.09 | wps 28088.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28703 | lr 0.000186654 | gnorm 0.332 | loss_scale 32 | train_wall 96 | gb_free 21.6 | wall 66807
2022-03-06 08:55:23 | INFO | fairseq.trainer | begin training epoch 591
2022-03-06 08:55:23 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4216, in multi_head_attention_forward
    k = linear(key, k_proj_weight_non_opt, in_proj_bias[embed_dim:(embed_dim * 2)])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 1692, in linear
    output = input.matmul(weight.t())
KeyboardInterrupt
