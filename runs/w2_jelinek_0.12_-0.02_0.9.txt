Sender: LSF System <lsfadmin@eu-g2-11>
Subject: Job 202287079: <w2_jelinek_0.12_-0.02_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.12_-0.02_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 07:38:16 2022
Job was executed on host(s) <eu-g2-11>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 07:38:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 07:38:20 2022
Terminated at Sat Jan 29 03:38:34 2022
Results reported at Sat Jan 29 03:38:34 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.12, -0.02, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72889.00 sec.
    Max Memory :                                 5071 MB
    Average Memory :                             2673.59 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14929.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72013 sec.
    Turnaround time :                            72018 sec.

The output (if any) follows:

2022-01-28 07:38:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.12, -0.02, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 07:38:26 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 07:38:27 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1444/36718 [00:00<00:02, 14402.35it/s]  8%|▊         | 2885/36718 [00:00<00:02, 13616.44it/s] 12%|█▏        | 4480/36718 [00:00<00:02, 14637.52it/s] 17%|█▋        | 6091/36718 [00:00<00:02, 15193.57it/s] 21%|██        | 7615/36718 [00:00<00:02, 14473.09it/s] 25%|██▍       | 9070/36718 [00:00<00:01, 14445.51it/s] 29%|██▊       | 10520/36718 [00:00<00:01, 14225.09it/s] 33%|███▎      | 11988/36718 [00:00<00:01, 14364.47it/s] 37%|███▋      | 13428/36718 [00:00<00:01, 14298.35it/s] 41%|████      | 14934/36718 [00:01<00:01, 14523.08it/s] 45%|████▍     | 16388/36718 [00:01<00:01, 14241.73it/s] 49%|████▊     | 17875/36718 [00:01<00:01, 14420.77it/s] 53%|█████▎    | 19471/36718 [00:01<00:01, 14877.34it/s] 57%|█████▋    | 20961/36718 [00:01<00:01, 14481.00it/s] 61%|██████    | 22413/36718 [00:01<00:00, 14373.97it/s] 65%|██████▌   | 24047/36718 [00:01<00:00, 14946.45it/s] 70%|██████▉   | 25631/36718 [00:01<00:00, 15207.91it/s] 74%|███████▍  | 27155/36718 [00:01<00:00, 14455.03it/s] 78%|███████▊  | 28712/36718 [00:01<00:00, 14771.22it/s] 82%|████████▏ | 30197/36718 [00:02<00:00, 14454.42it/s] 86%|████████▌ | 31649/36718 [00:02<00:00, 14114.86it/s] 90%|█████████ | 33066/36718 [00:02<00:00, 13696.28it/s] 94%|█████████▍| 34578/36718 [00:02<00:00, 14091.18it/s] 98%|█████████▊| 35993/36718 [00:02<00:00, 14000.92it/s]100%|██████████| 36718/36718 [00:02<00:00, 14397.64it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2803/36718 [00:00<00:01, 28027.29it/s] 16%|█▋        | 6053/36718 [00:00<00:01, 30656.27it/s] 25%|██▍       | 9119/36718 [00:00<00:00, 29172.08it/s] 33%|███▎      | 12052/36718 [00:00<00:00, 29231.82it/s] 41%|████      | 14981/36718 [00:00<00:00, 29226.11it/s] 49%|████▉     | 17907/36718 [00:00<00:00, 28757.27it/s] 57%|█████▋    | 20873/36718 [00:00<00:00, 29044.68it/s] 65%|██████▍   | 23850/36718 [00:00<00:00, 29265.60it/s] 73%|███████▎  | 26802/36718 [00:00<00:00, 29342.31it/s] 81%|████████  | 29738/36718 [00:01<00:00, 29290.25it/s] 89%|████████▉ | 32669/36718 [00:01<00:00, 28648.70it/s] 97%|█████████▋| 35538/36718 [00:01<00:00, 28614.84it/s]100%|██████████| 36718/36718 [00:01<00:00, 28999.84it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 208.45it/s]2022-01-28 07:38:36 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 07:38:36 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 07:38:36 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 07:38:36 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 07:38:36 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 07:38:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 07:38:36 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 07:38:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 07:38:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:38:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-28 07:38:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 07:38:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 07:38:36 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 07:38:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint_last.pt
2022-01-28 07:38:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint_last.pt
2022-01-28 07:38:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 07:38:36 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 07:38:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 07:38:36 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 07:38:36 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 07:43:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 07:44:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.734 | ppl 27252.2 | wps 8074.6 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 07:44:24 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 07:44:24 | INFO | train | epoch 001 | loss 16.133 | ppl 71855.8 | wps 6015.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.167 | train_wall 320 | gb_free 6.1 | wall 348
KL Stats: Epoch 1 Divergences: Uniform: 0.5170226998716474 Unigram: 3.686172123755342
2022-01-28 07:44:24 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 07:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:47:25 | INFO | train_inner | epoch 002:     36 / 64 loss=15.605, ppl=49852.7, wps=6195.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.594, train_wall=500, gb_free=6.1, wall=529
2022-01-28 07:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:50:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.755 | ppl 13827.8 | wps 8106.9 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:50:11 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:50:11 | INFO | train | epoch 002 | loss 14.464 | ppl 22604.4 | wps 6024.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.46 | train_wall 319 | gb_free 6.1 | wall 695
KL Stats: Epoch 2 Divergences: Uniform: 0.5326072519692219 Unigram: 2.417891821647505
2022-01-28 07:50:11 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:55:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.952 | ppl 7924.37 | wps 8108.2 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:55:58 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:55:58 | INFO | train | epoch 003 | loss 13.583 | ppl 12272.6 | wps 6020.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.175 | train_wall 319 | gb_free 6.1 | wall 1042
KL Stats: Epoch 3 Divergences: Uniform: 0.5135492255726868 Unigram: 1.7379617259283358
2022-01-28 07:55:58 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:56:38 | INFO | train_inner | epoch 004:      8 / 64 loss=13.713, ppl=13428.7, wps=5890.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.204, train_wall=498, gb_free=6.1, wall=1082
2022-01-28 08:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:01:44 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.13 | ppl 4481.22 | wps 8108.4 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 08:01:44 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 08:01:44 | INFO | train | epoch 004 | loss 12.655 | ppl 6449.35 | wps 6025.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.934 | train_wall 319 | gb_free 6.1 | wall 1389
KL Stats: Epoch 4 Divergences: Uniform: 0.59280870194124 Unigram: 1.1323036095115062
2022-01-28 08:01:44 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 08:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:05:25 | INFO | train_inner | epoch 005:     44 / 64 loss=12.316, ppl=5098.2, wps=6199.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.824, train_wall=499, gb_free=6.1, wall=1609
2022-01-28 08:07:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:07:31 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.623 | ppl 3154.15 | wps 8099.6 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 08:07:31 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 08:07:31 | INFO | train | epoch 005 | loss 11.883 | ppl 3775.88 | wps 6026 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.675 | train_wall 319 | gb_free 6.1 | wall 1735
KL Stats: Epoch 5 Divergences: Uniform: 0.8194153718402319 Unigram: 0.687219500700421
2022-01-28 08:07:31 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 08:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:13:18 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.376 | ppl 2657.59 | wps 8122 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 08:13:18 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 08:13:18 | INFO | train | epoch 006 | loss 11.462 | ppl 2821.32 | wps 6022.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.578 | train_wall 319 | gb_free 6.1 | wall 2082
KL Stats: Epoch 6 Divergences: Uniform: 1.098516527885762 Unigram: 0.4979954465357293
2022-01-28 08:13:18 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 08:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:14:38 | INFO | train_inner | epoch 007:     16 / 64 loss=11.484, ppl=2864.15, wps=5894.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.576, train_wall=498, gb_free=6.1, wall=2162
2022-01-28 08:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:19:05 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.229 | ppl 2400.04 | wps 8080.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 08:19:05 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 08:19:05 | INFO | train | epoch 007 | loss 11.263 | ppl 2458.28 | wps 6019 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 319 | gb_free 6.1 | wall 2429
KL Stats: Epoch 7 Divergences: Uniform: 1.3044228638430146 Unigram: 0.5186413961730953
2022-01-28 08:19:05 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 08:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:23:26 | INFO | train_inner | epoch 008:     52 / 64 loss=11.201, ppl=2354.17, wps=6192.3, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=500, gb_free=6.1, wall=2690
2022-01-28 08:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:24:52 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.12 | ppl 2225.02 | wps 8107.8 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 08:24:52 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 08:24:52 | INFO | train | epoch 008 | loss 11.148 | ppl 2269.29 | wps 6017.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.513 | train_wall 319 | gb_free 6.1 | wall 2776
KL Stats: Epoch 8 Divergences: Uniform: 1.4067154478825732 Unigram: 0.6077752292447232
2022-01-28 08:24:52 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 08:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:30:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.998 | ppl 2045.13 | wps 8093.4 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 08:30:39 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 08:30:39 | INFO | train | epoch 009 | loss 11.037 | ppl 2101.35 | wps 6017 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.485 | train_wall 319 | gb_free 6.1 | wall 3123
KL Stats: Epoch 9 Divergences: Uniform: 1.4441777877790685 Unigram: 0.730597650057678
2022-01-28 08:30:39 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 08:30:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:32:39 | INFO | train_inner | epoch 010:     24 / 64 loss=11.027, ppl=2087.18, wps=5890.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.486, train_wall=498, gb_free=6.1, wall=3244
2022-01-28 08:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:36:26 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.889 | ppl 1895.91 | wps 8109.4 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 08:36:26 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 08:36:26 | INFO | train | epoch 010 | loss 10.922 | ppl 1940.65 | wps 6025.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 319 | gb_free 6.1 | wall 3470
KL Stats: Epoch 10 Divergences: Uniform: 1.4649863841530486 Unigram: 0.8675036791743462
2022-01-28 08:36:26 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 08:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:41:27 | INFO | train_inner | epoch 011:     60 / 64 loss=10.843, ppl=1836.8, wps=6194, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=499, gb_free=6.1, wall=3771
2022-01-28 08:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:42:13 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.779 | ppl 1756.94 | wps 8092.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:42:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:42:13 | INFO | train | epoch 011 | loss 10.801 | ppl 1784.66 | wps 6017 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.497 | train_wall 319 | gb_free 6.1 | wall 3817
KL Stats: Epoch 11 Divergences: Uniform: 1.4812844336112234 Unigram: 1.0063934496017335
2022-01-28 08:42:13 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:47:59 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.665 | ppl 1623.49 | wps 8109.6 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:47:59 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:47:59 | INFO | train | epoch 012 | loss 10.681 | ppl 1641.9 | wps 6023.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.486 | train_wall 319 | gb_free 6.1 | wall 4164
KL Stats: Epoch 12 Divergences: Uniform: 1.4915332048139305 Unigram: 1.1406165777816806
2022-01-28 08:47:59 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:50:40 | INFO | train_inner | epoch 013:     32 / 64 loss=10.657, ppl=1614.18, wps=5893.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.5, train_wall=498, gb_free=6.1, wall=4324
2022-01-28 08:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:53:46 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.575 | ppl 1525.02 | wps 8088.7 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:53:46 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:53:46 | INFO | train | epoch 013 | loss 10.564 | ppl 1514.14 | wps 6023.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.518 | train_wall 319 | gb_free 6.1 | wall 4511
KL Stats: Epoch 13 Divergences: Uniform: 1.5142653002719904 Unigram: 1.2598585602023367
2022-01-28 08:53:46 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:59:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.479 | ppl 1427.19 | wps 8111.6 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 08:59:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 08:59:33 | INFO | train | epoch 014 | loss 10.452 | ppl 1400.56 | wps 6019.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.558 | train_wall 319 | gb_free 6.1 | wall 4858
KL Stats: Epoch 14 Divergences: Uniform: 1.5410855905352514 Unigram: 1.3690226776992487
2022-01-28 08:59:33 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 08:59:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:59:53 | INFO | train_inner | epoch 015:      4 / 64 loss=10.475, ppl=1422.98, wps=5892.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.536, train_wall=498, gb_free=6.1, wall=4878
2022-01-28 09:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:05:20 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.407 | ppl 1358.1 | wps 8075.4 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 09:05:20 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 09:05:20 | INFO | train | epoch 015 | loss 10.339 | ppl 1295.43 | wps 6015.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.545 | train_wall 319 | gb_free 6.1 | wall 5205
KL Stats: Epoch 15 Divergences: Uniform: 1.5623268699095718 Unigram: 1.4702822090094745
2022-01-28 09:05:20 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 09:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:08:42 | INFO | train_inner | epoch 016:     40 / 64 loss=10.298, ppl=1258.74, wps=6185.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.565, train_wall=500, gb_free=6.1, wall=5406
2022-01-28 09:10:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:11:08 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.326 | ppl 1283.19 | wps 8078.1 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 09:11:08 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 09:11:08 | INFO | train | epoch 016 | loss 10.232 | ppl 1202.86 | wps 6002.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.56 | train_wall 320 | gb_free 6.1 | wall 5553
KL Stats: Epoch 16 Divergences: Uniform: 1.588697463207863 Unigram: 1.566514510342242
2022-01-28 09:11:08 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 09:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:16:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:16:57 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.234 | ppl 1204.04 | wps 8070.5 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 09:16:57 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 09:16:57 | INFO | train | epoch 017 | loss 10.125 | ppl 1116.87 | wps 5996.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.554 | train_wall 320 | gb_free 6.1 | wall 5901
KL Stats: Epoch 17 Divergences: Uniform: 1.6207072158628075 Unigram: 1.6509711818593478
2022-01-28 09:16:57 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 09:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:17:57 | INFO | train_inner | epoch 018:     12 / 64 loss=10.139, ppl=1127.91, wps=5868.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.554, train_wall=500, gb_free=6.1, wall=5961
2022-01-28 09:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:22:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.17 | ppl 1152.16 | wps 8038.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 09:22:45 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 09:22:45 | INFO | train | epoch 018 | loss 10.025 | ppl 1041.98 | wps 6004.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.578 | train_wall 320 | gb_free 6.1 | wall 6249
KL Stats: Epoch 18 Divergences: Uniform: 1.652658116060842 Unigram: 1.7354387132210356
2022-01-28 09:22:45 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 09:22:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:26:46 | INFO | train_inner | epoch 019:     48 / 64 loss=9.975, ppl=1006.66, wps=6175.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.544, train_wall=501, gb_free=6.1, wall=6491
2022-01-28 09:28:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:28:33 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.093 | ppl 1092.03 | wps 8052 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 09:28:33 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 09:28:33 | INFO | train | epoch 019 | loss 9.921 | ppl 969.74 | wps 5998.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 320 | gb_free 6.1 | wall 6597
KL Stats: Epoch 19 Divergences: Uniform: 1.6802421214048249 Unigram: 1.8181145653637896
2022-01-28 09:28:33 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 09:28:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:34:21 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.008 | ppl 1029.86 | wps 8046.1 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 09:34:21 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 09:34:21 | INFO | train | epoch 020 | loss 9.825 | ppl 907.08 | wps 5995.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.56 | train_wall 320 | gb_free 6.1 | wall 6945
KL Stats: Epoch 20 Divergences: Uniform: 1.7106897226715427 Unigram: 1.8956319996901105
2022-01-28 09:34:21 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 09:34:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:36:02 | INFO | train_inner | epoch 021:     20 / 64 loss=9.82, ppl=903.84, wps=5865.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.554, train_wall=500, gb_free=6.1, wall=7047
2022-01-28 09:39:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:40:10 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.964 | ppl 998.72 | wps 8088.1 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 09:40:10 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 09:40:10 | INFO | train | epoch 021 | loss 9.73 | ppl 849.48 | wps 5988 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.536 | train_wall 321 | gb_free 6.1 | wall 7294
KL Stats: Epoch 21 Divergences: Uniform: 1.737469847817131 Unigram: 1.972170572412104
2022-01-28 09:40:10 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 09:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:44:52 | INFO | train_inner | epoch 022:     56 / 64 loss=9.678, ppl=819.15, wps=6166.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.55, train_wall=502, gb_free=6.1, wall=7577
2022-01-28 09:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:45:59 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.902 | ppl 956.64 | wps 8022.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:45:59 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:45:59 | INFO | train | epoch 022 | loss 9.641 | ppl 798.66 | wps 5990.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.56 | train_wall 321 | gb_free 6.1 | wall 7643
KL Stats: Epoch 22 Divergences: Uniform: 1.7617096044305056 Unigram: 2.048672271737828
2022-01-28 09:45:59 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:51:47 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.838 | ppl 914.92 | wps 8047.7 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:51:47 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:51:47 | INFO | train | epoch 023 | loss 9.554 | ppl 751.87 | wps 5988 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.522 | train_wall 321 | gb_free 6.1 | wall 7992
KL Stats: Epoch 23 Divergences: Uniform: 1.7909643627303047 Unigram: 2.116576932347514
2022-01-28 09:51:47 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:54:09 | INFO | train_inner | epoch 024:     28 / 64 loss=9.539, ppl=744.14, wps=5854, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.537, train_wall=501, gb_free=6.1, wall=8133
2022-01-28 09:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:57:38 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.775 | ppl 875.87 | wps 7965.9 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:57:38 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:57:38 | INFO | train | epoch 024 | loss 9.471 | ppl 709.64 | wps 5963.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.564 | train_wall 322 | gb_free 6.1 | wall 8342
KL Stats: Epoch 24 Divergences: Uniform: 1.811124942750334 Unigram: 2.1791437055288925
2022-01-28 09:57:38 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:03:00 | INFO | train_inner | epoch 025:     64 / 64 loss=9.417, ppl=683.64, wps=6140.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.548, train_wall=502, gb_free=6.1, wall=8664
2022-01-28 10:03:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:03:27 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.746 | ppl 858.98 | wps 8018.6 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 10:03:27 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 10:03:27 | INFO | train | epoch 025 | loss 9.39 | ppl 670.69 | wps 5974.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.537 | train_wall 321 | gb_free 6.1 | wall 8692
KL Stats: Epoch 25 Divergences: Uniform: 1.8396168865207243 Unigram: 2.246612374538112
2022-01-28 10:03:27 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 10:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:08:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:09:17 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.692 | ppl 827.08 | wps 8015.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 10:09:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 10:09:17 | INFO | train | epoch 026 | loss 9.308 | ppl 633.76 | wps 5974.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.543 | train_wall 321 | gb_free 6.1 | wall 9041
KL Stats: Epoch 26 Divergences: Uniform: 1.849553204725649 Unigram: 2.3056847182475773
2022-01-28 10:09:17 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 10:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:12:19 | INFO | train_inner | epoch 027:     36 / 64 loss=9.28, ppl=621.76, wps=5849.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.542, train_wall=503, gb_free=6.1, wall=9223
2022-01-28 10:14:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:15:06 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.666 | ppl 812.25 | wps 7997.3 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 10:15:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 10:15:06 | INFO | train | epoch 027 | loss 9.228 | ppl 599.74 | wps 5979 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.537 | train_wall 321 | gb_free 6.1 | wall 9390
KL Stats: Epoch 27 Divergences: Uniform: 1.8754222585633231 Unigram: 2.364272406404938
2022-01-28 10:15:06 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 10:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:20:54 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.633 | ppl 794.01 | wps 8070.3 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 10:20:54 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 10:20:54 | INFO | train | epoch 028 | loss 9.15 | ppl 568.05 | wps 5995.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.53 | train_wall 320 | gb_free 6.1 | wall 9739
KL Stats: Epoch 28 Divergences: Uniform: 1.904559111097787 Unigram: 2.4211359034630124
2022-01-28 10:20:54 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 10:20:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:21:35 | INFO | train_inner | epoch 029:      8 / 64 loss=9.166, ppl=574.29, wps=5860.9, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.536, train_wall=500, gb_free=6.1, wall=9779
2022-01-28 10:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:26:43 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.592 | ppl 771.96 | wps 8046.4 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 10:26:43 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 10:26:43 | INFO | train | epoch 029 | loss 9.072 | ppl 538.34 | wps 5989.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.542 | train_wall 321 | gb_free 6.1 | wall 10088
KL Stats: Epoch 29 Divergences: Uniform: 1.9228185937503048 Unigram: 2.4735840073808584
2022-01-28 10:26:43 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 10:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:30:25 | INFO | train_inner | epoch 030:     44 / 64 loss=9.039, ppl=526.09, wps=6162, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.529, train_wall=502, gb_free=6.1, wall=10310
2022-01-28 10:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:32:32 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.572 | ppl 761.09 | wps 8057.4 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 10:32:32 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 10:32:32 | INFO | train | epoch 030 | loss 8.994 | ppl 509.97 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.527 | train_wall 321 | gb_free 6.1 | wall 10436
KL Stats: Epoch 30 Divergences: Uniform: 1.9422763157991425 Unigram: 2.5308478554777714
2022-01-28 10:32:32 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 10:32:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:38:20 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.529 | ppl 738.93 | wps 8038.4 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 10:38:20 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 10:38:20 | INFO | train | epoch 031 | loss 8.915 | ppl 482.71 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.505 | train_wall 320 | gb_free 6.1 | wall 10785
KL Stats: Epoch 31 Divergences: Uniform: 1.9598587239735719 Unigram: 2.5811944532754207
2022-01-28 10:38:20 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 10:38:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:39:41 | INFO | train_inner | epoch 032:     16 / 64 loss=8.916, ppl=483.08, wps=5866.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.51, train_wall=500, gb_free=6.1, wall=10865
2022-01-28 10:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:44:09 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.487 | ppl 717.6 | wps 8064.8 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 10:44:09 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 10:44:09 | INFO | train | epoch 032 | loss 8.841 | ppl 458.72 | wps 5995.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.518 | train_wall 320 | gb_free 6.1 | wall 11133
KL Stats: Epoch 32 Divergences: Uniform: 1.9860209049355226 Unigram: 2.631945506763416
2022-01-28 10:44:09 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 10:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:48:31 | INFO | train_inner | epoch 033:     52 / 64 loss=8.805, ppl=447.22, wps=6165.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.526, train_wall=502, gb_free=6.1, wall=11395
2022-01-28 10:49:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:49:57 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.475 | ppl 711.72 | wps 8041.8 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 10:49:57 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 10:49:57 | INFO | train | epoch 033 | loss 8.767 | ppl 435.76 | wps 5989.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.525 | train_wall 321 | gb_free 6.1 | wall 11482
KL Stats: Epoch 33 Divergences: Uniform: 2.0101869885147914 Unigram: 2.692164783947636
2022-01-28 10:49:57 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 10:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:55:46 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.455 | ppl 702.08 | wps 8087.3 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:55:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:55:46 | INFO | train | epoch 034 | loss 8.691 | ppl 413.31 | wps 5993.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.519 | train_wall 321 | gb_free 6.1 | wall 11830
KL Stats: Epoch 34 Divergences: Uniform: 2.0281553317111065 Unigram: 2.744016696652253
2022-01-28 10:55:46 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:57:47 | INFO | train_inner | epoch 035:     24 / 64 loss=8.678, ppl=409.69, wps=5865.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.521, train_wall=500, gb_free=6.1, wall=11951
2022-01-28 11:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:01:34 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.418 | ppl 683.89 | wps 8028.4 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 11:01:34 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 11:01:34 | INFO | train | epoch 035 | loss 8.619 | ppl 393.17 | wps 5995.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.522 | train_wall 320 | gb_free 6.1 | wall 12179
KL Stats: Epoch 35 Divergences: Uniform: 2.0493113558608798 Unigram: 2.7907456132606883
2022-01-28 11:01:34 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 11:01:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:06:37 | INFO | train_inner | epoch 036:     60 / 64 loss=8.575, ppl=381.37, wps=6167.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.519, train_wall=501, gb_free=6.1, wall=12481
2022-01-28 11:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:07:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.396 | ppl 673.53 | wps 8022.6 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 11:07:23 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 11:07:23 | INFO | train | epoch 036 | loss 8.545 | ppl 373.58 | wps 5990.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.517 | train_wall 321 | gb_free 6.1 | wall 12527
KL Stats: Epoch 36 Divergences: Uniform: 2.0729371958502756 Unigram: 2.8467430210198184
2022-01-28 11:07:23 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 11:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:12:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:13:11 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.424 | ppl 686.8 | wps 8042.9 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 11:13:11 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 11:13:11 | INFO | train | epoch 037 | loss 8.475 | ppl 355.88 | wps 5993.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.519 | train_wall 320 | gb_free 6.1 | wall 12876
KL Stats: Epoch 37 Divergences: Uniform: 2.0889475731864486 Unigram: 2.8997331375658804
2022-01-28 11:13:11 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 11:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:15:53 | INFO | train_inner | epoch 038:     32 / 64 loss=8.454, ppl=350.7, wps=5860.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.519, train_wall=500, gb_free=6.1, wall=13037
2022-01-28 11:18:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:19:00 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.402 | ppl 676.33 | wps 8061.6 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 11:19:00 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 11:19:00 | INFO | train | epoch 038 | loss 8.407 | ppl 339.48 | wps 5989.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.523 | train_wall 321 | gb_free 6.1 | wall 13224
KL Stats: Epoch 38 Divergences: Uniform: 2.115740677964354 Unigram: 2.941568202883521
2022-01-28 11:19:00 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 11:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:24:49 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.372 | ppl 662.62 | wps 8025.1 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 11:24:49 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 11:24:49 | INFO | train | epoch 039 | loss 8.338 | ppl 323.52 | wps 5989.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.515 | train_wall 321 | gb_free 6.1 | wall 13573
KL Stats: Epoch 39 Divergences: Uniform: 2.123905963068055 Unigram: 2.9966322437054416
2022-01-28 11:24:49 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 11:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:25:09 | INFO | train_inner | epoch 040:      4 / 64 loss=8.36, ppl=328.45, wps=5861.3, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.52, train_wall=500, gb_free=6.1, wall=13593
2022-01-28 11:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:30:37 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.349 | ppl 652.33 | wps 8055.3 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 11:30:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 11:30:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint40.pt
2022-01-28 11:30:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint40.pt
2022-01-28 11:30:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.349) (writing took 5.752643659710884 seconds)
2022-01-28 11:30:43 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 11:30:43 | INFO | train | epoch 040 | loss 8.268 | ppl 308.31 | wps 5893.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.511 | train_wall 321 | gb_free 6.1 | wall 13927
KL Stats: Epoch 40 Divergences: Uniform: 2.152274182252338 Unigram: 3.048564895438555
2022-01-28 11:30:43 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 11:30:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:34:05 | INFO | train_inner | epoch 041:     40 / 64 loss=8.245, ppl=303.32, wps=6096.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.509, train_wall=502, gb_free=6.1, wall=14129
2022-01-28 11:36:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:36:32 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.336 | ppl 646.37 | wps 8058.5 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.336
2022-01-28 11:36:32 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 11:36:32 | INFO | train | epoch 041 | loss 8.205 | ppl 295 | wps 5988.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.512 | train_wall 321 | gb_free 6.1 | wall 14276
KL Stats: Epoch 41 Divergences: Uniform: 2.1665100541265074 Unigram: 3.0907407243993616
2022-01-28 11:36:32 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 11:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:42:21 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.324 | ppl 641.04 | wps 8020.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.324
2022-01-28 11:42:21 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 11:42:21 | INFO | train | epoch 042 | loss 8.141 | ppl 282.21 | wps 5991.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.524 | train_wall 320 | gb_free 6.1 | wall 14625
KL Stats: Epoch 42 Divergences: Uniform: 2.1839597728905336 Unigram: 3.145813340035958
2022-01-28 11:42:21 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 11:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:43:21 | INFO | train_inner | epoch 043:     12 / 64 loss=8.147, ppl=283.46, wps=5861.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.524, train_wall=500, gb_free=6.1, wall=14686
2022-01-28 11:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:48:09 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.351 | ppl 653.16 | wps 8055.1 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.349
2022-01-28 11:48:09 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 11:48:09 | INFO | train | epoch 043 | loss 8.075 | ppl 269.69 | wps 5987.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.519 | train_wall 321 | gb_free 6.1 | wall 14974
KL Stats: Epoch 43 Divergences: Uniform: 2.2048518450271803 Unigram: 3.1932352377582114
2022-01-28 11:48:09 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 11:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:52:11 | INFO | train_inner | epoch 044:     48 / 64 loss=8.042, ppl=263.47, wps=6164.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.525, train_wall=502, gb_free=6.1, wall=15216
2022-01-28 11:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:53:58 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.377 | ppl 664.77 | wps 8049.1 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.349
2022-01-28 11:53:58 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 11:53:58 | INFO | train | epoch 044 | loss 8.016 | ppl 258.81 | wps 5992.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.524 | train_wall 321 | gb_free 6.1 | wall 15322
KL Stats: Epoch 44 Divergences: Uniform: 2.221998399064851 Unigram: 3.237437205265958
2022-01-28 11:53:58 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 11:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:59:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:59:46 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.348 | ppl 651.52 | wps 8068.7 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.348
2022-01-28 11:59:46 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 11:59:46 | INFO | train | epoch 045 | loss 7.952 | ppl 247.69 | wps 5995.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.522 | train_wall 320 | gb_free 6.1 | wall 15671
KL Stats: Epoch 45 Divergences: Uniform: 2.2378169945277904 Unigram: 3.2908846207105262
2022-01-28 11:59:46 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 11:59:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:01:27 | INFO | train_inner | epoch 046:     20 / 64 loss=7.952, ppl=247.6, wps=5865.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.522, train_wall=500, gb_free=6.1, wall=15771
2022-01-28 12:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:05:35 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.358 | ppl 656.27 | wps 7994.5 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.349
2022-01-28 12:05:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 12:05:35 | INFO | train | epoch 046 | loss 7.894 | ppl 237.81 | wps 5990.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.531 | train_wall 320 | gb_free 6.1 | wall 16019
KL Stats: Epoch 46 Divergences: Uniform: 2.254317586918275 Unigram: 3.3281483328506463
2022-01-28 12:05:35 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 12:05:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:10:17 | INFO | train_inner | epoch 047:     56 / 64 loss=7.863, ppl=232.75, wps=6164.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.519, train_wall=501, gb_free=6.1, wall=16302
2022-01-28 12:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:11:23 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.336 | ppl 646.11 | wps 8050.9 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.336
2022-01-28 12:11:23 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 12:11:23 | INFO | train | epoch 047 | loss 7.834 | ppl 228.25 | wps 5992.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.514 | train_wall 320 | gb_free 6.1 | wall 16368
KL Stats: Epoch 47 Divergences: Uniform: 2.2720260080421335 Unigram: 3.3707604787109484
2022-01-28 12:11:23 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 12:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:17:12 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.344 | ppl 649.69 | wps 8016.7 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.344
2022-01-28 12:17:12 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 12:17:12 | INFO | train | epoch 048 | loss 7.777 | ppl 219.34 | wps 5986.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.526 | train_wall 321 | gb_free 6.1 | wall 16717
KL Stats: Epoch 48 Divergences: Uniform: 2.290408583889524 Unigram: 3.42255803314358
2022-01-28 12:17:12 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 12:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:19:34 | INFO | train_inner | epoch 049:     28 / 64 loss=7.76, ppl=216.7, wps=5859.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.524, train_wall=501, gb_free=6.1, wall=16858
2022-01-28 12:22:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:23:01 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.366 | ppl 659.68 | wps 8064.3 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.349
2022-01-28 12:23:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 12:23:01 | INFO | train | epoch 049 | loss 7.72 | ppl 210.87 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.527 | train_wall 321 | gb_free 6.1 | wall 17065
KL Stats: Epoch 49 Divergences: Uniform: 2.295788612357257 Unigram: 3.4656696867741745
2022-01-28 12:23:01 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 12:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:28:22 | INFO | train_inner | epoch 050:     64 / 64 loss=7.696, ppl=207.3, wps=6168.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.54, train_wall=500, gb_free=6.1, wall=17386
2022-01-28 12:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:28:49 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.386 | ppl 669.15 | wps 8045.5 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.349
2022-01-28 12:28:49 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 12:28:49 | INFO | train | epoch 050 | loss 7.669 | ppl 203.52 | wps 5995.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.546 | train_wall 320 | gb_free 6.1 | wall 17414
KL Stats: Epoch 50 Divergences: Uniform: 2.311621046574233 Unigram: 3.500539473623791
2022-01-28 12:28:49 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 12:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:34:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.383 | ppl 667.82 | wps 7960.5 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.349
2022-01-28 12:34:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 12:34:38 | INFO | train | epoch 051 | loss 7.613 | ppl 195.82 | wps 5988.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.533 | train_wall 320 | gb_free 6.1 | wall 17762
KL Stats: Epoch 51 Divergences: Uniform: 2.3336203669739786 Unigram: 3.5356269744148374
2022-01-28 12:34:38 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 12:34:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:37:40 | INFO | train_inner | epoch 052:     36 / 64 loss=7.59, ppl=192.61, wps=5862.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.535, train_wall=501, gb_free=6.1, wall=17944
2022-01-28 12:39:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:40:27 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.401 | ppl 676.15 | wps 8051.6 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.349
2022-01-28 12:40:27 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 12:40:27 | INFO | train | epoch 052 | loss 7.56 | ppl 188.75 | wps 5992.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.539 | train_wall 321 | gb_free 6.1 | wall 18111
KL Stats: Epoch 52 Divergences: Uniform: 2.3484696459357495 Unigram: 3.5913565612823444
2022-01-28 12:40:27 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 12:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:46:15 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.374 | ppl 663.64 | wps 8064.7 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.349
2022-01-28 12:46:15 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 12:46:15 | INFO | train | epoch 053 | loss 7.508 | ppl 182.04 | wps 5993.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.525 | train_wall 320 | gb_free 6.1 | wall 18459
KL Stats: Epoch 53 Divergences: Uniform: 2.365758582215493 Unigram: 3.629402703303419
2022-01-28 12:46:15 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 12:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:46:55 | INFO | train_inner | epoch 054:      8 / 64 loss=7.521, ppl=183.7, wps=5864.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.535, train_wall=500, gb_free=6.1, wall=18500
2022-01-28 12:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:52:04 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.424 | ppl 686.78 | wps 8039.1 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.349
2022-01-28 12:52:04 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 12:52:04 | INFO | train | epoch 054 | loss 7.458 | ppl 175.87 | wps 5988 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.535 | train_wall 321 | gb_free 6.1 | wall 18808
KL Stats: Epoch 54 Divergences: Uniform: 2.3711146948552373 Unigram: 3.660567313049086
2022-01-28 12:52:04 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 12:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:55:46 | INFO | train_inner | epoch 055:     44 / 64 loss=7.431, ppl=172.51, wps=6164.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.533, train_wall=502, gb_free=6.1, wall=19030
2022-01-28 12:57:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:57:52 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.415 | ppl 682.82 | wps 8066.3 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.349
2022-01-28 12:57:52 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 12:57:52 | INFO | train | epoch 055 | loss 7.411 | ppl 170.16 | wps 5995.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.549 | train_wall 320 | gb_free 6.1 | wall 19157
KL Stats: Epoch 55 Divergences: Uniform: 2.382140170189205 Unigram: 3.711443226971311
2022-01-28 12:57:52 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 12:57:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:03:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:03:41 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.484 | ppl 716.28 | wps 8075.3 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.349
2022-01-28 13:03:41 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 13:03:41 | INFO | train | epoch 056 | loss 7.362 | ppl 164.5 | wps 5988.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.547 | train_wall 321 | gb_free 6.1 | wall 19505
KL Stats: Epoch 56 Divergences: Uniform: 2.387184757578918 Unigram: 3.7452151427203373
2022-01-28 13:03:41 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 13:03:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:05:02 | INFO | train_inner | epoch 057:     16 / 64 loss=7.366, ppl=164.91, wps=5859.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.552, train_wall=501, gb_free=6.1, wall=19586
2022-01-28 13:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:09:30 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.512 | ppl 730.34 | wps 8057.2 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.349
2022-01-28 13:09:30 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 13:09:30 | INFO | train | epoch 057 | loss 7.313 | ppl 159.06 | wps 5992.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.555 | train_wall 321 | gb_free 6.1 | wall 19854
KL Stats: Epoch 57 Divergences: Uniform: 2.4135845605923874 Unigram: 3.7941191768942546
2022-01-28 13:09:30 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 13:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:13:52 | INFO | train_inner | epoch 058:     52 / 64 loss=7.289, ppl=156.34, wps=6168.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.551, train_wall=501, gb_free=6.1, wall=20116
2022-01-28 13:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:15:18 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.509 | ppl 728.54 | wps 8074.8 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.349
2022-01-28 13:15:18 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 13:15:18 | INFO | train | epoch 058 | loss 7.268 | ppl 154.11 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.549 | train_wall 321 | gb_free 6.1 | wall 20202
KL Stats: Epoch 58 Divergences: Uniform: 2.4240695148693208 Unigram: 3.827986533939177
2022-01-28 13:15:18 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 13:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:21:06 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.592 | ppl 771.5 | wps 8048.9 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.349
2022-01-28 13:21:06 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 13:21:06 | INFO | train | epoch 059 | loss 7.223 | ppl 149.45 | wps 5997 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.553 | train_wall 320 | gb_free 6.1 | wall 20551
KL Stats: Epoch 59 Divergences: Uniform: 2.437197490210434 Unigram: 3.866729309650934
2022-01-28 13:21:06 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 13:21:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:23:07 | INFO | train_inner | epoch 060:     24 / 64 loss=7.217, ppl=148.8, wps=5869.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.559, train_wall=500, gb_free=6.1, wall=20671
2022-01-28 13:26:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:26:55 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.577 | ppl 763.9 | wps 8055.7 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.349
2022-01-28 13:26:55 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 13:26:55 | INFO | train | epoch 060 | loss 7.178 | ppl 144.82 | wps 5993.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.566 | train_wall 320 | gb_free 6.1 | wall 20899
KL Stats: Epoch 60 Divergences: Uniform: 2.444973611641184 Unigram: 3.914577004330665
2022-01-28 13:26:55 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 13:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:31:57 | INFO | train_inner | epoch 061:     60 / 64 loss=7.159, ppl=142.89, wps=6163.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.564, train_wall=502, gb_free=6.1, wall=21202
2022-01-28 13:32:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:32:44 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.64 | ppl 797.71 | wps 8004.2 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.349
2022-01-28 13:32:44 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 13:32:44 | INFO | train | epoch 061 | loss 7.136 | ppl 140.63 | wps 5988.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.567 | train_wall 321 | gb_free 6.1 | wall 21248
KL Stats: Epoch 61 Divergences: Uniform: 2.460539255785614 Unigram: 3.93243252156948
2022-01-28 13:32:44 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 13:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:38:32 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.607 | ppl 779.8 | wps 8035.9 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.349
2022-01-28 13:38:32 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 13:38:32 | INFO | train | epoch 062 | loss 7.093 | ppl 136.55 | wps 5991.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.564 | train_wall 321 | gb_free 6.1 | wall 21597
KL Stats: Epoch 62 Divergences: Uniform: 2.4693935913241707 Unigram: 3.989700635697542
2022-01-28 13:38:32 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 13:38:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:41:14 | INFO | train_inner | epoch 063:     32 / 64 loss=7.068, ppl=134.13, wps=5851.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.565, train_wall=501, gb_free=6.1, wall=21759
2022-01-28 13:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:44:22 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.623 | ppl 788.43 | wps 8061.2 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.349
2022-01-28 13:44:22 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 13:44:22 | INFO | train | epoch 063 | loss 7.051 | ppl 132.59 | wps 5972 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.575 | train_wall 322 | gb_free 6.1 | wall 21946
KL Stats: Epoch 63 Divergences: Uniform: 2.481570212617748 Unigram: 4.022885566174693
2022-01-28 13:44:22 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 13:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:50:11 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.691 | ppl 826.81 | wps 8034 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.349
2022-01-28 13:50:11 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 13:50:11 | INFO | train | epoch 064 | loss 7.007 | ppl 128.64 | wps 5985.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.572 | train_wall 321 | gb_free 6.1 | wall 22295
KL Stats: Epoch 64 Divergences: Uniform: 2.491668205921564 Unigram: 4.054489908036369
2022-01-28 13:50:11 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 13:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:50:31 | INFO | train_inner | epoch 065:      4 / 64 loss=7.035, ppl=131.11, wps=5855.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.577, train_wall=501, gb_free=6.1, wall=22315
2022-01-28 13:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:56:00 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.688 | ppl 824.85 | wps 8021.8 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.349
2022-01-28 13:56:00 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 13:56:00 | INFO | train | epoch 065 | loss 6.964 | ppl 124.85 | wps 5976.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 22645
KL Stats: Epoch 65 Divergences: Uniform: 2.500474979546247 Unigram: 4.095581800102711
2022-01-28 13:56:00 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 13:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:59:22 | INFO | train_inner | epoch 066:     40 / 64 loss=6.94, ppl=122.8, wps=6156.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.587, train_wall=502, gb_free=6.1, wall=22846
2022-01-28 14:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:01:49 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.736 | ppl 852.69 | wps 8051 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.349
2022-01-28 14:01:49 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 14:01:49 | INFO | train | epoch 066 | loss 6.924 | ppl 121.46 | wps 5992.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.582 | train_wall 321 | gb_free 6.1 | wall 22993
KL Stats: Epoch 66 Divergences: Uniform: 2.5066929579945176 Unigram: 4.133835475073356
2022-01-28 14:01:49 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 14:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:07:38 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.711 | ppl 838.31 | wps 8032.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.349
2022-01-28 14:07:38 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 14:07:38 | INFO | train | epoch 067 | loss 6.881 | ppl 117.88 | wps 5986 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.58 | train_wall 321 | gb_free 6.1 | wall 23342
KL Stats: Epoch 67 Divergences: Uniform: 2.524318336329352 Unigram: 4.178278225028033
2022-01-28 14:07:38 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 14:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:08:38 | INFO | train_inner | epoch 068:     12 / 64 loss=6.89, ppl=118.61, wps=5861.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.575, train_wall=500, gb_free=6.1, wall=23403
2022-01-28 14:12:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:13:26 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.79 | ppl 885.54 | wps 8078.1 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.349
2022-01-28 14:13:26 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 14:13:26 | INFO | train | epoch 068 | loss 6.844 | ppl 114.88 | wps 6000.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.592 | train_wall 320 | gb_free 6.1 | wall 23690
KL Stats: Epoch 68 Divergences: Uniform: 2.541748799591979 Unigram: 4.218034655583259
2022-01-28 14:13:26 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 14:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:17:28 | INFO | train_inner | epoch 069:     48 / 64 loss=6.825, ppl=113.41, wps=6171, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.589, train_wall=501, gb_free=6.1, wall=23932
2022-01-28 14:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:19:14 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.788 | ppl 884.26 | wps 8050.1 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.349
2022-01-28 14:19:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 14:19:14 | INFO | train | epoch 069 | loss 6.805 | ppl 111.8 | wps 5993.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.587 | train_wall 320 | gb_free 6.1 | wall 24039
KL Stats: Epoch 69 Divergences: Uniform: 2.5457135530455717 Unigram: 4.249189192699529
2022-01-28 14:19:14 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 14:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:25:03 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.884 | ppl 945.07 | wps 8052.7 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.349
2022-01-28 14:25:03 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 14:25:03 | INFO | train | epoch 070 | loss 6.769 | ppl 109.07 | wps 5995.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.585 | train_wall 320 | gb_free 6.1 | wall 24387
KL Stats: Epoch 70 Divergences: Uniform: 2.5525051168584847 Unigram: 4.276057864949801
2022-01-28 14:25:03 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 14:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:26:44 | INFO | train_inner | epoch 071:     20 / 64 loss=6.764, ppl=108.67, wps=5865, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.591, train_wall=500, gb_free=6.1, wall=24488
2022-01-28 14:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:30:52 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.794 | ppl 888.01 | wps 8040.9 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.349
2022-01-28 14:30:52 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 14:30:52 | INFO | train | epoch 071 | loss 6.735 | ppl 106.5 | wps 5980.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.601 | train_wall 321 | gb_free 6.1 | wall 24736
KL Stats: Epoch 71 Divergences: Uniform: 2.568053779314213 Unigram: 4.324625967663233
2022-01-28 14:30:52 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 14:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:35:34 | INFO | train_inner | epoch 072:     56 / 64 loss=6.719, ppl=105.34, wps=6160.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.598, train_wall=502, gb_free=6.1, wall=25018
2022-01-28 14:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:36:40 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.791 | ppl 885.9 | wps 8019 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.349
2022-01-28 14:36:40 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 14:36:40 | INFO | train | epoch 072 | loss 6.699 | ppl 103.87 | wps 5994.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.596 | train_wall 320 | gb_free 6.1 | wall 25085
KL Stats: Epoch 72 Divergences: Uniform: 2.5823542092886704 Unigram: 4.363131451384523
2022-01-28 14:36:40 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 14:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:42:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:42:29 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.857 | ppl 927.32 | wps 8062.3 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.349
2022-01-28 14:42:29 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 14:42:29 | INFO | train | epoch 073 | loss 6.665 | ppl 101.48 | wps 5994.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.599 | train_wall 320 | gb_free 6.1 | wall 25433
KL Stats: Epoch 73 Divergences: Uniform: 2.58594255388127 Unigram: 4.391674006826551
2022-01-28 14:42:29 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 14:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:44:50 | INFO | train_inner | epoch 074:     28 / 64 loss=6.654, ppl=100.69, wps=5864.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.6, train_wall=500, gb_free=6.1, wall=25574
2022-01-28 14:47:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:48:17 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.841 | ppl 917.1 | wps 8063.7 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.349
2022-01-28 14:48:17 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 14:48:17 | INFO | train | epoch 074 | loss 6.632 | ppl 99.16 | wps 5993.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.601 | train_wall 320 | gb_free 6.1 | wall 25782
KL Stats: Epoch 74 Divergences: Uniform: 2.5920228078743115 Unigram: 4.428997452291869
2022-01-28 14:48:17 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 14:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:53:39 | INFO | train_inner | epoch 075:     64 / 64 loss=6.623, ppl=98.59, wps=6159.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.606, train_wall=501, gb_free=6.1, wall=26104
2022-01-28 14:53:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:54:07 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.977 | ppl 1007.82 | wps 7992.7 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.349
2022-01-28 14:54:07 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 14:54:07 | INFO | train | epoch 075 | loss 6.603 | ppl 97.22 | wps 5979.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.608 | train_wall 321 | gb_free 6.1 | wall 26131
KL Stats: Epoch 75 Divergences: Uniform: 2.600179611181504 Unigram: 4.466142522352196
2022-01-28 14:54:07 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 14:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:59:55 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.885 | ppl 945.24 | wps 8042.7 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.349
2022-01-28 14:59:55 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 14:59:55 | INFO | train | epoch 076 | loss 6.573 | ppl 95.19 | wps 5992.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.619 | train_wall 321 | gb_free 6.1 | wall 26479
KL Stats: Epoch 76 Divergences: Uniform: 2.6064722198303465 Unigram: 4.506014047174839
2022-01-28 14:59:55 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 14:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:02:56 | INFO | train_inner | epoch 077:     36 / 64 loss=6.547, ppl=93.51, wps=5864.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.623, train_wall=501, gb_free=6.1, wall=26661
2022-01-28 15:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:05:43 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.854 | ppl 925.62 | wps 7993.5 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.349
2022-01-28 15:05:43 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 15:05:43 | INFO | train | epoch 077 | loss 6.541 | ppl 93.15 | wps 5995.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.63 | train_wall 320 | gb_free 6.1 | wall 26828
KL Stats: Epoch 77 Divergences: Uniform: 2.6194052876126643 Unigram: 4.5455997190208794
2022-01-28 15:05:43 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 15:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:11:32 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.853 | ppl 924.89 | wps 8057.5 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.349
2022-01-28 15:11:32 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 15:11:32 | INFO | train | epoch 078 | loss 6.513 | ppl 91.35 | wps 5993.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.628 | train_wall 320 | gb_free 6.1 | wall 27176
KL Stats: Epoch 78 Divergences: Uniform: 2.626427832678377 Unigram: 4.575199792187213
2022-01-28 15:11:32 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 15:11:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:12:12 | INFO | train_inner | epoch 079:      8 / 64 loss=6.528, ppl=92.28, wps=5863.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.631, train_wall=500, gb_free=6.1, wall=27217
2022-01-28 15:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:17:21 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 10.021 | ppl 1039.21 | wps 8031.6 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.349
2022-01-28 15:17:21 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 15:17:21 | INFO | train | epoch 079 | loss 6.483 | ppl 89.45 | wps 5982.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.626 | train_wall 321 | gb_free 6.1 | wall 27525
KL Stats: Epoch 79 Divergences: Uniform: 2.6292567864768093 Unigram: 4.603806391536952
2022-01-28 15:17:21 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 15:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:21:03 | INFO | train_inner | epoch 080:     44 / 64 loss=6.466, ppl=88.42, wps=6161.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.627, train_wall=502, gb_free=6.1, wall=27747
2022-01-28 15:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:23:10 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.95 | ppl 989.15 | wps 8031.7 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.349
2022-01-28 15:23:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 15:23:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint80.pt
2022-01-28 15:23:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint80.pt
2022-01-28 15:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.95) (writing took 3.2680705450475216 seconds)
2022-01-28 15:23:13 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 15:23:13 | INFO | train | epoch 080 | loss 6.456 | ppl 87.81 | wps 5932.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.632 | train_wall 321 | gb_free 6.1 | wall 27877
KL Stats: Epoch 80 Divergences: Uniform: 2.6320918093138252 Unigram: 4.640487117233987
2022-01-28 15:23:13 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 15:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:29:02 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 10.001 | ppl 1024.41 | wps 8062.1 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.349
2022-01-28 15:29:02 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 15:29:02 | INFO | train | epoch 081 | loss 6.431 | ppl 86.3 | wps 5984.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.657 | train_wall 321 | gb_free 6.1 | wall 28227
KL Stats: Epoch 81 Divergences: Uniform: 2.651677842993129 Unigram: 4.688501099189863
2022-01-28 15:29:02 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 15:29:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:30:23 | INFO | train_inner | epoch 082:     16 / 64 loss=6.438, ppl=86.68, wps=5821.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.654, train_wall=501, gb_free=6.1, wall=28307
2022-01-28 15:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:34:50 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.954 | ppl 991.59 | wps 8043.6 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.349
2022-01-28 15:34:50 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 15:34:50 | INFO | train | epoch 082 | loss 6.404 | ppl 84.67 | wps 5997 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.639 | train_wall 320 | gb_free 6.1 | wall 28575
KL Stats: Epoch 82 Divergences: Uniform: 2.6531543711583137 Unigram: 4.726408429321479
2022-01-28 15:34:50 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 15:34:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:39:13 | INFO | train_inner | epoch 083:     52 / 64 loss=6.388, ppl=83.75, wps=6165.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.641, train_wall=502, gb_free=6.1, wall=28837
2022-01-28 15:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:40:39 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.849 | ppl 922.17 | wps 8024 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.349
2022-01-28 15:40:39 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 15:40:39 | INFO | train | epoch 083 | loss 6.377 | ppl 83.11 | wps 5986 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.65 | train_wall 321 | gb_free 6.1 | wall 28924
KL Stats: Epoch 83 Divergences: Uniform: 2.6644130334079503 Unigram: 4.758470564062099
2022-01-28 15:40:39 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 15:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:46:28 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.955 | ppl 992.65 | wps 8044.3 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.349
2022-01-28 15:46:28 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 15:46:28 | INFO | train | epoch 084 | loss 6.351 | ppl 81.65 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.641 | train_wall 321 | gb_free 6.1 | wall 29272
KL Stats: Epoch 84 Divergences: Uniform: 2.675309250421435 Unigram: 4.7754287503848225
2022-01-28 15:46:28 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 15:46:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:48:29 | INFO | train_inner | epoch 085:     24 / 64 loss=6.341, ppl=81.07, wps=5858.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.646, train_wall=501, gb_free=6.1, wall=29394
2022-01-28 15:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:52:17 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 10.003 | ppl 1026.42 | wps 8069 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.349
2022-01-28 15:52:17 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 15:52:17 | INFO | train | epoch 085 | loss 6.328 | ppl 80.34 | wps 5979.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.659 | train_wall 321 | gb_free 6.1 | wall 29622
KL Stats: Epoch 85 Divergences: Uniform: 2.6836852224149337 Unigram: 4.813568913984235
2022-01-28 15:52:17 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 15:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:57:19 | INFO | train_inner | epoch 086:     60 / 64 loss=6.324, ppl=80.13, wps=6164.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.666, train_wall=502, gb_free=6.1, wall=29924
2022-01-28 15:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:58:06 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.987 | ppl 1014.72 | wps 8038.8 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.349
2022-01-28 15:58:06 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 15:58:06 | INFO | train | epoch 086 | loss 6.303 | ppl 78.95 | wps 5997.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.673 | train_wall 320 | gb_free 6.1 | wall 29970
KL Stats: Epoch 86 Divergences: Uniform: 2.6825720762285825 Unigram: 4.861045358872022
2022-01-28 15:58:06 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 15:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:03:54 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.993 | ppl 1018.95 | wps 8007.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.349
2022-01-28 16:03:54 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 16:03:54 | INFO | train | epoch 087 | loss 6.281 | ppl 77.74 | wps 5991 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.671 | train_wall 320 | gb_free 6.1 | wall 30319
KL Stats: Epoch 87 Divergences: Uniform: 2.6926709802426925 Unigram: 4.888424580646419
2022-01-28 16:03:54 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 16:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:06:36 | INFO | train_inner | epoch 088:     32 / 64 loss=6.268, ppl=77.05, wps=5861, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.673, train_wall=500, gb_free=6.1, wall=30480
2022-01-28 16:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:09:43 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.973 | ppl 1004.68 | wps 8020 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.349
2022-01-28 16:09:43 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 16:09:43 | INFO | train | epoch 088 | loss 6.258 | ppl 76.55 | wps 5987.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.677 | train_wall 321 | gb_free 6.1 | wall 30667
KL Stats: Epoch 88 Divergences: Uniform: 2.6986580098199147 Unigram: 4.923983305970458
2022-01-28 16:09:43 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 16:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:15:32 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.995 | ppl 1020.54 | wps 8004.4 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.349
2022-01-28 16:15:32 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 16:15:32 | INFO | train | epoch 089 | loss 6.238 | ppl 75.47 | wps 5988.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.692 | train_wall 321 | gb_free 6.1 | wall 31016
KL Stats: Epoch 89 Divergences: Uniform: 2.7057758938509573 Unigram: 4.950992447505566
2022-01-28 16:15:32 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 16:15:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:15:52 | INFO | train_inner | epoch 090:      4 / 64 loss=6.249, ppl=76.06, wps=5858.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.687, train_wall=501, gb_free=6.1, wall=31036
2022-01-28 16:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:21:20 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 10.102 | ppl 1099.02 | wps 8006.2 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.349
2022-01-28 16:21:20 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 16:21:20 | INFO | train | epoch 090 | loss 6.214 | ppl 74.23 | wps 5992.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.677 | train_wall 320 | gb_free 6.1 | wall 31365
KL Stats: Epoch 90 Divergences: Uniform: 2.7072136670919824 Unigram: 4.979719358394266
2022-01-28 16:21:20 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 16:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:24:42 | INFO | train_inner | epoch 091:     40 / 64 loss=6.196, ppl=73.31, wps=6166.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.677, train_wall=501, gb_free=6.1, wall=31566
2022-01-28 16:26:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:27:09 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 10.069 | ppl 1074.38 | wps 8039.5 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.349
2022-01-28 16:27:09 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 16:27:09 | INFO | train | epoch 091 | loss 6.192 | ppl 73.12 | wps 5995 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.677 | train_wall 320 | gb_free 6.1 | wall 31713
KL Stats: Epoch 91 Divergences: Uniform: 2.7130206301113895 Unigram: 5.030405883518156
2022-01-28 16:27:09 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 16:27:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:32:57 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 10.057 | ppl 1065.49 | wps 8089 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.349
2022-01-28 16:32:57 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 16:32:57 | INFO | train | epoch 092 | loss 6.172 | ppl 72.13 | wps 5998.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.7 | train_wall 320 | gb_free 6.1 | wall 32061
KL Stats: Epoch 92 Divergences: Uniform: 2.718511915714858 Unigram: 5.063069725375254
2022-01-28 16:32:57 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 16:32:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:33:58 | INFO | train_inner | epoch 093:     12 / 64 loss=6.182, ppl=72.58, wps=5868.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.69, train_wall=500, gb_free=6.1, wall=32122
2022-01-28 16:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:38:46 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.997 | ppl 1021.57 | wps 8051.2 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.349
2022-01-28 16:38:46 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 16:38:46 | INFO | train | epoch 093 | loss 6.155 | ppl 71.24 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.692 | train_wall 321 | gb_free 6.1 | wall 32410
KL Stats: Epoch 93 Divergences: Uniform: 2.7264422690979493 Unigram: 5.098909193920232
2022-01-28 16:38:46 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 16:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:42:47 | INFO | train_inner | epoch 094:     48 / 64 loss=6.139, ppl=70.48, wps=6166.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.702, train_wall=501, gb_free=6.1, wall=32652
2022-01-28 16:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:44:34 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 10.159 | ppl 1143.63 | wps 8052 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.349
2022-01-28 16:44:34 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 16:44:34 | INFO | train | epoch 094 | loss 6.132 | ppl 70.12 | wps 5998 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.706 | train_wall 320 | gb_free 6.1 | wall 32758
KL Stats: Epoch 94 Divergences: Uniform: 2.7249271900348013 Unigram: 5.127052812326553
2022-01-28 16:44:34 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 16:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:50:23 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 10.129 | ppl 1119.76 | wps 8075.5 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.349
2022-01-28 16:50:23 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 16:50:23 | INFO | train | epoch 095 | loss 6.113 | ppl 69.2 | wps 5990.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.703 | train_wall 321 | gb_free 6.1 | wall 33107
KL Stats: Epoch 95 Divergences: Uniform: 2.729566520762031 Unigram: 5.153382924414718
2022-01-28 16:50:23 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 16:50:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:52:03 | INFO | train_inner | epoch 096:     20 / 64 loss=6.112, ppl=69.17, wps=5864.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.709, train_wall=500, gb_free=6.1, wall=33208
2022-01-28 16:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:56:11 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 10.015 | ppl 1034.39 | wps 8070.3 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.349
2022-01-28 16:56:11 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 16:56:11 | INFO | train | epoch 096 | loss 6.095 | ppl 68.36 | wps 5991.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.722 | train_wall 321 | gb_free 6.1 | wall 33455
KL Stats: Epoch 96 Divergences: Uniform: 2.7414144320430833 Unigram: 5.1800355318647675
2022-01-28 16:56:11 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 16:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:00:54 | INFO | train_inner | epoch 097:     56 / 64 loss=6.089, ppl=68.06, wps=6163.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.726, train_wall=502, gb_free=6.1, wall=33738
2022-01-28 17:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:02:00 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 10.091 | ppl 1090.84 | wps 8020 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.349
2022-01-28 17:02:00 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 17:02:00 | INFO | train | epoch 097 | loss 6.077 | ppl 67.51 | wps 5986.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.73 | train_wall 321 | gb_free 6.1 | wall 33804
KL Stats: Epoch 97 Divergences: Uniform: 2.7485801717518594 Unigram: 5.221975507706576
2022-01-28 17:02:00 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 17:02:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:07:48 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 10.141 | ppl 1129.3 | wps 8062.1 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.349
2022-01-28 17:07:48 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 17:07:48 | INFO | train | epoch 098 | loss 6.057 | ppl 66.57 | wps 5999 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.744 | train_wall 320 | gb_free 6.1 | wall 34153
KL Stats: Epoch 98 Divergences: Uniform: 2.742112156342677 Unigram: 5.235719114846248
2022-01-28 17:07:48 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 17:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:10:09 | INFO | train_inner | epoch 099:     28 / 64 loss=6.048, ppl=66.16, wps=5865.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.741, train_wall=500, gb_free=6.1, wall=34294
2022-01-28 17:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:13:37 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 10.088 | ppl 1088.65 | wps 8052.2 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.349
2022-01-28 17:13:37 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 17:13:37 | INFO | train | epoch 099 | loss 6.039 | ppl 65.74 | wps 5993.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.739 | train_wall 320 | gb_free 6.1 | wall 34501
KL Stats: Epoch 99 Divergences: Uniform: 2.7550167192949275 Unigram: 5.279559448672251
2022-01-28 17:13:37 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 17:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:18:58 | INFO | train_inner | epoch 100:     64 / 64 loss=6.041, ppl=65.85, wps=6162, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.749, train_wall=501, gb_free=6.1, wall=34823
2022-01-28 17:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:19:26 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 10.171 | ppl 1153.22 | wps 8033.8 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.349
2022-01-28 17:19:26 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 17:19:26 | INFO | train | epoch 100 | loss 6.023 | ppl 65.04 | wps 5984.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.753 | train_wall 321 | gb_free 6.1 | wall 34850
KL Stats: Epoch 100 Divergences: Uniform: 2.7513088953532066 Unigram: 5.297096695626941
2022-01-28 17:19:26 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 17:19:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:25:15 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 10.145 | ppl 1132.42 | wps 8039 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.349
2022-01-28 17:25:15 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 17:25:15 | INFO | train | epoch 101 | loss 6.003 | ppl 64.14 | wps 5977.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.742 | train_wall 321 | gb_free 6.1 | wall 35199
KL Stats: Epoch 101 Divergences: Uniform: 2.7695404840901965 Unigram: 5.341145468456609
2022-01-28 17:25:15 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 17:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:28:17 | INFO | train_inner | epoch 102:     36 / 64 loss=5.988, ppl=63.48, wps=5849.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.745, train_wall=503, gb_free=6.1, wall=35382
2022-01-28 17:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:31:05 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 10.144 | ppl 1131.55 | wps 8030.8 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.349
2022-01-28 17:31:05 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 17:31:05 | INFO | train | epoch 102 | loss 5.989 | ppl 63.51 | wps 5976.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.759 | train_wall 321 | gb_free 6.1 | wall 35549
KL Stats: Epoch 102 Divergences: Uniform: 2.7671229965253983 Unigram: 5.372799971555531
2022-01-28 17:31:05 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 17:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:36:54 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 10.153 | ppl 1138.61 | wps 8036.7 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.349
2022-01-28 17:36:54 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 17:36:54 | INFO | train | epoch 103 | loss 5.972 | ppl 62.77 | wps 5980 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.766 | train_wall 321 | gb_free 6.1 | wall 35898
KL Stats: Epoch 103 Divergences: Uniform: 2.78051347220362 Unigram: 5.400099572318425
2022-01-28 17:36:54 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 17:36:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:37:34 | INFO | train_inner | epoch 104:      8 / 64 loss=5.98, ppl=63.11, wps=5852.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.765, train_wall=501, gb_free=6.1, wall=35938
2022-01-28 17:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:42:42 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 10.257 | ppl 1224.04 | wps 8041 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.349
2022-01-28 17:42:42 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 17:42:42 | INFO | train | epoch 104 | loss 5.956 | ppl 62.07 | wps 5999.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.774 | train_wall 320 | gb_free 6.1 | wall 36246
KL Stats: Epoch 104 Divergences: Uniform: 2.771505176359635 Unigram: 5.42961284842324
2022-01-28 17:42:42 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 17:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:46:24 | INFO | train_inner | epoch 105:     44 / 64 loss=5.943, ppl=61.51, wps=6166.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.776, train_wall=502, gb_free=6.1, wall=36468
2022-01-28 17:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:48:31 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 10.141 | ppl 1129.29 | wps 8059.3 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.349
2022-01-28 17:48:31 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 17:48:31 | INFO | train | epoch 105 | loss 5.939 | ppl 61.35 | wps 5984.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.775 | train_wall 321 | gb_free 6.1 | wall 36595
KL Stats: Epoch 105 Divergences: Uniform: 2.781366967435313 Unigram: 5.456687393899605
2022-01-28 17:48:31 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 17:48:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:53:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:54:19 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 10.222 | ppl 1194.6 | wps 8055.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.349
2022-01-28 17:54:19 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 17:54:19 | INFO | train | epoch 106 | loss 5.921 | ppl 60.59 | wps 5994.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.775 | train_wall 320 | gb_free 6.1 | wall 36944
KL Stats: Epoch 106 Divergences: Uniform: 2.781658120542646 Unigram: 5.476930085362935
2022-01-28 17:54:19 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 17:54:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:55:40 | INFO | train_inner | epoch 107:     16 / 64 loss=5.926, ppl=60.78, wps=5860.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.779, train_wall=501, gb_free=6.1, wall=37025
2022-01-28 17:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:00:09 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 10.204 | ppl 1179.79 | wps 8053 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.349
2022-01-28 18:00:09 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 18:00:09 | INFO | train | epoch 107 | loss 5.907 | ppl 60.02 | wps 5981.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.794 | train_wall 321 | gb_free 6.1 | wall 37293
KL Stats: Epoch 107 Divergences: Uniform: 2.793541268142551 Unigram: 5.524429024985458
2022-01-28 18:00:09 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 18:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:04:31 | INFO | train_inner | epoch 108:     52 / 64 loss=5.901, ppl=59.76, wps=6163.6, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.789, train_wall=502, gb_free=6.1, wall=37555
2022-01-28 18:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:05:57 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 10.304 | ppl 1264.21 | wps 8016.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.349
2022-01-28 18:05:57 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 18:05:57 | INFO | train | epoch 108 | loss 5.893 | ppl 59.42 | wps 5991.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.783 | train_wall 320 | gb_free 6.1 | wall 37642
KL Stats: Epoch 108 Divergences: Uniform: 2.787567707363151 Unigram: 5.532035693453515
2022-01-28 18:05:57 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 18:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:11:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:11:46 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 10.239 | ppl 1208.21 | wps 8042.2 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.349
2022-01-28 18:11:46 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 18:11:46 | INFO | train | epoch 109 | loss 5.879 | ppl 58.84 | wps 5993 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.792 | train_wall 320 | gb_free 6.1 | wall 37990
KL Stats: Epoch 109 Divergences: Uniform: 2.7956748434135346 Unigram: 5.586743527076745
2022-01-28 18:11:46 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 18:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:13:47 | INFO | train_inner | epoch 110:     24 / 64 loss=5.872, ppl=58.58, wps=5859.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.796, train_wall=500, gb_free=6.1, wall=38111
2022-01-28 18:17:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:17:34 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 10.286 | ppl 1248.72 | wps 8035.6 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.349
2022-01-28 18:17:34 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 18:17:34 | INFO | train | epoch 110 | loss 5.864 | ppl 58.26 | wps 5989.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.792 | train_wall 321 | gb_free 6.1 | wall 38339
KL Stats: Epoch 110 Divergences: Uniform: 2.7989709718037963 Unigram: 5.601566813545549
2022-01-28 18:17:34 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 18:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:22:37 | INFO | train_inner | epoch 111:     60 / 64 loss=5.864, ppl=58.24, wps=6166.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.808, train_wall=501, gb_free=6.1, wall=38641
2022-01-28 18:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:23:23 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 10.208 | ppl 1182.79 | wps 8029.2 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.349
2022-01-28 18:23:23 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 18:23:23 | INFO | train | epoch 111 | loss 5.851 | ppl 57.73 | wps 5990.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.823 | train_wall 321 | gb_free 6.1 | wall 38687
KL Stats: Epoch 111 Divergences: Uniform: 2.805893824463466 Unigram: 5.650463054723016
2022-01-28 18:23:23 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 18:23:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:29:12 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 10.24 | ppl 1209.75 | wps 8038.8 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.349
2022-01-28 18:29:12 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 18:29:12 | INFO | train | epoch 112 | loss 5.836 | ppl 57.14 | wps 5982.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.814 | train_wall 321 | gb_free 6.1 | wall 39037
KL Stats: Epoch 112 Divergences: Uniform: 2.8099933303413103 Unigram: 5.674875271463204
2022-01-28 18:29:12 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 18:29:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:31:54 | INFO | train_inner | epoch 113:     32 / 64 loss=5.824, ppl=56.65, wps=5853.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.811, train_wall=501, gb_free=6.1, wall=39198
2022-01-28 18:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:35:01 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 10.228 | ppl 1198.96 | wps 8043.6 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.349
2022-01-28 18:35:01 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 18:35:01 | INFO | train | epoch 113 | loss 5.82 | ppl 56.49 | wps 5981.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.809 | train_wall 321 | gb_free 6.1 | wall 39386
KL Stats: Epoch 113 Divergences: Uniform: 2.81370676373356 Unigram: 5.693165815093493
2022-01-28 18:35:01 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 18:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:40:50 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 10.268 | ppl 1232.9 | wps 8029.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.349
2022-01-28 18:40:50 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 18:40:50 | INFO | train | epoch 114 | loss 5.807 | ppl 55.97 | wps 5982.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.818 | train_wall 321 | gb_free 6.1 | wall 39735
KL Stats: Epoch 114 Divergences: Uniform: 2.8120761327197483 Unigram: 5.724704577348204
2022-01-28 18:40:50 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 18:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:41:11 | INFO | train_inner | epoch 115:      4 / 64 loss=5.819, ppl=56.46, wps=5854.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.819, train_wall=501, gb_free=6.1, wall=39755
2022-01-28 18:46:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:46:39 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 10.228 | ppl 1198.99 | wps 8040.9 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.349
2022-01-28 18:46:39 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 18:46:39 | INFO | train | epoch 115 | loss 5.794 | ppl 55.5 | wps 5991.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.831 | train_wall 321 | gb_free 6.1 | wall 40083
KL Stats: Epoch 115 Divergences: Uniform: 2.821579324685887 Unigram: 5.7500136536701065
2022-01-28 18:46:39 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 18:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:50:01 | INFO | train_inner | epoch 116:     40 / 64 loss=5.781, ppl=54.99, wps=6161.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.835, train_wall=502, gb_free=6.1, wall=40285
2022-01-28 18:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:52:28 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 10.239 | ppl 1208.39 | wps 8053 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.349
2022-01-28 18:52:28 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 18:52:28 | INFO | train | epoch 116 | loss 5.782 | ppl 55.01 | wps 5979.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.836 | train_wall 321 | gb_free 6.1 | wall 40433
KL Stats: Epoch 116 Divergences: Uniform: 2.8236457121620906 Unigram: 5.779848232091505
2022-01-28 18:52:28 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 18:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:57:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:58:17 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10.318 | ppl 1276.92 | wps 8063.8 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.349
2022-01-28 18:58:17 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 18:58:17 | INFO | train | epoch 117 | loss 5.768 | ppl 54.5 | wps 5987.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.841 | train_wall 321 | gb_free 6.1 | wall 40782
KL Stats: Epoch 117 Divergences: Uniform: 2.8230381952726837 Unigram: 5.810460595623208
2022-01-28 18:58:17 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 18:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:59:18 | INFO | train_inner | epoch 118:     12 / 64 loss=5.774, ppl=54.7, wps=5855.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.84, train_wall=501, gb_free=6.1, wall=40842
2022-01-28 19:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:04:06 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 10.27 | ppl 1234.98 | wps 8069.1 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.349
2022-01-28 19:04:06 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 19:04:06 | INFO | train | epoch 118 | loss 5.756 | ppl 54.05 | wps 5991.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.838 | train_wall 321 | gb_free 6.1 | wall 41130
KL Stats: Epoch 118 Divergences: Uniform: 2.833440660425043 Unigram: 5.835710789222904
2022-01-28 19:04:06 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 19:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:08:08 | INFO | train_inner | epoch 119:     48 / 64 loss=5.745, ppl=53.62, wps=6169, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.833, train_wall=501, gb_free=6.1, wall=41372
2022-01-28 19:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:09:54 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 10.253 | ppl 1220.29 | wps 8049 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.349
2022-01-28 19:09:54 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 19:09:54 | INFO | train | epoch 119 | loss 5.741 | ppl 53.49 | wps 5996.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.839 | train_wall 320 | gb_free 6.1 | wall 41478
KL Stats: Epoch 119 Divergences: Uniform: 2.8337932564235504 Unigram: 5.869955773359926
2022-01-28 19:09:54 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 19:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:15:43 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 10.332 | ppl 1289.36 | wps 8079.9 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.349
2022-01-28 19:15:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 19:15:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint120.pt
2022-01-28 19:15:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint120.pt
2022-01-28 19:15:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 10.332) (writing took 4.225525522604585 seconds)
2022-01-28 19:15:47 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 19:15:47 | INFO | train | epoch 120 | loss 5.731 | ppl 53.12 | wps 5917.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.861 | train_wall 321 | gb_free 6.1 | wall 41831
KL Stats: Epoch 120 Divergences: Uniform: 2.8332370996369396 Unigram: 5.895372774248593
2022-01-28 19:15:47 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 19:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:17:28 | INFO | train_inner | epoch 121:     20 / 64 loss=5.733, ppl=53.18, wps=5816.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.862, train_wall=501, gb_free=6.1, wall=41932
2022-01-28 19:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:21:36 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 10.337 | ppl 1293.5 | wps 8031.2 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.349
2022-01-28 19:21:36 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 19:21:36 | INFO | train | epoch 121 | loss 5.719 | ppl 52.66 | wps 5984.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.853 | train_wall 321 | gb_free 6.1 | wall 42180
KL Stats: Epoch 121 Divergences: Uniform: 2.840453143655275 Unigram: 5.925308641305882
2022-01-28 19:21:36 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 19:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:26:18 | INFO | train_inner | epoch 122:     56 / 64 loss=5.716, ppl=52.57, wps=6160.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.864, train_wall=502, gb_free=6.1, wall=42463
2022-01-28 19:26:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:27:25 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 10.29 | ppl 1252.11 | wps 8003.7 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.349
2022-01-28 19:27:25 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 19:27:25 | INFO | train | epoch 122 | loss 5.709 | ppl 52.29 | wps 5985.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.876 | train_wall 321 | gb_free 6.1 | wall 42529
KL Stats: Epoch 122 Divergences: Uniform: 2.8407068390133006 Unigram: 5.9580194398767405
2022-01-28 19:27:25 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 19:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:32:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:33:13 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.348 | ppl 1303.41 | wps 8050.3 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.349
2022-01-28 19:33:13 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 19:33:13 | INFO | train | epoch 123 | loss 5.693 | ppl 51.74 | wps 5994.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.849 | train_wall 320 | gb_free 6.1 | wall 42878
KL Stats: Epoch 123 Divergences: Uniform: 2.8450796220020034 Unigram: 5.990927245423257
2022-01-28 19:33:13 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 19:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:35:35 | INFO | train_inner | epoch 124:     28 / 64 loss=5.687, ppl=51.51, wps=5862, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.861, train_wall=500, gb_free=6.1, wall=43019
2022-01-28 19:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:39:02 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.337 | ppl 1293.75 | wps 8072.4 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.349
2022-01-28 19:39:02 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 19:39:02 | INFO | train | epoch 124 | loss 5.683 | ppl 51.36 | wps 5993.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.888 | train_wall 321 | gb_free 6.1 | wall 43226
KL Stats: Epoch 124 Divergences: Uniform: 2.836621256230198 Unigram: 6.016434477108931
2022-01-28 19:39:02 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 19:39:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:44:24 | INFO | train_inner | epoch 125:     64 / 64 loss=5.686, ppl=51.5, wps=6158.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.884, train_wall=501, gb_free=6.1, wall=43548
2022-01-28 19:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:44:51 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.364 | ppl 1317.95 | wps 8068.9 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.349
2022-01-28 19:44:51 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 19:44:51 | INFO | train | epoch 125 | loss 5.673 | ppl 51 | wps 5983.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.882 | train_wall 321 | gb_free 6.1 | wall 43575
KL Stats: Epoch 125 Divergences: Uniform: 2.847621082148444 Unigram: 6.04150035907256
2022-01-28 19:44:51 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 19:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:50:39 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 10.333 | ppl 1289.95 | wps 8056.4 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.349
2022-01-28 19:50:39 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 19:50:39 | INFO | train | epoch 126 | loss 5.661 | ppl 50.6 | wps 5995.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.88 | train_wall 320 | gb_free 6.1 | wall 43924
KL Stats: Epoch 126 Divergences: Uniform: 2.8517448355026684 Unigram: 6.073957236248072
2022-01-28 19:50:39 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 19:50:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:53:40 | INFO | train_inner | epoch 127:     36 / 64 loss=5.649, ppl=50.16, wps=5872.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.893, train_wall=501, gb_free=6.1, wall=44105
2022-01-28 19:56:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:56:27 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.309 | ppl 1268.22 | wps 8032.1 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.349
2022-01-28 19:56:27 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 19:56:27 | INFO | train | epoch 127 | loss 5.65 | ppl 50.22 | wps 6001.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.896 | train_wall 320 | gb_free 6.1 | wall 44272
KL Stats: Epoch 127 Divergences: Uniform: 2.8536565535554237 Unigram: 6.094152411830409
2022-01-28 19:56:27 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 19:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:02:15 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.404 | ppl 1355.28 | wps 8066.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.349
2022-01-28 20:02:15 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 20:02:15 | INFO | train | epoch 128 | loss 5.638 | ppl 49.8 | wps 6012.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.898 | train_wall 319 | gb_free 6.1 | wall 44619
KL Stats: Epoch 128 Divergences: Uniform: 2.8500663209797485 Unigram: 6.1204626375021425
2022-01-28 20:02:15 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 20:02:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:02:55 | INFO | train_inner | epoch 129:      8 / 64 loss=5.646, ppl=50.07, wps=5877.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.893, train_wall=499, gb_free=6.1, wall=44659
2022-01-28 20:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:08:02 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.326 | ppl 1283.5 | wps 8058.1 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.349
2022-01-28 20:08:02 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 20:08:02 | INFO | train | epoch 129 | loss 5.631 | ppl 49.55 | wps 6008.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.918 | train_wall 320 | gb_free 6.1 | wall 44967
KL Stats: Epoch 129 Divergences: Uniform: 2.8539764579539293 Unigram: 6.1541059365338135
2022-01-28 20:08:02 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 20:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:11:44 | INFO | train_inner | epoch 130:     44 / 64 loss=5.618, ppl=49.12, wps=6184, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.91, train_wall=500, gb_free=6.1, wall=45188
2022-01-28 20:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:13:50 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.438 | ppl 1387.19 | wps 8085.6 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.349
2022-01-28 20:13:50 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 20:13:50 | INFO | train | epoch 130 | loss 5.618 | ppl 49.1 | wps 6011.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.913 | train_wall 320 | gb_free 6.1 | wall 45314
KL Stats: Epoch 130 Divergences: Uniform: 2.8534471568561797 Unigram: 6.188594471440017
2022-01-28 20:13:50 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 20:13:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:19:38 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.434 | ppl 1382.92 | wps 7977.7 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.349
2022-01-28 20:19:38 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 20:19:38 | INFO | train | epoch 131 | loss 5.609 | ppl 48.81 | wps 5998.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.945 | train_wall 320 | gb_free 6.1 | wall 45662
KL Stats: Epoch 131 Divergences: Uniform: 2.856713625996366 Unigram: 6.207384034574587
2022-01-28 20:19:38 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 20:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:20:59 | INFO | train_inner | epoch 132:     16 / 64 loss=5.611, ppl=48.88, wps=5865.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.935, train_wall=500, gb_free=6.1, wall=45744
2022-01-28 20:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:25:29 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.384 | ppl 1336.02 | wps 7989.8 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.349
2022-01-28 20:25:29 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 20:25:29 | INFO | train | epoch 132 | loss 5.596 | ppl 48.38 | wps 5951.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.916 | train_wall 323 | gb_free 6.1 | wall 46013
KL Stats: Epoch 132 Divergences: Uniform: 2.8610398395824475 Unigram: 6.248070634104546
2022-01-28 20:25:29 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 20:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:29:52 | INFO | train_inner | epoch 133:     52 / 64 loss=5.592, ppl=48.22, wps=6139.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.934, train_wall=504, gb_free=6.1, wall=46276
2022-01-28 20:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:31:18 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.458 | ppl 1407.04 | wps 8042.2 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.349
2022-01-28 20:31:18 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 20:31:18 | INFO | train | epoch 133 | loss 5.588 | ppl 48.1 | wps 5983 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.948 | train_wall 321 | gb_free 6.1 | wall 46362
KL Stats: Epoch 133 Divergences: Uniform: 2.8641093406897356 Unigram: 6.262666555388578
2022-01-28 20:31:18 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 20:31:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:36:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:37:07 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.421 | ppl 1371.25 | wps 8056.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.349
2022-01-28 20:37:07 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 20:37:07 | INFO | train | epoch 134 | loss 5.577 | ppl 47.75 | wps 5990.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.937 | train_wall 321 | gb_free 6.1 | wall 46711
KL Stats: Epoch 134 Divergences: Uniform: 2.8649768439918106 Unigram: 6.302952686204838
2022-01-28 20:37:07 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 20:37:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:39:08 | INFO | train_inner | epoch 135:     24 / 64 loss=5.577, ppl=47.75, wps=5863, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.945, train_wall=500, gb_free=6.1, wall=46832
2022-01-28 20:42:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:42:55 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.437 | ppl 1386.01 | wps 8054.8 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.349
2022-01-28 20:42:55 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 20:42:55 | INFO | train | epoch 135 | loss 5.569 | ppl 47.47 | wps 5991 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.949 | train_wall 321 | gb_free 6.1 | wall 47060
KL Stats: Epoch 135 Divergences: Uniform: 2.868463406179727 Unigram: 6.3326568920983775
2022-01-28 20:42:55 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 20:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:47:58 | INFO | train_inner | epoch 136:     60 / 64 loss=5.569, ppl=47.46, wps=6164.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.95, train_wall=502, gb_free=6.1, wall=47362
2022-01-28 20:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:48:44 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.458 | ppl 1406.63 | wps 8043.3 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.349
2022-01-28 20:48:44 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 20:48:44 | INFO | train | epoch 136 | loss 5.559 | ppl 47.15 | wps 5993 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.952 | train_wall 320 | gb_free 6.1 | wall 47408
KL Stats: Epoch 136 Divergences: Uniform: 2.864423710666018 Unigram: 6.344324185591087
2022-01-28 20:48:44 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 20:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:54:33 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.445 | ppl 1393.74 | wps 7984.4 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.349
2022-01-28 20:54:33 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 20:54:33 | INFO | train | epoch 137 | loss 5.548 | ppl 46.79 | wps 5976.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.957 | train_wall 321 | gb_free 6.1 | wall 47758
KL Stats: Epoch 137 Divergences: Uniform: 2.8720553404904976 Unigram: 6.383697765433307
2022-01-28 20:54:33 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 20:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:57:16 | INFO | train_inner | epoch 138:     32 / 64 loss=5.541, ppl=46.55, wps=5843.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.967, train_wall=502, gb_free=6.1, wall=47920
2022-01-28 20:59:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:00:23 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.502 | ppl 1450.13 | wps 8025 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.349
2022-01-28 21:00:23 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 21:00:23 | INFO | train | epoch 138 | loss 5.54 | ppl 46.54 | wps 5968.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.982 | train_wall 322 | gb_free 6.1 | wall 48108
KL Stats: Epoch 138 Divergences: Uniform: 2.874516604161506 Unigram: 6.400091123432781
2022-01-28 21:00:23 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 21:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:06:13 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.485 | ppl 1433.49 | wps 7963.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.349
2022-01-28 21:06:13 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 21:06:13 | INFO | train | epoch 139 | loss 5.53 | ppl 46.21 | wps 5969 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.984 | train_wall 322 | gb_free 6.1 | wall 48457
KL Stats: Epoch 139 Divergences: Uniform: 2.881660025859482 Unigram: 6.4301678170323955
2022-01-28 21:06:13 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 21:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:06:34 | INFO | train_inner | epoch 140:      4 / 64 loss=5.538, ppl=46.45, wps=5842.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.982, train_wall=502, gb_free=6.1, wall=48478
2022-01-28 21:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:12:02 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.501 | ppl 1449.24 | wps 8023.5 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.349
2022-01-28 21:12:02 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 21:12:02 | INFO | train | epoch 140 | loss 5.521 | ppl 45.93 | wps 5978.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.991 | train_wall 321 | gb_free 6.1 | wall 48807
KL Stats: Epoch 140 Divergences: Uniform: 2.8686561334731047 Unigram: 6.454438959181811
2022-01-28 21:12:02 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 21:12:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:15:24 | INFO | train_inner | epoch 141:     40 / 64 loss=5.513, ppl=45.66, wps=6155.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.989, train_wall=502, gb_free=6.1, wall=49009
2022-01-28 21:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:17:51 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.49 | ppl 1437.68 | wps 8061.8 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.349
2022-01-28 21:17:51 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 21:17:51 | INFO | train | epoch 141 | loss 5.512 | ppl 45.63 | wps 5984.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.987 | train_wall 321 | gb_free 6.1 | wall 49156
KL Stats: Epoch 141 Divergences: Uniform: 2.8754361644089617 Unigram: 6.493843711856414
2022-01-28 21:17:51 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 21:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:23:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:23:40 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.459 | ppl 1407.63 | wps 8027.8 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.349
2022-01-28 21:23:40 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 21:23:40 | INFO | train | epoch 142 | loss 5.504 | ppl 45.39 | wps 5988.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 1.017 | train_wall 321 | gb_free 6.1 | wall 49505
KL Stats: Epoch 142 Divergences: Uniform: 2.8768031443694513 Unigram: 6.510805143126899
2022-01-28 21:23:40 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 21:23:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:24:41 | INFO | train_inner | epoch 143:     12 / 64 loss=5.505, ppl=45.42, wps=5859.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=1.008, train_wall=501, gb_free=6.1, wall=49565
2022-01-28 21:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:29:29 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.435 | ppl 1384.73 | wps 8007.5 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.349
2022-01-28 21:29:29 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 21:29:29 | INFO | train | epoch 143 | loss 5.496 | ppl 45.14 | wps 5985.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 1.018 | train_wall 321 | gb_free 6.1 | wall 49854
KL Stats: Epoch 143 Divergences: Uniform: 2.891237589289652 Unigram: 6.547804139531352
2022-01-28 21:29:29 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 21:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:33:32 | INFO | train_inner | epoch 144:     48 / 64 loss=5.492, ppl=45.02, wps=6154, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=1.012, train_wall=502, gb_free=6.1, wall=50096
2022-01-28 21:34:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:35:18 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.583 | ppl 1533.77 | wps 8053.6 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.349
2022-01-28 21:35:18 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 21:35:18 | INFO | train | epoch 144 | loss 5.488 | ppl 44.89 | wps 5979.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 1.009 | train_wall 321 | gb_free 6.1 | wall 50203
KL Stats: Epoch 144 Divergences: Uniform: 2.8783453608215304 Unigram: 6.545517881658412
2022-01-28 21:35:19 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 21:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:41:07 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.522 | ppl 1470.84 | wps 7998.8 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.349
2022-01-28 21:41:07 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 21:41:07 | INFO | train | epoch 145 | loss 5.479 | ppl 44.6 | wps 5986.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 1.006 | train_wall 321 | gb_free 6.1 | wall 50552
KL Stats: Epoch 145 Divergences: Uniform: 2.8909773504898064 Unigram: 6.598354756964401
2022-01-28 21:41:07 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 21:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:42:48 | INFO | train_inner | epoch 146:     20 / 64 loss=5.476, ppl=44.51, wps=5856.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=1.017, train_wall=501, gb_free=6.1, wall=50653
2022-01-28 21:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:46:57 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.498 | ppl 1446.44 | wps 8003.1 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.349
2022-01-28 21:46:57 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 21:46:57 | INFO | train | epoch 146 | loss 5.47 | ppl 44.32 | wps 5973.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 1.037 | train_wall 321 | gb_free 6.1 | wall 50901
KL Stats: Epoch 146 Divergences: Uniform: 2.8830149830895637 Unigram: 6.611513088503997
2022-01-28 21:46:57 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 21:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:51:40 | INFO | train_inner | epoch 147:     56 / 64 loss=5.471, ppl=44.35, wps=6146.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=1.034, train_wall=503, gb_free=6.1, wall=51184
2022-01-28 21:52:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:52:46 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.485 | ppl 1433.38 | wps 8043.4 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.349
2022-01-28 21:52:46 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 21:52:46 | INFO | train | epoch 147 | loss 5.461 | ppl 44.06 | wps 5978.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 1.031 | train_wall 321 | gb_free 6.1 | wall 51251
KL Stats: Epoch 147 Divergences: Uniform: 2.888657917195408 Unigram: 6.634974009822434
2022-01-28 21:52:46 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 21:52:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:58:36 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.476 | ppl 1424.57 | wps 8025.4 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.349
2022-01-28 21:58:36 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 21:58:36 | INFO | train | epoch 148 | loss 5.452 | ppl 43.78 | wps 5982.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 1.017 | train_wall 321 | gb_free 6.1 | wall 51600
KL Stats: Epoch 148 Divergences: Uniform: 2.8910309484255774 Unigram: 6.679379518646904
2022-01-28 21:58:36 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 21:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:00:57 | INFO | train_inner | epoch 149:     28 / 64 loss=5.447, ppl=43.64, wps=5856.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=1.025, train_wall=501, gb_free=6.1, wall=51741
2022-01-28 22:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:04:24 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.512 | ppl 1460.27 | wps 8037.9 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.349
2022-01-28 22:04:24 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 22:04:24 | INFO | train | epoch 149 | loss 5.447 | ppl 43.62 | wps 5991.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 1.075 | train_wall 321 | gb_free 6.1 | wall 51948
KL Stats: Epoch 149 Divergences: Uniform: 2.8954923794209244 Unigram: 6.6887378282034815
2022-01-28 22:04:24 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 22:04:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:09:46 | INFO | train_inner | epoch 150:     64 / 64 loss=5.449, ppl=43.67, wps=6158, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=1.066, train_wall=501, gb_free=6.1, wall=52271
2022-01-28 22:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:10:13 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.539 | ppl 1487.39 | wps 8058.1 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.349
2022-01-28 22:10:13 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 22:10:13 | INFO | train | epoch 150 | loss 5.437 | ppl 43.32 | wps 5981.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 1.045 | train_wall 321 | gb_free 6.1 | wall 52298
KL Stats: Epoch 150 Divergences: Uniform: 2.893940262195538 Unigram: 6.714705998454155
2022-01-28 22:10:13 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 22:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:15:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:16:02 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.625 | ppl 1579.28 | wps 8046.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.349
2022-01-28 22:16:02 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 22:16:02 | INFO | train | epoch 151 | loss 5.429 | ppl 43.09 | wps 5983 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 1.052 | train_wall 321 | gb_free 6.1 | wall 52647
KL Stats: Epoch 151 Divergences: Uniform: 2.8915532952777236 Unigram: 6.742053467910977
2022-01-28 22:16:02 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 22:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:19:04 | INFO | train_inner | epoch 152:     36 / 64 loss=5.416, ppl=42.71, wps=5856.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=1.065, train_wall=502, gb_free=6.1, wall=52828
2022-01-28 22:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:21:52 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.489 | ppl 1437.02 | wps 7953.8 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.349
2022-01-28 22:21:52 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 22:21:52 | INFO | train | epoch 152 | loss 5.422 | ppl 42.88 | wps 5972.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 1.099 | train_wall 321 | gb_free 6.1 | wall 52996
KL Stats: Epoch 152 Divergences: Uniform: 2.899045220703958 Unigram: 6.782135025215742
2022-01-28 22:21:52 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 22:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:27:41 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.549 | ppl 1498.41 | wps 8046.8 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.349
2022-01-28 22:27:41 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 22:27:41 | INFO | train | epoch 153 | loss 5.412 | ppl 42.58 | wps 5987.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 1.035 | train_wall 321 | gb_free 6.1 | wall 53345
KL Stats: Epoch 153 Divergences: Uniform: 2.9027196115459066 Unigram: 6.804545584541927
2022-01-28 22:27:41 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 22:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:28:21 | INFO | train_inner | epoch 154:      8 / 64 loss=5.421, ppl=42.85, wps=5849.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=1.068, train_wall=501, gb_free=6.1, wall=53386
2022-01-28 22:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:33:30 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.616 | ppl 1568.92 | wps 8037 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.349
2022-01-28 22:33:30 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 22:33:30 | INFO | train | epoch 154 | loss 5.408 | ppl 42.45 | wps 5982.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.122 | train_wall 321 | gb_free 6.1 | wall 53694
KL Stats: Epoch 154 Divergences: Uniform: 2.902380475667758 Unigram: 6.821758201690552
2022-01-28 22:33:30 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 22:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:37:12 | INFO | train_inner | epoch 155:     44 / 64 loss=5.399, ppl=42.2, wps=6159, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.113, train_wall=502, gb_free=6.1, wall=53916
2022-01-28 22:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:39:19 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.557 | ppl 1506.01 | wps 8012.3 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.349
2022-01-28 22:39:19 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 22:39:19 | INFO | train | epoch 155 | loss 5.401 | ppl 42.26 | wps 5983.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.117 | train_wall 321 | gb_free 6.1 | wall 54043
KL Stats: Epoch 155 Divergences: Uniform: 2.9025080321473227 Unigram: 6.86205514737674
2022-01-28 22:39:19 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 22:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:45:08 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.614 | ppl 1567.07 | wps 8026.4 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.349
2022-01-28 22:45:08 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 22:45:08 | INFO | train | epoch 156 | loss 5.393 | ppl 42.01 | wps 5992.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.117 | train_wall 320 | gb_free 6.1 | wall 54392
KL Stats: Epoch 156 Divergences: Uniform: 2.9043690466214116 Unigram: 6.882026552360322
2022-01-28 22:45:08 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 22:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:46:28 | INFO | train_inner | epoch 157:     16 / 64 loss=5.399, ppl=42.19, wps=5859.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.111, train_wall=500, gb_free=6.1, wall=54473
2022-01-28 22:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:50:56 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.529 | ppl 1477.62 | wps 8051.3 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.349
2022-01-28 22:50:56 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 22:50:56 | INFO | train | epoch 157 | loss 5.385 | ppl 41.8 | wps 5995.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.089 | train_wall 320 | gb_free 6.1 | wall 54740
KL Stats: Epoch 157 Divergences: Uniform: 2.9060335761433014 Unigram: 6.917043664748543
2022-01-28 22:50:56 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 22:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:55:19 | INFO | train_inner | epoch 158:     52 / 64 loss=5.377, ppl=41.57, wps=6163.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.091, train_wall=502, gb_free=6.1, wall=55003
2022-01-28 22:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:56:45 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.608 | ppl 1560.36 | wps 8002.6 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.349
2022-01-28 22:56:45 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 22:56:45 | INFO | train | epoch 158 | loss 5.378 | ppl 41.58 | wps 5979.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.104 | train_wall 321 | gb_free 6.1 | wall 55090
KL Stats: Epoch 158 Divergences: Uniform: 2.9028389913158525 Unigram: 6.938892234974949
2022-01-28 22:56:45 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 22:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:02:36 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.601 | ppl 1552.8 | wps 7990.3 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.349
2022-01-28 23:02:36 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 23:02:36 | INFO | train | epoch 159 | loss 5.37 | ppl 41.35 | wps 5961.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.132 | train_wall 322 | gb_free 6.1 | wall 55440
KL Stats: Epoch 159 Divergences: Uniform: 2.903766616841607 Unigram: 6.969343968301257
2022-01-28 23:02:36 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 23:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:04:37 | INFO | train_inner | epoch 160:     24 / 64 loss=5.37, ppl=41.35, wps=5837.2, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.143, train_wall=502, gb_free=6.1, wall=55561
2022-01-28 23:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:08:25 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.609 | ppl 1562.35 | wps 8035.1 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.349
2022-01-28 23:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 23:08:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint160.pt
2022-01-28 23:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint160.pt
2022-01-28 23:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.609) (writing took 3.932610746473074 seconds)
2022-01-28 23:08:29 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 23:08:29 | INFO | train | epoch 160 | loss 5.363 | ppl 41.15 | wps 5917 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.12 | train_wall 321 | gb_free 6.1 | wall 55793
KL Stats: Epoch 160 Divergences: Uniform: 2.9054230016123386 Unigram: 6.995116622406696
2022-01-28 23:08:29 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 23:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:13:32 | INFO | train_inner | epoch 161:     60 / 64 loss=5.364, ppl=41.17, wps=6112.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.108, train_wall=502, gb_free=6.1, wall=56096
2022-01-28 23:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:14:18 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.544 | ppl 1492.95 | wps 8052.2 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.349
2022-01-28 23:14:18 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 23:14:18 | INFO | train | epoch 161 | loss 5.357 | ppl 40.98 | wps 5983.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.115 | train_wall 321 | gb_free 6.1 | wall 56142
KL Stats: Epoch 161 Divergences: Uniform: 2.9115189276321485 Unigram: 7.019437825473425
2022-01-28 23:14:18 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 23:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:19:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:20:07 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.616 | ppl 1569.34 | wps 8038.3 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.349
2022-01-28 23:20:07 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 23:20:07 | INFO | train | epoch 162 | loss 5.349 | ppl 40.76 | wps 5980.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.117 | train_wall 321 | gb_free 6.1 | wall 56491
KL Stats: Epoch 162 Divergences: Uniform: 2.916612448398135 Unigram: 7.048350702007241
2022-01-28 23:20:07 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 23:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:22:48 | INFO | train_inner | epoch 163:     32 / 64 loss=5.336, ppl=40.4, wps=5855.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.129, train_wall=501, gb_free=6.1, wall=56653
2022-01-28 23:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:25:56 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.655 | ppl 1612.05 | wps 8007.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.349
2022-01-28 23:25:56 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 23:25:56 | INFO | train | epoch 163 | loss 5.344 | ppl 40.62 | wps 5984.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.151 | train_wall 321 | gb_free 6.1 | wall 56840
KL Stats: Epoch 163 Divergences: Uniform: 2.9130539055988094 Unigram: 7.074044230563134
2022-01-28 23:25:56 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 23:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:31:45 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.555 | ppl 1504.03 | wps 8031.1 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.349
2022-01-28 23:31:45 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 23:31:45 | INFO | train | epoch 164 | loss 5.337 | ppl 40.42 | wps 5977.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.178 | train_wall 321 | gb_free 6.1 | wall 57190
KL Stats: Epoch 164 Divergences: Uniform: 2.9084209762993147 Unigram: 7.098897405269672
2022-01-28 23:31:45 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 23:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:32:06 | INFO | train_inner | epoch 165:      4 / 64 loss=5.351, ppl=40.82, wps=5849.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.167, train_wall=501, gb_free=6.1, wall=57210
2022-01-28 23:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:37:35 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.637 | ppl 1592.82 | wps 7974.4 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.349
2022-01-28 23:37:35 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 23:37:35 | INFO | train | epoch 165 | loss 5.327 | ppl 40.13 | wps 5968 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.135 | train_wall 322 | gb_free 6.1 | wall 57540
KL Stats: Epoch 165 Divergences: Uniform: 2.9196622870098574 Unigram: 7.133010340012078
2022-01-28 23:37:35 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 23:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:40:58 | INFO | train_inner | epoch 166:     40 / 64 loss=5.319, ppl=39.92, wps=6143.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.152, train_wall=503, gb_free=6.1, wall=57742
2022-01-28 23:42:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:43:25 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.527 | ppl 1475.14 | wps 8051.5 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.349
2022-01-28 23:43:25 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 23:43:25 | INFO | train | epoch 166 | loss 5.322 | ppl 39.99 | wps 5978 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.183 | train_wall 321 | gb_free 6.1 | wall 57889
KL Stats: Epoch 166 Divergences: Uniform: 2.919911851260697 Unigram: 7.157684712848079
2022-01-28 23:43:25 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 23:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:49:14 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.566 | ppl 1516.15 | wps 8041.2 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.349
2022-01-28 23:49:14 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-28 23:49:14 | INFO | train | epoch 167 | loss 5.316 | ppl 39.84 | wps 5984 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.187 | train_wall 321 | gb_free 6.1 | wall 58238
KL Stats: Epoch 167 Divergences: Uniform: 2.915485434144854 Unigram: 7.179631237659886
2022-01-28 23:49:14 | INFO | fairseq.trainer | begin training epoch 168
2022-01-28 23:49:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:50:14 | INFO | train_inner | epoch 168:     12 / 64 loss=5.318, ppl=39.89, wps=5854.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.181, train_wall=501, gb_free=6.1, wall=58299
2022-01-28 23:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:55:03 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.637 | ppl 1592.29 | wps 7998.2 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.349
2022-01-28 23:55:03 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-28 23:55:03 | INFO | train | epoch 168 | loss 5.31 | ppl 39.67 | wps 5982.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.17 | train_wall 321 | gb_free 6.1 | wall 58587
KL Stats: Epoch 168 Divergences: Uniform: 2.92158244823383 Unigram: 7.203670529646182
2022-01-28 23:55:03 | INFO | fairseq.trainer | begin training epoch 169
2022-01-28 23:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:59:05 | INFO | train_inner | epoch 169:     48 / 64 loss=5.31, ppl=39.67, wps=6159.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.203, train_wall=502, gb_free=6.1, wall=58829
2022-01-29 00:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:00:52 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.579 | ppl 1529.75 | wps 8015.5 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.349
2022-01-29 00:00:52 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-29 00:00:52 | INFO | train | epoch 169 | loss 5.305 | ppl 39.54 | wps 5988.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.212 | train_wall 321 | gb_free 6.1 | wall 58936
KL Stats: Epoch 169 Divergences: Uniform: 2.9228433393342095 Unigram: 7.233954535237535
2022-01-29 00:00:52 | INFO | fairseq.trainer | begin training epoch 170
2022-01-29 00:00:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:06:41 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.654 | ppl 1611.09 | wps 7969.5 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.349
2022-01-29 00:06:41 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-29 00:06:41 | INFO | train | epoch 170 | loss 5.301 | ppl 39.43 | wps 5975.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.219 | train_wall 321 | gb_free 6.1 | wall 59285
KL Stats: Epoch 170 Divergences: Uniform: 2.9207258944081773 Unigram: 7.258508184249275
2022-01-29 00:06:41 | INFO | fairseq.trainer | begin training epoch 171
2022-01-29 00:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:08:22 | INFO | train_inner | epoch 171:     20 / 64 loss=5.295, ppl=39.26, wps=5852.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.214, train_wall=501, gb_free=6.1, wall=59386
2022-01-29 00:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:12:30 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.662 | ppl 1620.3 | wps 8047.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.349
2022-01-29 00:12:30 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-29 00:12:30 | INFO | train | epoch 171 | loss 5.292 | ppl 39.18 | wps 5990.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.211 | train_wall 321 | gb_free 6.1 | wall 59634
KL Stats: Epoch 171 Divergences: Uniform: 2.922572690013034 Unigram: 7.277583847350668
2022-01-29 00:12:30 | INFO | fairseq.trainer | begin training epoch 172
2022-01-29 00:12:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:17:13 | INFO | train_inner | epoch 172:     56 / 64 loss=5.293, ppl=39.21, wps=6154.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.191, train_wall=503, gb_free=6.1, wall=59917
2022-01-29 00:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:18:19 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.587 | ppl 1538.07 | wps 8023.8 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.349
2022-01-29 00:18:19 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-29 00:18:19 | INFO | train | epoch 172 | loss 5.283 | ppl 38.95 | wps 5974.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.19 | train_wall 321 | gb_free 6.1 | wall 59984
KL Stats: Epoch 172 Divergences: Uniform: 2.928328249965622 Unigram: 7.308370438671831
2022-01-29 00:18:19 | INFO | fairseq.trainer | begin training epoch 173
2022-01-29 00:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:24:08 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.521 | ppl 1469.2 | wps 8060.3 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.349
2022-01-29 00:24:08 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-29 00:24:08 | INFO | train | epoch 173 | loss 5.279 | ppl 38.82 | wps 5991.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.223 | train_wall 321 | gb_free 6.1 | wall 60332
KL Stats: Epoch 173 Divergences: Uniform: 2.924629558312644 Unigram: 7.33638160111266
2022-01-29 00:24:08 | INFO | fairseq.trainer | begin training epoch 174
2022-01-29 00:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:26:29 | INFO | train_inner | epoch 174:     28 / 64 loss=5.272, ppl=38.64, wps=5860.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.222, train_wall=500, gb_free=6.1, wall=60474
2022-01-29 00:29:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:29:57 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.583 | ppl 1534.37 | wps 8052.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.349
2022-01-29 00:29:57 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-29 00:29:57 | INFO | train | epoch 174 | loss 5.273 | ppl 38.65 | wps 5990.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.22 | train_wall 321 | gb_free 6.1 | wall 60681
KL Stats: Epoch 174 Divergences: Uniform: 2.928434294486014 Unigram: 7.369873581914652
2022-01-29 00:29:57 | INFO | fairseq.trainer | begin training epoch 175
2022-01-29 00:29:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:35:18 | INFO | train_inner | epoch 175:     64 / 64 loss=5.277, ppl=38.78, wps=6165.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.251, train_wall=500, gb_free=6.1, wall=61002
2022-01-29 00:35:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:35:45 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.627 | ppl 1580.88 | wps 8056.8 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.349
2022-01-29 00:35:45 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-29 00:35:45 | INFO | train | epoch 175 | loss 5.267 | ppl 38.51 | wps 5992.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.268 | train_wall 321 | gb_free 6.1 | wall 61029
KL Stats: Epoch 175 Divergences: Uniform: 2.9349596578705537 Unigram: 7.389199632355969
2022-01-29 00:35:45 | INFO | fairseq.trainer | begin training epoch 176
2022-01-29 00:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:41:35 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.654 | ppl 1611.18 | wps 8001 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.349
2022-01-29 00:41:35 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-29 00:41:35 | INFO | train | epoch 176 | loss 5.261 | ppl 38.34 | wps 5968.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.259 | train_wall 322 | gb_free 6.1 | wall 61379
KL Stats: Epoch 176 Divergences: Uniform: 2.935176257075493 Unigram: 7.428442222300604
2022-01-29 00:41:35 | INFO | fairseq.trainer | begin training epoch 177
2022-01-29 00:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:44:37 | INFO | train_inner | epoch 177:     36 / 64 loss=5.247, ppl=37.99, wps=5843, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.252, train_wall=503, gb_free=6.1, wall=61562
2022-01-29 00:46:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:47:25 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.611 | ppl 1563.59 | wps 8014 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.349
2022-01-29 00:47:25 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-29 00:47:25 | INFO | train | epoch 177 | loss 5.253 | ppl 38.14 | wps 5972.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.256 | train_wall 322 | gb_free 6.1 | wall 61729
KL Stats: Epoch 177 Divergences: Uniform: 2.9314639349275837 Unigram: 7.448320576311798
2022-01-29 00:47:25 | INFO | fairseq.trainer | begin training epoch 178
2022-01-29 00:47:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:52:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:53:15 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.646 | ppl 1602.47 | wps 8024.4 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.349
2022-01-29 00:53:15 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-29 00:53:15 | INFO | train | epoch 178 | loss 5.251 | ppl 38.08 | wps 5968.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.285 | train_wall 322 | gb_free 6.1 | wall 62079
KL Stats: Epoch 178 Divergences: Uniform: 2.9334230105505483 Unigram: 7.471710224126213
2022-01-29 00:53:15 | INFO | fairseq.trainer | begin training epoch 179
2022-01-29 00:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:53:56 | INFO | train_inner | epoch 179:      8 / 64 loss=5.258, ppl=38.26, wps=5839.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.277, train_wall=502, gb_free=6.1, wall=62120
2022-01-29 00:58:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:59:05 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.584 | ppl 1535.5 | wps 8053.6 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.349
2022-01-29 00:59:05 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-29 00:59:05 | INFO | train | epoch 179 | loss 5.244 | ppl 37.9 | wps 5957.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.276 | train_wall 323 | gb_free 6.1 | wall 62430
KL Stats: Epoch 179 Divergences: Uniform: 2.9385511410590865 Unigram: 7.503811081938356
2022-01-29 00:59:05 | INFO | fairseq.trainer | begin training epoch 180
2022-01-29 00:59:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:02:48 | INFO | train_inner | epoch 180:     44 / 64 loss=5.239, ppl=37.76, wps=6139.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.28, train_wall=504, gb_free=6.1, wall=62652
2022-01-29 01:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:04:55 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.607 | ppl 1559.39 | wps 8046.7 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.349
2022-01-29 01:04:55 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-29 01:04:55 | INFO | train | epoch 180 | loss 5.239 | ppl 37.77 | wps 5979.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.314 | train_wall 321 | gb_free 6.1 | wall 62779
KL Stats: Epoch 180 Divergences: Uniform: 2.9360407080271482 Unigram: 7.5308838411272765
2022-01-29 01:04:55 | INFO | fairseq.trainer | begin training epoch 181
2022-01-29 01:04:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:10:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:10:44 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.602 | ppl 1554.32 | wps 7997.5 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.349
2022-01-29 01:10:44 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-29 01:10:44 | INFO | train | epoch 181 | loss 5.229 | ppl 37.5 | wps 5983.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.271 | train_wall 321 | gb_free 6.1 | wall 63128
KL Stats: Epoch 181 Divergences: Uniform: 2.935434079413619 Unigram: 7.5529799975663146
2022-01-29 01:10:44 | INFO | fairseq.trainer | begin training epoch 182
2022-01-29 01:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:12:04 | INFO | train_inner | epoch 182:     16 / 64 loss=5.231, ppl=37.55, wps=5857.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.291, train_wall=501, gb_free=6.1, wall=63209
2022-01-29 01:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:16:32 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.618 | ppl 1571.51 | wps 8007.4 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.349
2022-01-29 01:16:32 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-29 01:16:32 | INFO | train | epoch 182 | loss 5.227 | ppl 37.45 | wps 5996.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.301 | train_wall 320 | gb_free 6.1 | wall 63476
KL Stats: Epoch 182 Divergences: Uniform: 2.9417053729335416 Unigram: 7.57069901027417
2022-01-29 01:16:32 | INFO | fairseq.trainer | begin training epoch 183
2022-01-29 01:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:20:54 | INFO | train_inner | epoch 183:     52 / 64 loss=5.225, ppl=37.41, wps=6169.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.318, train_wall=501, gb_free=6.1, wall=63738
2022-01-29 01:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:22:21 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.612 | ppl 1564.73 | wps 8000.5 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.349
2022-01-29 01:22:21 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-29 01:22:21 | INFO | train | epoch 183 | loss 5.221 | ppl 37.29 | wps 5991.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.311 | train_wall 320 | gb_free 6.1 | wall 63825
KL Stats: Epoch 183 Divergences: Uniform: 2.9392287429575914 Unigram: 7.615151701638077
2022-01-29 01:22:21 | INFO | fairseq.trainer | begin training epoch 184
2022-01-29 01:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:27:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:28:10 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.557 | ppl 1506.93 | wps 8062.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.349
2022-01-29 01:28:10 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-29 01:28:10 | INFO | train | epoch 184 | loss 5.217 | ppl 37.18 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.327 | train_wall 321 | gb_free 6.1 | wall 64174
KL Stats: Epoch 184 Divergences: Uniform: 2.943473212940133 Unigram: 7.63059919292113
2022-01-29 01:28:10 | INFO | fairseq.trainer | begin training epoch 185
2022-01-29 01:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:30:11 | INFO | train_inner | epoch 185:     24 / 64 loss=5.216, ppl=37.17, wps=5854.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.325, train_wall=501, gb_free=6.1, wall=64295
2022-01-29 01:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:33:59 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.638 | ppl 1592.98 | wps 8033.7 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.349
2022-01-29 01:33:59 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 01:33:59 | INFO | train | epoch 185 | loss 5.211 | ppl 37.04 | wps 5979 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.334 | train_wall 321 | gb_free 6.1 | wall 64523
KL Stats: Epoch 185 Divergences: Uniform: 2.93687611307719 Unigram: 7.665727351646237
2022-01-29 01:33:59 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 01:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:39:02 | INFO | train_inner | epoch 186:     60 / 64 loss=5.212, ppl=37.06, wps=6154.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.381, train_wall=502, gb_free=6.1, wall=64826
2022-01-29 01:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:39:48 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.575 | ppl 1525.37 | wps 8038.3 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.349
2022-01-29 01:39:48 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 01:39:48 | INFO | train | epoch 186 | loss 5.208 | ppl 36.96 | wps 5984.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.407 | train_wall 321 | gb_free 6.1 | wall 64872
KL Stats: Epoch 186 Divergences: Uniform: 2.9425823869463925 Unigram: 7.691626517443566
2022-01-29 01:39:48 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 01:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:45:37 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.616 | ppl 1569.91 | wps 8018.5 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.349
2022-01-29 01:45:37 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 01:45:37 | INFO | train | epoch 187 | loss 5.199 | ppl 36.74 | wps 5993.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.323 | train_wall 320 | gb_free 6.1 | wall 65221
KL Stats: Epoch 187 Divergences: Uniform: 2.9361408039352073 Unigram: 7.717017553882286
2022-01-29 01:45:37 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 01:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:48:18 | INFO | train_inner | epoch 188:     32 / 64 loss=5.192, ppl=36.56, wps=5861.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.325, train_wall=500, gb_free=6.1, wall=65382
2022-01-29 01:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:51:26 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.584 | ppl 1535.46 | wps 8011.5 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.349
2022-01-29 01:51:26 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 01:51:26 | INFO | train | epoch 188 | loss 5.193 | ppl 36.59 | wps 5984.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.366 | train_wall 321 | gb_free 6.1 | wall 65570
KL Stats: Epoch 188 Divergences: Uniform: 2.9403476865356146 Unigram: 7.745306866675866
2022-01-29 01:51:26 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 01:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:57:15 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.642 | ppl 1598.48 | wps 7989.6 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.349
2022-01-29 01:57:15 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 01:57:15 | INFO | train | epoch 189 | loss 5.189 | ppl 36.48 | wps 5984.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.404 | train_wall 321 | gb_free 6.1 | wall 65919
KL Stats: Epoch 189 Divergences: Uniform: 2.940927212575886 Unigram: 7.763469155502489
2022-01-29 01:57:15 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 01:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:57:35 | INFO | train_inner | epoch 190:      4 / 64 loss=5.196, ppl=36.65, wps=5855.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.404, train_wall=501, gb_free=6.1, wall=65939
2022-01-29 02:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:03:04 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.617 | ppl 1571.03 | wps 8025 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.349
2022-01-29 02:03:04 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 02:03:04 | INFO | train | epoch 190 | loss 5.187 | ppl 36.42 | wps 5983.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.398 | train_wall 321 | gb_free 6.1 | wall 66268
KL Stats: Epoch 190 Divergences: Uniform: 2.9455467847205243 Unigram: 7.805007336883612
2022-01-29 02:03:04 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 02:03:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:06:26 | INFO | train_inner | epoch 191:     40 / 64 loss=5.174, ppl=36.1, wps=6154.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.4, train_wall=502, gb_free=6.1, wall=66470
2022-01-29 02:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:08:53 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.586 | ppl 1537.1 | wps 8033.2 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.349
2022-01-29 02:08:53 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 02:08:53 | INFO | train | epoch 191 | loss 5.179 | ppl 36.22 | wps 5973.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.396 | train_wall 322 | gb_free 6.1 | wall 66618
KL Stats: Epoch 191 Divergences: Uniform: 2.9458293768759574 Unigram: 7.827002210401187
2022-01-29 02:08:53 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 02:08:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:14:42 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.608 | ppl 1560.94 | wps 8005.2 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.349
2022-01-29 02:14:42 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 02:14:42 | INFO | train | epoch 192 | loss 5.173 | ppl 36.07 | wps 5985.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.39 | train_wall 321 | gb_free 6.1 | wall 66967
KL Stats: Epoch 192 Divergences: Uniform: 2.9435887736740822 Unigram: 7.84592194394223
2022-01-29 02:14:42 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 02:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:15:43 | INFO | train_inner | epoch 193:     12 / 64 loss=5.18, ppl=36.26, wps=5853.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.39, train_wall=501, gb_free=6.1, wall=67027
2022-01-29 02:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:20:33 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.551 | ppl 1500.54 | wps 8003.2 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.349
2022-01-29 02:20:33 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 02:20:33 | INFO | train | epoch 193 | loss 5.17 | ppl 36.01 | wps 5952.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.408 | train_wall 323 | gb_free 6.1 | wall 67317
KL Stats: Epoch 193 Divergences: Uniform: 2.9473316046168314 Unigram: 7.878641423997062
2022-01-29 02:20:33 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 02:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:24:36 | INFO | train_inner | epoch 194:     48 / 64 loss=5.166, ppl=35.89, wps=6133.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.414, train_wall=504, gb_free=6.1, wall=67560
2022-01-29 02:25:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:26:23 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.605 | ppl 1557.64 | wps 7999.4 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.349
2022-01-29 02:26:23 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 02:26:23 | INFO | train | epoch 194 | loss 5.164 | ppl 35.85 | wps 5974.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.42 | train_wall 321 | gb_free 6.1 | wall 67667
KL Stats: Epoch 194 Divergences: Uniform: 2.945735980286579 Unigram: 7.903098860688597
2022-01-29 02:26:23 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 02:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:31:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:32:12 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.594 | ppl 1545.61 | wps 7999.6 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.349
2022-01-29 02:32:12 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 02:32:12 | INFO | train | epoch 195 | loss 5.162 | ppl 35.79 | wps 5972.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.485 | train_wall 322 | gb_free 6.1 | wall 68017
KL Stats: Epoch 195 Divergences: Uniform: 2.948750797082094 Unigram: 7.930376642077328
2022-01-29 02:32:12 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 02:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:33:54 | INFO | train_inner | epoch 196:     20 / 64 loss=5.158, ppl=35.71, wps=5843.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.458, train_wall=502, gb_free=6.1, wall=68118
2022-01-29 02:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:38:02 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.615 | ppl 1568.6 | wps 7986.1 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.349
2022-01-29 02:38:02 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 02:38:02 | INFO | train | epoch 196 | loss 5.156 | ppl 35.66 | wps 5969.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.471 | train_wall 322 | gb_free 6.1 | wall 68367
KL Stats: Epoch 196 Divergences: Uniform: 2.9478089741691185 Unigram: 7.955576038233608
2022-01-29 02:38:02 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 02:38:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:42:46 | INFO | train_inner | epoch 197:     56 / 64 loss=5.156, ppl=35.67, wps=6135.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.492, train_wall=504, gb_free=6.1, wall=68651
2022-01-29 02:43:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:43:53 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.624 | ppl 1578.09 | wps 8016.2 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.349
2022-01-29 02:43:53 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 02:43:53 | INFO | train | epoch 197 | loss 5.151 | ppl 35.53 | wps 5961.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.487 | train_wall 322 | gb_free 6.1 | wall 68717
KL Stats: Epoch 197 Divergences: Uniform: 2.9508309975974147 Unigram: 7.9841447094520674
2022-01-29 02:43:53 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 02:43:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:49:42 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.596 | ppl 1548.18 | wps 8019.9 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.349
2022-01-29 02:49:42 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 02:49:42 | INFO | train | epoch 198 | loss 5.145 | ppl 35.39 | wps 5972.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.511 | train_wall 322 | gb_free 6.1 | wall 69067
KL Stats: Epoch 198 Divergences: Uniform: 2.9522827210237965 Unigram: 8.01290577271754
2022-01-29 02:49:42 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 02:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:52:04 | INFO | train_inner | epoch 199:     28 / 64 loss=5.14, ppl=35.26, wps=5843.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.493, train_wall=502, gb_free=6.1, wall=69208
2022-01-29 02:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:55:32 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.611 | ppl 1564.05 | wps 8034.5 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.349
2022-01-29 02:55:32 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 02:55:32 | INFO | train | epoch 199 | loss 5.141 | ppl 35.27 | wps 5968.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.475 | train_wall 322 | gb_free 6.1 | wall 69417
KL Stats: Epoch 199 Divergences: Uniform: 2.947180077281466 Unigram: 8.045870006322543
2022-01-29 02:55:32 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 02:55:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:00:55 | INFO | train_inner | epoch 200:     64 / 64 loss=5.148, ppl=35.47, wps=6143.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.516, train_wall=502, gb_free=6.1, wall=69739
2022-01-29 03:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:01:22 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.636 | ppl 1591.33 | wps 7998.6 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.349
2022-01-29 03:01:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 03:01:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint200.pt
2022-01-29 03:01:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint200.pt
2022-01-29 03:01:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.12_-0.02_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.636) (writing took 3.2974583953619003 seconds)
2022-01-29 03:01:25 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 03:01:25 | INFO | train | epoch 200 | loss 5.136 | ppl 35.16 | wps 5914.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.527 | train_wall 322 | gb_free 6.1 | wall 69770
KL Stats: Epoch 200 Divergences: Uniform: 2.94745146683254 Unigram: 8.066256496888291
2022-01-29 03:01:25 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 03:01:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:07:15 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.592 | ppl 1543.89 | wps 8023.5 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.349
2022-01-29 03:07:15 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 03:07:15 | INFO | train | epoch 201 | loss 5.134 | ppl 35.1 | wps 5970 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.518 | train_wall 322 | gb_free 6.1 | wall 70120
KL Stats: Epoch 201 Divergences: Uniform: 2.9538731079761895 Unigram: 8.097408685375202
2022-01-29 03:07:15 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 03:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:10:16 | INFO | train_inner | epoch 202:     36 / 64 loss=5.119, ppl=34.74, wps=5819.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.516, train_wall=502, gb_free=6.1, wall=70301
2022-01-29 03:12:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:13:03 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.582 | ppl 1533.11 | wps 8004.9 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.349
2022-01-29 03:13:03 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 03:13:03 | INFO | train | epoch 202 | loss 5.126 | ppl 34.91 | wps 6000.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.502 | train_wall 320 | gb_free 6.1 | wall 70468
KL Stats: Epoch 202 Divergences: Uniform: 2.9554171098691326 Unigram: 8.128234447609621
2022-01-29 03:13:03 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 03:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:18:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:18:52 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.605 | ppl 1557.47 | wps 8056.4 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.349
2022-01-29 03:18:52 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-01-29 03:18:52 | INFO | train | epoch 203 | loss 5.12 | ppl 34.77 | wps 5990.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.511 | train_wall 321 | gb_free 6.1 | wall 70816
KL Stats: Epoch 203 Divergences: Uniform: 2.9525727775961466 Unigram: 8.164475318647945
2022-01-29 03:18:52 | INFO | fairseq.trainer | begin training epoch 204
2022-01-29 03:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:19:32 | INFO | train_inner | epoch 204:      8 / 64 loss=5.129, ppl=35, wps=5862.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.514, train_wall=500, gb_free=6.1, wall=70857
2022-01-29 03:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:24:40 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.609 | ppl 1562.09 | wps 8043.4 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.349
2022-01-29 03:24:40 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-01-29 03:24:40 | INFO | train | epoch 204 | loss 5.118 | ppl 34.72 | wps 5995.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.583 | train_wall 320 | gb_free 6.1 | wall 71165
KL Stats: Epoch 204 Divergences: Uniform: 2.9567090505184304 Unigram: 8.192758786641276
2022-01-29 03:24:40 | INFO | fairseq.trainer | begin training epoch 205
2022-01-29 03:24:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:28:22 | INFO | train_inner | epoch 205:     44 / 64 loss=5.112, ppl=34.59, wps=6169.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.555, train_wall=501, gb_free=6.1, wall=71386
2022-01-29 03:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:30:28 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.598 | ppl 1549.54 | wps 8036.6 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.349
2022-01-29 03:30:28 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-01-29 03:30:28 | INFO | train | epoch 205 | loss 5.113 | ppl 34.6 | wps 5997.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.547 | train_wall 320 | gb_free 6.1 | wall 71513
KL Stats: Epoch 205 Divergences: Uniform: 2.954436858600899 Unigram: 8.217134308084825
2022-01-29 03:30:28 | INFO | fairseq.trainer | begin training epoch 206
2022-01-29 03:30:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 03:36:17 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.608 | ppl 1560.96 | wps 8050.1 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.349
2022-01-29 03:36:17 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-01-29 03:36:17 | INFO | train | epoch 206 | loss 5.107 | ppl 34.46 | wps 5998.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.53 | train_wall 320 | gb_free 6.1 | wall 71861
KL Stats: Epoch 206 Divergences: Uniform: 2.9482916718951553 Unigram: 8.2374384287882
2022-01-29 03:36:17 | INFO | fairseq.trainer | begin training epoch 207
2022-01-29 03:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 03:37:37 | INFO | train_inner | epoch 207:     16 / 64 loss=5.11, ppl=34.54, wps=5871.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.549, train_wall=500, gb_free=6.1, wall=71942
User defined signal 2
