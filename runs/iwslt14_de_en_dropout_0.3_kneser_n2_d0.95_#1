Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 210653105: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:56:09 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:56:38 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:56:38 2022
Terminated at Wed Mar 23 23:52:30 2022
Results reported at Wed Mar 23 23:52:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.95 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17729.38 sec.
    Max Memory :                                 4990 MB
    Average Memory :                             4325.93 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15010.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   17751 sec.
    Turnaround time :                            17781 sec.

The output (if any) follows:

2022-03-23 18:56:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.95, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.95, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:56:48 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:56:48 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:56:49 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:56:49 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:56:49 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1082/160239 [00:00<00:14, 10816.48it/s]  1%|▏         | 2393/160239 [00:00<00:12, 12161.24it/s]  2%|▏         | 3719/160239 [00:00<00:12, 12661.54it/s]  3%|▎         | 5045/160239 [00:00<00:12, 12896.21it/s]  4%|▍         | 6335/160239 [00:00<00:12, 12683.60it/s]  5%|▍         | 7604/160239 [00:00<00:12, 12601.99it/s]  6%|▌         | 8865/160239 [00:00<00:12, 12331.05it/s]  6%|▋         | 10174/160239 [00:00<00:11, 12566.82it/s]  7%|▋         | 11482/160239 [00:00<00:11, 12722.48it/s]  8%|▊         | 12756/160239 [00:01<00:11, 12676.21it/s]  9%|▉         | 14025/160239 [00:01<00:11, 12627.73it/s] 10%|▉         | 15289/160239 [00:01<00:11, 12537.70it/s] 10%|█         | 16544/160239 [00:01<00:11, 12130.49it/s] 11%|█         | 17772/160239 [00:01<00:11, 12172.27it/s] 12%|█▏        | 19031/160239 [00:01<00:11, 12292.64it/s] 13%|█▎        | 20417/160239 [00:01<00:10, 12755.40it/s] 14%|█▎        | 21695/160239 [00:01<00:11, 12386.14it/s] 14%|█▍        | 22937/160239 [00:01<00:11, 12353.06it/s] 15%|█▌        | 24180/160239 [00:01<00:10, 12371.20it/s] 16%|█▌        | 25441/160239 [00:02<00:10, 12438.61it/s] 17%|█▋        | 26687/160239 [00:02<00:10, 12260.59it/s] 17%|█▋        | 28015/160239 [00:02<00:10, 12557.35it/s] 18%|█▊        | 29273/160239 [00:02<00:10, 12505.51it/s] 19%|█▉        | 30525/160239 [00:02<00:10, 12130.64it/s] 20%|█▉        | 31916/160239 [00:02<00:10, 12647.40it/s] 21%|██        | 33185/160239 [00:02<00:10, 12370.68it/s] 21%|██▏       | 34426/160239 [00:02<00:10, 12298.71it/s] 22%|██▏       | 35659/160239 [00:02<00:10, 12055.97it/s] 23%|██▎       | 36936/160239 [00:02<00:10, 12256.07it/s] 24%|██▍       | 38190/160239 [00:03<00:09, 12338.45it/s] 25%|██▍       | 39426/160239 [00:03<00:09, 12338.00it/s] 25%|██▌       | 40726/160239 [00:03<00:09, 12533.78it/s] 26%|██▌       | 41981/160239 [00:03<00:09, 12319.40it/s] 27%|██▋       | 43215/160239 [00:03<00:09, 12049.85it/s] 28%|██▊       | 44422/160239 [00:03<00:09, 11758.63it/s] 29%|██▊       | 45785/160239 [00:03<00:09, 12298.16it/s] 29%|██▉       | 47035/160239 [00:03<00:09, 12356.29it/s] 30%|███       | 48295/160239 [00:03<00:09, 12425.94it/s] 31%|███       | 49540/160239 [00:04<00:08, 12415.63it/s] 32%|███▏      | 50784/160239 [00:04<00:08, 12421.56it/s] 32%|███▏      | 52047/160239 [00:04<00:08, 12481.24it/s] 33%|███▎      | 53298/160239 [00:04<00:08, 12486.31it/s] 34%|███▍      | 54548/160239 [00:04<00:08, 12243.73it/s] 35%|███▍      | 55783/160239 [00:04<00:08, 12271.52it/s] 36%|███▌      | 57107/160239 [00:04<00:08, 12557.87it/s] 36%|███▋      | 58420/160239 [00:04<00:08, 12722.91it/s] 37%|███▋      | 59719/160239 [00:04<00:07, 12801.53it/s] 38%|███▊      | 61000/160239 [00:04<00:07, 12565.72it/s] 39%|███▉      | 62270/160239 [00:05<00:07, 12603.32it/s] 40%|███▉      | 63556/160239 [00:05<00:07, 12676.30it/s] 41%|████      | 65026/160239 [00:05<00:07, 13274.67it/s] 41%|████▏     | 66355/160239 [00:05<00:07, 13237.81it/s] 42%|████▏     | 67680/160239 [00:05<00:07, 12766.07it/s] 43%|████▎     | 68961/160239 [00:05<00:07, 12481.42it/s] 44%|████▍     | 70241/160239 [00:05<00:07, 12571.67it/s] 45%|████▍     | 71501/160239 [00:05<00:07, 12540.97it/s] 45%|████▌     | 72757/160239 [00:05<00:07, 12462.20it/s] 46%|████▌     | 74005/160239 [00:05<00:06, 12393.27it/s] 47%|████▋     | 75246/160239 [00:06<00:06, 12237.13it/s] 48%|████▊     | 76486/160239 [00:06<00:06, 12283.18it/s] 49%|████▊     | 77857/160239 [00:06<00:06, 12700.85it/s] 49%|████▉     | 79136/160239 [00:06<00:06, 12725.43it/s] 50%|█████     | 80466/160239 [00:06<00:06, 12895.84it/s] 51%|█████     | 81795/160239 [00:06<00:06, 13004.21it/s] 52%|█████▏    | 83103/160239 [00:06<00:05, 13025.00it/s] 53%|█████▎    | 84406/160239 [00:06<00:05, 12860.38it/s] 54%|█████▎    | 85775/160239 [00:06<00:05, 13105.94it/s] 54%|█████▍    | 87095/160239 [00:06<00:05, 13131.43it/s] 55%|█████▌    | 88409/160239 [00:07<00:05, 12915.71it/s] 56%|█████▌    | 89765/160239 [00:07<00:05, 13104.75it/s] 57%|█████▋    | 91077/160239 [00:07<00:05, 12852.28it/s] 58%|█████▊    | 92364/160239 [00:07<00:05, 12822.13it/s] 58%|█████▊    | 93648/160239 [00:07<00:05, 12684.14it/s] 59%|█████▉    | 94918/160239 [00:07<00:05, 12239.53it/s] 60%|██████    | 96222/160239 [00:07<00:05, 12466.43it/s] 61%|██████    | 97479/160239 [00:07<00:05, 12493.14it/s] 62%|██████▏   | 98767/160239 [00:07<00:04, 12606.48it/s] 62%|██████▏   | 100117/160239 [00:07<00:04, 12867.18it/s] 63%|██████▎   | 101406/160239 [00:08<00:04, 12871.00it/s] 64%|██████▍   | 102695/160239 [00:08<00:04, 12672.32it/s] 65%|██████▍   | 103964/160239 [00:08<00:04, 12539.12it/s] 66%|██████▌   | 105344/160239 [00:08<00:04, 12909.51it/s] 67%|██████▋   | 106637/160239 [00:08<00:04, 12869.91it/s] 67%|██████▋   | 107926/160239 [00:08<00:04, 12437.35it/s] 68%|██████▊   | 109174/160239 [00:08<00:04, 12137.27it/s] 69%|██████▉   | 110419/160239 [00:08<00:04, 12223.28it/s] 70%|██████▉   | 111783/160239 [00:08<00:03, 12634.81it/s] 71%|███████   | 113050/160239 [00:09<00:03, 12443.14it/s] 71%|███████▏  | 114350/160239 [00:09<00:03, 12602.76it/s] 72%|███████▏  | 115613/160239 [00:09<00:03, 12599.75it/s] 73%|███████▎  | 116875/160239 [00:09<00:03, 12354.39it/s] 74%|███████▍  | 118178/160239 [00:09<00:03, 12552.10it/s] 75%|███████▍  | 119485/160239 [00:09<00:03, 12704.71it/s] 75%|███████▌  | 120757/160239 [00:09<00:03, 12491.70it/s] 76%|███████▌  | 122173/160239 [00:09<00:02, 12981.23it/s] 77%|███████▋  | 123474/160239 [00:09<00:02, 12877.65it/s] 78%|███████▊  | 124764/160239 [00:09<00:02, 12590.26it/s] 79%|███████▊  | 126026/160239 [00:10<00:02, 12515.00it/s] 79%|███████▉  | 127287/160239 [00:10<00:02, 12541.35it/s] 80%|████████  | 128623/160239 [00:10<00:02, 12782.05it/s] 81%|████████  | 129903/160239 [00:10<00:02, 12548.22it/s] 82%|████████▏ | 131160/160239 [00:10<00:02, 12370.03it/s] 83%|████████▎ | 132399/160239 [00:10<00:02, 12308.50it/s] 83%|████████▎ | 133631/160239 [00:10<00:02, 12197.52it/s] 84%|████████▍ | 134875/160239 [00:10<00:02, 12267.94it/s] 85%|████████▍ | 136117/160239 [00:10<00:01, 12308.09it/s] 86%|████████▌ | 137388/160239 [00:10<00:01, 12426.90it/s] 87%|████████▋ | 138708/160239 [00:11<00:01, 12654.26it/s] 87%|████████▋ | 140026/160239 [00:11<00:01, 12810.18it/s] 88%|████████▊ | 141355/160239 [00:11<00:01, 12947.71it/s] 89%|████████▉ | 142651/160239 [00:11<00:01, 12613.48it/s] 90%|████████▉ | 143915/160239 [00:11<00:01, 12602.57it/s] 91%|█████████ | 145177/160239 [00:11<00:01, 12542.64it/s] 91%|█████████▏| 146433/160239 [00:11<00:01, 12340.45it/s] 92%|█████████▏| 147669/160239 [00:11<00:01, 12297.44it/s] 93%|█████████▎| 148900/160239 [00:11<00:00, 12051.83it/s] 94%|█████████▎| 150143/160239 [00:11<00:00, 12160.98it/s] 94%|█████████▍| 151414/160239 [00:12<00:00, 12320.70it/s] 95%|█████████▌| 152681/160239 [00:12<00:00, 12419.12it/s] 96%|█████████▌| 153924/160239 [00:12<00:00, 12348.61it/s] 97%|█████████▋| 155290/160239 [00:12<00:00, 12737.35it/s] 98%|█████████▊| 156565/160239 [00:12<00:00, 12396.99it/s] 98%|█████████▊| 157816/160239 [00:12<00:00, 12428.98it/s] 99%|█████████▉| 159061/160239 [00:12<00:00, 12258.11it/s]100%|██████████| 160239/160239 [00:12<00:00, 12526.40it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 30/6629 [00:00<00:22, 292.39it/s]  1%|          | 60/6629 [00:00<00:23, 284.48it/s]  1%|▏         | 89/6629 [00:00<00:23, 278.54it/s]  2%|▏         | 117/6629 [00:00<00:23, 272.53it/s]  2%|▏         | 145/6629 [00:00<00:24, 269.06it/s]  3%|▎         | 172/6629 [00:00<00:24, 267.80it/s]  3%|▎         | 199/6629 [00:00<00:24, 266.11it/s]  3%|▎         | 226/6629 [00:00<00:24, 265.52it/s]  4%|▍         | 253/6629 [00:00<00:24, 265.26it/s]  4%|▍         | 280/6629 [00:01<00:23, 265.17it/s]  5%|▍         | 307/6629 [00:01<00:23, 265.10it/s]  5%|▌         | 334/6629 [00:01<00:23, 264.74it/s]  5%|▌         | 361/6629 [00:01<00:23, 263.90it/s]  6%|▌         | 388/6629 [00:01<00:23, 263.59it/s]  6%|▋         | 415/6629 [00:01<00:23, 263.61it/s]  7%|▋         | 442/6629 [00:01<00:23, 262.43it/s]  7%|▋         | 469/6629 [00:01<00:23, 262.31it/s]  7%|▋         | 496/6629 [00:01<00:23, 262.58it/s]  8%|▊         | 523/6629 [00:01<00:23, 263.27it/s]  8%|▊         | 550/6629 [00:02<00:23, 263.53it/s]  9%|▊         | 577/6629 [00:02<00:22, 263.98it/s]  9%|▉         | 604/6629 [00:02<00:22, 263.76it/s] 10%|▉         | 631/6629 [00:02<00:22, 263.85it/s] 10%|▉         | 658/6629 [00:02<00:22, 263.73it/s] 10%|█         | 685/6629 [00:02<00:22, 263.91it/s] 11%|█         | 712/6629 [00:02<00:22, 263.55it/s] 11%|█         | 739/6629 [00:02<00:22, 263.31it/s] 12%|█▏        | 766/6629 [00:02<00:22, 263.35it/s] 12%|█▏        | 793/6629 [00:02<00:22, 263.85it/s] 12%|█▏        | 820/6629 [00:03<00:21, 264.27it/s] 13%|█▎        | 847/6629 [00:03<00:21, 263.37it/s] 13%|█▎        | 874/6629 [00:03<00:21, 263.65it/s] 14%|█▎        | 901/6629 [00:03<00:21, 263.59it/s] 14%|█▍        | 928/6629 [00:03<00:21, 264.18it/s] 14%|█▍        | 955/6629 [00:03<00:21, 264.15it/s] 15%|█▍        | 982/6629 [00:03<00:21, 263.21it/s] 15%|█▌        | 1009/6629 [00:03<00:21, 263.28it/s] 16%|█▌        | 1037/6629 [00:03<00:21, 265.67it/s] 16%|█▌        | 1065/6629 [00:04<00:20, 269.26it/s] 17%|█▋        | 1094/6629 [00:04<00:20, 272.77it/s] 17%|█▋        | 1123/6629 [00:04<00:20, 275.22it/s] 17%|█▋        | 1152/6629 [00:04<00:19, 277.07it/s] 18%|█▊        | 1180/6629 [00:04<00:19, 277.45it/s] 18%|█▊        | 1209/6629 [00:04<00:19, 278.43it/s] 19%|█▊        | 1238/6629 [00:04<00:19, 279.15it/s] 19%|█▉        | 1266/6629 [00:04<00:19, 279.33it/s] 20%|█▉        | 1294/6629 [00:04<00:19, 279.17it/s] 20%|█▉        | 1322/6629 [00:04<00:19, 278.65it/s] 20%|██        | 1350/6629 [00:05<00:19, 276.81it/s] 21%|██        | 1378/6629 [00:05<00:18, 277.30it/s] 21%|██        | 1407/6629 [00:05<00:18, 278.21it/s] 22%|██▏       | 1436/6629 [00:05<00:18, 278.89it/s] 22%|██▏       | 1464/6629 [00:05<00:18, 278.99it/s] 23%|██▎       | 1492/6629 [00:05<00:18, 278.96it/s] 23%|██▎       | 1521/6629 [00:05<00:18, 279.89it/s] 23%|██▎       | 1550/6629 [00:05<00:18, 280.80it/s] 24%|██▍       | 1579/6629 [00:05<00:17, 280.87it/s] 24%|██▍       | 1608/6629 [00:05<00:17, 280.74it/s] 25%|██▍       | 1637/6629 [00:06<00:17, 280.57it/s] 25%|██▌       | 1666/6629 [00:06<00:17, 281.34it/s] 26%|██▌       | 1695/6629 [00:06<00:17, 280.31it/s] 26%|██▌       | 1724/6629 [00:06<00:17, 280.46it/s] 26%|██▋       | 1753/6629 [00:06<00:17, 281.12it/s] 27%|██▋       | 1782/6629 [00:06<00:17, 280.63it/s] 27%|██▋       | 1811/6629 [00:06<00:17, 279.71it/s] 28%|██▊       | 1840/6629 [00:06<00:17, 280.13it/s] 28%|██▊       | 1869/6629 [00:06<00:16, 280.90it/s] 29%|██▊       | 1898/6629 [00:06<00:16, 280.78it/s] 29%|██▉       | 1927/6629 [00:07<00:16, 280.92it/s] 30%|██▉       | 1956/6629 [00:07<00:16, 280.81it/s] 30%|██▉       | 1985/6629 [00:07<00:16, 280.61it/s] 30%|███       | 2014/6629 [00:07<00:16, 279.00it/s] 31%|███       | 2043/6629 [00:07<00:16, 279.48it/s] 31%|███▏      | 2072/6629 [00:07<00:16, 279.84it/s] 32%|███▏      | 2100/6629 [00:07<00:16, 278.77it/s] 32%|███▏      | 2128/6629 [00:07<00:16, 278.55it/s] 33%|███▎      | 2156/6629 [00:07<00:16, 278.79it/s] 33%|███▎      | 2185/6629 [00:08<00:15, 279.58it/s] 33%|███▎      | 2213/6629 [00:08<00:15, 279.22it/s] 34%|███▍      | 2241/6629 [00:08<00:15, 279.12it/s] 34%|███▍      | 2269/6629 [00:08<00:15, 279.20it/s] 35%|███▍      | 2297/6629 [00:08<00:15, 278.50it/s] 35%|███▌      | 2325/6629 [00:08<00:15, 278.32it/s] 36%|███▌      | 2354/6629 [00:08<00:15, 279.35it/s] 36%|███▌      | 2383/6629 [00:08<00:15, 280.01it/s] 36%|███▋      | 2411/6629 [00:08<00:15, 279.67it/s] 37%|███▋      | 2440/6629 [00:08<00:14, 280.44it/s] 37%|███▋      | 2469/6629 [00:09<00:14, 281.01it/s] 38%|███▊      | 2498/6629 [00:09<00:14, 281.26it/s] 38%|███▊      | 2527/6629 [00:09<00:14, 281.05it/s] 39%|███▊      | 2556/6629 [00:09<00:14, 280.85it/s] 39%|███▉      | 2585/6629 [00:09<00:14, 281.05it/s] 39%|███▉      | 2614/6629 [00:09<00:14, 281.38it/s] 40%|███▉      | 2643/6629 [00:09<00:14, 281.27it/s] 40%|████      | 2672/6629 [00:09<00:14, 281.57it/s] 41%|████      | 2701/6629 [00:09<00:13, 281.50it/s] 41%|████      | 2730/6629 [00:09<00:13, 280.95it/s] 42%|████▏     | 2759/6629 [00:10<00:13, 279.96it/s] 42%|████▏     | 2787/6629 [00:10<00:13, 278.90it/s] 42%|████▏     | 2815/6629 [00:10<00:13, 278.21it/s] 43%|████▎     | 2843/6629 [00:10<00:13, 278.42it/s] 43%|████▎     | 2871/6629 [00:10<00:13, 278.85it/s] 44%|████▎     | 2900/6629 [00:10<00:13, 279.77it/s] 44%|████▍     | 2928/6629 [00:10<00:13, 279.40it/s] 45%|████▍     | 2956/6629 [00:10<00:13, 279.24it/s] 45%|████▌     | 2984/6629 [00:10<00:13, 279.27it/s] 45%|████▌     | 3012/6629 [00:10<00:12, 279.02it/s] 46%|████▌     | 3041/6629 [00:11<00:12, 279.98it/s] 46%|████▋     | 3070/6629 [00:11<00:12, 280.27it/s] 47%|████▋     | 3099/6629 [00:11<00:12, 279.94it/s] 47%|████▋     | 3128/6629 [00:11<00:12, 280.42it/s] 48%|████▊     | 3157/6629 [00:11<00:12, 280.57it/s] 48%|████▊     | 3186/6629 [00:11<00:12, 279.89it/s] 48%|████▊     | 3215/6629 [00:11<00:12, 280.12it/s] 49%|████▉     | 3244/6629 [00:11<00:12, 279.59it/s] 49%|████▉     | 3272/6629 [00:11<00:12, 279.30it/s] 50%|████▉     | 3300/6629 [00:11<00:11, 278.55it/s] 50%|█████     | 3328/6629 [00:12<00:11, 278.49it/s] 51%|█████     | 3357/6629 [00:12<00:11, 279.91it/s] 51%|█████     | 3385/6629 [00:12<00:11, 279.43it/s] 52%|█████▏    | 3414/6629 [00:12<00:11, 279.74it/s] 52%|█████▏    | 3443/6629 [00:12<00:11, 280.13it/s] 52%|█████▏    | 3472/6629 [00:12<00:11, 280.92it/s] 53%|█████▎    | 3501/6629 [00:12<00:11, 278.71it/s] 53%|█████▎    | 3530/6629 [00:12<00:11, 279.43it/s] 54%|█████▎    | 3558/6629 [00:12<00:10, 279.55it/s] 54%|█████▍    | 3587/6629 [00:13<00:10, 280.28it/s] 55%|█████▍    | 3616/6629 [00:13<00:10, 280.40it/s] 55%|█████▍    | 3645/6629 [00:13<00:10, 280.11it/s] 55%|█████▌    | 3674/6629 [00:13<00:10, 280.32it/s] 56%|█████▌    | 3703/6629 [00:13<00:10, 280.44it/s] 56%|█████▋    | 3732/6629 [00:13<00:10, 279.23it/s] 57%|█████▋    | 3760/6629 [00:13<00:10, 279.39it/s] 57%|█████▋    | 3788/6629 [00:13<00:10, 279.18it/s] 58%|█████▊    | 3816/6629 [00:13<00:10, 278.72it/s] 58%|█████▊    | 3844/6629 [00:13<00:09, 279.06it/s] 58%|█████▊    | 3872/6629 [00:14<00:09, 279.10it/s] 59%|█████▉    | 3900/6629 [00:14<00:09, 278.70it/s] 59%|█████▉    | 3929/6629 [00:14<00:09, 279.28it/s] 60%|█████▉    | 3958/6629 [00:14<00:09, 280.28it/s] 60%|██████    | 3987/6629 [00:14<00:09, 280.23it/s] 61%|██████    | 4016/6629 [00:14<00:09, 280.06it/s] 61%|██████    | 4045/6629 [00:14<00:09, 279.29it/s] 61%|██████▏   | 4074/6629 [00:14<00:09, 279.71it/s] 62%|██████▏   | 4102/6629 [00:14<00:09, 279.57it/s] 62%|██████▏   | 4130/6629 [00:14<00:08, 279.35it/s] 63%|██████▎   | 4159/6629 [00:15<00:08, 280.38it/s] 63%|██████▎   | 4188/6629 [00:15<00:08, 279.45it/s] 64%|██████▎   | 4216/6629 [00:15<00:08, 278.43it/s] 64%|██████▍   | 4244/6629 [00:15<00:08, 278.63it/s] 64%|██████▍   | 4272/6629 [00:15<00:08, 278.63it/s] 65%|██████▍   | 4301/6629 [00:15<00:08, 279.69it/s] 65%|██████▌   | 4329/6629 [00:15<00:08, 279.42it/s] 66%|██████▌   | 4358/6629 [00:15<00:08, 279.83it/s] 66%|██████▌   | 4387/6629 [00:15<00:08, 280.00it/s] 67%|██████▋   | 4416/6629 [00:15<00:07, 280.14it/s] 67%|██████▋   | 4445/6629 [00:16<00:07, 278.91it/s] 67%|██████▋   | 4474/6629 [00:16<00:07, 279.51it/s] 68%|██████▊   | 4503/6629 [00:16<00:07, 279.88it/s] 68%|██████▊   | 4531/6629 [00:16<00:07, 279.73it/s] 69%|██████▉   | 4559/6629 [00:16<00:07, 279.59it/s] 69%|██████▉   | 4588/6629 [00:16<00:07, 280.47it/s] 70%|██████▉   | 4617/6629 [00:16<00:07, 280.06it/s] 70%|███████   | 4646/6629 [00:16<00:07, 279.93it/s] 71%|███████   | 4674/6629 [00:16<00:06, 279.67it/s] 71%|███████   | 4703/6629 [00:17<00:06, 280.35it/s] 71%|███████▏  | 4732/6629 [00:17<00:06, 280.77it/s] 72%|███████▏  | 4761/6629 [00:17<00:06, 279.35it/s] 72%|███████▏  | 4789/6629 [00:17<00:06, 279.09it/s] 73%|███████▎  | 4817/6629 [00:17<00:06, 277.28it/s] 73%|███████▎  | 4845/6629 [00:17<00:06, 276.77it/s] 74%|███████▎  | 4873/6629 [00:17<00:06, 277.70it/s] 74%|███████▍  | 4902/6629 [00:17<00:06, 279.24it/s] 74%|███████▍  | 4931/6629 [00:17<00:06, 279.53it/s] 75%|███████▍  | 4959/6629 [00:17<00:05, 279.22it/s] 75%|███████▌  | 4987/6629 [00:18<00:05, 278.20it/s] 76%|███████▌  | 5015/6629 [00:18<00:05, 276.93it/s] 76%|███████▌  | 5043/6629 [00:18<00:05, 276.79it/s] 76%|███████▋  | 5071/6629 [00:18<00:05, 277.03it/s] 77%|███████▋  | 5099/6629 [00:18<00:05, 276.54it/s] 77%|███████▋  | 5127/6629 [00:18<00:05, 275.99it/s] 78%|███████▊  | 5155/6629 [00:18<00:05, 275.13it/s] 78%|███████▊  | 5183/6629 [00:18<00:05, 274.50it/s] 79%|███████▊  | 5211/6629 [00:18<00:05, 274.48it/s] 79%|███████▉  | 5239/6629 [00:18<00:05, 274.42it/s] 79%|███████▉  | 5267/6629 [00:19<00:04, 275.00it/s] 80%|███████▉  | 5295/6629 [00:19<00:04, 274.78it/s] 80%|████████  | 5323/6629 [00:19<00:04, 276.24it/s] 81%|████████  | 5351/6629 [00:19<00:04, 277.23it/s] 81%|████████  | 5379/6629 [00:19<00:04, 276.84it/s] 82%|████████▏ | 5407/6629 [00:19<00:04, 277.46it/s] 82%|████████▏ | 5436/6629 [00:19<00:04, 278.48it/s] 82%|████████▏ | 5464/6629 [00:19<00:04, 277.29it/s] 83%|████████▎ | 5492/6629 [00:19<00:04, 277.76it/s] 83%|████████▎ | 5520/6629 [00:19<00:03, 277.80it/s] 84%|████████▎ | 5548/6629 [00:20<00:03, 277.67it/s] 84%|████████▍ | 5576/6629 [00:20<00:03, 278.04it/s] 85%|████████▍ | 5604/6629 [00:20<00:03, 278.61it/s] 85%|████████▍ | 5632/6629 [00:20<00:03, 277.45it/s] 85%|████████▌ | 5661/6629 [00:20<00:03, 279.13it/s] 86%|████████▌ | 5689/6629 [00:20<00:03, 278.49it/s] 86%|████████▋ | 5718/6629 [00:20<00:03, 279.56it/s] 87%|████████▋ | 5747/6629 [00:20<00:03, 280.06it/s] 87%|████████▋ | 5776/6629 [00:20<00:03, 280.12it/s] 88%|████████▊ | 5805/6629 [00:20<00:02, 280.13it/s] 88%|████████▊ | 5834/6629 [00:21<00:02, 280.16it/s] 88%|████████▊ | 5863/6629 [00:21<00:02, 280.20it/s] 89%|████████▉ | 5892/6629 [00:21<00:02, 280.67it/s] 89%|████████▉ | 5921/6629 [00:21<00:02, 279.62it/s] 90%|████████▉ | 5949/6629 [00:21<00:02, 279.50it/s] 90%|█████████ | 5977/6629 [00:21<00:02, 278.81it/s] 91%|█████████ | 6005/6629 [00:21<00:02, 278.00it/s] 91%|█████████ | 6034/6629 [00:21<00:02, 278.74it/s] 91%|█████████▏| 6062/6629 [00:21<00:02, 278.77it/s] 92%|█████████▏| 6090/6629 [00:22<00:01, 279.08it/s] 92%|█████████▏| 6118/6629 [00:22<00:01, 279.33it/s] 93%|█████████▎| 6147/6629 [00:22<00:01, 279.76it/s] 93%|█████████▎| 6176/6629 [00:22<00:01, 280.02it/s] 94%|█████████▎| 6205/6629 [00:22<00:01, 279.27it/s] 94%|█████████▍| 6233/6629 [00:22<00:01, 278.46it/s] 94%|█████████▍| 6261/6629 [00:22<00:01, 278.08it/s] 95%|█████████▍| 6289/6629 [00:22<00:01, 278.10it/s] 95%|█████████▌| 6318/6629 [00:22<00:01, 278.77it/s] 96%|█████████▌| 6346/6629 [00:22<00:01, 278.01it/s] 96%|█████████▌| 6374/6629 [00:23<00:00, 277.93it/s] 97%|█████████▋| 6403/6629 [00:23<00:00, 278.58it/s] 97%|█████████▋| 6431/6629 [00:23<00:00, 278.81it/s] 97%|█████████▋| 6459/6629 [00:23<00:00, 278.58it/s] 98%|█████████▊| 6487/6629 [00:23<00:00, 278.71it/s] 98%|█████████▊| 6515/6629 [00:23<00:00, 278.41it/s] 99%|█████████▊| 6543/6629 [00:23<00:00, 278.69it/s] 99%|█████████▉| 6572/6629 [00:23<00:00, 279.38it/s]100%|█████████▉| 6600/6629 [00:23<00:00, 279.53it/s]100%|█████████▉| 6628/6629 [00:23<00:00, 279.56it/s]100%|██████████| 6629/6629 [00:23<00:00, 276.92it/s]AVERAGE DENSITY :0.0
2022-03-23 18:57:44 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:57:44 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:57:44 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:57:44 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:57:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:57:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:57:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:57:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:57:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:57:44 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:57:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_last.pt
2022-03-23 18:57:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_last.pt
2022-03-23 18:57:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:57:44 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:57:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:57:44 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:57:44 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:57:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:57:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:57:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:58:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 19:02:36 | INFO | train_inner | epoch 001:    104 / 157 loss=11.41, ppl=2721.85, wps=8945.7, ups=0.36, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.604, loss_scale=8, train_wall=291, gb_free=13.5, wall=292
2022-03-23 19:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:05:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:05:06 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 19:05:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:05:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,.....
2022-03-23 19:05:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:05:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 19:05:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:05:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:05:28 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:05:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:05:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:05:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:05:58 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:05:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:06:01 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:06:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:06:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.669 | ppl 813.84 | bleu 0.01 | wps 2991.1 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-23 19:06:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-23 19:06:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:06:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 0.8272089553065598 seconds)
2022-03-23 19:06:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:06:01 | INFO | train | epoch 001 | loss 10.957 | ppl 1987.62 | wps 7849.5 | ups 0.31 | wpb 25120.6 | bsz 980.6 | num_updates 152 | lr 1.9e-05 | gnorm 2.854 | loss_scale 4 | train_wall 436 | gb_free 22.4 | wall 497
2022-03-23 19:06:02 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:08:18 | INFO | train_inner | epoch 002:     48 / 157 loss=9.791, ppl=885.81, wps=7441.2, ups=0.29, wpb=25437.5, bsz=1087.6, num_updates=200, lr=2.5e-05, gnorm=1.42, loss_scale=4, train_wall=281, gb_free=13.7, wall=634
2022-03-23 19:12:52 | INFO | train_inner | epoch 002:    148 / 157 loss=9.078, ppl=540.62, wps=9114, ups=0.37, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.527, loss_scale=4, train_wall=274, gb_free=20, wall=908
2022-03-23 19:13:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:13:20 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we.
2022-03-23 19:13:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:13:25 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:13:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:13:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:13:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:13:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:13:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:13:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:13:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:13:53 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:13:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:14:01 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:14:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:14:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:14:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" ""
2022-03-23 19:14:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:14:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:14:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:14:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.675 | ppl 408.78 | bleu 0.01 | wps 2714.7 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 19:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 19:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 0.777415594086051 seconds)
2022-03-23 19:14:21 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:14:21 | INFO | train | epoch 002 | loss 9.187 | ppl 582.78 | wps 7908.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.485 | loss_scale 4 | train_wall 432 | gb_free 13.5 | wall 997
2022-03-23 19:14:21 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:18:32 | INFO | train_inner | epoch 003:     91 / 157 loss=8.714, ppl=419.96, wps=7307.9, ups=0.29, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.438, loss_scale=4, train_wall=273, gb_free=12.9, wall=1248
2022-03-23 19:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:21:40 | INFO | fairseq.tasks.translation | example hypothesis: we we the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:21:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:21:45 | INFO | fairseq.tasks.translation | example hypothesis: is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:21:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:21:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:21:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:21:58 | INFO | fairseq.tasks.translation | example hypothesis: it's's a, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and it
2022-03-23 19:21:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:22:05 | INFO | fairseq.tasks.translation | example hypothesis: we we that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that.
2022-03-23 19:22:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:22:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:22:20 | INFO | fairseq.tasks.translation | example hypothesis: 's the the the the the the the, and the the the the the the the, and and and and the the the the the the the the the the the the the the the the the the the the the the the the the, and and and the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:22:28 | INFO | fairseq.tasks.translation | example hypothesis: we we we the the the, and the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:22:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:22:37 | INFO | fairseq.tasks.translation | example hypothesis: 's's, "" "" "" "" "" "" "" "
2022-03-23 19:22:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:22:39 | INFO | fairseq.tasks.translation | example hypothesis: we we we, we a a a a a a a a a a, and the the the the, and the the the the the the the the the the the the the, and the the the the the the the the the the the, and the the the the the the the the the the the the, and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and the the the the the the the the the the the the the the the the the the the the the, and that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that,
2022-03-23 19:22:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:22:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.453 | ppl 350.52 | bleu 0.04 | wps 2747 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.04
2022-03-23 19:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 19:22:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:22:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.04) (writing took 0.7930945218540728 seconds)
2022-03-23 19:22:40 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:22:40 | INFO | train | epoch 003 | loss 8.626 | ppl 395.2 | wps 7911.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.575 | loss_scale 4 | train_wall 433 | gb_free 13.2 | wall 1496
2022-03-23 19:22:40 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:24:16 | INFO | train_inner | epoch 004:     34 / 157 loss=8.467, ppl=353.9, wps=7397.9, ups=0.29, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.523, loss_scale=4, train_wall=278, gb_free=13, wall=1592
2022-03-23 19:28:52 | INFO | train_inner | epoch 004:    134 / 157 loss=8.229, ppl=300.09, wps=9132.5, ups=0.36, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=1.604, loss_scale=4, train_wall=276, gb_free=13.8, wall=1868
2022-03-23 19:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:29:58 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 19:29:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:30:03 | INFO | fairseq.tasks.translation | example hypothesis: the world is the world is the world.
2022-03-23 19:30:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:30:09 | INFO | fairseq.tasks.translation | example hypothesis: you have have to have to have to have to have to be be the world.
2022-03-23 19:30:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:30:15 | INFO | fairseq.tasks.translation | example hypothesis: , it's a way, and it's a way, and it's a way.
2022-03-23 19:30:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:30:21 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not not that we're not not not not not not not.
2022-03-23 19:30:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:30:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world, and the world is the world, and the world, and the world of the world, and the world, and the world.
2022-03-23 19:30:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:30:35 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not, and you can can can can can can can can can can can can can can can can can can're're're're're're're be be be be the world, and it, and it, and it's the world, and it.
2022-03-23 19:30:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:30:42 | INFO | fairseq.tasks.translation | example hypothesis: we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see, and that we're the the way, and we're the world of the way of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:30:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:30:51 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:30:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:30:53 | INFO | fairseq.tasks.translation | example hypothesis: , we have to have the world, it's the world, and we have the world of the world, and we're're're're're the world, it's the world, which we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be to be, and it, and the world, and it's the world, and the world, and it's the world, and it's be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, and it, and it's the world, and it's the world, and you can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:30:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:30:53 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.869 | ppl 233.72 | bleu 0.9 | wps 2950.2 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.9
2022-03-23 19:30:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 19:30:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:30:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:30:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.9) (writing took 0.7570879328995943 seconds)
2022-03-23 19:30:54 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:30:54 | INFO | train | epoch 004 | loss 8.243 | ppl 302.98 | wps 7993.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.524 | loss_scale 4 | train_wall 432 | gb_free 13.4 | wall 1990
2022-03-23 19:30:54 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:34:23 | INFO | train_inner | epoch 005:     77 / 157 loss=7.96, ppl=248.94, wps=7389.7, ups=0.3, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=1.93, loss_scale=4, train_wall=269, gb_free=14.6, wall=2199
2022-03-23 19:38:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:38:14 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the future of the world.
2022-03-23 19:38:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:38:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most of the most of the most of the most of the most of the most of here here here here here here.
2022-03-23 19:38:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:38:27 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new new new new new new new new year.
2022-03-23 19:38:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:38:34 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of a lot, and it's going to be a lot, and it's going to be a lot.
2022-03-23 19:38:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:38:42 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have that we're going to be a lot of the way that we're going to get that we're going to be not not not not not not going to be that we're going to be going to be that that we
2022-03-23 19:38:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:38:49 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of the world, and we're a lot of the most of the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world of the world, in the world, and
2022-03-23 19:38:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:38:57 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to be a lot of the way, and they're going to be in the lot of the lot of the way, and they're going to go to go to go to be in the way, and they're going to go to be in the way, and they're going to go to be in the way of the way of the
2022-03-23 19:38:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:39:05 | INFO | fairseq.tasks.translation | example hypothesis: we can see that we can see that we can see that we can see that we can see that we can see that we can see the way, and we can see that we can see that we can see that we can see the way of the way of the way, and we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can see that we can
2022-03-23 19:39:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:39:15 | INFO | fairseq.tasks.translation | example hypothesis: , we've have in the first, "" we've have to be, "" we've have in the first, "we've've have in the first," that, "we've've have in the first," "" ",", ",", ",", ",", "we've've have to be,", ",", "we've've've've've have to be,", "that we're in the first," that, "" "we've've've have to be in the first," "we've've've have to be," "we're in the first," "we're in the first," we're, ",", ",", ",", ",", ",", "we're in the first," "we've've've've've've've
2022-03-23 19:39:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:39:17 | INFO | fairseq.tasks.translation | example hypothesis: we're a lot of that we have to be in that we have to be a lot of the way, and we can be in the way that we have to be in the way that we have to be in the way that we have to be, and we have in the way that we have to be in that we have to be in the way that we have to be in that we have to be that we have to be in the way that we have to be in the first of that we have to be in that we have in the way that we have to be in the way, and we have to be in that we have to be in that we have to be in the same, we're in the same, and we have to be in the same, and we have to be in that we have to be that we have to be in the way that we have to be in the way that we have to be, and we have to be in the way, in the way, and we have to be in the way, and we can
2022-03-23 19:39:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:39:17 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.446 | ppl 174.4 | bleu 1.1 | wps 2581.1 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.1
2022-03-23 19:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:39:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.1) (writing took 0.7702545099891722 seconds)
2022-03-23 19:39:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:39:18 | INFO | train | epoch 005 | loss 7.775 | ppl 218.98 | wps 7837.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.745 | loss_scale 4 | train_wall 433 | gb_free 13.6 | wall 2494
2022-03-23 19:39:18 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:40:11 | INFO | train_inner | epoch 006:     20 / 157 loss=7.66, ppl=202.3, wps=7305.1, ups=0.29, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.63, loss_scale=4, train_wall=278, gb_free=12.2, wall=2547
2022-03-23 19:44:50 | INFO | train_inner | epoch 006:    120 / 157 loss=7.411, ppl=170.17, wps=9090.9, ups=0.36, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.574, loss_scale=4, train_wall=278, gb_free=13.6, wall=2826
2022-03-23 19:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:46:36 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 19:46:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:46:42 | INFO | fairseq.tasks.translation | example hypothesis: here's here here here here here's the world.
2022-03-23 19:46:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:46:48 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:46:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:46:55 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's going to be, and it's going to be a lot of the world.
2022-03-23 19:46:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:47:02 | INFO | fairseq.tasks.translation | example hypothesis: we're not going to do that we're going to do that we're going to do that we're going to do that's not not not not going to do that we're going to do that we're going to do it's going to
2022-03-23 19:47:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:47:10 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people who are a lot of people for people for the world, and people for the world, and people for the world, for the world, for the world, for the world, for the world, for the world, for the world.
2022-03-23 19:47:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:47:18 | INFO | fairseq.tasks.translation | example hypothesis: if you're not not going to be a lot of the world, but they're not not not going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be not not not not going to be able to be able to be
2022-03-23 19:47:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:47:26 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we can see that we can see that we can see the world, and we can see the world
2022-03-23 19:47:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:47:35 | INFO | fairseq.tasks.translation | example hypothesis: , i said, "" "" it's a lot of the world, "i said," i'm going to say, "it's going to say," it's going to say, "" "" it's a "it's going to say," it's going to say, "" "" "it's a" it's going to say, "it's going to say," "it's a" "" "" "" "" "" "it's a" "" "" "it's a" "" it's a "" "" it's a "" "" "it's," we said, "it's," we said, "it's going to say," it's going to say, "we said," we said, "it's going to say," "" "" "" ""
2022-03-23 19:47:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:47:38 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world, and we're going to be going to be a lot of the world that we can't have to be a lot of the world, and we're going to be able to be able to be a lot of the world that we're going to be able to be a lot of the world that we're going to be that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be able to be able to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world, and then that we're going to be a lot of the world that we can't have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be,
2022-03-23 19:47:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:47:38 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.081 | ppl 135.43 | bleu 1.48 | wps 2655.5 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.48
2022-03-23 19:47:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:47:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:47:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:47:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.48) (writing took 0.796555289067328 seconds)
2022-03-23 19:47:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:47:39 | INFO | train | epoch 006 | loss 7.4 | ppl 168.86 | wps 7884 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.631 | loss_scale 4 | train_wall 432 | gb_free 14.3 | wall 2995
2022-03-23 19:47:39 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:50:32 | INFO | train_inner | epoch 007:     63 / 157 loss=7.185, ppl=145.56, wps=7345.8, ups=0.29, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.477, loss_scale=4, train_wall=274, gb_free=14.4, wall=3168
2022-03-23 19:54:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:54:56 | INFO | fairseq.tasks.translation | example hypothesis: we've been in this.
2022-03-23 19:54:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:55:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the idea of the most most of the most of the most of the most of the most of the most of the most of
2022-03-23 19:55:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:55:08 | INFO | fairseq.tasks.translation | example hypothesis: you're going to be new new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:55:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:55:15 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's going to be, and it's going to be going to be going to be a lot, and it.
2022-03-23 19:55:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:55:22 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do is that we're going to do that we're going to do that we're going to be going to be going to do that we're going to be going to be going to be going to do.
2022-03-23 19:55:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:55:29 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of people in the people who have a lot of people in the world, and the world, and it's the people in the people in the world, and the world.
2022-03-23 19:55:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:55:36 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to get a lot of these things, but you're going to get a lot of them, but they're going to get a lot of them, but they're going to get a lot of them, but they're going to get a lot of them, but they're going to get a lot of them, but they're going to
2022-03-23 19:55:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:55:44 | INFO | fairseq.tasks.translation | example hypothesis: we're going to get a lot of the world, and we're going to see the world, and we're going to get a lot of the brain, and we're going to be able to be able to be able to be a lot of the world.
2022-03-23 19:55:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:55:53 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to say, "you know," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you know, "you're going to say," you're going to say, "you know," you know, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you know, "you're going to say," you're going to say, "you're going to say," you're going to say, ""
2022-03-23 19:55:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:55:55 | INFO | fairseq.tasks.translation | example hypothesis: we're going to get a lot of the world, and then we're going to be able to be a lot of the world, and it's going to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be able to be a lot of the world, and then we're going to be able to be a lot of the world, and then we're going to be able to be able to be able to be able to be able to be a lot of the world, and then we're going to be able to be a lot of the world, and then then we're going to be able to be a lot of the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 19:55:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:55:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.835 | ppl 114.17 | bleu 1.94 | wps 2767 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.94
2022-03-23 19:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:55:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 19:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.94) (writing took 0.8072402239777148 seconds)
2022-03-23 19:55:56 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:55:56 | INFO | train | epoch 007 | loss 7.097 | ppl 136.87 | wps 7945 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.457 | loss_scale 4 | train_wall 431 | gb_free 14 | wall 3492
2022-03-23 19:55:56 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:56:11 | INFO | train_inner | epoch 008:      6 / 157 loss=7.031, ppl=130.74, wps=7372.4, ups=0.29, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.491, loss_scale=4, train_wall=273, gb_free=13.9, wall=3508
2022-03-23 20:00:47 | INFO | train_inner | epoch 008:    106 / 157 loss=6.803, ppl=111.7, wps=9170.7, ups=0.36, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.408, loss_scale=4, train_wall=275, gb_free=14.2, wall=3783
2022-03-23 20:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:03:13 | INFO | fairseq.tasks.translation | example hypothesis: we've got in this.
2022-03-23 20:03:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:03:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most of the most most of the most of the most most of the most of the most most of the most of
2022-03-23 20:03:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:03:25 | INFO | fairseq.tasks.translation | example hypothesis: this is new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:03:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:03:32 | INFO | fairseq.tasks.translation | example hypothesis: it's an example where you're going to see where you're going to see, where you're going to see where you're going to see, where it's where you're going to see where are going
2022-03-23 20:03:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:03:39 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do is that we're going to do with a little bit of what we're going to do, and what we're going to do is that we're going to do it's not going to do.
2022-03-23 20:03:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:03:47 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the most people who are in the people in the people in the people in the people who are in the people in the people in the people who are in the people in the people in the people who are in the people in the people who are in the people in the people
2022-03-23 20:03:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:03:54 | INFO | fairseq.tasks.translation | example hypothesis: if you have a lot of these things, but there are not a lot of their own, but it's a lot of the same way, but they're not a lot of them, but it's a lot of them, but they're not a lot of the same, but they're not a lot of them, but but they're going to get
2022-03-23 20:03:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:04:02 | INFO | fairseq.tasks.translation | example hypothesis: if we can see that, we can take a lot of the brain, you can see, and then we can see the brain, you can see the brain, you can see that we can see the brain, you can see the brain, you can see the brain, you can see the brain, you can see the brain, you can see the brain, you can see the brain, you can see the brain, you can see the brain, and the brain
2022-03-23 20:04:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:04:11 | INFO | fairseq.tasks.translation | example hypothesis: in fact, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," "
2022-03-23 20:04:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:04:13 | INFO | fairseq.tasks.translation | example hypothesis: if you know, it's a lot of the world that we're going to be a lot of the world, and then we have a lot of the world in the world, which is a lot of the world, which is a lot of the world, which is a lot of the world that we're going to be a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world that we have a lot of the world, which is a lot of the world that we're going to be able to be a lot of the world, which is that we're going to see that we're going to see that we're going to see that we're going to see that we have a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the world, which is a lot of the
2022-03-23 20:04:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:04:13 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.564 | ppl 94.6 | bleu 2.68 | wps 2695.6 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.68
2022-03-23 20:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:04:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:04:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.68) (writing took 0.7958976891823113 seconds)
2022-03-23 20:04:14 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:04:14 | INFO | train | epoch 008 | loss 6.872 | ppl 117.1 | wps 7921.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.388 | loss_scale 4 | train_wall 431 | gb_free 13.1 | wall 3990
2022-03-23 20:04:15 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:06:34 | INFO | train_inner | epoch 009:     49 / 157 loss=6.793, ppl=110.9, wps=7393.9, ups=0.29, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.287, loss_scale=4, train_wall=279, gb_free=14.5, wall=4130
2022-03-23 20:11:05 | INFO | train_inner | epoch 009:    149 / 157 loss=6.622, ppl=98.51, wps=9143.4, ups=0.37, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.469, loss_scale=4, train_wall=271, gb_free=13.9, wall=4401
2022-03-23 20:11:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:11:32 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the end of the ground.
2022-03-23 20:11:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:11:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most most of the most most most most most of the most most.
2022-03-23 20:11:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:11:44 | INFO | fairseq.tasks.translation | example hypothesis: now, new new new new new new new new new new new new new new new new are going to be going to be new new new york.
2022-03-23 20:11:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:11:50 | INFO | fairseq.tasks.translation | example hypothesis: there's example of example, there's an example, where it's where it's going to be in the mamaoooan, and where it's going to be where it's going.
2022-03-23 20:11:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:11:57 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just a little bit of what we're going to do, and what's going to do.
2022-03-23 20:11:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:12:04 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the people like people who are in the people for people in the people, and the most people who are in the people in the most people in the most people in the people who are going to find in the most people in the most people in the most people in the united
2022-03-23 20:12:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:12:12 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of some of some of some of the time, but there are the same time, but it's not the same time, but if you can't see the same time, but it's the same time, but it's the same time, but it doesn't be the same time, but it's
2022-03-23 20:12:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:12:20 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we're going to use the information that we can see the information, and we can see the information that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 20:12:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:12:29 | INFO | fairseq.tasks.translation | example hypothesis: one of the one: there's a lot of the world, and it's going to say, "and there's a lot of you know," you know, "you know," you know, "you know," you're going to say, "you know," well, "you know," and then there's a very good for me, "you know," and then we're going to say, "you're going to say," "and then there's the first time," and then we're going to say, "you're going to say," you're going to say, "and then we're going to say," you're going to say, "you're going to say," you know, "and then there's a good good good for me," and then there's a good good good for me, "" "" "
2022-03-23 20:12:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:12:32 | INFO | fairseq.tasks.translation | example hypothesis: in fact, there is the same time that the same time that we're going to be in the same time, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 20:12:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:12:32 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.241 | ppl 75.63 | bleu 3.65 | wps 2724.9 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.65
2022-03-23 20:12:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:12:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:12:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:12:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.65) (writing took 0.7983904401771724 seconds)
2022-03-23 20:12:33 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:12:33 | INFO | train | epoch 009 | loss 6.606 | ppl 97.39 | wps 7925.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.383 | loss_scale 4 | train_wall 431 | gb_free 14.2 | wall 4489
2022-03-23 20:12:33 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:12:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:16:48 | INFO | train_inner | epoch 010:     92 / 157 loss=6.369, ppl=82.68, wps=7316.6, ups=0.29, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.305, loss_scale=4, train_wall=276, gb_free=13.8, wall=4744
2022-03-23 20:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:19:50 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the way.
2022-03-23 20:19:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:19:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the name of the most most of the most most most most most of the most most most most.
2022-03-23 20:19:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:20:03 | INFO | fairseq.tasks.translation | example hypothesis: they're going to get new new new new new new new new new cells.
2022-03-23 20:20:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:20:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a place where where it's where it's going to go.
2022-03-23 20:20:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:20:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just a little bit of his eyes, and what's going to do.
2022-03-23 20:20:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:20:20 | INFO | fairseq.tasks.translation | example hypothesis: in the middle of people like people like the people who are used for the people in the most people, and it's a lot of people in the market.
2022-03-23 20:20:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:20:27 | INFO | fairseq.tasks.translation | example hypothesis: some of you are some of them, but if you're going to go, it doesn't have the energy, but if you don't have the energy, you don't have the energy, you don't have the energy, if you don't have the energy, it's the energy.
2022-03-23 20:20:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:20:35 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use this information, we can use this information, and we can use a kind of information, and we can use the brain, and that's a kind of information that can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the brain and the brain and the brain and the structure of the information
2022-03-23 20:20:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:20:43 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reason, and it's interesting interesting, and it's going to talk about the first time, and then we've been working with a long time, and then you know, when you're going to go back to me, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to know, you know, you know, you know, you're going to go to do that is that's going to do that's going to do that's going to do that's going to do that's a lot of the time, you're going to do that's going to go to go with a lot of the first time, and then we're going to go to get a long time, and then, "
2022-03-23 20:20:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:20:45 | INFO | fairseq.tasks.translation | example hypothesis: in fact, there's a little bit of the mother, and we've been a little bit of the world, and if we had a little bit of the system that we were able to do with a little bit of the system that we could be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:20:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:20:45 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.863 | ppl 58.22 | bleu 6.25 | wps 2990.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.25
2022-03-23 20:20:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:20:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.25) (writing took 0.8132277620024979 seconds)
2022-03-23 20:20:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:20:46 | INFO | train | epoch 010 | loss 6.286 | ppl 78.05 | wps 8004.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.386 | loss_scale 4 | train_wall 431 | gb_free 13.3 | wall 4982
2022-03-23 20:20:46 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:22:20 | INFO | train_inner | epoch 011:     35 / 157 loss=6.204, ppl=73.73, wps=7491.1, ups=0.3, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.475, loss_scale=4, train_wall=270, gb_free=13, wall=5076
2022-03-23 20:26:58 | INFO | train_inner | epoch 011:    135 / 157 loss=5.952, ppl=61.92, wps=9174.2, ups=0.36, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.416, loss_scale=4, train_wall=278, gb_free=12.9, wall=5355
2022-03-23 20:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:28:03 | INFO | fairseq.tasks.translation | example hypothesis: we found these ppat the end of the clinics.
2022-03-23 20:28:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:28:09 | INFO | fairseq.tasks.translation | example hypothesis: that's not the most ha, most most most most most most of you know.
2022-03-23 20:28:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:28:15 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new york are going to be two ways.
2022-03-23 20:28:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:28:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese, where they're going to go and get it.
2022-03-23 20:28:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:28:27 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just a few months on his head, and what's going on.
2022-03-23 20:28:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:28:33 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamace of people who had the number of the number of animals, and that's a number of people in order to have a million years.
2022-03-23 20:28:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:28:39 | INFO | fairseq.tasks.translation | example hypothesis: some of some of you are actually able to go back in the ground, but if you don't need the energy, it doesn't need the energy.
2022-03-23 20:28:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:28:45 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use information information that we can see the structure of a structure, and we can use the structure of the structure, the structure of the structure, and the information that are going to be able to be able to be able to be able to be able to be able to create a structure.
2022-03-23 20:28:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:28:51 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that there's interesting interesting interesting for me, and then, "if we're going to talk to you," you know, "you're going to say," you know, "'' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '"
2022-03-23 20:28:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:28:53 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still the mother, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 20:28:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:28:53 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.583 | ppl 47.93 | bleu 8.64 | wps 3277.1 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.64
2022-03-23 20:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:28:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.64) (writing took 0.8289240705780685 seconds)
2022-03-23 20:28:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:28:54 | INFO | train | epoch 011 | loss 6.018 | ppl 64.81 | wps 8090.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.418 | loss_scale 4 | train_wall 431 | gb_free 13.6 | wall 5470
2022-03-23 20:28:54 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:32:30 | INFO | train_inner | epoch 012:     78 / 157 loss=5.844, ppl=57.45, wps=7537.7, ups=0.3, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.39, loss_scale=4, train_wall=274, gb_free=13.5, wall=5686
2022-03-23 20:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:36:12 | INFO | fairseq.tasks.translation | example hypothesis: we went into this clinics.
2022-03-23 20:36:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:36:18 | INFO | fairseq.tasks.translation | example hypothesis: that's the bottom of ha ha, most of the most most most most most of the most here.
2022-03-23 20:36:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:36:25 | INFO | fairseq.tasks.translation | example hypothesis: new states will be able to be two kinds of orored the new new york.
2022-03-23 20:36:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:36:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese, where they're going to get up with your legs, and they're going to get up.
2022-03-23 20:36:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:36:37 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just going to understand a few years on his head on his head, and what's going on.
2022-03-23 20:36:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:36:43 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the mamamamace of the responsibility, for the number of animals, and the number of animals has been used to build a million years.
2022-03-23 20:36:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:36:50 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you're going to look at the pattern, but if you don't need to use the energy, if you don't need your energy, it doesn't need to get your energy, and you need your energy.
2022-03-23 20:36:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:36:56 | INFO | fairseq.tasks.translation | example hypothesis: if we use information from this information, we can see this structure, we can see a very much of the structure, which is the structure of the structure, and all the structure of the structure, and all the structure of the structure, all the structure of the structure, and all the structure.
2022-03-23 20:36:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:37:02 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to do, and it's interesting for me to be here for women, "if we said," well, "if we say," well, "if we're going to say," well, "you know," you know, "you know," if we're going to say, "you're going to say," you know, "you know," you're going to go to go to you know, "and then you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," a
2022-03-23 20:37:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:37:05 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still the mother of the mother, and a lot of work that we had to see that we had to create a very large system that we had to see that if we had to be able to create a little bit of energy, and then we had to create a little bit of the same system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a
2022-03-23 20:37:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:37:05 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.203 | ppl 36.83 | bleu 10.58 | wps 3112.4 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.58
2022-03-23 20:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.58) (writing took 0.8365266141481698 seconds)
2022-03-23 20:37:06 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:37:06 | INFO | train | epoch 012 | loss 5.69 | ppl 51.62 | wps 8033.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.371 | loss_scale 4 | train_wall 432 | gb_free 13.7 | wall 5962
2022-03-23 20:37:06 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:38:03 | INFO | train_inner | epoch 013:     21 / 157 loss=5.537, ppl=46.41, wps=7548, ups=0.3, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.422, loss_scale=4, train_wall=273, gb_free=13.4, wall=6019
2022-03-23 20:42:40 | INFO | train_inner | epoch 013:    121 / 157 loss=5.408, ppl=42.45, wps=9131.3, ups=0.36, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.322, loss_scale=4, train_wall=277, gb_free=13.1, wall=6296
2022-03-23 20:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:44:23 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppon the clinic.
2022-03-23 20:44:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:44:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the top of doha, most of most, most most of the most.
2022-03-23 20:44:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:44:35 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be new ororored by two new ways.
2022-03-23 20:44:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:44:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese food, where your legs are going to go and get it.
2022-03-23 20:44:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:44:46 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a couple of electroelectrodes on his head, and what's going on.
2022-03-23 20:44:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:44:52 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamace of responsibility for the number of animals, and this is a number of animals that has been created in the iiiibia.
2022-03-23 20:44:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:44:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are able to go through the microscope, but it doesn't need your energy energy, if you need your energy, the energy.
2022-03-23 20:44:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:45:04 | INFO | fairseq.tasks.translation | example hypothesis: if we use information that information, we can look at this reflection, we can start with a big form of the structure, and the structure of the structure of the structure.
2022-03-23 20:45:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:45:09 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's interesting to make tedtedtedson for women, "oh," oh, when we said, "well," if you say, "well," if you're going to say, "you're going to say," well, "if we're going to say," well, "well, if you're going to say," you're going to say, "well," well, "you're going to say," well, "well," you're going to say, "well," well, "you're going to say," if we're going to say, "well," you're going to say, "you're going to say," you're going to say, "you've got to say," one of you're going to be a long time to be a long time to be a
2022-03-23 20:45:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:45:10 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the ultimate mother is still the invention, and a lot of work that we had to solve our business system that we had to use it into a drug system, and if we had to use it to use it to be able to use it to be able to use it in a source of the ground.
2022-03-23 20:45:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:45:10 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.012 | ppl 32.26 | bleu 12.44 | wps 3499.8 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.44
2022-03-23 20:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:45:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:45:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.44) (writing took 0.8617277620360255 seconds)
2022-03-23 20:45:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:45:11 | INFO | train | epoch 013 | loss 5.379 | ppl 41.62 | wps 8135.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.349 | loss_scale 4 | train_wall 431 | gb_free 13 | wall 6447
2022-03-23 20:45:11 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:48:07 | INFO | train_inner | epoch 014:     64 / 157 loss=5.244, ppl=37.9, wps=7628.3, ups=0.31, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.355, loss_scale=4, train_wall=273, gb_free=13.6, wall=6623
2022-03-23 20:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:52:29 | INFO | fairseq.tasks.translation | example hypothesis: we made this pppppure in the clinics.
2022-03-23 20:52:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:52:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, ha, which most most of most of the most most knows here.
2022-03-23 20:52:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:52:41 | INFO | fairseq.tasks.translation | example hypothesis: these new stars are going to create new dins that are going to create two new new forces.
2022-03-23 20:52:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:52:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french, chinese food, where the legs are happy with legs, and they're going to be in front.
2022-03-23 20:52:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:52:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a few electrodes on his head on his head, and what all the thoughts are.
2022-03-23 20:52:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:53:00 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamamamace, how people took the responsibility for the number of animals, and this has become become a group.
2022-03-23 20:53:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:53:06 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magnetic magnetic magnetic magnetic lines in the lines, but it doesn't need to move the energy, if you need your energy and the energy.
2022-03-23 20:53:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:53:12 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection of reflection, we can start to start with a traditional traditional traditional symphony, and the whole structure of the structure.
2022-03-23 20:53:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:53:17 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting, and it's interesting to do interesting for me to be here for tedtedson, "oh, when we've got a long talk to you."
2022-03-23 20:53:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:53:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still still the invention of the invention of invention, and a big design that we had to see that if we had to use a unique system to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 20:53:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:53:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.774 | ppl 27.35 | bleu 14.52 | wps 3263.2 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.52
2022-03-23 20:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:53:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 20:53:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.52) (writing took 0.8281448232010007 seconds)
2022-03-23 20:53:20 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:53:20 | INFO | train | epoch 014 | loss 5.074 | ppl 33.68 | wps 8073.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.29 | loss_scale 4 | train_wall 432 | gb_free 13.3 | wall 6936
2022-03-23 20:53:21 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:53:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:53:43 | INFO | train_inner | epoch 015:      7 / 157 loss=4.936, ppl=30.61, wps=7595.5, ups=0.3, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.186, loss_scale=4, train_wall=279, gb_free=13.4, wall=6959
2022-03-23 20:58:17 | INFO | train_inner | epoch 015:    107 / 157 loss=4.792, ppl=27.71, wps=9184.5, ups=0.37, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.315, loss_scale=4, train_wall=273, gb_free=13.5, wall=7233
2022-03-23 21:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:00:38 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinics.
2022-03-23 21:00:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:00:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 21:00:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:00:50 | INFO | fairseq.tasks.translation | example hypothesis: these new stars are going to create new dines that are going to make two new restores.
2022-03-23 21:00:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:00:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese chinese chinese food, where they're going to be salt with legs and poke.
2022-03-23 21:00:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:01:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a few electroelectrodes on his head, and what all of his thoughts are going to understand.
2022-03-23 21:01:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:01:08 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamace of people like the responsibility, the number of animals grew up again, and this is a number of conservation for the way of conservaiiiiiibia.
2022-03-23 21:01:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:01:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are some of the magnetic magnetic magnetic lines in the lines, but it doesn't like it, if you're not going to move your energy, it doesn't need your energy, and you need your energy.
2022-03-23 21:01:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:01:21 | INFO | fairseq.tasks.translation | example hypothesis: if we use information that reflection from this reflection, we can start with a traditional reflection of traditional faces, we can start able to start able to start able to create a big shape of the shape of the structure of the information, and the whole structure of the structure and the information that are all the structure of the information and all the information, the information that are all the information, the information and the information, the information that are all the information that
2022-03-23 21:01:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:01:27 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and interesting for example, for example, for example, for example, is that women were talking to me, "oh," oh, "oh, if you're playing the best part of the best time," and then you've got a lot of love for you're going to share with you're talking to love "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 21:01:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:01:30 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, interestingly, the mother of the invention of the invention, and one part of our work was part of our airplane, we had to solve a unique system that if we were able to solve a unique system, it was a unique system, or if we were able to use it to use it to use it, if we were able to be able to be able to be able to use it, if it was able to use a unique, if we were able to use it was able to be able to be able to use it was able to be able to be able to be able to be able to see that if we were able to be able to use it was able to be able to use it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use it, if we were able to use it was able to use it was able to use it's all the most effective, if we were able to use the same, if you
2022-03-23 21:01:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:01:30 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.419 | ppl 21.4 | bleu 15.6 | wps 3169.5 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.6
2022-03-23 21:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 21:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.6) (writing took 0.8381704771891236 seconds)
2022-03-23 21:01:30 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 21:01:30 | INFO | train | epoch 015 | loss 4.823 | ppl 28.3 | wps 8056.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.272 | loss_scale 4 | train_wall 431 | gb_free 13.3 | wall 7427
2022-03-23 21:01:31 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 21:01:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:03:54 | INFO | train_inner | epoch 016:     50 / 157 loss=4.826, ppl=28.36, wps=7535.6, ups=0.3, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.218, loss_scale=4, train_wall=279, gb_free=13.8, wall=7570
2022-03-23 21:08:24 | INFO | train_inner | epoch 016:    150 / 157 loss=4.465, ppl=22.09, wps=9151.4, ups=0.37, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.11, loss_scale=4, train_wall=269, gb_free=14, wall=7840
2022-03-23 21:08:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:08:48 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-23 21:08:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:08:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of us know.
2022-03-23 21:08:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:08:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 21:08:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:09:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are going to be picking with legs.
2022-03-23 21:09:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:09:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electromagnetic on his head and understand what all the thoughts are on its mind.
2022-03-23 21:09:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:09:15 | INFO | fairseq.tasks.translation | example hypothesis: in the mammals of responsibility, the number of responsibility grew up, and this is a number of animals that grew up in namibia.
2022-03-23 21:09:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:09:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but the conductor doesn't move if they need their energy, they don't need their energy, and so if they need their energy.
2022-03-23 21:09:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:09:27 | INFO | fairseq.tasks.translation | example hypothesis: if we use information.
2022-03-23 21:09:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:09:33 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that we have interesting and measure for tedtalks, "is that the best time we've been talking about to women," yeah, it was the best time when somebody said, "and then the best part of them starts to support you."
2022-03-23 21:09:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:09:33 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention is that if we're able to use a lot of design on our work, that we had to solve was a unique result that we had to solve a unique result that we had to solve.
2022-03-23 21:09:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:09:33 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.289 | ppl 19.55 | bleu 13.47 | wps 3604.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.6
2022-03-23 21:09:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:09:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:09:33 | INFO | train | epoch 016 | loss 4.549 | ppl 23.41 | wps 8176.2 | ups 0.33 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.171 | loss_scale 4 | train_wall 431 | gb_free 13.6 | wall 7910
2022-03-23 21:09:34 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:13:53 | INFO | train_inner | epoch 017:     93 / 157 loss=4.357, ppl=20.49, wps=7684.6, ups=0.3, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.185, loss_scale=4, train_wall=278, gb_free=14.5, wall=8169
2022-03-23 21:16:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:16:52 | INFO | fairseq.tasks.translation | example hypothesis: we did this pink in the clinic clinics.
2022-03-23 21:16:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:16:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 21:16:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:17:04 | INFO | fairseq.tasks.translation | example hypothesis: the stars are going to create new goldial dindining the two new locations.
2022-03-23 21:17:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:17:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs are going to be salt with salsales and fat.
2022-03-23 21:17:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:17:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head, and understand what all of his thoughts are on the ground.
2022-03-23 21:17:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:17:23 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamaal like the people who grew up for life, grew up the number of animals, and this is a foundation for conservation in namibia.
2022-03-23 21:17:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:17:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some blool of magnetic field lines, but the susullal lines in the inside of the field, if they don't need their energy, and so they don't need their energy.
2022-03-23 21:17:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:17:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection reflection reflection reflection reflect reflection, we can start with a traditional face of the interfaces, and you can start through the interactions of the information, and the whole structure of the structure of the information, and the whole structure of the structure of the structure, the structure of the structure, the whole structure, the structure of the structure of the structure, the whole structure, the structure,
2022-03-23 21:17:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:17:43 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that it's interesting and measure for me for tedwomen, "that if we've been talking about the best thing," if we've started to support the best thing, "and then we're working with a table revolution," if we're working on a table revolution, "and then we've been working with you've been working with you've got a game," and then we've been working with you've been working with you've been working with you know, "long time to help you've been working with you've been working with you've got a game," silent, "and then we've been working with you've been working with you've been working with you know," silent, "silent," and then we've been working with you've been working with you know, "silent," and then you've been working on
2022-03-23 21:17:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:17:46 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, economist is still the mother invention of invention, and a big part of the design design design that we've had to be connected to the ground, and if we had to see it was a unique result of the problems that we've had to be connected to the ground, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the mechanism, and see the mechanism, and see if we're able to be able to use
2022-03-23 21:17:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:17:46 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.079 | ppl 16.9 | bleu 17.92 | wps 3078.7 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17.92
2022-03-23 21:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:17:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:17:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:17:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.92) (writing took 0.9210812249220908 seconds)
2022-03-23 21:17:47 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:17:47 | INFO | train | epoch 017 | loss 4.346 | ppl 20.33 | wps 8007.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.192 | loss_scale 4 | train_wall 432 | gb_free 13.2 | wall 8403
2022-03-23 21:17:47 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:19:29 | INFO | train_inner | epoch 018:     36 / 157 loss=4.272, ppl=19.32, wps=7505.6, ups=0.3, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.177, loss_scale=4, train_wall=275, gb_free=13.9, wall=8505
2022-03-23 21:24:00 | INFO | train_inner | epoch 018:    136 / 157 loss=4.076, ppl=16.87, wps=9164.9, ups=0.37, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.031, loss_scale=4, train_wall=271, gb_free=13.7, wall=8776
2022-03-23 21:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:25:05 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic.
2022-03-23 21:25:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:25:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which most of you know.
2022-03-23 21:25:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:25:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dindindindindines that will create two new pigs.
2022-03-23 21:25:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:25:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs are made with salz and fat.
2022-03-23 21:25:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:25:28 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 21:25:28 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:25:34 | INFO | fairseq.tasks.translation | example hypothesis: in the maibia, like the people who took responsibility for the wild, grew up the number of wildlife again, and this is a foundation for conservation protection in namibia.
2022-03-23 21:25:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:25:40 | INFO | fairseq.tasks.translation | example hypothesis: first, there's some bloop of magnetic fields in the inner lines, but the susulal alalarm doesn't like it, if you need your energy movements, you need your energy movements, and you don't need the aluminum.
2022-03-23 21:25:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:25:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that can start with a traditional face of the big contains of the face and reform it through this information, which is the whole structure.
2022-03-23 21:25:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:25:52 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to be interesting and measure it for me here in tedwomen is that... "oh," yeah, it was that... "
2022-03-23 21:25:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:25:55 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother's invention of invention, and one part of the design of the design work that we're in our plane, was a result that we had to solve the unique problems that we had to solve it in the ground -- all the way to do it is to be a recycling system, and that if you're able to use an aircraft system to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the emergence, it in the emergence, it in the air, it, it, it, it's a very specific, it's an airplane, it's an airplane, it's an aircraft, it's an airplane, or an airplane, it's an airplane, it's an airplane, and that if you can't be able
2022-03-23 21:25:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:25:55 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.729 | ppl 13.26 | bleu 21.01 | wps 3264.2 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.01
2022-03-23 21:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:25:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.01) (writing took 0.8165683192200959 seconds)
2022-03-23 21:25:56 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:25:56 | INFO | train | epoch 018 | loss 4.088 | ppl 17.01 | wps 8076.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.015 | loss_scale 4 | train_wall 431 | gb_free 13.2 | wall 8892
2022-03-23 21:25:56 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:29:38 | INFO | train_inner | epoch 019:     79 / 157 loss=3.971, ppl=15.68, wps=7584.2, ups=0.3, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.006, loss_scale=4, train_wall=281, gb_free=13.5, wall=9114
2022-03-23 21:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:33:14 | INFO | fairseq.tasks.translation | example hypothesis: we made this sheep in the clinic.
2022-03-23 21:33:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:33:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most here.
2022-03-23 21:33:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:33:25 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dindindindindindines that will become two new pigs.
2022-03-23 21:33:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:33:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are served with salz and fat.
2022-03-23 21:33:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:33:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 21:33:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:33:42 | INFO | fairseq.tasks.translation | example hypothesis: in the makeen like people, the responsibility for wildlife, grew up the number of wildlife again, and that's a basis for conservation protection in namibia.
2022-03-23 21:33:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:33:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloods of magnetic field, but the susulant alalarm may not move if they need energy, their energy need to disorders, and the sulength of magnetic field.
2022-03-23 21:33:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:33:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can begin with a traditional face, which is the big constructions of the face of the face and reform the information through the whole structure of this reflection, and the whole structure of these reflection, and all the structure of this reflection.
2022-03-23 21:33:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:34:01 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting, interesting and measure for me here at tedwomen is that... you know, "parament, you know, when the best one said to you," the people who have a table for a table, and then we've come up with you, and then we have a long time to support for you, "parallel for you."
2022-03-23 21:34:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:34:03 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention of invention, and a big part of the design work that we're going to use in our airplane was that we had to solve the unique problems in the ground -- all the way to transfer the ground -- and a great part of the invention of the invention of the invention of the invention of the design, and a very large part of the design of the design of the design of the design of the design of the design, or the engine, or the aircraft, or to use it would use it, or to use it to use it.
2022-03-23 21:34:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:34:03 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.684 | ppl 12.85 | bleu 21.23 | wps 3288.5 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.23
2022-03-23 21:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.23) (writing took 0.8624371821060777 seconds)
2022-03-23 21:34:04 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:34:04 | INFO | train | epoch 019 | loss 3.882 | ppl 14.74 | wps 8081.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.02 | loss_scale 4 | train_wall 431 | gb_free 13.4 | wall 9380
2022-03-23 21:34:05 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:35:07 | INFO | train_inner | epoch 020:     22 / 157 loss=3.777, ppl=13.71, wps=7543.2, ups=0.3, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.967, loss_scale=4, train_wall=272, gb_free=14.2, wall=9443
2022-03-23 21:39:48 | INFO | train_inner | epoch 020:    122 / 157 loss=3.658, ppl=12.62, wps=9183, ups=0.36, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.863, loss_scale=4, train_wall=281, gb_free=13.2, wall=9724
2022-03-23 21:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:41:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 21:41:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:41:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you know here.
2022-03-23 21:41:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:41:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golgollocks of dindindindindindindines that create two new pigs.
2022-03-23 21:41:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:41:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are getting salt with salz and pupppet.
2022-03-23 21:41:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:41:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electroelectrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 21:41:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:41:54 | INFO | fairseq.tasks.translation | example hypothesis: in the mainframe, how people had the responsibility for the wild, grew up the number of wild animals again, and this is a foundation for conservation in namibia.
2022-03-23 21:41:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:42:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic fields are caught in the inner inner, but the sulalalalalarm doesn't like it if you're moving your movements, your energy needs, and so the suitalty of magnetic field.
2022-03-23 21:42:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:42:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial that can begin to start with a traditional facial, which is the big constructions of the face and the basic shape of information, and through that information, which is the entire portion, the whole structure, the whole portion, the whole structure, which is folded up and the whole structure.
2022-03-23 21:42:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:42:14 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measuring it interesting to me here in tedwomen is that... "yes, when you were going to be the best dinner, somebody said," hey, someone said to you, "and if you're going to be able to be able to be able to be able to be able to be a table and say," if you're going to be here at tedtedwomen in tedwomen in tedwomen in tedwomen in tedwomen, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 21:42:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:42:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, the invention of invention, and a big part of the design work that we're going to see in our airplane was a result of it that we had to solve the unique problems that were connected to the ground -- everything from the ground, and everything from a continents of a continent, and a big part of the design framework that allows us to use in the aircraft, if you're going to use a mechanism, or a mechanism, if you're going to see the mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it allows us to use of a mechanism, it's a mechanism, or a mechanism, it's a mechanism, it allows us to use of a mechanism, or a mechanism, or a mechanism, it's a mechanism, or a mechanism that's a contract in the current current current current current current
2022-03-23 21:42:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:42:16 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.531 | ppl 11.56 | bleu 23.14 | wps 3091.8 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.14
2022-03-23 21:42:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:42:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:42:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:42:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.14) (writing took 0.8182525453157723 seconds)
2022-03-23 21:42:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:42:17 | INFO | train | epoch 020 | loss 3.654 | ppl 12.59 | wps 8011.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.926 | loss_scale 4 | train_wall 433 | gb_free 13.7 | wall 9873
2022-03-23 21:42:17 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:45:21 | INFO | train_inner | epoch 021:     65 / 157 loss=3.539, ppl=11.62, wps=7481.3, ups=0.3, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.023, loss_scale=4, train_wall=273, gb_free=13.4, wall=10057
2022-03-23 21:49:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:49:35 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheet into the clinic.
2022-03-23 21:49:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:49:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 21:49:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:49:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dindining the two new pigs.
2022-03-23 21:49:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:49:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz and pills.
2022-03-23 21:49:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:49:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 21:49:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:50:05 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people, the responsibility of the wildlife, grew up to the number of wildlife animals. and this is a foundation for conservation in nambia.
2022-03-23 21:50:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:50:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic fields are caught in the inner inner lines, but the susuperconductor may not like it, because your movements need to move, and the superconductor.
2022-03-23 21:50:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:50:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial.
2022-03-23 21:50:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:50:23 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it starts to be very interesting, and if we've started to be here in tedwomen. "
2022-03-23 21:50:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:50:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the ground, and a big part of the design system, is that we're going to be able to do a result of it, which is that we had to solve the unique problems that were connected to the ground -- all of a variation of a variable system, and it allows us to do it.
2022-03-23 21:50:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:50:25 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.419 | ppl 10.7 | bleu 22.09 | wps 3257.4 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.14
2022-03-23 21:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:50:25 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:50:25 | INFO | train | epoch 021 | loss 3.526 | ppl 11.52 | wps 8089.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.952 | loss_scale 4 | train_wall 431 | gb_free 14.3 | wall 10361
2022-03-23 21:50:26 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:50:49 | INFO | train_inner | epoch 022:      8 / 157 loss=3.551, ppl=11.72, wps=7549, ups=0.3, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.945, loss_scale=4, train_wall=271, gb_free=13.4, wall=10385
2022-03-23 21:55:19 | INFO | train_inner | epoch 022:    108 / 157 loss=3.439, ppl=10.85, wps=9132, ups=0.37, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.971, loss_scale=4, train_wall=270, gb_free=13.4, wall=10655
2022-03-23 21:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:57:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 21:57:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:57:50 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline line of doha, probably most of you know here.
2022-03-23 21:57:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:57:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks that are going to be writing two new pigs.
2022-03-23 21:57:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:58:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz.
2022-03-23 21:58:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:58:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on your head and understand exactly what their thoughts are on the track.
2022-03-23 21:58:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:58:12 | INFO | fairseq.tasks.translation | example hypothesis: so in the mammals, people like the responsibility for wildlife, grew up again, and that's a foundation for conservation.
2022-03-23 21:58:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:58:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are caught in the inner, but the superconductor doesn't like it if you're moving, you don't need your energy.
2022-03-23 21:58:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:58:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face, and the basic shape of the face, which is revelations, which is the information that comes through the sound, which is the whole portion of the information that gives it all the portion and the portion.
2022-03-23 21:58:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:58:30 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's very interesting and measuring me here at tedwomen is that... well, you know, you know, you've got a little bit of silent. "
2022-03-23 21:58:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:58:33 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're in the plane was a result that we had to solve the unique problems that were connected to the ground so that it was connected to the ground -- all of us would be able to be able to make a refrigerated, or a refrigerated system, or that if you're going to have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 21:58:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:58:33 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.279 | ppl 9.71 | bleu 23.31 | wps 3359.7 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.31
2022-03-23 21:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 21:58:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 21:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 23.31) (writing took 0.8014494050294161 seconds)
2022-03-23 21:58:34 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 21:58:34 | INFO | train | epoch 022 | loss 3.403 | ppl 10.57 | wps 8088 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.916 | loss_scale 4 | train_wall 431 | gb_free 14 | wall 10850
2022-03-23 21:58:34 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 21:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:00:54 | INFO | train_inner | epoch 023:     51 / 157 loss=3.323, ppl=10.01, wps=7605.3, ups=0.3, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.779, loss_scale=4, train_wall=279, gb_free=13.3, wall=10990
2022-03-23 22:05:31 | INFO | train_inner | epoch 023:    151 / 157 loss=3.174, ppl=9.03, wps=9168.1, ups=0.36, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.867, loss_scale=4, train_wall=277, gb_free=13.3, wall=11267
2022-03-23 22:05:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:05:52 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic.
2022-03-23 22:05:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:05:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 22:05:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:06:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks.
2022-03-23 22:06:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:06:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ptiffer.
2022-03-23 22:06:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:06:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to put some electrodes on his head and understand exactly what all their thoughts are on the track.
2022-03-23 22:06:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:06:21 | INFO | fairseq.tasks.translation | example hypothesis: this is a foundation of conservation in the manamibia.
2022-03-23 22:06:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:06:27 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some blooding magnetic field lines in the inner inner, but the superconductor doesn't like if you move, because your movements need their energy, and so the supermovements of the supermovements.
2022-03-23 22:06:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:06:34 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic basic shape of the face, and through the basic form of information that information, which gives you the whole portion structure and all the portion of this information that we can fold all the portudes of the portion of the portion of this information that we can reform,
2022-03-23 22:06:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:06:42 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting to be here in tedwomen, is that we've already been supported "parkinson," and then, "thank you," thank you, "clash," when someone said, "you said," turn to the men on a table and tell you, "if we'll say," thank you, "thank you."
2022-03-23 22:06:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:06:44 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a big part of the design system that allows us to be able to be able to be able to refrigerate the mechanism, if you can see the unique result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation, everything from a continuous variation, everything, everything from a continuous version of the current system that allows us to refrigerators to be able to be able to be able to be able to be able to be able to be able to refrigergergergergergergergergergergergergergergerated to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to refrigergergergergergergergergergergergergergergergergergergergergergergergerated to be able to be able,
2022-03-23 22:06:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:06:44 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.247 | ppl 9.49 | bleu 24.49 | wps 3158.3 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.49
2022-03-23 22:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:06:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:06:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:06:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.49) (writing took 0.8217481835745275 seconds)
2022-03-23 22:06:45 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:06:45 | INFO | train | epoch 023 | loss 3.223 | ppl 9.33 | wps 8036.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.833 | loss_scale 4 | train_wall 432 | gb_free 14.2 | wall 11341
2022-03-23 22:06:45 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:06:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:11:04 | INFO | train_inner | epoch 024:     94 / 157 loss=3.139, ppl=8.81, wps=7490.8, ups=0.3, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.826, loss_scale=4, train_wall=274, gb_free=13.3, wall=11600
2022-03-23 22:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:14:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:14:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:14:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:14:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:14:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are creating new goldicks that are going to be signed by two new pigs.
2022-03-23 22:14:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:14:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pcase.
2022-03-23 22:14:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:14:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 22:14:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:14:32 | INFO | fairseq.tasks.translation | example hypothesis: in the maceo like the people of responsibility for wildlife, the number of wild animals again, and that's a basis for conservation in namibia.
2022-03-23 22:14:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:14:38 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic fields are caught in the inner, but the superconductor doesn't like you moving, because your movements need, and so the superconductor.
2022-03-23 22:14:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:14:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that's coming from this reflection, we can start with a traditional facial, the grows of the face and the basic form, and through the diethief of information that pulls all the pores and all the components.
2022-03-23 22:14:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:14:50 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and measured for me here at tedwomen, is that... tja, it's the best dinner, when someone said, "wasting you to the men in a table and say," if the revolution starts to help you.
2022-03-23 22:14:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:14:52 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're at our plane, was a result of that we had to solve the unique problems that were connected to operate -- everything from a continually variable system that allows us to be able to see if you're going to be able to be able to use the power of an aircraft, or the market, if you're going to be able to be able to be able to be able to be able to be able to see that you're able to be able to be able to be able to restore the traject the traject the tral, if you're going to be able to be able to be able to operate, or the trait's an aircraft, or the market market market, if you're able to be able to be able to be able to make the tral, or the tral, or the market market market market, or the trajectory of the tral, if you've got to see
2022-03-23 22:14:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:14:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.042 | ppl 8.24 | bleu 26.19 | wps 3363.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.19
2022-03-23 22:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:14:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.19) (writing took 0.8400317151099443 seconds)
2022-03-23 22:14:53 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:14:53 | INFO | train | epoch 024 | loss 3.111 | ppl 8.64 | wps 8090.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.806 | loss_scale 4 | train_wall 432 | gb_free 13.9 | wall 11829
2022-03-23 22:14:53 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:16:39 | INFO | train_inner | epoch 025:     37 / 157 loss=3.01, ppl=8.06, wps=7606, ups=0.3, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.781, loss_scale=4, train_wall=279, gb_free=13.5, wall=11935
2022-03-23 22:21:12 | INFO | train_inner | epoch 025:    137 / 157 loss=3.054, ppl=8.3, wps=9159.9, ups=0.37, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.85, loss_scale=4, train_wall=273, gb_free=13.4, wall=12209
2022-03-23 22:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:22:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:22:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:22:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 22:22:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:22:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to transcript two new pigs.
2022-03-23 22:22:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:22:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and pcase.
2022-03-23 22:22:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:22:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:22:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:22:40 | INFO | fairseq.tasks.translation | example hypothesis: this is how people took responsibility for wildlife, the number of wildlife animals grew back. and this is a basis for conservation in namibia.
2022-03-23 22:22:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:22:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some pulls of magnetic fields are caught in the inner inner, but the superconductor doesn't like you move because your energy is required, and so the superconductor disorder.
2022-03-23 22:22:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:22:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face and the basic shape of information that pulls all the pores.
2022-03-23 22:22:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:22:57 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that we do it very interesting and measured for me is that... tja, it was best summarized as someone said, "turn you to your men in your desk and tell them," if the revolution starts, "we love that story for you."
2022-03-23 22:22:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:22:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're on the edge was a result that we had to solve the unique problems that were connected to operating it -- everything from a continually variable system and cooling the aircraft, or if you can see the aircraft, either if you're able to see the engine, or the engine, if you're going to be able to go to the aircraft.
2022-03-23 22:22:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:22:58 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.048 | ppl 8.27 | bleu 24.28 | wps 3532.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.19
2022-03-23 22:22:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:22:58 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:22:58 | INFO | train | epoch 025 | loss 3.009 | ppl 8.05 | wps 8142.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.822 | loss_scale 4 | train_wall 432 | gb_free 14.2 | wall 12314
2022-03-23 22:22:58 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:26:45 | INFO | train_inner | epoch 026:     80 / 157 loss=2.899, ppl=7.46, wps=7641.4, ups=0.3, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.774, loss_scale=4, train_wall=280, gb_free=13.5, wall=12541
2022-03-23 22:30:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:30:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepans in the clinic.
2022-03-23 22:30:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:30:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 22:30:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:30:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 22:30:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:30:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pitcase.
2022-03-23 22:30:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:30:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 22:30:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:30:47 | INFO | fairseq.tasks.translation | example hypothesis: this is how people took responsibility for wildlife, the number of wildlife animals grew up again, and that's a foundation for conservation.
2022-03-23 22:30:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:30:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic fields are caught in the inner, but the superconductor doesn't like it if they're moving, because their movements need energy, and so the superconductor disorder.
2022-03-23 22:30:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:30:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which is the great constructures of the face and the basic shape, and it restores it through the theft of information that refits all the porn structure and fold it up.
2022-03-23 22:30:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:31:06 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it was very interesting and appropriate for me here at tedwomen, is that -- tn, it was best summarized when someone said, "turning you on your men on your table, and tell them," if the revolution starts to support you, we're going to support you, "the truth is that we've already been supported for you, we've already started to support you've been working on this topic, and then we've already started to support you've been working with" — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — thank you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-23 22:31:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:31:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variety system, and a refrigerator system that allows us to do in the aircraft, that we're going to use it to become a refrigergerator machine, or a trajectory machine that will be used to operate in the interior of a system that is that can actually drive, if you can actually drive it will be used to operate in the interior ior ior of a system, if you can actually drive the market, if you had to be used to be used to be used to be in the market, if you had to be used to be used to be connected to be in the market, if you had to be used to be in the market, if you had to be used to be used to be used to be connected to be used to be used to be
2022-03-23 22:31:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:31:08 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.834 | ppl 7.13 | bleu 28.23 | wps 3254.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.23
2022-03-23 22:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:31:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:31:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.23) (writing took 0.8118887110613286 seconds)
2022-03-23 22:31:09 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:31:09 | INFO | train | epoch 026 | loss 2.898 | ppl 7.45 | wps 8044.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.805 | loss_scale 4 | train_wall 433 | gb_free 13.8 | wall 12805
2022-03-23 22:31:09 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:31:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:32:16 | INFO | train_inner | epoch 027:     23 / 157 loss=2.823, ppl=7.08, wps=7545.7, ups=0.3, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.776, loss_scale=4, train_wall=273, gb_free=14.3, wall=12872
2022-03-23 22:36:52 | INFO | train_inner | epoch 027:    123 / 157 loss=2.821, ppl=7.07, wps=9089.4, ups=0.36, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.785, loss_scale=4, train_wall=275, gb_free=13.1, wall=13148
2022-03-23 22:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:38:29 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:38:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:38:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably knows most here.
2022-03-23 22:38:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:38:40 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will write two new pigs.
2022-03-23 22:38:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:38:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pffer.
2022-03-23 22:38:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:38:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what's all his thoughts on the track.
2022-03-23 22:38:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:38:58 | INFO | fairseq.tasks.translation | example hypothesis: in the case, as people took responsibility for wildlife, the number of wildwildwildwildanimals grew again, and that's a foundation for conservation in namibia.
2022-03-23 22:38:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:39:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught in inner, but the superconductor doesn't like it if you're moving, because your energy is using, and so the supralty disorder.
2022-03-23 22:39:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:39:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which refits the groves constructures of the face and the basic shape of the face and restores it through themes of information that draws all the porter structure and all fold a fold.
2022-03-23 22:39:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:39:15 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... tja, it was best summarized when someone said, "wade you on your table and tell you," if the revolution starts to support you. "the truth is women, we've already been supporting you."
2022-03-23 22:39:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:39:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to operate the unique problems that were connected to the ground -- everything from a continuous system that allows us to refrigerate an aircraft, that allows us to use a trajectory machine, or the propellers to operate the web, or whatever you can see.
2022-03-23 22:39:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:39:16 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.754 | ppl 6.74 | bleu 27.95 | wps 3454.6 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.23
2022-03-23 22:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:39:16 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:39:16 | INFO | train | epoch 027 | loss 2.768 | ppl 6.81 | wps 8101.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.745 | loss_scale 4 | train_wall 434 | gb_free 13.5 | wall 13293
2022-03-23 22:39:17 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:42:19 | INFO | train_inner | epoch 028:     66 / 157 loss=2.702, ppl=6.51, wps=7591.2, ups=0.3, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.765, loss_scale=4, train_wall=274, gb_free=14.2, wall=13476
2022-03-23 22:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:46:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:46:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:46:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 22:46:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:46:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to cross two new pigs.
2022-03-23 22:46:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:46:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pcase.
2022-03-23 22:46:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:46:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 22:46:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:47:05 | INFO | fairseq.tasks.translation | example hypothesis: in the case of the human responsibility for wildlife, the number of wildlife animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 22:47:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:47:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some pulls of magnetic field lines in the inside, but the superconductor doesn't like it if they move because they use their energy, and so the superconducting disorder.
2022-03-23 22:47:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:47:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which is the grove constructures of the face and the basic form, and it restores the diedieone information that puts all the porter structure and all the wrinkles.
2022-03-23 22:47:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:47:24 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and appropriate to me here at tedwomen, is that, if the revolution starts to be here at tedwomen, we've already been supported with a long time when someone said, "turn you to men on your table, and say," if the revolution starts, we're supporting you. "the truth is that we've already been supporting you, we've already been supporting you in this topic."
2022-03-23 22:47:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:47:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is the most proud test, was a result that we had to solve the unique problems that were connected to operating it on the ground -- all of a continually variable drive, and a cooling system that allows us to be able to use in the aircraft or a cooler system, if you're either, you're able to use it to use it to use it to use it, or to be able to make it, if you're able to use it in a specific, you're either.
2022-03-23 22:47:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:47:27 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.677 | ppl 6.4 | bleu 28.74 | wps 3250.2 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.74
2022-03-23 22:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:47:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:47:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.74) (writing took 0.8042333037592471 seconds)
2022-03-23 22:47:27 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:47:27 | INFO | train | epoch 028 | loss 2.701 | ppl 6.5 | wps 8044.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.802 | loss_scale 4 | train_wall 433 | gb_free 13.3 | wall 13783
2022-03-23 22:47:28 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:47:52 | INFO | train_inner | epoch 029:      9 / 157 loss=2.732, ppl=6.64, wps=7567.9, ups=0.3, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.84, loss_scale=4, train_wall=275, gb_free=13.2, wall=13808
2022-03-23 22:52:27 | INFO | train_inner | epoch 029:    109 / 157 loss=2.59, ppl=6.02, wps=9136.7, ups=0.36, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.763, loss_scale=4, train_wall=275, gb_free=13.1, wall=14084
2022-03-23 22:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:54:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:54:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:54:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 22:54:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:54:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcend two new pigs.
2022-03-23 22:54:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:55:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salz and ppeffer.
2022-03-23 22:55:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:55:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:55:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:55:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, like the people responsibility for wildlife survival, they grew up again, and that's become a basis for conservation in namibia.
2022-03-23 22:55:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:55:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are captured in the inner, but the superconductor doesn't like it if they move, because they use their movements, and so the superconduction.
2022-03-23 22:55:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:55:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial able that gives the big constructions of the face and the fundamental form, and through this information that refers all the porter structure, and all the folds a fold.
2022-03-23 22:55:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:55:34 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it was very interesting and appropriate for me to be here at tedwomen, is that... tja, when tested dinner became summarized at best when someone said, "turn you to men on your desk and tell you," if the revolution starts, we support you. "
2022-03-23 22:55:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:55:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous varieties and cooling system that allows us to use a flight, or a mechanism, or a mechanism, if you can use the market, or a mechanism, or a mechanism, or a chain of propeller, or a mechanism, or a system, or a chain of propeller, until you can either.
2022-03-23 22:55:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:55:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.612 | ppl 6.11 | bleu 28.91 | wps 3242.5 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.91
2022-03-23 22:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 22:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 22:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 28.91) (writing took 0.8066458678804338 seconds)
2022-03-23 22:55:37 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 22:55:37 | INFO | train | epoch 029 | loss 2.582 | ppl 5.99 | wps 8070.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.769 | loss_scale 4 | train_wall 432 | gb_free 12.9 | wall 14273
2022-03-23 22:55:37 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 22:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:58:00 | INFO | train_inner | epoch 030:     52 / 157 loss=2.535, ppl=5.79, wps=7548.1, ups=0.3, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.749, loss_scale=4, train_wall=275, gb_free=13.5, wall=14416
2022-03-23 23:02:36 | INFO | train_inner | epoch 030:    152 / 157 loss=2.452, ppl=5.47, wps=9177.7, ups=0.36, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.732, loss_scale=4, train_wall=276, gb_free=14.3, wall=14692
2022-03-23 23:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:02:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers on the clinic.
2022-03-23 23:02:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:03:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-23 23:03:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:03:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcend two new pigs.
2022-03-23 23:03:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:03:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pepper.
2022-03-23 23:03:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:03:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his minds are on the track.
2022-03-23 23:03:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:03:24 | INFO | fairseq.tasks.translation | example hypothesis: so in the sense of how people were taking responsibility for wildlife, the number of wildlife animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 23:03:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:03:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the superconductor may not like it if they move, because their movements use, and the superconducting disorder.
2022-03-23 23:03:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:03:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that refuses the big constructures of the face and the basic form of information that pulls the whole porter structure and all folds.
2022-03-23 23:03:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:03:42 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tja, when dinner was summarized, it became best summarized when someone said, "turn you to men on your table and say," if the revolution starts to support you for a long time. "
2022-03-23 23:03:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:03:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our aircraft is a result that we had to solve the unique problems that were connected to operate in the ground -- everything that allows us to use a continuously variable device to the aircraft, to a specific device, if you can either see the propelled by the propelled to a particular gps, or the machine.
2022-03-23 23:03:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:03:44 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.538 | ppl 5.81 | bleu 29.34 | wps 3333.2 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.34
2022-03-23 23:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:03:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.34) (writing took 0.7990209967829287 seconds)
2022-03-23 23:03:45 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:03:45 | INFO | train | epoch 030 | loss 2.466 | ppl 5.53 | wps 8092.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.74 | loss_scale 4 | train_wall 432 | gb_free 12.9 | wall 14761
2022-03-23 23:03:45 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:08:11 | INFO | train_inner | epoch 031:     95 / 157 loss=2.406, ppl=5.3, wps=7606.5, ups=0.3, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.77, loss_scale=4, train_wall=280, gb_free=13.1, wall=15027
2022-03-23 23:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:11:02 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 23:11:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:11:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably most of you know here.
2022-03-23 23:11:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:11:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcend two new pigs.
2022-03-23 23:11:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:11:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pffer.
2022-03-23 23:11:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:11:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:11:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:11:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 23:11:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:11:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconduction disrupts.
2022-03-23 23:11:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:11:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial able that refuses the big constraints of the face and restore it through the very basic information that pulls the whole porn structure and all the wrinkles.
2022-03-23 23:11:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:11:51 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's been very interesting and appropriate for me to be here at tedwomen is that... tja, when he stripped dinner, it became best summarized when someone said, "turn you to men on your table and say," if the revolution begins, then we support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 23:11:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:11:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is the most proud toe, a result of solving the unique problems that were connected to operate it on the ground -- everything, from a continual variable and cooling system that allows us to use aircraft, to a traffic, and to a very frigergergergergergergerator, to a particular cycle, or if you're going to be able to do it.
2022-03-23 23:11:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:11:53 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.469 | ppl 5.54 | bleu 29.95 | wps 3248.7 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 29.95
2022-03-23 23:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:11:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:11:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 29.95) (writing took 0.822145126760006 seconds)
2022-03-23 23:11:53 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:11:53 | INFO | train | epoch 031 | loss 2.395 | ppl 5.26 | wps 8079 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.784 | loss_scale 4 | train_wall 431 | gb_free 12.9 | wall 15250
2022-03-23 23:11:54 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:13:40 | INFO | train_inner | epoch 032:     38 / 157 loss=2.315, ppl=4.97, wps=7581.5, ups=0.3, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.77, loss_scale=4, train_wall=271, gb_free=13.9, wall=15356
2022-03-23 23:18:17 | INFO | train_inner | epoch 032:    138 / 157 loss=2.338, ppl=5.06, wps=9106.6, ups=0.36, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.901, loss_scale=4, train_wall=277, gb_free=13.9, wall=15634
2022-03-23 23:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:19:12 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:19:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:19:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you.
2022-03-23 23:19:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:19:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 23:19:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:19:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salce and pffer.
2022-03-23 23:19:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:19:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:19:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:19:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans's responsibility for wildlife, the number of wildlife animals grew back. and this has become a foundation for conservation in namibia.
2022-03-23 23:19:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:19:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught in the inner, but the superconductor doesn't like it, if you move, because your movements use, and so the superconductation.
2022-03-23 23:19:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:19:52 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can begin with a traditional facial can, which refuses the big constraints of the face, and reproduce the basic shape, and puts it through the one information that pulls all the porter structure and all the fits.
2022-03-23 23:19:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:19:58 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tja, when he stripped dinner was best, when someone said, "turn you to men on your desk and tell them, 'when the revolution starts, we support you.' '" the truth, love is that we've already started with you with a long term of grapie and charcoal. "
2022-03-23 23:19:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:20:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to it -- everything, from a continual variable system and refrigeration system, that allows us to use aircraft in traffic, to a specific wheelchair, or aggressive machine, to a promoter, to a propulsion, or a promoter, to a promoter, to a propulsion, to a propulsion machine, or a promoter, to a propulsion machine, to a promoter, to a promoter, to the field, to a promoter, to a promoter, to a promoter.
2022-03-23 23:20:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:20:01 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.418 | ppl 5.35 | bleu 29.43 | wps 3338.3 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 29.95
2022-03-23 23:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:20:01 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:20:01 | INFO | train | epoch 032 | loss 2.31 | ppl 4.96 | wps 8105.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.844 | loss_scale 4 | train_wall 432 | gb_free 14 | wall 15737
2022-03-23 23:20:02 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:23:47 | INFO | train_inner | epoch 033:     81 / 157 loss=2.188, ppl=4.56, wps=7617.3, ups=0.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.846, loss_scale=4, train_wall=273, gb_free=13.6, wall=15963
2022-03-23 23:27:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:27:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieptinas in the clinic.
2022-03-23 23:27:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:27:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-23 23:27:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:27:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 23:27:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:27:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and ppeffer.
2022-03-23 23:27:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:27:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:27:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:27:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people were responsible for wildlife, the number of wildlife animals grew up again, and that has become a foundation for conservation in namibia.
2022-03-23 23:27:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:27:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of strands of magnetic field are trapped in the inner, but the superconductor doesn't like it if you move, because your movements use, and so the superconducalty disorder.
2022-03-23 23:27:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:28:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face bar that refers the big configurations of the face and the basic shape, and through the diethest information, which is the whole porter structure and all the fine fold.
2022-03-23 23:28:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:28:08 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that, when strikes dinner, it was best summarized at the best, when someone said, "turn you to men's desk and tell them," if the revolution starts, then we support you. "the truth is that we've already been supporting you," well, "well, we're going to have been working on a long time," parkinson's "and then we're going to put it together."
2022-03-23 23:28:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:28:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane is the most staggering, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continual variables and cooling system that allows us to use aircraft in the aircraft, to a particular way that is propelled to be solved, or if you can see that's going to be propelled in the air conditioning the ground, it's going on the air conditioning, it's going on the air conditioning, it's going on the air conditioning, it's going on the air conditioning system, the air conditioning, it's going on the air conditioning system, and cooling, it's going to make it's going to make it's going to make it be solved, to make it happen.
2022-03-23 23:28:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:28:10 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.347 | ppl 5.09 | bleu 30.68 | wps 3254 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 30.68
2022-03-23 23:28:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:28:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:28:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt
2022-03-23 23:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.95_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 30.68) (writing took 0.8772479663603008 seconds)
2022-03-23 23:28:11 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:28:11 | INFO | train | epoch 033 | loss 2.225 | ppl 4.67 | wps 8050.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.849 | loss_scale 4 | train_wall 431 | gb_free 13.5 | wall 16227
2022-03-23 23:28:12 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:29:21 | INFO | train_inner | epoch 034:     24 / 157 loss=2.247, ppl=4.75, wps=7528.7, ups=0.3, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.837, loss_scale=4, train_wall=276, gb_free=13.4, wall=16297
2022-03-23 23:33:56 | INFO | train_inner | epoch 034:    124 / 157 loss=2.116, ppl=4.33, wps=9122.2, ups=0.36, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.901, loss_scale=4, train_wall=275, gb_free=13.2, wall=16572
2022-03-23 23:35:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:35:31 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieces in the clinic.
2022-03-23 23:35:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:35:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-23 23:35:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:35:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 23:35:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:35:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salt and ppeffer.
2022-03-23 23:35:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:35:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 23:35:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:36:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife survival, the number of wildlife animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 23:36:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:36:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured in the inside, but the superconductor doesn't like it, if they move, they use their movements, and so the superconducting disorder.
2022-03-23 23:36:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:36:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face bar, which will restore the big contextures of the face and the basic shape, and then embrace it through the diethief of this reflection that pulls the whole porter structure and all the wrinkles.
2022-03-23 23:36:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:36:18 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it very interesting and measured to me here at tedwomen, is that, well, when strikes dinner, it became best summarized when someone said, "turn you to men in your desk and tell them," if the revolution starts to support you, then we support you. '"the truth, love is that we've already supported for a long time for a long time."
2022-03-23 23:36:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:36:21 | INFO | fairseq.tasks.translation | example hypothesis: , luckily, the mother of invention, and a large part of the design work that we're on our plane are the stumes, was a result that we had to solve the unique problems that were connected to operate on the ground -- all of us, from a continuous variables and a cooling system that allows us to use an aircraft in the goand to use a regret to a particular traffic, to a particular, to a particular, and to a particular eventually, if you can see the most compelling system, to the most compiling, to the propheating system, it's not to the mourishing system, to the propulsive, to the rations that we can either be able to see if you'll be able to see the harm, to see the rage, to see the harmful, to see the most compiling the harmful, to see the harm, to be able to be able to see the rage.
2022-03-23 23:36:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:36:21 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.311 | ppl 4.96 | bleu 30.35 | wps 3275.5 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 30.68
2022-03-23 23:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:36:21 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:36:21 | INFO | train | epoch 034 | loss 2.146 | ppl 4.43 | wps 8067.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.925 | loss_scale 4 | train_wall 433 | gb_free 13.2 | wall 16717
2022-03-23 23:36:21 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:39:25 | INFO | train_inner | epoch 035:     67 / 157 loss=2.167, ppl=4.49, wps=7633.6, ups=0.3, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=1.026, loss_scale=4, train_wall=273, gb_free=14.2, wall=16901
2022-03-23 23:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:43:35 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:43:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:43:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 23:43:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:43:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of india that are going to translate two fresh pigs.
2022-03-23 23:43:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:43:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog's legs are served with salt and pffer.
2022-03-23 23:43:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:43:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:43:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:44:04 | INFO | fairseq.tasks.translation | example hypothesis: in this case, like the people of responsibility for wildlife took, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 23:44:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:44:10 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are caught in the inside, but the superconductor doesn't like it if they move, because they use their movements, and so the superconducting disorder.
2022-03-23 23:44:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:44:16 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional face that restores the big contextures of the face and the basic form, and then picks it through the diethest information that draws the whole porn structure and all the fffits.
2022-03-23 23:44:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:44:22 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it be very interesting and appropriate to me here at tedwomen is that, when dinner was sucked it up best, when someone said, "turn you to men on your table and tell them," if the revolution starts, we support you. "the truth, love is that we've already been supporting you for a long time."
2022-03-23 23:44:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:44:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on our airplane on the most proud test, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous version of rivers and cooling system that allows us to use an aircraft machine in traffic to a special cycle, or if you're going to be able to use the propelled by a mechanism, all the way.
2022-03-23 23:44:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:44:24 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.212 | ppl 4.63 | bleu 30.67 | wps 3342.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 30.68
2022-03-23 23:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:44:24 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:44:24 | INFO | train | epoch 035 | loss 2.063 | ppl 4.18 | wps 8171.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.946 | loss_scale 4 | train_wall 428 | gb_free 12.9 | wall 17200
2022-03-23 23:44:24 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:44:51 | INFO | train_inner | epoch 036:     10 / 157 loss=2.01, ppl=4.03, wps=7655.5, ups=0.31, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.9, loss_scale=4, train_wall=270, gb_free=14.2, wall=17227
2022-03-23 23:49:25 | INFO | train_inner | epoch 036:    110 / 157 loss=1.957, ppl=3.88, wps=9220.1, ups=0.36, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.959, loss_scale=4, train_wall=274, gb_free=14.2, wall=17501
2022-03-23 23:51:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:51:37 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:51:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:51:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 23:51:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:51:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 23:51:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:51:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and ppeffer.
2022-03-23 23:51:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:52:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what's all his thoughts on the track.
2022-03-23 23:52:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:52:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the human responsibility for wildlife, the number of wildlife animals grew up again, and that has become a foundation for conservation in namibia.
2022-03-23 23:52:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:52:12 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured in the inner, but the superconductor doesn't like it if they move, because they use their movements, and so the superconduction.
2022-03-23 23:52:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:52:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which restores the big constraints of the face and the basic shape, and then restores it through that single piece of information that pulls the entire porter structure, and all the stamps is folding.
2022-03-23 23:52:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:52:25 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it really interesting and measured for me is that, if the revolution begins to be here at tedwomen, is that -- tja, when checked dinner, it was best summarized, when someone said, "turn you to your desk, and tell you, ''" if the revolution starts, we support you. '"'" '"the truth is that we've already supported you for a long time, it's a grain of grain of sand is best,"
2022-03-23 23:52:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:52:27 | INFO | fairseq.tasks.translation | example hypothesis: , luckily, it's still the mother of invention, and a large part of the design work that we're on our airplane is the most staggering, it was a product that we had to solve the unique problems that were connected to it -- all, from a continuous varieties, and a cooling system that allows us to use an aircraft machine in traffic, to a special, or if you're aggressive, or if you're at the same, it's a gas gas gas gas gas gas gas gas gas gas gas, or the same, it's till you're going to be connected to the same, it's till you're going to the same, it's going to the wheel.
2022-03-23 23:52:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:52:27 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.19 | ppl 4.56 | bleu 30.18 | wps 3310.8 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 30.68
2022-03-23 23:52:27 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 23:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:52:27 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:52:27 | INFO | train | epoch 036 | loss 1.972 | ppl 3.92 | wps 8178.7 | ups 0.33 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 1.027 | loss_scale 4 | train_wall 427 | gb_free 13.4 | wall 17683
2022-03-23 23:52:27 | INFO | fairseq_cli.train | done training in 17682.6 seconds
