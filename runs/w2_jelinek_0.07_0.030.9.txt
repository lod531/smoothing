Sender: LSF System <lsfadmin@eu-g3-027>
Subject: Job 202286051: <w2_jelinek_00.07_0.03_0.9> in cluster <euler> Exited

Job <w2_jelinek_00.07_0.03_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 06:52:28 2022
Job was executed on host(s) <eu-g3-027>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 06:52:48 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 06:52:48 2022
Terminated at Sat Jan 29 02:53:04 2022
Results reported at Sat Jan 29 02:53:04 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.07, 0.03, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71983.00 sec.
    Max Memory :                                 5873 MB
    Average Memory :                             3071.79 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14127.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72015 sec.
    Turnaround time :                            72036 sec.

The output (if any) follows:

2022-01-28 06:52:57 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.07, 0.03, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 06:52:57 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 06:52:58 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1099/36718 [00:00<00:03, 10977.58it/s]  6%|▌         | 2197/36718 [00:00<00:03, 10186.75it/s]  9%|▉         | 3425/36718 [00:00<00:03, 11097.40it/s] 13%|█▎        | 4658/36718 [00:00<00:02, 11564.35it/s] 16%|█▌        | 5960/36718 [00:00<00:02, 12069.04it/s] 20%|█▉        | 7171/36718 [00:00<00:02, 11248.98it/s] 23%|██▎       | 8308/36718 [00:00<00:02, 11214.70it/s] 26%|██▌       | 9438/36718 [00:00<00:02, 11212.87it/s] 29%|██▉       | 10565/36718 [00:00<00:02, 11090.40it/s] 32%|███▏      | 11678/36718 [00:01<00:02, 10980.09it/s] 35%|███▍      | 12838/36718 [00:01<00:02, 11163.85it/s] 38%|███▊      | 14014/36718 [00:01<00:02, 11341.25it/s] 41%|████▏     | 15231/36718 [00:01<00:01, 11585.30it/s] 45%|████▍     | 16392/36718 [00:01<00:01, 11016.90it/s] 48%|████▊     | 17525/36718 [00:01<00:01, 11106.63it/s] 51%|█████     | 18641/36718 [00:01<00:01, 11041.38it/s] 54%|█████▍    | 19935/36718 [00:01<00:01, 11596.00it/s] 57%|█████▋    | 21099/36718 [00:01<00:01, 11334.23it/s] 61%|██████    | 22237/36718 [00:01<00:01, 11165.05it/s] 64%|██████▍   | 23427/36718 [00:02<00:01, 11370.31it/s] 68%|██████▊   | 24808/36718 [00:02<00:00, 12081.10it/s] 71%|███████   | 26020/36718 [00:02<00:00, 11838.12it/s] 74%|███████▍  | 27207/36718 [00:02<00:00, 11163.44it/s] 77%|███████▋  | 28366/36718 [00:02<00:00, 11283.25it/s] 80%|████████  | 29502/36718 [00:02<00:00, 11224.18it/s] 83%|████████▎ | 30630/36718 [00:02<00:00, 11078.27it/s] 86%|████████▋ | 31757/36718 [00:02<00:00, 11130.48it/s] 90%|████████▉ | 32873/36718 [00:02<00:00, 10814.77it/s] 92%|█████████▏| 33958/36718 [00:03<00:00, 10768.91it/s] 96%|█████████▌| 35095/36718 [00:03<00:00, 10936.29it/s] 99%|█████████▊| 36216/36718 [00:03<00:00, 11011.97it/s]100%|██████████| 36718/36718 [00:03<00:00, 11212.03it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 2016/36718 [00:00<00:01, 20158.53it/s] 12%|█▏        | 4272/36718 [00:00<00:01, 21563.87it/s] 18%|█▊        | 6498/36718 [00:00<00:01, 21863.27it/s] 24%|██▎       | 8685/36718 [00:00<00:01, 21306.42it/s] 29%|██▉       | 10818/36718 [00:00<00:01, 21165.60it/s] 35%|███▌      | 12936/36718 [00:00<00:01, 21103.30it/s] 41%|████▏     | 15185/36718 [00:00<00:00, 21550.29it/s] 47%|████▋     | 17342/36718 [00:00<00:00, 21037.39it/s] 53%|█████▎    | 19616/36718 [00:00<00:00, 21549.84it/s] 59%|█████▉    | 21775/36718 [00:01<00:00, 21013.10it/s] 66%|██████▌   | 24110/36718 [00:01<00:00, 21704.28it/s] 72%|███████▏  | 26302/36718 [00:01<00:00, 21765.37it/s] 78%|███████▊  | 28483/36718 [00:01<00:00, 21399.42it/s] 83%|████████▎ | 30627/36718 [00:01<00:00, 21085.54it/s] 89%|████████▉ | 32739/36718 [00:01<00:00, 20783.41it/s] 95%|█████████▍| 34881/36718 [00:01<00:00, 20966.02it/s]100%|██████████| 36718/36718 [00:01<00:00, 21177.85it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.76it/s]2022-01-28 06:53:12 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 06:53:12 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 06:53:12 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 06:53:12 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 06:53:12 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 06:53:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 06:53:12 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 06:53:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 06:53:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 06:53:12 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-01-28 06:53:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 06:53:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 06:53:12 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 06:53:12 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint_last.pt
2022-01-28 06:53:12 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint_last.pt
2022-01-28 06:53:12 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 06:53:12 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 06:53:12 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 06:53:12 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 06:53:12 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 06:58:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 06:59:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.572 | ppl 24349.6 | wps 7626.9 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 06:59:21 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 06:59:21 | INFO | train | epoch 001 | loss 16.06 | ppl 68298.4 | wps 5719.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.344 | train_wall 335 | gb_free 6.1 | wall 368
KL Stats: Epoch 1 Divergences: Uniform: 0.5175159612444841 Unigram: 3.6848140647556322
2022-01-28 06:59:21 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 06:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:02:31 | INFO | train_inner | epoch 002:     36 / 64 loss=15.501, ppl=46362.9, wps=5891.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.741, train_wall=524, gb_free=6.1, wall=558
2022-01-28 07:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:05:26 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.538 | ppl 11890.9 | wps 7636.5 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:05:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:05:26 | INFO | train | epoch 002 | loss 14.291 | ppl 20042.5 | wps 5726.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.548 | train_wall 334 | gb_free 6.1 | wall 733
KL Stats: Epoch 2 Divergences: Uniform: 0.5377482534566034 Unigram: 2.4133455832693453
2022-01-28 07:05:26 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:11:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:11:31 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.688 | ppl 6599.09 | wps 7687.5 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:11:31 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:11:31 | INFO | train | epoch 003 | loss 13.356 | ppl 10484 | wps 5720.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.249 | train_wall 335 | gb_free 6.1 | wall 1098
KL Stats: Epoch 3 Divergences: Uniform: 0.5281791748918008 Unigram: 1.7270944351838844
2022-01-28 07:11:31 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:12:13 | INFO | train_inner | epoch 004:      8 / 64 loss=13.494, ppl=11533.6, wps=5597.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.279, train_wall=523, gb_free=6.1, wall=1140
2022-01-28 07:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:17:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.806 | ppl 3580.29 | wps 7666.8 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 07:17:35 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 07:17:35 | INFO | train | epoch 004 | loss 12.378 | ppl 5322.52 | wps 5736.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.998 | train_wall 334 | gb_free 6.1 | wall 1462
KL Stats: Epoch 4 Divergences: Uniform: 0.620036702128553 Unigram: 1.102516510753276
2022-01-28 07:17:35 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 07:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:21:26 | INFO | train_inner | epoch 005:     44 / 64 loss=12.014, ppl=4136.05, wps=5903.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.875, train_wall=522, gb_free=6.1, wall=1694
2022-01-28 07:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:23:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.267 | ppl 2463.54 | wps 7660.3 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 07:23:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 07:23:39 | INFO | train | epoch 005 | loss 11.547 | ppl 2991.23 | wps 5733.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.708 | train_wall 334 | gb_free 6.1 | wall 1827
KL Stats: Epoch 5 Divergences: Uniform: 0.8790521959807679 Unigram: 0.6386331936755394
2022-01-28 07:23:39 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 07:23:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:29:43 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.017 | ppl 2072.63 | wps 7666.4 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 07:29:43 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 07:29:43 | INFO | train | epoch 006 | loss 11.094 | ppl 2186.57 | wps 5734.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.595 | train_wall 334 | gb_free 6.1 | wall 2191
KL Stats: Epoch 6 Divergences: Uniform: 1.2073179179702502 Unigram: 0.42404978485886274
2022-01-28 07:29:43 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 07:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:31:08 | INFO | train_inner | epoch 007:     16 / 64 loss=11.118, ppl=2222.73, wps=5608.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.594, train_wall=522, gb_free=6.1, wall=2275
2022-01-28 07:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:35:48 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.878 | ppl 1881.92 | wps 7684 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 07:35:48 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 07:35:48 | INFO | train | epoch 007 | loss 10.886 | ppl 1892.89 | wps 5734.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.527 | train_wall 334 | gb_free 6.1 | wall 2555
KL Stats: Epoch 7 Divergences: Uniform: 1.467402046858021 Unigram: 0.42041872799581703
2022-01-28 07:35:48 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 07:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:40:22 | INFO | train_inner | epoch 008:     52 / 64 loss=10.825, ppl=1813.87, wps=5898.3, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.519, train_wall=523, gb_free=6.1, wall=2829
2022-01-28 07:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:41:52 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.778 | ppl 1756.32 | wps 7658.9 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 07:41:52 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 07:41:52 | INFO | train | epoch 008 | loss 10.774 | ppl 1750.45 | wps 5725.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.514 | train_wall 335 | gb_free 6.1 | wall 2920
KL Stats: Epoch 8 Divergences: Uniform: 1.61192371387033 Unigram: 0.4802935741183708
2022-01-28 07:41:52 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 07:41:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:47:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:47:57 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.665 | ppl 1623.77 | wps 7682.6 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 07:47:57 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 07:47:57 | INFO | train | epoch 009 | loss 10.672 | ppl 1631.17 | wps 5726.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.487 | train_wall 335 | gb_free 6.1 | wall 3285
KL Stats: Epoch 9 Divergences: Uniform: 1.675592428305601 Unigram: 0.5630433045648439
2022-01-28 07:47:57 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 07:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:50:03 | INFO | train_inner | epoch 010:     24 / 64 loss=10.663, ppl=1621.37, wps=5605.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.49, train_wall=522, gb_free=6.1, wall=3411
2022-01-28 07:53:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:54:01 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.564 | ppl 1513.75 | wps 7635.1 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 07:54:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 07:54:01 | INFO | train | epoch 010 | loss 10.567 | ppl 1516.71 | wps 5731.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 334 | gb_free 6.1 | wall 3649
KL Stats: Epoch 10 Divergences: Uniform: 1.7106471377058237 Unigram: 0.6537441173977604
2022-01-28 07:54:01 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 07:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:59:18 | INFO | train_inner | epoch 011:     60 / 64 loss=10.493, ppl=1441.28, wps=5892.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=523, gb_free=6.1, wall=3966
2022-01-28 07:59:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:00:06 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.459 | ppl 1407.31 | wps 7681.1 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 08:00:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 08:00:06 | INFO | train | epoch 011 | loss 10.455 | ppl 1403.35 | wps 5727 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.501 | train_wall 335 | gb_free 6.1 | wall 4014
KL Stats: Epoch 11 Divergences: Uniform: 1.7340435218768706 Unigram: 0.7430741397000079
2022-01-28 08:00:06 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 08:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:06:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.353 | ppl 1308.3 | wps 7660.8 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 08:06:10 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 08:06:10 | INFO | train | epoch 012 | loss 10.34 | ppl 1296.26 | wps 5736.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.476 | train_wall 334 | gb_free 6.1 | wall 4378
KL Stats: Epoch 12 Divergences: Uniform: 1.7477595932050858 Unigram: 0.8317695715879262
2022-01-28 08:06:10 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 08:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:08:59 | INFO | train_inner | epoch 013:     32 / 64 loss=10.316, ppl=1275.19, wps=5608.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.49, train_wall=522, gb_free=6.1, wall=4547
2022-01-28 08:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:12:15 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.263 | ppl 1229.11 | wps 7652.1 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:12:15 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:12:15 | INFO | train | epoch 013 | loss 10.228 | ppl 1198.91 | wps 5724.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.518 | train_wall 335 | gb_free 6.1 | wall 4743
KL Stats: Epoch 13 Divergences: Uniform: 1.7779744003700564 Unigram: 0.9092587218303655
2022-01-28 08:12:15 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:12:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:18:20 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.171 | ppl 1152.74 | wps 7625.5 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 08:18:20 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 08:18:20 | INFO | train | epoch 014 | loss 10.117 | ppl 1110.67 | wps 5725.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.548 | train_wall 334 | gb_free 6.1 | wall 5107
KL Stats: Epoch 14 Divergences: Uniform: 1.8060263438167647 Unigram: 0.9828556908854261
2022-01-28 08:18:20 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 08:18:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:18:41 | INFO | train_inner | epoch 015:      4 / 64 loss=10.14, ppl=1128.18, wps=5602.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.533, train_wall=522, gb_free=6.1, wall=5129
2022-01-28 08:23:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:24:24 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.103 | ppl 1099.69 | wps 7657.1 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 08:24:24 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 08:24:24 | INFO | train | epoch 015 | loss 10.006 | ppl 1028.13 | wps 5728.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.529 | train_wall 334 | gb_free 6.1 | wall 5472
KL Stats: Epoch 15 Divergences: Uniform: 1.835046909832182 Unigram: 1.048929058971058
2022-01-28 08:24:24 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 08:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:27:56 | INFO | train_inner | epoch 016:     40 / 64 loss=9.965, ppl=999.31, wps=5891.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.551, train_wall=524, gb_free=6.1, wall=5683
2022-01-28 08:30:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:30:30 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.024 | ppl 1040.96 | wps 7644.9 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 08:30:30 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 08:30:30 | INFO | train | epoch 016 | loss 9.899 | ppl 955.06 | wps 5718.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.55 | train_wall 335 | gb_free 6.1 | wall 5837
KL Stats: Epoch 16 Divergences: Uniform: 1.8678701715473593 Unigram: 1.114723738648338
2022-01-28 08:30:30 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 08:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:36:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.93 | ppl 975.67 | wps 7639.9 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 08:36:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 08:36:34 | INFO | train | epoch 017 | loss 9.792 | ppl 886.73 | wps 5726.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.538 | train_wall 334 | gb_free 6.1 | wall 6202
KL Stats: Epoch 17 Divergences: Uniform: 1.9061858076230187 Unigram: 1.171238506787415
2022-01-28 08:36:34 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 08:36:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:37:38 | INFO | train_inner | epoch 018:     12 / 64 loss=9.806, ppl=895.4, wps=5601.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.54, train_wall=522, gb_free=6.1, wall=6265
2022-01-28 08:42:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:42:39 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.86 | ppl 929.34 | wps 7641 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 08:42:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 08:42:39 | INFO | train | epoch 018 | loss 9.692 | ppl 827.19 | wps 5732.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.571 | train_wall 334 | gb_free 6.1 | wall 6566
KL Stats: Epoch 18 Divergences: Uniform: 1.9450838916099606 Unigram: 1.2273014920370557
2022-01-28 08:42:39 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 08:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:46:52 | INFO | train_inner | epoch 019:     48 / 64 loss=9.642, ppl=799.06, wps=5900.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.534, train_wall=523, gb_free=6.1, wall=6819
2022-01-28 08:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:48:43 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.795 | ppl 888.43 | wps 7685.8 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 08:48:43 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 08:48:43 | INFO | train | epoch 019 | loss 9.588 | ppl 769.74 | wps 5734.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.516 | train_wall 334 | gb_free 6.1 | wall 6931
KL Stats: Epoch 19 Divergences: Uniform: 1.9813243520561452 Unigram: 1.2838453189881176
2022-01-28 08:48:43 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 08:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:54:47 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.705 | ppl 834.84 | wps 7647.1 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 08:54:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 08:54:47 | INFO | train | epoch 020 | loss 9.49 | ppl 719.28 | wps 5732.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.532 | train_wall 334 | gb_free 6.1 | wall 7295
KL Stats: Epoch 20 Divergences: Uniform: 2.0172795577415403 Unigram: 1.3348767729901865
2022-01-28 08:54:47 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 08:54:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:56:33 | INFO | train_inner | epoch 021:     20 / 64 loss=9.486, ppl=717.14, wps=5609.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.54, train_wall=522, gb_free=6.1, wall=7400
2022-01-28 09:00:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:00:52 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.655 | ppl 806.09 | wps 7648.9 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 09:00:52 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 09:00:52 | INFO | train | epoch 021 | loss 9.397 | ppl 674.18 | wps 5730.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.537 | train_wall 334 | gb_free 6.1 | wall 7659
KL Stats: Epoch 21 Divergences: Uniform: 2.048863650532336 Unigram: 1.384735512405409
2022-01-28 09:00:52 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 09:00:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:05:47 | INFO | train_inner | epoch 022:     56 / 64 loss=9.344, ppl=649.88, wps=5898.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.532, train_wall=523, gb_free=6.1, wall=7954
2022-01-28 09:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:06:56 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.604 | ppl 778.01 | wps 7641.5 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 09:06:56 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 09:06:56 | INFO | train | epoch 022 | loss 9.307 | ppl 633.59 | wps 5732.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.537 | train_wall 334 | gb_free 6.1 | wall 8024
KL Stats: Epoch 22 Divergences: Uniform: 2.0793031350909157 Unigram: 1.4325078695655344
2022-01-28 09:06:56 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 09:06:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:12:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:13:01 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.539 | ppl 744.18 | wps 7664.3 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:13:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:13:01 | INFO | train | epoch 023 | loss 9.221 | ppl 596.82 | wps 5732 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.52 | train_wall 334 | gb_free 6.1 | wall 8388
KL Stats: Epoch 23 Divergences: Uniform: 2.1092595790578588 Unigram: 1.4752457135526857
2022-01-28 09:13:01 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:15:28 | INFO | train_inner | epoch 024:     28 / 64 loss=9.206, ppl=590.44, wps=5608.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.525, train_wall=521, gb_free=6.1, wall=8536
2022-01-28 09:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:19:05 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.484 | ppl 715.93 | wps 7630.8 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:19:05 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:19:05 | INFO | train | epoch 024 | loss 9.137 | ppl 562.93 | wps 5729 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.533 | train_wall 334 | gb_free 6.1 | wall 8753
KL Stats: Epoch 24 Divergences: Uniform: 2.1367439464944975 Unigram: 1.5140172495505464
2022-01-28 09:19:05 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:24:41 | INFO | train_inner | epoch 025:     64 / 64 loss=9.083, ppl=542.29, wps=5892.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.524, train_wall=522, gb_free=6.1, wall=9089
2022-01-28 09:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:25:10 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.456 | ppl 702.34 | wps 7652.5 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 09:25:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 09:25:10 | INFO | train | epoch 025 | loss 9.055 | ppl 531.94 | wps 5727.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.518 | train_wall 334 | gb_free 6.1 | wall 9117
KL Stats: Epoch 25 Divergences: Uniform: 2.168704512486498 Unigram: 1.555541568579168
2022-01-28 09:25:10 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 09:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:31:14 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.401 | ppl 675.97 | wps 7692.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 09:31:14 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 09:31:14 | INFO | train | epoch 026 | loss 8.974 | ppl 502.98 | wps 5729.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.536 | train_wall 334 | gb_free 6.1 | wall 9482
KL Stats: Epoch 26 Divergences: Uniform: 2.183527024015553 Unigram: 1.590323357385262
2022-01-28 09:31:14 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 09:31:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:34:24 | INFO | train_inner | epoch 027:     36 / 64 loss=8.946, ppl=493.24, wps=5607.4, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.528, train_wall=523, gb_free=6.1, wall=9672
2022-01-28 09:36:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:37:19 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.375 | ppl 663.8 | wps 7640.2 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 09:37:19 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 09:37:19 | INFO | train | epoch 027 | loss 8.893 | ppl 475.51 | wps 5729.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.517 | train_wall 334 | gb_free 6.1 | wall 9846
KL Stats: Epoch 27 Divergences: Uniform: 2.2128797475888473 Unigram: 1.6274388416364782
2022-01-28 09:37:19 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 09:37:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:43:24 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.341 | ppl 648.48 | wps 7642.9 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 09:43:24 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 09:43:24 | INFO | train | epoch 028 | loss 8.814 | ppl 450.21 | wps 5724.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.517 | train_wall 335 | gb_free 6.1 | wall 10211
KL Stats: Epoch 28 Divergences: Uniform: 2.2442144390957863 Unigram: 1.659081925617765
2022-01-28 09:43:24 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 09:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:44:06 | INFO | train_inner | epoch 029:      8 / 64 loss=8.83, ppl=455.18, wps=5602.7, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.519, train_wall=522, gb_free=6.1, wall=10253
2022-01-28 09:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:49:28 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.312 | ppl 635.55 | wps 7653.2 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 09:49:28 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 09:49:28 | INFO | train | epoch 029 | loss 8.736 | ppl 426.28 | wps 5730 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.521 | train_wall 334 | gb_free 6.1 | wall 10576
KL Stats: Epoch 29 Divergences: Uniform: 2.2696437994427434 Unigram: 1.692220440452701
2022-01-28 09:49:28 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 09:49:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:53:20 | INFO | train_inner | epoch 030:     44 / 64 loss=8.702, ppl=416.55, wps=5895.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.512, train_wall=523, gb_free=6.1, wall=10808
2022-01-28 09:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:55:33 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.291 | ppl 626.54 | wps 7646.5 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 09:55:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 09:55:33 | INFO | train | epoch 030 | loss 8.658 | ppl 403.83 | wps 5731.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.514 | train_wall 334 | gb_free 6.1 | wall 10940
KL Stats: Epoch 30 Divergences: Uniform: 2.2907573078348538 Unigram: 1.7270034701359627
2022-01-28 09:55:33 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 09:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:01:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:01:38 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.244 | ppl 606.44 | wps 7643 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 10:01:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 10:01:38 | INFO | train | epoch 031 | loss 8.578 | ppl 382.13 | wps 5722.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.486 | train_wall 335 | gb_free 6.1 | wall 11305
KL Stats: Epoch 31 Divergences: Uniform: 2.314094414247495 Unigram: 1.757207722754887
2022-01-28 10:01:38 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 10:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:03:02 | INFO | train_inner | epoch 032:     16 / 64 loss=8.579, ppl=382.53, wps=5602.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.496, train_wall=522, gb_free=6.1, wall=11390
2022-01-28 10:07:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:07:42 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.213 | ppl 593.45 | wps 7682.7 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 10:07:42 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 10:07:42 | INFO | train | epoch 032 | loss 8.504 | ppl 363 | wps 5729.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.5 | train_wall 334 | gb_free 6.1 | wall 11670
KL Stats: Epoch 32 Divergences: Uniform: 2.3415497067870956 Unigram: 1.7874358378671509
2022-01-28 10:07:42 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 10:07:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:12:16 | INFO | train_inner | epoch 033:     52 / 64 loss=8.467, ppl=353.81, wps=5895.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.504, train_wall=523, gb_free=6.1, wall=11944
2022-01-28 10:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:13:47 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.194 | ppl 585.56 | wps 7656.3 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 10:13:47 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 10:13:47 | INFO | train | epoch 033 | loss 8.429 | ppl 344.7 | wps 5726.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.499 | train_wall 334 | gb_free 6.1 | wall 12035
KL Stats: Epoch 33 Divergences: Uniform: 2.369400666546303 Unigram: 1.818223096083071
2022-01-28 10:13:47 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 10:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:19:52 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.175 | ppl 577.86 | wps 7651.4 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:19:52 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:19:52 | INFO | train | epoch 034 | loss 8.352 | ppl 326.84 | wps 5724.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.498 | train_wall 335 | gb_free 6.1 | wall 12399
KL Stats: Epoch 34 Divergences: Uniform: 2.393554905071504 Unigram: 1.8488760981832777
2022-01-28 10:19:52 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:21:59 | INFO | train_inner | epoch 035:     24 / 64 loss=8.34, ppl=324.03, wps=5599.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.498, train_wall=522, gb_free=6.1, wall=12526
2022-01-28 10:25:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:25:56 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.153 | ppl 569.18 | wps 7657 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 10:25:56 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 10:25:56 | INFO | train | epoch 035 | loss 8.281 | ppl 311.06 | wps 5726.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.496 | train_wall 334 | gb_free 6.1 | wall 12764
KL Stats: Epoch 35 Divergences: Uniform: 2.4181919041814353 Unigram: 1.8741064584895446
2022-01-28 10:25:57 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 10:25:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:31:12 | INFO | train_inner | epoch 036:     60 / 64 loss=8.237, ppl=301.68, wps=5902.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.493, train_wall=523, gb_free=6.1, wall=13080
2022-01-28 10:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:32:01 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.128 | ppl 559.6 | wps 7657.5 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 10:32:01 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 10:32:01 | INFO | train | epoch 036 | loss 8.207 | ppl 295.51 | wps 5737.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.493 | train_wall 334 | gb_free 6.1 | wall 13128
KL Stats: Epoch 36 Divergences: Uniform: 2.4415028373559102 Unigram: 1.9055765784162444
2022-01-28 10:32:01 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 10:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:38:05 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.132 | ppl 561.24 | wps 7651 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 10:38:05 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 10:38:05 | INFO | train | epoch 037 | loss 8.137 | ppl 281.53 | wps 5732.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.498 | train_wall 334 | gb_free 6.1 | wall 13492
KL Stats: Epoch 37 Divergences: Uniform: 2.4648854960032267 Unigram: 1.9338614753337102
2022-01-28 10:38:05 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 10:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:40:53 | INFO | train_inner | epoch 038:     32 / 64 loss=8.115, ppl=277.33, wps=5609.2, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.495, train_wall=521, gb_free=6.1, wall=13661
2022-01-28 10:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:44:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.124 | ppl 557.87 | wps 7686.7 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 10:44:10 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 10:44:10 | INFO | train | epoch 038 | loss 8.069 | ppl 268.52 | wps 5728.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.501 | train_wall 334 | gb_free 6.1 | wall 13857
KL Stats: Epoch 38 Divergences: Uniform: 2.499134960885689 Unigram: 1.9562152817256706
2022-01-28 10:44:10 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 10:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:50:14 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.102 | ppl 549.48 | wps 7653.3 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 10:50:14 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 10:50:14 | INFO | train | epoch 039 | loss 7.999 | ppl 255.87 | wps 5734.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.489 | train_wall 334 | gb_free 6.1 | wall 14221
KL Stats: Epoch 39 Divergences: Uniform: 2.5086699324716637 Unigram: 1.9875788705591302
2022-01-28 10:50:14 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 10:50:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:50:35 | INFO | train_inner | epoch 040:      4 / 64 loss=8.022, ppl=259.87, wps=5606.3, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.498, train_wall=522, gb_free=6.1, wall=14242
2022-01-28 10:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:56:18 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.086 | ppl 543.38 | wps 7677.1 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 10:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 10:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint40.pt
2022-01-28 10:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint40.pt
2022-01-28 10:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.086) (writing took 4.783139440231025 seconds)
2022-01-28 10:56:23 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 10:56:23 | INFO | train | epoch 040 | loss 7.931 | ppl 243.96 | wps 5659.3 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.487 | train_wall 334 | gb_free 6.1 | wall 14590
KL Stats: Epoch 40 Divergences: Uniform: 2.5389774890142816 Unigram: 2.0112981458690182
2022-01-28 10:56:23 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 10:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:59:54 | INFO | train_inner | epoch 041:     40 / 64 loss=7.907, ppl=240, wps=5849.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.484, train_wall=523, gb_free=6.1, wall=14801
2022-01-28 11:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:02:27 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.078 | ppl 540.38 | wps 7694.8 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.078
2022-01-28 11:02:27 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 11:02:27 | INFO | train | epoch 041 | loss 7.866 | ppl 233.37 | wps 5730.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.49 | train_wall 334 | gb_free 6.1 | wall 14955
KL Stats: Epoch 41 Divergences: Uniform: 2.5552572429418245 Unigram: 2.0336292132874143
2022-01-28 11:02:27 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 11:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:08:31 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.046 | ppl 528.68 | wps 7684.7 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.046
2022-01-28 11:08:31 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 11:08:31 | INFO | train | epoch 042 | loss 7.802 | ppl 223.14 | wps 5735 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.502 | train_wall 334 | gb_free 6.1 | wall 15319
KL Stats: Epoch 42 Divergences: Uniform: 2.575946464254969 Unigram: 2.062660936456334
2022-01-28 11:08:31 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 11:08:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:09:35 | INFO | train_inner | epoch 043:     12 / 64 loss=7.808, ppl=224.14, wps=5610.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.5, train_wall=522, gb_free=6.1, wall=15382
2022-01-28 11:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:14:36 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.073 | ppl 538.55 | wps 7658.3 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.073
2022-01-28 11:14:36 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 11:14:36 | INFO | train | epoch 043 | loss 7.736 | ppl 213.21 | wps 5732.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.489 | train_wall 334 | gb_free 6.1 | wall 15683
KL Stats: Epoch 43 Divergences: Uniform: 2.600645857496469 Unigram: 2.083937239657494
2022-01-28 11:14:36 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 11:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:18:49 | INFO | train_inner | epoch 044:     48 / 64 loss=7.702, ppl=208.24, wps=5893.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.495, train_wall=523, gb_free=6.1, wall=15937
2022-01-28 11:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:20:41 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.069 | ppl 537.13 | wps 7654.1 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.069
2022-01-28 11:20:41 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 11:20:41 | INFO | train | epoch 044 | loss 7.677 | ppl 204.6 | wps 5723.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.499 | train_wall 335 | gb_free 6.1 | wall 16048
KL Stats: Epoch 44 Divergences: Uniform: 2.6221834558198256 Unigram: 2.1080706425365
2022-01-28 11:20:41 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 11:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:26:45 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.069 | ppl 537.2 | wps 7671.1 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.069
2022-01-28 11:26:45 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 11:26:45 | INFO | train | epoch 045 | loss 7.614 | ppl 195.85 | wps 5736.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.502 | train_wall 334 | gb_free 6.1 | wall 16412
KL Stats: Epoch 45 Divergences: Uniform: 2.6421435339631794 Unigram: 2.135230586627193
2022-01-28 11:26:45 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 11:26:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:28:30 | INFO | train_inner | epoch 046:     20 / 64 loss=7.613, ppl=195.77, wps=5612.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.499, train_wall=521, gb_free=6.1, wall=16518
2022-01-28 11:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:32:49 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.056 | ppl 532.15 | wps 7669.9 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.056
2022-01-28 11:32:49 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 11:32:49 | INFO | train | epoch 046 | loss 7.554 | ppl 187.91 | wps 5738.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.502 | train_wall 334 | gb_free 6.1 | wall 16776
KL Stats: Epoch 46 Divergences: Uniform: 2.659551259204646 Unigram: 2.153234616947132
2022-01-28 11:32:49 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 11:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:37:44 | INFO | train_inner | epoch 047:     56 / 64 loss=7.523, ppl=183.87, wps=5900.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.493, train_wall=523, gb_free=6.1, wall=17071
2022-01-28 11:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:38:53 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.05 | ppl 529.9 | wps 7653 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.05
2022-01-28 11:38:53 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 11:38:53 | INFO | train | epoch 047 | loss 7.494 | ppl 180.29 | wps 5732.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.485 | train_wall 334 | gb_free 6.1 | wall 17141
KL Stats: Epoch 47 Divergences: Uniform: 2.6838623144020253 Unigram: 2.173896736321955
2022-01-28 11:38:53 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 11:38:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:44:57 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.043 | ppl 527.52 | wps 7672.2 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.043
2022-01-28 11:44:57 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 11:44:57 | INFO | train | epoch 048 | loss 7.438 | ppl 173.4 | wps 5738 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.5 | train_wall 334 | gb_free 6.1 | wall 17505
KL Stats: Epoch 48 Divergences: Uniform: 2.705383798042192 Unigram: 2.1990438348919987
2022-01-28 11:44:57 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 11:44:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:47:25 | INFO | train_inner | epoch 049:     28 / 64 loss=7.42, ppl=171.27, wps=5612.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.495, train_wall=521, gb_free=6.1, wall=17652
2022-01-28 11:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:51:01 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.062 | ppl 534.34 | wps 7674.6 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.062
2022-01-28 11:51:01 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 11:51:01 | INFO | train | epoch 049 | loss 7.38 | ppl 166.6 | wps 5739.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.497 | train_wall 334 | gb_free 6.1 | wall 17869
KL Stats: Epoch 49 Divergences: Uniform: 2.714315098759549 Unigram: 2.217306107242955
2022-01-28 11:51:01 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 11:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:56:37 | INFO | train_inner | epoch 050:     64 / 64 loss=7.356, ppl=163.77, wps=5906.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.512, train_wall=521, gb_free=6.1, wall=18204
2022-01-28 11:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:57:05 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.099 | ppl 548.32 | wps 7695.5 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.086
2022-01-28 11:57:05 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 11:57:05 | INFO | train | epoch 050 | loss 7.329 | ppl 160.76 | wps 5738.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.516 | train_wall 334 | gb_free 6.1 | wall 18233
KL Stats: Epoch 50 Divergences: Uniform: 2.733632289828907 Unigram: 2.229665829666551
2022-01-28 11:57:05 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 11:57:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:03:09 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.089 | ppl 544.67 | wps 7696 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.086
2022-01-28 12:03:09 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 12:03:09 | INFO | train | epoch 051 | loss 7.273 | ppl 154.67 | wps 5737.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.501 | train_wall 334 | gb_free 6.1 | wall 18597
KL Stats: Epoch 51 Divergences: Uniform: 2.76030001468887 Unigram: 2.2506229265816624
2022-01-28 12:03:09 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 12:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:06:18 | INFO | train_inner | epoch 052:     36 / 64 loss=7.249, ppl=152.12, wps=5621.5, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.501, train_wall=522, gb_free=6.1, wall=18786
2022-01-28 12:08:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:09:13 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.066 | ppl 535.79 | wps 7666.8 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.066
2022-01-28 12:09:13 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 12:09:13 | INFO | train | epoch 052 | loss 7.22 | ppl 149.12 | wps 5744.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.506 | train_wall 333 | gb_free 6.1 | wall 18960
KL Stats: Epoch 52 Divergences: Uniform: 2.7722818833481084 Unigram: 2.274252288774337
2022-01-28 12:09:13 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 12:09:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:15:17 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.064 | ppl 535.32 | wps 7678.7 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.064
2022-01-28 12:15:17 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 12:15:17 | INFO | train | epoch 053 | loss 7.168 | ppl 143.82 | wps 5735 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.492 | train_wall 334 | gb_free 6.1 | wall 19324
KL Stats: Epoch 53 Divergences: Uniform: 2.800854298785904 Unigram: 2.2902876127575746
2022-01-28 12:15:17 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 12:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:15:59 | INFO | train_inner | epoch 054:      8 / 64 loss=7.181, ppl=145.14, wps=5611.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.503, train_wall=521, gb_free=6.1, wall=19366
2022-01-28 12:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:21:21 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.109 | ppl 552.06 | wps 7687.2 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.086
2022-01-28 12:21:21 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 12:21:21 | INFO | train | epoch 054 | loss 7.119 | ppl 138.98 | wps 5736.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.515 | train_wall 334 | gb_free 6.1 | wall 19688
KL Stats: Epoch 54 Divergences: Uniform: 2.8031087935473513 Unigram: 2.3074682623452203
2022-01-28 12:21:21 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 12:21:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:25:13 | INFO | train_inner | epoch 055:     44 / 64 loss=7.091, ppl=136.33, wps=5900.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.512, train_wall=523, gb_free=6.1, wall=19920
2022-01-28 12:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:27:25 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.087 | ppl 543.68 | wps 7667.2 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.086
2022-01-28 12:27:25 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 12:27:25 | INFO | train | epoch 055 | loss 7.071 | ppl 134.5 | wps 5729.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.525 | train_wall 334 | gb_free 6.1 | wall 20053
KL Stats: Epoch 55 Divergences: Uniform: 2.8229758797673927 Unigram: 2.329169163744131
2022-01-28 12:27:25 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 12:27:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:33:30 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.213 | ppl 593.31 | wps 7674.4 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.086
2022-01-28 12:33:30 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 12:33:30 | INFO | train | epoch 056 | loss 7.021 | ppl 129.88 | wps 5734 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.51 | train_wall 334 | gb_free 6.1 | wall 20417
KL Stats: Epoch 56 Divergences: Uniform: 2.820523814524326 Unigram: 2.340387183615646
2022-01-28 12:33:30 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 12:33:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:34:54 | INFO | train_inner | epoch 057:     16 / 64 loss=7.025, ppl=130.27, wps=5606.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.518, train_wall=522, gb_free=6.1, wall=20502
2022-01-28 12:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:39:35 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.176 | ppl 578.5 | wps 7647.3 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.086
2022-01-28 12:39:35 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 12:39:35 | INFO | train | epoch 057 | loss 6.974 | ppl 125.71 | wps 5724.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.514 | train_wall 335 | gb_free 6.1 | wall 20782
KL Stats: Epoch 57 Divergences: Uniform: 2.8590112039368787 Unigram: 2.364418425879582
2022-01-28 12:39:35 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 12:39:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:44:09 | INFO | train_inner | epoch 058:     52 / 64 loss=6.95, ppl=123.61, wps=5893.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.515, train_wall=523, gb_free=6.1, wall=21056
2022-01-28 12:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:45:39 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.164 | ppl 573.75 | wps 7687.5 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.086
2022-01-28 12:45:39 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 12:45:39 | INFO | train | epoch 058 | loss 6.93 | ppl 121.92 | wps 5731.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.518 | train_wall 334 | gb_free 6.1 | wall 21147
KL Stats: Epoch 58 Divergences: Uniform: 2.8687257401635264 Unigram: 2.3790578895074446
2022-01-28 12:45:39 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 12:45:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:51:43 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.23 | ppl 600.38 | wps 7660.2 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.086
2022-01-28 12:51:43 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 12:51:43 | INFO | train | epoch 059 | loss 6.885 | ppl 118.16 | wps 5738.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.521 | train_wall 334 | gb_free 6.1 | wall 21510
KL Stats: Epoch 59 Divergences: Uniform: 2.8888694117241736 Unigram: 2.3909172024453844
2022-01-28 12:51:43 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 12:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:53:50 | INFO | train_inner | epoch 060:     24 / 64 loss=6.879, ppl=117.68, wps=5612.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.523, train_wall=521, gb_free=6.1, wall=21637
2022-01-28 12:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:57:47 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.185 | ppl 582.18 | wps 7665.6 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.086
2022-01-28 12:57:47 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 12:57:47 | INFO | train | epoch 060 | loss 6.84 | ppl 114.55 | wps 5733.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.528 | train_wall 334 | gb_free 6.1 | wall 21875
KL Stats: Epoch 60 Divergences: Uniform: 2.9036124835160377 Unigram: 2.414414274920054
2022-01-28 12:57:47 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 12:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:03:03 | INFO | train_inner | epoch 061:     60 / 64 loss=6.82, ppl=112.98, wps=5900.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.532, train_wall=523, gb_free=6.1, wall=22191
2022-01-28 13:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:03:52 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.246 | ppl 607.1 | wps 7670.1 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.086
2022-01-28 13:03:52 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 13:03:52 | INFO | train | epoch 061 | loss 6.797 | ppl 111.19 | wps 5730.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.536 | train_wall 334 | gb_free 6.1 | wall 22239
KL Stats: Epoch 61 Divergences: Uniform: 2.9243096204741605 Unigram: 2.4269596399120155
2022-01-28 13:03:52 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 13:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:09:56 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.221 | ppl 596.9 | wps 7653.4 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.086
2022-01-28 13:09:56 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 13:09:56 | INFO | train | epoch 062 | loss 6.756 | ppl 108.06 | wps 5738.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.537 | train_wall 334 | gb_free 6.1 | wall 22603
KL Stats: Epoch 62 Divergences: Uniform: 2.9358173764868414 Unigram: 2.4442199216225493
2022-01-28 13:09:56 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 13:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:12:44 | INFO | train_inner | epoch 063:     32 / 64 loss=6.73, ppl=106.18, wps=5614.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.535, train_wall=521, gb_free=6.1, wall=22772
2022-01-28 13:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:15:59 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.233 | ppl 601.86 | wps 7699.2 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.086
2022-01-28 13:15:59 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 13:15:59 | INFO | train | epoch 063 | loss 6.713 | ppl 104.9 | wps 5747.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.532 | train_wall 333 | gb_free 6.1 | wall 22967
KL Stats: Epoch 63 Divergences: Uniform: 2.9528173195008853 Unigram: 2.458890682953599
2022-01-28 13:15:59 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 13:15:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:22:04 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.242 | ppl 605.71 | wps 7656.5 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.086
2022-01-28 13:22:04 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 13:22:04 | INFO | train | epoch 064 | loss 6.669 | ppl 101.74 | wps 5728.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.538 | train_wall 334 | gb_free 6.1 | wall 23331
KL Stats: Epoch 64 Divergences: Uniform: 2.9608943276123845 Unigram: 2.474403460714693
2022-01-28 13:22:04 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 13:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:22:25 | INFO | train_inner | epoch 065:      4 / 64 loss=6.696, ppl=103.68, wps=5613.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.538, train_wall=521, gb_free=6.1, wall=23352
2022-01-28 13:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:28:08 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.234 | ppl 602.02 | wps 7660.8 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.086
2022-01-28 13:28:08 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 13:28:08 | INFO | train | epoch 065 | loss 6.626 | ppl 98.78 | wps 5726.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.542 | train_wall 335 | gb_free 6.1 | wall 23696
KL Stats: Epoch 65 Divergences: Uniform: 2.975474559303077 Unigram: 2.490023801869622
2022-01-28 13:28:08 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 13:28:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:31:39 | INFO | train_inner | epoch 066:     40 / 64 loss=6.602, ppl=97.13, wps=5894.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.545, train_wall=523, gb_free=6.1, wall=23907
2022-01-28 13:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:34:13 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.265 | ppl 615.18 | wps 7639.3 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.086
2022-01-28 13:34:13 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 13:34:13 | INFO | train | epoch 066 | loss 6.585 | ppl 96.03 | wps 5724.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.538 | train_wall 335 | gb_free 6.1 | wall 24061
KL Stats: Epoch 66 Divergences: Uniform: 2.987183346411836 Unigram: 2.5031021148217714
2022-01-28 13:34:13 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 13:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:40:18 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.234 | ppl 602.2 | wps 7654.9 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.086
2022-01-28 13:40:18 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 13:40:18 | INFO | train | epoch 067 | loss 6.546 | ppl 93.45 | wps 5724 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.543 | train_wall 335 | gb_free 6.1 | wall 24426
KL Stats: Epoch 67 Divergences: Uniform: 3.016155414246899 Unigram: 2.5257978517639863
2022-01-28 13:40:18 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 13:40:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:41:21 | INFO | train_inner | epoch 068:     12 / 64 loss=6.554, ppl=93.99, wps=5599.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.539, train_wall=522, gb_free=6.1, wall=24489
2022-01-28 13:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:46:22 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.327 | ppl 642.42 | wps 7666 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.086
2022-01-28 13:46:22 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 13:46:22 | INFO | train | epoch 068 | loss 6.508 | ppl 91.02 | wps 5731.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.558 | train_wall 334 | gb_free 6.1 | wall 24790
KL Stats: Epoch 68 Divergences: Uniform: 3.0217938054893687 Unigram: 2.5353542074752924
2022-01-28 13:46:22 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 13:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:50:35 | INFO | train_inner | epoch 069:     48 / 64 loss=6.49, ppl=89.87, wps=5898.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.552, train_wall=523, gb_free=6.1, wall=25043
2022-01-28 13:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:52:27 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.338 | ppl 647.38 | wps 7681.5 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.086
2022-01-28 13:52:27 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 13:52:27 | INFO | train | epoch 069 | loss 6.47 | ppl 88.63 | wps 5734.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.553 | train_wall 334 | gb_free 6.1 | wall 25154
KL Stats: Epoch 69 Divergences: Uniform: 3.0350417955367237 Unigram: 2.5502968304325515
2022-01-28 13:52:27 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 13:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:58:31 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.366 | ppl 659.81 | wps 7664 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.086
2022-01-28 13:58:31 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 13:58:31 | INFO | train | epoch 070 | loss 6.435 | ppl 86.53 | wps 5731.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.547 | train_wall 334 | gb_free 6.1 | wall 25519
KL Stats: Epoch 70 Divergences: Uniform: 3.0476411447173692 Unigram: 2.560979718480489
2022-01-28 13:58:31 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 13:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:00:17 | INFO | train_inner | epoch 071:     20 / 64 loss=6.43, ppl=86.21, wps=5610.2, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.553, train_wall=522, gb_free=6.1, wall=25624
2022-01-28 14:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:04:35 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.347 | ppl 651.21 | wps 7668.2 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.086
2022-01-28 14:04:35 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 14:04:35 | INFO | train | epoch 071 | loss 6.402 | ppl 84.58 | wps 5737 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.572 | train_wall 334 | gb_free 6.1 | wall 25883
KL Stats: Epoch 71 Divergences: Uniform: 3.055521363530538 Unigram: 2.5783876267952546
2022-01-28 14:04:35 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 14:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:09:30 | INFO | train_inner | epoch 072:     56 / 64 loss=6.386, ppl=83.65, wps=5903.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.562, train_wall=522, gb_free=6.1, wall=26178
2022-01-28 14:10:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:10:39 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.327 | ppl 642.43 | wps 7648.2 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.086
2022-01-28 14:10:39 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 14:10:39 | INFO | train | epoch 072 | loss 6.366 | ppl 82.46 | wps 5733.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.551 | train_wall 334 | gb_free 6.1 | wall 26247
KL Stats: Epoch 72 Divergences: Uniform: 3.080372062514636 Unigram: 2.590835087890896
2022-01-28 14:10:39 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 14:10:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:16:43 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.417 | ppl 683.46 | wps 7678.8 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.086
2022-01-28 14:16:43 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 14:16:43 | INFO | train | epoch 073 | loss 6.334 | ppl 80.69 | wps 5738.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.558 | train_wall 334 | gb_free 6.1 | wall 26611
KL Stats: Epoch 73 Divergences: Uniform: 3.07359487672832 Unigram: 2.600926452142315
2022-01-28 14:16:43 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 14:16:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:19:11 | INFO | train_inner | epoch 074:     28 / 64 loss=6.323, ppl=80.06, wps=5614.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.557, train_wall=521, gb_free=6.1, wall=26758
2022-01-28 14:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:22:48 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.34 | ppl 647.84 | wps 7631 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.086
2022-01-28 14:22:48 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 14:22:48 | INFO | train | epoch 074 | loss 6.302 | ppl 78.89 | wps 5729.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.558 | train_wall 334 | gb_free 6.1 | wall 26976
KL Stats: Epoch 74 Divergences: Uniform: 3.092956818319457 Unigram: 2.619227705243107
2022-01-28 14:22:48 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 14:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:28:24 | INFO | train_inner | epoch 075:     64 / 64 loss=6.293, ppl=78.4, wps=5894, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.567, train_wall=522, gb_free=6.1, wall=27312
2022-01-28 14:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:28:52 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.481 | ppl 714.83 | wps 7678 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.086
2022-01-28 14:28:52 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 14:28:52 | INFO | train | epoch 075 | loss 6.273 | ppl 77.31 | wps 5731.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.569 | train_wall 334 | gb_free 6.1 | wall 27340
KL Stats: Epoch 75 Divergences: Uniform: 3.0987612210640734 Unigram: 2.6324400519774427
2022-01-28 14:28:52 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 14:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:34:56 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.412 | ppl 681.11 | wps 7677.2 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.086
2022-01-28 14:34:56 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 14:34:56 | INFO | train | epoch 076 | loss 6.243 | ppl 75.72 | wps 5741.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.574 | train_wall 334 | gb_free 6.1 | wall 27704
KL Stats: Epoch 76 Divergences: Uniform: 3.1108629924691207 Unigram: 2.646146530053164
2022-01-28 14:34:56 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 14:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:38:06 | INFO | train_inner | epoch 077:     36 / 64 loss=6.218, ppl=74.47, wps=5619.5, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.577, train_wall=522, gb_free=6.1, wall=27893
2022-01-28 14:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:41:00 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.469 | ppl 708.67 | wps 7664.6 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.086
2022-01-28 14:41:00 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 14:41:00 | INFO | train | epoch 077 | loss 6.215 | ppl 74.27 | wps 5734.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.583 | train_wall 334 | gb_free 6.1 | wall 28068
KL Stats: Epoch 77 Divergences: Uniform: 3.1087363512316015 Unigram: 2.662108991710123
2022-01-28 14:41:00 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 14:41:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:47:05 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.432 | ppl 690.69 | wps 7680 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.086
2022-01-28 14:47:05 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 14:47:05 | INFO | train | epoch 078 | loss 6.187 | ppl 72.84 | wps 5734.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.581 | train_wall 334 | gb_free 6.1 | wall 28432
KL Stats: Epoch 78 Divergences: Uniform: 3.12571335494968 Unigram: 2.670690522953716
2022-01-28 14:47:05 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 14:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:47:47 | INFO | train_inner | epoch 079:      8 / 64 loss=6.201, ppl=73.57, wps=5609.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.583, train_wall=522, gb_free=6.1, wall=28474
2022-01-28 14:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:53:08 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.496 | ppl 722.21 | wps 7691.4 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.086
2022-01-28 14:53:08 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 14:53:08 | INFO | train | epoch 079 | loss 6.155 | ppl 71.28 | wps 5740.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.575 | train_wall 334 | gb_free 6.1 | wall 28796
KL Stats: Epoch 79 Divergences: Uniform: 3.13182453224514 Unigram: 2.6767539707121193
2022-01-28 14:53:08 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 14:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:57:00 | INFO | train_inner | epoch 080:     44 / 64 loss=6.14, ppl=70.51, wps=5903.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.575, train_wall=523, gb_free=6.1, wall=29028
2022-01-28 14:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:59:13 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.43 | ppl 689.92 | wps 7682.6 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.086
2022-01-28 14:59:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 14:59:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint80.pt
2022-01-28 14:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint80.pt
2022-01-28 14:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.43) (writing took 3.4367021564394236 seconds)
2022-01-28 14:59:16 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 14:59:16 | INFO | train | epoch 080 | loss 6.131 | ppl 70.07 | wps 5679.6 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.582 | train_wall 334 | gb_free 6.1 | wall 29164
KL Stats: Epoch 80 Divergences: Uniform: 3.1378645530765024 Unigram: 2.6949666163363672
2022-01-28 14:59:16 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 14:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:05:21 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.496 | ppl 722 | wps 7635.1 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.086
2022-01-28 15:05:21 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 15:05:21 | INFO | train | epoch 081 | loss 6.104 | ppl 68.8 | wps 5732.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.591 | train_wall 334 | gb_free 6.1 | wall 29528
KL Stats: Epoch 81 Divergences: Uniform: 3.159504341433644 Unigram: 2.7106901840585844
2022-01-28 15:05:21 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 15:05:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:06:45 | INFO | train_inner | epoch 082:     16 / 64 loss=6.111, ppl=69.1, wps=5573.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.591, train_wall=522, gb_free=6.1, wall=29613
2022-01-28 15:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:11:26 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.492 | ppl 720.05 | wps 7667.5 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.086
2022-01-28 15:11:26 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 15:11:26 | INFO | train | epoch 082 | loss 6.08 | ppl 67.64 | wps 5712.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.589 | train_wall 335 | gb_free 6.1 | wall 29894
KL Stats: Epoch 82 Divergences: Uniform: 3.168935712474852 Unigram: 2.723445324277645
2022-01-28 15:11:26 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 15:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:16:00 | INFO | train_inner | epoch 083:     52 / 64 loss=6.067, ppl=67.02, wps=5889.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.595, train_wall=524, gb_free=6.1, wall=30168
2022-01-28 15:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:17:30 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.433 | ppl 691.23 | wps 7674.4 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.086
2022-01-28 15:17:30 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 15:17:30 | INFO | train | epoch 083 | loss 6.056 | ppl 66.54 | wps 5739.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.597 | train_wall 334 | gb_free 6.1 | wall 30258
KL Stats: Epoch 83 Divergences: Uniform: 3.173050078719233 Unigram: 2.7366140490894684
2022-01-28 15:17:30 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 15:17:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:23:34 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.426 | ppl 687.8 | wps 7670.9 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.086
2022-01-28 15:23:34 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 15:23:34 | INFO | train | epoch 084 | loss 6.03 | ppl 65.36 | wps 5737.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.586 | train_wall 334 | gb_free 6.1 | wall 30622
KL Stats: Epoch 84 Divergences: Uniform: 3.1851076149591275 Unigram: 2.7499620356773513
2022-01-28 15:23:34 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 15:23:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:25:40 | INFO | train_inner | epoch 085:     24 / 64 loss=6.02, ppl=64.91, wps=5619.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.594, train_wall=521, gb_free=6.1, wall=30748
2022-01-28 15:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:29:38 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.472 | ppl 710.33 | wps 7672.4 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.086
2022-01-28 15:29:38 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 15:29:38 | INFO | train | epoch 085 | loss 6.006 | ppl 64.29 | wps 5743 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.598 | train_wall 334 | gb_free 6.1 | wall 30985
KL Stats: Epoch 85 Divergences: Uniform: 3.1958890577130883 Unigram: 2.7526897886727473
2022-01-28 15:29:38 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 15:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:34:54 | INFO | train_inner | epoch 086:     60 / 64 loss=6.004, ppl=64.18, wps=5904, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.598, train_wall=522, gb_free=6.1, wall=31301
2022-01-28 15:35:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:35:42 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.506 | ppl 727.2 | wps 7666.4 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.086
2022-01-28 15:35:42 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 15:35:42 | INFO | train | epoch 086 | loss 5.984 | ppl 63.29 | wps 5736.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.607 | train_wall 334 | gb_free 6.1 | wall 31350
KL Stats: Epoch 86 Divergences: Uniform: 3.196358587601108 Unigram: 2.7682439286180776
2022-01-28 15:35:42 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 15:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:41:46 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.499 | ppl 723.37 | wps 7637.7 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.086
2022-01-28 15:41:46 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 15:41:46 | INFO | train | epoch 087 | loss 5.962 | ppl 62.33 | wps 5733.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.625 | train_wall 334 | gb_free 6.1 | wall 31714
KL Stats: Epoch 87 Divergences: Uniform: 3.200002175037775 Unigram: 2.7818798951133323
2022-01-28 15:41:46 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 15:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:44:35 | INFO | train_inner | epoch 088:     32 / 64 loss=5.949, ppl=61.77, wps=5607, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.622, train_wall=522, gb_free=6.1, wall=31883
2022-01-28 15:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:47:51 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.542 | ppl 745.62 | wps 7657.5 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.086
2022-01-28 15:47:51 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 15:47:51 | INFO | train | epoch 088 | loss 5.939 | ppl 61.36 | wps 5730.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.619 | train_wall 334 | gb_free 6.1 | wall 32078
KL Stats: Epoch 88 Divergences: Uniform: 3.205743634113459 Unigram: 2.790111910434389
2022-01-28 15:47:51 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 15:47:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:53:54 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.506 | ppl 726.96 | wps 7615.6 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.086
2022-01-28 15:53:54 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 15:53:54 | INFO | train | epoch 089 | loss 5.921 | ppl 60.57 | wps 5742.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.637 | train_wall 333 | gb_free 6.1 | wall 32442
KL Stats: Epoch 89 Divergences: Uniform: 3.2213362925750015 Unigram: 2.7987486237798116
2022-01-28 15:53:54 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 15:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:54:16 | INFO | train_inner | epoch 090:      4 / 64 loss=5.931, ppl=61.01, wps=5615.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.63, train_wall=521, gb_free=6.1, wall=32463
2022-01-28 15:59:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:59:59 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.619 | ppl 786.18 | wps 7660.3 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.086
2022-01-28 15:59:59 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 15:59:59 | INFO | train | epoch 090 | loss 5.898 | ppl 59.63 | wps 5729.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.62 | train_wall 334 | gb_free 6.1 | wall 32807
KL Stats: Epoch 90 Divergences: Uniform: 3.220441957499999 Unigram: 2.80510625995851
2022-01-28 15:59:59 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 15:59:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:03:29 | INFO | train_inner | epoch 091:     40 / 64 loss=5.881, ppl=58.93, wps=5900.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.623, train_wall=523, gb_free=6.1, wall=33017
2022-01-28 16:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:06:03 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.573 | ppl 761.79 | wps 7636 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.086
2022-01-28 16:06:03 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 16:06:03 | INFO | train | epoch 091 | loss 5.879 | ppl 58.84 | wps 5740.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.633 | train_wall 334 | gb_free 6.1 | wall 33170
KL Stats: Epoch 91 Divergences: Uniform: 3.2346300471374 Unigram: 2.8259957178507813
2022-01-28 16:06:03 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 16:06:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:12:07 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.571 | ppl 760.5 | wps 7656.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.086
2022-01-28 16:12:07 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 16:12:07 | INFO | train | epoch 092 | loss 5.858 | ppl 58.02 | wps 5730.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.64 | train_wall 334 | gb_free 6.1 | wall 33535
KL Stats: Epoch 92 Divergences: Uniform: 3.235743198932355 Unigram: 2.8309148643686672
2022-01-28 16:12:07 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 16:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:13:11 | INFO | train_inner | epoch 093:     12 / 64 loss=5.868, ppl=58.41, wps=5608, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.637, train_wall=522, gb_free=6.1, wall=33598
2022-01-28 16:17:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:18:12 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.594 | ppl 772.95 | wps 7663 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.086
2022-01-28 16:18:12 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 16:18:12 | INFO | train | epoch 093 | loss 5.84 | ppl 57.28 | wps 5723.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.641 | train_wall 335 | gb_free 6.1 | wall 33900
KL Stats: Epoch 93 Divergences: Uniform: 3.246475965035951 Unigram: 2.8440285909985414
2022-01-28 16:18:12 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 16:18:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:22:25 | INFO | train_inner | epoch 094:     48 / 64 loss=5.826, ppl=56.72, wps=5892.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.638, train_wall=523, gb_free=6.1, wall=34153
2022-01-28 16:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:24:17 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.587 | ppl 769.06 | wps 7663.9 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.086
2022-01-28 16:24:17 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 16:24:17 | INFO | train | epoch 094 | loss 5.819 | ppl 56.46 | wps 5732 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.634 | train_wall 334 | gb_free 6.1 | wall 34264
KL Stats: Epoch 94 Divergences: Uniform: 3.246145316139624 Unigram: 2.858223502603151
2022-01-28 16:24:17 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 16:24:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:30:21 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.624 | ppl 789.21 | wps 7648.6 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.086
2022-01-28 16:30:21 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 16:30:21 | INFO | train | epoch 095 | loss 5.801 | ppl 55.76 | wps 5728.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.639 | train_wall 334 | gb_free 6.1 | wall 34629
KL Stats: Epoch 95 Divergences: Uniform: 3.247626741674282 Unigram: 2.8618622907680034
2022-01-28 16:30:21 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 16:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:32:07 | INFO | train_inner | epoch 096:     20 / 64 loss=5.8, ppl=55.72, wps=5606.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.642, train_wall=522, gb_free=6.1, wall=34734
2022-01-28 16:35:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:36:25 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.542 | ppl 745.33 | wps 7661.8 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.086
2022-01-28 16:36:25 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 16:36:25 | INFO | train | epoch 096 | loss 5.784 | ppl 55.11 | wps 5735.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.654 | train_wall 334 | gb_free 6.1 | wall 34993
KL Stats: Epoch 96 Divergences: Uniform: 3.262884280123924 Unigram: 2.8729634989752433
2022-01-28 16:36:25 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 16:36:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:41:20 | INFO | train_inner | epoch 097:     56 / 64 loss=5.779, ppl=54.92, wps=5908.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.665, train_wall=522, gb_free=6.1, wall=35287
2022-01-28 16:42:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:42:29 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.649 | ppl 803.05 | wps 7696.6 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.086
2022-01-28 16:42:29 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 16:42:29 | INFO | train | epoch 097 | loss 5.768 | ppl 54.51 | wps 5741.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.669 | train_wall 334 | gb_free 6.1 | wall 35357
KL Stats: Epoch 97 Divergences: Uniform: 3.267714940120631 Unigram: 2.8855998183799434
2022-01-28 16:42:29 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 16:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:48:33 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.639 | ppl 797.1 | wps 7686.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.086
2022-01-28 16:48:33 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 16:48:33 | INFO | train | epoch 098 | loss 5.747 | ppl 53.71 | wps 5740.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.653 | train_wall 334 | gb_free 6.1 | wall 35721
KL Stats: Epoch 98 Divergences: Uniform: 3.268746959755699 Unigram: 2.8907966664564433
2022-01-28 16:48:33 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 16:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:51:01 | INFO | train_inner | epoch 099:     28 / 64 loss=5.739, ppl=53.4, wps=5613.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.658, train_wall=521, gb_free=6.1, wall=35868
2022-01-28 16:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:54:38 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.606 | ppl 779.19 | wps 7687.7 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.086
2022-01-28 16:54:38 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 16:54:38 | INFO | train | epoch 099 | loss 5.732 | ppl 53.15 | wps 5728.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.682 | train_wall 334 | gb_free 6.1 | wall 36085
KL Stats: Epoch 99 Divergences: Uniform: 3.277915388226668 Unigram: 2.903039085880894
2022-01-28 16:54:38 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 16:54:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:00:13 | INFO | train_inner | epoch 100:     64 / 64 loss=5.735, ppl=53.26, wps=5901.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.69, train_wall=521, gb_free=6.1, wall=36421
2022-01-28 17:00:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:00:42 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.569 | ppl 759.66 | wps 7649.3 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.086
2022-01-28 17:00:42 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 17:00:42 | INFO | train | epoch 100 | loss 5.718 | ppl 52.62 | wps 5738.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.688 | train_wall 334 | gb_free 6.1 | wall 36449
KL Stats: Epoch 100 Divergences: Uniform: 3.2797604166979903 Unigram: 2.911841879089938
2022-01-28 17:00:42 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 17:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:06:46 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.638 | ppl 796.68 | wps 7648.9 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.086
2022-01-28 17:06:46 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 17:06:46 | INFO | train | epoch 101 | loss 5.697 | ppl 51.87 | wps 5725.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.681 | train_wall 335 | gb_free 6.1 | wall 36814
KL Stats: Epoch 101 Divergences: Uniform: 3.2922335528184505 Unigram: 2.9246502631619617
2022-01-28 17:06:46 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 17:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:09:56 | INFO | train_inner | epoch 102:     36 / 64 loss=5.683, ppl=51.36, wps=5603.1, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.681, train_wall=523, gb_free=6.1, wall=37004
2022-01-28 17:12:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:12:51 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.646 | ppl 801.27 | wps 7673.8 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.086
2022-01-28 17:12:51 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 17:12:51 | INFO | train | epoch 102 | loss 5.684 | ppl 51.4 | wps 5731.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.691 | train_wall 334 | gb_free 6.1 | wall 37178
KL Stats: Epoch 102 Divergences: Uniform: 3.2796897444786413 Unigram: 2.929404796942361
2022-01-28 17:12:51 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 17:12:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:18:55 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.662 | ppl 810.12 | wps 7663.4 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.086
2022-01-28 17:18:55 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 17:18:55 | INFO | train | epoch 103 | loss 5.667 | ppl 50.81 | wps 5735.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.685 | train_wall 334 | gb_free 6.1 | wall 37542
KL Stats: Epoch 103 Divergences: Uniform: 3.294087577173036 Unigram: 2.939763084814594
2022-01-28 17:18:55 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 17:18:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:19:37 | INFO | train_inner | epoch 104:      8 / 64 loss=5.675, ppl=51.1, wps=5612.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.694, train_wall=521, gb_free=6.1, wall=37585
2022-01-28 17:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:24:59 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.649 | ppl 803.03 | wps 7662.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.086
2022-01-28 17:24:59 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 17:24:59 | INFO | train | epoch 104 | loss 5.655 | ppl 50.38 | wps 5730.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.698 | train_wall 334 | gb_free 6.1 | wall 37907
KL Stats: Epoch 104 Divergences: Uniform: 3.2912294228660017 Unigram: 2.9495538182645915
2022-01-28 17:24:59 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 17:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:28:51 | INFO | train_inner | epoch 105:     44 / 64 loss=5.642, ppl=49.93, wps=5895.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.697, train_wall=523, gb_free=6.1, wall=38139
2022-01-28 17:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:31:04 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.635 | ppl 795.08 | wps 7680.3 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.086
2022-01-28 17:31:04 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 17:31:04 | INFO | train | epoch 105 | loss 5.638 | ppl 49.78 | wps 5727.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.706 | train_wall 335 | gb_free 6.1 | wall 38272
KL Stats: Epoch 105 Divergences: Uniform: 3.2969007231741547 Unigram: 2.9533011133386142
2022-01-28 17:31:04 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 17:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:36:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:37:08 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.667 | ppl 813.07 | wps 7677.1 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.086
2022-01-28 17:37:08 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 17:37:08 | INFO | train | epoch 106 | loss 5.621 | ppl 49.22 | wps 5739.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.69 | train_wall 334 | gb_free 6.1 | wall 38636
KL Stats: Epoch 106 Divergences: Uniform: 3.2970101695773977 Unigram: 2.9620525869749623
2022-01-28 17:37:08 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 17:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:38:32 | INFO | train_inner | epoch 107:     16 / 64 loss=5.625, ppl=49.34, wps=5611.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.698, train_wall=521, gb_free=6.1, wall=38720
2022-01-28 17:42:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:43:12 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.659 | ppl 808.54 | wps 7692.6 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.086
2022-01-28 17:43:12 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 17:43:12 | INFO | train | epoch 107 | loss 5.607 | ppl 48.75 | wps 5735.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.699 | train_wall 334 | gb_free 6.1 | wall 39000
KL Stats: Epoch 107 Divergences: Uniform: 3.3051893437009254 Unigram: 2.9759572525845597
2022-01-28 17:43:12 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 17:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:47:45 | INFO | train_inner | epoch 108:     52 / 64 loss=5.602, ppl=48.58, wps=5909.6, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.702, train_wall=522, gb_free=6.1, wall=39273
2022-01-28 17:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:49:15 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.691 | ppl 826.84 | wps 7734.8 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.086
2022-01-28 17:49:15 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 17:49:15 | INFO | train | epoch 108 | loss 5.595 | ppl 48.33 | wps 5754.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.71 | train_wall 333 | gb_free 6.1 | wall 39363
KL Stats: Epoch 108 Divergences: Uniform: 3.3107502878479464 Unigram: 2.980628239436516
2022-01-28 17:49:15 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 17:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:54:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:55:18 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.701 | ppl 832.45 | wps 7738.5 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.086
2022-01-28 17:55:18 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 17:55:18 | INFO | train | epoch 109 | loss 5.58 | ppl 47.83 | wps 5751.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.711 | train_wall 333 | gb_free 6.1 | wall 39726
KL Stats: Epoch 109 Divergences: Uniform: 3.316680694652884 Unigram: 2.993679714901311
2022-01-28 17:55:18 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 17:55:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:57:24 | INFO | train_inner | epoch 110:     24 / 64 loss=5.575, ppl=47.66, wps=5630, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.72, train_wall=520, gb_free=6.1, wall=39852
2022-01-28 18:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:01:21 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.787 | ppl 883.61 | wps 7732.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.086
2022-01-28 18:01:21 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 18:01:21 | INFO | train | epoch 110 | loss 5.568 | ppl 47.42 | wps 5751.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.724 | train_wall 333 | gb_free 6.1 | wall 40089
KL Stats: Epoch 110 Divergences: Uniform: 3.321210238862662 Unigram: 3.000754029392085
2022-01-28 18:01:21 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 18:01:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:06:37 | INFO | train_inner | epoch 111:     60 / 64 loss=5.566, ppl=47.37, wps=5917.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.721, train_wall=521, gb_free=6.1, wall=40404
2022-01-28 18:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:07:25 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.71 | ppl 837.41 | wps 7705.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.086
2022-01-28 18:07:25 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 18:07:25 | INFO | train | epoch 111 | loss 5.553 | ppl 46.96 | wps 5750.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.727 | train_wall 333 | gb_free 6.1 | wall 40452
KL Stats: Epoch 111 Divergences: Uniform: 3.3222070897995923 Unigram: 3.0096239609767
2022-01-28 18:07:25 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 18:07:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:13:28 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.747 | ppl 859.34 | wps 7697.8 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.086
2022-01-28 18:13:28 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 18:13:28 | INFO | train | epoch 112 | loss 5.54 | ppl 46.54 | wps 5742.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.723 | train_wall 334 | gb_free 6.1 | wall 40816
KL Stats: Epoch 112 Divergences: Uniform: 3.322567286937966 Unigram: 3.0182541144777817
2022-01-28 18:13:28 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 18:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:16:16 | INFO | train_inner | epoch 113:     32 / 64 loss=5.529, ppl=46.17, wps=5625.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.726, train_wall=520, gb_free=6.1, wall=40984
2022-01-28 18:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:19:31 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.741 | ppl 855.8 | wps 7714.8 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.086
2022-01-28 18:19:31 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 18:19:31 | INFO | train | epoch 113 | loss 5.526 | ppl 46.07 | wps 5753.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.734 | train_wall 333 | gb_free 6.1 | wall 41179
KL Stats: Epoch 113 Divergences: Uniform: 3.3379605477828744 Unigram: 3.025056263313683
2022-01-28 18:19:31 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 18:19:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:25:34 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.755 | ppl 864.33 | wps 7694.9 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.086
2022-01-28 18:25:34 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 18:25:34 | INFO | train | epoch 114 | loss 5.514 | ppl 45.68 | wps 5753.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.755 | train_wall 333 | gb_free 6.1 | wall 41542
KL Stats: Epoch 114 Divergences: Uniform: 3.3245362928587756 Unigram: 3.0285397356899377
2022-01-28 18:25:34 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 18:25:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:25:55 | INFO | train_inner | epoch 115:      4 / 64 loss=5.525, ppl=46.06, wps=5627.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.748, train_wall=520, gb_free=6.1, wall=41563
2022-01-28 18:31:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:31:37 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.806 | ppl 895.38 | wps 7695.1 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.086
2022-01-28 18:31:37 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 18:31:37 | INFO | train | epoch 115 | loss 5.501 | ppl 45.28 | wps 5755.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.745 | train_wall 333 | gb_free 6.1 | wall 41905
KL Stats: Epoch 115 Divergences: Uniform: 3.332626533042681 Unigram: 3.0374235210554152
2022-01-28 18:31:37 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 18:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:35:07 | INFO | train_inner | epoch 116:     40 / 64 loss=5.488, ppl=44.87, wps=5922.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.74, train_wall=521, gb_free=6.1, wall=42115
2022-01-28 18:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:37:40 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.705 | ppl 834.61 | wps 7732.1 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.086
2022-01-28 18:37:40 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 18:37:40 | INFO | train | epoch 116 | loss 5.489 | ppl 44.91 | wps 5752.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.734 | train_wall 333 | gb_free 6.1 | wall 42268
KL Stats: Epoch 116 Divergences: Uniform: 3.3346821674494227 Unigram: 3.042476211184668
2022-01-28 18:37:40 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 18:37:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:43:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:43:43 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.785 | ppl 882.01 | wps 7727.5 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.086
2022-01-28 18:43:43 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 18:43:43 | INFO | train | epoch 117 | loss 5.477 | ppl 44.54 | wps 5758 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.755 | train_wall 333 | gb_free 6.1 | wall 42631
KL Stats: Epoch 117 Divergences: Uniform: 3.3399354593519948 Unigram: 3.0558448716158133
2022-01-28 18:43:43 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 18:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:44:46 | INFO | train_inner | epoch 118:     12 / 64 loss=5.482, ppl=44.69, wps=5630, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.751, train_wall=520, gb_free=6.1, wall=42694
2022-01-28 18:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:49:46 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.788 | ppl 884.28 | wps 7725.9 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.086
2022-01-28 18:49:46 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 18:49:46 | INFO | train | epoch 118 | loss 5.464 | ppl 44.13 | wps 5749.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.743 | train_wall 333 | gb_free 6.1 | wall 42994
KL Stats: Epoch 118 Divergences: Uniform: 3.343852740735199 Unigram: 3.061686890526343
2022-01-28 18:49:46 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 18:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:53:58 | INFO | train_inner | epoch 119:     48 / 64 loss=5.455, ppl=43.87, wps=5921.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.758, train_wall=521, gb_free=6.1, wall=43246
2022-01-28 18:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:55:49 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.786 | ppl 883.13 | wps 7703.9 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.086
2022-01-28 18:55:49 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 18:55:49 | INFO | train | epoch 119 | loss 5.454 | ppl 43.83 | wps 5759.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.776 | train_wall 333 | gb_free 6.1 | wall 43357
KL Stats: Epoch 119 Divergences: Uniform: 3.3488494667327515 Unigram: 3.069325546132582
2022-01-28 18:55:49 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 18:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:01:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:01:52 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.779 | ppl 878.7 | wps 7716.4 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.086
2022-01-28 19:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 19:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint120.pt
2022-01-28 19:01:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint120.pt
2022-01-28 19:01:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.779) (writing took 3.0590412514284253 seconds)
2022-01-28 19:01:55 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 19:01:55 | INFO | train | epoch 120 | loss 5.443 | ppl 43.49 | wps 5700 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.775 | train_wall 333 | gb_free 6.1 | wall 43723
KL Stats: Epoch 120 Divergences: Uniform: 3.3551629140966477 Unigram: 3.079452970955989
2022-01-28 19:01:55 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 19:01:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:03:40 | INFO | train_inner | epoch 121:     20 / 64 loss=5.444, ppl=43.54, wps=5599.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.775, train_wall=520, gb_free=6.1, wall=43828
2022-01-28 19:07:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:07:58 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.809 | ppl 897.25 | wps 7723.1 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.086
2022-01-28 19:07:58 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 19:07:58 | INFO | train | epoch 121 | loss 5.431 | ppl 43.13 | wps 5763.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.767 | train_wall 332 | gb_free 6.1 | wall 44085
KL Stats: Epoch 121 Divergences: Uniform: 3.360283041021531 Unigram: 3.0829059019440077
2022-01-28 19:07:58 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 19:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:12:51 | INFO | train_inner | epoch 122:     56 / 64 loss=5.429, ppl=43.07, wps=5936, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.775, train_wall=520, gb_free=6.1, wall=44378
2022-01-28 19:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:14:00 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.824 | ppl 906.69 | wps 7708.5 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.086
2022-01-28 19:14:00 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 19:14:00 | INFO | train | epoch 122 | loss 5.422 | ppl 42.88 | wps 5769 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.784 | train_wall 332 | gb_free 6.1 | wall 44447
KL Stats: Epoch 122 Divergences: Uniform: 3.3583518454513177 Unigram: 3.0887948240220044
2022-01-28 19:14:00 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 19:14:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:20:02 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.834 | ppl 912.77 | wps 7724 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.086
2022-01-28 19:20:02 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 19:20:02 | INFO | train | epoch 123 | loss 5.409 | ppl 42.5 | wps 5763.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.781 | train_wall 332 | gb_free 6.1 | wall 44810
KL Stats: Epoch 123 Divergences: Uniform: 3.362058570318311 Unigram: 3.0998390424637807
2022-01-28 19:20:02 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 19:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:22:29 | INFO | train_inner | epoch 124:     28 / 64 loss=5.403, ppl=42.32, wps=5638.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.782, train_wall=519, gb_free=6.1, wall=44957
2022-01-28 19:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:26:05 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.824 | ppl 906.55 | wps 7687.9 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.086
2022-01-28 19:26:05 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 19:26:05 | INFO | train | epoch 124 | loss 5.4 | ppl 42.23 | wps 5762 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.79 | train_wall 332 | gb_free 6.1 | wall 45172
KL Stats: Epoch 124 Divergences: Uniform: 3.3492350489417024 Unigram: 3.0951387372167174
2022-01-28 19:26:05 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 19:26:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:31:39 | INFO | train_inner | epoch 125:     64 / 64 loss=5.403, ppl=42.3, wps=5924.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.796, train_wall=519, gb_free=6.1, wall=45507
2022-01-28 19:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:32:08 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.855 | ppl 925.84 | wps 7717.4 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.086
2022-01-28 19:32:08 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 19:32:08 | INFO | train | epoch 125 | loss 5.389 | ppl 41.89 | wps 5756.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.797 | train_wall 333 | gb_free 6.1 | wall 45535
KL Stats: Epoch 125 Divergences: Uniform: 3.36285542605773 Unigram: 3.107663466779063
2022-01-28 19:32:08 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 19:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:37:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:38:10 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.764 | ppl 869.68 | wps 7711.9 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.086
2022-01-28 19:38:10 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 19:38:10 | INFO | train | epoch 126 | loss 5.378 | ppl 41.59 | wps 5769.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.779 | train_wall 332 | gb_free 6.1 | wall 45897
KL Stats: Epoch 126 Divergences: Uniform: 3.369370487600869 Unigram: 3.113407048340961
2022-01-28 19:38:10 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 19:38:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:41:18 | INFO | train_inner | epoch 127:     36 / 64 loss=5.366, ppl=41.24, wps=5643.4, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.793, train_wall=520, gb_free=6.1, wall=46086
2022-01-28 19:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:44:12 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.771 | ppl 873.9 | wps 7717 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.086
2022-01-28 19:44:12 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 19:44:12 | INFO | train | epoch 127 | loss 5.368 | ppl 41.3 | wps 5763.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.81 | train_wall 332 | gb_free 6.1 | wall 46259
KL Stats: Epoch 127 Divergences: Uniform: 3.3669166297209934 Unigram: 3.123678209619738
2022-01-28 19:44:12 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 19:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:49:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:50:15 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.791 | ppl 885.77 | wps 7724.9 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.086
2022-01-28 19:50:15 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 19:50:15 | INFO | train | epoch 128 | loss 5.356 | ppl 40.96 | wps 5757.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.807 | train_wall 333 | gb_free 6.1 | wall 46622
KL Stats: Epoch 128 Divergences: Uniform: 3.371077646745664 Unigram: 3.1273717183935554
2022-01-28 19:50:15 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 19:50:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:50:57 | INFO | train_inner | epoch 129:      8 / 64 loss=5.364, ppl=41.18, wps=5635.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.809, train_wall=519, gb_free=6.1, wall=46664
2022-01-28 19:55:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:56:17 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.77 | ppl 873.26 | wps 7730.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.086
2022-01-28 19:56:17 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 19:56:17 | INFO | train | epoch 129 | loss 5.35 | ppl 40.77 | wps 5762.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.83 | train_wall 333 | gb_free 6.1 | wall 46985
KL Stats: Epoch 129 Divergences: Uniform: 3.3723130549952764 Unigram: 3.13444327472106
2022-01-28 19:56:17 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 19:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:00:08 | INFO | train_inner | epoch 130:     44 / 64 loss=5.338, ppl=40.44, wps=5924.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.815, train_wall=521, gb_free=6.1, wall=47216
2022-01-28 20:01:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:02:21 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.829 | ppl 909.24 | wps 7713.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.086
2022-01-28 20:02:21 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 20:02:21 | INFO | train | epoch 130 | loss 5.338 | ppl 40.45 | wps 5746.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.805 | train_wall 333 | gb_free 6.1 | wall 47348
KL Stats: Epoch 130 Divergences: Uniform: 3.370407725036594 Unigram: 3.1421107702979074
2022-01-28 20:02:21 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 20:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:07:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:08:24 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.796 | ppl 889.1 | wps 7698.9 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.086
2022-01-28 20:08:24 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 20:08:24 | INFO | train | epoch 131 | loss 5.33 | ppl 40.22 | wps 5749.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.825 | train_wall 333 | gb_free 6.1 | wall 47711
KL Stats: Epoch 131 Divergences: Uniform: 3.3697497942052945 Unigram: 3.1428665911627514
2022-01-28 20:08:24 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 20:08:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:09:48 | INFO | train_inner | epoch 132:     16 / 64 loss=5.333, ppl=40.31, wps=5626.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.828, train_wall=520, gb_free=6.1, wall=47795
2022-01-28 20:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:14:27 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.802 | ppl 892.37 | wps 7708.6 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.086
2022-01-28 20:14:27 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 20:14:27 | INFO | train | epoch 132 | loss 5.32 | ppl 39.95 | wps 5753.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.846 | train_wall 333 | gb_free 6.1 | wall 48074
KL Stats: Epoch 132 Divergences: Uniform: 3.38267247009108 Unigram: 3.1523545691028363
2022-01-28 20:14:27 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 20:14:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:19:00 | INFO | train_inner | epoch 133:     52 / 64 loss=5.315, ppl=39.81, wps=5920.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.85, train_wall=521, gb_free=6.1, wall=48347
2022-01-28 20:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:20:30 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.836 | ppl 913.99 | wps 7706.4 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.086
2022-01-28 20:20:30 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 20:20:30 | INFO | train | epoch 133 | loss 5.311 | ppl 39.71 | wps 5757.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.85 | train_wall 333 | gb_free 6.1 | wall 48437
KL Stats: Epoch 133 Divergences: Uniform: 3.389863985038788 Unigram: 3.158255506397828
2022-01-28 20:20:30 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 20:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:26:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:26:33 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.886 | ppl 946.53 | wps 7718.2 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.086
2022-01-28 20:26:33 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 20:26:33 | INFO | train | epoch 134 | loss 5.302 | ppl 39.44 | wps 5749.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.85 | train_wall 333 | gb_free 6.1 | wall 48800
KL Stats: Epoch 134 Divergences: Uniform: 3.3809869494694262 Unigram: 3.162351727326923
2022-01-28 20:26:33 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 20:26:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:28:39 | INFO | train_inner | epoch 135:     24 / 64 loss=5.301, ppl=39.43, wps=5630.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.85, train_wall=520, gb_free=6.1, wall=48926
2022-01-28 20:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:32:36 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.834 | ppl 912.46 | wps 7709 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.086
2022-01-28 20:32:36 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 20:32:36 | INFO | train | epoch 135 | loss 5.293 | ppl 39.2 | wps 5756.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.846 | train_wall 333 | gb_free 6.1 | wall 49163
KL Stats: Epoch 135 Divergences: Uniform: 3.3887039043614453 Unigram: 3.1719262955509393
2022-01-28 20:32:36 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 20:32:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:37:50 | INFO | train_inner | epoch 136:     60 / 64 loss=5.293, ppl=39.2, wps=5927.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.852, train_wall=521, gb_free=6.1, wall=49478
2022-01-28 20:38:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:38:38 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.886 | ppl 946.37 | wps 7723.6 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.086
2022-01-28 20:38:38 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 20:38:38 | INFO | train | epoch 136 | loss 5.283 | ppl 38.95 | wps 5764.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.859 | train_wall 332 | gb_free 6.1 | wall 49526
KL Stats: Epoch 136 Divergences: Uniform: 3.3832490087560796 Unigram: 3.1738830409576986
2022-01-28 20:38:38 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 20:38:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:44:41 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.811 | ppl 898.08 | wps 7729.5 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.086
2022-01-28 20:44:41 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 20:44:41 | INFO | train | epoch 137 | loss 5.275 | ppl 38.71 | wps 5750.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.845 | train_wall 333 | gb_free 6.1 | wall 49889
KL Stats: Epoch 137 Divergences: Uniform: 3.38790715941841 Unigram: 3.1825301104315744
2022-01-28 20:44:41 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 20:44:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:47:29 | INFO | train_inner | epoch 138:     32 / 64 loss=5.267, ppl=38.5, wps=5627.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.849, train_wall=520, gb_free=6.1, wall=50057
2022-01-28 20:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:50:44 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.882 | ppl 943.32 | wps 7718.1 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.086
2022-01-28 20:50:44 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 20:50:44 | INFO | train | epoch 138 | loss 5.267 | ppl 38.5 | wps 5752.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.883 | train_wall 333 | gb_free 6.1 | wall 50252
KL Stats: Epoch 138 Divergences: Uniform: 3.3889928508535045 Unigram: 3.1869167863555448
2022-01-28 20:50:44 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 20:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:56:47 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.817 | ppl 902.23 | wps 7726.5 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.086
2022-01-28 20:56:47 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 20:56:47 | INFO | train | epoch 139 | loss 5.256 | ppl 38.2 | wps 5756.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.867 | train_wall 333 | gb_free 6.1 | wall 50615
KL Stats: Epoch 139 Divergences: Uniform: 3.387236277897306 Unigram: 3.1955786804278796
2022-01-28 20:56:47 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 20:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:57:08 | INFO | train_inner | epoch 140:      4 / 64 loss=5.264, ppl=38.42, wps=5631.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.879, train_wall=520, gb_free=6.1, wall=50636
2022-01-28 21:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:02:49 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.846 | ppl 920.44 | wps 7704.5 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.086
2022-01-28 21:02:49 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 21:02:49 | INFO | train | epoch 140 | loss 5.249 | ppl 38.04 | wps 5770.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.87 | train_wall 332 | gb_free 6.1 | wall 50977
KL Stats: Epoch 140 Divergences: Uniform: 3.385516680350475 Unigram: 3.1998125951236163
2022-01-28 21:02:49 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 21:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:06:19 | INFO | train_inner | epoch 141:     40 / 64 loss=5.242, ppl=37.83, wps=5938.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.871, train_wall=519, gb_free=6.1, wall=51186
2022-01-28 21:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:08:51 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.924 | ppl 971.58 | wps 7727.2 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.086
2022-01-28 21:08:51 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 21:08:51 | INFO | train | epoch 141 | loss 5.241 | ppl 37.82 | wps 5770.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.867 | train_wall 332 | gb_free 6.1 | wall 51339
KL Stats: Epoch 141 Divergences: Uniform: 3.3920368831844474 Unigram: 3.2086601084833193
2022-01-28 21:08:51 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 21:08:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:14:54 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.831 | ppl 910.84 | wps 7735 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.086
2022-01-28 21:14:54 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 21:14:54 | INFO | train | epoch 142 | loss 5.231 | ppl 37.56 | wps 5760.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.899 | train_wall 333 | gb_free 6.1 | wall 51701
KL Stats: Epoch 142 Divergences: Uniform: 3.394930751070784 Unigram: 3.210692334693641
2022-01-28 21:14:54 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 21:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:15:57 | INFO | train_inner | epoch 143:     12 / 64 loss=5.233, ppl=37.61, wps=5638.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.889, train_wall=519, gb_free=6.1, wall=51764
2022-01-28 21:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:20:56 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.873 | ppl 938.02 | wps 7721.2 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.086
2022-01-28 21:20:56 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 21:20:56 | INFO | train | epoch 143 | loss 5.225 | ppl 37.41 | wps 5759.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.893 | train_wall 333 | gb_free 6.1 | wall 52064
KL Stats: Epoch 143 Divergences: Uniform: 3.4041490713543645 Unigram: 3.211666949844022
2022-01-28 21:20:56 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 21:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:25:08 | INFO | train_inner | epoch 144:     48 / 64 loss=5.222, ppl=37.33, wps=5926.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.9, train_wall=521, gb_free=6.1, wall=52316
2022-01-28 21:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:26:59 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.93 | ppl 975.66 | wps 7726.6 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.086
2022-01-28 21:26:59 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 21:26:59 | INFO | train | epoch 144 | loss 5.219 | ppl 37.24 | wps 5753.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.898 | train_wall 333 | gb_free 6.1 | wall 52427
KL Stats: Epoch 144 Divergences: Uniform: 3.3884368777751286 Unigram: 3.2167970908783405
2022-01-28 21:26:59 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 21:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:32:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:33:03 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.879 | ppl 941.84 | wps 7700.9 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.086
2022-01-28 21:33:03 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 21:33:03 | INFO | train | epoch 145 | loss 5.212 | ppl 37.07 | wps 5750.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.931 | train_wall 333 | gb_free 6.1 | wall 52790
KL Stats: Epoch 145 Divergences: Uniform: 3.404453925857849 Unigram: 3.2238305504989793
2022-01-28 21:33:03 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 21:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:34:48 | INFO | train_inner | epoch 146:     20 / 64 loss=5.208, ppl=36.97, wps=5625.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.922, train_wall=520, gb_free=6.1, wall=52895
2022-01-28 21:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:39:06 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.902 | ppl 956.93 | wps 7704.3 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.086
2022-01-28 21:39:06 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 21:39:06 | INFO | train | epoch 146 | loss 5.201 | ppl 36.78 | wps 5748.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.919 | train_wall 333 | gb_free 6.1 | wall 53153
KL Stats: Epoch 146 Divergences: Uniform: 3.4004915597647285 Unigram: 3.2298613569231707
2022-01-28 21:39:06 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 21:39:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:44:00 | INFO | train_inner | epoch 147:     56 / 64 loss=5.202, ppl=36.8, wps=5917.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.909, train_wall=521, gb_free=6.1, wall=53448
2022-01-28 21:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:45:09 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.88 | ppl 942.54 | wps 7724.3 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.086
2022-01-28 21:45:09 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 21:45:09 | INFO | train | epoch 147 | loss 5.193 | ppl 36.58 | wps 5755.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.909 | train_wall 333 | gb_free 6.1 | wall 53516
KL Stats: Epoch 147 Divergences: Uniform: 3.4023881398779627 Unigram: 3.233306895136251
2022-01-28 21:45:09 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 21:45:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:50:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:51:12 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.842 | ppl 917.52 | wps 7704.7 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.086
2022-01-28 21:51:12 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 21:51:12 | INFO | train | epoch 148 | loss 5.186 | ppl 36.41 | wps 5754.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.926 | train_wall 333 | gb_free 6.1 | wall 53879
KL Stats: Epoch 148 Divergences: Uniform: 3.4059172597293372 Unigram: 3.2383489807711356
2022-01-28 21:51:12 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 21:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:53:39 | INFO | train_inner | epoch 149:     28 / 64 loss=5.182, ppl=36.31, wps=5630.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.926, train_wall=520, gb_free=6.1, wall=54026
2022-01-28 21:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:57:15 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.871 | ppl 936.25 | wps 7692.2 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.086
2022-01-28 21:57:15 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 21:57:15 | INFO | train | epoch 149 | loss 5.182 | ppl 36.31 | wps 5744.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.952 | train_wall 334 | gb_free 6.1 | wall 54243
KL Stats: Epoch 149 Divergences: Uniform: 3.4097702641832104 Unigram: 3.2431878912358933
2022-01-28 21:57:15 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 21:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:02:50 | INFO | train_inner | epoch 150:     64 / 64 loss=5.183, ppl=36.33, wps=5916.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.955, train_wall=520, gb_free=6.1, wall=54577
2022-01-28 22:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:03:18 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.87 | ppl 935.63 | wps 7708.9 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.086
2022-01-28 22:03:18 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 22:03:18 | INFO | train | epoch 150 | loss 5.172 | ppl 36.05 | wps 5754.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.944 | train_wall 333 | gb_free 6.1 | wall 54606
KL Stats: Epoch 150 Divergences: Uniform: 3.410738780770469 Unigram: 3.245695623566297
2022-01-28 22:03:18 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 22:03:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:09:21 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.925 | ppl 971.86 | wps 7728.5 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.086
2022-01-28 22:09:21 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 22:09:21 | INFO | train | epoch 151 | loss 5.164 | ppl 35.85 | wps 5754.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.953 | train_wall 333 | gb_free 6.1 | wall 54969
KL Stats: Epoch 151 Divergences: Uniform: 3.401458398850293 Unigram: 3.2501966023095914
2022-01-28 22:09:21 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 22:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:12:31 | INFO | train_inner | epoch 152:     36 / 64 loss=5.152, ppl=35.55, wps=5628.1, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.95, train_wall=521, gb_free=6.1, wall=55158
2022-01-28 22:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:15:25 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.923 | ppl 970.93 | wps 7723.1 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.086
2022-01-28 22:15:25 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 22:15:25 | INFO | train | epoch 152 | loss 5.157 | ppl 35.68 | wps 5746.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.944 | train_wall 334 | gb_free 6.1 | wall 55332
KL Stats: Epoch 152 Divergences: Uniform: 3.413313587347878 Unigram: 3.259726889653043
2022-01-28 22:15:25 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 22:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:20:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:21:27 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.899 | ppl 954.58 | wps 7726.9 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.086
2022-01-28 22:21:27 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 22:21:27 | INFO | train | epoch 153 | loss 5.149 | ppl 35.49 | wps 5760.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.937 | train_wall 333 | gb_free 6.1 | wall 55695
KL Stats: Epoch 153 Divergences: Uniform: 3.4192151240227333 Unigram: 3.2631443112996013
2022-01-28 22:21:27 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 22:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:22:09 | INFO | train_inner | epoch 154:      8 / 64 loss=5.157, ppl=35.69, wps=5632.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.942, train_wall=520, gb_free=6.1, wall=55737
2022-01-28 22:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:27:30 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.967 | ppl 1000.51 | wps 7700.6 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.086
2022-01-28 22:27:30 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 22:27:30 | INFO | train | epoch 154 | loss 5.144 | ppl 35.36 | wps 5754.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.961 | train_wall 333 | gb_free 6.1 | wall 56058
KL Stats: Epoch 154 Divergences: Uniform: 3.4216561770365073 Unigram: 3.2664454483848333
2022-01-28 22:27:30 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 22:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:31:21 | INFO | train_inner | epoch 155:     44 / 64 loss=5.136, ppl=35.16, wps=5921.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.959, train_wall=521, gb_free=6.1, wall=56289
2022-01-28 22:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:33:33 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.956 | ppl 993.06 | wps 7717.7 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.086
2022-01-28 22:33:33 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 22:33:33 | INFO | train | epoch 155 | loss 5.138 | ppl 35.21 | wps 5750.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.965 | train_wall 333 | gb_free 6.1 | wall 56421
KL Stats: Epoch 155 Divergences: Uniform: 3.414455287254391 Unigram: 3.2775118290663716
2022-01-28 22:33:33 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 22:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:39:37 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.932 | ppl 977.03 | wps 7729.3 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.086
2022-01-28 22:39:37 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 22:39:37 | INFO | train | epoch 156 | loss 5.132 | ppl 35.06 | wps 5751.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 0.986 | train_wall 333 | gb_free 6.1 | wall 56784
KL Stats: Epoch 156 Divergences: Uniform: 3.415873908065342 Unigram: 3.2724112334168862
2022-01-28 22:39:37 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 22:39:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:41:01 | INFO | train_inner | epoch 157:     16 / 64 loss=5.137, ppl=35.2, wps=5628.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=0.988, train_wall=520, gb_free=6.1, wall=56868
2022-01-28 22:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:45:40 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.906 | ppl 959.21 | wps 7724.3 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.086
2022-01-28 22:45:40 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 22:45:40 | INFO | train | epoch 157 | loss 5.123 | ppl 34.85 | wps 5754.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 0.987 | train_wall 333 | gb_free 6.1 | wall 57147
KL Stats: Epoch 157 Divergences: Uniform: 3.417323461596933 Unigram: 3.285967290533737
2022-01-28 22:45:40 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 22:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:50:12 | INFO | train_inner | epoch 158:     52 / 64 loss=5.117, ppl=34.7, wps=5921.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.98, train_wall=521, gb_free=6.1, wall=57420
2022-01-28 22:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:51:43 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.031 | ppl 1045.96 | wps 7698.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.086
2022-01-28 22:51:43 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 22:51:43 | INFO | train | epoch 158 | loss 5.119 | ppl 34.75 | wps 5753.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.983 | train_wall 333 | gb_free 6.1 | wall 57510
KL Stats: Epoch 158 Divergences: Uniform: 3.4217430580154398 Unigram: 3.2852025374909055
2022-01-28 22:51:43 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 22:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:57:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:57:46 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.006 | ppl 1028.07 | wps 7690.6 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.086
2022-01-28 22:57:46 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 22:57:46 | INFO | train | epoch 159 | loss 5.11 | ppl 34.54 | wps 5748.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 0.98 | train_wall 333 | gb_free 6.1 | wall 57873
KL Stats: Epoch 159 Divergences: Uniform: 3.411692019943867 Unigram: 3.2936596269349336
2022-01-28 22:57:46 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 22:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:59:52 | INFO | train_inner | epoch 160:     24 / 64 loss=5.111, ppl=34.55, wps=5622.6, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=0.988, train_wall=520, gb_free=6.1, wall=58000
2022-01-28 23:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:03:49 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 9.968 | ppl 1001.4 | wps 7708.8 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.086
2022-01-28 23:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 23:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint160.pt
2022-01-28 23:03:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint160.pt
2022-01-28 23:03:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.07_0.03_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 9.968) (writing took 3.231060119345784 seconds)
2022-01-28 23:03:53 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 23:03:53 | INFO | train | epoch 160 | loss 5.106 | ppl 34.44 | wps 5695.3 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.004 | train_wall 333 | gb_free 6.1 | wall 58240
KL Stats: Epoch 160 Divergences: Uniform: 3.4138535735769056 Unigram: 3.293616888737922
2022-01-28 23:03:53 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 23:03:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:09:08 | INFO | train_inner | epoch 161:     60 / 64 loss=5.106, ppl=34.43, wps=5881.4, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.011, train_wall=522, gb_free=6.1, wall=58555
2022-01-28 23:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:09:56 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.941 | ppl 983.29 | wps 7676.2 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.086
2022-01-28 23:09:56 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 23:09:56 | INFO | train | epoch 161 | loss 5.098 | ppl 34.26 | wps 5748.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.019 | train_wall 333 | gb_free 6.1 | wall 58604
KL Stats: Epoch 161 Divergences: Uniform: 3.4251210749863628 Unigram: 3.297561035757323
2022-01-28 23:09:56 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 23:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:16:00 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 9.935 | ppl 978.68 | wps 7690.6 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.086
2022-01-28 23:16:00 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 23:16:00 | INFO | train | epoch 162 | loss 5.092 | ppl 34.12 | wps 5742.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.006 | train_wall 334 | gb_free 6.1 | wall 58967
KL Stats: Epoch 162 Divergences: Uniform: 3.4282281001938006 Unigram: 3.303149967367153
2022-01-28 23:16:00 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 23:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:18:48 | INFO | train_inner | epoch 163:     32 / 64 loss=5.08, ppl=33.82, wps=5621.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.006, train_wall=521, gb_free=6.1, wall=59135
2022-01-28 23:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:22:03 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.003 | ppl 1026.37 | wps 7713.9 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.086
2022-01-28 23:22:03 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 23:22:03 | INFO | train | epoch 163 | loss 5.088 | ppl 34.01 | wps 5752 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.012 | train_wall 333 | gb_free 6.1 | wall 59330
KL Stats: Epoch 163 Divergences: Uniform: 3.4238619486914175 Unigram: 3.3079730381819603
2022-01-28 23:22:03 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 23:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:28:06 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 9.946 | ppl 986.3 | wps 7715.6 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.086
2022-01-28 23:28:06 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 23:28:06 | INFO | train | epoch 164 | loss 5.079 | ppl 33.81 | wps 5748.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.018 | train_wall 333 | gb_free 6.1 | wall 59694
KL Stats: Epoch 164 Divergences: Uniform: 3.4191067327777915 Unigram: 3.3109038783029825
2022-01-28 23:28:06 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 23:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:28:27 | INFO | train_inner | epoch 165:      4 / 64 loss=5.094, ppl=34.16, wps=5626.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.019, train_wall=520, gb_free=6.1, wall=59715
2022-01-28 23:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:34:09 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.986 | ppl 1014.46 | wps 7724.5 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.086
2022-01-28 23:34:09 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 23:34:09 | INFO | train | epoch 165 | loss 5.073 | ppl 33.66 | wps 5757.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.004 | train_wall 333 | gb_free 6.1 | wall 60057
KL Stats: Epoch 165 Divergences: Uniform: 3.430436032960217 Unigram: 3.318985751508026
2022-01-28 23:34:09 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 23:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:37:39 | INFO | train_inner | epoch 166:     40 / 64 loss=5.066, ppl=33.5, wps=5924.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.026, train_wall=521, gb_free=6.1, wall=60266
2022-01-28 23:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:40:12 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 9.938 | ppl 980.83 | wps 7692.2 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.086
2022-01-28 23:40:12 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 23:40:12 | INFO | train | epoch 166 | loss 5.069 | ppl 33.56 | wps 5752 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.05 | train_wall 333 | gb_free 6.1 | wall 60420
KL Stats: Epoch 166 Divergences: Uniform: 3.4293252963571086 Unigram: 3.3209965693596146
2022-01-28 23:40:12 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 23:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:46:15 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 9.9 | ppl 955.24 | wps 7706.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.086
2022-01-28 23:46:15 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-28 23:46:15 | INFO | train | epoch 167 | loss 5.061 | ppl 33.39 | wps 5751 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.023 | train_wall 333 | gb_free 6.1 | wall 60783
KL Stats: Epoch 167 Divergences: Uniform: 3.4240554776976917 Unigram: 3.3220208507085767
2022-01-28 23:46:15 | INFO | fairseq.trainer | begin training epoch 168
2022-01-28 23:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:47:18 | INFO | train_inner | epoch 168:     12 / 64 loss=5.063, ppl=33.43, wps=5625.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.024, train_wall=520, gb_free=6.1, wall=60846
2022-01-28 23:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:52:18 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 9.993 | ppl 1019.24 | wps 7732.6 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.086
2022-01-28 23:52:18 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-28 23:52:18 | INFO | train | epoch 168 | loss 5.057 | ppl 33.28 | wps 5749.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.046 | train_wall 333 | gb_free 6.1 | wall 61146
KL Stats: Epoch 168 Divergences: Uniform: 3.4289850045774335 Unigram: 3.322926632097653
2022-01-28 23:52:18 | INFO | fairseq.trainer | begin training epoch 169
2022-01-28 23:52:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:56:31 | INFO | train_inner | epoch 169:     48 / 64 loss=5.056, ppl=33.27, wps=5915, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.054, train_wall=522, gb_free=6.1, wall=61398
2022-01-28 23:57:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:58:22 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 9.97 | ppl 1003.1 | wps 7728.2 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.086
2022-01-28 23:58:22 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-28 23:58:22 | INFO | train | epoch 169 | loss 5.051 | ppl 33.14 | wps 5746.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.057 | train_wall 333 | gb_free 6.1 | wall 61509
KL Stats: Epoch 169 Divergences: Uniform: 3.4325118842677336 Unigram: 3.332145320855931
2022-01-28 23:58:22 | INFO | fairseq.trainer | begin training epoch 170
2022-01-28 23:58:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:04:25 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 9.998 | ppl 1022.37 | wps 7700 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.086
2022-01-29 00:04:25 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-29 00:04:25 | INFO | train | epoch 170 | loss 5.045 | ppl 33.02 | wps 5749.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.057 | train_wall 333 | gb_free 6.1 | wall 61873
KL Stats: Epoch 170 Divergences: Uniform: 3.435744428973276 Unigram: 3.3385492730976685
2022-01-29 00:04:25 | INFO | fairseq.trainer | begin training epoch 171
2022-01-29 00:04:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:06:10 | INFO | train_inner | epoch 171:     20 / 64 loss=5.04, ppl=32.89, wps=5627, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.063, train_wall=520, gb_free=6.1, wall=61978
2022-01-29 00:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:10:28 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 9.931 | ppl 976.2 | wps 7703.8 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.086
2022-01-29 00:10:28 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-29 00:10:28 | INFO | train | epoch 171 | loss 5.042 | ppl 32.94 | wps 5759 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.103 | train_wall 333 | gb_free 6.1 | wall 62235
KL Stats: Epoch 171 Divergences: Uniform: 3.4342216749060066 Unigram: 3.3393093759728916
2022-01-29 00:10:28 | INFO | fairseq.trainer | begin training epoch 172
2022-01-29 00:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:15:21 | INFO | train_inner | epoch 172:     56 / 64 loss=5.044, ppl=32.99, wps=5927.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.085, train_wall=520, gb_free=6.1, wall=62529
2022-01-29 00:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:16:31 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 9.961 | ppl 996.91 | wps 7705.3 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.086
2022-01-29 00:16:31 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-29 00:16:31 | INFO | train | epoch 172 | loss 5.034 | ppl 32.76 | wps 5758.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.067 | train_wall 333 | gb_free 6.1 | wall 62598
KL Stats: Epoch 172 Divergences: Uniform: 3.432538634028056 Unigram: 3.339983572708042
2022-01-29 00:16:31 | INFO | fairseq.trainer | begin training epoch 173
2022-01-29 00:16:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:22:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:22:33 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.919 | ppl 968.09 | wps 7710.9 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.086
2022-01-29 00:22:33 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-29 00:22:33 | INFO | train | epoch 173 | loss 5.028 | ppl 32.63 | wps 5758 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.124 | train_wall 333 | gb_free 6.1 | wall 62961
KL Stats: Epoch 173 Divergences: Uniform: 3.4340110284404863 Unigram: 3.3430172623500156
2022-01-29 00:22:33 | INFO | fairseq.trainer | begin training epoch 174
2022-01-29 00:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:25:01 | INFO | train_inner | epoch 174:     28 / 64 loss=5.022, ppl=32.5, wps=5629.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.105, train_wall=520, gb_free=6.1, wall=63108
2022-01-29 00:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:28:37 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.012 | ppl 1032.39 | wps 7700.6 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.086
2022-01-29 00:28:37 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-29 00:28:37 | INFO | train | epoch 174 | loss 5.024 | ppl 32.53 | wps 5743.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.096 | train_wall 334 | gb_free 6.1 | wall 63325
KL Stats: Epoch 174 Divergences: Uniform: 3.433180902250809 Unigram: 3.351150480525207
2022-01-29 00:28:37 | INFO | fairseq.trainer | begin training epoch 175
2022-01-29 00:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:34:12 | INFO | train_inner | epoch 175:     64 / 64 loss=5.027, ppl=32.6, wps=5912.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.107, train_wall=520, gb_free=6.1, wall=63660
2022-01-29 00:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:34:40 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.976 | ppl 1007.03 | wps 7699.9 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.086
2022-01-29 00:34:40 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-29 00:34:40 | INFO | train | epoch 175 | loss 5.017 | ppl 32.37 | wps 5748.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.098 | train_wall 333 | gb_free 6.1 | wall 63688
KL Stats: Epoch 175 Divergences: Uniform: 3.440384923009623 Unigram: 3.3561049356388613
2022-01-29 00:34:40 | INFO | fairseq.trainer | begin training epoch 176
2022-01-29 00:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:40:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:40:43 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.999 | ppl 1023.61 | wps 7739.6 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.086
2022-01-29 00:40:43 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-29 00:40:43 | INFO | train | epoch 176 | loss 5.012 | ppl 32.26 | wps 5752.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.074 | train_wall 333 | gb_free 6.1 | wall 64051
KL Stats: Epoch 176 Divergences: Uniform: 3.438187478755878 Unigram: 3.3594038187002426
2022-01-29 00:40:43 | INFO | fairseq.trainer | begin training epoch 177
2022-01-29 00:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:43:52 | INFO | train_inner | epoch 177:     36 / 64 loss=5, ppl=32.01, wps=5632.5, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.093, train_wall=521, gb_free=6.1, wall=64240
2022-01-29 00:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:46:47 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.966 | ppl 1000.38 | wps 7678.9 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.086
2022-01-29 00:46:47 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-29 00:46:47 | INFO | train | epoch 177 | loss 5.008 | ppl 32.18 | wps 5750.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.127 | train_wall 333 | gb_free 6.1 | wall 64414
KL Stats: Epoch 177 Divergences: Uniform: 3.435610529903407 Unigram: 3.358416817635893
2022-01-29 00:46:47 | INFO | fairseq.trainer | begin training epoch 178
2022-01-29 00:46:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:52:50 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.997 | ppl 1021.73 | wps 7724.1 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.086
2022-01-29 00:52:50 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-29 00:52:50 | INFO | train | epoch 178 | loss 5.003 | ppl 32.07 | wps 5748.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.097 | train_wall 333 | gb_free 6.1 | wall 64777
KL Stats: Epoch 178 Divergences: Uniform: 3.4458926183300127 Unigram: 3.365866130688325
2022-01-29 00:52:50 | INFO | fairseq.trainer | begin training epoch 179
2022-01-29 00:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:53:32 | INFO | train_inner | epoch 179:      8 / 64 loss=5.011, ppl=32.24, wps=5622.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.107, train_wall=520, gb_free=6.1, wall=64820
2022-01-29 00:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:58:53 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.956 | ppl 993.38 | wps 7700.8 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.086
2022-01-29 00:58:53 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-29 00:58:53 | INFO | train | epoch 179 | loss 4.998 | ppl 31.95 | wps 5750.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.135 | train_wall 333 | gb_free 6.1 | wall 65141
KL Stats: Epoch 179 Divergences: Uniform: 3.4462023767639782 Unigram: 3.3667320223104356
2022-01-29 00:58:53 | INFO | fairseq.trainer | begin training epoch 180
2022-01-29 00:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:02:45 | INFO | train_inner | epoch 180:     44 / 64 loss=4.993, ppl=31.84, wps=5912.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.133, train_wall=522, gb_free=6.1, wall=65372
2022-01-29 01:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:04:57 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.957 | ppl 994.01 | wps 7700.6 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.086
2022-01-29 01:04:57 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-29 01:04:57 | INFO | train | epoch 180 | loss 4.992 | ppl 31.83 | wps 5742.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.135 | train_wall 334 | gb_free 6.1 | wall 65504
KL Stats: Epoch 180 Divergences: Uniform: 3.445389316074593 Unigram: 3.3719773966632203
2022-01-29 01:04:57 | INFO | fairseq.trainer | begin training epoch 181
2022-01-29 01:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:11:00 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.992 | ppl 1018.46 | wps 7680.4 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.086
2022-01-29 01:11:00 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-29 01:11:00 | INFO | train | epoch 181 | loss 4.985 | ppl 31.68 | wps 5758.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.123 | train_wall 333 | gb_free 6.1 | wall 65867
KL Stats: Epoch 181 Divergences: Uniform: 3.4482983679333317 Unigram: 3.3769432284596017
2022-01-29 01:11:00 | INFO | fairseq.trainer | begin training epoch 182
2022-01-29 01:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:12:24 | INFO | train_inner | epoch 182:     16 / 64 loss=4.986, ppl=31.7, wps=5629.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.13, train_wall=520, gb_free=6.1, wall=65951
2022-01-29 01:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:17:03 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.989 | ppl 1016.36 | wps 7708.9 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.086
2022-01-29 01:17:03 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-29 01:17:03 | INFO | train | epoch 182 | loss 4.984 | ppl 31.65 | wps 5745.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.157 | train_wall 334 | gb_free 6.1 | wall 66231
KL Stats: Epoch 182 Divergences: Uniform: 3.443017642126579 Unigram: 3.3758879992573516
2022-01-29 01:17:03 | INFO | fairseq.trainer | begin training epoch 183
2022-01-29 01:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:21:36 | INFO | train_inner | epoch 183:     52 / 64 loss=4.982, ppl=31.6, wps=5915, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.163, train_wall=522, gb_free=6.1, wall=66504
2022-01-29 01:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:23:06 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.981 | ppl 1010.42 | wps 7712.9 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.086
2022-01-29 01:23:06 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-29 01:23:06 | INFO | train | epoch 183 | loss 4.977 | ppl 31.5 | wps 5747.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.157 | train_wall 333 | gb_free 6.1 | wall 66594
KL Stats: Epoch 183 Divergences: Uniform: 3.4472591923545637 Unigram: 3.3812509979928698
2022-01-29 01:23:06 | INFO | fairseq.trainer | begin training epoch 184
2022-01-29 01:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:29:10 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.963 | ppl 998.32 | wps 7712 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.086
2022-01-29 01:29:10 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-29 01:29:10 | INFO | train | epoch 184 | loss 4.973 | ppl 31.41 | wps 5749.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.188 | train_wall 333 | gb_free 6.1 | wall 66957
KL Stats: Epoch 184 Divergences: Uniform: 3.442044993797197 Unigram: 3.383626996703641
2022-01-29 01:29:10 | INFO | fairseq.trainer | begin training epoch 185
2022-01-29 01:29:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:31:16 | INFO | train_inner | epoch 185:     24 / 64 loss=4.973, ppl=31.41, wps=5626.2, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.179, train_wall=520, gb_free=6.1, wall=67083
2022-01-29 01:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:35:13 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.025 | ppl 1042.05 | wps 7697.5 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.086
2022-01-29 01:35:13 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 01:35:13 | INFO | train | epoch 185 | loss 4.969 | ppl 31.31 | wps 5755.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.176 | train_wall 333 | gb_free 6.1 | wall 67320
KL Stats: Epoch 185 Divergences: Uniform: 3.446237867798109 Unigram: 3.389772678659696
2022-01-29 01:35:13 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 01:35:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:40:28 | INFO | train_inner | epoch 186:     60 / 64 loss=4.969, ppl=31.33, wps=5919, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.188, train_wall=521, gb_free=6.1, wall=67635
2022-01-29 01:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:41:16 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.936 | ppl 979.79 | wps 7724.3 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.086
2022-01-29 01:41:16 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 01:41:16 | INFO | train | epoch 186 | loss 4.966 | ppl 31.25 | wps 5750.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.201 | train_wall 333 | gb_free 6.1 | wall 67683
KL Stats: Epoch 186 Divergences: Uniform: 3.4504766095970347 Unigram: 3.3905366103066057
2022-01-29 01:41:16 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 01:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:47:19 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.965 | ppl 999.17 | wps 7700.5 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.086
2022-01-29 01:47:19 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 01:47:19 | INFO | train | epoch 187 | loss 4.96 | ppl 31.13 | wps 5753.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.198 | train_wall 333 | gb_free 6.1 | wall 68046
KL Stats: Epoch 187 Divergences: Uniform: 3.446418263358748 Unigram: 3.395335888471066
2022-01-29 01:47:19 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 01:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:50:07 | INFO | train_inner | epoch 188:     32 / 64 loss=4.953, ppl=30.98, wps=5626.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.189, train_wall=520, gb_free=6.1, wall=68215
2022-01-29 01:52:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:53:22 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.977 | ppl 1008.06 | wps 7711.5 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.086
2022-01-29 01:53:22 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 01:53:22 | INFO | train | epoch 188 | loss 4.953 | ppl 30.97 | wps 5744.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.187 | train_wall 334 | gb_free 6.1 | wall 68410
KL Stats: Epoch 188 Divergences: Uniform: 3.449181052033128 Unigram: 3.4017395147788383
2022-01-29 01:53:22 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 01:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:58:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:59:26 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.977 | ppl 1007.6 | wps 7702.3 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.086
2022-01-29 01:59:26 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 01:59:26 | INFO | train | epoch 189 | loss 4.95 | ppl 30.91 | wps 5751.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.226 | train_wall 333 | gb_free 6.1 | wall 68773
KL Stats: Epoch 189 Divergences: Uniform: 3.449695824624378 Unigram: 3.4024041121237762
2022-01-29 01:59:26 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 01:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:59:47 | INFO | train_inner | epoch 190:      4 / 64 loss=4.955, ppl=31.02, wps=5625.5, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.219, train_wall=520, gb_free=6.1, wall=68794
2022-01-29 02:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:05:28 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.97 | ppl 1002.99 | wps 7712.5 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.086
2022-01-29 02:05:28 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 02:05:28 | INFO | train | epoch 190 | loss 4.945 | ppl 30.81 | wps 5756.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.201 | train_wall 333 | gb_free 6.1 | wall 69136
KL Stats: Epoch 190 Divergences: Uniform: 3.4531377546003115 Unigram: 3.403845211372765
2022-01-29 02:05:28 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 02:05:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:08:59 | INFO | train_inner | epoch 191:     40 / 64 loss=4.935, ppl=30.58, wps=5922.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.214, train_wall=521, gb_free=6.1, wall=69346
2022-01-29 02:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:11:31 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.974 | ppl 1005.76 | wps 7737.7 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.086
2022-01-29 02:11:31 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 02:11:31 | INFO | train | epoch 191 | loss 4.942 | ppl 30.73 | wps 5759.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.233 | train_wall 333 | gb_free 6.1 | wall 69499
KL Stats: Epoch 191 Divergences: Uniform: 3.4517504700120165 Unigram: 3.4068377335443003
2022-01-29 02:11:31 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 02:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:17:34 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.974 | ppl 1005.49 | wps 7729.3 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.086
2022-01-29 02:17:34 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 02:17:34 | INFO | train | epoch 192 | loss 4.939 | ppl 30.66 | wps 5759.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.267 | train_wall 333 | gb_free 6.1 | wall 69861
KL Stats: Epoch 192 Divergences: Uniform: 3.449524972367911 Unigram: 3.404550037858119
2022-01-29 02:17:34 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 02:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:18:37 | INFO | train_inner | epoch 193:     12 / 64 loss=4.944, ppl=30.79, wps=5639.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.263, train_wall=519, gb_free=6.1, wall=69924
2022-01-29 02:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:23:36 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.97 | ppl 1002.96 | wps 7746.2 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.086
2022-01-29 02:23:36 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 02:23:36 | INFO | train | epoch 193 | loss 4.932 | ppl 30.53 | wps 5760.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.233 | train_wall 333 | gb_free 6.1 | wall 70224
KL Stats: Epoch 193 Divergences: Uniform: 3.45513824881102 Unigram: 3.4117442237711777
2022-01-29 02:23:36 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 02:23:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:27:48 | INFO | train_inner | epoch 194:     48 / 64 loss=4.929, ppl=30.46, wps=5926.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.245, train_wall=521, gb_free=6.1, wall=70476
2022-01-29 02:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:29:39 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.025 | ppl 1041.95 | wps 7707 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.086
2022-01-29 02:29:39 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 02:29:39 | INFO | train | epoch 194 | loss 4.928 | ppl 30.43 | wps 5761.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.265 | train_wall 333 | gb_free 6.1 | wall 70586
KL Stats: Epoch 194 Divergences: Uniform: 3.4543072219642066 Unigram: 3.4138664823609144
2022-01-29 02:29:39 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 02:29:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:35:42 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.005 | ppl 1027.75 | wps 7702.7 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.086
2022-01-29 02:35:42 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 02:35:42 | INFO | train | epoch 195 | loss 4.926 | ppl 30.39 | wps 5752 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.28 | train_wall 333 | gb_free 6.1 | wall 70950
KL Stats: Epoch 195 Divergences: Uniform: 3.451686950138395 Unigram: 3.4171892387095526
2022-01-29 02:35:42 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 02:35:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:37:27 | INFO | train_inner | epoch 196:     20 / 64 loss=4.923, ppl=30.34, wps=5630.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.26, train_wall=520, gb_free=6.1, wall=71055
2022-01-29 02:41:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:41:45 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.981 | ppl 1010.79 | wps 7734 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.086
2022-01-29 02:41:45 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 02:41:45 | INFO | train | epoch 196 | loss 4.921 | ppl 30.3 | wps 5759.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.258 | train_wall 333 | gb_free 6.1 | wall 71312
KL Stats: Epoch 196 Divergences: Uniform: 3.453346077093166 Unigram: 3.4189327381157737
2022-01-29 02:41:45 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 02:41:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:46:38 | INFO | train_inner | epoch 197:     56 / 64 loss=4.922, ppl=30.31, wps=5932.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.289, train_wall=520, gb_free=6.1, wall=71606
2022-01-29 02:47:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:47:47 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.966 | ppl 1000.21 | wps 7721.1 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.086
2022-01-29 02:47:47 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 02:47:47 | INFO | train | epoch 197 | loss 4.917 | ppl 30.21 | wps 5768.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.306 | train_wall 332 | gb_free 6.1 | wall 71674
KL Stats: Epoch 197 Divergences: Uniform: 3.450138818831429 Unigram: 3.4169446697141983
2022-01-29 02:47:47 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 02:47:47 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
