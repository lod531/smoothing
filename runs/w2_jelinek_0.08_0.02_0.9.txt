Sender: LSF System <lsfadmin@eu-g2-15>
Subject: Job 202286040: <w2_jelinek_0.08_0.02_0.9> in cluster <euler> Exited

Job <w2_jelinek_0.08_0.02_0.9> was submitted from host <eu-login-22> by user <andriusb> in cluster <euler> at Fri Jan 28 06:51:54 2022
Job was executed on host(s) <eu-g2-15>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Fri Jan 28 06:52:22 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Fri Jan 28 06:52:22 2022
Terminated at Sat Jan 29 02:52:32 2022
Results reported at Sat Jan 29 02:52:32 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.08, 0.02, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72717.00 sec.
    Max Memory :                                 6038 MB
    Average Memory :                             3628.30 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13962.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72008 sec.
    Turnaround time :                            72038 sec.

The output (if any) follows:

2022-01-28 06:52:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.08, 0.02, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-28 06:52:30 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-28 06:52:31 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▍         | 1421/36718 [00:00<00:02, 14198.03it/s]  8%|▊         | 2841/36718 [00:00<00:02, 13774.35it/s] 12%|█▏        | 4455/36718 [00:00<00:02, 14834.98it/s] 17%|█▋        | 6068/36718 [00:00<00:02, 15322.08it/s] 21%|██        | 7602/36718 [00:00<00:02, 14555.17it/s] 25%|██▍       | 9065/36718 [00:00<00:01, 14516.71it/s] 29%|██▊       | 10522/36718 [00:00<00:01, 14285.89it/s] 33%|███▎      | 11954/36718 [00:00<00:01, 14288.75it/s] 36%|███▋      | 13386/36718 [00:00<00:01, 14266.39it/s] 41%|████      | 14895/36718 [00:01<00:01, 14514.44it/s] 45%|████▍     | 16348/36718 [00:01<00:01, 14290.20it/s] 48%|████▊     | 17804/36718 [00:01<00:01, 14368.81it/s] 53%|█████▎    | 19419/36718 [00:01<00:01, 14898.04it/s] 57%|█████▋    | 20911/36718 [00:01<00:01, 14538.53it/s] 61%|██████    | 22368/36718 [00:01<00:00, 14479.84it/s] 65%|██████▌   | 24018/36718 [00:01<00:00, 15074.10it/s] 70%|██████▉   | 25621/36718 [00:01<00:00, 15346.59it/s] 74%|███████▍  | 27158/36718 [00:01<00:00, 14650.90it/s] 78%|███████▊  | 28716/36718 [00:01<00:00, 14918.51it/s] 82%|████████▏ | 30215/36718 [00:02<00:00, 14509.11it/s] 86%|████████▋ | 31672/36718 [00:02<00:00, 14217.88it/s] 90%|█████████ | 33099/36718 [00:02<00:00, 13725.12it/s] 94%|█████████▍| 34638/36718 [00:02<00:00, 14196.70it/s] 98%|█████████▊| 36065/36718 [00:02<00:00, 13924.20it/s]100%|██████████| 36718/36718 [00:02<00:00, 14440.90it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  8%|▊         | 2775/36718 [00:00<00:01, 27740.44it/s] 16%|█▋        | 6022/36718 [00:00<00:01, 30516.68it/s] 25%|██▍       | 9074/36718 [00:00<00:00, 29095.44it/s] 33%|███▎      | 11991/36718 [00:00<00:00, 29024.63it/s] 41%|████      | 14898/36718 [00:00<00:00, 29029.90it/s] 48%|████▊     | 17804/36718 [00:00<00:00, 28887.30it/s] 57%|█████▋    | 20767/36718 [00:00<00:00, 29125.63it/s] 65%|██████▍   | 23723/36718 [00:00<00:00, 29260.11it/s] 73%|███████▎  | 26753/36718 [00:00<00:00, 29582.52it/s] 81%|████████  | 29713/36718 [00:01<00:00, 29377.88it/s] 89%|████████▉ | 32652/36718 [00:01<00:00, 28726.28it/s] 97%|█████████▋| 35528/36718 [00:01<00:00, 28725.14it/s]100%|██████████| 36718/36718 [00:01<00:00, 29029.39it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 74.21it/s]2022-01-28 06:52:45 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-28 06:52:45 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-28 06:52:45 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-28 06:52:45 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-28 06:52:45 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-28 06:52:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-28 06:52:45 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-28 06:52:45 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-28 06:52:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 06:52:45 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-01-28 06:52:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-28 06:52:45 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-28 06:52:45 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-28 06:52:45 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint_last.pt
2022-01-28 06:52:45 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint_last.pt
2022-01-28 06:52:45 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-28 06:52:45 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-28 06:52:45 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-28 06:52:45 | INFO | fairseq.trainer | begin training epoch 1
2022-01-28 06:52:45 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-28 06:57:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-28 06:58:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.664 | ppl 25957.1 | wps 8468 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-28 06:58:20 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-28 06:58:20 | INFO | train | epoch 001 | loss 16.133 | ppl 71878.1 | wps 6263 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.308 | train_wall 308 | gb_free 6.1 | wall 335
KL Stats: Epoch 1 Divergences: Uniform: 0.5173801774191317 Unigram: 3.685053322720517
2022-01-28 06:58:20 | INFO | fairseq.trainer | begin training epoch 2
2022-01-28 06:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:01:14 | INFO | train_inner | epoch 002:     36 / 64 loss=15.581, ppl=49009, wps=6443.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.711, train_wall=481, gb_free=6.1, wall=509
2022-01-28 07:03:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:03:54 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.641 | ppl 12772.1 | wps 8517.6 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-28 07:03:54 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-28 07:03:54 | INFO | train | epoch 002 | loss 14.385 | ppl 21392.3 | wps 6260.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.529 | train_wall 307 | gb_free 6.1 | wall 669
KL Stats: Epoch 2 Divergences: Uniform: 0.5364236072916165 Unigram: 2.414200696636188
2022-01-28 07:03:54 | INFO | fairseq.trainer | begin training epoch 3
2022-01-28 07:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:09:27 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.801 | ppl 7135.49 | wps 8502.6 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-28 07:09:27 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-28 07:09:27 | INFO | train | epoch 003 | loss 13.461 | ppl 11274.8 | wps 6268.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.234 | train_wall 307 | gb_free 6.1 | wall 1002
KL Stats: Epoch 3 Divergences: Uniform: 0.5244610114357919 Unigram: 1.7292314146129069
2022-01-28 07:09:27 | INFO | fairseq.trainer | begin training epoch 4
2022-01-28 07:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:10:06 | INFO | train_inner | epoch 004:      8 / 64 loss=13.597, ppl=12390.2, wps=6132.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.263, train_wall=479, gb_free=6.1, wall=1041
2022-01-28 07:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:15:00 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.932 | ppl 3908.21 | wps 8548.1 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-28 07:15:00 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-28 07:15:00 | INFO | train | epoch 004 | loss 12.494 | ppl 5766.85 | wps 6268.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.984 | train_wall 307 | gb_free 6.1 | wall 1335
KL Stats: Epoch 4 Divergences: Uniform: 0.6129015052366193 Unigram: 1.1083006395586745
2022-01-28 07:15:00 | INFO | fairseq.trainer | begin training epoch 5
2022-01-28 07:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:18:32 | INFO | train_inner | epoch 005:     44 / 64 loss=12.135, ppl=4498.89, wps=6453.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.863, train_wall=480, gb_free=6.1, wall=1547
2022-01-28 07:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:20:33 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.401 | ppl 2704.82 | wps 8503 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-28 07:20:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-28 07:20:33 | INFO | train | epoch 005 | loss 11.676 | ppl 3271.72 | wps 6273.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.7 | train_wall 306 | gb_free 6.1 | wall 1668
KL Stats: Epoch 5 Divergences: Uniform: 0.8636519084016958 Unigram: 0.6478378792841911
2022-01-28 07:20:33 | INFO | fairseq.trainer | begin training epoch 6
2022-01-28 07:20:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:26:07 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.154 | ppl 2279.47 | wps 8503.2 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-28 07:26:07 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-28 07:26:07 | INFO | train | epoch 006 | loss 11.232 | ppl 2405.81 | wps 6264 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.591 | train_wall 307 | gb_free 6.1 | wall 2002
KL Stats: Epoch 6 Divergences: Uniform: 1.178841494423942 Unigram: 0.43796408231979045
2022-01-28 07:26:07 | INFO | fairseq.trainer | begin training epoch 7
2022-01-28 07:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:27:24 | INFO | train_inner | epoch 007:     16 / 64 loss=11.255, ppl=2444.78, wps=6131.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.59, train_wall=479, gb_free=6.1, wall=2079
2022-01-28 07:31:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:31:40 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.013 | ppl 2066.79 | wps 8504.4 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-28 07:31:40 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-28 07:31:40 | INFO | train | epoch 007 | loss 11.028 | ppl 2087.85 | wps 6268.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.525 | train_wall 307 | gb_free 6.1 | wall 2335
KL Stats: Epoch 7 Divergences: Uniform: 1.4230790631378485 Unigram: 0.43851688058440863
2022-01-28 07:31:40 | INFO | fairseq.trainer | begin training epoch 8
2022-01-28 07:31:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:35:51 | INFO | train_inner | epoch 008:     52 / 64 loss=10.967, ppl=2001.22, wps=6444, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.518, train_wall=480, gb_free=6.1, wall=2586
2022-01-28 07:36:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:37:14 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.911 | ppl 1925.97 | wps 8523.6 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-28 07:37:14 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-28 07:37:14 | INFO | train | epoch 008 | loss 10.915 | ppl 1931.41 | wps 6259.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.513 | train_wall 307 | gb_free 6.1 | wall 2668
KL Stats: Epoch 8 Divergences: Uniform: 1.5542552727251862 Unigram: 0.5026875627448281
2022-01-28 07:37:14 | INFO | fairseq.trainer | begin training epoch 9
2022-01-28 07:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:42:47 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.797 | ppl 1779.55 | wps 8503.7 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-28 07:42:47 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-28 07:42:47 | INFO | train | epoch 009 | loss 10.812 | ppl 1798.31 | wps 6269.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.487 | train_wall 307 | gb_free 6.1 | wall 3002
KL Stats: Epoch 9 Divergences: Uniform: 1.6092375539643364 Unigram: 0.5913813915508777
2022-01-28 07:42:47 | INFO | fairseq.trainer | begin training epoch 10
2022-01-28 07:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:44:43 | INFO | train_inner | epoch 010:     24 / 64 loss=10.804, ppl=1787.28, wps=6133.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.489, train_wall=479, gb_free=6.1, wall=3117
2022-01-28 07:47:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:48:21 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.695 | ppl 1658.22 | wps 8477.7 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-28 07:48:21 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-28 07:48:21 | INFO | train | epoch 010 | loss 10.706 | ppl 1670.41 | wps 6253.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.483 | train_wall 307 | gb_free 6.1 | wall 3336
KL Stats: Epoch 10 Divergences: Uniform: 1.6390500871858964 Unigram: 0.6888151387347151
2022-01-28 07:48:21 | INFO | fairseq.trainer | begin training epoch 11
2022-01-28 07:48:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:53:11 | INFO | train_inner | epoch 011:     60 / 64 loss=10.632, ppl=1586.4, wps=6426.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=481, gb_free=6.1, wall=3626
2022-01-28 07:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:53:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.589 | ppl 1540.05 | wps 8472.4 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-28 07:53:55 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-28 07:53:55 | INFO | train | epoch 011 | loss 10.593 | ppl 1544.14 | wps 6247.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.5 | train_wall 308 | gb_free 6.1 | wall 3670
KL Stats: Epoch 11 Divergences: Uniform: 1.659925221126978 Unigram: 0.7846113919047742
2022-01-28 07:53:55 | INFO | fairseq.trainer | begin training epoch 12
2022-01-28 07:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 07:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 07:59:29 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.483 | ppl 1431.25 | wps 8539.9 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-28 07:59:29 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-28 07:59:29 | INFO | train | epoch 012 | loss 10.477 | ppl 1425.5 | wps 6260.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.476 | train_wall 307 | gb_free 6.1 | wall 4003
KL Stats: Epoch 12 Divergences: Uniform: 1.6720524535833123 Unigram: 0.8788581744226625
2022-01-28 07:59:29 | INFO | fairseq.trainer | begin training epoch 13
2022-01-28 07:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:02:02 | INFO | train_inner | epoch 013:     32 / 64 loss=10.454, ppl=1402.24, wps=6135.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.49, train_wall=478, gb_free=6.1, wall=4157
2022-01-28 08:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:05:02 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.392 | ppl 1344.13 | wps 8481.2 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-28 08:05:02 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-28 08:05:02 | INFO | train | epoch 013 | loss 10.364 | ppl 1318.07 | wps 6272 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.52 | train_wall 306 | gb_free 6.1 | wall 4337
KL Stats: Epoch 13 Divergences: Uniform: 1.700370513276423 Unigram: 0.9612759330565803
2022-01-28 08:05:02 | INFO | fairseq.trainer | begin training epoch 14
2022-01-28 08:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:10:35 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.299 | ppl 1260.21 | wps 8506.5 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-28 08:10:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-28 08:10:35 | INFO | train | epoch 014 | loss 10.254 | ppl 1221.02 | wps 6259.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.551 | train_wall 307 | gb_free 6.1 | wall 4670
KL Stats: Epoch 14 Divergences: Uniform: 1.7268886178850968 Unigram: 1.0388726647885387
2022-01-28 08:10:35 | INFO | fairseq.trainer | begin training epoch 15
2022-01-28 08:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:10:55 | INFO | train_inner | epoch 015:      4 / 64 loss=10.276, ppl=1240.26, wps=6124.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.535, train_wall=479, gb_free=6.1, wall=4690
2022-01-28 08:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:16:09 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.231 | ppl 1202.08 | wps 8482.8 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-28 08:16:09 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-28 08:16:09 | INFO | train | epoch 015 | loss 10.142 | ppl 1130.19 | wps 6258.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.529 | train_wall 307 | gb_free 6.1 | wall 5004
KL Stats: Epoch 15 Divergences: Uniform: 1.7536212679443495 Unigram: 1.108520451197347
2022-01-28 08:16:09 | INFO | fairseq.trainer | begin training epoch 16
2022-01-28 08:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:19:22 | INFO | train_inner | epoch 016:     40 / 64 loss=10.101, ppl=1098.57, wps=6439.2, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.551, train_wall=480, gb_free=6.1, wall=5197
2022-01-28 08:21:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:21:43 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.152 | ppl 1137.78 | wps 8494.5 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-28 08:21:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-28 08:21:43 | INFO | train | epoch 016 | loss 10.036 | ppl 1050.08 | wps 6257.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.551 | train_wall 307 | gb_free 6.1 | wall 5338
KL Stats: Epoch 16 Divergences: Uniform: 1.7842080368764972 Unigram: 1.1773090201169187
2022-01-28 08:21:43 | INFO | fairseq.trainer | begin training epoch 17
2022-01-28 08:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:27:16 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.058 | ppl 1066.09 | wps 8506.1 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-28 08:27:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-28 08:27:16 | INFO | train | epoch 017 | loss 9.929 | ppl 975.16 | wps 6273 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.541 | train_wall 306 | gb_free 6.1 | wall 5671
KL Stats: Epoch 17 Divergences: Uniform: 1.8200729569487184 Unigram: 1.236062497337077
2022-01-28 08:27:16 | INFO | fairseq.trainer | begin training epoch 18
2022-01-28 08:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:28:14 | INFO | train_inner | epoch 018:     12 / 64 loss=9.944, ppl=984.71, wps=6134.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.544, train_wall=479, gb_free=6.1, wall=5729
2022-01-28 08:32:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:32:49 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.992 | ppl 1018.19 | wps 8495.3 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-28 08:32:49 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-28 08:32:49 | INFO | train | epoch 018 | loss 9.83 | ppl 909.94 | wps 6262.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.573 | train_wall 307 | gb_free 6.1 | wall 6004
KL Stats: Epoch 18 Divergences: Uniform: 1.8563996187274423 Unigram: 1.2945309735064077
2022-01-28 08:32:49 | INFO | fairseq.trainer | begin training epoch 19
2022-01-28 08:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:36:41 | INFO | train_inner | epoch 019:     48 / 64 loss=9.78, ppl=879.15, wps=6441.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.537, train_wall=480, gb_free=6.1, wall=6236
2022-01-28 08:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:38:23 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.924 | ppl 971.59 | wps 8514.7 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-28 08:38:23 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-28 08:38:23 | INFO | train | epoch 019 | loss 9.726 | ppl 847.04 | wps 6261.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.521 | train_wall 307 | gb_free 6.1 | wall 6338
KL Stats: Epoch 19 Divergences: Uniform: 1.8904255234925311 Unigram: 1.3528559730680476
2022-01-28 08:38:23 | INFO | fairseq.trainer | begin training epoch 20
2022-01-28 08:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:43:56 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.836 | ppl 913.83 | wps 8475.6 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-28 08:43:56 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-28 08:43:56 | INFO | train | epoch 020 | loss 9.629 | ppl 791.94 | wps 6265.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.54 | train_wall 307 | gb_free 6.1 | wall 6671
KL Stats: Epoch 20 Divergences: Uniform: 1.9230880548940252 Unigram: 1.405314289618745
2022-01-28 08:43:56 | INFO | fairseq.trainer | begin training epoch 21
2022-01-28 08:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:45:32 | INFO | train_inner | epoch 021:     20 / 64 loss=9.625, ppl=789.46, wps=6138.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.544, train_wall=478, gb_free=6.1, wall=6767
2022-01-28 08:49:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:49:29 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.787 | ppl 883.25 | wps 8497.5 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-28 08:49:29 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-28 08:49:29 | INFO | train | epoch 021 | loss 9.535 | ppl 742.03 | wps 6279.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.525 | train_wall 306 | gb_free 6.1 | wall 7004
KL Stats: Epoch 21 Divergences: Uniform: 1.953663216979039 Unigram: 1.4570498174421003
2022-01-28 08:49:29 | INFO | fairseq.trainer | begin training epoch 22
2022-01-28 08:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 08:54:00 | INFO | train_inner | epoch 022:     56 / 64 loss=9.483, ppl=715.47, wps=6442.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.53, train_wall=480, gb_free=6.1, wall=7274
2022-01-28 08:54:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 08:55:03 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.732 | ppl 850.47 | wps 8464.3 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-28 08:55:03 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-28 08:55:03 | INFO | train | epoch 022 | loss 9.446 | ppl 697.67 | wps 6252.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.541 | train_wall 307 | gb_free 6.1 | wall 7338
KL Stats: Epoch 22 Divergences: Uniform: 1.9824356378791494 Unigram: 1.5057499603964835
2022-01-28 08:55:03 | INFO | fairseq.trainer | begin training epoch 23
2022-01-28 08:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:00:37 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.669 | ppl 814.24 | wps 8483.4 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-28 09:00:37 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-28 09:00:37 | INFO | train | epoch 023 | loss 9.36 | ppl 657.14 | wps 6251.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.519 | train_wall 307 | gb_free 6.1 | wall 7672
KL Stats: Epoch 23 Divergences: Uniform: 2.0108132104158294 Unigram: 1.5501490988521855
2022-01-28 09:00:37 | INFO | fairseq.trainer | begin training epoch 24
2022-01-28 09:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:02:52 | INFO | train_inner | epoch 024:     28 / 64 loss=9.345, ppl=650.18, wps=6122.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.524, train_wall=479, gb_free=6.1, wall=7807
2022-01-28 09:05:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:06:10 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.613 | ppl 783.03 | wps 8487.3 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-28 09:06:10 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-28 09:06:10 | INFO | train | epoch 024 | loss 9.276 | ppl 619.94 | wps 6269.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.533 | train_wall 306 | gb_free 6.1 | wall 8005
KL Stats: Epoch 24 Divergences: Uniform: 2.035370869367746 Unigram: 1.5899900627093901
2022-01-28 09:06:10 | INFO | fairseq.trainer | begin training epoch 25
2022-01-28 09:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:11:17 | INFO | train_inner | epoch 025:     64 / 64 loss=9.222, ppl=597.35, wps=6449.6, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.525, train_wall=478, gb_free=6.1, wall=8312
2022-01-28 09:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:11:43 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.587 | ppl 768.88 | wps 8506.8 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-28 09:11:43 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-28 09:11:43 | INFO | train | epoch 025 | loss 9.195 | ppl 586.06 | wps 6272.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.52 | train_wall 306 | gb_free 6.1 | wall 8338
KL Stats: Epoch 25 Divergences: Uniform: 2.0661030063298984 Unigram: 1.6325158932131765
2022-01-28 09:11:43 | INFO | fairseq.trainer | begin training epoch 26
2022-01-28 09:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:16:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:17:17 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.531 | ppl 739.93 | wps 8501.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-28 09:17:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-28 09:17:17 | INFO | train | epoch 026 | loss 9.114 | ppl 554.29 | wps 6254.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.54 | train_wall 307 | gb_free 6.1 | wall 8672
KL Stats: Epoch 26 Divergences: Uniform: 2.079140509069098 Unigram: 1.6699436735270874
2022-01-28 09:17:17 | INFO | fairseq.trainer | begin training epoch 27
2022-01-28 09:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:20:11 | INFO | train_inner | epoch 027:     36 / 64 loss=9.086, ppl=543.52, wps=6123, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.53, train_wall=481, gb_free=6.1, wall=8846
2022-01-28 09:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:22:51 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.501 | ppl 724.34 | wps 8491.5 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-28 09:22:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-28 09:22:51 | INFO | train | epoch 027 | loss 9.033 | ppl 523.9 | wps 6253.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.516 | train_wall 307 | gb_free 6.1 | wall 9006
KL Stats: Epoch 27 Divergences: Uniform: 2.1053213996988798 Unigram: 1.7065859347833192
2022-01-28 09:22:51 | INFO | fairseq.trainer | begin training epoch 28
2022-01-28 09:22:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:27:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:28:25 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.475 | ppl 711.41 | wps 8481.3 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-28 09:28:25 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-28 09:28:25 | INFO | train | epoch 028 | loss 8.955 | ppl 496.19 | wps 6259.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.519 | train_wall 307 | gb_free 6.1 | wall 9340
KL Stats: Epoch 28 Divergences: Uniform: 2.1379206410207803 Unigram: 1.73998532737566
2022-01-28 09:28:25 | INFO | fairseq.trainer | begin training epoch 29
2022-01-28 09:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:29:03 | INFO | train_inner | epoch 029:      8 / 64 loss=8.971, ppl=501.65, wps=6124.5, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.522, train_wall=479, gb_free=6.1, wall=9378
2022-01-28 09:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:33:58 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.44 | ppl 694.48 | wps 8512 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-28 09:33:58 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-28 09:33:58 | INFO | train | epoch 029 | loss 8.876 | ppl 469.95 | wps 6275.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.521 | train_wall 306 | gb_free 6.1 | wall 9672
KL Stats: Epoch 29 Divergences: Uniform: 2.1587328465314 Unigram: 1.7745278783231855
2022-01-28 09:33:58 | INFO | fairseq.trainer | begin training epoch 30
2022-01-28 09:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:37:30 | INFO | train_inner | epoch 030:     44 / 64 loss=8.843, ppl=459.25, wps=6450.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.511, train_wall=480, gb_free=6.1, wall=9885
2022-01-28 09:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:39:31 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.419 | ppl 684.57 | wps 8479.7 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-28 09:39:31 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-28 09:39:31 | INFO | train | epoch 030 | loss 8.799 | ppl 445.28 | wps 6257.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.515 | train_wall 307 | gb_free 6.1 | wall 10006
KL Stats: Epoch 30 Divergences: Uniform: 2.178997528590047 Unigram: 1.8100558204540824
2022-01-28 09:39:31 | INFO | fairseq.trainer | begin training epoch 31
2022-01-28 09:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:44:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:45:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.371 | ppl 662.17 | wps 8473.7 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-28 09:45:05 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-28 09:45:05 | INFO | train | epoch 031 | loss 8.72 | ppl 421.58 | wps 6258.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.489 | train_wall 307 | gb_free 6.1 | wall 10340
KL Stats: Epoch 31 Divergences: Uniform: 2.1995947068921735 Unigram: 1.8405951807036487
2022-01-28 09:45:05 | INFO | fairseq.trainer | begin training epoch 32
2022-01-28 09:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:46:22 | INFO | train_inner | epoch 032:     16 / 64 loss=8.721, ppl=421.99, wps=6124.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.499, train_wall=479, gb_free=6.1, wall=10417
2022-01-28 09:50:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:50:39 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.337 | ppl 646.78 | wps 8507 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-28 09:50:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-28 09:50:39 | INFO | train | epoch 032 | loss 8.646 | ppl 400.61 | wps 6259 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.503 | train_wall 307 | gb_free 6.1 | wall 10674
KL Stats: Epoch 32 Divergences: Uniform: 2.2253380894819683 Unigram: 1.871692876206257
2022-01-28 09:50:39 | INFO | fairseq.trainer | begin training epoch 33
2022-01-28 09:50:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 09:54:49 | INFO | train_inner | epoch 033:     52 / 64 loss=8.609, ppl=390.5, wps=6447.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.506, train_wall=480, gb_free=6.1, wall=10924
2022-01-28 09:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 09:56:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.32 | ppl 639.25 | wps 8489.5 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-28 09:56:12 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-28 09:56:12 | INFO | train | epoch 033 | loss 8.572 | ppl 380.51 | wps 6272.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.505 | train_wall 306 | gb_free 6.1 | wall 11007
KL Stats: Epoch 33 Divergences: Uniform: 2.2521036551679128 Unigram: 1.9041829794923093
2022-01-28 09:56:12 | INFO | fairseq.trainer | begin training epoch 34
2022-01-28 09:56:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:01:45 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.302 | ppl 631.05 | wps 8518.3 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-28 10:01:45 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-28 10:01:45 | INFO | train | epoch 034 | loss 8.495 | ppl 360.86 | wps 6263.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.501 | train_wall 307 | gb_free 6.1 | wall 11340
KL Stats: Epoch 34 Divergences: Uniform: 2.274099217697191 Unigram: 1.9356674272856393
2022-01-28 10:01:45 | INFO | fairseq.trainer | begin training epoch 35
2022-01-28 10:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:03:41 | INFO | train_inner | epoch 035:     24 / 64 loss=8.483, ppl=357.7, wps=6129, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.5, train_wall=479, gb_free=6.1, wall=11456
2022-01-28 10:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:07:19 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.275 | ppl 619.54 | wps 8506.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-28 10:07:19 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-28 10:07:19 | INFO | train | epoch 035 | loss 8.424 | ppl 343.37 | wps 6258.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.497 | train_wall 307 | gb_free 6.1 | wall 11674
KL Stats: Epoch 35 Divergences: Uniform: 2.2968319093075213 Unigram: 1.9619642239488924
2022-01-28 10:07:19 | INFO | fairseq.trainer | begin training epoch 36
2022-01-28 10:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:12:09 | INFO | train_inner | epoch 036:     60 / 64 loss=8.38, ppl=333.15, wps=6436, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.497, train_wall=481, gb_free=6.1, wall=11964
2022-01-28 10:12:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:12:53 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.251 | ppl 609.14 | wps 8502.9 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-28 10:12:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-28 10:12:53 | INFO | train | epoch 036 | loss 8.35 | ppl 326.34 | wps 6255.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.495 | train_wall 307 | gb_free 6.1 | wall 12008
KL Stats: Epoch 36 Divergences: Uniform: 2.320459160760303 Unigram: 1.9942174308097897
2022-01-28 10:12:53 | INFO | fairseq.trainer | begin training epoch 37
2022-01-28 10:12:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:18:26 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.264 | ppl 614.89 | wps 8464.5 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-28 10:18:26 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-28 10:18:26 | INFO | train | epoch 037 | loss 8.281 | ppl 310.97 | wps 6270.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.502 | train_wall 306 | gb_free 6.1 | wall 12341
KL Stats: Epoch 37 Divergences: Uniform: 2.3430082975786313 Unigram: 2.0252211985988082
2022-01-28 10:18:26 | INFO | fairseq.trainer | begin training epoch 38
2022-01-28 10:18:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:21:01 | INFO | train_inner | epoch 038:     32 / 64 loss=8.259, ppl=306.38, wps=6129.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.5, train_wall=479, gb_free=6.1, wall=12496
2022-01-28 10:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:24:00 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.244 | ppl 606.44 | wps 8482.7 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-28 10:24:00 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-28 10:24:00 | INFO | train | epoch 038 | loss 8.213 | ppl 296.65 | wps 6248.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.503 | train_wall 308 | gb_free 6.1 | wall 12675
KL Stats: Epoch 38 Divergences: Uniform: 2.373022897054077 Unigram: 2.0466199871491604
2022-01-28 10:24:00 | INFO | fairseq.trainer | begin training epoch 39
2022-01-28 10:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:29:34 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.226 | ppl 598.69 | wps 8521.7 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-28 10:29:34 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-28 10:29:34 | INFO | train | epoch 039 | loss 8.143 | ppl 282.69 | wps 6251.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.489 | train_wall 307 | gb_free 6.1 | wall 13009
KL Stats: Epoch 39 Divergences: Uniform: 2.381606244638767 Unigram: 2.0805214950893385
2022-01-28 10:29:34 | INFO | fairseq.trainer | begin training epoch 40
2022-01-28 10:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:29:54 | INFO | train_inner | epoch 040:      4 / 64 loss=8.165, ppl=287.06, wps=6116.4, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.496, train_wall=480, gb_free=6.1, wall=13029
2022-01-28 10:34:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:35:08 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.212 | ppl 593.13 | wps 8511.1 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-28 10:35:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-28 10:35:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint40.pt
2022-01-28 10:35:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint40.pt
2022-01-28 10:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.212) (writing took 5.808358911424875 seconds)
2022-01-28 10:35:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-28 10:35:14 | INFO | train | epoch 040 | loss 8.075 | ppl 269.64 | wps 6153.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.495 | train_wall 307 | gb_free 6.1 | wall 13349
KL Stats: Epoch 40 Divergences: Uniform: 2.410110059231057 Unigram: 2.105670633180587
2022-01-28 10:35:14 | INFO | fairseq.trainer | begin training epoch 41
2022-01-28 10:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:38:26 | INFO | train_inner | epoch 041:     40 / 64 loss=8.051, ppl=265.23, wps=6377, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.491, train_wall=480, gb_free=6.1, wall=13541
2022-01-28 10:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:40:47 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.2 | ppl 588.16 | wps 8480.9 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.2
2022-01-28 10:40:47 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-28 10:40:47 | INFO | train | epoch 041 | loss 8.01 | ppl 257.82 | wps 6273 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.491 | train_wall 306 | gb_free 6.1 | wall 13682
KL Stats: Epoch 41 Divergences: Uniform: 2.4276875941635923 Unigram: 2.129369634551257
2022-01-28 10:40:47 | INFO | fairseq.trainer | begin training epoch 42
2022-01-28 10:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:45:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:46:20 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.174 | ppl 577.55 | wps 8487.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.174
2022-01-28 10:46:20 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-28 10:46:20 | INFO | train | epoch 042 | loss 7.946 | ppl 246.67 | wps 6261.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.503 | train_wall 307 | gb_free 6.1 | wall 14015
KL Stats: Epoch 42 Divergences: Uniform: 2.4470530792283736 Unigram: 2.158753692654044
2022-01-28 10:46:20 | INFO | fairseq.trainer | begin training epoch 43
2022-01-28 10:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:47:18 | INFO | train_inner | epoch 043:     12 / 64 loss=7.953, ppl=247.74, wps=6126.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.501, train_wall=479, gb_free=6.1, wall=14073
2022-01-28 10:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:51:54 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.202 | ppl 589.04 | wps 8520.6 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.202
2022-01-28 10:51:54 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-28 10:51:54 | INFO | train | epoch 043 | loss 7.881 | ppl 235.72 | wps 6255.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.492 | train_wall 307 | gb_free 6.1 | wall 14349
KL Stats: Epoch 43 Divergences: Uniform: 2.470365285979236 Unigram: 2.1819817770125334
2022-01-28 10:51:54 | INFO | fairseq.trainer | begin training epoch 44
2022-01-28 10:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 10:55:46 | INFO | train_inner | epoch 044:     48 / 64 loss=7.847, ppl=230.27, wps=6437, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.498, train_wall=481, gb_free=6.1, wall=14581
2022-01-28 10:57:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 10:57:28 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.202 | ppl 588.8 | wps 8496.2 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.202
2022-01-28 10:57:28 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-28 10:57:28 | INFO | train | epoch 044 | loss 7.822 | ppl 226.28 | wps 6257.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.501 | train_wall 307 | gb_free 6.1 | wall 14683
KL Stats: Epoch 44 Divergences: Uniform: 2.4869772871494082 Unigram: 2.204752648083094
2022-01-28 10:57:28 | INFO | fairseq.trainer | begin training epoch 45
2022-01-28 10:57:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:03:01 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.184 | ppl 581.8 | wps 8485.3 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.184
2022-01-28 11:03:01 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-28 11:03:01 | INFO | train | epoch 045 | loss 7.758 | ppl 216.53 | wps 6267.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.501 | train_wall 307 | gb_free 6.1 | wall 15016
KL Stats: Epoch 45 Divergences: Uniform: 2.507184029048779 Unigram: 2.2335086497422383
2022-01-28 11:03:01 | INFO | fairseq.trainer | begin training epoch 46
2022-01-28 11:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:04:38 | INFO | train_inner | epoch 046:     20 / 64 loss=7.758, ppl=216.45, wps=6130.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.5, train_wall=479, gb_free=6.1, wall=15113
2022-01-28 11:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:08:35 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.187 | ppl 582.7 | wps 8489.9 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.187
2022-01-28 11:08:35 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-28 11:08:35 | INFO | train | epoch 046 | loss 7.699 | ppl 207.79 | wps 6249.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.502 | train_wall 308 | gb_free 6.1 | wall 15350
KL Stats: Epoch 46 Divergences: Uniform: 2.522572905341096 Unigram: 2.2522415603683412
2022-01-28 11:08:35 | INFO | fairseq.trainer | begin training epoch 47
2022-01-28 11:08:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:13:06 | INFO | train_inner | epoch 047:     56 / 64 loss=7.668, ppl=203.43, wps=6427.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.494, train_wall=481, gb_free=6.1, wall=15621
2022-01-28 11:13:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:14:10 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.177 | ppl 578.94 | wps 8503.1 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.177
2022-01-28 11:14:10 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-28 11:14:10 | INFO | train | epoch 047 | loss 7.64 | ppl 199.51 | wps 6250.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.488 | train_wall 308 | gb_free 6.1 | wall 15684
KL Stats: Epoch 47 Divergences: Uniform: 2.5465827728979225 Unigram: 2.2727750470465784
2022-01-28 11:14:10 | INFO | fairseq.trainer | begin training epoch 48
2022-01-28 11:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:19:43 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.157 | ppl 570.82 | wps 8537.1 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.157
2022-01-28 11:19:43 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-28 11:19:43 | INFO | train | epoch 048 | loss 7.584 | ppl 191.84 | wps 6257.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.504 | train_wall 307 | gb_free 6.1 | wall 16018
KL Stats: Epoch 48 Divergences: Uniform: 2.5667824443583482 Unigram: 2.300132673896793
2022-01-28 11:19:43 | INFO | fairseq.trainer | begin training epoch 49
2022-01-28 11:19:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:21:58 | INFO | train_inner | epoch 049:     28 / 64 loss=7.566, ppl=189.49, wps=6135.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.498, train_wall=479, gb_free=6.1, wall=16153
2022-01-28 11:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:25:15 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.187 | ppl 582.79 | wps 8487.1 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.187
2022-01-28 11:25:15 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-28 11:25:15 | INFO | train | epoch 049 | loss 7.527 | ppl 184.4 | wps 6290.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.5 | train_wall 305 | gb_free 6.1 | wall 16350
KL Stats: Epoch 49 Divergences: Uniform: 2.575137480809008 Unigram: 2.3182926625608604
2022-01-28 11:25:15 | INFO | fairseq.trainer | begin training epoch 50
2022-01-28 11:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:30:23 | INFO | train_inner | epoch 050:     64 / 64 loss=7.502, ppl=181.33, wps=6455.8, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.516, train_wall=478, gb_free=6.1, wall=16657
2022-01-28 11:30:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:30:48 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.212 | ppl 593.22 | wps 8515.3 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.212
2022-01-28 11:30:48 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-28 11:30:48 | INFO | train | epoch 050 | loss 7.476 | ppl 178 | wps 6272.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.52 | train_wall 306 | gb_free 6.1 | wall 16683
KL Stats: Epoch 50 Divergences: Uniform: 2.5908792755416483 Unigram: 2.3329497966774824
2022-01-28 11:30:48 | INFO | fairseq.trainer | begin training epoch 51
2022-01-28 11:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:35:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:36:21 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.204 | ppl 589.68 | wps 8539.8 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.204
2022-01-28 11:36:21 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-28 11:36:21 | INFO | train | epoch 051 | loss 7.42 | ppl 171.25 | wps 6273.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.507 | train_wall 306 | gb_free 6.1 | wall 17016
KL Stats: Epoch 51 Divergences: Uniform: 2.621161768926391 Unigram: 2.3536828963215806
2022-01-28 11:36:21 | INFO | fairseq.trainer | begin training epoch 52
2022-01-28 11:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:39:15 | INFO | train_inner | epoch 052:     36 / 64 loss=7.396, ppl=168.41, wps=6141.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.504, train_wall=479, gb_free=6.1, wall=17190
2022-01-28 11:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:41:54 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.204 | ppl 589.85 | wps 8475.5 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.204
2022-01-28 11:41:54 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-28 11:41:54 | INFO | train | epoch 052 | loss 7.367 | ppl 165.11 | wps 6269.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.507 | train_wall 306 | gb_free 6.1 | wall 17349
KL Stats: Epoch 52 Divergences: Uniform: 2.6295608193727267 Unigram: 2.3794946779529624
2022-01-28 11:41:54 | INFO | fairseq.trainer | begin training epoch 53
2022-01-28 11:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:47:27 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.184 | ppl 581.8 | wps 8491.1 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.184
2022-01-28 11:47:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-28 11:47:27 | INFO | train | epoch 053 | loss 7.316 | ppl 159.32 | wps 6286.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.494 | train_wall 306 | gb_free 6.1 | wall 17681
KL Stats: Epoch 53 Divergences: Uniform: 2.651955715137961 Unigram: 2.395890324157024
2022-01-28 11:47:27 | INFO | fairseq.trainer | begin training epoch 54
2022-01-28 11:47:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:48:05 | INFO | train_inner | epoch 054:      8 / 64 loss=7.329, ppl=160.77, wps=6144.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.505, train_wall=478, gb_free=6.1, wall=17720
2022-01-28 11:52:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:53:00 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.211 | ppl 592.78 | wps 8484.8 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.211
2022-01-28 11:53:00 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-28 11:53:00 | INFO | train | epoch 054 | loss 7.266 | ppl 153.88 | wps 6268.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.512 | train_wall 307 | gb_free 6.1 | wall 18015
KL Stats: Epoch 54 Divergences: Uniform: 2.6612936731872696 Unigram: 2.413880097194084
2022-01-28 11:53:00 | INFO | fairseq.trainer | begin training epoch 55
2022-01-28 11:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 11:56:32 | INFO | train_inner | epoch 055:     44 / 64 loss=7.238, ppl=150.97, wps=6451.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.511, train_wall=479, gb_free=6.1, wall=18227
2022-01-28 11:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 11:58:33 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.211 | ppl 592.6 | wps 8509.2 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.211
2022-01-28 11:58:33 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-28 11:58:33 | INFO | train | epoch 055 | loss 7.219 | ppl 149.01 | wps 6272.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.53 | train_wall 306 | gb_free 6.1 | wall 18348
KL Stats: Epoch 55 Divergences: Uniform: 2.675939082781897 Unigram: 2.438074646131547
2022-01-28 11:58:33 | INFO | fairseq.trainer | begin training epoch 56
2022-01-28 11:58:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:04:06 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.343 | ppl 649.57 | wps 8515.6 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.212
2022-01-28 12:04:06 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-28 12:04:06 | INFO | train | epoch 056 | loss 7.169 | ppl 143.95 | wps 6273 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.51 | train_wall 306 | gb_free 6.1 | wall 18681
KL Stats: Epoch 56 Divergences: Uniform: 2.6727863848077105 Unigram: 2.449227376879452
2022-01-28 12:04:06 | INFO | fairseq.trainer | begin training epoch 57
2022-01-28 12:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:05:23 | INFO | train_inner | epoch 057:     16 / 64 loss=7.174, ppl=144.4, wps=6139.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.521, train_wall=478, gb_free=6.1, wall=18758
2022-01-28 12:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:09:38 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.312 | ppl 635.55 | wps 8487.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.212
2022-01-28 12:09:38 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-28 12:09:38 | INFO | train | epoch 057 | loss 7.123 | ppl 139.35 | wps 6287.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.525 | train_wall 306 | gb_free 6.1 | wall 19013
KL Stats: Epoch 57 Divergences: Uniform: 2.7085520048645195 Unigram: 2.472074532582926
2022-01-28 12:09:38 | INFO | fairseq.trainer | begin training epoch 58
2022-01-28 12:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:13:49 | INFO | train_inner | epoch 058:     52 / 64 loss=7.098, ppl=137.04, wps=6462.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.522, train_wall=479, gb_free=6.1, wall=19263
2022-01-28 12:14:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:15:11 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.303 | ppl 631.54 | wps 8501.1 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.212
2022-01-28 12:15:11 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-28 12:15:11 | INFO | train | epoch 058 | loss 7.078 | ppl 135.15 | wps 6268.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.523 | train_wall 307 | gb_free 6.1 | wall 19346
KL Stats: Epoch 58 Divergences: Uniform: 2.719788656306701 Unigram: 2.488186223740796
2022-01-28 12:15:11 | INFO | fairseq.trainer | begin training epoch 59
2022-01-28 12:15:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:20:44 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.378 | ppl 665.34 | wps 8470.1 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.212
2022-01-28 12:20:44 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-28 12:20:44 | INFO | train | epoch 059 | loss 7.032 | ppl 130.91 | wps 6275.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.515 | train_wall 306 | gb_free 6.1 | wall 19679
KL Stats: Epoch 59 Divergences: Uniform: 2.7328056563179706 Unigram: 2.501775313630085
2022-01-28 12:20:44 | INFO | fairseq.trainer | begin training epoch 60
2022-01-28 12:20:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:22:40 | INFO | train_inner | epoch 060:     24 / 64 loss=7.027, ppl=130.41, wps=6141.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.521, train_wall=478, gb_free=6.1, wall=19794
2022-01-28 12:25:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:26:17 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.341 | ppl 648.69 | wps 8505.9 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.212
2022-01-28 12:26:17 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-28 12:26:17 | INFO | train | epoch 060 | loss 6.989 | ppl 127.01 | wps 6274.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.533 | train_wall 306 | gb_free 6.1 | wall 20012
KL Stats: Epoch 60 Divergences: Uniform: 2.745945432373433 Unigram: 2.5262758697978773
2022-01-28 12:26:17 | INFO | fairseq.trainer | begin training epoch 61
2022-01-28 12:26:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:31:05 | INFO | train_inner | epoch 061:     60 / 64 loss=6.969, ppl=125.28, wps=6466.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.534, train_wall=478, gb_free=6.1, wall=20300
2022-01-28 12:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:31:49 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.336 | ppl 646.1 | wps 8489.6 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.212
2022-01-28 12:31:49 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-28 12:31:49 | INFO | train | epoch 061 | loss 6.946 | ppl 123.3 | wps 6290.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.537 | train_wall 305 | gb_free 6.1 | wall 20344
KL Stats: Epoch 61 Divergences: Uniform: 2.7733260832836084 Unigram: 2.5390955252590257
2022-01-28 12:31:49 | INFO | fairseq.trainer | begin training epoch 62
2022-01-28 12:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:37:22 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.332 | ppl 644.37 | wps 8490.1 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.212
2022-01-28 12:37:22 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-28 12:37:22 | INFO | train | epoch 062 | loss 6.904 | ppl 119.8 | wps 6268.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.537 | train_wall 307 | gb_free 6.1 | wall 20677
KL Stats: Epoch 62 Divergences: Uniform: 2.77607334215695 Unigram: 2.5598802025774243
2022-01-28 12:37:22 | INFO | fairseq.trainer | begin training epoch 63
2022-01-28 12:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:39:56 | INFO | train_inner | epoch 063:     32 / 64 loss=6.879, ppl=117.69, wps=6135.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.538, train_wall=478, gb_free=6.1, wall=20831
2022-01-28 12:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:42:55 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.342 | ppl 648.82 | wps 8501.7 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.212
2022-01-28 12:42:55 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-28 12:42:55 | INFO | train | epoch 063 | loss 6.861 | ppl 116.26 | wps 6273.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.536 | train_wall 306 | gb_free 6.1 | wall 21010
KL Stats: Epoch 63 Divergences: Uniform: 2.7906801303756854 Unigram: 2.573818647009608
2022-01-28 12:42:55 | INFO | fairseq.trainer | begin training epoch 64
2022-01-28 12:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:48:28 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.412 | ppl 681.23 | wps 8506.4 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.212
2022-01-28 12:48:28 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-28 12:48:28 | INFO | train | epoch 064 | loss 6.819 | ppl 112.89 | wps 6275.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.541 | train_wall 306 | gb_free 6.1 | wall 21343
KL Stats: Epoch 64 Divergences: Uniform: 2.799619287583122 Unigram: 2.589835544718248
2022-01-28 12:48:28 | INFO | fairseq.trainer | begin training epoch 65
2022-01-28 12:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:48:47 | INFO | train_inner | epoch 065:      4 / 64 loss=6.846, ppl=115.01, wps=6140.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.54, train_wall=478, gb_free=6.1, wall=21362
2022-01-28 12:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:54:00 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.385 | ppl 668.42 | wps 8475 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.212
2022-01-28 12:54:00 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-28 12:54:00 | INFO | train | epoch 065 | loss 6.776 | ppl 109.63 | wps 6284.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.549 | train_wall 306 | gb_free 6.1 | wall 21675
KL Stats: Epoch 65 Divergences: Uniform: 2.8109008905044197 Unigram: 2.606668638114235
2022-01-28 12:54:00 | INFO | fairseq.trainer | begin training epoch 66
2022-01-28 12:54:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 12:57:13 | INFO | train_inner | epoch 066:     40 / 64 loss=6.751, ppl=107.73, wps=6459.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.545, train_wall=479, gb_free=6.1, wall=21868
2022-01-28 12:59:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 12:59:33 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.423 | ppl 686.48 | wps 8503 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.212
2022-01-28 12:59:33 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-28 12:59:33 | INFO | train | epoch 066 | loss 6.734 | ppl 106.47 | wps 6270.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.535 | train_wall 306 | gb_free 6.1 | wall 22008
KL Stats: Epoch 66 Divergences: Uniform: 2.822962552666188 Unigram: 2.6179153913928834
2022-01-28 12:59:33 | INFO | fairseq.trainer | begin training epoch 67
2022-01-28 12:59:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:05:07 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.353 | ppl 654.03 | wps 8490.5 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.212
2022-01-28 13:05:07 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-28 13:05:07 | INFO | train | epoch 067 | loss 6.695 | ppl 103.63 | wps 6265 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.548 | train_wall 307 | gb_free 6.1 | wall 22341
KL Stats: Epoch 67 Divergences: Uniform: 2.849128459116855 Unigram: 2.641450019291227
2022-01-28 13:05:07 | INFO | fairseq.trainer | begin training epoch 68
2022-01-28 13:05:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:06:05 | INFO | train_inner | epoch 068:     12 / 64 loss=6.704, ppl=104.22, wps=6135.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.542, train_wall=478, gb_free=6.1, wall=22399
2022-01-28 13:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:10:40 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.478 | ppl 713.19 | wps 8483.7 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.212
2022-01-28 13:10:40 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-28 13:10:40 | INFO | train | epoch 068 | loss 6.657 | ppl 100.93 | wps 6267.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.557 | train_wall 307 | gb_free 6.1 | wall 22675
KL Stats: Epoch 68 Divergences: Uniform: 2.8595101315870424 Unigram: 2.6557896614497998
2022-01-28 13:10:40 | INFO | fairseq.trainer | begin training epoch 69
2022-01-28 13:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:14:30 | INFO | train_inner | epoch 069:     48 / 64 loss=6.64, ppl=99.7, wps=6460.3, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.554, train_wall=479, gb_free=6.1, wall=22905
2022-01-28 13:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:16:12 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.5 | ppl 724.21 | wps 8491.6 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.212
2022-01-28 13:16:12 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-28 13:16:12 | INFO | train | epoch 069 | loss 6.62 | ppl 98.37 | wps 6284.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.558 | train_wall 306 | gb_free 6.1 | wall 23007
KL Stats: Epoch 69 Divergences: Uniform: 2.871531605138495 Unigram: 2.666141268099037
2022-01-28 13:16:12 | INFO | fairseq.trainer | begin training epoch 70
2022-01-28 13:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:21:46 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.53 | ppl 739.21 | wps 8497 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.212
2022-01-28 13:21:46 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-28 13:21:46 | INFO | train | epoch 070 | loss 6.585 | ppl 95.99 | wps 6262.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.546 | train_wall 307 | gb_free 6.1 | wall 23340
KL Stats: Epoch 70 Divergences: Uniform: 2.879955758532047 Unigram: 2.678726370155785
2022-01-28 13:21:46 | INFO | fairseq.trainer | begin training epoch 71
2022-01-28 13:21:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:23:22 | INFO | train_inner | epoch 071:     20 / 64 loss=6.58, ppl=95.66, wps=6127.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.561, train_wall=479, gb_free=6.1, wall=23437
2022-01-28 13:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:27:19 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.509 | ppl 728.65 | wps 8485.9 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.212
2022-01-28 13:27:19 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-28 13:27:19 | INFO | train | epoch 071 | loss 6.552 | ppl 93.82 | wps 6262.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.582 | train_wall 307 | gb_free 6.1 | wall 23674
KL Stats: Epoch 71 Divergences: Uniform: 2.8902756961461864 Unigram: 2.695931604159339
2022-01-28 13:27:19 | INFO | fairseq.trainer | begin training epoch 72
2022-01-28 13:27:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:31:50 | INFO | train_inner | epoch 072:     56 / 64 loss=6.536, ppl=92.82, wps=6443.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.573, train_wall=480, gb_free=6.1, wall=23944
2022-01-28 13:32:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:32:53 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.485 | ppl 716.73 | wps 8479.6 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.212
2022-01-28 13:32:53 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-28 13:32:53 | INFO | train | epoch 072 | loss 6.517 | ppl 91.57 | wps 6259.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.568 | train_wall 307 | gb_free 6.1 | wall 24008
KL Stats: Epoch 72 Divergences: Uniform: 2.9125810924552042 Unigram: 2.713765904261068
2022-01-28 13:32:53 | INFO | fairseq.trainer | begin training epoch 73
2022-01-28 13:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:38:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:38:26 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.573 | ppl 761.49 | wps 8484.9 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.212
2022-01-28 13:38:26 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-28 13:38:26 | INFO | train | epoch 073 | loss 6.483 | ppl 89.48 | wps 6271.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.562 | train_wall 306 | gb_free 6.1 | wall 24341
KL Stats: Epoch 73 Divergences: Uniform: 2.9062714337561855 Unigram: 2.7222324638857716
2022-01-28 13:38:26 | INFO | fairseq.trainer | begin training epoch 74
2022-01-28 13:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:40:41 | INFO | train_inner | epoch 074:     28 / 64 loss=6.473, ppl=88.81, wps=6131.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.563, train_wall=479, gb_free=6.1, wall=24476
2022-01-28 13:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:43:59 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.466 | ppl 707.3 | wps 8506.6 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.212
2022-01-28 13:43:59 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-28 13:43:59 | INFO | train | epoch 074 | loss 6.451 | ppl 87.51 | wps 6265.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.562 | train_wall 307 | gb_free 6.1 | wall 24674
KL Stats: Epoch 74 Divergences: Uniform: 2.9266480906402275 Unigram: 2.744325715279611
2022-01-28 13:43:59 | INFO | fairseq.trainer | begin training epoch 75
2022-01-28 13:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:49:07 | INFO | train_inner | epoch 075:     64 / 64 loss=6.442, ppl=86.96, wps=6445.6, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.571, train_wall=479, gb_free=6.1, wall=24982
2022-01-28 13:49:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:49:33 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.616 | ppl 784.57 | wps 8494.4 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.212
2022-01-28 13:49:33 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-28 13:49:33 | INFO | train | epoch 075 | loss 6.422 | ppl 85.75 | wps 6260.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.574 | train_wall 307 | gb_free 6.1 | wall 25008
KL Stats: Epoch 75 Divergences: Uniform: 2.925409949836443 Unigram: 2.7545937279092962
2022-01-28 13:49:33 | INFO | fairseq.trainer | begin training epoch 76
2022-01-28 13:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 13:55:06 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.585 | ppl 768.16 | wps 8489.8 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.212
2022-01-28 13:55:06 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-28 13:55:06 | INFO | train | epoch 076 | loss 6.393 | ppl 84.04 | wps 6266 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.587 | train_wall 307 | gb_free 6.1 | wall 25341
KL Stats: Epoch 76 Divergences: Uniform: 2.938464729192254 Unigram: 2.770064954592607
2022-01-28 13:55:06 | INFO | fairseq.trainer | begin training epoch 77
2022-01-28 13:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 13:58:00 | INFO | train_inner | epoch 077:     36 / 64 loss=6.368, ppl=82.59, wps=6129.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.581, train_wall=480, gb_free=6.1, wall=25515
2022-01-28 14:00:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:00:40 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.596 | ppl 773.84 | wps 8468.2 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.212
2022-01-28 14:00:40 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-28 14:00:40 | INFO | train | epoch 077 | loss 6.363 | ppl 82.33 | wps 6262.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.582 | train_wall 307 | gb_free 6.1 | wall 25674
KL Stats: Epoch 77 Divergences: Uniform: 2.9386034043587634 Unigram: 2.789951195041709
2022-01-28 14:00:40 | INFO | fairseq.trainer | begin training epoch 78
2022-01-28 14:00:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:06:13 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.593 | ppl 772.07 | wps 8505.2 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.212
2022-01-28 14:06:13 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-28 14:06:13 | INFO | train | epoch 078 | loss 6.336 | ppl 80.81 | wps 6257.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.592 | train_wall 307 | gb_free 6.1 | wall 26008
KL Stats: Epoch 78 Divergences: Uniform: 2.9549166059896144 Unigram: 2.79729347825844
2022-01-28 14:06:13 | INFO | fairseq.trainer | begin training epoch 79
2022-01-28 14:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:06:52 | INFO | train_inner | epoch 079:      8 / 64 loss=6.351, ppl=81.62, wps=6128.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.597, train_wall=479, gb_free=6.1, wall=26047
2022-01-28 14:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:11:47 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.637 | ppl 796.19 | wps 8470.2 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.212
2022-01-28 14:11:47 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-28 14:11:47 | INFO | train | epoch 079 | loss 6.306 | ppl 79.1 | wps 6260.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.583 | train_wall 307 | gb_free 6.1 | wall 26342
KL Stats: Epoch 79 Divergences: Uniform: 2.9606739380494043 Unigram: 2.803800765112459
2022-01-28 14:11:47 | INFO | fairseq.trainer | begin training epoch 80
2022-01-28 14:11:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:15:20 | INFO | train_inner | epoch 080:     44 / 64 loss=6.289, ppl=78.2, wps=6437.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.575, train_wall=480, gb_free=6.1, wall=26555
2022-01-28 14:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:17:21 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.585 | ppl 767.76 | wps 8492.3 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.212
2022-01-28 14:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-28 14:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint80.pt
2022-01-28 14:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint80.pt
2022-01-28 14:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.585) (writing took 3.521732944995165 seconds)
2022-01-28 14:17:25 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-28 14:17:25 | INFO | train | epoch 080 | loss 6.28 | ppl 77.71 | wps 6188.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.579 | train_wall 307 | gb_free 6.1 | wall 26679
KL Stats: Epoch 80 Divergences: Uniform: 2.9675251524341513 Unigram: 2.8230873850573976
2022-01-28 14:17:25 | INFO | fairseq.trainer | begin training epoch 81
2022-01-28 14:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:22:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:22:57 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.644 | ppl 800.21 | wps 8495.1 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.212
2022-01-28 14:22:57 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-28 14:22:57 | INFO | train | epoch 081 | loss 6.256 | ppl 76.42 | wps 6281.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.61 | train_wall 306 | gb_free 6.1 | wall 27012
KL Stats: Epoch 81 Divergences: Uniform: 2.9857536873392037 Unigram: 2.839603696671582
2022-01-28 14:22:57 | INFO | fairseq.trainer | begin training epoch 82
2022-01-28 14:22:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:24:15 | INFO | train_inner | epoch 082:     16 / 64 loss=6.262, ppl=76.75, wps=6096.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.608, train_wall=478, gb_free=6.1, wall=27089
2022-01-28 14:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:28:31 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.614 | ppl 783.53 | wps 8486.8 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.212
2022-01-28 14:28:31 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-28 14:28:31 | INFO | train | epoch 082 | loss 6.229 | ppl 75.02 | wps 6255.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.598 | train_wall 307 | gb_free 6.1 | wall 27346
KL Stats: Epoch 82 Divergences: Uniform: 2.9945206758555867 Unigram: 2.8587595017497085
2022-01-28 14:28:31 | INFO | fairseq.trainer | begin training epoch 83
2022-01-28 14:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:32:42 | INFO | train_inner | epoch 083:     52 / 64 loss=6.215, ppl=74.26, wps=6438, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.597, train_wall=481, gb_free=6.1, wall=27597
2022-01-28 14:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:34:05 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.566 | ppl 757.89 | wps 8487.3 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.212
2022-01-28 14:34:05 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-28 14:34:05 | INFO | train | epoch 083 | loss 6.204 | ppl 73.75 | wps 6259.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.604 | train_wall 307 | gb_free 6.1 | wall 27680
KL Stats: Epoch 83 Divergences: Uniform: 2.994474107087902 Unigram: 2.8658385735006795
2022-01-28 14:34:05 | INFO | fairseq.trainer | begin training epoch 84
2022-01-28 14:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:39:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:39:38 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.597 | ppl 774.25 | wps 8508.6 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.212
2022-01-28 14:39:38 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-28 14:39:38 | INFO | train | epoch 084 | loss 6.179 | ppl 72.44 | wps 6261.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.583 | train_wall 307 | gb_free 6.1 | wall 28013
KL Stats: Epoch 84 Divergences: Uniform: 3.006359184259211 Unigram: 2.879411032397748
2022-01-28 14:39:38 | INFO | fairseq.trainer | begin training epoch 85
2022-01-28 14:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:41:34 | INFO | train_inner | epoch 085:     24 / 64 loss=6.169, ppl=71.94, wps=6128.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.597, train_wall=479, gb_free=6.1, wall=28129
2022-01-28 14:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:45:11 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.65 | ppl 803.4 | wps 8484.3 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.212
2022-01-28 14:45:11 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-28 14:45:11 | INFO | train | epoch 085 | loss 6.155 | ppl 71.25 | wps 6280.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.601 | train_wall 306 | gb_free 6.1 | wall 28346
KL Stats: Epoch 85 Divergences: Uniform: 3.0167257929716014 Unigram: 2.887568972346733
2022-01-28 14:45:11 | INFO | fairseq.trainer | begin training epoch 86
2022-01-28 14:45:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:50:01 | INFO | train_inner | epoch 086:     60 / 64 loss=6.154, ppl=71.2, wps=6449.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.608, train_wall=480, gb_free=6.1, wall=28636
2022-01-28 14:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:50:45 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.679 | ppl 819.6 | wps 8489.4 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.212
2022-01-28 14:50:45 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-28 14:50:45 | INFO | train | epoch 086 | loss 6.135 | ppl 70.26 | wps 6253.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.626 | train_wall 307 | gb_free 6.1 | wall 28680
KL Stats: Epoch 86 Divergences: Uniform: 3.016061286210908 Unigram: 2.902210811694569
2022-01-28 14:50:45 | INFO | fairseq.trainer | begin training epoch 87
2022-01-28 14:50:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:55:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 14:56:19 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.673 | ppl 816.5 | wps 8478.3 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.212
2022-01-28 14:56:19 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-28 14:56:19 | INFO | train | epoch 087 | loss 6.111 | ppl 69.1 | wps 6253.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.632 | train_wall 307 | gb_free 6.1 | wall 29014
KL Stats: Epoch 87 Divergences: Uniform: 3.023125668922319 Unigram: 2.9126622792196124
2022-01-28 14:56:19 | INFO | fairseq.trainer | begin training epoch 88
2022-01-28 14:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 14:58:54 | INFO | train_inner | epoch 088:     32 / 64 loss=6.097, ppl=68.47, wps=6117.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.631, train_wall=480, gb_free=6.1, wall=29169
2022-01-28 15:01:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:01:53 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.689 | ppl 825.3 | wps 8485.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.212
2022-01-28 15:01:53 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-28 15:01:53 | INFO | train | epoch 088 | loss 6.088 | ppl 68.04 | wps 6248.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.632 | train_wall 308 | gb_free 6.1 | wall 29348
KL Stats: Epoch 88 Divergences: Uniform: 3.029314487497911 Unigram: 2.9223172328126097
2022-01-28 15:01:53 | INFO | fairseq.trainer | begin training epoch 89
2022-01-28 15:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:07:26 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.68 | ppl 820.34 | wps 8501.8 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.212
2022-01-28 15:07:26 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-28 15:07:26 | INFO | train | epoch 089 | loss 6.07 | ppl 67.16 | wps 6278.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.635 | train_wall 306 | gb_free 6.1 | wall 29681
KL Stats: Epoch 89 Divergences: Uniform: 3.0411947592596875 Unigram: 2.934921955882418
2022-01-28 15:07:26 | INFO | fairseq.trainer | begin training epoch 90
2022-01-28 15:07:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:07:45 | INFO | train_inner | epoch 090:      4 / 64 loss=6.081, ppl=67.68, wps=6134.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.636, train_wall=479, gb_free=6.1, wall=29700
2022-01-28 15:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:13:00 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.723 | ppl 845.4 | wps 8484.3 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.212
2022-01-28 15:13:00 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-28 15:13:00 | INFO | train | epoch 090 | loss 6.047 | ppl 66.13 | wps 6252.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.626 | train_wall 307 | gb_free 6.1 | wall 30015
KL Stats: Epoch 90 Divergences: Uniform: 3.041624417688071 Unigram: 2.9428471886101057
2022-01-28 15:13:00 | INFO | fairseq.trainer | begin training epoch 91
2022-01-28 15:13:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:16:13 | INFO | train_inner | epoch 091:     40 / 64 loss=6.029, ppl=65.32, wps=6433.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.626, train_wall=481, gb_free=6.1, wall=30208
2022-01-28 15:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:18:34 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.7 | ppl 831.53 | wps 8509.4 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.212
2022-01-28 15:18:34 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-28 15:18:34 | INFO | train | epoch 091 | loss 6.026 | ppl 65.17 | wps 6258.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.634 | train_wall 307 | gb_free 6.1 | wall 30348
KL Stats: Epoch 91 Divergences: Uniform: 3.054069039771888 Unigram: 2.9652825311930826
2022-01-28 15:18:34 | INFO | fairseq.trainer | begin training epoch 92
2022-01-28 15:18:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:24:07 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.745 | ppl 858.25 | wps 8477.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.212
2022-01-28 15:24:07 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-28 15:24:07 | INFO | train | epoch 092 | loss 6.006 | ppl 64.27 | wps 6261.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.64 | train_wall 307 | gb_free 6.1 | wall 30682
KL Stats: Epoch 92 Divergences: Uniform: 3.0572705696383635 Unigram: 2.9694714127145656
2022-01-28 15:24:07 | INFO | fairseq.trainer | begin training epoch 93
2022-01-28 15:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:25:05 | INFO | train_inner | epoch 093:     12 / 64 loss=6.016, ppl=64.69, wps=6126.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.637, train_wall=479, gb_free=6.1, wall=30740
2022-01-28 15:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:29:40 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.731 | ppl 849.73 | wps 8498.5 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.212
2022-01-28 15:29:40 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-28 15:29:40 | INFO | train | epoch 093 | loss 5.989 | ppl 63.5 | wps 6267.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.64 | train_wall 307 | gb_free 6.1 | wall 31015
KL Stats: Epoch 93 Divergences: Uniform: 3.0643505559092463 Unigram: 2.9821856166858223
2022-01-28 15:29:40 | INFO | fairseq.trainer | begin training epoch 94
2022-01-28 15:29:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:33:32 | INFO | train_inner | epoch 094:     48 / 64 loss=5.975, ppl=62.92, wps=6450, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.65, train_wall=480, gb_free=6.1, wall=31247
2022-01-28 15:34:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:35:14 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.763 | ppl 869.11 | wps 8487.9 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.212
2022-01-28 15:35:14 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-28 15:35:14 | INFO | train | epoch 094 | loss 5.969 | ppl 62.65 | wps 6261.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.652 | train_wall 307 | gb_free 6.1 | wall 31349
KL Stats: Epoch 94 Divergences: Uniform: 3.0606136791874343 Unigram: 2.9910460114214508
2022-01-28 15:35:14 | INFO | fairseq.trainer | begin training epoch 95
2022-01-28 15:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:40:47 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.81 | ppl 897.53 | wps 8498.4 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.212
2022-01-28 15:40:47 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-28 15:40:47 | INFO | train | epoch 095 | loss 5.949 | ppl 61.78 | wps 6270.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.636 | train_wall 306 | gb_free 6.1 | wall 31682
KL Stats: Epoch 95 Divergences: Uniform: 3.0702467081126668 Unigram: 3.00402058382538
2022-01-28 15:40:47 | INFO | fairseq.trainer | begin training epoch 96
2022-01-28 15:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:42:24 | INFO | train_inner | epoch 096:     20 / 64 loss=5.949, ppl=61.77, wps=6132.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.645, train_wall=479, gb_free=6.1, wall=31778
2022-01-28 15:45:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:46:20 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.686 | ppl 823.72 | wps 8511.8 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.212
2022-01-28 15:46:20 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-28 15:46:20 | INFO | train | epoch 096 | loss 5.933 | ppl 61.11 | wps 6262.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.668 | train_wall 307 | gb_free 6.1 | wall 32015
KL Stats: Epoch 96 Divergences: Uniform: 3.0838956995852724 Unigram: 3.0159895884636185
2022-01-28 15:46:20 | INFO | fairseq.trainer | begin training epoch 97
2022-01-28 15:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:50:50 | INFO | train_inner | epoch 097:     56 / 64 loss=5.927, ppl=60.83, wps=6451.6, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.669, train_wall=480, gb_free=6.1, wall=32285
2022-01-28 15:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:51:53 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.8 | ppl 891.33 | wps 8495.3 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.212
2022-01-28 15:51:53 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-28 15:51:53 | INFO | train | epoch 097 | loss 5.915 | ppl 60.33 | wps 6278.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.669 | train_wall 306 | gb_free 6.1 | wall 32348
KL Stats: Epoch 97 Divergences: Uniform: 3.087607891042128 Unigram: 3.0282830963439533
2022-01-28 15:51:53 | INFO | fairseq.trainer | begin training epoch 98
2022-01-28 15:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 15:57:27 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.825 | ppl 907.1 | wps 8493.1 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.212
2022-01-28 15:57:27 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-28 15:57:27 | INFO | train | epoch 098 | loss 5.895 | ppl 59.53 | wps 6252.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.666 | train_wall 307 | gb_free 6.1 | wall 32682
KL Stats: Epoch 98 Divergences: Uniform: 3.085548492521378 Unigram: 3.030706777289027
2022-01-28 15:57:27 | INFO | fairseq.trainer | begin training epoch 99
2022-01-28 15:57:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 15:59:42 | INFO | train_inner | epoch 099:     28 / 64 loss=5.887, ppl=59.16, wps=6124.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.67, train_wall=479, gb_free=6.1, wall=32817
2022-01-28 16:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:03:01 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.771 | ppl 873.44 | wps 8517.1 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.212
2022-01-28 16:03:01 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-28 16:03:01 | INFO | train | epoch 099 | loss 5.879 | ppl 58.87 | wps 6265.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.68 | train_wall 307 | gb_free 6.1 | wall 33015
KL Stats: Epoch 99 Divergences: Uniform: 3.096195647412811 Unigram: 3.0434336857006277
2022-01-28 16:03:01 | INFO | fairseq.trainer | begin training epoch 100
2022-01-28 16:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:08:09 | INFO | train_inner | epoch 100:     64 / 64 loss=5.883, ppl=59, wps=6438.7, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.697, train_wall=479, gb_free=6.1, wall=33324
2022-01-28 16:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:08:34 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.731 | ppl 849.84 | wps 8479.9 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.212
2022-01-28 16:08:34 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-28 16:08:35 | INFO | train | epoch 100 | loss 5.866 | ppl 58.31 | wps 6253.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.705 | train_wall 307 | gb_free 6.1 | wall 33349
KL Stats: Epoch 100 Divergences: Uniform: 3.095336701358841 Unigram: 3.052665296470754
2022-01-28 16:08:35 | INFO | fairseq.trainer | begin training epoch 101
2022-01-28 16:08:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:14:07 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.791 | ppl 885.66 | wps 8510.6 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.212
2022-01-28 16:14:07 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-28 16:14:07 | INFO | train | epoch 101 | loss 5.844 | ppl 57.46 | wps 6273.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.682 | train_wall 306 | gb_free 6.1 | wall 33682
KL Stats: Epoch 101 Divergences: Uniform: 3.108724925764603 Unigram: 3.0663214344688376
2022-01-28 16:14:07 | INFO | fairseq.trainer | begin training epoch 102
2022-01-28 16:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:17:01 | INFO | train_inner | epoch 102:     36 / 64 loss=5.831, ppl=56.92, wps=6135.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.687, train_wall=480, gb_free=6.1, wall=33856
2022-01-28 16:19:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:19:41 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.815 | ppl 900.86 | wps 8498.5 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.212
2022-01-28 16:19:41 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-28 16:19:41 | INFO | train | epoch 102 | loss 5.832 | ppl 56.97 | wps 6261.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.706 | train_wall 307 | gb_free 6.1 | wall 34016
KL Stats: Epoch 102 Divergences: Uniform: 3.1029042304488113 Unigram: 3.0710060611281245
2022-01-28 16:19:41 | INFO | fairseq.trainer | begin training epoch 103
2022-01-28 16:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:25:15 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.823 | ppl 906.07 | wps 8507.5 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.212
2022-01-28 16:25:15 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-28 16:25:15 | INFO | train | epoch 103 | loss 5.813 | ppl 56.22 | wps 6261.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.682 | train_wall 307 | gb_free 6.1 | wall 34349
KL Stats: Epoch 103 Divergences: Uniform: 3.1176261321946983 Unigram: 3.084494119213255
2022-01-28 16:25:15 | INFO | fairseq.trainer | begin training epoch 104
2022-01-28 16:25:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:25:53 | INFO | train_inner | epoch 104:      8 / 64 loss=5.822, ppl=56.56, wps=6129.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.695, train_wall=479, gb_free=6.1, wall=34388
2022-01-28 16:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:30:48 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.827 | ppl 908.26 | wps 8522.3 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.212
2022-01-28 16:30:48 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-28 16:30:48 | INFO | train | epoch 104 | loss 5.802 | ppl 55.78 | wps 6263.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.705 | train_wall 307 | gb_free 6.1 | wall 34683
KL Stats: Epoch 104 Divergences: Uniform: 3.1101506677035804 Unigram: 3.0942053436121832
2022-01-28 16:30:48 | INFO | fairseq.trainer | begin training epoch 105
2022-01-28 16:30:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:34:20 | INFO | train_inner | epoch 105:     44 / 64 loss=5.789, ppl=55.29, wps=6445.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.703, train_wall=480, gb_free=6.1, wall=34895
2022-01-28 16:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:36:21 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.78 | ppl 879.36 | wps 8472.5 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.212
2022-01-28 16:36:21 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-28 16:36:21 | INFO | train | epoch 105 | loss 5.784 | ppl 55.11 | wps 6275.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.704 | train_wall 306 | gb_free 6.1 | wall 35016
KL Stats: Epoch 105 Divergences: Uniform: 3.1169002630739175 Unigram: 3.1020777231843746
2022-01-28 16:36:21 | INFO | fairseq.trainer | begin training epoch 106
2022-01-28 16:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:41:54 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.807 | ppl 895.62 | wps 8511.9 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.212
2022-01-28 16:41:54 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-28 16:41:54 | INFO | train | epoch 106 | loss 5.769 | ppl 54.53 | wps 6264.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.71 | train_wall 307 | gb_free 6.1 | wall 35349
KL Stats: Epoch 106 Divergences: Uniform: 3.1173691554858958 Unigram: 3.1100773451543096
2022-01-28 16:41:54 | INFO | fairseq.trainer | begin training epoch 107
2022-01-28 16:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:43:11 | INFO | train_inner | epoch 107:     16 / 64 loss=5.772, ppl=54.65, wps=6137.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.709, train_wall=478, gb_free=6.1, wall=35426
2022-01-28 16:47:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:47:28 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.789 | ppl 884.89 | wps 8471.9 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.212
2022-01-28 16:47:28 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-28 16:47:28 | INFO | train | epoch 107 | loss 5.755 | ppl 54.01 | wps 6259.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.709 | train_wall 307 | gb_free 6.1 | wall 35683
KL Stats: Epoch 107 Divergences: Uniform: 3.1297468546491913 Unigram: 3.1227323047013162
2022-01-28 16:47:28 | INFO | fairseq.trainer | begin training epoch 108
2022-01-28 16:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:51:39 | INFO | train_inner | epoch 108:     52 / 64 loss=5.751, ppl=53.84, wps=6436.6, ups=0.2, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.724, train_wall=481, gb_free=6.1, wall=35934
2022-01-28 16:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:53:02 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.826 | ppl 907.62 | wps 8480.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.212
2022-01-28 16:53:02 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-28 16:53:02 | INFO | train | epoch 108 | loss 5.743 | ppl 53.56 | wps 6253.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.73 | train_wall 307 | gb_free 6.1 | wall 36017
KL Stats: Epoch 108 Divergences: Uniform: 3.130486584535134 Unigram: 3.1265858982702492
2022-01-28 16:53:02 | INFO | fairseq.trainer | begin training epoch 109
2022-01-28 16:53:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 16:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 16:58:35 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.87 | ppl 935.73 | wps 8503.7 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.212
2022-01-28 16:58:35 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-28 16:58:35 | INFO | train | epoch 109 | loss 5.727 | ppl 52.96 | wps 6271.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.724 | train_wall 306 | gb_free 6.1 | wall 36350
KL Stats: Epoch 109 Divergences: Uniform: 3.1335150364817803 Unigram: 3.1365814128559113
2022-01-28 16:58:35 | INFO | fairseq.trainer | begin training epoch 110
2022-01-28 16:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:00:31 | INFO | train_inner | epoch 110:     24 / 64 loss=5.722, ppl=52.78, wps=6131.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.725, train_wall=479, gb_free=6.1, wall=36466
2022-01-28 17:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:04:08 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.886 | ppl 945.91 | wps 8511.7 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.212
2022-01-28 17:04:08 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-28 17:04:08 | INFO | train | epoch 110 | loss 5.716 | ppl 52.56 | wps 6263.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.729 | train_wall 307 | gb_free 6.1 | wall 36683
KL Stats: Epoch 110 Divergences: Uniform: 3.144504971891523 Unigram: 3.1463130781823034
2022-01-28 17:04:08 | INFO | fairseq.trainer | begin training epoch 111
2022-01-28 17:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:08:58 | INFO | train_inner | epoch 111:     60 / 64 loss=5.714, ppl=52.49, wps=6442.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.727, train_wall=480, gb_free=6.1, wall=36973
2022-01-28 17:09:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:09:42 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.821 | ppl 904.58 | wps 8493.9 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.212
2022-01-28 17:09:42 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-28 17:09:42 | INFO | train | epoch 111 | loss 5.701 | ppl 52.03 | wps 6259.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.729 | train_wall 307 | gb_free 6.1 | wall 37017
KL Stats: Epoch 111 Divergences: Uniform: 3.144323112591076 Unigram: 3.1601203568395486
2022-01-28 17:09:42 | INFO | fairseq.trainer | begin training epoch 112
2022-01-28 17:09:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:15:16 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.907 | ppl 960.34 | wps 8457.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.212
2022-01-28 17:15:16 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-28 17:15:16 | INFO | train | epoch 112 | loss 5.687 | ppl 51.53 | wps 6253.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.742 | train_wall 307 | gb_free 6.1 | wall 37351
KL Stats: Epoch 112 Divergences: Uniform: 3.1391891046888927 Unigram: 3.1656188878069123
2022-01-28 17:15:16 | INFO | fairseq.trainer | begin training epoch 113
2022-01-28 17:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:17:51 | INFO | train_inner | epoch 113:     32 / 64 loss=5.676, ppl=51.12, wps=6120.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.741, train_wall=480, gb_free=6.1, wall=37506
2022-01-28 17:20:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:20:49 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.873 | ppl 937.6 | wps 8524.3 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.212
2022-01-28 17:20:49 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-28 17:20:49 | INFO | train | epoch 113 | loss 5.673 | ppl 51.01 | wps 6269.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.739 | train_wall 307 | gb_free 6.1 | wall 37684
KL Stats: Epoch 113 Divergences: Uniform: 3.1569347419687976 Unigram: 3.1733781345357275
2022-01-28 17:20:49 | INFO | fairseq.trainer | begin training epoch 114
2022-01-28 17:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:26:23 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.898 | ppl 954.01 | wps 8502.3 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.212
2022-01-28 17:26:23 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-28 17:26:23 | INFO | train | epoch 114 | loss 5.661 | ppl 50.59 | wps 6258.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.757 | train_wall 307 | gb_free 6.1 | wall 38018
KL Stats: Epoch 114 Divergences: Uniform: 3.1507170635279262 Unigram: 3.1827235380596868
2022-01-28 17:26:23 | INFO | fairseq.trainer | begin training epoch 115
2022-01-28 17:26:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:26:42 | INFO | train_inner | epoch 115:      4 / 64 loss=5.673, ppl=51, wps=6132, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.754, train_wall=479, gb_free=6.1, wall=38037
2022-01-28 17:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:31:57 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.861 | ppl 930.07 | wps 8518.6 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.212
2022-01-28 17:31:57 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-28 17:31:57 | INFO | train | epoch 115 | loss 5.648 | ppl 50.14 | wps 6254 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.768 | train_wall 307 | gb_free 6.1 | wall 38352
KL Stats: Epoch 115 Divergences: Uniform: 3.159651173626747 Unigram: 3.1899656637795384
2022-01-28 17:31:57 | INFO | fairseq.trainer | begin training epoch 116
2022-01-28 17:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:35:10 | INFO | train_inner | epoch 116:     40 / 64 loss=5.635, ppl=49.68, wps=6434.7, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.759, train_wall=481, gb_free=6.1, wall=38545
2022-01-28 17:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:37:31 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.867 | ppl 934 | wps 8463 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.212
2022-01-28 17:37:31 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-28 17:37:31 | INFO | train | epoch 116 | loss 5.635 | ppl 49.7 | wps 6251.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.745 | train_wall 307 | gb_free 6.1 | wall 38686
KL Stats: Epoch 116 Divergences: Uniform: 3.153633775681429 Unigram: 3.1903435754289218
2022-01-28 17:37:31 | INFO | fairseq.trainer | begin training epoch 117
2022-01-28 17:37:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:43:04 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.909 | ppl 961.69 | wps 8520.4 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.212
2022-01-28 17:43:04 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-28 17:43:04 | INFO | train | epoch 117 | loss 5.624 | ppl 49.3 | wps 6276.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.749 | train_wall 306 | gb_free 6.1 | wall 39019
KL Stats: Epoch 117 Divergences: Uniform: 3.1608014364957917 Unigram: 3.2070332587267947
2022-01-28 17:43:04 | INFO | fairseq.trainer | begin training epoch 118
2022-01-28 17:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:44:02 | INFO | train_inner | epoch 118:     12 / 64 loss=5.628, ppl=49.46, wps=6133.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.752, train_wall=479, gb_free=6.1, wall=39077
2022-01-28 17:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:48:38 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.893 | ppl 950.71 | wps 8482 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.212
2022-01-28 17:48:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-28 17:48:38 | INFO | train | epoch 118 | loss 5.613 | ppl 48.95 | wps 6249.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.777 | train_wall 308 | gb_free 6.1 | wall 39353
KL Stats: Epoch 118 Divergences: Uniform: 3.166869802999856 Unigram: 3.2133602062120366
2022-01-28 17:48:38 | INFO | fairseq.trainer | begin training epoch 119
2022-01-28 17:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:52:30 | INFO | train_inner | epoch 119:     48 / 64 loss=5.602, ppl=48.58, wps=6429, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.767, train_wall=481, gb_free=6.1, wall=39585
2022-01-28 17:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:54:12 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.902 | ppl 956.94 | wps 8496.7 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.212
2022-01-28 17:54:12 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-28 17:54:12 | INFO | train | epoch 119 | loss 5.599 | ppl 48.48 | wps 6249.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.765 | train_wall 308 | gb_free 6.1 | wall 39687
KL Stats: Epoch 119 Divergences: Uniform: 3.172201657369303 Unigram: 3.2230997119434557
2022-01-28 17:54:12 | INFO | fairseq.trainer | begin training epoch 120
2022-01-28 17:54:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 17:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 17:59:46 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.939 | ppl 981.38 | wps 8479 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.212
2022-01-28 17:59:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-28 17:59:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint120.pt
2022-01-28 17:59:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint120.pt
2022-01-28 17:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.939) (writing took 3.563856760971248 seconds)
2022-01-28 17:59:49 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-28 17:59:49 | INFO | train | epoch 120 | loss 5.59 | ppl 48.17 | wps 6196 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.773 | train_wall 307 | gb_free 6.1 | wall 40024
KL Stats: Epoch 120 Divergences: Uniform: 3.1781836021650225 Unigram: 3.22927980173232
2022-01-28 17:59:49 | INFO | fairseq.trainer | begin training epoch 121
2022-01-28 17:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:01:26 | INFO | train_inner | epoch 121:     20 / 64 loss=5.591, ppl=48.22, wps=6085.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.774, train_wall=479, gb_free=6.1, wall=40121
2022-01-28 18:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:05:22 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.96 | ppl 996.18 | wps 8535.7 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.212
2022-01-28 18:05:22 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-28 18:05:22 | INFO | train | epoch 121 | loss 5.579 | ppl 47.8 | wps 6280.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.782 | train_wall 306 | gb_free 6.1 | wall 40357
KL Stats: Epoch 121 Divergences: Uniform: 3.174736450684637 Unigram: 3.2350913613730414
2022-01-28 18:05:22 | INFO | fairseq.trainer | begin training epoch 122
2022-01-28 18:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:09:52 | INFO | train_inner | epoch 122:     56 / 64 loss=5.576, ppl=47.69, wps=6451.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.787, train_wall=480, gb_free=6.1, wall=40627
2022-01-28 18:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:10:56 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.914 | ppl 964.8 | wps 8481.7 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.212
2022-01-28 18:10:56 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-28 18:10:56 | INFO | train | epoch 122 | loss 5.567 | ppl 47.4 | wps 6254.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.784 | train_wall 307 | gb_free 6.1 | wall 40691
KL Stats: Epoch 122 Divergences: Uniform: 3.181726049011779 Unigram: 3.2436303913566835
2022-01-28 18:10:56 | INFO | fairseq.trainer | begin training epoch 123
2022-01-28 18:10:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:16:29 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.966 | ppl 1000.05 | wps 8483.7 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.212
2022-01-28 18:16:29 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-28 18:16:29 | INFO | train | epoch 123 | loss 5.557 | ppl 47.07 | wps 6261.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.796 | train_wall 307 | gb_free 6.1 | wall 41024
KL Stats: Epoch 123 Divergences: Uniform: 3.1816717034385196 Unigram: 3.252862519917359
2022-01-28 18:16:29 | INFO | fairseq.trainer | begin training epoch 124
2022-01-28 18:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:18:45 | INFO | train_inner | epoch 124:     28 / 64 loss=5.549, ppl=46.82, wps=6125.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.791, train_wall=479, gb_free=6.1, wall=41159
2022-01-28 18:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:22:03 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.912 | ppl 963.68 | wps 8479.6 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.212
2022-01-28 18:22:03 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-28 18:22:03 | INFO | train | epoch 124 | loss 5.544 | ppl 46.66 | wps 6252.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.792 | train_wall 307 | gb_free 6.1 | wall 41358
KL Stats: Epoch 124 Divergences: Uniform: 3.171529963341386 Unigram: 3.2551559511947463
2022-01-28 18:22:03 | INFO | fairseq.trainer | begin training epoch 125
2022-01-28 18:22:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:27:11 | INFO | train_inner | epoch 125:     64 / 64 loss=5.548, ppl=46.79, wps=6440, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.805, train_wall=479, gb_free=6.1, wall=41666
2022-01-28 18:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:27:36 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.936 | ppl 979.57 | wps 8540.2 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.212
2022-01-28 18:27:36 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-28 18:27:36 | INFO | train | epoch 125 | loss 5.534 | ppl 46.34 | wps 6269.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.811 | train_wall 307 | gb_free 6.1 | wall 41691
KL Stats: Epoch 125 Divergences: Uniform: 3.184911737746786 Unigram: 3.2655485758927467
2022-01-28 18:27:36 | INFO | fairseq.trainer | begin training epoch 126
2022-01-28 18:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:32:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:33:10 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.923 | ppl 970.48 | wps 8503 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.212
2022-01-28 18:33:10 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-28 18:33:10 | INFO | train | epoch 126 | loss 5.524 | ppl 46.01 | wps 6265.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.795 | train_wall 307 | gb_free 6.1 | wall 42025
KL Stats: Epoch 126 Divergences: Uniform: 3.191268368080569 Unigram: 3.272555555600989
2022-01-28 18:33:10 | INFO | fairseq.trainer | begin training epoch 127
2022-01-28 18:33:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:36:04 | INFO | train_inner | epoch 127:     36 / 64 loss=5.512, ppl=45.63, wps=6132.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.805, train_wall=480, gb_free=6.1, wall=42199
2022-01-28 18:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:38:43 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.908 | ppl 960.76 | wps 8488.2 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.212
2022-01-28 18:38:43 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-28 18:38:43 | INFO | train | epoch 127 | loss 5.514 | ppl 45.71 | wps 6261.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.822 | train_wall 307 | gb_free 6.1 | wall 42358
KL Stats: Epoch 127 Divergences: Uniform: 3.1884019768507916 Unigram: 3.280528103463977
2022-01-28 18:38:43 | INFO | fairseq.trainer | begin training epoch 128
2022-01-28 18:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:44:17 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.918 | ppl 967.41 | wps 8498 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.212
2022-01-28 18:44:17 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-28 18:44:17 | INFO | train | epoch 128 | loss 5.502 | ppl 45.31 | wps 6263.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.819 | train_wall 307 | gb_free 6.1 | wall 42692
KL Stats: Epoch 128 Divergences: Uniform: 3.1888194779422725 Unigram: 3.2831524147545026
2022-01-28 18:44:17 | INFO | fairseq.trainer | begin training epoch 129
2022-01-28 18:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:44:55 | INFO | train_inner | epoch 129:      8 / 64 loss=5.51, ppl=45.56, wps=6130.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.821, train_wall=479, gb_free=6.1, wall=42730
2022-01-28 18:49:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:49:50 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.898 | ppl 953.81 | wps 8547.6 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.212
2022-01-28 18:49:50 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-28 18:49:50 | INFO | train | epoch 129 | loss 5.495 | ppl 45.11 | wps 6276.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.82 | train_wall 306 | gb_free 6.1 | wall 43024
KL Stats: Epoch 129 Divergences: Uniform: 3.191034844437018 Unigram: 3.2934530082936293
2022-01-28 18:49:50 | INFO | fairseq.trainer | begin training epoch 130
2022-01-28 18:49:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 18:53:23 | INFO | train_inner | epoch 130:     44 / 64 loss=5.483, ppl=44.74, wps=6445.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.813, train_wall=480, gb_free=6.1, wall=43237
2022-01-28 18:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 18:55:24 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.996 | ppl 1021.33 | wps 8503.8 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.212
2022-01-28 18:55:24 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-28 18:55:24 | INFO | train | epoch 130 | loss 5.484 | ppl 44.74 | wps 6249.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.812 | train_wall 308 | gb_free 6.1 | wall 43359
KL Stats: Epoch 130 Divergences: Uniform: 3.191748357062545 Unigram: 3.301491777155064
2022-01-28 18:55:24 | INFO | fairseq.trainer | begin training epoch 131
2022-01-28 18:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:00:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:00:57 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.928 | ppl 974.44 | wps 8507.1 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.212
2022-01-28 19:00:57 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-28 19:00:57 | INFO | train | epoch 131 | loss 5.477 | ppl 44.54 | wps 6266.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.843 | train_wall 307 | gb_free 6.1 | wall 43692
KL Stats: Epoch 131 Divergences: Uniform: 3.19072019254902 Unigram: 3.3014604386043085
2022-01-28 19:00:57 | INFO | fairseq.trainer | begin training epoch 132
2022-01-28 19:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:02:14 | INFO | train_inner | epoch 132:     16 / 64 loss=5.48, ppl=44.62, wps=6129.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.847, train_wall=479, gb_free=6.1, wall=43769
2022-01-28 19:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:06:31 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.925 | ppl 971.85 | wps 8521.4 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.212
2022-01-28 19:06:31 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-28 19:06:31 | INFO | train | epoch 132 | loss 5.466 | ppl 44.21 | wps 6259.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.87 | train_wall 307 | gb_free 6.1 | wall 44026
KL Stats: Epoch 132 Divergences: Uniform: 3.1984297635552092 Unigram: 3.3108707385437786
2022-01-28 19:06:31 | INFO | fairseq.trainer | begin training epoch 133
2022-01-28 19:06:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:10:42 | INFO | train_inner | epoch 133:     52 / 64 loss=5.46, ppl=44.01, wps=6444.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.854, train_wall=480, gb_free=6.1, wall=44276
2022-01-28 19:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:12:04 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.96 | ppl 995.73 | wps 8534.5 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.212
2022-01-28 19:12:04 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-28 19:12:04 | INFO | train | epoch 133 | loss 5.455 | ppl 43.85 | wps 6276.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.849 | train_wall 306 | gb_free 6.1 | wall 44358
KL Stats: Epoch 133 Divergences: Uniform: 3.206367482940091 Unigram: 3.318105811602901
2022-01-28 19:12:04 | INFO | fairseq.trainer | begin training epoch 134
2022-01-28 19:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:17:37 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.966 | ppl 1000.2 | wps 8472.5 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.212
2022-01-28 19:17:37 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-28 19:17:37 | INFO | train | epoch 134 | loss 5.448 | ppl 43.65 | wps 6257.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.867 | train_wall 307 | gb_free 6.1 | wall 44692
KL Stats: Epoch 134 Divergences: Uniform: 3.197374360803705 Unigram: 3.3192576316532114
2022-01-28 19:17:37 | INFO | fairseq.trainer | begin training epoch 135
2022-01-28 19:17:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:19:33 | INFO | train_inner | epoch 135:     24 / 64 loss=5.447, ppl=43.63, wps=6130.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.861, train_wall=479, gb_free=6.1, wall=44808
2022-01-28 19:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:23:11 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.936 | ppl 979.63 | wps 8496 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.212
2022-01-28 19:23:11 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-28 19:23:11 | INFO | train | epoch 135 | loss 5.439 | ppl 43.38 | wps 6263.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.854 | train_wall 307 | gb_free 6.1 | wall 45026
KL Stats: Epoch 135 Divergences: Uniform: 3.20364960489726 Unigram: 3.329928999522819
2022-01-28 19:23:11 | INFO | fairseq.trainer | begin training epoch 136
2022-01-28 19:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:28:01 | INFO | train_inner | epoch 136:     60 / 64 loss=5.439, ppl=43.37, wps=6444.3, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.862, train_wall=480, gb_free=6.1, wall=45315
2022-01-28 19:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:28:44 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.978 | ppl 1008.2 | wps 8488.2 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.212
2022-01-28 19:28:44 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-28 19:28:44 | INFO | train | epoch 136 | loss 5.429 | ppl 43.09 | wps 6260.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.865 | train_wall 307 | gb_free 6.1 | wall 45359
KL Stats: Epoch 136 Divergences: Uniform: 3.204405839952214 Unigram: 3.333655221696118
2022-01-28 19:28:44 | INFO | fairseq.trainer | begin training epoch 137
2022-01-28 19:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:34:17 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.978 | ppl 1008.72 | wps 8549.6 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.212
2022-01-28 19:34:17 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-28 19:34:17 | INFO | train | epoch 137 | loss 5.421 | ppl 42.86 | wps 6273 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.865 | train_wall 307 | gb_free 6.1 | wall 45692
KL Stats: Epoch 137 Divergences: Uniform: 3.204099863093004 Unigram: 3.341171640319079
2022-01-28 19:34:17 | INFO | fairseq.trainer | begin training epoch 138
2022-01-28 19:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:36:52 | INFO | train_inner | epoch 138:     32 / 64 loss=5.413, ppl=42.61, wps=6136.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.872, train_wall=478, gb_free=6.1, wall=45847
2022-01-28 19:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:39:51 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.043 | ppl 1055.1 | wps 8505.7 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.212
2022-01-28 19:39:51 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-28 19:39:51 | INFO | train | epoch 138 | loss 5.412 | ppl 42.57 | wps 6261.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.886 | train_wall 307 | gb_free 6.1 | wall 46026
KL Stats: Epoch 138 Divergences: Uniform: 3.2040944103659177 Unigram: 3.3437472446939442
2022-01-28 19:39:51 | INFO | fairseq.trainer | begin training epoch 139
2022-01-28 19:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:44:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:45:25 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.953 | ppl 991.29 | wps 8498.3 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.212
2022-01-28 19:45:25 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-28 19:45:25 | INFO | train | epoch 139 | loss 5.402 | ppl 42.28 | wps 6261.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.882 | train_wall 307 | gb_free 6.1 | wall 46359
KL Stats: Epoch 139 Divergences: Uniform: 3.209070317225619 Unigram: 3.3559910789681076
2022-01-28 19:45:25 | INFO | fairseq.trainer | begin training epoch 140
2022-01-28 19:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:45:44 | INFO | train_inner | epoch 140:      4 / 64 loss=5.41, ppl=42.5, wps=6126.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.883, train_wall=479, gb_free=6.1, wall=46379
2022-01-28 19:50:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:50:58 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.958 | ppl 994.46 | wps 8477.6 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.212
2022-01-28 19:50:58 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-28 19:50:58 | INFO | train | epoch 140 | loss 5.396 | ppl 42.1 | wps 6253.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.895 | train_wall 307 | gb_free 6.1 | wall 46693
KL Stats: Epoch 140 Divergences: Uniform: 3.2047800385999614 Unigram: 3.3583494767156434
2022-01-28 19:50:58 | INFO | fairseq.trainer | begin training epoch 141
2022-01-28 19:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 19:54:12 | INFO | train_inner | epoch 141:     40 / 64 loss=5.387, ppl=41.85, wps=6431.4, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.893, train_wall=481, gb_free=6.1, wall=46887
2022-01-28 19:56:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 19:56:32 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.012 | ppl 1032.7 | wps 8550.5 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.212
2022-01-28 19:56:32 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-28 19:56:32 | INFO | train | epoch 141 | loss 5.386 | ppl 41.82 | wps 6261.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.881 | train_wall 307 | gb_free 6.1 | wall 47027
KL Stats: Epoch 141 Divergences: Uniform: 3.2144156198632805 Unigram: 3.3674930064772375
2022-01-28 19:56:32 | INFO | fairseq.trainer | begin training epoch 142
2022-01-28 19:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:02:05 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.984 | ppl 1012.79 | wps 8495.6 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.212
2022-01-28 20:02:05 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-28 20:02:05 | INFO | train | epoch 142 | loss 5.378 | ppl 41.58 | wps 6271.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.929 | train_wall 306 | gb_free 6.1 | wall 47360
KL Stats: Epoch 142 Divergences: Uniform: 3.21181370002452 Unigram: 3.363554190488799
2022-01-28 20:02:05 | INFO | fairseq.trainer | begin training epoch 143
2022-01-28 20:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:03:03 | INFO | train_inner | epoch 143:     12 / 64 loss=5.379, ppl=41.63, wps=6139.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.913, train_wall=478, gb_free=6.1, wall=47418
2022-01-28 20:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:07:38 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.987 | ppl 1014.68 | wps 8497.9 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.212
2022-01-28 20:07:38 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-28 20:07:38 | INFO | train | epoch 143 | loss 5.371 | ppl 41.38 | wps 6265.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.902 | train_wall 307 | gb_free 6.1 | wall 47693
KL Stats: Epoch 143 Divergences: Uniform: 3.225005281167299 Unigram: 3.3724817003190015
2022-01-28 20:07:38 | INFO | fairseq.trainer | begin training epoch 144
2022-01-28 20:07:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:11:30 | INFO | train_inner | epoch 144:     48 / 64 loss=5.368, ppl=41.28, wps=6443.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.908, train_wall=480, gb_free=6.1, wall=47925
2022-01-28 20:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:13:12 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.029 | ppl 1044.58 | wps 8484.2 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.212
2022-01-28 20:13:12 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-28 20:13:12 | INFO | train | epoch 144 | loss 5.364 | ppl 41.17 | wps 6260.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.911 | train_wall 307 | gb_free 6.1 | wall 48027
KL Stats: Epoch 144 Divergences: Uniform: 3.213141496796318 Unigram: 3.375510767730564
2022-01-28 20:13:12 | INFO | fairseq.trainer | begin training epoch 145
2022-01-28 20:13:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:18:46 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.029 | ppl 1044.92 | wps 8575.9 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.212
2022-01-28 20:18:46 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-28 20:18:46 | INFO | train | epoch 145 | loss 5.357 | ppl 40.99 | wps 6262.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.938 | train_wall 307 | gb_free 6.1 | wall 48360
KL Stats: Epoch 145 Divergences: Uniform: 3.225605940215597 Unigram: 3.3861116230673014
2022-01-28 20:18:46 | INFO | fairseq.trainer | begin training epoch 146
2022-01-28 20:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:20:22 | INFO | train_inner | epoch 146:     20 / 64 loss=5.353, ppl=40.88, wps=6132.4, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.935, train_wall=479, gb_free=6.1, wall=48457
2022-01-28 20:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:24:19 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.048 | ppl 1058.7 | wps 8479.9 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.212
2022-01-28 20:24:19 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-28 20:24:19 | INFO | train | epoch 146 | loss 5.347 | ppl 40.71 | wps 6266.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.946 | train_wall 307 | gb_free 6.1 | wall 48694
KL Stats: Epoch 146 Divergences: Uniform: 3.2201238447858977 Unigram: 3.389756344182725
2022-01-28 20:24:19 | INFO | fairseq.trainer | begin training epoch 147
2022-01-28 20:24:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:28:50 | INFO | train_inner | epoch 147:     56 / 64 loss=5.348, ppl=40.73, wps=6435.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.929, train_wall=481, gb_free=6.1, wall=48965
2022-01-28 20:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:29:53 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.001 | ppl 1025.04 | wps 8517.8 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.212
2022-01-28 20:29:53 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-28 20:29:53 | INFO | train | epoch 147 | loss 5.339 | ppl 40.47 | wps 6255.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.926 | train_wall 307 | gb_free 6.1 | wall 49028
KL Stats: Epoch 147 Divergences: Uniform: 3.223390391070844 Unigram: 3.3966878366322186
2022-01-28 20:29:53 | INFO | fairseq.trainer | begin training epoch 148
2022-01-28 20:29:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:35:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:35:27 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.973 | ppl 1005.27 | wps 8491.6 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.212
2022-01-28 20:35:27 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-28 20:35:27 | INFO | train | epoch 148 | loss 5.332 | ppl 40.28 | wps 6254.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.939 | train_wall 307 | gb_free 6.1 | wall 49362
KL Stats: Epoch 148 Divergences: Uniform: 3.2219659873659325 Unigram: 3.400688609916054
2022-01-28 20:35:27 | INFO | fairseq.trainer | begin training epoch 149
2022-01-28 20:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:37:42 | INFO | train_inner | epoch 149:     28 / 64 loss=5.327, ppl=40.13, wps=6124.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.936, train_wall=479, gb_free=6.1, wall=49497
2022-01-28 20:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:41:01 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.045 | ppl 1056.22 | wps 8527.1 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.212
2022-01-28 20:41:01 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-28 20:41:01 | INFO | train | epoch 149 | loss 5.325 | ppl 40.1 | wps 6256.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.938 | train_wall 307 | gb_free 6.1 | wall 49695
KL Stats: Epoch 149 Divergences: Uniform: 3.2304524029301263 Unigram: 3.4057117999525954
2022-01-28 20:41:01 | INFO | fairseq.trainer | begin training epoch 150
2022-01-28 20:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:46:09 | INFO | train_inner | epoch 150:     64 / 64 loss=5.328, ppl=40.18, wps=6434.6, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.956, train_wall=480, gb_free=6.1, wall=50003
2022-01-28 20:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:46:34 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.019 | ppl 1037.37 | wps 8494.3 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.212
2022-01-28 20:46:34 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-28 20:46:34 | INFO | train | epoch 150 | loss 5.318 | ppl 39.89 | wps 6256.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.958 | train_wall 307 | gb_free 6.1 | wall 50029
KL Stats: Epoch 150 Divergences: Uniform: 3.230618757403696 Unigram: 3.4071539876940404
2022-01-28 20:46:34 | INFO | fairseq.trainer | begin training epoch 151
2022-01-28 20:46:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:51:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:52:08 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.05 | ppl 1059.92 | wps 8484.5 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.212
2022-01-28 20:52:08 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-28 20:52:08 | INFO | train | epoch 151 | loss 5.31 | ppl 39.68 | wps 6253.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.973 | train_wall 307 | gb_free 6.1 | wall 50363
KL Stats: Epoch 151 Divergences: Uniform: 3.2297676781046087 Unigram: 3.4148679665338184
2022-01-28 20:52:08 | INFO | fairseq.trainer | begin training epoch 152
2022-01-28 20:52:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 20:55:02 | INFO | train_inner | epoch 152:     36 / 64 loss=5.298, ppl=39.34, wps=6123.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.977, train_wall=481, gb_free=6.1, wall=50537
2022-01-28 20:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 20:57:42 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.032 | ppl 1047.2 | wps 8502.6 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.212
2022-01-28 20:57:42 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-28 20:57:42 | INFO | train | epoch 152 | loss 5.304 | ppl 39.51 | wps 6257.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.98 | train_wall 307 | gb_free 6.1 | wall 50697
KL Stats: Epoch 152 Divergences: Uniform: 3.2363407208662376 Unigram: 3.422062702090064
2022-01-28 20:57:42 | INFO | fairseq.trainer | begin training epoch 153
2022-01-28 20:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:02:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:03:16 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.988 | ppl 1015.72 | wps 8522.6 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.212
2022-01-28 21:03:16 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-28 21:03:16 | INFO | train | epoch 153 | loss 5.294 | ppl 39.24 | wps 6254.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.949 | train_wall 307 | gb_free 6.1 | wall 51031
KL Stats: Epoch 153 Divergences: Uniform: 3.2348445648095154 Unigram: 3.4263026784167945
2022-01-28 21:03:16 | INFO | fairseq.trainer | begin training epoch 154
2022-01-28 21:03:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:03:55 | INFO | train_inner | epoch 154:      8 / 64 loss=5.303, ppl=39.47, wps=6123.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.958, train_wall=480, gb_free=6.1, wall=51069
2022-01-28 21:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:08:50 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.056 | ppl 1064.67 | wps 8471 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.212
2022-01-28 21:08:50 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-28 21:08:50 | INFO | train | epoch 154 | loss 5.29 | ppl 39.12 | wps 6264.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.97 | train_wall 307 | gb_free 6.1 | wall 51364
KL Stats: Epoch 154 Divergences: Uniform: 3.241643020538452 Unigram: 3.430313965610753
2022-01-28 21:08:50 | INFO | fairseq.trainer | begin training epoch 155
2022-01-28 21:08:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:12:22 | INFO | train_inner | epoch 155:     44 / 64 loss=5.282, ppl=38.9, wps=6439.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.982, train_wall=480, gb_free=6.1, wall=51577
2022-01-28 21:13:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:14:23 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.089 | ppl 1089.26 | wps 8491.8 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.212
2022-01-28 21:14:23 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-01-28 21:14:23 | INFO | train | epoch 155 | loss 5.284 | ppl 38.96 | wps 6261.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.997 | train_wall 307 | gb_free 6.1 | wall 51698
KL Stats: Epoch 155 Divergences: Uniform: 3.236014870395144 Unigram: 3.4424263135729714
2022-01-28 21:14:23 | INFO | fairseq.trainer | begin training epoch 156
2022-01-28 21:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:19:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:19:57 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.076 | ppl 1079.17 | wps 8512.9 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.212
2022-01-28 21:19:57 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-01-28 21:19:57 | INFO | train | epoch 156 | loss 5.278 | ppl 38.79 | wps 6253.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.005 | train_wall 307 | gb_free 6.1 | wall 52032
KL Stats: Epoch 156 Divergences: Uniform: 3.234826482141277 Unigram: 3.4376325988261582
2022-01-28 21:19:57 | INFO | fairseq.trainer | begin training epoch 157
2022-01-28 21:19:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:21:14 | INFO | train_inner | epoch 157:     16 / 64 loss=5.283, ppl=38.94, wps=6124.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=0.995, train_wall=479, gb_free=6.1, wall=52109
2022-01-28 21:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:25:31 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.046 | ppl 1057.48 | wps 8517.7 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.212
2022-01-28 21:25:31 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-01-28 21:25:31 | INFO | train | epoch 157 | loss 5.269 | ppl 38.55 | wps 6262.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 0.985 | train_wall 307 | gb_free 6.1 | wall 52365
KL Stats: Epoch 157 Divergences: Uniform: 3.2387392370636285 Unigram: 3.450335510984506
2022-01-28 21:25:31 | INFO | fairseq.trainer | begin training epoch 158
2022-01-28 21:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:29:41 | INFO | train_inner | epoch 158:     52 / 64 loss=5.262, ppl=38.38, wps=6446.5, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.993, train_wall=480, gb_free=6.1, wall=52616
2022-01-28 21:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:31:04 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.098 | ppl 1095.89 | wps 8494.2 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.212
2022-01-28 21:31:04 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-01-28 21:31:04 | INFO | train | epoch 158 | loss 5.262 | ppl 38.38 | wps 6265.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.993 | train_wall 307 | gb_free 6.1 | wall 52699
KL Stats: Epoch 158 Divergences: Uniform: 3.2411868025131665 Unigram: 3.451385030204648
2022-01-28 21:31:04 | INFO | fairseq.trainer | begin training epoch 159
2022-01-28 21:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:36:38 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.083 | ppl 1084.41 | wps 8491.3 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.212
2022-01-28 21:36:38 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-01-28 21:36:38 | INFO | train | epoch 159 | loss 5.256 | ppl 38.21 | wps 6257.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 0.999 | train_wall 307 | gb_free 6.1 | wall 53033
KL Stats: Epoch 159 Divergences: Uniform: 3.232833174033743 Unigram: 3.459262600381058
2022-01-28 21:36:38 | INFO | fairseq.trainer | begin training epoch 160
2022-01-28 21:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:38:34 | INFO | train_inner | epoch 160:     24 / 64 loss=5.255, ppl=38.19, wps=6122.7, ups=0.19, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.002, train_wall=479, gb_free=6.1, wall=53149
2022-01-28 21:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:42:12 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.071 | ppl 1075.74 | wps 8495.3 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.212
2022-01-28 21:42:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-01-28 21:42:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint160.pt
2022-01-28 21:42:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint160.pt
2022-01-28 21:42:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.071) (writing took 3.5496991043910384 seconds)
2022-01-28 21:42:15 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-01-28 21:42:15 | INFO | train | epoch 160 | loss 5.251 | ppl 38.07 | wps 6188.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.02 | train_wall 307 | gb_free 6.1 | wall 53370
KL Stats: Epoch 160 Divergences: Uniform: 3.2384125562016823 Unigram: 3.4603333377965124
2022-01-28 21:42:15 | INFO | fairseq.trainer | begin training epoch 161
2022-01-28 21:42:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:47:05 | INFO | train_inner | epoch 161:     60 / 64 loss=5.251, ppl=38.08, wps=6393.4, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.022, train_wall=481, gb_free=6.1, wall=53660
2022-01-28 21:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:47:49 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.037 | ppl 1050.84 | wps 8510.6 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.212
2022-01-28 21:47:49 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-01-28 21:47:49 | INFO | train | epoch 161 | loss 5.243 | ppl 37.88 | wps 6262.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.019 | train_wall 307 | gb_free 6.1 | wall 53704
KL Stats: Epoch 161 Divergences: Uniform: 3.2479800258379115 Unigram: 3.46558921473639
2022-01-28 21:47:49 | INFO | fairseq.trainer | begin training epoch 162
2022-01-28 21:47:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:53:23 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.069 | ppl 1074.29 | wps 8501.1 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.212
2022-01-28 21:53:23 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-01-28 21:53:23 | INFO | train | epoch 162 | loss 5.237 | ppl 37.7 | wps 6251.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.02 | train_wall 307 | gb_free 6.1 | wall 54038
KL Stats: Epoch 162 Divergences: Uniform: 3.2485191469662356 Unigram: 3.4720291858559653
2022-01-28 21:53:23 | INFO | fairseq.trainer | begin training epoch 163
2022-01-28 21:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 21:55:58 | INFO | train_inner | epoch 163:     32 / 64 loss=5.224, ppl=37.37, wps=6117.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.025, train_wall=480, gb_free=6.1, wall=54193
2022-01-28 21:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 21:58:57 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.097 | ppl 1095.38 | wps 8480.2 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.212
2022-01-28 21:58:57 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-01-28 21:58:57 | INFO | train | epoch 163 | loss 5.233 | ppl 37.61 | wps 6245.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.042 | train_wall 308 | gb_free 6.1 | wall 54372
KL Stats: Epoch 163 Divergences: Uniform: 3.2483882274407576 Unigram: 3.4776440215967943
2022-01-28 21:58:57 | INFO | fairseq.trainer | begin training epoch 164
2022-01-28 21:58:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:04:32 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.023 | ppl 1040.3 | wps 8507 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.212
2022-01-28 22:04:32 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-01-28 22:04:32 | INFO | train | epoch 164 | loss 5.226 | ppl 37.42 | wps 6249.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.05 | train_wall 308 | gb_free 6.1 | wall 54706
KL Stats: Epoch 164 Divergences: Uniform: 3.2435764323538057 Unigram: 3.4790286183939263
2022-01-28 22:04:32 | INFO | fairseq.trainer | begin training epoch 165
2022-01-28 22:04:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:04:51 | INFO | train_inner | epoch 165:      4 / 64 loss=5.24, ppl=37.8, wps=6115.5, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.047, train_wall=480, gb_free=6.1, wall=54726
2022-01-28 22:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:10:05 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.116 | ppl 1110.1 | wps 8516.5 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.212
2022-01-28 22:10:05 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-01-28 22:10:05 | INFO | train | epoch 165 | loss 5.217 | ppl 37.2 | wps 6265 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.019 | train_wall 307 | gb_free 6.1 | wall 55040
KL Stats: Epoch 165 Divergences: Uniform: 3.247415441012732 Unigram: 3.48916096683084
2022-01-28 22:10:05 | INFO | fairseq.trainer | begin training epoch 166
2022-01-28 22:10:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:13:18 | INFO | train_inner | epoch 166:     40 / 64 loss=5.211, ppl=37.05, wps=6447.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.037, train_wall=480, gb_free=6.1, wall=55233
2022-01-28 22:15:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:15:38 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.021 | ppl 1039.06 | wps 8518.6 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.212
2022-01-28 22:15:38 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-01-28 22:15:38 | INFO | train | epoch 166 | loss 5.216 | ppl 37.16 | wps 6263.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.059 | train_wall 307 | gb_free 6.1 | wall 55373
KL Stats: Epoch 166 Divergences: Uniform: 3.2507272147624375 Unigram: 3.4887148590020165
2022-01-28 22:15:38 | INFO | fairseq.trainer | begin training epoch 167
2022-01-28 22:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:21:12 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.028 | ppl 1043.75 | wps 8467.5 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.212
2022-01-28 22:21:12 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-01-28 22:21:12 | INFO | train | epoch 167 | loss 5.206 | ppl 36.91 | wps 6255.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.052 | train_wall 307 | gb_free 6.1 | wall 55707
KL Stats: Epoch 167 Divergences: Uniform: 3.2463644910694702 Unigram: 3.490097366541267
2022-01-28 22:21:12 | INFO | fairseq.trainer | begin training epoch 168
2022-01-28 22:21:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:22:10 | INFO | train_inner | epoch 168:     12 / 64 loss=5.208, ppl=36.97, wps=6122.7, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.051, train_wall=480, gb_free=6.1, wall=55765
2022-01-28 22:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:26:46 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.133 | ppl 1122.77 | wps 8482.2 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.212
2022-01-28 22:26:46 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-01-28 22:26:46 | INFO | train | epoch 168 | loss 5.202 | ppl 36.8 | wps 6255 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.059 | train_wall 307 | gb_free 6.1 | wall 56041
KL Stats: Epoch 168 Divergences: Uniform: 3.2518742364933373 Unigram: 3.4934331450100427
2022-01-28 22:26:46 | INFO | fairseq.trainer | begin training epoch 169
2022-01-28 22:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:30:38 | INFO | train_inner | epoch 169:     48 / 64 loss=5.201, ppl=36.78, wps=6437.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.062, train_wall=480, gb_free=6.1, wall=56273
2022-01-28 22:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:32:20 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.049 | ppl 1059.39 | wps 8555 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.212
2022-01-28 22:32:20 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-01-28 22:32:20 | INFO | train | epoch 169 | loss 5.195 | ppl 36.63 | wps 6266 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.063 | train_wall 307 | gb_free 6.1 | wall 56374
KL Stats: Epoch 169 Divergences: Uniform: 3.254667992386562 Unigram: 3.5017697439688975
2022-01-28 22:32:20 | INFO | fairseq.trainer | begin training epoch 170
2022-01-28 22:32:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:37:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:37:53 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.065 | ppl 1071.34 | wps 8492.2 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.212
2022-01-28 22:37:53 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-01-28 22:37:53 | INFO | train | epoch 170 | loss 5.191 | ppl 36.53 | wps 6268.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.097 | train_wall 307 | gb_free 6.1 | wall 56708
KL Stats: Epoch 170 Divergences: Uniform: 3.2581615864939546 Unigram: 3.5027783706460167
2022-01-28 22:37:53 | INFO | fairseq.trainer | begin training epoch 171
2022-01-28 22:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:39:30 | INFO | train_inner | epoch 171:     20 / 64 loss=5.185, ppl=36.37, wps=6133.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.098, train_wall=479, gb_free=6.1, wall=56804
2022-01-28 22:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:43:27 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.074 | ppl 1077.67 | wps 8490.6 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.212
2022-01-28 22:43:27 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-01-28 22:43:27 | INFO | train | epoch 171 | loss 5.185 | ppl 36.37 | wps 6252.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.112 | train_wall 307 | gb_free 6.1 | wall 57042
KL Stats: Epoch 171 Divergences: Uniform: 3.253578696947229 Unigram: 3.5073408039209846
2022-01-28 22:43:27 | INFO | fairseq.trainer | begin training epoch 172
2022-01-28 22:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:47:58 | INFO | train_inner | epoch 172:     56 / 64 loss=5.188, ppl=36.45, wps=6424.6, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.091, train_wall=482, gb_free=6.1, wall=57313
2022-01-28 22:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:49:02 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.115 | ppl 1108.61 | wps 8445.5 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.212
2022-01-28 22:49:02 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-01-28 22:49:02 | INFO | train | epoch 172 | loss 5.179 | ppl 36.22 | wps 6235 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.087 | train_wall 308 | gb_free 6.1 | wall 57377
KL Stats: Epoch 172 Divergences: Uniform: 3.251818382205616 Unigram: 3.512715328231791
2022-01-28 22:49:02 | INFO | fairseq.trainer | begin training epoch 173
2022-01-28 22:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 22:54:36 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.089 | ppl 1089.13 | wps 8534.4 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.212
2022-01-28 22:54:36 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-01-28 22:54:36 | INFO | train | epoch 173 | loss 5.174 | ppl 36.09 | wps 6252.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.138 | train_wall 308 | gb_free 6.1 | wall 57711
KL Stats: Epoch 173 Divergences: Uniform: 3.256436805644672 Unigram: 3.5129159362486506
2022-01-28 22:54:36 | INFO | fairseq.trainer | begin training epoch 174
2022-01-28 22:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 22:56:51 | INFO | train_inner | epoch 174:     28 / 64 loss=5.168, ppl=35.94, wps=6122.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.121, train_wall=479, gb_free=6.1, wall=57845
2022-01-28 22:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:00:09 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.167 | ppl 1149.54 | wps 8481.8 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.212
2022-01-28 23:00:09 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-01-28 23:00:09 | INFO | train | epoch 174 | loss 5.169 | ppl 35.96 | wps 6265.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.111 | train_wall 307 | gb_free 6.1 | wall 58044
KL Stats: Epoch 174 Divergences: Uniform: 3.2537491875016524 Unigram: 3.520383773461692
2022-01-28 23:00:09 | INFO | fairseq.trainer | begin training epoch 175
2022-01-28 23:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:05:17 | INFO | train_inner | epoch 175:     64 / 64 loss=5.172, ppl=36.05, wps=6440.9, ups=0.2, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.131, train_wall=479, gb_free=6.1, wall=58352
2022-01-28 23:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:05:43 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.079 | ppl 1081.44 | wps 8484.9 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.212
2022-01-28 23:05:43 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-01-28 23:05:43 | INFO | train | epoch 175 | loss 5.162 | ppl 35.8 | wps 6264.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.126 | train_wall 307 | gb_free 6.1 | wall 58377
KL Stats: Epoch 175 Divergences: Uniform: 3.2623591334143587 Unigram: 3.5247173055351655
2022-01-28 23:05:43 | INFO | fairseq.trainer | begin training epoch 176
2022-01-28 23:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:11:16 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.094 | ppl 1092.97 | wps 8486.4 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.212
2022-01-28 23:11:16 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-01-28 23:11:16 | INFO | train | epoch 176 | loss 5.156 | ppl 35.66 | wps 6254.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.106 | train_wall 307 | gb_free 6.1 | wall 58711
KL Stats: Epoch 176 Divergences: Uniform: 3.2602489457043657 Unigram: 3.5277070002295523
2022-01-28 23:11:16 | INFO | fairseq.trainer | begin training epoch 177
2022-01-28 23:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:14:10 | INFO | train_inner | epoch 177:     36 / 64 loss=5.145, ppl=35.38, wps=6123.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.121, train_wall=481, gb_free=6.1, wall=58885
2022-01-28 23:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:16:50 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.043 | ppl 1054.63 | wps 8520.4 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.212
2022-01-28 23:16:50 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-01-28 23:16:50 | INFO | train | epoch 177 | loss 5.153 | ppl 35.58 | wps 6259.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.15 | train_wall 307 | gb_free 6.1 | wall 59045
KL Stats: Epoch 177 Divergences: Uniform: 3.262525429367966 Unigram: 3.5305600902846903
2022-01-28 23:16:50 | INFO | fairseq.trainer | begin training epoch 178
2022-01-28 23:16:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:22:23 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.116 | ppl 1109.61 | wps 8510.2 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.212
2022-01-28 23:22:23 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-01-28 23:22:23 | INFO | train | epoch 178 | loss 5.15 | ppl 35.5 | wps 6274 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.149 | train_wall 306 | gb_free 6.1 | wall 59378
KL Stats: Epoch 178 Divergences: Uniform: 3.2667548687152212 Unigram: 3.533893813676322
2022-01-28 23:22:23 | INFO | fairseq.trainer | begin training epoch 179
2022-01-28 23:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:23:02 | INFO | train_inner | epoch 179:      8 / 64 loss=5.157, ppl=35.68, wps=6135.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.148, train_wall=479, gb_free=6.1, wall=59417
2022-01-28 23:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:27:57 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.084 | ppl 1085.67 | wps 8474.4 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.212
2022-01-28 23:27:57 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-01-28 23:27:57 | INFO | train | epoch 179 | loss 5.143 | ppl 35.33 | wps 6253.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.163 | train_wall 307 | gb_free 6.1 | wall 59712
KL Stats: Epoch 179 Divergences: Uniform: 3.2670809868119632 Unigram: 3.5389117089790925
2022-01-28 23:27:57 | INFO | fairseq.trainer | begin training epoch 180
2022-01-28 23:27:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:31:30 | INFO | train_inner | epoch 180:     44 / 64 loss=5.139, ppl=35.23, wps=6433, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.166, train_wall=481, gb_free=6.1, wall=59925
2022-01-28 23:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:33:31 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.082 | ppl 1084.14 | wps 8510.2 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.212
2022-01-28 23:33:31 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-01-28 23:33:31 | INFO | train | epoch 180 | loss 5.139 | ppl 35.23 | wps 6252.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.169 | train_wall 307 | gb_free 6.1 | wall 60046
KL Stats: Epoch 180 Divergences: Uniform: 3.265704105231585 Unigram: 3.5458872042070535
2022-01-28 23:33:31 | INFO | fairseq.trainer | begin training epoch 181
2022-01-28 23:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:39:05 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.082 | ppl 1084.08 | wps 8490.3 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.212
2022-01-28 23:39:05 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-01-28 23:39:05 | INFO | train | epoch 181 | loss 5.13 | ppl 35.02 | wps 6248.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.161 | train_wall 308 | gb_free 6.1 | wall 60380
KL Stats: Epoch 181 Divergences: Uniform: 3.2665440372715935 Unigram: 3.5459490836169314
2022-01-28 23:39:05 | INFO | fairseq.trainer | begin training epoch 182
2022-01-28 23:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:40:22 | INFO | train_inner | epoch 182:     16 / 64 loss=5.131, ppl=35.04, wps=6120.8, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.165, train_wall=480, gb_free=6.1, wall=60457
2022-01-28 23:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:44:39 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.102 | ppl 1099.37 | wps 8492.6 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.212
2022-01-28 23:44:39 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-01-28 23:44:39 | INFO | train | epoch 182 | loss 5.128 | ppl 34.97 | wps 6265.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.185 | train_wall 307 | gb_free 6.1 | wall 60713
KL Stats: Epoch 182 Divergences: Uniform: 3.267540352428113 Unigram: 3.547210110699501
2022-01-28 23:44:39 | INFO | fairseq.trainer | begin training epoch 183
2022-01-28 23:44:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:48:50 | INFO | train_inner | epoch 183:     52 / 64 loss=5.126, ppl=34.92, wps=6437.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.19, train_wall=481, gb_free=6.1, wall=60965
2022-01-28 23:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:50:13 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.095 | ppl 1093.35 | wps 8506.5 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.212
2022-01-28 23:50:13 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-01-28 23:50:13 | INFO | train | epoch 183 | loss 5.122 | ppl 34.83 | wps 6253.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.187 | train_wall 307 | gb_free 6.1 | wall 61047
KL Stats: Epoch 183 Divergences: Uniform: 3.2686835075027934 Unigram: 3.553345172499425
2022-01-28 23:50:13 | INFO | fairseq.trainer | begin training epoch 184
2022-01-28 23:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-28 23:55:46 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.033 | ppl 1047.96 | wps 8508.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.212
2022-01-28 23:55:46 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-01-28 23:55:46 | INFO | train | epoch 184 | loss 5.118 | ppl 34.72 | wps 6264.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.191 | train_wall 307 | gb_free 6.1 | wall 61381
KL Stats: Epoch 184 Divergences: Uniform: 3.2693459463817938 Unigram: 3.55628643414734
2022-01-28 23:55:46 | INFO | fairseq.trainer | begin training epoch 185
2022-01-28 23:55:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-28 23:57:42 | INFO | train_inner | epoch 185:     24 / 64 loss=5.118, ppl=34.73, wps=6130.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.195, train_wall=479, gb_free=6.1, wall=61497
2022-01-29 00:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:01:20 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.105 | ppl 1101.46 | wps 8504.6 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.212
2022-01-29 00:01:20 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-01-29 00:01:20 | INFO | train | epoch 185 | loss 5.114 | ppl 34.63 | wps 6263.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.189 | train_wall 307 | gb_free 6.1 | wall 61714
KL Stats: Epoch 185 Divergences: Uniform: 3.2690791383193853 Unigram: 3.5600703137216176
2022-01-29 00:01:20 | INFO | fairseq.trainer | begin training epoch 186
2022-01-29 00:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:06:08 | INFO | train_inner | epoch 186:     60 / 64 loss=5.114, ppl=34.62, wps=6451.1, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.189, train_wall=480, gb_free=6.1, wall=62003
2022-01-29 00:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:06:52 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.018 | ppl 1036.91 | wps 8495.1 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.212
2022-01-29 00:06:52 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-01-29 00:06:52 | INFO | train | epoch 186 | loss 5.109 | ppl 34.52 | wps 6274.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.202 | train_wall 306 | gb_free 6.1 | wall 62047
KL Stats: Epoch 186 Divergences: Uniform: 3.274071165894171 Unigram: 3.562291663961838
2022-01-29 00:06:52 | INFO | fairseq.trainer | begin training epoch 187
2022-01-29 00:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:12:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:12:26 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.09 | ppl 1090.22 | wps 8515.3 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.212
2022-01-29 00:12:26 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-01-29 00:12:26 | INFO | train | epoch 187 | loss 5.105 | ppl 34.42 | wps 6255.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.214 | train_wall 307 | gb_free 6.1 | wall 62381
KL Stats: Epoch 187 Divergences: Uniform: 3.2696355744779666 Unigram: 3.5678597262738494
2022-01-29 00:12:26 | INFO | fairseq.trainer | begin training epoch 188
2022-01-29 00:12:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:15:01 | INFO | train_inner | epoch 188:     32 / 64 loss=5.098, ppl=34.25, wps=6122.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.205, train_wall=480, gb_free=6.1, wall=62536
2022-01-29 00:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:18:00 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.1 | ppl 1097.81 | wps 8484.3 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.212
2022-01-29 00:18:00 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-01-29 00:18:00 | INFO | train | epoch 188 | loss 5.098 | ppl 34.24 | wps 6259.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.205 | train_wall 307 | gb_free 6.1 | wall 62715
KL Stats: Epoch 188 Divergences: Uniform: 3.2680550343292953 Unigram: 3.567827181132486
2022-01-29 00:18:00 | INFO | fairseq.trainer | begin training epoch 189
2022-01-29 00:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:23:34 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.067 | ppl 1072.54 | wps 8519 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.212
2022-01-29 00:23:34 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-01-29 00:23:34 | INFO | train | epoch 189 | loss 5.094 | ppl 34.16 | wps 6260.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.236 | train_wall 307 | gb_free 6.1 | wall 63048
KL Stats: Epoch 189 Divergences: Uniform: 3.2723129934276205 Unigram: 3.574354289745258
2022-01-29 00:23:34 | INFO | fairseq.trainer | begin training epoch 190
2022-01-29 00:23:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:23:53 | INFO | train_inner | epoch 190:      4 / 64 loss=5.1, ppl=34.29, wps=6127.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.235, train_wall=479, gb_free=6.1, wall=63068
2022-01-29 00:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:29:07 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.104 | ppl 1100.8 | wps 8493.2 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.212
2022-01-29 00:29:07 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-01-29 00:29:07 | INFO | train | epoch 190 | loss 5.09 | ppl 34.05 | wps 6272.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.206 | train_wall 306 | gb_free 6.1 | wall 63381
KL Stats: Epoch 190 Divergences: Uniform: 3.2742238233103205 Unigram: 3.5778739323258346
2022-01-29 00:29:07 | INFO | fairseq.trainer | begin training epoch 191
2022-01-29 00:29:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:32:20 | INFO | train_inner | epoch 191:     40 / 64 loss=5.08, ppl=33.81, wps=6450.1, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.235, train_wall=480, gb_free=6.1, wall=63575
2022-01-29 00:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:34:40 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.075 | ppl 1078.31 | wps 8498.9 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.212
2022-01-29 00:34:40 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-01-29 00:34:40 | INFO | train | epoch 191 | loss 5.087 | ppl 33.98 | wps 6257.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.276 | train_wall 307 | gb_free 6.1 | wall 63715
KL Stats: Epoch 191 Divergences: Uniform: 3.271593173662398 Unigram: 3.5768974491928716
2022-01-29 00:34:40 | INFO | fairseq.trainer | begin training epoch 192
2022-01-29 00:34:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:40:14 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.068 | ppl 1073.74 | wps 8516.5 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.212
2022-01-29 00:40:14 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-01-29 00:40:14 | INFO | train | epoch 192 | loss 5.082 | ppl 33.86 | wps 6261.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.26 | train_wall 307 | gb_free 6.1 | wall 64049
KL Stats: Epoch 192 Divergences: Uniform: 3.2713508749875926 Unigram: 3.5751890181648536
2022-01-29 00:40:14 | INFO | fairseq.trainer | begin training epoch 193
2022-01-29 00:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:41:12 | INFO | train_inner | epoch 193:     12 / 64 loss=5.088, ppl=34.02, wps=6124.7, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.27, train_wall=479, gb_free=6.1, wall=64107
2022-01-29 00:45:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:45:47 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.068 | ppl 1073.15 | wps 8498.4 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.212
2022-01-29 00:45:47 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-01-29 00:45:47 | INFO | train | epoch 193 | loss 5.077 | ppl 33.74 | wps 6261.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.244 | train_wall 307 | gb_free 6.1 | wall 64382
KL Stats: Epoch 193 Divergences: Uniform: 3.2789860021470125 Unigram: 3.5841865777651893
2022-01-29 00:45:47 | INFO | fairseq.trainer | begin training epoch 194
2022-01-29 00:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:49:39 | INFO | train_inner | epoch 194:     48 / 64 loss=5.073, ppl=33.67, wps=6449.8, ups=0.2, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.259, train_wall=480, gb_free=6.1, wall=64613
2022-01-29 00:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:51:21 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.109 | ppl 1104.31 | wps 8475.2 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.212
2022-01-29 00:51:21 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-01-29 00:51:21 | INFO | train | epoch 194 | loss 5.073 | ppl 33.65 | wps 6268 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.307 | train_wall 307 | gb_free 6.1 | wall 64716
KL Stats: Epoch 194 Divergences: Uniform: 3.2748083668288475 Unigram: 3.587258579780724
2022-01-29 00:51:21 | INFO | fairseq.trainer | begin training epoch 195
2022-01-29 00:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 00:56:55 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.093 | ppl 1091.82 | wps 8487 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.212
2022-01-29 00:56:55 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-01-29 00:56:55 | INFO | train | epoch 195 | loss 5.071 | ppl 33.61 | wps 6253.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.309 | train_wall 307 | gb_free 6.1 | wall 65050
KL Stats: Epoch 195 Divergences: Uniform: 3.2774409271059066 Unigram: 3.589870094882611
2022-01-29 00:56:55 | INFO | fairseq.trainer | begin training epoch 196
2022-01-29 00:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 00:58:31 | INFO | train_inner | epoch 196:     20 / 64 loss=5.068, ppl=33.54, wps=6120.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.301, train_wall=480, gb_free=6.1, wall=65146
2022-01-29 01:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:02:29 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.095 | ppl 1093.43 | wps 8502.4 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.212
2022-01-29 01:02:29 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-01-29 01:02:29 | INFO | train | epoch 196 | loss 5.065 | ppl 33.46 | wps 6255.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.275 | train_wall 307 | gb_free 6.1 | wall 65383
KL Stats: Epoch 196 Divergences: Uniform: 3.274849717901698 Unigram: 3.591417507970804
2022-01-29 01:02:29 | INFO | fairseq.trainer | begin training epoch 197
2022-01-29 01:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:06:59 | INFO | train_inner | epoch 197:     56 / 64 loss=5.066, ppl=33.49, wps=6434.9, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.308, train_wall=481, gb_free=6.1, wall=65654
2022-01-29 01:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:08:02 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.075 | ppl 1078.75 | wps 8499.3 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.212
2022-01-29 01:08:02 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-01-29 01:08:02 | INFO | train | epoch 197 | loss 5.061 | ppl 33.38 | wps 6258.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.329 | train_wall 307 | gb_free 6.1 | wall 65717
KL Stats: Epoch 197 Divergences: Uniform: 3.2768667386576062 Unigram: 3.5940218680813953
2022-01-29 01:08:02 | INFO | fairseq.trainer | begin training epoch 198
2022-01-29 01:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:13:36 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.126 | ppl 1117.23 | wps 8496.6 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.212
2022-01-29 01:13:36 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-01-29 01:13:36 | INFO | train | epoch 198 | loss 5.055 | ppl 33.25 | wps 6264.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.322 | train_wall 307 | gb_free 6.1 | wall 66051
KL Stats: Epoch 198 Divergences: Uniform: 3.2799513538943046 Unigram: 3.6020607317599835
2022-01-29 01:13:36 | INFO | fairseq.trainer | begin training epoch 199
2022-01-29 01:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:15:51 | INFO | train_inner | epoch 199:     28 / 64 loss=5.051, ppl=33.14, wps=6128.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.326, train_wall=479, gb_free=6.1, wall=66186
2022-01-29 01:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:19:10 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.106 | ppl 1102.07 | wps 8481.5 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.212
2022-01-29 01:19:10 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-01-29 01:19:10 | INFO | train | epoch 199 | loss 5.052 | ppl 33.17 | wps 6253.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.318 | train_wall 307 | gb_free 6.1 | wall 66385
KL Stats: Epoch 199 Divergences: Uniform: 3.2806801593838086 Unigram: 3.606936278154836
2022-01-29 01:19:10 | INFO | fairseq.trainer | begin training epoch 200
2022-01-29 01:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:24:18 | INFO | train_inner | epoch 200:     64 / 64 loss=5.06, ppl=33.36, wps=6432.4, ups=0.2, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.335, train_wall=480, gb_free=6.1, wall=66693
2022-01-29 01:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:24:44 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.083 | ppl 1084.86 | wps 8481.9 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.212
2022-01-29 01:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-01-29 01:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint200.pt
2022-01-29 01:24:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint200.pt
2022-01-29 01:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.08_0.02_0.9/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.083) (writing took 4.351784218102694 seconds)
2022-01-29 01:24:48 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-01-29 01:24:48 | INFO | train | epoch 200 | loss 5.048 | ppl 33.09 | wps 6171.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.343 | train_wall 307 | gb_free 6.1 | wall 66723
KL Stats: Epoch 200 Divergences: Uniform: 3.277536243636821 Unigram: 3.6064652072764267
2022-01-29 01:24:48 | INFO | fairseq.trainer | begin training epoch 201
2022-01-29 01:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:29:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:30:22 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.115 | ppl 1108.9 | wps 8485.2 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.212
2022-01-29 01:30:22 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-01-29 01:30:22 | INFO | train | epoch 201 | loss 5.044 | ppl 33 | wps 6255.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.344 | train_wall 307 | gb_free 6.1 | wall 67057
KL Stats: Epoch 201 Divergences: Uniform: 3.2737767121763266 Unigram: 3.6058381828159107
2022-01-29 01:30:22 | INFO | fairseq.trainer | begin training epoch 202
2022-01-29 01:30:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:33:15 | INFO | train_inner | epoch 202:     36 / 64 loss=5.031, ppl=32.7, wps=6082.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.358, train_wall=480, gb_free=6.1, wall=67230
2022-01-29 01:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:35:55 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.109 | ppl 1104.54 | wps 8469.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.212
2022-01-29 01:35:55 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-01-29 01:35:55 | INFO | train | epoch 202 | loss 5.04 | ppl 32.9 | wps 6272.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.376 | train_wall 306 | gb_free 6.1 | wall 67390
KL Stats: Epoch 202 Divergences: Uniform: 3.278938196946714 Unigram: 3.613206090050912
2022-01-29 01:35:55 | INFO | fairseq.trainer | begin training epoch 203
2022-01-29 01:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:41:29 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.12 | ppl 1112.51 | wps 8491 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.212
2022-01-29 01:41:29 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-01-29 01:41:29 | INFO | train | epoch 203 | loss 5.034 | ppl 32.76 | wps 6261.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.339 | train_wall 307 | gb_free 6.1 | wall 67723
KL Stats: Epoch 203 Divergences: Uniform: 3.2766958436487625 Unigram: 3.61935782231493
2022-01-29 01:41:29 | INFO | fairseq.trainer | begin training epoch 204
2022-01-29 01:41:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:42:07 | INFO | train_inner | epoch 204:      8 / 64 loss=5.043, ppl=32.97, wps=6127.1, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.356, train_wall=479, gb_free=6.1, wall=67762
2022-01-29 01:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:47:02 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.084 | ppl 1085.19 | wps 8489.8 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.212
2022-01-29 01:47:02 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-01-29 01:47:02 | INFO | train | epoch 204 | loss 5.03 | ppl 32.68 | wps 6258.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.376 | train_wall 307 | gb_free 6.1 | wall 68057
KL Stats: Epoch 204 Divergences: Uniform: 3.2830053191686597 Unigram: 3.6195615905155565
2022-01-29 01:47:02 | INFO | fairseq.trainer | begin training epoch 205
2022-01-29 01:47:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:50:35 | INFO | train_inner | epoch 205:     44 / 64 loss=5.026, ppl=32.58, wps=6437.5, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.377, train_wall=481, gb_free=6.1, wall=68270
2022-01-29 01:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:52:36 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.135 | ppl 1124.51 | wps 8514.4 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.212
2022-01-29 01:52:36 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-01-29 01:52:36 | INFO | train | epoch 205 | loss 5.027 | ppl 32.6 | wps 6260.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.409 | train_wall 307 | gb_free 6.1 | wall 68391
KL Stats: Epoch 205 Divergences: Uniform: 3.2795173829785993 Unigram: 3.622830511250604
2022-01-29 01:52:36 | INFO | fairseq.trainer | begin training epoch 206
2022-01-29 01:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 01:58:09 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.12 | ppl 1112.69 | wps 8499.1 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.212
2022-01-29 01:58:09 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-01-29 01:58:09 | INFO | train | epoch 206 | loss 5.024 | ppl 32.55 | wps 6263.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.367 | train_wall 307 | gb_free 6.1 | wall 68724
KL Stats: Epoch 206 Divergences: Uniform: 3.27717811438014 Unigram: 3.624462150754899
2022-01-29 01:58:09 | INFO | fairseq.trainer | begin training epoch 207
2022-01-29 01:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 01:59:27 | INFO | train_inner | epoch 207:     16 / 64 loss=5.026, ppl=32.58, wps=6130.5, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.396, train_wall=479, gb_free=6.1, wall=68802
2022-01-29 02:03:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:03:43 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.1 | ppl 1097.75 | wps 8512.9 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.212
2022-01-29 02:03:43 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-01-29 02:03:43 | INFO | train | epoch 207 | loss 5.022 | ppl 32.5 | wps 6256.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.442 | train_wall 307 | gb_free 6.1 | wall 69058
KL Stats: Epoch 207 Divergences: Uniform: 3.280787353138896 Unigram: 3.6227188149505967
2022-01-29 02:03:43 | INFO | fairseq.trainer | begin training epoch 208
2022-01-29 02:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:07:55 | INFO | train_inner | epoch 208:     52 / 64 loss=5.019, ppl=32.42, wps=6432.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.408, train_wall=481, gb_free=6.1, wall=69310
2022-01-29 02:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:09:17 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.173 | ppl 1154.63 | wps 8482.9 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.212
2022-01-29 02:09:17 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-01-29 02:09:17 | INFO | train | epoch 208 | loss 5.016 | ppl 32.36 | wps 6250.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.382 | train_wall 307 | gb_free 6.1 | wall 69392
KL Stats: Epoch 208 Divergences: Uniform: 3.2802907526360796 Unigram: 3.6303732534858106
2022-01-29 02:09:17 | INFO | fairseq.trainer | begin training epoch 209
2022-01-29 02:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:14:51 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 10.116 | ppl 1109.53 | wps 8500.8 | wpb 2034.1 | bsz 4 | num_updates 13376 | best_loss 9.212
2022-01-29 02:14:51 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-01-29 02:14:51 | INFO | train | epoch 209 | loss 5.014 | ppl 32.3 | wps 6254 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13376 | lr 0.000273424 | gnorm 1.441 | train_wall 307 | gb_free 6.1 | wall 69726
KL Stats: Epoch 209 Divergences: Uniform: 3.2841103535147176 Unigram: 3.6318934343679183
2022-01-29 02:14:51 | INFO | fairseq.trainer | begin training epoch 210
2022-01-29 02:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:16:47 | INFO | train_inner | epoch 210:     24 / 64 loss=5.01, ppl=32.22, wps=6121.3, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13400, lr=0.000273179, gnorm=1.432, train_wall=480, gb_free=6.1, wall=69842
2022-01-29 02:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:20:25 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 10.132 | ppl 1121.77 | wps 8489.8 | wpb 2034.1 | bsz 4 | num_updates 13440 | best_loss 9.212
2022-01-29 02:20:25 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-01-29 02:20:25 | INFO | train | epoch 210 | loss 5.008 | ppl 32.17 | wps 6256.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13440 | lr 0.000272772 | gnorm 1.432 | train_wall 307 | gb_free 6.1 | wall 70060
KL Stats: Epoch 210 Divergences: Uniform: 3.286372666458421 Unigram: 3.6376627980472245
2022-01-29 02:20:25 | INFO | fairseq.trainer | begin training epoch 211
2022-01-29 02:20:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:25:15 | INFO | train_inner | epoch 211:     60 / 64 loss=5.009, ppl=32.21, wps=6436.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13500, lr=0.000272166, gnorm=1.414, train_wall=481, gb_free=6.1, wall=70350
2022-01-29 02:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:25:59 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 10.124 | ppl 1115.7 | wps 8492.5 | wpb 2034.1 | bsz 4 | num_updates 13504 | best_loss 9.212
2022-01-29 02:25:59 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-01-29 02:25:59 | INFO | train | epoch 211 | loss 5.003 | ppl 32.07 | wps 6254.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13504 | lr 0.000272125 | gnorm 1.393 | train_wall 307 | gb_free 6.1 | wall 70394
KL Stats: Epoch 211 Divergences: Uniform: 3.2833911316478406 Unigram: 3.641740841914218
2022-01-29 02:25:59 | INFO | fairseq.trainer | begin training epoch 212
2022-01-29 02:25:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:31:33 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 10.14 | ppl 1128.04 | wps 8491 | wpb 2034.1 | bsz 4 | num_updates 13568 | best_loss 9.212
2022-01-29 02:31:33 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-01-29 02:31:33 | INFO | train | epoch 212 | loss 5.003 | ppl 32.06 | wps 6263.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13568 | lr 0.000271483 | gnorm 1.445 | train_wall 307 | gb_free 6.1 | wall 70727
KL Stats: Epoch 212 Divergences: Uniform: 3.2899251409599213 Unigram: 3.6400298100813093
2022-01-29 02:31:33 | INFO | fairseq.trainer | begin training epoch 213
2022-01-29 02:31:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:34:07 | INFO | train_inner | epoch 213:     32 / 64 loss=4.995, ppl=31.9, wps=6127.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=13600, lr=0.000271163, gnorm=1.427, train_wall=479, gb_free=6.1, wall=70882
2022-01-29 02:36:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:37:06 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 10.124 | ppl 1115.76 | wps 8495 | wpb 2034.1 | bsz 4 | num_updates 13632 | best_loss 9.212
2022-01-29 02:37:06 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-01-29 02:37:06 | INFO | train | epoch 213 | loss 4.997 | ppl 31.93 | wps 6257.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13632 | lr 0.000270845 | gnorm 1.416 | train_wall 307 | gb_free 6.1 | wall 71061
KL Stats: Epoch 213 Divergences: Uniform: 3.288086954667946 Unigram: 3.6450606655979283
2022-01-29 02:37:06 | INFO | fairseq.trainer | begin training epoch 214
2022-01-29 02:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:42:39 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 10.157 | ppl 1141.8 | wps 8514.5 | wpb 2034.1 | bsz 4 | num_updates 13696 | best_loss 9.212
2022-01-29 02:42:39 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-01-29 02:42:39 | INFO | train | epoch 214 | loss 4.996 | ppl 31.9 | wps 6272.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13696 | lr 0.000270211 | gnorm 1.486 | train_wall 306 | gb_free 6.1 | wall 71394
KL Stats: Epoch 214 Divergences: Uniform: 3.2899723728127444 Unigram: 3.649084033195675
2022-01-29 02:42:39 | INFO | fairseq.trainer | begin training epoch 215
2022-01-29 02:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:42:59 | INFO | train_inner | epoch 215:      4 / 64 loss=5.001, ppl=32.03, wps=6133.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=13700, lr=0.000270172, gnorm=1.473, train_wall=479, gb_free=6.1, wall=71414
2022-01-29 02:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-29 02:48:13 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 10.101 | ppl 1098.57 | wps 8503.5 | wpb 2034.1 | bsz 4 | num_updates 13760 | best_loss 9.212
2022-01-29 02:48:13 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-01-29 02:48:13 | INFO | train | epoch 215 | loss 4.991 | ppl 31.79 | wps 6257 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 13760 | lr 0.000269582 | gnorm 1.5 | train_wall 307 | gb_free 6.1 | wall 71728
KL Stats: Epoch 215 Divergences: Uniform: 3.2890813899897386 Unigram: 3.6488753410640737
2022-01-29 02:48:13 | INFO | fairseq.trainer | begin training epoch 216
2022-01-29 02:48:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-29 02:51:26 | INFO | train_inner | epoch 216:     40 / 64 loss=4.985, ppl=31.66, wps=6436.2, ups=0.2, wpb=32679.4, bsz=63.8, num_updates=13800, lr=0.000269191, gnorm=1.494, train_wall=481, gb_free=6.1, wall=71921
User defined signal 2
