Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 210652720: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:52:02 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:52:08 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:52:08 2022
Terminated at Thu Mar 24 00:32:34 2022
Results reported at Thu Mar 24 00:32:34 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.02 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   20397.43 sec.
    Max Memory :                                 5301 MB
    Average Memory :                             4588.47 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14699.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   20425 sec.
    Turnaround time :                            20432 sec.

The output (if any) follows:

2022-03-23 18:52:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.02, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.02, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:52:15 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:52:15 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:52:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:52:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:52:16 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1108/160239 [00:00<00:14, 11078.16it/s]  2%|▏         | 2436/160239 [00:00<00:12, 12368.02it/s]  2%|▏         | 3791/160239 [00:00<00:12, 12902.52it/s]  3%|▎         | 5110/160239 [00:00<00:11, 13013.69it/s]  4%|▍         | 6412/160239 [00:00<00:11, 12860.70it/s]  5%|▍         | 7699/160239 [00:00<00:11, 12744.11it/s]  6%|▌         | 8974/160239 [00:00<00:12, 12591.03it/s]  6%|▋         | 10298/160239 [00:00<00:11, 12793.97it/s]  7%|▋         | 11579/160239 [00:00<00:11, 12740.16it/s]  8%|▊         | 12854/160239 [00:01<00:11, 12695.99it/s]  9%|▉         | 14124/160239 [00:01<00:11, 12679.75it/s] 10%|▉         | 15393/160239 [00:01<00:11, 12491.33it/s] 10%|█         | 16643/160239 [00:01<00:11, 12340.89it/s] 11%|█         | 17894/160239 [00:01<00:11, 12388.87it/s] 12%|█▏        | 19172/160239 [00:01<00:11, 12504.72it/s] 13%|█▎        | 20589/160239 [00:01<00:10, 12999.29it/s] 14%|█▎        | 21890/160239 [00:01<00:11, 12540.73it/s] 14%|█▍        | 23148/160239 [00:01<00:11, 12432.24it/s] 15%|█▌        | 24418/160239 [00:01<00:10, 12508.27it/s] 16%|█▌        | 25705/160239 [00:02<00:10, 12608.89it/s] 17%|█▋        | 26968/160239 [00:02<00:10, 12396.84it/s] 18%|█▊        | 28305/160239 [00:02<00:10, 12680.50it/s] 18%|█▊        | 29575/160239 [00:02<00:10, 12639.51it/s] 19%|█▉        | 30841/160239 [00:02<00:10, 12353.80it/s] 20%|██        | 32199/160239 [00:02<00:10, 12709.28it/s] 21%|██        | 33473/160239 [00:02<00:10, 12271.04it/s] 22%|██▏       | 34705/160239 [00:02<00:10, 12120.78it/s] 22%|██▏       | 35979/160239 [00:02<00:10, 12299.37it/s] 23%|██▎       | 37212/160239 [00:02<00:10, 12200.38it/s] 24%|██▍       | 38486/160239 [00:03<00:09, 12356.53it/s] 25%|██▍       | 39724/160239 [00:03<00:09, 12336.56it/s] 26%|██▌       | 41030/160239 [00:03<00:09, 12549.68it/s] 26%|██▋       | 42287/160239 [00:03<00:09, 12263.77it/s] 27%|██▋       | 43516/160239 [00:03<00:09, 12141.09it/s] 28%|██▊       | 44732/160239 [00:03<00:09, 11981.03it/s] 29%|██▉       | 46071/160239 [00:03<00:09, 12392.44it/s] 30%|██▉       | 47332/160239 [00:03<00:09, 12454.40it/s] 30%|███       | 48579/160239 [00:03<00:08, 12419.70it/s] 31%|███       | 49836/160239 [00:03<00:08, 12459.86it/s] 32%|███▏      | 51124/160239 [00:04<00:08, 12583.36it/s] 33%|███▎      | 52405/160239 [00:04<00:08, 12647.70it/s] 33%|███▎      | 53671/160239 [00:04<00:08, 12462.59it/s] 34%|███▍      | 54967/160239 [00:04<00:08, 12609.40it/s] 35%|███▌      | 56262/160239 [00:04<00:08, 12708.05it/s] 36%|███▌      | 57577/160239 [00:04<00:07, 12837.05it/s] 37%|███▋      | 58884/160239 [00:04<00:07, 12903.08it/s] 38%|███▊      | 60175/160239 [00:04<00:07, 12868.65it/s] 38%|███▊      | 61463/160239 [00:04<00:07, 12610.90it/s] 39%|███▉      | 62814/160239 [00:05<00:07, 12874.60it/s] 40%|████      | 64103/160239 [00:05<00:07, 12754.85it/s] 41%|████      | 65613/160239 [00:05<00:07, 13444.93it/s] 42%|████▏     | 66960/160239 [00:05<00:07, 13195.65it/s] 43%|████▎     | 68282/160239 [00:05<00:07, 12959.32it/s] 43%|████▎     | 69580/160239 [00:05<00:07, 12497.61it/s] 44%|████▍     | 70834/160239 [00:05<00:07, 12439.56it/s] 45%|████▌     | 72109/160239 [00:05<00:07, 12525.33it/s] 46%|████▌     | 73364/160239 [00:05<00:07, 12350.89it/s] 47%|████▋     | 74601/160239 [00:05<00:06, 12340.63it/s] 47%|████▋     | 75851/160239 [00:06<00:06, 12386.11it/s] 48%|████▊     | 77167/160239 [00:06<00:06, 12612.08it/s] 49%|████▉     | 78499/160239 [00:06<00:06, 12818.18it/s] 50%|████▉     | 79808/160239 [00:06<00:06, 12898.65it/s] 51%|█████     | 81243/160239 [00:06<00:05, 13329.70it/s] 52%|█████▏    | 82577/160239 [00:06<00:05, 13022.36it/s] 52%|█████▏    | 83898/160239 [00:06<00:05, 13073.56it/s] 53%|█████▎    | 85207/160239 [00:06<00:05, 12813.04it/s] 54%|█████▍    | 86607/160239 [00:06<00:05, 13160.12it/s] 55%|█████▍    | 87932/160239 [00:06<00:05, 13185.38it/s] 56%|█████▌    | 89253/160239 [00:07<00:05, 13028.08it/s] 57%|█████▋    | 90587/160239 [00:07<00:05, 13118.44it/s] 57%|█████▋    | 91900/160239 [00:07<00:05, 12771.59it/s] 58%|█████▊    | 93198/160239 [00:07<00:05, 12828.48it/s] 59%|█████▉    | 94483/160239 [00:07<00:05, 12573.60it/s] 60%|█████▉    | 95791/160239 [00:07<00:05, 12720.04it/s] 61%|██████    | 97065/160239 [00:07<00:04, 12651.12it/s] 61%|██████▏   | 98355/160239 [00:07<00:04, 12722.95it/s] 62%|██████▏   | 99661/160239 [00:07<00:04, 12821.78it/s] 63%|██████▎   | 101003/160239 [00:07<00:04, 12997.45it/s] 64%|██████▍   | 102304/160239 [00:08<00:04, 12959.02it/s] 65%|██████▍   | 103601/160239 [00:08<00:04, 12634.21it/s] 66%|██████▌   | 104994/160239 [00:08<00:04, 13013.41it/s] 66%|██████▋   | 106298/160239 [00:08<00:04, 12862.05it/s] 67%|██████▋   | 107586/160239 [00:08<00:04, 12579.20it/s] 68%|██████▊   | 108847/160239 [00:08<00:04, 12353.50it/s] 69%|██████▊   | 110085/160239 [00:08<00:04, 12279.87it/s] 70%|██████▉   | 111380/160239 [00:08<00:03, 12473.45it/s] 70%|███████   | 112693/160239 [00:08<00:03, 12665.29it/s] 71%|███████   | 113972/160239 [00:09<00:03, 12700.50it/s] 72%|███████▏  | 115244/160239 [00:09<00:03, 12662.13it/s] 73%|███████▎  | 116511/160239 [00:09<00:03, 12570.81it/s] 74%|███████▎  | 117776/160239 [00:09<00:03, 12592.81it/s] 74%|███████▍  | 119118/160239 [00:09<00:03, 12837.03it/s] 75%|███████▌  | 120403/160239 [00:09<00:03, 12640.79it/s] 76%|███████▌  | 121670/160239 [00:09<00:03, 12647.99it/s] 77%|███████▋  | 123072/160239 [00:09<00:02, 13047.98it/s] 78%|███████▊  | 124378/160239 [00:09<00:02, 12777.52it/s] 78%|███████▊  | 125658/160239 [00:09<00:02, 12591.82it/s] 79%|███████▉  | 126950/160239 [00:10<00:02, 12685.70it/s] 80%|████████  | 128266/160239 [00:10<00:02, 12823.42it/s] 81%|████████  | 129550/160239 [00:10<00:02, 12512.92it/s] 82%|████████▏ | 130804/160239 [00:10<00:02, 12243.18it/s] 82%|████████▏ | 132045/160239 [00:10<00:02, 12290.21it/s] 83%|████████▎ | 133276/160239 [00:10<00:02, 12253.79it/s] 84%|████████▍ | 134503/160239 [00:10<00:02, 12185.50it/s] 85%|████████▍ | 135787/160239 [00:10<00:01, 12375.99it/s] 86%|████████▌ | 137071/160239 [00:10<00:01, 12509.32it/s] 86%|████████▋ | 138371/160239 [00:10<00:01, 12650.36it/s] 87%|████████▋ | 139721/160239 [00:11<00:01, 12902.58it/s] 88%|████████▊ | 141038/160239 [00:11<00:01, 12980.80it/s] 89%|████████▉ | 142337/160239 [00:11<00:01, 12820.42it/s] 90%|████████▉ | 143620/160239 [00:11<00:01, 12647.43it/s] 90%|█████████ | 144886/160239 [00:11<00:01, 12545.57it/s] 91%|█████████ | 146142/160239 [00:11<00:01, 12333.96it/s] 92%|█████████▏| 147378/160239 [00:11<00:01, 12340.21it/s] 93%|█████████▎| 148613/160239 [00:11<00:00, 12063.77it/s] 94%|█████████▎| 149854/160239 [00:11<00:00, 12163.63it/s] 94%|█████████▍| 151134/160239 [00:11<00:00, 12347.77it/s] 95%|█████████▌| 152409/160239 [00:12<00:00, 12463.51it/s] 96%|█████████▌| 153657/160239 [00:12<00:00, 12447.03it/s] 97%|█████████▋| 155044/160239 [00:12<00:00, 12868.36it/s] 98%|█████████▊| 156332/160239 [00:12<00:00, 12839.04it/s] 98%|█████████▊| 157628/160239 [00:12<00:00, 12869.77it/s] 99%|█████████▉| 158916/160239 [00:12<00:00, 12427.34it/s]100%|██████████| 160239/160239 [00:12<00:00, 12626.85it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 27/6629 [00:00<00:24, 269.06it/s]  1%|          | 58/6629 [00:00<00:22, 290.80it/s]  1%|▏         | 89/6629 [00:00<00:21, 298.71it/s]  2%|▏         | 120/6629 [00:00<00:21, 301.12it/s]  2%|▏         | 151/6629 [00:00<00:22, 292.37it/s]  3%|▎         | 182/6629 [00:00<00:21, 297.19it/s]  3%|▎         | 212/6629 [00:00<00:22, 283.75it/s]  4%|▎         | 241/6629 [00:00<00:22, 283.55it/s]  4%|▍         | 270/6629 [00:00<00:22, 283.66it/s]  5%|▍         | 301/6629 [00:01<00:21, 289.94it/s]  5%|▍         | 331/6629 [00:01<00:22, 283.98it/s]  5%|▌         | 361/6629 [00:01<00:21, 286.12it/s]  6%|▌         | 391/6629 [00:01<00:21, 290.01it/s]  6%|▋         | 421/6629 [00:01<00:21, 292.32it/s]  7%|▋         | 451/6629 [00:01<00:21, 293.49it/s]  7%|▋         | 481/6629 [00:01<00:20, 295.23it/s]  8%|▊         | 511/6629 [00:01<00:20, 292.82it/s]  8%|▊         | 541/6629 [00:01<00:20, 290.16it/s]  9%|▊         | 571/6629 [00:01<00:21, 281.67it/s]  9%|▉         | 600/6629 [00:02<00:22, 263.69it/s]  9%|▉         | 629/6629 [00:02<00:22, 268.97it/s] 10%|▉         | 660/6629 [00:02<00:21, 278.58it/s] 10%|█         | 690/6629 [00:02<00:20, 283.45it/s] 11%|█         | 719/6629 [00:02<00:20, 283.78it/s] 11%|█▏        | 750/6629 [00:02<00:20, 288.59it/s] 12%|█▏        | 779/6629 [00:02<00:21, 274.49it/s] 12%|█▏        | 807/6629 [00:02<00:22, 262.81it/s] 13%|█▎        | 837/6629 [00:02<00:21, 271.69it/s] 13%|█▎        | 866/6629 [00:03<00:20, 276.81it/s] 14%|█▎        | 896/6629 [00:03<00:20, 283.28it/s] 14%|█▍        | 927/6629 [00:03<00:19, 290.15it/s] 14%|█▍        | 958/6629 [00:03<00:19, 294.62it/s] 15%|█▍        | 989/6629 [00:03<00:18, 297.57it/s] 15%|█▌        | 1019/6629 [00:03<00:18, 297.27it/s] 16%|█▌        | 1049/6629 [00:03<00:18, 296.10it/s] 16%|█▋        | 1079/6629 [00:03<00:18, 293.18it/s] 17%|█▋        | 1110/6629 [00:03<00:18, 297.56it/s] 17%|█▋        | 1140/6629 [00:03<00:19, 287.49it/s] 18%|█▊        | 1170/6629 [00:04<00:18, 289.56it/s] 18%|█▊        | 1203/6629 [00:04<00:18, 299.52it/s] 19%|█▊        | 1235/6629 [00:04<00:17, 304.58it/s] 19%|█▉        | 1266/6629 [00:04<00:17, 303.04it/s] 20%|█▉        | 1298/6629 [00:04<00:17, 307.09it/s] 20%|██        | 1329/6629 [00:04<00:17, 294.45it/s] 21%|██        | 1359/6629 [00:04<00:17, 294.94it/s] 21%|██        | 1391/6629 [00:04<00:17, 301.15it/s] 21%|██▏       | 1424/6629 [00:04<00:16, 307.36it/s] 22%|██▏       | 1455/6629 [00:05<00:16, 306.26it/s] 22%|██▏       | 1488/6629 [00:05<00:16, 311.21it/s] 23%|██▎       | 1521/6629 [00:05<00:16, 314.55it/s] 23%|██▎       | 1554/6629 [00:05<00:16, 316.93it/s] 24%|██▍       | 1587/6629 [00:05<00:15, 318.88it/s] 24%|██▍       | 1620/6629 [00:05<00:15, 319.63it/s] 25%|██▍       | 1652/6629 [00:05<00:15, 316.68it/s] 25%|██▌       | 1684/6629 [00:05<00:16, 302.38it/s] 26%|██▌       | 1715/6629 [00:05<00:16, 291.20it/s] 26%|██▋       | 1745/6629 [00:05<00:17, 280.52it/s] 27%|██▋       | 1777/6629 [00:06<00:16, 289.29it/s] 27%|██▋       | 1810/6629 [00:06<00:16, 298.64it/s] 28%|██▊       | 1841/6629 [00:06<00:15, 300.37it/s] 28%|██▊       | 1873/6629 [00:06<00:15, 303.56it/s] 29%|██▊       | 1904/6629 [00:06<00:15, 301.37it/s] 29%|██▉       | 1935/6629 [00:06<00:15, 298.51it/s] 30%|██▉       | 1965/6629 [00:06<00:15, 297.62it/s] 30%|███       | 1996/6629 [00:06<00:15, 300.74it/s] 31%|███       | 2027/6629 [00:06<00:15, 301.64it/s] 31%|███       | 2058/6629 [00:07<00:15, 303.40it/s] 32%|███▏      | 2090/6629 [00:07<00:14, 307.99it/s] 32%|███▏      | 2122/6629 [00:07<00:14, 310.55it/s] 32%|███▏      | 2154/6629 [00:07<00:14, 312.82it/s] 33%|███▎      | 2186/6629 [00:07<00:14, 314.57it/s] 33%|███▎      | 2218/6629 [00:07<00:14, 313.35it/s] 34%|███▍      | 2250/6629 [00:07<00:14, 309.92it/s] 34%|███▍      | 2282/6629 [00:07<00:14, 308.79it/s] 35%|███▍      | 2313/6629 [00:07<00:14, 302.06it/s] 35%|███▌      | 2344/6629 [00:07<00:14, 295.67it/s] 36%|███▌      | 2375/6629 [00:08<00:14, 299.54it/s] 36%|███▋      | 2407/6629 [00:08<00:13, 302.85it/s] 37%|███▋      | 2439/6629 [00:08<00:13, 306.55it/s] 37%|███▋      | 2470/6629 [00:08<00:13, 306.80it/s] 38%|███▊      | 2501/6629 [00:08<00:13, 307.55it/s] 38%|███▊      | 2532/6629 [00:08<00:13, 299.78it/s] 39%|███▊      | 2563/6629 [00:08<00:13, 295.44it/s] 39%|███▉      | 2595/6629 [00:08<00:13, 300.50it/s] 40%|███▉      | 2627/6629 [00:08<00:13, 304.22it/s] 40%|████      | 2658/6629 [00:08<00:13, 302.00it/s] 41%|████      | 2691/6629 [00:09<00:12, 307.90it/s] 41%|████      | 2723/6629 [00:09<00:12, 311.12it/s] 42%|████▏     | 2756/6629 [00:09<00:12, 314.18it/s] 42%|████▏     | 2788/6629 [00:09<00:12, 313.28it/s] 43%|████▎     | 2820/6629 [00:09<00:12, 305.64it/s] 43%|████▎     | 2851/6629 [00:09<00:12, 295.10it/s] 43%|████▎     | 2881/6629 [00:09<00:12, 293.89it/s] 44%|████▍     | 2911/6629 [00:09<00:13, 279.95it/s] 44%|████▍     | 2940/6629 [00:09<00:13, 275.47it/s] 45%|████▍     | 2972/6629 [00:10<00:12, 286.95it/s] 45%|████▌     | 3003/6629 [00:10<00:12, 292.54it/s] 46%|████▌     | 3033/6629 [00:10<00:12, 293.18it/s] 46%|████▌     | 3065/6629 [00:10<00:11, 300.57it/s] 47%|████▋     | 3097/6629 [00:10<00:11, 303.68it/s] 47%|████▋     | 3128/6629 [00:10<00:11, 292.36it/s] 48%|████▊     | 3158/6629 [00:10<00:12, 286.42it/s] 48%|████▊     | 3189/6629 [00:10<00:11, 290.89it/s] 49%|████▊     | 3219/6629 [00:10<00:11, 286.66it/s] 49%|████▉     | 3251/6629 [00:10<00:11, 294.18it/s] 50%|████▉     | 3283/6629 [00:11<00:11, 299.12it/s] 50%|█████     | 3315/6629 [00:11<00:10, 303.13it/s] 50%|█████     | 3346/6629 [00:11<00:10, 303.39it/s] 51%|█████     | 3378/6629 [00:11<00:10, 307.04it/s] 51%|█████▏    | 3409/6629 [00:11<00:10, 302.82it/s] 52%|█████▏    | 3440/6629 [00:11<00:10, 299.11it/s] 52%|█████▏    | 3470/6629 [00:11<00:10, 292.81it/s] 53%|█████▎    | 3500/6629 [00:11<00:10, 286.18it/s] 53%|█████▎    | 3533/6629 [00:11<00:10, 296.21it/s] 54%|█████▍    | 3566/6629 [00:12<00:10, 305.61it/s] 54%|█████▍    | 3597/6629 [00:12<00:10, 300.57it/s] 55%|█████▍    | 3629/6629 [00:12<00:09, 305.34it/s] 55%|█████▌    | 3660/6629 [00:12<00:09, 304.45it/s] 56%|█████▌    | 3691/6629 [00:12<00:09, 295.79it/s] 56%|█████▌    | 3721/6629 [00:12<00:10, 290.45it/s] 57%|█████▋    | 3754/6629 [00:12<00:09, 300.65it/s] 57%|█████▋    | 3788/6629 [00:12<00:09, 309.43it/s] 58%|█████▊    | 3821/6629 [00:12<00:08, 314.30it/s] 58%|█████▊    | 3853/6629 [00:12<00:08, 315.62it/s] 59%|█████▊    | 3886/6629 [00:13<00:08, 317.05it/s] 59%|█████▉    | 3918/6629 [00:13<00:08, 317.90it/s] 60%|█████▉    | 3950/6629 [00:13<00:08, 318.15it/s] 60%|██████    | 3983/6629 [00:13<00:08, 319.86it/s] 61%|██████    | 4015/6629 [00:13<00:08, 311.17it/s] 61%|██████    | 4047/6629 [00:13<00:08, 300.88it/s] 62%|██████▏   | 4078/6629 [00:13<00:08, 286.56it/s] 62%|██████▏   | 4107/6629 [00:13<00:09, 274.65it/s] 62%|██████▏   | 4140/6629 [00:13<00:08, 287.66it/s] 63%|██████▎   | 4174/6629 [00:14<00:08, 300.02it/s] 63%|██████▎   | 4205/6629 [00:14<00:08, 299.23it/s] 64%|██████▍   | 4237/6629 [00:14<00:07, 304.32it/s] 64%|██████▍   | 4270/6629 [00:14<00:07, 308.74it/s] 65%|██████▍   | 4301/6629 [00:14<00:07, 299.82it/s] 65%|██████▌   | 4332/6629 [00:14<00:07, 297.32it/s] 66%|██████▌   | 4364/6629 [00:14<00:07, 303.31it/s] 66%|██████▋   | 4397/6629 [00:14<00:07, 310.17it/s] 67%|██████▋   | 4429/6629 [00:14<00:07, 303.98it/s] 67%|██████▋   | 4461/6629 [00:14<00:07, 307.01it/s] 68%|██████▊   | 4494/6629 [00:15<00:06, 310.98it/s] 68%|██████▊   | 4527/6629 [00:15<00:06, 313.76it/s] 69%|██████▉   | 4559/6629 [00:15<00:06, 313.95it/s] 69%|██████▉   | 4592/6629 [00:15<00:06, 315.99it/s] 70%|██████▉   | 4624/6629 [00:15<00:06, 301.32it/s] 70%|███████   | 4655/6629 [00:15<00:06, 302.95it/s] 71%|███████   | 4686/6629 [00:15<00:06, 299.24it/s] 71%|███████   | 4717/6629 [00:15<00:06, 290.87it/s] 72%|███████▏  | 4750/6629 [00:15<00:06, 301.21it/s] 72%|███████▏  | 4783/6629 [00:16<00:05, 308.68it/s] 73%|███████▎  | 4814/6629 [00:16<00:05, 308.80it/s] 73%|███████▎  | 4847/6629 [00:16<00:05, 313.25it/s] 74%|███████▎  | 4879/6629 [00:16<00:05, 304.10it/s] 74%|███████▍  | 4910/6629 [00:16<00:05, 303.35it/s] 75%|███████▍  | 4941/6629 [00:16<00:05, 304.25it/s] 75%|███████▌  | 4973/6629 [00:16<00:05, 306.33it/s] 75%|███████▌  | 5004/6629 [00:16<00:05, 307.15it/s] 76%|███████▌  | 5035/6629 [00:16<00:05, 305.11it/s] 76%|███████▋  | 5067/6629 [00:16<00:05, 309.17it/s] 77%|███████▋  | 5099/6629 [00:17<00:04, 310.91it/s] 77%|███████▋  | 5132/6629 [00:17<00:04, 314.62it/s] 78%|███████▊  | 5165/6629 [00:17<00:04, 317.70it/s] 78%|███████▊  | 5197/6629 [00:17<00:04, 316.82it/s] 79%|███████▉  | 5229/6629 [00:17<00:04, 307.39it/s] 79%|███████▉  | 5260/6629 [00:17<00:04, 300.40it/s] 80%|███████▉  | 5291/6629 [00:17<00:04, 290.74it/s] 80%|████████  | 5324/6629 [00:17<00:04, 301.26it/s] 81%|████████  | 5357/6629 [00:17<00:04, 309.44it/s] 81%|████████▏ | 5390/6629 [00:17<00:03, 314.43it/s] 82%|████████▏ | 5422/6629 [00:18<00:03, 311.78it/s] 82%|████████▏ | 5455/6629 [00:18<00:03, 315.78it/s] 83%|████████▎ | 5487/6629 [00:18<00:03, 309.84it/s] 83%|████████▎ | 5519/6629 [00:18<00:03, 305.95it/s] 84%|████████▎ | 5550/6629 [00:18<00:03, 298.09it/s] 84%|████████▍ | 5583/6629 [00:18<00:03, 305.19it/s] 85%|████████▍ | 5615/6629 [00:18<00:03, 308.27it/s] 85%|████████▌ | 5649/6629 [00:18<00:03, 314.91it/s] 86%|████████▌ | 5682/6629 [00:18<00:02, 318.78it/s] 86%|████████▌ | 5715/6629 [00:19<00:02, 319.32it/s] 87%|████████▋ | 5747/6629 [00:19<00:02, 319.09it/s] 87%|████████▋ | 5779/6629 [00:19<00:02, 314.96it/s] 88%|████████▊ | 5811/6629 [00:19<00:02, 315.96it/s] 88%|████████▊ | 5843/6629 [00:19<00:02, 314.26it/s] 89%|████████▊ | 5875/6629 [00:19<00:02, 300.04it/s] 89%|████████▉ | 5906/6629 [00:19<00:02, 297.05it/s] 90%|████████▉ | 5939/6629 [00:19<00:02, 305.46it/s] 90%|█████████ | 5971/6629 [00:19<00:02, 308.77it/s] 91%|█████████ | 6002/6629 [00:19<00:02, 307.06it/s] 91%|█████████ | 6035/6629 [00:20<00:01, 312.50it/s] 92%|█████████▏| 6067/6629 [00:20<00:01, 294.69it/s] 92%|█████████▏| 6097/6629 [00:20<00:01, 285.80it/s] 92%|█████████▏| 6128/6629 [00:20<00:01, 292.50it/s] 93%|█████████▎| 6159/6629 [00:20<00:01, 297.40it/s] 93%|█████████▎| 6192/6629 [00:20<00:01, 304.70it/s] 94%|█████████▍| 6225/6629 [00:20<00:01, 311.35it/s] 94%|█████████▍| 6258/6629 [00:20<00:01, 315.63it/s] 95%|█████████▍| 6290/6629 [00:20<00:01, 316.51it/s] 95%|█████████▌| 6323/6629 [00:21<00:00, 317.96it/s] 96%|█████████▌| 6355/6629 [00:21<00:00, 314.41it/s] 96%|█████████▋| 6387/6629 [00:21<00:00, 309.07it/s] 97%|█████████▋| 6418/6629 [00:21<00:00, 299.69it/s] 97%|█████████▋| 6449/6629 [00:21<00:00, 278.23it/s] 98%|█████████▊| 6482/6629 [00:21<00:00, 290.92it/s] 98%|█████████▊| 6516/6629 [00:21<00:00, 302.31it/s] 99%|█████████▉| 6547/6629 [00:21<00:00, 300.88it/s] 99%|█████████▉| 6580/6629 [00:21<00:00, 308.12it/s]100%|█████████▉| 6611/6629 [00:21<00:00, 304.51it/s]100%|██████████| 6629/6629 [00:22<00:00, 300.60it/s]AVERAGE DENSITY :0.0
2022-03-23 18:53:11 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:53:11 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:53:11 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:53:11 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:53:11 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:53:11 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:53:11 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:53:11 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:53:11 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:53:11 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:53:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:53:11 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:53:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:53:11 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:53:11 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:53:11 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_last.pt
2022-03-23 18:53:11 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_last.pt
2022-03-23 18:53:11 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:53:11 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:53:11 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:53:11 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:53:11 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:53:11 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:53:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:53:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:53:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:53:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 18:58:13 | INFO | train_inner | epoch 001:    104 / 157 loss=11.412, ppl=2724.5, wps=8642.7, ups=0.34, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.606, loss_scale=8, train_wall=301, gb_free=13.5, wall=302
2022-03-23 18:58:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:00:49 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 19:00:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:00:54 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,.....
2022-03-23 19:00:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:00:59 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 19:00:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:01:04 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:01:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:01:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:01:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:01:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:01:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:01:46 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:01:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:01:46 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.669 | ppl 814.07 | bleu 0.01 | wps 2866.9 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-23 19:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-23 19:01:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:01:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:01:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 0.9418127126991749 seconds)
2022-03-23 19:01:47 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:01:47 | INFO | train | epoch 001 | loss 10.958 | ppl 1988.91 | wps 7565.4 | ups 0.3 | wpb 25120.6 | bsz 980.6 | num_updates 152 | lr 1.9e-05 | gnorm 2.855 | loss_scale 4 | train_wall 451 | gb_free 22.4 | wall 516
2022-03-23 19:01:47 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:01:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:04:08 | INFO | train_inner | epoch 002:     48 / 157 loss=9.792, ppl=886.21, wps=7162.3, ups=0.28, wpb=25437.5, bsz=1087.6, num_updates=200, lr=2.5e-05, gnorm=1.421, loss_scale=4, train_wall=291, gb_free=13.7, wall=657
2022-03-23 19:08:53 | INFO | train_inner | epoch 002:    148 / 157 loss=9.078, ppl=540.55, wps=8757.8, ups=0.35, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.528, loss_scale=4, train_wall=285, gb_free=20, wall=943
2022-03-23 19:09:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:09:22 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we.
2022-03-23 19:09:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:09:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:09:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:09:35 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:09:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:09:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:09:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:09:49 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:09:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:09:57 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:09:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:10:05 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:10:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:10:13 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:10:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:10:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" ""
2022-03-23 19:10:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:10:25 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:10:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:10:25 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.675 | ppl 408.64 | bleu 0.01 | wps 2613.4 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 19:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 19:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:10:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 0.929619531147182 seconds)
2022-03-23 19:10:26 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:10:26 | INFO | train | epoch 002 | loss 9.187 | ppl 582.86 | wps 7610.2 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.486 | loss_scale 4 | train_wall 449 | gb_free 13.5 | wall 1035
2022-03-23 19:10:26 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:14:45 | INFO | train_inner | epoch 003:     91 / 157 loss=8.713, ppl=419.67, wps=7061.6, ups=0.28, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.439, loss_scale=4, train_wall=282, gb_free=12.9, wall=1294
2022-03-23 19:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:17:59 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:17:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:18:05 | INFO | fairseq.tasks.translation | example hypothesis: is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:18:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:18:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:18:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:18:18 | INFO | fairseq.tasks.translation | example hypothesis: it's's a, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and it
2022-03-23 19:18:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:18:26 | INFO | fairseq.tasks.translation | example hypothesis: we we that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that.
2022-03-23 19:18:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:18:33 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:18:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:18:42 | INFO | fairseq.tasks.translation | example hypothesis: 's the the the the the the the, and the the the the the the the the, and and and the the the the the the the the the the the the the the the the the the the the, and and and and and and the the the the the the the the the the the the the the the the the the the the the the,
2022-03-23 19:18:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:18:50 | INFO | fairseq.tasks.translation | example hypothesis: we we we the the the the, and the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:18:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:18:59 | INFO | fairseq.tasks.translation | example hypothesis: 's's, "" "" "" "" "" "" "" ""
2022-03-23 19:18:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:19:01 | INFO | fairseq.tasks.translation | example hypothesis: we we we, we a a a a a a a a a a, and the the the the the, and the the the the the the the the the the, and the the the the the the the the the the the the the the the, and the the the the the the the the the the the the the, and the the the the the the the the the the the the the the the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that,
2022-03-23 19:19:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:19:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.445 | ppl 348.54 | bleu 0.04 | wps 2637.2 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.04
2022-03-23 19:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 19:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.04) (writing took 0.9651266150176525 seconds)
2022-03-23 19:19:02 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:19:02 | INFO | train | epoch 003 | loss 8.625 | ppl 394.81 | wps 7643.3 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.577 | loss_scale 4 | train_wall 447 | gb_free 13.2 | wall 1551
2022-03-23 19:19:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:20:43 | INFO | train_inner | epoch 004:     34 / 157 loss=8.464, ppl=353.11, wps=7114.9, ups=0.28, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.525, loss_scale=4, train_wall=289, gb_free=13, wall=1652
2022-03-23 19:25:29 | INFO | train_inner | epoch 004:    134 / 157 loss=8.214, ppl=296.85, wps=8817.3, ups=0.35, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=1.575, loss_scale=4, train_wall=286, gb_free=13.8, wall=1938
2022-03-23 19:26:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:26:37 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 19:26:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:26:43 | INFO | fairseq.tasks.translation | example hypothesis: the world is the world is the world.
2022-03-23 19:26:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:26:49 | INFO | fairseq.tasks.translation | example hypothesis: we're're the world of the world of the world.
2022-03-23 19:26:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:26:55 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot, and it's a way, and it's a world.
2022-03-23 19:26:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:27:02 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not not not not not not not not not not not.
2022-03-23 19:27:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:27:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world, and the world is the world of the world, and the world, and the world, and the world of the world of the world.
2022-03-23 19:27:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:27:16 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not, but you can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be their their their their, but but but it.
2022-03-23 19:27:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:27:24 | INFO | fairseq.tasks.translation | example hypothesis: we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see to the the way of the way of the way of the world of the world of the world of the world of the world of the world of the world of the world of the world, and we can can see
2022-03-23 19:27:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:27:33 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:27:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example hypothesis: , we have to have the world, which we have to can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be the world, which which which is the world, which which is the world, which is the world, which is the world of the world of the world of the world, which which is the world of the world of the world, which which is the world, which we're the world, and we're be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be world, and we're be be be be world, which which is the world, and the world, and we're be be be be world, and we have to be world, and we have to be world, and we have to be world, which is the world, which is a world, and we have to be world, which
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:27:35 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.794 | ppl 221.95 | bleu 0.95 | wps 2831.8 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.95
2022-03-23 19:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 19:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.95) (writing took 0.9271260760724545 seconds)
2022-03-23 19:27:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:27:36 | INFO | train | epoch 004 | loss 8.228 | ppl 299.76 | wps 7684.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.5 | loss_scale 4 | train_wall 449 | gb_free 13.4 | wall 2065
2022-03-23 19:27:36 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:31:13 | INFO | train_inner | epoch 005:     77 / 157 loss=7.924, ppl=242.95, wps=7099.1, ups=0.29, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=2.024, loss_scale=4, train_wall=280, gb_free=14.6, wall=2282
2022-03-23 19:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:35:13 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 19:35:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:35:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the world.
2022-03-23 19:35:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:35:25 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the way.
2022-03-23 19:35:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:35:32 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way, and it's going to be a lot, and it.
2022-03-23 19:35:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:35:39 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not that we don't know that we're not not not not not not going to be a lot of the world.
2022-03-23 19:35:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:35:47 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of the lot of the world, and it's a lot of the way of the world, and it's a lot of the world of the world, and the world of the world, and the world of the world of the world of the world, and the world,
2022-03-23 19:35:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:35:55 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way, and you can't can't see the lot of the lot of the way, and you can't see it, and you can't see it, and you can't see the way of the way of the lot of the way, and you can't see it, and you can't see it can't see it
2022-03-23 19:35:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:36:03 | INFO | fairseq.tasks.translation | example hypothesis: we can can see that we can see that we can see the way of the world, and we can see the way of the world, and we can see the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way, and we can can can see that we can see that we can see that we can see that we can see that we can can
2022-03-23 19:36:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:36:13 | INFO | fairseq.tasks.translation | example hypothesis: , it's a lot of the way, "" you can't know, "it," you can't know, "it," it's a lot of the way, "it," it, "it's a lot of the way," it's a lot of the way, "it," it's a lot of the way, "it's a lot of the way," it's a lot of the way, "it," you can't say, "it," it, "you can't say," it, "it," it's a lot of the way, "" it's a lot of the way, "it's a lot of the way," it's a lot of the way, "it's a lot of the way," it's a lot of the way, "it's a lot of the way," "
2022-03-23 19:36:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:36:15 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the lot of the way, and we can't see that we can see that we can see that, and it's a lot of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way, and it, and it, and it, and you can't see the way of the way of the way of the way of the way of the way of the way of the way, and it, and we can't see that we can't see that we can't see that we can't see that we can't see that we can't see the same of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way of the way,
2022-03-23 19:36:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:36:15 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.33 | ppl 160.87 | bleu 1.21 | wps 2632.5 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.21
2022-03-23 19:36:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:36:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:36:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.21) (writing took 0.9509737798944116 seconds)
2022-03-23 19:36:16 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:36:16 | INFO | train | epoch 005 | loss 7.721 | ppl 211.04 | wps 7590.5 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.812 | loss_scale 4 | train_wall 450 | gb_free 13.6 | wall 2585
2022-03-23 19:36:17 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:37:12 | INFO | train_inner | epoch 006:     20 / 157 loss=7.594, ppl=193.22, wps=7084.5, ups=0.28, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.724, loss_scale=4, train_wall=289, gb_free=12.2, wall=2641
2022-03-23 19:42:01 | INFO | train_inner | epoch 006:    120 / 157 loss=7.314, ppl=159.12, wps=8776.8, ups=0.35, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.572, loss_scale=4, train_wall=288, gb_free=13.6, wall=2930
2022-03-23 19:43:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:43:52 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 19:43:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:43:57 | INFO | fairseq.tasks.translation | example hypothesis: this is here here here here here here here's the most most of the most of the first first.
2022-03-23 19:43:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:44:04 | INFO | fairseq.tasks.translation | example hypothesis: we're new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 19:44:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:44:10 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's going to be a lot of the world.
2022-03-23 19:44:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:44:18 | INFO | fairseq.tasks.translation | example hypothesis: what we're not not going to do that we're not not not going to do that we're going to do that we're not not not not going to do that we're going to do it's not not not not not not going to
2022-03-23 19:44:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:44:25 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people for the people for the people for the people who are in the people for people for the people for the people for the people for the people for the people for the people for the people for the people for the people for the world.
2022-03-23 19:44:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:44:34 | INFO | fairseq.tasks.translation | example hypothesis: if you're not going to be a lot of the way, but they're not going to be going to be not not going to be not going to be able to be a lot of the way, but they're going to be able to be able to be not going to be able to be able to be able to be able to be able to be
2022-03-23 19:44:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:44:42 | INFO | fairseq.tasks.translation | example hypothesis: we're going to make a lot of the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, we're going to be a lot of the world, and we can see that we can see the way of the world that we can see the world, and we can see that we can see the way of the world
2022-03-23 19:44:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:44:52 | INFO | fairseq.tasks.translation | example hypothesis: i said, "" you know, "you know," you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," "you're going to say," you're going to say, "" "" "" "you're going to say," "" you're going to say, "" "" you're going to say, "" "" you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "" "" ""
2022-03-23 19:44:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:44:54 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be able to be able to be able to be able to be a lot of the world, and then then we're going to be able to be a lot of the most of the world, and then we're going to be a lot of the same same same same same same same same way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world
2022-03-23 19:44:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:44:54 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.963 | ppl 124.76 | bleu 1.4 | wps 2603.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.4
2022-03-23 19:44:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:44:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.4) (writing took 0.9858147669583559 seconds)
2022-03-23 19:44:55 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:44:55 | INFO | train | epoch 006 | loss 7.305 | ppl 158.14 | wps 7608.7 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.693 | loss_scale 4 | train_wall 449 | gb_free 14.3 | wall 3104
2022-03-23 19:44:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:47:55 | INFO | train_inner | epoch 007:     63 / 157 loss=7.078, ppl=135.14, wps=7089.2, ups=0.28, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.555, loss_scale=4, train_wall=285, gb_free=14.4, wall=3284
2022-03-23 19:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:52:29 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go on this.
2022-03-23 19:52:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:52:35 | INFO | fairseq.tasks.translation | example hypothesis: here's here here here here's the middle of the middle of this.
2022-03-23 19:52:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:52:41 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new new new new new new new new new new new new new new york.
2022-03-23 19:52:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:52:48 | INFO | fairseq.tasks.translation | example hypothesis: it's going to be a lot of life, and it's going to be going to be, and it.
2022-03-23 19:52:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:52:55 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do is that we're going to do is that we're going to do that we're going to be going to be going to do that we're going to do.
2022-03-23 19:52:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:53:02 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of people in the people, and it's the people who's a lot of people in the people, and it's the people who's a lot of people in the people in the people.
2022-03-23 19:53:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:53:10 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to see, but they're going to get a lot of the same way, but they're going to be able to be able, but they're going to be able to be able to be able to be able, but they're going to be able to be able, but it, but they're going to be able to be able
2022-03-23 19:53:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:53:18 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that, and we're going to see the world, and we can see the brain, and we're going to be able to see the world, and we can see the brain, and we can see the brain, and we can see the brain, and we can see the world, and we can see the world, and we can see the brain, and we can see the brain, and we can see the brain, and we can
2022-03-23 19:53:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:53:27 | INFO | fairseq.tasks.translation | example hypothesis: we said, "" you're going to say, "and then you're going to say," and then you're going to say, "you're going to say," you're going to say, "and then you're going to say," and then you're going to say, "and then you're going to say," and then you're going to say, "and then you're going to say," "" and then you're going to say, "and then you're going to say," and then you're going to say, "and then you're going to say," "" and then then you're going to say, "and then you're going to say," you're going to say, "the first first first first first first first first first first first first first first first first first first first first first first first first first first,"
2022-03-23 19:53:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:53:30 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world, and we're going to be able to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to the world, and the world, and the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to get the world, and then we're going to be able to be able to be able to get the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 19:53:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:53:30 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.68 | ppl 102.52 | bleu 1.89 | wps 2673.5 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.89
2022-03-23 19:53:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:53:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:53:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 19:53:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.89) (writing took 0.9512993460521102 seconds)
2022-03-23 19:53:31 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:53:31 | INFO | train | epoch 007 | loss 6.983 | ppl 126.47 | wps 7664.6 | ups 0.3 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.483 | loss_scale 4 | train_wall 446 | gb_free 14 | wall 3620
2022-03-23 19:53:31 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:53:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:53:47 | INFO | train_inner | epoch 008:      6 / 157 loss=6.911, ppl=120.32, wps=7116.4, ups=0.28, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.456, loss_scale=4, train_wall=283, gb_free=13.9, wall=3636
2022-03-23 19:58:32 | INFO | train_inner | epoch 008:    106 / 157 loss=6.691, ppl=103.32, wps=8843.8, ups=0.35, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.54, loss_scale=4, train_wall=285, gb_free=14.2, wall=3921
2022-03-23 20:00:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:01:05 | INFO | fairseq.tasks.translation | example hypothesis: we've got in this.
2022-03-23 20:01:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:01:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most most of the most most most of the most of the most most most of the most of
2022-03-23 20:01:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example hypothesis: that's new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:01:24 | INFO | fairseq.tasks.translation | example hypothesis: it's a place, and it's where it's called the water, and it's called the water.
2022-03-23 20:01:24 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:01:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do that we're going to do that we're not going to do that we're going to do that we're going to do that we're going to do it.
2022-03-23 20:01:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:01:38 | INFO | fairseq.tasks.translation | example hypothesis: in fact, for the people who are a lot of people in the most people who are in the people in the people who are in the people in the people who are in the most people in the people.
2022-03-23 20:01:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:01:46 | INFO | fairseq.tasks.translation | example hypothesis: if you get some of them, but it's not a lot of the same, but it's not a lot of them, but it's not a lot of them.
2022-03-23 20:01:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:01:53 | INFO | fairseq.tasks.translation | example hypothesis: if we can take the brain, we can take the brain, and we can use the brain of the brain, and we can use the brain, and we can make the brain, and we can get the brain.
2022-03-23 20:01:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:02:01 | INFO | fairseq.tasks.translation | example hypothesis: if you say, "you know, you know," you know, "you know," you know, "you know, it's a lot of the first thing," you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "
2022-03-23 20:02:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:02:03 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to make a lot of the world that we're going to make a lot of the world, which is that we're going to make a lot of the world, which is that we're going to make a little little bit of the world, which is that we're going to make a little little bit of the world, and we're going to make a little little little bit of the world, which is that we're going to make a little bit of the world, which is that we're going to make a little little bit of the world, which is that we're going to do that we're going to make a little little little little little little little little little bit of the world, which is that we're going to do that we're going to make a little little bit of the most of the world, which is a little little little bit of the world, and then we're going to be able to be able to be able to be able to make a little little little bit of the world, which is that we're going
2022-03-23 20:02:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:02:03 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.435 | ppl 86.55 | bleu 2.9 | wps 2794.9 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.9
2022-03-23 20:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:02:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:02:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:02:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.9) (writing took 0.9587168251164258 seconds)
2022-03-23 20:02:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:02:04 | INFO | train | epoch 008 | loss 6.752 | ppl 107.78 | wps 7686 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.48 | loss_scale 4 | train_wall 448 | gb_free 13.1 | wall 4133
2022-03-23 20:02:05 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:04:29 | INFO | train_inner | epoch 009:     49 / 157 loss=6.681, ppl=102.59, wps=7187.7, ups=0.28, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.368, loss_scale=4, train_wall=291, gb_free=14.5, wall=4278
2022-03-23 20:09:11 | INFO | train_inner | epoch 009:    149 / 157 loss=6.484, ppl=89.54, wps=8830.6, ups=0.36, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.431, loss_scale=4, train_wall=281, gb_free=13.9, wall=4560
2022-03-23 20:09:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:09:38 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the ground.
2022-03-23 20:09:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:09:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most most most of the most most most most of the most most most most most of
2022-03-23 20:09:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:09:50 | INFO | fairseq.tasks.translation | example hypothesis: this new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new york
2022-03-23 20:09:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:09:57 | INFO | fairseq.tasks.translation | example hypothesis: there's an example, there's a pover, and it's where it's going to be where it's going to be where it's going to go.
2022-03-23 20:09:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:10:03 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're not going to do it in his life, and what we're going to do.
2022-03-23 20:10:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:10:10 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the people in the people, for the people, and for the people in the people in the people, and it's a lot of people in the people in the people.
2022-03-23 20:10:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:10:18 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of them, but it's not, but if you can't see it, but it doesn't have a lot of energy, but it doesn't have to get it, but it's the same way, but it's the same time.
2022-03-23 20:10:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:10:25 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we can take the brain, and we can see that we can see the brain, and then we can see the brain, and then we can see the information of the brain, and then we can see the brain, and then we can see the brain.
2022-03-23 20:10:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:10:34 | INFO | fairseq.tasks.translation | example hypothesis: one of the one: there's a lot of the world, "well," well, "you know," well, "you know," "" you know, "" "well," "" "" "" "you know," well, "" "well," well, "well," "" "" "" "" "" "" "" "" "" "" "" "" "" "you know," "" "" "" "" "" "" "" "" "" "" "" "it's a" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 20:10:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:10:37 | INFO | fairseq.tasks.translation | example hypothesis: it's still still more than the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:10:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:10:37 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.055 | ppl 66.47 | bleu 3.99 | wps 2790 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.99
2022-03-23 20:10:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:10:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.99) (writing took 0.9338560709729791 seconds)
2022-03-23 20:10:38 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:10:38 | INFO | train | epoch 009 | loss 6.482 | ppl 89.38 | wps 7694.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.397 | loss_scale 4 | train_wall 447 | gb_free 14.2 | wall 4647
2022-03-23 20:10:38 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:15:02 | INFO | train_inner | epoch 010:     92 / 157 loss=6.225, ppl=74.78, wps=7133, ups=0.28, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.355, loss_scale=4, train_wall=286, gb_free=13.8, wall=4911
2022-03-23 20:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:18:11 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the middle of the ground.
2022-03-23 20:18:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:18:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the name, most of the most most most of the most most of the most.
2022-03-23 20:18:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:18:23 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new york are going to be new york.
2022-03-23 20:18:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:18:29 | INFO | fairseq.tasks.translation | example hypothesis: here's example, there's a chinese chinese, where where you're going to go.
2022-03-23 20:18:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:18:36 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few years ago, and what's going on.
2022-03-23 20:18:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:18:42 | INFO | fairseq.tasks.translation | example hypothesis: in fact, as people are like people for the people who are working for the people, and for a few years.
2022-03-23 20:18:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:18:49 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of you're going to see the brain, but if you don't have to use it, but if you don't have the energy, if you don't have the energy, you don't have the energy, you don't need to get the energy, it, you don't have the energy, but there's the energy,
2022-03-23 20:18:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:18:57 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we can use this information, and we can use a lot of information, and we can use a little bit of the brain, and the information that can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the brain, and the brain, and
2022-03-23 20:18:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:19:05 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the two, and there's no interesting, and it's a lot of interesting, and then it's a lot of time for me, and then if you're going to go back to the first time, and then you're going to the first time, you're going to be able to be able to be able to be able to be able to be able to be able to talk about the first time, and then you know, and then you know, and then, and then, and then you know, and then you know, and then you know, and then there's a little bit about this is a little bit about a little bit about a little bit about a little bit of the first time, and then we're going to go out of the first time, and then we're going to do that's a little bit of the first time, and then then then then,
2022-03-23 20:19:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:19:08 | INFO | fairseq.tasks.translation | example hypothesis: then, there's a lot of work, and a little bit of the mother, and when we're going to get a little bit of the world, and if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get a little bit of a little bit of a little bit of a little bit of the system, which which which is a new york, and then we're able to be able to be able to be able to be able to be able to be able to take a
2022-03-23 20:19:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:19:08 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.731 | ppl 53.13 | bleu 5.66 | wps 2872.5 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 5.66
2022-03-23 20:19:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:19:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 5.66) (writing took 0.9721863651648164 seconds)
2022-03-23 20:19:09 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:19:09 | INFO | train | epoch 010 | loss 6.159 | ppl 71.46 | wps 7724.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.449 | loss_scale 4 | train_wall 447 | gb_free 13.3 | wall 5158
2022-03-23 20:19:09 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:20:47 | INFO | train_inner | epoch 011:     35 / 157 loss=6.096, ppl=68.38, wps=7204.5, ups=0.29, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.525, loss_scale=4, train_wall=280, gb_free=13, wall=5256
2022-03-23 20:25:38 | INFO | train_inner | epoch 011:    135 / 157 loss=5.796, ppl=55.55, wps=8807.5, ups=0.34, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.387, loss_scale=4, train_wall=290, gb_free=12.9, wall=5547
2022-03-23 20:26:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:26:45 | INFO | fairseq.tasks.translation | example hypothesis: we went to the top of the clinics.
2022-03-23 20:26:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:26:51 | INFO | fairseq.tasks.translation | example hypothesis: that's the point of ha, most of most most most most most of you know.
2022-03-23 20:26:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:26:57 | INFO | fairseq.tasks.translation | example hypothesis: new new new york are going to take two two two two two two two new york.
2022-03-23 20:26:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:27:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese, where they're going to go, and you're going to go to the pple.
2022-03-23 20:27:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:27:10 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a few years on his head, and what's going on.
2022-03-23 20:27:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:27:17 | INFO | fairseq.tasks.translation | example hypothesis: in the middle of people like the people who have been used for the number of the number of people, and that's a number of people who have been used to be able to be in the heart.
2022-03-23 20:27:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:27:23 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you are a little bit of the water, but if you don't need to use the energy, if you don't need to use the energy, if you need to use the energy, you need to use the energy, you need to use the energy.
2022-03-23 20:27:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:27:30 | INFO | fairseq.tasks.translation | example hypothesis: if we use information information information that we can use this information, we can take a structure of information with a structure of information that can be able to be able to be able to use the structure of the structure of information.
2022-03-23 20:27:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:27:38 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that it's interesting, and it's really interesting for me, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "well," you know, "you know," you know, "you know," you know, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," you know, "you know," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "
2022-03-23 20:27:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:27:40 | INFO | fairseq.tasks.translation | example hypothesis: then, in fact, the mother, and a lot of work that we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 20:27:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:27:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.374 | ppl 41.47 | bleu 7.59 | wps 2961.8 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 7.59
2022-03-23 20:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 7.59) (writing took 0.9667613911442459 seconds)
2022-03-23 20:27:41 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:27:41 | INFO | train | epoch 011 | loss 5.866 | ppl 58.34 | wps 7708.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.406 | loss_scale 4 | train_wall 449 | gb_free 13.6 | wall 5670
2022-03-23 20:27:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:31:25 | INFO | train_inner | epoch 012:     78 / 157 loss=5.695, ppl=51.8, wps=7187.7, ups=0.29, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.464, loss_scale=4, train_wall=285, gb_free=13.5, wall=5894
2022-03-23 20:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:35:15 | INFO | fairseq.tasks.translation | example hypothesis: we did that in front of the clinics.
2022-03-23 20:35:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:35:21 | INFO | fairseq.tasks.translation | example hypothesis: that's the bottom point of ha, most of most most most most most most of you know.
2022-03-23 20:35:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:35:28 | INFO | fairseq.tasks.translation | example hypothesis: these new states are going to be two ways.
2022-03-23 20:35:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:35:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese chinese chinese, where they're going to get up, and they're going to get it.
2022-03-23 20:35:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:35:41 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a few ways on his head, and what's going on on your mind.
2022-03-23 20:35:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:35:47 | INFO | fairseq.tasks.translation | example hypothesis: in fact, in the mamamamamamamamamace people for the way, the number of animals, and this is a number of people in order to become a viiiiiiiiiiiiiiiiiiiiii
2022-03-23 20:35:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:35:54 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you're going to look at the pattern, but if you don't need to use the energy, if you don't need to use your energy, it doesn't need your energy.
2022-03-23 20:35:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:36:01 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use this information from a structure, we can take a structure of information, and we can move the structure of the structure, and all the structure of the structure, and all the information, and all the information, and all the information is all the information, and all the structure of the information, and all the information that are all the information.
2022-03-23 20:36:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:36:08 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting, and it's interesting for example, "for instance, if we're going to ask me that women," okay, "if we said," okay, "well," if you're going to say, "you're going to say," okay, "if we're going to say," well, "you're going to say," okay, "okay," well, "if we're going to say," okay, "well," well, "well," well, "well," well, "if we're going to say," if we're going to do it's going to say, "you're going to say," well, "well," well, "well," okay, "okay," if we're going to say, "you're going to do it's going to say,
2022-03-23 20:36:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:36:11 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still the mother, and the fact that we had a lot of design, if we had to build a huge system that we had to build a huge system that we had to build a huge system, and then we had to build it into a huge system that we had to build a huge system that we had to build a huge system, to create a huge system, to build a huge system, to build a huge system, and we had to build a huge system that we had to build a huge system that we had to build a huge system that we had to build a huge system, and we had to build a huge system that we had to build a huge system that we had to build a huge system, and we had to make it would put it, to build a huge system that we had to build a huge system that we had to build a huge system that we had to build a huge system that we had to build a huge system that we had to build a huge system that we had to build a huge system
2022-03-23 20:36:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:36:11 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.082 | ppl 33.87 | bleu 9.43 | wps 2957.7 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.43
2022-03-23 20:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:36:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:36:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:36:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.43) (writing took 0.9769484661519527 seconds)
2022-03-23 20:36:12 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:36:12 | INFO | train | epoch 012 | loss 5.542 | ppl 46.58 | wps 7735.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.448 | loss_scale 4 | train_wall 448 | gb_free 13.7 | wall 6181
2022-03-23 20:36:12 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:37:11 | INFO | train_inner | epoch 013:     21 / 157 loss=5.39, ppl=41.93, wps=7256.2, ups=0.29, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.487, loss_scale=4, train_wall=283, gb_free=13.4, wall=6240
2022-03-23 20:41:57 | INFO | train_inner | epoch 013:    121 / 157 loss=5.262, ppl=38.37, wps=8842.8, ups=0.35, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.39, loss_scale=4, train_wall=286, gb_free=13.1, wall=6526
2022-03-23 20:43:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:43:44 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppace in the clinics.
2022-03-23 20:43:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:43:50 | INFO | fairseq.tasks.translation | example hypothesis: that's the bottom line of doha, most most most most most of you know.
2022-03-23 20:43:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:43:56 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to get two pieces of orores that are going to get two new ways.
2022-03-23 20:43:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:44:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where they're going to get your legs and get up.
2022-03-23 20:44:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:44:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electroelectrodes on his head, and what's going on on your mind.
2022-03-23 20:44:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:44:15 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamamamamacy people who began to get the number of animals, and that's become a congress for the iiiiiiiiiiiiiiiic.
2022-03-23 20:44:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:44:21 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the magnetic magnetic neurons in the lines, but it doesn't need to go to the energy, if you don't need your energy energy, you need your energy.
2022-03-23 20:44:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:44:27 | INFO | fairseq.tasks.translation | example hypothesis: if we use information information that we can look at this reflection, we can begin to start with a traditional traditional structure, and the structure of the structure of the structure, and the structure of the structure.
2022-03-23 20:44:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:44:33 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons the reasons that it's interesting, and it's interesting for me to be talking about women, "oh," yeah, "if you're going to say," you're going to say, "you're going to say," oh, "you're going to say," you're going to say, "well," you're going to say, "you're going to say," you're going to say, "you're going to say," oh, "well," you're going to say, "well," well, "you're going to say," you're going to ask you're going to have a long time to be a long time, "you're going to say," you know, "you're going to say," you're going to say, "you're going to say," you're going to be a
2022-03-23 20:44:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:44:34 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still the mother invention of the invention, and part of our work, we've got to solve our work on the bottom system, or if we had to use it into a mechanical system that we had to be able to be able to be able to be able to use it.
2022-03-23 20:44:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:44:34 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.779 | ppl 27.46 | bleu 12.28 | wps 3317.8 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.28
2022-03-23 20:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.28) (writing took 0.9546431289054453 seconds)
2022-03-23 20:44:35 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:44:35 | INFO | train | epoch 013 | loss 5.231 | ppl 37.56 | wps 7850.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.392 | loss_scale 4 | train_wall 446 | gb_free 13 | wall 6684
2022-03-23 20:44:35 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:47:37 | INFO | train_inner | epoch 014:     64 / 157 loss=5.065, ppl=33.47, wps=7340.4, ups=0.29, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.328, loss_scale=4, train_wall=283, gb_free=13.6, wall=6866
2022-03-23 20:52:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:52:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppace in the clinics.
2022-03-23 20:52:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:52:15 | INFO | fairseq.tasks.translation | example hypothesis: that's the car line of doha, ha, most of most of the most most most of the most.
2022-03-23 20:52:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:52:21 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to make a new dine that are going to make two new forces.
2022-03-23 20:52:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:52:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where they're eating legs, and they're going to be cheaper.
2022-03-23 20:52:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:52:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electroelectrodes on his head and understand what all the thoughts are on the mind.
2022-03-23 20:52:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:52:40 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamamamace of people, the responsibility for the number of animals, and this has become a lot of conservation.
2022-03-23 20:52:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:52:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic magnetic magnetic magnetic lines in the lines, but it doesn't have to move the energy, if you don't need your energy, you need the energy.
2022-03-23 20:52:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:52:52 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the information reflection of this reflection, we can actually start with a traditional traditional traditional electronic electrons, the shape of the information and all the information.
2022-03-23 20:52:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:52:58 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that it's interesting, and it's interesting to make me here for tedtedtalks about women, "oh, when we're talking to you're talking about this talk to you.
2022-03-23 20:52:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:52:59 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the idea of mother's mother, the invention of the invention, and a lot of design that we had to use a lot of problems that we had to use it to be able to be able to be able to be able to be able to be able to be able to make a market.
2022-03-23 20:52:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:52:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.56 | ppl 23.59 | bleu 14.4 | wps 3277.7 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.4
2022-03-23 20:52:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:52:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 20:53:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.4) (writing took 0.977229721378535 seconds)
2022-03-23 20:53:00 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:53:00 | INFO | train | epoch 014 | loss 4.91 | ppl 30.06 | wps 7816.8 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.32 | loss_scale 4 | train_wall 448 | gb_free 13.3 | wall 7189
2022-03-23 20:53:00 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:53:23 | INFO | train_inner | epoch 015:      7 / 157 loss=4.786, ppl=27.58, wps=7377, ups=0.29, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.244, loss_scale=4, train_wall=289, gb_free=13.4, wall=7213
2022-03-23 20:58:07 | INFO | train_inner | epoch 015:    107 / 157 loss=4.62, ppl=24.59, wps=8855.6, ups=0.35, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.325, loss_scale=4, train_wall=284, gb_free=13.5, wall=7496
2022-03-23 21:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:00:34 | INFO | fairseq.tasks.translation | example hypothesis: we made this ppink in the clinic clinics.
2022-03-23 21:00:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:00:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which most of you know.
2022-03-23 21:00:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:00:46 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to create new dindiners that are going to get two new practices.
2022-03-23 21:00:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:00:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese food, where the legs are going to do with legs, and they're going to be cut.
2022-03-23 21:00:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:00:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just have a few electrodes on his head and understand what all the thoughts are on his mind.
2022-03-23 21:00:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:01:05 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamated, like the responsibility of responsibility, grew up, and this is a number of animals that have become a conservaiiiiiiibia.
2022-03-23 21:01:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:01:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic lines in the lines, but when it's not going to move, if you don't have the power of the energy, and if you need your energy, you need to move the power of the power.
2022-03-23 21:01:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:01:18 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the information comes from this reflect reflection, we can start with a traditional face, we can start able to start able to start able to start able to start with the shape of the shape of the information, and the whole structure of the structure.
2022-03-23 21:01:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:01:25 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that it's interesting and interesting to do it for me to be here for tedl women -- yes, "yeah, when it was the best thing that somebody said," oh, "if we've been working with the best revolution," and then we're working with a long time. "
2022-03-23 21:01:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:01:27 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a big design part of our work that we were able to use the airplane, if we had to solve a unique solution, if we had to use a unique solution, if we were able to use all the problems, it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to use it, if we were able to use a unique, if we were able to use it, if we're still able to use it, if we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the
2022-03-23 21:01:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:01:27 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.247 | ppl 18.99 | bleu 15.72 | wps 3087.1 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.72
2022-03-23 21:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 21:01:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 15.72) (writing took 0.9751676032319665 seconds)
2022-03-23 21:01:28 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 21:01:28 | INFO | train | epoch 015 | loss 4.655 | ppl 25.19 | wps 7774.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.292 | loss_scale 4 | train_wall 447 | gb_free 13.3 | wall 7697
2022-03-23 21:01:28 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 21:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:03:57 | INFO | train_inner | epoch 016:     50 / 157 loss=4.657, ppl=25.23, wps=7267.8, ups=0.29, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.261, loss_scale=4, train_wall=289, gb_free=13.8, wall=7846
2022-03-23 21:08:36 | INFO | train_inner | epoch 016:    150 / 157 loss=4.287, ppl=19.53, wps=8831.7, ups=0.36, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.115, loss_scale=4, train_wall=279, gb_free=14, wall=8126
2022-03-23 21:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:09:02 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-23 21:09:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:09:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 21:09:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:09:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 21:09:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:09:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where happy legs and fat.
2022-03-23 21:09:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:09:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electroelectroelectrodes on his head and understand what all the thoughts are.
2022-03-23 21:09:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:09:30 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamace of the responsibility, the number of animals grew up, and the number of animals have become a foundation in namibia.
2022-03-23 21:09:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:09:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic magnetic lines in the field, but the conductor like this, if you don't need it, if you need your energy, and you need your energy.
2022-03-23 21:09:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:09:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection reflection, we can start with a traditional face, we can start able to start able to start able to start with the face of the face of the face, and we can start through it.
2022-03-23 21:09:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:09:48 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting for me and measure for tedley, "yes, you know, you know," yes, you know, you know, it was the best thing that you're going to say, "you know," you know, "if you're talking about it."
2022-03-23 21:09:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:09:49 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention of the invention, and one part of the work that we had to solve on our airplane was that we had to solve a unique result that we had to solve it.
2022-03-23 21:09:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:09:49 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.074 | ppl 16.85 | bleu 14.43 | wps 3461.7 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 15.72
2022-03-23 21:09:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:09:49 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:09:49 | INFO | train | epoch 016 | loss 4.371 | ppl 20.69 | wps 7880.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.181 | loss_scale 4 | train_wall 447 | gb_free 13.6 | wall 8198
2022-03-23 21:09:49 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:14:19 | INFO | train_inner | epoch 017:     93 / 157 loss=4.191, ppl=18.27, wps=7396.1, ups=0.29, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.204, loss_scale=4, train_wall=288, gb_free=14.5, wall=8468
2022-03-23 21:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:17:25 | INFO | fairseq.tasks.translation | example hypothesis: we got this pink in the clinic clinic clinic clinic in the clinic clinic clinic.
2022-03-23 21:17:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:17:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 21:17:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:17:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf locks that are going to create two new trucks.
2022-03-23 21:17:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:17:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food food food food, where happy legs are going to be salt and fat.
2022-03-23 21:17:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:17:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electrodes on his head and understand what all its thoughts are on the top of the way.
2022-03-23 21:17:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:17:58 | INFO | fairseq.tasks.translation | example hypothesis: this is where people took responsibility for the wild responsibility, and the number of animals grew up, and this is a foundation for conservation in namibia.
2022-03-23 21:17:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:18:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of magnetic magnetic magnetic magnetic field, but the susullies, but the susucks, if you don't need your energy, and you know, you know, you know, you know, you're going to have a few energy, you know, you know, you're going to have to
2022-03-23 21:18:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:18:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection reflection reflection reflection reflection, we can start with a traditional facial face, and you can start to reform it through the shape, and that's the whole shape of the structure, and the whole structure of the structure, and the whole structure, which gives you all the structure, which is a whole structure.
2022-03-23 21:18:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:18:20 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that it's interesting and measure it interesting for me to be here for tedtalks, "yes, it's been said," well, when you're going to say, "the best thing that you're going to say," '"you're going to support you're going to support,"' "and you've been working on," well, "you know," well, "you've got a long time for you know, you know, you know," well, "you're going to have been working with you're going to have a long time for example," you're going to do it's a silent, "you're going to say, you're going to do it's a silent," and you know, "you're going to be working with you know," and you're going to be working with you've got
2022-03-23 21:18:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:18:22 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, interestingly, the mother is still the invention of invention, and one part of the design design that we have to see is that we had to use a unique result of it, and if you're all connected to the solution, it's a mechanism that you're all connected to the ground, you can see if you're able to use it, you're able to see the engine, you're able to use it, you're able to see, you're able to see, you're able to see, you're able to see, you're able to use the engine, you're all the engine, you're all the engine, you're going to see, you're able to use it, you're able to use it, you're able to use it, you're going to see, you're able to use it, you're going to see, you're able to see, you're going to see, you're able to see, you're able to see, and if you're able to see the engine, you can
2022-03-23 21:18:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:18:22 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.902 | ppl 14.94 | bleu 16.02 | wps 2834.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 16.02
2022-03-23 21:18:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:18:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 16.02) (writing took 0.9484279453754425 seconds)
2022-03-23 21:18:23 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:18:23 | INFO | train | epoch 017 | loss 4.172 | ppl 18.03 | wps 7678.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.193 | loss_scale 4 | train_wall 449 | gb_free 13.2 | wall 8712
2022-03-23 21:18:24 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:18:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:20:10 | INFO | train_inner | epoch 018:     36 / 157 loss=4.092, ppl=17.05, wps=7182.6, ups=0.28, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.163, loss_scale=4, train_wall=286, gb_free=13.9, wall=8819
2022-03-23 21:24:50 | INFO | train_inner | epoch 018:    136 / 157 loss=3.943, ppl=15.38, wps=8849.8, ups=0.36, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.094, loss_scale=4, train_wall=280, gb_free=13.7, wall=9099
2022-03-23 21:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:25:57 | INFO | fairseq.tasks.translation | example hypothesis: we made this sheep in the clinic.
2022-03-23 21:25:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:26:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is the most familiar here.
2022-03-23 21:26:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:26:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks of dindindindines.
2022-03-23 21:26:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:26:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs are being served with salz and fat.
2022-03-23 21:26:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:26:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a couple of electrodes on his head, and understand exactly what all his thoughts are on the top.
2022-03-23 21:26:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:26:27 | INFO | fairseq.tasks.translation | example hypothesis: in the mamaibia, like the people of responsibility for the wild, grew up to the number of wild animals, and that's a foundation for conservation protection.
2022-03-23 21:26:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:26:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some blooding of magnetic fields in the inner lines, but the susulant alalalarm doesn't like you, if you need your energy movements, you need energy, and you need the conductor.
2022-03-23 21:26:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:26:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that can reflect from this reflection, we can start with a traditional facial face, which can start with a traditional face of the face of the faces, and that's what's going to be able to be able to be able to reform the information, and the whole structure that creates a whole structure.
2022-03-23 21:26:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:26:48 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting to be interesting and measure it for me to be here in tedwomen, "well, that..." yes, it was that... "
2022-03-23 21:26:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:26:50 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and one part of the design work that we've been able to see in our plane, is a result of them that we had to solve the unique problems that we had to solve it in the ground, it was connected to the soil, to an aircraft, and it is to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to navigate the same
2022-03-23 21:26:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:26:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.578 | ppl 11.94 | bleu 20.94 | wps 3101.9 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.94
2022-03-23 21:26:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:26:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:26:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.94) (writing took 0.9612615620717406 seconds)
2022-03-23 21:26:51 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:26:51 | INFO | train | epoch 018 | loss 3.945 | ppl 15.4 | wps 7779.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.061 | loss_scale 4 | train_wall 447 | gb_free 13.2 | wall 9220
2022-03-23 21:26:51 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:26:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:30:42 | INFO | train_inner | epoch 019:     79 / 157 loss=3.814, ppl=14.07, wps=7284.3, ups=0.28, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.008, loss_scale=4, train_wall=292, gb_free=13.5, wall=9451
2022-03-23 21:34:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:34:26 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in clinics.
2022-03-23 21:34:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:34:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha, which probably knows most of you here.
2022-03-23 21:34:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:34:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldial dines that are going to get two new pigs.
2022-03-23 21:34:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:34:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where frog legs are served with salz and ppure.
2022-03-23 21:34:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:34:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 21:34:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:34:55 | INFO | fairseq.tasks.translation | example hypothesis: this is a basis of how people had responsibility for wildlife, grew up the number of wild animals again, and that's a foundation for conservation in nambia.
2022-03-23 21:34:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:35:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some blooding field lines in the inner field, but the susulalalalalalalaly like you don't move, if you need your energy movements and so forth.
2022-03-23 21:35:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:35:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, the big constrains of the face of the face, and the basic shape of the information, which is the whole structure, the whole structure, and the whole structure.
2022-03-23 21:35:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:35:14 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measured for me here at tedwomen is that... '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''
2022-03-23 21:35:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:35:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design work that we're in our airplane, and if we were a result of the trajectory, we had to solve the unique problems that were connected to the ground -- everything that were connected to the ground, and it was a refugee, and it allows us to refugee, or a refugee, and if you, it, you can see, or in the aircraft, or in the aircraft, and you can see, you can see, or the aircraft, or the aircraft, and you can see, or in the aircraft, it's a mechanism, it, you can see, or the trains, or in the aircraft, or the aircraft, or the edge, or the trains, and you're either, or the trains, or the aircraft, you can see, or the aircraft, or the trains, and you can see, or you can
2022-03-23 21:35:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:35:16 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.458 | ppl 10.99 | bleu 21.23 | wps 3227 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.23
2022-03-23 21:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:35:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.23) (writing took 0.9639792270027101 seconds)
2022-03-23 21:35:17 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:35:17 | INFO | train | epoch 019 | loss 3.722 | ppl 13.2 | wps 7798 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.017 | loss_scale 4 | train_wall 448 | gb_free 13.4 | wall 9726
2022-03-23 21:35:18 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:35:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:36:22 | INFO | train_inner | epoch 020:     22 / 157 loss=3.624, ppl=12.33, wps=7298.7, ups=0.29, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.992, loss_scale=4, train_wall=282, gb_free=14.2, wall=9791
2022-03-23 21:41:16 | INFO | train_inner | epoch 020:    122 / 157 loss=3.534, ppl=11.58, wps=8794.6, ups=0.34, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.885, loss_scale=4, train_wall=294, gb_free=13.2, wall=10085
2022-03-23 21:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:42:53 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 21:42:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:42:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:42:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:43:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollolocks of dinners that create two new pigments.
2022-03-23 21:43:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:43:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are doing with salsalz and puppet legs.
2022-03-23 21:43:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:43:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making some electroelectrodes on his head, and understand exactly what all his thoughts are on the track.
2022-03-23 21:43:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:43:25 | INFO | fairseq.tasks.translation | example hypothesis: this is a foundation of how the people had committed for the wild responsibility, grew up to the number of wild animals again, and that's a foundation of conservation in namibia.
2022-03-23 21:43:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:43:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field lines in the inner field, but the sulalaly doesn't like you, if you're going to move your movements, and so the sulength of magnetic field.
2022-03-23 21:43:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:43:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape of the information, and through that information that information that creates the whole structure, and the whole structure of all the shape, and all the shape of these shapes.
2022-03-23 21:43:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:43:45 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to be very interesting, and measure it for me here at tedwomen, is that... yes, when you were in the best way, "somebody said," you know, the men in a table of a table, and if you're going to be able to be able to be able to be able to be the revolution, and when the revolution starts to be the revolution that revolution, and then you know, and then we've been listening to you know, "] ["] ["] ["] ["] [" well, we've been listening to you know, we've got a long time to you know, we've been listening to the piano for the piano for the piano for you know, we've got a long time in the piano for the piano, we've got a long time to you know, we've got a long time
2022-03-23 21:43:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:43:48 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuing to a continuous transition, and all the variation of a continuous variable system, and it allows us to be able to be able to be able to be able to be able to be able to be able to see if we're able to use a mechanism in a market market market, or a mechanism in the same mechanism, or a market market market market, or a market, if you can either, if you can actually put it's a mechanism in the aircraft in the way, or a market, or a market market, or a market, or a market, if you're actually put it in the way, if you're actually put it in the way, you can actually put it in the way, you can actually put it in the way, you've got to
2022-03-23 21:43:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:43:48 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.369 | ppl 10.33 | bleu 23.33 | wps 3004.3 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.33
2022-03-23 21:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:43:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 21:43:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.33) (writing took 0.8952788440510631 seconds)
2022-03-23 21:43:49 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:43:49 | INFO | train | epoch 020 | loss 3.522 | ppl 11.49 | wps 7721.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.942 | loss_scale 4 | train_wall 449 | gb_free 13.7 | wall 10238
2022-03-23 21:43:49 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:46:59 | INFO | train_inner | epoch 021:     65 / 157 loss=3.399, ppl=10.55, wps=7249.8, ups=0.29, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.013, loss_scale=4, train_wall=281, gb_free=13.4, wall=10428
2022-03-23 21:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:51:23 | INFO | fairseq.tasks.translation | example hypothesis: we did this sheep in the clinic clinic.
2022-03-23 21:51:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:51:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 21:51:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:51:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gollocks.
2022-03-23 21:51:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:51:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs will be done with salz.
2022-03-23 21:51:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:51:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand what all its thoughts are on the track.
2022-03-23 21:51:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:51:54 | INFO | fairseq.tasks.translation | example hypothesis: this is one of the people like the responsibility of the wildlife animals. and that's a foundation for conservation in nambia.
2022-03-23 21:51:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:52:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bust of magnetic fields in the inner field, but the sulaly of the supermovements don't like you move, because your movements need to move, and so the sususuitation of the superconductors.
2022-03-23 21:52:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:52:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial of the face and the basic shape of the face and reform it through that information that is the whole structure.
2022-03-23 21:52:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:52:11 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and measuring me here at tedwomen. "
2022-03-23 21:52:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:52:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design system, that we're going to be able to be able to be able to be able to be able to be able to solve the unique problems that were connected to the ground.
2022-03-23 21:52:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:52:12 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.286 | ppl 9.76 | bleu 22.24 | wps 3333.1 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.33
2022-03-23 21:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:52:12 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:52:12 | INFO | train | epoch 021 | loss 3.397 | ppl 10.53 | wps 7850.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.969 | loss_scale 4 | train_wall 447 | gb_free 14.3 | wall 10741
2022-03-23 21:52:12 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:52:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:52:37 | INFO | train_inner | epoch 022:      8 / 157 loss=3.419, ppl=10.69, wps=7345.6, ups=0.3, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.952, loss_scale=4, train_wall=281, gb_free=13.4, wall=10766
2022-03-23 21:57:16 | INFO | train_inner | epoch 022:    108 / 157 loss=3.303, ppl=9.87, wps=8805.1, ups=0.36, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.949, loss_scale=4, train_wall=280, gb_free=13.4, wall=11045
2022-03-23 21:59:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:59:46 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 21:59:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:59:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha who probably know most of you here.
2022-03-23 21:59:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:59:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to write new golden locks.
2022-03-23 21:59:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:00:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, french food, where frog legs are served with salz and puppet.
2022-03-23 22:00:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:00:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:00:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:00:15 | INFO | fairseq.tasks.translation | example hypothesis: this is a basis of how people were taking responsibility for wild animals, and that's a foundation for conservation.
2022-03-23 22:00:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:00:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodding lines in the inner field, but the suprouters don't like you, because your movements need.
2022-03-23 22:00:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:00:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape of the face, and then reform it through that information that gives it through the sound of the sound, and puts it into the desperate.
2022-03-23 22:00:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:00:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measuring me here at tedwomen, is that... "
2022-03-23 22:00:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:00:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in the plane, was a result that we had to solve the unique problems that we had to be connected to the ground so that they were connected to the ground, and they're able to refrigergergergergerate it, and they're going to be able to be able to refrigerate the aircraft.
2022-03-23 22:00:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:00:35 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.212 | ppl 9.27 | bleu 22.65 | wps 3355.2 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.33
2022-03-23 22:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 22:00:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 22:00:35 | INFO | train | epoch 022 | loss 3.264 | ppl 9.61 | wps 7847.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.897 | loss_scale 4 | train_wall 448 | gb_free 14 | wall 11244
2022-03-23 22:00:35 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 22:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:03:02 | INFO | train_inner | epoch 023:     51 / 157 loss=3.196, ppl=9.16, wps=7387.8, ups=0.29, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.776, loss_scale=4, train_wall=290, gb_free=13.3, wall=11391
2022-03-23 22:07:50 | INFO | train_inner | epoch 023:    151 / 157 loss=3.078, ppl=8.44, wps=8812.9, ups=0.35, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.882, loss_scale=4, train_wall=288, gb_free=13.3, wall=11679
2022-03-23 22:08:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:08:11 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 22:08:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:08:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha, which i think most of you here.
2022-03-23 22:08:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:08:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to run new goldicks.
2022-03-23 22:08:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:08:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food where frog legs are served with salz and phalt.
2022-03-23 22:08:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:08:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and just understanding what all his thoughts are on the track.
2022-03-23 22:08:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:08:41 | INFO | fairseq.tasks.translation | example hypothesis: this is a foundation for wildlife. and this is a foundation of wildlife.
2022-03-23 22:08:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:08:47 | INFO | fairseq.tasks.translation | example hypothesis: first is some blow of magnetic field in the inner, but the superconductor doesn't like if you move, because your energy, and so the superconductor of magnetic field.
2022-03-23 22:08:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:08:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face that can be able to restore the big constructions of the face and the basic shape of the face and the basic shape of the fundamental structure, and through the entire portion, which is the whole porting of the whole portion, which is a whole portion that we can fold.
2022-03-23 22:08:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:09:01 | INFO | fairseq.tasks.translation | example hypothesis: sixth: one of the reasons that it's highly interesting and measuring to me here in tedwomen, is that -- tj, when you're striking dinner, it's best than someone said, "turn you on the best," turn you to the men on your table and say, "if we're talking to you're talking to you," we're talking to you, "well," we're talking about the fact, "parkinson," well, "well," we're talking about the fact, "well," we're talking about the fact, "parkinson," we're talking to you're talking to you're talking to you're talking to you're talking to you're talking to you're talking about a game game game game, "-- that's a game," -- that's a game game, "-- that's a long time,
2022-03-23 22:09:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:09:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're using in the plane, was a result that we had to solve the unique problems that we had to solve the unique problems that they were connected to the ground -- all sorts of communication and a continuously variable system, all of the things that we're going to have to do with aircraft, that we're going to be able to be able to be able to do is that if you can use aircraft.
2022-03-23 22:09:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:09:03 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.143 | ppl 8.84 | bleu 24.55 | wps 3100 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.55
2022-03-23 22:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:09:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:09:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.55) (writing took 0.9076229170896113 seconds)
2022-03-23 22:09:04 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:09:04 | INFO | train | epoch 023 | loss 3.123 | ppl 8.71 | wps 7756.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.852 | loss_scale 4 | train_wall 449 | gb_free 14.2 | wall 11753
2022-03-23 22:09:05 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:13:33 | INFO | train_inner | epoch 024:     94 / 157 loss=3.038, ppl=8.21, wps=7269.1, ups=0.29, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.809, loss_scale=4, train_wall=283, gb_free=13.3, wall=12022
2022-03-23 22:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:16:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:16:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:16:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-23 22:16:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:16:50 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gold locks that are going to transcend two new pigs.
2022-03-23 22:16:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:16:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pit.
2022-03-23 22:16:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:17:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:17:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:17:09 | INFO | fairseq.tasks.translation | example hypothesis: this is how people have been taking responsibility for wildlife, the number of wildwildwildwildwildwildwildwildwildwildanimals, and that's a foundation for conservation in namibia.
2022-03-23 22:17:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:17:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some bust of magnetic fields are caught in the inside, but the superconductors don't like if they're moving, because their movements need energy, and so the superconductor of magnetic field.
2022-03-23 22:17:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:17:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, the big configurations of the face and the basic form of the face and restoring it through the branch of information that makes the whole portion and all the folds.
2022-03-23 22:17:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:17:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's extremely interesting and measuring me here at tedwomen is that... tn, it was the best when someone said, "wasting you on your men and saying," if the revolution begins to you, "'"' "'"' "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 22:17:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:17:29 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're in our airplane is a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous refrigerator and cooling system and refrigerators to the aircraft, and that if you can't see the republicans in the aircraft, or aggregate, if you can't see the power of the republicans.
2022-03-23 22:17:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:17:29 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.946 | ppl 7.71 | bleu 26.21 | wps 3210.2 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.21
2022-03-23 22:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:17:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:17:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.21) (writing took 0.8756536217406392 seconds)
2022-03-23 22:17:30 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:17:30 | INFO | train | epoch 024 | loss 3.004 | ppl 8.02 | wps 7802.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.775 | loss_scale 4 | train_wall 447 | gb_free 13.9 | wall 12259
2022-03-23 22:17:31 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:19:20 | INFO | train_inner | epoch 025:     37 / 157 loss=2.902, ppl=7.48, wps=7334.2, ups=0.29, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.736, loss_scale=4, train_wall=289, gb_free=13.5, wall=12369
2022-03-23 22:24:06 | INFO | train_inner | epoch 025:    137 / 157 loss=2.985, ppl=7.92, wps=8767.1, ups=0.35, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.855, loss_scale=4, train_wall=285, gb_free=13.4, wall=12655
2022-03-23 22:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:25:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:25:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:25:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 22:25:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:25:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to run two new pigs.
2022-03-23 22:25:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:25:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food where happy legs are served with salz and pitcase.
2022-03-23 22:25:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:25:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:25:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:25:35 | INFO | fairseq.tasks.translation | example hypothesis: this is like people's responsibility for wildlife survival, and this is a foundation for conservation protection in namibia.
2022-03-23 22:25:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:25:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like you move, because your movements need your energy, and so the superconducting disorder.
2022-03-23 22:25:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:25:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional facial view, which is the big constructure of the face and the basic shape of the face and the basic shape, and through the one of the information that makes the whole portion structure and all the folds.
2022-03-23 22:25:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:25:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measuring me here at tedwomen is that... tja, it was best summarized when someone said, "turn you on the men on a table and say," if the revolution starts supporting you. "
2022-03-23 22:25:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:25:56 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a large part of the design work that we're at the most stumes, was a result that we had to solve the unique problems that were connected to surgery to operate on the ground -- everything from a continuous variables and refrigering system that drivers us in the air, or to the wind, if you can't see the same thing that we have to be able to be able to be able to be able to be able to be able to do is to get able to get able to the most specific, if we had to do is to get able to do is to get able to do, to the same, to the same thing that we had to do is to solve the same thing that we had to do is to do with the same thing that we had to solve the same thing that we had to do is to solve the same thing that we had to operate in the same way that we had to operate in the world, to operate in the world, to operate in the world,
2022-03-23 22:25:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:25:56 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.972 | ppl 7.85 | bleu 25.06 | wps 3299.8 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.21
2022-03-23 22:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:25:56 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:25:56 | INFO | train | epoch 025 | loss 2.927 | ppl 7.6 | wps 7814.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.802 | loss_scale 4 | train_wall 449 | gb_free 14.2 | wall 12765
2022-03-23 22:25:56 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:29:51 | INFO | train_inner | epoch 026:     80 / 157 loss=2.825, ppl=7.09, wps=7361.5, ups=0.29, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.755, loss_scale=4, train_wall=289, gb_free=13.5, wall=13000
2022-03-23 22:33:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:33:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples into the clinic.
2022-03-23 22:33:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:33:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:33:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:33:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will generate two new pigs.
2022-03-23 22:33:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:33:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 22:33:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:33:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:33:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:34:02 | INFO | fairseq.tasks.translation | example hypothesis: so in the case of people like the responsibility for wildlife, the number of wildwildanimals grew again, and that's a foundation for conservation in namibia.
2022-03-23 22:34:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:34:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bamongst magnetic field lines are caught in the inside, but the superconductor doesn't like it, if you move, because your movements are moving, and so the superconductor disorders of magnetic field.
2022-03-23 22:34:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:34:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the big constructures of the face and the basic shape, and through the theft of information, which is all the porting.
2022-03-23 22:34:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:34:22 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's been very interesting and measuring it up to me here at tedwomen, is that... tyes, when someone said, "turn you to your men on a table and say," when the revolution starts to support you, "when we support you to you," when the truth is that we've been supported here at tedwomen, we've already been the truth is that we've been working with silent. "
2022-03-23 22:34:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:34:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at the edge of our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system and refrigerating with a refriction system that allows us to use tissues to a refriction, that allows us to become a steadily modify, that it to be a steadily modify, if we can be able to deal with a steadily modify the propellence of propellity, or to be able to be able to be connected to be able to navigate mechanism, if we can be able to navigate the propelled, if we can be able to be able to be able to be able to navigate the propelled, if we can be able to navigate the intercept the earth, if we can be connected to be connected to the intercept the intercept the most specific problem with a
2022-03-23 22:34:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:34:24 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.777 | ppl 6.85 | bleu 28.13 | wps 3110.5 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.13
2022-03-23 22:34:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:34:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.13) (writing took 0.8714582454413176 seconds)
2022-03-23 22:34:25 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:34:25 | INFO | train | epoch 026 | loss 2.823 | ppl 7.07 | wps 7754 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.769 | loss_scale 4 | train_wall 449 | gb_free 13.8 | wall 13274
2022-03-23 22:34:25 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:35:33 | INFO | train_inner | epoch 027:     23 / 157 loss=2.747, ppl=6.72, wps=7295.4, ups=0.29, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.732, loss_scale=4, train_wall=282, gb_free=14.3, wall=13342
2022-03-23 22:40:18 | INFO | train_inner | epoch 027:    123 / 157 loss=2.756, ppl=6.75, wps=8803.7, ups=0.35, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.724, loss_scale=4, train_wall=284, gb_free=13.1, wall=13627
2022-03-23 22:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:41:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these bars in the clinic.
2022-03-23 22:41:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:42:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:42:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:42:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 22:42:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:42:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food where frogs are served with salz and pitcase.
2022-03-23 22:42:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:42:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:42:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:42:30 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach like people's responsibility for wildlife, the number of wildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildwildlife grew again, and that's a foundation for conservation in namibia.
2022-03-23 22:42:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:42:36 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught in the inside, but the supraleiters don't like it if you're moving, because your energy movements use, and so the superconductor disorder.
2022-03-23 22:42:36 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:42:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can begin with a traditional face, and recovery of the face and the basic shape, and through this information that pulls all the porting the whole porting structure and folds a fold.
2022-03-23 22:42:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:42:48 | INFO | fairseq.tasks.translation | example hypothesis: i mean, one of the reasons that it's very interesting and measured to be here at tedwomen is that... tja, when dinner was best summarized when somebody said, "turn you to the men on your table," and say, "if the revolution starts to support you."
2022-03-23 22:42:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:42:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane was a result that we had to operate the unique problems that were connected to the ground -- everything from a continuous variables and cooling a refrigerators and cooling a refrigerators system with liquid refrigerators, and a refrigerators, that it allows us to use aircraft traffic, or a particular transportation in the same direction, if you can't see the propelled to the propellers to the propelled to the propellers to the propellers to the propellers to the same place where you can't see the propelled it to the propelled it to the propelled it in a particular vehicle, if you can't see the propelled by a particular vehicle, to the most specific vehicle, or the propelled to the propelled by a device that you can't see the propelled.
2022-03-23 22:42:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:42:51 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.74 | ppl 6.68 | bleu 27.76 | wps 3156.6 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.13
2022-03-23 22:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:42:51 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:42:51 | INFO | train | epoch 027 | loss 2.713 | ppl 6.56 | wps 7809.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.703 | loss_scale 4 | train_wall 447 | gb_free 13.5 | wall 13780
2022-03-23 22:42:51 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:45:58 | INFO | train_inner | epoch 028:     66 / 157 loss=2.658, ppl=6.31, wps=7309.5, ups=0.29, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.706, loss_scale=4, train_wall=282, gb_free=14.2, wall=13967
2022-03-23 22:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:50:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 22:50:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:50:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you here.
2022-03-23 22:50:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:50:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 22:50:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:50:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food where frogs are served with salz and psuitcase.
2022-03-23 22:50:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:50:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:50:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:50:55 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people's responsibility for wildlife, the number of wildlife animals grew back again. and this is a foundation for conservation in namibia.
2022-03-23 22:50:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:51:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like you move because your movements use your energy, and so the superconductor disorder.
2022-03-23 22:51:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:51:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that refers the big constructures of the face and the basic form, and it restores the whole portural structure and all the folds.
2022-03-23 22:51:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:51:14 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it very interesting and measured to be here at tedwomen is that... tja, when they were striking dinner, it was best summarized when someone said, "turn you to your table and tell them," if the revolution begins to support you. "the truth is that we've already been supporting you."
2022-03-23 22:51:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:51:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a large part of the design work that we're in our airplane at the most staggering, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable drives and a system that allows us to refrigerate the aircraft, or to a refrigerator, if you can either get a device to the refrigerator or to an aircraft, if you can use the propellant or the prophecy of a mechanism, if you can use it's a device to a device that allows us to a device to a device that allows us to the fly, if you to the fly, it's appropriate device to a device to a device to the fly, it's appropriate device to the fly, it's appropriate, or to the fly, or to the fly, if you can either drive it allows you can use it's a device to the fly, it's a device to the fly, it's a
2022-03-23 22:51:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:51:17 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.682 | ppl 6.42 | bleu 28.85 | wps 3139.1 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.85
2022-03-23 22:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:51:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:51:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.85) (writing took 0.8941943659447134 seconds)
2022-03-23 22:51:18 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:51:18 | INFO | train | epoch 028 | loss 2.641 | ppl 6.24 | wps 7790.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.723 | loss_scale 4 | train_wall 447 | gb_free 13.3 | wall 14287
2022-03-23 22:51:18 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:51:43 | INFO | train_inner | epoch 029:      9 / 157 loss=2.666, ppl=6.35, wps=7299.5, ups=0.29, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.759, loss_scale=4, train_wall=286, gb_free=13.2, wall=14313
2022-03-23 22:56:28 | INFO | train_inner | epoch 029:    109 / 157 loss=2.557, ppl=5.88, wps=8831.5, ups=0.35, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.662, loss_scale=4, train_wall=284, gb_free=13.1, wall=14597
2022-03-23 22:58:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:58:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 22:58:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:58:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, and most of you know here.
2022-03-23 22:58:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:59:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of dinners that will transcend two new vibrations.
2022-03-23 22:59:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:59:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salz and pbuffer.
2022-03-23 22:59:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:59:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on track.
2022-03-23 22:59:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:59:23 | INFO | fairseq.tasks.translation | example hypothesis: in the sense, like the people responsibility for wildlife, the number of wildlife animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 22:59:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:59:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it if they move, because their movements use their energy, and so the superconductor doesn't like disorder.
2022-03-23 22:59:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:59:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflective reflection, we can start with a traditional facial constructions of the face and reconstructions, and the basic information that contains all the portural structure and all folds.
2022-03-23 22:59:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:59:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it has been highly interesting and appropriate to me here at tedwomen is that... tja, when you were striking dinner, it was best summarized when someone said, "turn you to the men on your desk and tell you," if the revolution starts to support you. "
2022-03-23 22:59:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:59:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane the stumest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and refrigeration system that allows us to refrigerate aircraft, to either be able to use the mechanism of a device that allows us to refrigerators to be able traffic.
2022-03-23 22:59:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:59:44 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.686 | ppl 6.43 | bleu 28.95 | wps 3131.6 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.95
2022-03-23 22:59:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 22:59:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:59:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 22:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 28.95) (writing took 0.8873832430690527 seconds)
2022-03-23 22:59:45 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 22:59:45 | INFO | train | epoch 029 | loss 2.56 | ppl 5.9 | wps 7788.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.688 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 14794
2022-03-23 22:59:45 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 22:59:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:02:13 | INFO | train_inner | epoch 030:     52 / 157 loss=2.549, ppl=5.85, wps=7281.2, ups=0.29, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.699, loss_scale=4, train_wall=285, gb_free=13.5, wall=14942
2022-03-23 23:06:58 | INFO | train_inner | epoch 030:    152 / 157 loss=2.452, ppl=5.47, wps=8855.6, ups=0.35, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.607, loss_scale=4, train_wall=286, gb_free=14.3, wall=15227
2022-03-23 23:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:07:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters on the clinic.
2022-03-23 23:07:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:07:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:07:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:07:30 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be transmitted by two new pigs.
2022-03-23 23:07:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:07:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salce and pitcase.
2022-03-23 23:07:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:07:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 23:07:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:07:49 | INFO | fairseq.tasks.translation | example hypothesis: so in the sense of people's responsibility for wildlife, the number of wildlife animals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 23:07:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:07:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements use their energy, and so the superconducting disorders.
2022-03-23 23:07:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:08:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that reproduce the big configurations of the face and the basic shape, and through the dieting information that makes all the pores structure and all the folds.
2022-03-23 23:08:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:08:08 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and measured to me here at tedwomen is that... tja, when dinner was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution starts, we already have a long theme for you. "
2022-03-23 23:08:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:08:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use aircraft in the aircraft until one particular thing, to the propelled to the propeller, or to the propeller.
2022-03-23 23:08:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:08:10 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.607 | ppl 6.09 | bleu 29.92 | wps 3147.3 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.92
2022-03-23 23:08:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:08:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:08:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:08:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.92) (writing took 0.9034753642044961 seconds)
2022-03-23 23:08:11 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:08:11 | INFO | train | epoch 030 | loss 2.475 | ppl 5.56 | wps 7796.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.639 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 15300
2022-03-23 23:08:12 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:12:48 | INFO | train_inner | epoch 031:     95 / 157 loss=2.461, ppl=5.5, wps=7309.6, ups=0.29, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.685, loss_scale=4, train_wall=290, gb_free=13.1, wall=15577
2022-03-23 23:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:15:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these piecer in the clinic.
2022-03-23 23:15:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:15:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:15:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:15:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to cross two new pigs.
2022-03-23 23:15:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:16:03 | INFO | fairseq.tasks.translation | example hypothesis: there's french chinese food, for example, where frogs are served with salz and ppeffer.
2022-03-23 23:16:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:16:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on track.
2022-03-23 23:16:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:16:16 | INFO | fairseq.tasks.translation | example hypothesis: in the maginy of people like responsibility for wildlife, the number of wildlife survivors grew back again, and that has become a foundation for conservation in namibia.
2022-03-23 23:16:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:16:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use your energy, and so the superconducting disorder.
2022-03-23 23:16:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which resembles the big configurations of the face and restores the basic shape, and through that information that whole porter structure and all the floods.
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:16:35 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tja, when you strive dinner, it was best summarized when someone said, "turn you to men on your table and tell them," when the revolution begins, we support you. "the truth is that we've already been supported for you."
2022-03-23 23:16:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:16:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane are stump, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variable drives and a system of refrigeration that allows us to use aircraft in the aircraft, to a particular transport, to a legal transport, to a legal transport, to a gps conditioning machine.
2022-03-23 23:16:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:16:37 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.565 | ppl 5.92 | bleu 30.36 | wps 3153.1 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.36
2022-03-23 23:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:16:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.36) (writing took 0.8857837067916989 seconds)
2022-03-23 23:16:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:16:38 | INFO | train | epoch 031 | loss 2.436 | ppl 5.41 | wps 7790.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.657 | loss_scale 4 | train_wall 447 | gb_free 12.9 | wall 15807
2022-03-23 23:16:39 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:16:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:18:28 | INFO | train_inner | epoch 032:     38 / 157 loss=2.343, ppl=5.07, wps=7319.6, ups=0.29, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.593, loss_scale=4, train_wall=281, gb_free=13.9, wall=15917
2022-03-23 23:23:16 | INFO | train_inner | epoch 032:    138 / 157 loss=2.379, ppl=5.2, wps=8791.6, ups=0.35, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.663, loss_scale=4, train_wall=287, gb_free=13.9, wall=16205
2022-03-23 23:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:24:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep plasters in the clinic.
2022-03-23 23:24:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:24:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:24:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:24:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 23:24:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:24:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pitcase.
2022-03-23 23:24:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:24:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all of his thoughts are on track.
2022-03-23 23:24:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:24:42 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people's responsibility for survival, the number of wildlife animals grew back. and that's become a foundation for conservation in namibia.
2022-03-23 23:24:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:24:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and the superconducting disorder.
2022-03-23 23:24:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:24:55 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constraints of the face and reproduce the basic shape, and then refuse it through the one that refers the whole porter structure and all the folds.
2022-03-23 23:24:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:25:01 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tja, when i was striking dinner, it was best summarized when someone said, "turn you to men on your desk and tell you," when the revolution begins, we'll support you. "the truth is that we've been supporting you in this topic for a long time."
2022-03-23 23:25:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:25:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're on our airplane are stumbling, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a refrigeration system with refrigeration, that allows us to use a vehicle in the aircraft, or a trajectory, or a lawyer.
2022-03-23 23:25:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:25:03 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.545 | ppl 5.84 | bleu 30.08 | wps 3214.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.36
2022-03-23 23:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:25:03 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:25:03 | INFO | train | epoch 032 | loss 2.355 | ppl 5.12 | wps 7826.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.637 | loss_scale 4 | train_wall 447 | gb_free 14 | wall 16312
2022-03-23 23:25:03 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:28:56 | INFO | train_inner | epoch 033:     81 / 157 loss=2.255, ppl=4.77, wps=7371.6, ups=0.29, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.617, loss_scale=4, train_wall=283, gb_free=13.6, wall=16545
2022-03-23 23:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:32:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:32:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:32:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-23 23:32:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:32:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of signs that are going to cross two new vibrations.
2022-03-23 23:32:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:32:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salt and pitffer.
2022-03-23 23:32:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:33:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:33:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:33:08 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people taking responsibility for wildlife, the number of wildlife animals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 23:33:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:33:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the wires of magnetic field are captured inside, but the superconductor doesn't like it if they move, because their movements use their energy, and the superconductor disorder.
2022-03-23 23:33:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:33:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and then through the diethful information that refers the whole portion structure and all the fits.
2022-03-23 23:33:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:33:27 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons it's really interesting and measured to me here at tedwomen, is that... tja, when dinner was best summarized when someone said, "turn you to men on your desk and tell you," if the revolution starts to support you. "the truth is that we love women, we've already been supporting you for a long time," and then we've been supporting rape, "silly," and then we're going to send you to the future. "
2022-03-23 23:33:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:33:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigerator system that allows us to use aircraft in the aircraft, or to a promoting device, or to a promoting device, if we were able to use the aircraft, to fly, or to fly, or to the aircraft, or to a mechanism, or to the flowing, to the aircraft, to the ground, to the aircraft, to the aircraft, to the aircraft, to the aircraft, or to the aircraft, or to fly, or to be able thing, to be able thing, to be able to be able to be able to do, to do, to do, to do, or to do, to do, to do, or to be able to do, to do, to do
2022-03-23 23:33:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:33:29 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.508 | ppl 5.69 | bleu 31.28 | wps 3132.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.28
2022-03-23 23:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:33:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.28) (writing took 0.956550176255405 seconds)
2022-03-23 23:33:30 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:33:30 | INFO | train | epoch 033 | loss 2.3 | ppl 4.92 | wps 7778.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.619 | loss_scale 4 | train_wall 448 | gb_free 13.5 | wall 16819
2022-03-23 23:33:32 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:34:43 | INFO | train_inner | epoch 034:     24 / 157 loss=2.336, ppl=5.05, wps=7251.5, ups=0.29, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.627, loss_scale=4, train_wall=285, gb_free=13.4, wall=16892
2022-03-23 23:39:27 | INFO | train_inner | epoch 034:    124 / 157 loss=2.234, ppl=4.7, wps=8833.9, ups=0.35, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.637, loss_scale=4, train_wall=284, gb_free=13.2, wall=17176
2022-03-23 23:40:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:41:05 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepples in the clinic.
2022-03-23 23:41:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:41:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:41:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:41:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to cross two new pigs.
2022-03-23 23:41:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:41:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pitcase.
2022-03-23 23:41:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:41:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 23:41:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:41:35 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach like human responsibility for survival, the number of wildlife animals grew back again, and that's a basis for conservation in namibia.
2022-03-23 23:41:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:41:42 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it if they move, because their movements use their energy, and that's the superconductor disorder.
2022-03-23 23:41:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:41:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that resurrecates the larger constraints of the face, and reproduce the basic shape, and then we pull it through the dieting of that information that wraps the entire porch structure, and all the fits up.
2022-03-23 23:41:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:41:54 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it interesting and appropriate to me here at tedwomen is that, you know, if you were striking dinner, it was best summarized when someone said, "well, if the revolution begins to support you to your table and tell you, 'if the revolution starts to support you.' '' the truth is that we've already been supporting you for a long time with silel carcines."
2022-03-23 23:41:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:41:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane is the one result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variables and a cooling system with refrigeration that allows us to use a plane plane plane plane to a congo to a particular vehicle, if we had to see the propeller, if we had to be able to deal with the ground, if we had to be able to be able to deal with the point out of a mechanism, it's connected to the point where we can't be able to the point where we can't be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate,
2022-03-23 23:41:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:41:57 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.503 | ppl 5.67 | bleu 31.23 | wps 3154.4 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.28
2022-03-23 23:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:41:57 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:41:57 | INFO | train | epoch 034 | loss 2.258 | ppl 4.78 | wps 7797.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.647 | loss_scale 4 | train_wall 446 | gb_free 13.2 | wall 17326
2022-03-23 23:41:57 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:45:12 | INFO | train_inner | epoch 035:     67 / 157 loss=2.262, ppl=4.8, wps=7286.9, ups=0.29, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.642, loss_scale=4, train_wall=286, gb_free=14.2, wall=17521
2022-03-23 23:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:49:32 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepples in the clinic.
2022-03-23 23:49:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:49:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:49:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:49:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to translate two new pigs.
2022-03-23 23:49:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:49:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pffer.
2022-03-23 23:49:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:49:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on track.
2022-03-23 23:49:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:50:02 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people taking responsibility for wildlife, the number of wildlife animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 23:50:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:50:08 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some atoms of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your energy movements are abusing, and so the superconducting disorder.
2022-03-23 23:50:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:50:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial sphere that restores the big constructions of the face and the basic shape, and picks it through this information that refuses the whole portion structure and all the ffits.
2022-03-23 23:50:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:50:20 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate to be here at tedwomen, is that... tyes, when striking dinner was summarized best, when someone said, "turn you to the men in your table and tell them," when the revolution begins, we support you. '"the truth is that we've already been supporting you on this topic for a long time with silly carroton," and then we've been supporting the future. "
2022-03-23 23:50:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:50:22 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, necessary is still the mother of invention, and a large part of the design work we're on on our airplane is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable drives and cooling system with refrigeration that allows us to use a portable aircraft in the go-and-passing, or to the propeller floor, if we can see it in the air conditioning space, or the propelled to a mechanism, all the propeller system, to a continuously variable system, all of a continuously variable system with a continuously variable system, to a steady system, to become a refrigerator.
2022-03-23 23:50:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:50:22 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.468 | ppl 5.53 | bleu 31.46 | wps 3244.2 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.46
2022-03-23 23:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:50:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 31.46) (writing took 0.9499867800623178 seconds)
2022-03-23 23:50:23 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:50:23 | INFO | train | epoch 035 | loss 2.193 | ppl 4.57 | wps 7797.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.591 | loss_scale 4 | train_wall 448 | gb_free 12.9 | wall 17832
2022-03-23 23:50:24 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:50:52 | INFO | train_inner | epoch 036:     10 / 157 loss=2.169, ppl=4.5, wps=7314.3, ups=0.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.58, loss_scale=4, train_wall=283, gb_free=14.2, wall=17861
2022-03-23 23:55:38 | INFO | train_inner | epoch 036:    110 / 157 loss=2.134, ppl=4.39, wps=8852.1, ups=0.35, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.591, loss_scale=4, train_wall=285, gb_free=14.2, wall=18147
2022-03-23 23:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:57:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:57:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:58:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:58:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:58:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 23:58:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:58:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pitcase.
2022-03-23 23:58:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:58:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on track.
2022-03-23 23:58:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:58:28 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people taking responsibility for wildlife, the number of wildlife was growing back again, and that's become a foundation for conservation in namibia.
2022-03-23 23:58:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:58:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use your energy, and so the superconduction disrupts.
2022-03-23 23:58:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:58:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which resembles the big constraints of the face, and restores the basic shape, and reconcipating it through that particular information that refers the entire porter structure and all the fits.
2022-03-23 23:58:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:58:47 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that, well, if you were striking dinner, it was best summarized when someone said, "turn to men on your table and tell them, 'if the revolution begins, then we support you.' '' 'the truth, love is that we've already supported you in this topic for a long time."] ["] ["] ["] ["] ["] ["] [unclear] [unclear] ["] [unclear] ["] ["] ["] rama h] rama hunter] rama hunter] [unclear] rama hunter] ["] rama hunter] rama hunter] rama hunter] rama hunter] rama:
2022-03-23 23:58:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:58:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane are stumbling, was a result that we had to solve the unique problems associated with operating on the ground -- everything, from a continual variable drives and a cooler system that allows us to be able to use a steam in the aircraft, or to a steam traffic, which is that if we had to make a lawyer, it all the way down to a lawyer, it's a lawyer, it's a lawyer, it's going to the ground, it's going to be reliable to be reliable to be allowed to be able to be able to be able to be able to operate, it, it, it, it's going to be allowed to be able to be able to be allowed to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 23:58:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:58:50 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.463 | ppl 5.52 | bleu 31.8 | wps 3153 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.8
2022-03-23 23:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-23 23:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 31.8) (writing took 0.9921136819757521 seconds)
2022-03-23 23:58:51 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:58:51 | INFO | train | epoch 036 | loss 2.154 | ppl 4.45 | wps 7784.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.617 | loss_scale 4 | train_wall 448 | gb_free 13.4 | wall 18340
2022-03-23 23:58:51 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 23:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:01:26 | INFO | train_inner | epoch 037:     53 / 157 loss=2.103, ppl=4.3, wps=7345.4, ups=0.29, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.624, loss_scale=4, train_wall=288, gb_free=14.2, wall=18495
2022-03-24 00:06:06 | INFO | train_inner | epoch 037:    153 / 157 loss=2.191, ppl=4.57, wps=8837.9, ups=0.36, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.619, loss_scale=4, train_wall=280, gb_free=13.1, wall=18775
2022-03-24 00:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:06:24 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep plasters in the clinic.
2022-03-24 00:06:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:06:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-24 00:06:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:06:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to be transcend two new pigs.
2022-03-24 00:06:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:06:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pffer.
2022-03-24 00:06:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:06:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-24 00:06:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:06:54 | INFO | fairseq.tasks.translation | example hypothesis: in the stomach, as human responsibility for the wildlife has increased, the number of wildlife grows again. and that has become a foundation for conservation in namibia.
2022-03-24 00:06:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:07:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use their energy, and the superconductor disorders.
2022-03-24 00:07:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:07:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face, which gives the big constraints of the face and reproduce the basic shape of the face, and recover it through that information that's raising the entire porn structure and all the fits.
2022-03-24 00:07:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:07:13 | INFO | fairseq.tasks.translation | example hypothesis: then one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, when constrict dinner was summed best, when someone said, "then you turn to the men in your desk and tell them," if the revolution begins, then we support you. '"'" 'the truth is that we love women is that we've already been supporting you on this topic for a long time. "
2022-03-24 00:07:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:07:16 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variables and a coolest system of refrigeration that allows us to use a port-stop aircraft machine in the go-to-a traffic machine, to a specially appropriate vehicle vehicle vehicle vehicle vehicle vehicle, or the propelled to a physician, to a point where you can see the prophearest est passage in the ground, or the prophearest est est est est est est est est est, the propheed to a mechanism, to a mechanism, all the propeller.
2022-03-24 00:07:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:07:16 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 2.426 | ppl 5.38 | bleu 32.36 | wps 3146.4 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.36
2022-03-24 00:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-24 00:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-24 00:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt
2022-03-24 00:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.02_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.36) (writing took 0.9535598009824753 seconds)
2022-03-24 00:07:17 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-24 00:07:17 | INFO | train | epoch 037 | loss 2.123 | ppl 4.36 | wps 7801.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.605 | loss_scale 4 | train_wall 447 | gb_free 13.7 | wall 18846
2022-03-24 00:07:17 | INFO | fairseq.trainer | begin training epoch 38
2022-03-24 00:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:11:46 | INFO | train_inner | epoch 038:     96 / 157 loss=2.096, ppl=4.27, wps=7246.3, ups=0.29, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.62, loss_scale=4, train_wall=280, gb_free=13.9, wall=19115
2022-03-24 00:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:14:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-24 00:14:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:14:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think know most of you here.
2022-03-24 00:14:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:15:02 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining that will transcend two new pigs.
2022-03-24 00:15:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:15:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served salt and pills.
2022-03-24 00:15:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:15:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-24 00:15:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:15:21 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people taking responsibility for wildlife, the number of wildlife grew back again, and this has become a foundation for conservation in namibia.
2022-03-24 00:15:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:15:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use your energy, and so the superconducting disorder.
2022-03-24 00:15:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:15:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial horizon that restore the big constraints of the face and the basic shape, and then through dieting that information that refers the whole portural structure and all the ffat-fold.
2022-03-24 00:15:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:15:39 | INFO | fairseq.tasks.translation | example hypothesis: then, one of the reasons that makes it interesting and measured to me here at tedwomen is that -- tyes, when constrict dinner, it was best summarized when someone said, "turn to men on your desk and tell them, 'when the revolution begins, we support you.'" the truth is that we've already supported you in this topic for a long time.
2022-03-24 00:15:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:15:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need to be the mother of invention, and a large part of design work that we're on our airplane on the stumbling toes was a result that we had to solve the unique problems associated with operating on the ground -- everything from a continuous variables and cooling system of liquid that allows us to use a portable aircraft in the aircraft at the most proud zealand to a specially appropriate appropriate transportation, either to a propeller space that allows us to see the propelled by a mechanism of a mechanical propeller, or to a mechanism that allows us to use of a conditioning system of a conditioning system of a conditioning system of a conditioning system of a conditioning system of a refrigerator of a mechanism to a mechanism, to the earth to a mechanism that allows us to use of liquid liquid liquid liquid liquid liquid liquid space that allows us to use of aircraft, that allows us to use of a vehicle vehicle vehicle vehicle
2022-03-24 00:15:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:15:42 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 2.435 | ppl 5.41 | bleu 31.21 | wps 3142.5 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.36
2022-03-24 00:15:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-24 00:15:42 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-24 00:15:42 | INFO | train | epoch 038 | loss 2.094 | ppl 4.27 | wps 7825.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.621 | loss_scale 4 | train_wall 446 | gb_free 14.5 | wall 19351
2022-03-24 00:15:42 | INFO | fairseq.trainer | begin training epoch 39
2022-03-24 00:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:17:38 | INFO | train_inner | epoch 039:     39 / 157 loss=2.007, ppl=4.02, wps=7415, ups=0.28, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.573, loss_scale=4, train_wall=293, gb_free=13.2, wall=19467
2022-03-24 00:22:19 | INFO | train_inner | epoch 039:    139 / 157 loss=2.087, ppl=4.25, wps=8823.5, ups=0.36, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.637, loss_scale=4, train_wall=281, gb_free=14.2, wall=19748
2022-03-24 00:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:23:14 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppetters in the clinic.
2022-03-24 00:23:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:23:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-24 00:23:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:23:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to cross two new pigs.
2022-03-24 00:23:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:23:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and pepper.
2022-03-24 00:23:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:23:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-24 00:23:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:23:46 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people's responsibility for wildlife survivors, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-24 00:23:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:23:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if they move, because their movements use, and so the superconductor disorders.
2022-03-24 00:23:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:23:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflective reflection, we can start with a traditional face, which restores the big constraints of the face and restores the basic shape, and then through the diethful information that refers the whole porter structure and all the fine folds.
2022-03-24 00:23:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:24:05 | INFO | fairseq.tasks.translation | example hypothesis: so one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that... tyes, when constrict dinner was best summarized, when someone said, "turn to men on your table and tell them, 'when the revolution begins, we will support you.'" '"the truth, women love is that we've already been supporting you about this issue for a long time.
2022-03-24 00:24:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:24:07 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a lot of the design work that we're on our airplane is the most stumbling, and it was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable and cooling system of liquid that allows us to use a machine in the aircraft and traffic to a particular passenger, or to one of the most propelled to one of the most propellant, either to one of the most propellant, to one of the most propeller, to the point where you can see it's the point where you can see it's going to the point where you can see it's in the point where you can see it's the point where you can see it's in a mechanism of a mechanism of a mechanism is in the same time you can see it's in the same time you can see it's going on the same time you can see it's going to a mechanism is,
2022-03-24 00:24:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:24:07 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 2.407 | ppl 5.3 | bleu 32.01 | wps 3085.4 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.36
2022-03-24 00:24:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-24 00:24:07 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-24 00:24:07 | INFO | train | epoch 039 | loss 2.041 | ppl 4.11 | wps 7806 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.597 | loss_scale 4 | train_wall 446 | gb_free 14.3 | wall 19856
2022-03-24 00:24:08 | INFO | fairseq.trainer | begin training epoch 40
2022-03-24 00:24:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-24 00:27:59 | INFO | train_inner | epoch 040:     82 / 157 loss=2.005, ppl=4.01, wps=7299, ups=0.29, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.557, loss_scale=4, train_wall=280, gb_free=13.7, wall=20088
2022-03-24 00:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:31:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-24 00:31:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-24 00:31:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-24 00:31:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-24 00:31:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-24 00:31:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-24 00:31:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salt and pills.
2022-03-24 00:31:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-24 00:32:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on track.
2022-03-24 00:32:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-24 00:32:10 | INFO | fairseq.tasks.translation | example hypothesis: in the case of people's responsibility for wildlife, the number of wildlife survivors grew again, and that has become a foundation for conservation in namibia.
2022-03-24 00:32:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-24 00:32:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-24 00:32:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:32:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial sscan that restores the big constraints of the face and the basic shape, and replaces it through the thief of information that refers all the porn structure and all the fine folds.
2022-03-24 00:32:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:32:29 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's been really interesting and appropriate for me to be here at tedwomen is that... tyes, when constrict dinner, it was summarized best, when someone said, "turn you to men on your desk and tell them, 'if the revolution begins, then we support you.'" the truth is that we've been supporting you at this topic for a long time. "
2022-03-24 00:32:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:32:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft on our stumest toes was a product of how we had to solve the unique problems that were connected to it on the ground -- everything from a continuously variables and cooling system, that it allows us to use a aircraft machine in the go-traffic until a particular passing device, or the propeller, or when we're going to see the ground.
2022-03-24 00:32:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:32:30 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 2.417 | ppl 5.34 | bleu 31.89 | wps 3298.3 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 32.36
2022-03-24 00:32:30 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-24 00:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-24 00:32:30 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-24 00:32:30 | INFO | train | epoch 040 | loss 1.996 | ppl 3.99 | wps 7855 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.57 | loss_scale 4 | train_wall 446 | gb_free 13.6 | wall 20359
2022-03-24 00:32:30 | INFO | fairseq_cli.train | done training in 20358.8 seconds
