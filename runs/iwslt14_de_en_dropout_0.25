Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 208118122: <iwslt14_de_en_dropout_0.25> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.25> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 07:20:24 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Mon Mar 14 07:20:36 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 07:20:36 2022
Terminated at Mon Mar 14 08:15:27 2022
Results reported at Mon Mar 14 08:15:27 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.25 --weight-decay 0.0001 --criterion cross_entropy --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3275.89 sec.
    Max Memory :                                 4517 MB
    Average Memory :                             3471.48 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15483.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3292 sec.
    Turnaround time :                            3303 sec.

The output (if any) follows:

2022-03-14 07:20:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.25, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-14 07:20:43 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-14 07:20:43 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-14 07:20:43 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-14 07:20:43 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-14 07:20:43 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-14 07:20:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 07:20:43 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-14 07:20:43 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-14 07:20:46 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 07:20:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:46 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-14 07:20:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:46 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 07:20:46 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-14 07:20:46 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:20:46 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:20:46 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 07:20:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-14 07:20:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-14 07:20:46 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-14 07:20:47 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 07:20:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 07:20:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:20:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 07:21:22 | INFO | train_inner | epoch 001:    104 / 157 loss=11.813, ppl=3597.67, wps=80638.1, ups=3.21, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.825, loss_scale=8, train_wall=35, gb_free=14.4, wall=36
2022-03-14 07:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:21:42 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-14 07:21:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:21:44 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-14 07:21:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:21:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,.....
2022-03-14 07:21:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:21:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,
2022-03-14 07:21:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:21:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:22:00 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:22:05 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:22:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:22:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:22:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:22:20 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.995 | ppl 1020.51 | bleu 0.01 | wps 4213.6 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-14 07:22:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-14 07:22:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:22:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.8813046768773347 seconds)
2022-03-14 07:22:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 07:22:22 | INFO | train | epoch 001 | loss 11.325 | ppl 2566.12 | wps 41950.3 | ups 1.67 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 3.048 | loss_scale 8 | train_wall 51 | gb_free 22.4 | wall 96
2022-03-14 07:22:23 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 07:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:22:37 | INFO | train_inner | epoch 002:     47 / 157 loss=10.123, ppl=1114.98, wps=33728.9, ups=1.33, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.546, loss_scale=8, train_wall=30, gb_free=15.1, wall=111
2022-03-14 07:23:09 | INFO | train_inner | epoch 002:    147 / 157 loss=9.306, ppl=632.83, wps=80708, ups=3.2, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.716, loss_scale=8, train_wall=31, gb_free=14.4, wall=142
2022-03-14 07:23:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:23:15 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-14 07:23:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:23:18 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the.
2022-03-14 07:23:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:23:23 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the.
2022-03-14 07:23:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:23:28 | INFO | fairseq.tasks.translation | example hypothesis: and and it,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:23:33 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:23:38 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:23:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:23:44 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:23:50 | INFO | fairseq.tasks.translation | example hypothesis: and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:23:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:23:57 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-14 07:23:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:23:59 | INFO | fairseq.tasks.translation | example hypothesis: and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:23:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.903 | ppl 478.85 | bleu 0.01 | wps 3658.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-14 07:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-14 07:23:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 2.0171561748720706 seconds)
2022-03-14 07:24:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 07:24:01 | INFO | train | epoch 002 | loss 9.447 | ppl 698.08 | wps 39823.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.646 | loss_scale 8 | train_wall 48 | gb_free 14.3 | wall 195
2022-03-14 07:24:02 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 07:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:24:30 | INFO | train_inner | epoch 003:     90 / 157 loss=8.915, ppl=482.69, wps=30327.4, ups=1.23, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.516, loss_scale=8, train_wall=30, gb_free=14.1, wall=223
2022-03-14 07:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example hypothesis: it's the the the the the the the the the the the the the.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example hypothesis: it's a to to to the the the the the the the.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:25:07 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's's's's's's's's a.
2022-03-14 07:25:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:25:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's's that that's's that it's that's's's's's's's's's to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-14 07:25:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:25:18 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the of the the the of the the the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the
2022-03-14 07:25:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:25:24 | INFO | fairseq.tasks.translation | example hypothesis: and it's, but it's's's to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to the the the the
2022-03-14 07:25:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:25:30 | INFO | fairseq.tasks.translation | example hypothesis: and we to to to to the the the the the the the the the the the the to to to to to to to to to to to to to the the the the the the the the the the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to the the the the the the the the the the the the the the the the the the the the of the the the
2022-03-14 07:25:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:25:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-14 07:25:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:25:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's a a a a a a a a a a a a, and the a a a a, and the a a a, and the a a a a a a a a a a, and the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-14 07:25:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:25:40 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.511 | ppl 364.88 | bleu 0.1 | wps 3566.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.1
2022-03-14 07:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-14 07:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:25:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.1) (writing took 1.829591769957915 seconds)
2022-03-14 07:25:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 07:25:42 | INFO | train | epoch 003 | loss 8.804 | ppl 446.87 | wps 39400.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.632 | loss_scale 8 | train_wall 48 | gb_free 14.1 | wall 296
2022-03-14 07:25:42 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 07:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:25:53 | INFO | train_inner | epoch 004:     33 / 157 loss=8.611, ppl=391.11, wps=30680.2, ups=1.21, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.738, loss_scale=8, train_wall=31, gb_free=14.3, wall=306
2022-03-14 07:26:24 | INFO | train_inner | epoch 004:    133 / 157 loss=8.327, ppl=321.19, wps=80927.1, ups=3.2, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.861, loss_scale=8, train_wall=31, gb_free=13, wall=338
2022-03-14 07:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:26:34 | INFO | fairseq.tasks.translation | example hypothesis: we're the world of the world.
2022-03-14 07:26:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world of the world is the world.
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:26:42 | INFO | fairseq.tasks.translation | example hypothesis: now, you're the world of the world.
2022-03-14 07:26:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world of the world, and there's a world.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:26:50 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not not not not not not not not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not that we have
2022-03-14 07:26:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:26:55 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world of the world, and the world of the world of the world.
2022-03-14 07:26:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:27:00 | INFO | fairseq.tasks.translation | example hypothesis: but it's the world of the world, but they're not not not not not not not not not not not not not not not not not not not not not not not not the world, but it.
2022-03-14 07:27:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:27:05 | INFO | fairseq.tasks.translation | example hypothesis: and we have to have the world of the world of the world, and we have the world of the world of the world, and we have the world, and we have the world of the world of the world of the world.
2022-03-14 07:27:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:27:12 | INFO | fairseq.tasks.translation | example hypothesis: it's a "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-14 07:27:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:27:14 | INFO | fairseq.tasks.translation | example hypothesis: so we have to be the world of the world of the world, and it's the world of the world of the world of the world, and it's the world of the world of the world of the world of the world of the world, and we've've've've've've've've've've've've've have to be be be be be to be be be be be be be be be be be be be be be be be be to be be be be be to be to be to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be be be be to be to be be be be be be be be be be to be to be be be be be to be to be to be be be be be be be be be be be be be be be be be be be be be be be be
2022-03-14 07:27:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:27:14 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.886 | ppl 236.61 | bleu 1.37 | wps 4110.7 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.37
2022-03-14 07:27:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-14 07:27:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.37) (writing took 1.8950279830023646 seconds)
2022-03-14 07:27:16 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 07:27:16 | INFO | train | epoch 004 | loss 8.335 | ppl 322.92 | wps 41809.1 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.82 | loss_scale 8 | train_wall 48 | gb_free 14.3 | wall 390
2022-03-14 07:27:17 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 07:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:27:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 07:27:40 | INFO | train_inner | epoch 005:     77 / 157 loss=8.03, ppl=261.32, wps=31895.9, ups=1.31, wpb=24439.7, bsz=968.2, num_updates=700, lr=8.75e-05, gnorm=2.109, loss_scale=4, train_wall=30, gb_free=15.5, wall=414
2022-03-14 07:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:28:09 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the future.
2022-03-14 07:28:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:28:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the time.
2022-03-14 07:28:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:28:16 | INFO | fairseq.tasks.translation | example hypothesis: now, we're going to go to be a new new new new year.
2022-03-14 07:28:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:28:20 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, there's going to be a lot of the world.
2022-03-14 07:28:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:28:23 | INFO | fairseq.tasks.translation | example hypothesis: and it's not a lot of what we're going to do that we're going to do it.
2022-03-14 07:28:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:28:27 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world of the world of the world, and the world in the world.
2022-03-14 07:28:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:28:31 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be a lot of the world, but they're going to be going to be a lot of the lot of the lot of the world.
2022-03-14 07:28:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:28:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to be a lot of the lot of the world, and we can see the world, and we're going to see the world, and we're going to see the world of the world of the world.
2022-03-14 07:28:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:28:42 | INFO | fairseq.tasks.translation | example hypothesis: and if if we're going to say, "you're going to say," it's a lot of the world, "you're going to say," it's going to say, "it's a lot of the world," "the world," it's a lot of the world, "it's a lot of the world," it's going to say, "it's going to say," it's going to be a lot of the world, "" and we're going to say, "it's going to say," it's a lot of the world. "" "" "
2022-03-14 07:28:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:28:44 | INFO | fairseq.tasks.translation | example hypothesis: but if we're going to be a lot of the world of the world, we're going to see the world, but we're going to be a lot of the world that we're going to see the world of the world of the world of the world of the world, but we're going to do that we're going to see the world of the world of the world of the world of the world, but we're going to see the world of the world of the world of the world of the world that we're going to do the world, but we're going to do the world of the world, but we're going to do that we're going to do that we're going to do the world, and we're going to do the world of the world that we're going to see the world of the world of the world of the world of the world of the world of the world of the world of the world, but we're going to do the world of the world of the world, but we're going to do the world, but
2022-03-14 07:28:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:28:44 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.41 | ppl 170.12 | bleu 1.87 | wps 4692 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.87
2022-03-14 07:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-14 07:28:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:28:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.87) (writing took 1.8733268359210342 seconds)
2022-03-14 07:28:46 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 07:28:46 | INFO | train | epoch 005 | loss 7.816 | ppl 225.39 | wps 43736.2 | ups 1.74 | wpb 25128.7 | bsz 1022.8 | num_updates 780 | lr 9.75e-05 | gnorm 1.844 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 480
2022-03-14 07:28:46 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 07:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:28:52 | INFO | train_inner | epoch 006:     20 / 157 loss=7.682, ppl=205.29, wps=35387.7, ups=1.39, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.814, loss_scale=4, train_wall=30, gb_free=13, wall=486
2022-03-14 07:29:23 | INFO | train_inner | epoch 006:    120 / 157 loss=7.4, ppl=168.84, wps=81329.5, ups=3.21, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.684, loss_scale=4, train_wall=31, gb_free=14.5, wall=517
2022-03-14 07:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:29:39 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the future.
2022-03-14 07:29:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most most most most most of the most most most most of the most of the most.
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:29:47 | INFO | fairseq.tasks.translation | example hypothesis: so these are new new new new new new new new new new new new new new new new new york.
2022-03-14 07:29:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:29:51 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of course, and it's a lot of the world.
2022-03-14 07:29:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:29:56 | INFO | fairseq.tasks.translation | example hypothesis: it's what it's not not, and it's not, we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do.
2022-03-14 07:29:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:30:01 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people, in the world, in the world, in the world.
2022-03-14 07:30:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:30:07 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be a lot of the same way, but you're going to go, but they're going to go, but they're going to be a lot of the same, but they're going to be a lot of the same, but it, but it, but they're going to be a lot of the same, but it
2022-03-14 07:30:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:30:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to be a lot of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see it, and we can see the world, and we can see it, we can see the world, we can see the world.
2022-03-14 07:30:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:30:20 | INFO | fairseq.tasks.translation | example hypothesis: "well," we said, "well," you know, "well," well, "well," you know, "well," well, "you know," well, "you know," you know, "well," it's no, "well," well, "you know," well, "you know," it's no, "it's going to say," well, "well," well, "well," "well," well, "it's the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first"
2022-03-14 07:30:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:30:22 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, we're going to be a lot of the world that we're going to be a lot of the world, and then we're going to be a lot of the most of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world.
2022-03-14 07:30:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:30:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.053 | ppl 132.77 | bleu 2.32 | wps 3768.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 2.32
2022-03-14 07:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-14 07:30:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:30:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 6 @ 937 updates, score 2.32) (writing took 2.021316624013707 seconds)
2022-03-14 07:30:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 07:30:24 | INFO | train | epoch 006 | loss 7.406 | ppl 169.64 | wps 40136.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.916 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 578
2022-03-14 07:30:24 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 07:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:30:44 | INFO | train_inner | epoch 007:     63 / 157 loss=7.161, ppl=143.14, wps=31189.1, ups=1.24, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.713, loss_scale=4, train_wall=30, gb_free=15.3, wall=598
2022-03-14 07:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:31:17 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the world.
2022-03-14 07:31:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:31:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most of the world.
2022-03-14 07:31:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:31:25 | INFO | fairseq.tasks.translation | example hypothesis: so, are new new new new new new new new new new new new york.
2022-03-14 07:31:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:31:29 | INFO | fairseq.tasks.translation | example hypothesis: so, for example, there's no example, where you're going to see, where you're going to see, where you're going.
2022-03-14 07:31:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:31:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not going to do that we're going to do it's going to be going to be going to be going to be going to be going to be going to be going to be going to do that.
2022-03-14 07:31:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:31:38 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, for the world, for the world, the world, for the world, the world, and it's a lot of the world.
2022-03-14 07:31:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:31:44 | INFO | fairseq.tasks.translation | example hypothesis: some are some of some of some of some of some of some of the world, but if you're going to see it, but they're going to get a lot of the world, but they're going to be able to be able to be able to be able to be able, but it, but they're going to be able to be able to
2022-03-14 07:31:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:31:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the world, we're going to see the world, and we can see that we can see that we can see that we can see the world, and can see the brain, and we can see the world.
2022-03-14 07:31:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:31:57 | INFO | fairseq.tasks.translation | example hypothesis: ::::: well, "well, it's a lot of the world," you know, "you know," well, "you know," you know, "well," well, "well," you know, "you know," you know, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "you know," well, "you know," you know, "well," well, "you know," you know, "well," well, "well," well, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "
2022-03-14 07:31:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:31:59 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's going to be a lot of the world, if we're going to be a lot of the world that we're going to be able to be able to be able to be a lot of the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-14 07:31:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:31:59 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.637 | ppl 99.5 | bleu 3.16 | wps 3829.5 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 3.16
2022-03-14 07:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-14 07:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:32:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 7 @ 1094 updates, score 3.16) (writing took 2.135993148200214 seconds)
2022-03-14 07:32:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 07:32:02 | INFO | train | epoch 007 | loss 7.005 | ppl 128.43 | wps 40511.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.591 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 675
2022-03-14 07:32:02 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 07:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:32:04 | INFO | train_inner | epoch 008:      6 / 157 loss=6.918, ppl=120.96, wps=31332.8, ups=1.25, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.642, loss_scale=4, train_wall=30, gb_free=14.8, wall=678
2022-03-14 07:32:35 | INFO | train_inner | epoch 008:    106 / 157 loss=6.651, ppl=100.5, wps=81915.5, ups=3.25, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.669, loss_scale=4, train_wall=30, gb_free=15.1, wall=709
2022-03-14 07:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:32:54 | INFO | fairseq.tasks.translation | example hypothesis: we put this.
2022-03-14 07:32:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most of the most most most most most most of the most most most most most most most.
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:33:02 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-14 07:33:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:33:06 | INFO | fairseq.tasks.translation | example hypothesis: for example.
2022-03-14 07:33:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:33:10 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know what we don't know, and we're going to see what's a few of what's going to do.
2022-03-14 07:33:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:33:15 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, like people like people for the people for the people for the people, for the people, for the people, and the most people in the most people in the most people, and the most people in the most people in the most people in the most people, and the people
2022-03-14 07:33:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:33:21 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of them, but if you're going to see it, but if you don't see it, but if you don't have a lot of the same way, but if you don't see it, but it's a lot of the same system, but it's not have a lot of the way, but it's
2022-03-14 07:33:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:33:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use these things that we can see this.
2022-03-14 07:33:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:33:34 | INFO | fairseq.tasks.translation | example hypothesis: yeah: the one of the first thing, and it's a lot of you know, "you know," well, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," well, "well," well, "you know," you know, "you know," you know, "well," well, "well," you know, "well," well, "you know," well, "well," well, "you know," you know, "well," you know, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know,"
2022-03-14 07:33:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:33:37 | INFO | fairseq.tasks.translation | example hypothesis: but then, the same thing is a lot of the world, and if we have a lot of the world, and if we have a lot of the world, and then we have a lot of the world that we have a lot of the world that we have a little little bit of the world that we have a lot of the world that we have been been been been been been been been been been been a new new new new new new system that we have a lot of the world that we have a lot of the world that we have a lot of us that we have a lot of the world, if we have a lot of the world, if we have a lot of the world, if we have a lot of the world that we have a lot of the world, if we have a lot of the world, and then we have a lot of the world, and then we have a lot of the world, if we have been been been been been been been been been been been been been been been been been been been been been been been been a
2022-03-14 07:33:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:33:37 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.319 | ppl 79.85 | bleu 4.5 | wps 3873.7 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 4.5
2022-03-14 07:33:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-14 07:33:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:33:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 8 @ 1251 updates, score 4.5) (writing took 1.9573857691138983 seconds)
2022-03-14 07:33:39 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 07:33:39 | INFO | train | epoch 008 | loss 6.678 | ppl 102.37 | wps 40726.2 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.587 | loss_scale 4 | train_wall 47 | gb_free 14 | wall 772
2022-03-14 07:33:39 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 07:33:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:33:54 | INFO | train_inner | epoch 009:     49 / 157 loss=6.549, ppl=93.65, wps=32227.7, ups=1.26, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.547, loss_scale=4, train_wall=30, gb_free=15.3, wall=788
2022-03-14 07:34:25 | INFO | train_inner | epoch 009:    149 / 157 loss=6.343, ppl=81.19, wps=80899.6, ups=3.26, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.556, loss_scale=4, train_wall=30, gb_free=14.7, wall=819
2022-03-14 07:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:34:31 | INFO | fairseq.tasks.translation | example hypothesis: we had this pppppon the end of the end.
2022-03-14 07:34:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:34:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of you know, most of most of most most of the most most most.
2022-03-14 07:34:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:34:40 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new york are two.
2022-03-14 07:34:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:34:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese, where they're going to go, where they're going to go, and they're going on.
2022-03-14 07:34:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:34:48 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few few on the number of his eyes, and what's going on.
2022-03-14 07:34:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:34:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like people for the people for the people for the people, and the number of people, and this is a number of people, and it's a lot of people.
2022-03-14 07:34:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:34:58 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are in the water, but if you don't see, but if you don't know, if you don't know, if you don't have the energy, and if you don't have the energy, it's the energy, it's the energy, and if you don't have the energy, and if you don't have
2022-03-14 07:34:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:35:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information of this, we can see that we can take a picture of the brain, and we can use the brain, and the brain, and we can take the brain, and all all the brain, and all the brain, and the brain, and we can use the brain, and the brain, and we can use of the brain, and the brain, and that's all all all all the brain, and the brain
2022-03-14 07:35:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:35:10 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reason it's interesting, and it's really interesting for me, "oh," you know, "oh," oh, "you know," you know, "you know," oh, "you know," oh, "oh," oh, "you know," oh, "oh," you know, "you know," oh, "you know," oh, "you know," oh, "oh," oh, "oh," you know, "oh," oh, "oh," you know, "oh," oh, "oh," you know, "oh," oh, "you know," you know, "you know," you know, "oh," oh, "you know," oh, "oh," oh, "oh," oh, "oh,"
2022-03-14 07:35:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:35:12 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still at the mother, and the time, if we have a lot of the system, if we had a little bit of the system that we had to have a new system, and then we had to do that there was a lot of the world, and then we have a little bit of the world that there was a new system that we had a little bit of the system that we had a new system that we had to do that we have a new system that we have a new system that we have a lot of the same system that we have to do that we had to be able system that we have to be able system that we have to do that we have to be a new system that we have to have a new system that we have to be able to have a little bit of the world, and then have to be able system that we had to be able to do that we had to be able to have to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:35:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:35:12 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.842 | ppl 57.36 | bleu 7.16 | wps 4004.8 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 7.16
2022-03-14 07:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-14 07:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:35:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 9 @ 1408 updates, score 7.16) (writing took 1.9814091369044036 seconds)
2022-03-14 07:35:14 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 07:35:14 | INFO | train | epoch 009 | loss 6.35 | ppl 81.55 | wps 41211.6 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.6 | loss_scale 4 | train_wall 47 | gb_free 15.1 | wall 868
2022-03-14 07:35:15 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 07:35:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:35:44 | INFO | train_inner | epoch 010:     92 / 157 loss=6.08, ppl=67.63, wps=31966, ups=1.27, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.509, loss_scale=4, train_wall=30, gb_free=14.7, wall=897
2022-03-14 07:36:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:36:07 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppppin the center.
2022-03-14 07:36:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:36:11 | INFO | fairseq.tasks.translation | example hypothesis: and that's the car of the ha, most most of most most most most of most most most of the most.
2022-03-14 07:36:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:36:15 | INFO | fairseq.tasks.translation | example hypothesis: these new york are going to take two new new new new new new york.
2022-03-14 07:36:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:36:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese, where it's going to get with ppppppppg.
2022-03-14 07:36:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:36:23 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few few few of his head, and what's going on.
2022-03-14 07:36:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:36:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamay of people like the most people for the number of the number, and the number of the number of the number of the number.
2022-03-14 07:36:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:36:32 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of the bbe, but in the surface, but if you're not able to do it, but if you need the same energy, if you need the energy, and if you need the energy, you need the energy, and the energy, you need the energy, and the energy, and if you need the energy.
2022-03-14 07:36:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:36:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information, we can use this structure, we can take a little bit of the brain, and we can use the brain, and we can use the structure of the structure of the brain, and the structure of the structure, and the structure, and the structure, and the structure of the structure, and the structure of the structure of the structure, and the structure of the structure of the structure, and the structure of the structure,
2022-03-14 07:36:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:36:44 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons that there's interesting and interesting, and interesting for me to do here here here is that i'm going to talk to you, who's a big talk about the first time, and then we've got to talk about how to you know, if you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, is that's a cco is that is that's a lot of this is that many of the parparparparparparo is that is that's a big, who's going to talk about that's a cccccccco is that's going to talk about that's going to talk about that's going to talk about this is, who's going to talk about that's a
2022-03-14 07:36:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:36:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, it's still still at the mother, and the big part of the work that we have a new work on our work, when we have a little bit of the world, and if we had to use a little bit of the same system, which is that we've got to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-14 07:36:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:36:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.503 | ppl 45.36 | bleu 9.24 | wps 4213.4 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 9.24
2022-03-14 07:36:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-14 07:36:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:36:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 10 @ 1565 updates, score 9.24) (writing took 1.8583447090350091 seconds)
2022-03-14 07:36:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 07:36:48 | INFO | train | epoch 010 | loss 5.974 | ppl 62.84 | wps 42252.3 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.497 | loss_scale 4 | train_wall 47 | gb_free 14.2 | wall 962
2022-03-14 07:36:48 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 07:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:36:59 | INFO | train_inner | epoch 011:     35 / 157 loss=5.864, ppl=58.23, wps=32839.2, ups=1.32, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.509, loss_scale=4, train_wall=30, gb_free=13.8, wall=973
2022-03-14 07:37:30 | INFO | train_inner | epoch 011:    135 / 157 loss=5.576, ppl=47.71, wps=82669.2, ups=3.24, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.514, loss_scale=4, train_wall=30, gb_free=13.7, wall=1004
2022-03-14 07:37:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:37:41 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppat the clinic.
2022-03-14 07:37:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:37:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the machine that most of most of most of most most of most of most of the most most.
2022-03-14 07:37:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:37:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new forces that will be used two new new forces.
2022-03-14 07:37:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:37:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french where they're going to be pow with your legs, and they're going to be able to get it.
2022-03-14 07:37:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:37:57 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we're not just just a couple of light on his head, and what's going to understand what's going on.
2022-03-14 07:37:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:38:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamase of people who grew up for the number of animals, and the number of animals, and that's actually a very important.
2022-03-14 07:38:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:38:05 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these are some files in the lines, but if you don't need it, it doesn't need your energy energy, and if you need your energy.
2022-03-14 07:38:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:38:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can see this reflection, we can start with a form of the web, and that's all the structure of the structure of the structure.
2022-03-14 07:38:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:38:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting to be able to be here for me, "oh," if you say, "you're going to say," you're going to say, "well," you're going to say, "you're going to say," you know, "well," well, "you're going to say," you're going to say, "well," you're going to say, "well," well, "well," well, "well," well, "well," well, "well," you're going to say, "well," well, "well," well, "well," you know, "you're going to say," you're going to say, "you know," you're going to say, "well," you're going to say, "you're
2022-03-14 07:38:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:38:16 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still the mother, and we had a lot of work at the world that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:38:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:38:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.245 | ppl 37.91 | bleu 11.63 | wps 4736.6 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 11.63
2022-03-14 07:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-14 07:38:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:38:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 11 @ 1722 updates, score 11.63) (writing took 2.0480002749245614 seconds)
2022-03-14 07:38:18 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 07:38:18 | INFO | train | epoch 011 | loss 5.65 | ppl 50.23 | wps 44003.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.524 | loss_scale 4 | train_wall 47 | gb_free 14.5 | wall 1051
2022-03-14 07:38:18 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 07:38:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:38:42 | INFO | train_inner | epoch 012:     78 / 157 loss=5.447, ppl=43.63, wps=34719.6, ups=1.39, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.424, loss_scale=4, train_wall=30, gb_free=14.4, wall=1076
2022-03-14 07:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:39:10 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the clinics.
2022-03-14 07:39:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:39:14 | INFO | fairseq.tasks.translation | example hypothesis: that's the key line of doha, most of most of most of most of the most.
2022-03-14 07:39:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:39:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new ored by the gulf.
2022-03-14 07:39:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:39:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese chinese food, where they're going to be on, and they're going to be on.
2022-03-14 07:39:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:39:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a couple of electrodes on his head on his head, and what's all the idea of your mind.
2022-03-14 07:39:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:39:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamace of people like the responsibility for the number of animals, the number of animals, and this is a number of coordination, and it has become a viiiiiiiiiiiiiiiiiiiiii
2022-03-14 07:39:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:39:35 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some bbble of the color in the lines, but it doesn't have to go, if you don't need the energy energy energy energy, and if you need your energy and the energy.
2022-03-14 07:39:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:39:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information from this information, we can be able to be able to be able to be able to start with a traditional source of the shape of the information, and you can start through the structure of information and the information.
2022-03-14 07:39:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:39:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for women -- that's the best time, if we said, "oh," oh, you know, you're going to say, "oh, if we're going to tell you know," you know, you're going to say, "oh, you're going to go to be working with you know," oh, "oh," oh, you're going to be in this word, "oh," you're going to be in this word, "oh," oh, "oh, you know," you're going to be in this word word, "oh," we're going to be in this word for you know, you're going to go to be in this word, "oh," oh, "oh, and you're working with you're working with a
2022-03-14 07:39:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:39:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still the mother of the invention, and a lot of work on the airplane that we had to solve our business, if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:39:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:39:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.848 | ppl 28.79 | bleu 12.69 | wps 4634.4 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 12.69
2022-03-14 07:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-14 07:39:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 12 @ 1879 updates, score 12.69) (writing took 2.007581651909277 seconds)
2022-03-14 07:39:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 07:39:48 | INFO | train | epoch 012 | loss 5.295 | ppl 39.26 | wps 43763.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.407 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1142
2022-03-14 07:39:48 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 07:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:39:55 | INFO | train_inner | epoch 013:     21 / 157 loss=5.164, ppl=35.86, wps=34601.4, ups=1.38, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.507, loss_scale=4, train_wall=30, gb_free=14.3, wall=1149
2022-03-14 07:40:26 | INFO | train_inner | epoch 013:    121 / 157 loss=5.039, ppl=32.88, wps=81394, ups=3.22, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.377, loss_scale=4, train_wall=31, gb_free=14, wall=1180
2022-03-14 07:40:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:40:41 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppills in the clinic.
2022-03-14 07:40:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:40:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, most of most of the most of here.
2022-03-14 07:40:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:40:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dindindindines that will be used to get two new york.
2022-03-14 07:40:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:40:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where they're going to do with pppace.
2022-03-14 07:40:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:40:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electroelectrodes on his head, and understand what all the thoughts are on his mind.
2022-03-14 07:40:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:41:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamace of people who grew up to the responsibility of the number of animals, again, and this is a conviiiiiiiibia.
2022-03-14 07:41:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:41:04 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of magnetic magnetic magnetic lines in the lines, but it doesn't have to move the alalalalalalalalty energy energy energy, and if you need their energy energy.
2022-03-14 07:41:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:41:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that reflection from this reflection, we can begin to be able to look at a traditional face, the big shape of the shape of the information, and all the structure of the information that's all the structure.
2022-03-14 07:41:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:41:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting for me to be here for tedtedwomen... "yes," oh, "someone's best to say," the best revolution of the best revolution, "the best revolution," and then the best revolution starts to tell you. "
2022-03-14 07:41:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:41:15 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a big design part of our work on the airplane, we had to solve a unique system that we had to solve all the problems of the problems that were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-14 07:41:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:41:15 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.616 | ppl 24.52 | bleu 14.34 | wps 4749.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 14.34
2022-03-14 07:41:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-14 07:41:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:41:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:41:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 13 @ 2036 updates, score 14.34) (writing took 2.0024361829273403 seconds)
2022-03-14 07:41:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 07:41:17 | INFO | train | epoch 013 | loss 5.016 | ppl 32.36 | wps 44167.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.424 | loss_scale 4 | train_wall 47 | gb_free 13.9 | wall 1231
2022-03-14 07:41:18 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 07:41:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:41:38 | INFO | train_inner | epoch 014:     64 / 157 loss=4.829, ppl=28.42, wps=34802.8, ups=1.39, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.323, loss_scale=4, train_wall=30, gb_free=14.4, wall=1251
2022-03-14 07:42:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:42:10 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-14 07:42:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:42:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, probably most of you know.
2022-03-14 07:42:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:42:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new forces.
2022-03-14 07:42:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:42:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where happy legs and sales are going to get rid of it.
2022-03-14 07:42:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:42:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electroelectroelectrodes on his head, and understand what all the thoughts are.
2022-03-14 07:42:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:42:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people who grew up for the responsibility, grew up to the number of animals, and it's become become a conservation for the epidemic.
2022-03-14 07:42:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:42:34 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magnetic magnetic lines in the lines, but it doesn't seem to move, if you need the energy, and you need to use the alalalable.
2022-03-14 07:42:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:42:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face of traditional face, the whole shape of the structure, and the whole structure of the structure.
2022-03-14 07:42:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:42:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and interesting for me here for tedwomen, "oh, when someone was going to say," if you're going to ask you, "and then you're going to support the table of the table," and then we've got to support you. "
2022-03-14 07:42:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:42:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention of the invention, and a big design that we had to solve the airplane, that we had to solve a unique system, and it had to solve all the power of the ground -- and it's all got to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if it.
2022-03-14 07:42:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:42:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.394 | ppl 21.02 | bleu 17.28 | wps 4807.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 17.28
2022-03-14 07:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-14 07:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:42:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:42:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 14 @ 2193 updates, score 17.28) (writing took 1.931879892013967 seconds)
2022-03-14 07:42:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 07:42:46 | INFO | train | epoch 014 | loss 4.648 | ppl 25.07 | wps 44496.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.245 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1320
2022-03-14 07:42:46 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 07:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:42:49 | INFO | train_inner | epoch 015:      7 / 157 loss=4.524, ppl=23, wps=35785.4, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.182, loss_scale=4, train_wall=30, gb_free=14.3, wall=1323
2022-03-14 07:43:20 | INFO | train_inner | epoch 015:    107 / 157 loss=4.371, ppl=20.69, wps=81388.5, ups=3.24, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.304, loss_scale=4, train_wall=30, gb_free=14.3, wall=1354
2022-03-14 07:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:43:39 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic.
2022-03-14 07:43:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:43:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-14 07:43:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:43:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to make two new revenue.
2022-03-14 07:43:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:43:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food, where happy legs and salt.
2022-03-14 07:43:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:43:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a couple of electrodes on his head and understand what all its thoughts are.
2022-03-14 07:43:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:43:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamapping of people like the responsibility for the survived, the number of animals grew up again, and this is a foundation for conservaiibia.
2022-03-14 07:43:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:44:03 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of magnetic magnetic lines are in the field, but the susule of the superconductor, if you don't have energy, you need to move your energy, and you need to move your energy.
2022-03-14 07:44:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:44:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional face, we can start able to begin with a traditional face of the face and remove through the information and reform of the information.
2022-03-14 07:44:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:44:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting to measure it, for me here for tedwomen, is that -- yes, when someone was going to say, "oh, somebody who said," if somebody's going to support you. "
2022-03-14 07:44:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:44:13 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big design part of the work on our airplane, we've had to solve a problem that we had to solve a unique deal with the problem that we had to solve it -- it's a unique deal with a reducing system, and make it all the energy system that if you're going to use it in the engine, you're going to use to use to be able to be able to use it to use the engine, you're able to use a little bit of a little bit of a little bit more efficient system, or make it in the engine, if you're able to use it, you're able to use it, you're going to use, or make it, you're able to use it, you're able to use it, you're able to use it, you're going to use it, you're going to use it, you're able to use it to use it to use it, you're able to use, you're able to use the car
2022-03-14 07:44:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:44:13 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.026 | ppl 16.29 | bleu 18.42 | wps 4759 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 18.42
2022-03-14 07:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-14 07:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 15 @ 2350 updates, score 18.42) (writing took 2.0922562298364937 seconds)
2022-03-14 07:44:16 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 07:44:16 | INFO | train | epoch 015 | loss 4.397 | ppl 21.07 | wps 44093.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.264 | loss_scale 4 | train_wall 47 | gb_free 14.2 | wall 1409
2022-03-14 07:44:16 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 07:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:44:32 | INFO | train_inner | epoch 016:     50 / 157 loss=4.374, ppl=20.73, wps=35279.6, ups=1.39, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.223, loss_scale=4, train_wall=30, gb_free=14.7, wall=1426
2022-03-14 07:45:02 | INFO | train_inner | epoch 016:    150 / 157 loss=4.066, ppl=16.75, wps=81006, ups=3.29, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.119, loss_scale=4, train_wall=30, gb_free=14.9, wall=1456
2022-03-14 07:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:45:09 | INFO | fairseq.tasks.translation | example hypothesis: we created these pills in the clinic clinic.
2022-03-14 07:45:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:45:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-14 07:45:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:45:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golgolsticks.
2022-03-14 07:45:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:45:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where happy legs are and fat.
2022-03-14 07:45:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:45:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understanding what all its thoughts are on the mind.
2022-03-14 07:45:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:45:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamature of the responsibility for the wild animals, the number of animals. and this is a foundation for conservation protection.
2022-03-14 07:45:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:45:31 | INFO | fairseq.tasks.translation | example hypothesis: first of magnetic fields in the inner lines, but the sulength of superconductor, if you don't need your energy, you need energy, and you need your energy energy, and so that you don't need your energy.
2022-03-14 07:45:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:45:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face of traditional face, which is the big face of the face and the shape of the face of the face of the face of the face, and we can start able to fold it through it through the information, and then we're able to fold it through the information and the information that's all the structure of the structure of the structure of the structure.
2022-03-14 07:45:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:45:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure me for tedsters. "
2022-03-14 07:45:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:45:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention and a big part of the design work on our airplane, we have a result of the plane that we've had to solve is that we had to solve is that we had to solve is that we had to solve the problem of these are unique problems that we had to be connected to solve, so that it was available to be connected to be connected to a lot of energy system.
2022-03-14 07:45:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:45:42 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.973 | ppl 15.71 | bleu 16.59 | wps 4966 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 18.42
2022-03-14 07:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-14 07:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 16 @ 2507 updates, score 16.59) (writing took 0.9275495959445834 seconds)
2022-03-14 07:45:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 07:45:43 | INFO | train | epoch 016 | loss 4.134 | ppl 17.56 | wps 45344.5 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.191 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1497
2022-03-14 07:45:43 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 07:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:46:12 | INFO | train_inner | epoch 017:     93 / 157 loss=3.974, ppl=15.72, wps=36179.1, ups=1.43, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.204, loss_scale=4, train_wall=30, gb_free=15.3, wall=1526
2022-03-14 07:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic on the clinic.
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:46:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most familiar here here.
2022-03-14 07:46:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to make two new pigs.
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:46:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where frog legs are filled with salz and fat.
2022-03-14 07:46:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:46:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all its thoughts are on the top.
2022-03-14 07:46:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:46:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of the people like the responsibility for the wildlife, the number of wild animals, and this is a foundation for conservation in namibia.
2022-03-14 07:46:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:47:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, there are some bloodl of magnetic lines, but the sususulalalty, not if you're moving there, you need energy, and so the sulength of magnetic fields.
2022-03-14 07:47:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:47:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of a traditional face, which is the big constructions and the shape of the information, and through that whole structure, and all the structure, and all the structure of the structure, and all the structure of the structure, we can fold up with a structure, we can start with a structure, we can begin to fold up with a whole structure, we can
2022-03-14 07:47:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:47:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure me here for tedwomen, "is that..."
2022-03-14 07:47:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:47:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of design work on our plane, we're on the plane, a result that we had to solve the unique problems that were connected to the ground -- everything that we were connected to the ground -- everything that you're able to use a continuous system, and if you're able to be able to use the propelled, if you're able to see, if you're able to be able to be able to be able to use the propelled to use the propelled, or a very specific, if you're able to be able to see, if you're able to see that you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, if you're able to be able to be able to be able to see, if you're able to be able to be able to be able to be able to see,
2022-03-14 07:47:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:47:15 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.713 | ppl 13.11 | bleu 19.9 | wps 4181.7 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.9
2022-03-14 07:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-14 07:47:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:47:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:47:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.9) (writing took 1.9094634191133082 seconds)
2022-03-14 07:47:17 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 07:47:17 | INFO | train | epoch 017 | loss 3.946 | ppl 15.41 | wps 41963.3 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.167 | loss_scale 4 | train_wall 47 | gb_free 14.1 | wall 1591
2022-03-14 07:47:17 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 07:47:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:47:29 | INFO | train_inner | epoch 018:     36 / 157 loss=3.877, ppl=14.69, wps=33067.9, ups=1.31, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.16, loss_scale=4, train_wall=30, gb_free=14.7, wall=1602
2022-03-14 07:47:59 | INFO | train_inner | epoch 018:    136 / 157 loss=3.708, ppl=13.07, wps=80794.7, ups=3.25, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.044, loss_scale=4, train_wall=30, gb_free=14.5, wall=1633
2022-03-14 07:48:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:48:10 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-14 07:48:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:48:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line from doha who probably know most of you here.
2022-03-14 07:48:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:48:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dindines that are going to be the two new pigs.
2022-03-14 07:48:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:48:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are being served with salz and fat.
2022-03-14 07:48:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:48:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-14 07:48:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:48:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mastery like the people's responsibility for the wild, the number of wild animals grew up again, and this is a foundation for conservation protection in namibia.
2022-03-14 07:48:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:48:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bumber of magnetic fields in the inner field, but the superconductor doesn't like the superconductor, if you don't want to move your energy movements, your energy movements, and the superconductor.
2022-03-14 07:48:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:48:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face, which is the big configuration of the face and the shape of the fundamental constructions, and the shape of this information, and then we can fold it through the entire information, and all the structure.
2022-03-14 07:48:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:48:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to be here for me here for tedwomen, is that we've been talking about "silly," and then we've been talking about, "oh," well, if you're working on the piano, "that's a silent story," we're working with you're working with silent, "and then you know," if you're going to have a silent, "if you're going to help you know, you're going to have a silent, you're going to help you know, you're going to have a silly," -- you know, you're going to be a silly, "-- you know, you're going to be a silent," and then you know, you know, you're going to have a long time, you're going to have a silent
2022-03-14 07:48:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:48:46 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother's invention, and a big part of the design work that we're using in the plane, and we're a result that we had to solve is that we had to solve a result of the unique problems that we had to solve the unique problems that we had to solve it was connected to the ground -- everything everything is a continuous variable system, and it would be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do anything anything that if you, or a flocked in the air air air, or the air, or a very much more expensive, if you,
2022-03-14 07:48:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:48:46 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.476 | ppl 11.13 | bleu 23.74 | wps 4463 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 23.74
2022-03-14 07:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-14 07:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 18 @ 2821 updates, score 23.74) (writing took 1.8744817900005728 seconds)
2022-03-14 07:48:48 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 07:48:48 | INFO | train | epoch 018 | loss 3.722 | ppl 13.2 | wps 43196.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.046 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1682
2022-03-14 07:48:49 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 07:48:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:49:13 | INFO | train_inner | epoch 019:     79 / 157 loss=3.607, ppl=12.18, wps=34588.5, ups=1.35, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.989, loss_scale=4, train_wall=31, gb_free=14.3, wall=1707
2022-03-14 07:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:49:41 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-14 07:49:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:49:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-14 07:49:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:49:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golgoldicks that create the two new pigs.
2022-03-14 07:49:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:49:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are salt with salz and fat.
2022-03-14 07:49:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:49:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 07:49:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:50:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people who had responsibility for wildlife, grew up the number of wildlife animals again, and this is a foundation for conservation in namibia.
2022-03-14 07:50:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:50:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, there are some bloop of magnetic fields in the inside the inner lines, but the susuconductor doesn't like if they need energy, and so the supersuperconductor.
2022-03-14 07:50:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:50:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face and the basic shape of information, which is the whole information that we can fold and fold the whole structure of this reflection, and all the structure of this reflection, and we can fold a shape.
2022-03-14 07:50:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:50:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's extremely interesting and measured, for me to be here at tedwomen, then we have sex, and then we said, "you know," the men, "and if you say," you know, "the men and then you say," then you know, "that we have sex sex sex sex," "we have sex sex sex," "" "" then we have sex sex sex sex sex sex sex, "" "" "" "" "then we have sex sex sex sex," "" "" then we have sex sex sex sex sex sex sex sex sex, "
2022-03-14 07:50:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:50:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we have had to solve is that we had to solve the unique problems on the ground -- all of us had to deal with a continuous system, and a big part of the continually scale, and a big part of the current system, which is that allows us to be able to be able to navigate the propheartwork, that we can be able to be able to monitoring, or the propheartwork, or the motor motor motor motor motor motor motor motor system, which is that we can be able to be able to be able to monitoring, or to be able to monitoring, or the motor motor motor motor motor motor motor motor motor motor motor system, which is that we can be a system, or the current current current current current current current current current problems, or a system, or a system, and to be able to be able to be able to monitoring us, if you will be able to make us
2022-03-14 07:50:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:50:16 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.46 | ppl 11 | bleu 22.95 | wps 4705.7 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 23.74
2022-03-14 07:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-14 07:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 19 @ 2978 updates, score 22.95) (writing took 0.9203455650713295 seconds)
2022-03-14 07:50:17 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 07:50:17 | INFO | train | epoch 019 | loss 3.537 | ppl 11.61 | wps 44692.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.014 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1770
2022-03-14 07:50:17 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 07:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:50:24 | INFO | train_inner | epoch 020:     22 / 157 loss=3.455, ppl=10.97, wps=35134.7, ups=1.42, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.994, loss_scale=4, train_wall=30, gb_free=15.1, wall=1778
2022-03-14 07:50:55 | INFO | train_inner | epoch 020:    122 / 157 loss=3.34, ppl=10.13, wps=82554.2, ups=3.19, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.822, loss_scale=4, train_wall=31, gb_free=14.1, wall=1809
2022-03-14 07:51:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:51:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-14 07:51:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:51:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-14 07:51:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:51:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dinners that are going to get rid of two new pigs.
2022-03-14 07:51:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:51:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salsalz and pbump.
2022-03-14 07:51:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:51:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 07:51:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:51:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for wildlife, the number of wildlife animals grew again again, and that's a foundation for conservation in namibia.
2022-03-14 07:51:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:51:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bumber of magnetic field lines are caught in the inside of the inside, but the superconductor doesn't like if they're moving, because their movements need energy, and so the superconducting disorders.
2022-03-14 07:51:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:51:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big configurations of the face and rerepeat it through the basic shape, and through the basic shape of the information that makes the whole portion and all the shape.
2022-03-14 07:51:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:51:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measuring it interesting and measuring it interesting to be here for me here at tedwomen is that... "yes, when you put it on the best dinner, when somebody said," look at men in a table, and say, "if you're going to support the revolution here at tedtedwomen here," that's the truth is that we've got a long time, "oh," oh, and then we've got a piano piano for the piano piano piano piano piano piano piano piano piano piano piano piano, "we've been summarks up until we've got a piano piano piano piano piano, and then we've got a piano piano piano piano piano piano piano piano piano piano piano piano, and then we've been summarily, and then we've been summarily, and then we've been summarily,
2022-03-14 07:51:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:51:45 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work that we are at our airplane at the top of the smartest test, a result that we had to solve the unique problems that were connected to surgery -- everything from a continuing to a continent and a very large part of the design design design framework that we're going to see in the airplane, until we're going to be able to solve the aircraft aircraft, or the aircraft aircraft, if you're going to solve a particular flight, or the aircraft, or the aircraft is that we had to be able to be able to solve the engine is that we had to be able to be able to be able to solve the aircraft it's a particular aircraft it's a very unique problem with a very unique problem with a particular flight, or the aircraft, it is that we had to solve the aircraft that we had to be able to solve the aircraft that we had to be able to be able to solve the aircraft,
2022-03-14 07:51:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:51:45 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.277 | ppl 9.69 | bleu 25.47 | wps 4573.1 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 25.47
2022-03-14 07:51:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-14 07:51:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:51:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 20 @ 3135 updates, score 25.47) (writing took 1.8812232371419668 seconds)
2022-03-14 07:51:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 07:51:47 | INFO | train | epoch 020 | loss 3.342 | ppl 10.14 | wps 43687 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.902 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 1861
2022-03-14 07:51:47 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 07:51:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:52:08 | INFO | train_inner | epoch 021:     65 / 157 loss=3.253, ppl=9.53, wps=34359.7, ups=1.38, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.999, loss_scale=4, train_wall=30, gb_free=14.3, wall=1882
2022-03-14 07:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:52:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-14 07:52:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:52:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha, most of you know.
2022-03-14 07:52:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:52:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to generate new goldicks.
2022-03-14 07:52:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:52:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where frog legs are served with salsalz.
2022-03-14 07:52:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:52:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what's going on.
2022-03-14 07:52:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:53:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, as people took responsibility for wildlife, the number of wildlife animals again grew back again, and this is a foundation for conservation in namibia.
2022-03-14 07:53:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:53:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are caught in inside the inside, but the superconductor doesn't like it, if you move your energy, and so the superconductor.
2022-03-14 07:53:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:53:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face and the basic shape, and we restore it through the brain, and through the rest of it, which is the whole structure and fold it.
2022-03-14 07:53:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:53:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's extremely interesting and measured and measured to be here for me at tedwomen, is that... well, when you were the best dinner, as someone said, "turning you to your men on your table and tell you," if you're going to help you, you, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, "
2022-03-14 07:53:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:53:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane, was a result that we had to solve the unique problems so that it was connected to the ground -- everything from a continual system, and it allows us to be able to be able to make a refrigerator, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get the
2022-03-14 07:53:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:53:15 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.16 | ppl 8.94 | bleu 26.33 | wps 4661.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 26.33
2022-03-14 07:53:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-14 07:53:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 21 @ 3292 updates, score 26.33) (writing took 2.1648784670978785 seconds)
2022-03-14 07:53:18 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 07:53:18 | INFO | train | epoch 021 | loss 3.245 | ppl 9.48 | wps 43557.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.932 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 1951
2022-03-14 07:53:18 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 07:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:53:21 | INFO | train_inner | epoch 022:      8 / 157 loss=3.265, ppl=9.61, wps=33977.9, ups=1.37, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.915, loss_scale=4, train_wall=30, gb_free=14.3, wall=1954
2022-03-14 07:53:51 | INFO | train_inner | epoch 022:    108 / 157 loss=3.164, ppl=8.97, wps=79958.2, ups=3.24, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.925, loss_scale=4, train_wall=30, gb_free=14.2, wall=1985
2022-03-14 07:54:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:54:11 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepter in the clinic.
2022-03-14 07:54:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:54:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha, probably most of you know here.
2022-03-14 07:54:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:54:18 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldicks.
2022-03-14 07:54:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:54:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pcase.
2022-03-14 07:54:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:54:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 07:54:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:54:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wildlife animals grew again, and this is a foundation for conservation in namibia.
2022-03-14 07:54:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:54:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines are caught inside, but the superconductor doesn't like if they're moving, because their movements need energy, and so the superconducting disorder.
2022-03-14 07:54:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:54:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face, and the basic shape of the face and the basic shape, and restoring it through the diethresses of information that can fold the entire portion of information that can fold the entire portion.
2022-03-14 07:54:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:54:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting to be, for me here at tedwomen is that... well, when you're talking about, "silly."
2022-03-14 07:54:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:54:43 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of design work that we're on our airplane, and we're going to be able to use a fluid, or if you had to solve the unique trajectory.
2022-03-14 07:54:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:54:43 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.162 | ppl 8.95 | bleu 25.07 | wps 5027.2 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 26.33
2022-03-14 07:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-14 07:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 22 @ 3449 updates, score 25.07) (writing took 0.9352963040582836 seconds)
2022-03-14 07:54:44 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 07:54:44 | INFO | train | epoch 022 | loss 3.136 | ppl 8.79 | wps 45606.2 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.881 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 2038
2022-03-14 07:54:45 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 07:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:55:01 | INFO | train_inner | epoch 023:     51 / 157 loss=3.072, ppl=8.41, wps=36888.2, ups=1.45, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.77, loss_scale=4, train_wall=30, gb_free=14.2, wall=2054
2022-03-14 07:55:31 | INFO | train_inner | epoch 023:    151 / 157 loss=2.949, ppl=7.72, wps=82629.1, ups=3.25, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.842, loss_scale=4, train_wall=30, gb_free=14.2, wall=2085
2022-03-14 07:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:55:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-14 07:55:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:55:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you.
2022-03-14 07:55:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:55:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create the two new pigs.
2022-03-14 07:55:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:55:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and phalt.
2022-03-14 07:55:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:55:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:55:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:55:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation for conservation in the maibia.
2022-03-14 07:55:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:56:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are caught inside, but the superconductor may not be if they're moving, because their energy uses its energy, and so the superconducting disorder.
2022-03-14 07:56:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:56:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big configurations of the face and the basic shape of the face of the face and the basic shape of the face of the face of the face of the face of the face of the face of the face of the face of the face, and restoring it through the ground.
2022-03-14 07:56:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:56:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured to me here, is that women have been working on this talk, "well, when they were the first dinner dinner dinner dinner, when somebody said," turn you to the men on your table and say, "turn you to the men on your table."
2022-03-14 07:56:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:56:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that we had to deal with with, so that we have to operate on the ground -- everything from the ground -- everything from a continuous variation, and a large part of the recycling system that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:56:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:56:12 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.065 | ppl 8.37 | bleu 26.79 | wps 4643 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.79
2022-03-14 07:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-14 07:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:56:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:56:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.79) (writing took 1.9556752969510853 seconds)
2022-03-14 07:56:14 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 07:56:14 | INFO | train | epoch 023 | loss 2.987 | ppl 7.93 | wps 43949.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.809 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2128
2022-03-14 07:56:14 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 07:56:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:56:44 | INFO | train_inner | epoch 024:     94 / 157 loss=2.927, ppl=7.61, wps=34477.2, ups=1.38, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.818, loss_scale=4, train_wall=30, gb_free=14.2, wall=2157
2022-03-14 07:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:57:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietars into the clinic clinic clinics.
2022-03-14 07:57:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:57:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably most familiar here.
2022-03-14 07:57:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:57:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-14 07:57:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:57:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ppepper.
2022-03-14 07:57:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:57:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what they're all thinking on the track.
2022-03-14 07:57:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:57:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of people like responsibility for wildlife, the number of wildlife animals grew again, and that's a foundation for conservation in namibia.
2022-03-14 07:57:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:57:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic fields are caught inside the inside, but the superconductor may not like you, because your energy uses, and so the superconducting disorders.
2022-03-14 07:57:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:57:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar, which is the big configurations of the face and the basic shape, and then restoring it through the information that pulls the whole portion structure and all the fits.
2022-03-14 07:57:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:57:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's going to be highly interesting and measured to me here at tedwomen is that... tum, when he was best summarized when someone said, "turn on the men on a table and tell you," if the revolution starts to support you. "the truth is that there's a long quarter," silent for sandstein and the moon moon, "silver and then we've been working on the moon."
2022-03-14 07:57:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:57:41 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're at our airplane at the stump, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continually variable and cooling system to the air, to the freestine, to the aircraft, to the aircraft, to the airplanes, or the air conditioning to a state, if you can see the airplanes, if you could either be able space, if you can actually be able space, if you can see the airplanes, if you wanted to the airplanes, if you wanted to the airplanes, if you wanted to the airplanes, if you can actually be able to the airplanes in the airplanes, if you can actually be able to the market, or the airplanes, if you can actually be able, if you can see the market, if you can see the airplanes, if you can actually be able to the market, if you can
2022-03-14 07:57:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:57:41 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.921 | ppl 7.57 | bleu 28.02 | wps 4823.7 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 28.02
2022-03-14 07:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-14 07:57:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 07:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 24 @ 3763 updates, score 28.02) (writing took 1.940516937058419 seconds)
2022-03-14 07:57:43 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 07:57:43 | INFO | train | epoch 024 | loss 2.899 | ppl 7.46 | wps 44437.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.775 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2217
2022-03-14 07:57:43 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 07:57:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:57:55 | INFO | train_inner | epoch 025:     37 / 157 loss=2.806, ppl=6.99, wps=35729.7, ups=1.4, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.708, loss_scale=4, train_wall=30, gb_free=14.4, wall=2229
2022-03-14 07:58:26 | INFO | train_inner | epoch 025:    137 / 157 loss=2.885, ppl=7.39, wps=80866.1, ups=3.23, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.834, loss_scale=4, train_wall=31, gb_free=14.3, wall=2260
2022-03-14 07:58:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:58:36 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepter in the clinic.
2022-03-14 07:58:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:58:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks.
2022-03-14 07:58:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:58:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pffer.
2022-03-14 07:58:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:58:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on track.
2022-03-14 07:58:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:58:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for wildlife survival, the number of wildwildwildlife animals grew again. and that's a foundation for conservation in namibia.
2022-03-14 07:58:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:58:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught inside, but the superconductor doesn't like you move because your movements need energy, and so the superconducting disorder.
2022-03-14 07:58:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:59:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with traditional facial constructions of face and the basic shape, and then restoring it through the dietrash information that pulls the whole porter structure and all the fits.
2022-03-14 07:59:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:59:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured to me here at tedwomen is that — well, when dinner was best summarized when someone said, "turn on the men on a table and tell you," if revolution starts supporting you. "
2022-03-14 07:59:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:59:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on aircraft, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variable route to a refrigeration device that allows us to be able to use a refrigerator or a particular device that allows us to be able to see if you're going to be able to see the vehicle.
2022-03-14 07:59:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:59:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.022 | ppl 8.12 | bleu 25.43 | wps 5048.9 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.02
2022-03-14 07:59:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-14 07:59:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 07:59:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 25 @ 3920 updates, score 25.43) (writing took 0.8945060248952359 seconds)
2022-03-14 07:59:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 07:59:09 | INFO | train | epoch 025 | loss 2.835 | ppl 7.14 | wps 45911.8 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.798 | loss_scale 4 | train_wall 47 | gb_free 15 | wall 2303
2022-03-14 07:59:09 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 07:59:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:59:34 | INFO | train_inner | epoch 026:     80 / 157 loss=2.724, ppl=6.61, wps=37151.3, ups=1.46, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.724, loss_scale=4, train_wall=30, gb_free=14.3, wall=2328
2022-03-14 07:59:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:00:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietters in the clinic.
2022-03-14 08:00:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:00:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you here know.
2022-03-14 08:00:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:00:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldilocks that are going to cross two new pigs.
2022-03-14 08:00:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:00:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-14 08:00:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:00:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:00:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:00:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew up again, and this is a foundation for conservation in namibia.
2022-03-14 08:00:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:00:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it, if you move, because your movements need energy, and so the superconducting disorders.
2022-03-14 08:00:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:00:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face that repeats the big constructions of the face and the basic shape, and put it through the themes of information that contains the whole portion structure and all the fits.
2022-03-14 08:00:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:00:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... well, when he was best summarized, when someone said, "turn to the men on a table, and they say," if the revolution starts to support you, "the truth is that we have been supported to you for you for a long time."
2022-03-14 08:00:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:00:37 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're at our airplane at the stagent, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous version of refrigerating system, that allows us to use a refrigeration machine, and we're going to be used to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be solved
2022-03-14 08:00:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:00:37 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.78 | ppl 6.87 | bleu 29.81 | wps 4701.5 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.81
2022-03-14 08:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-14 08:00:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:00:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.81) (writing took 1.8939010379835963 seconds)
2022-03-14 08:00:39 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 08:00:39 | INFO | train | epoch 026 | loss 2.716 | ppl 6.57 | wps 43975.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.717 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2393
2022-03-14 08:00:39 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 08:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:00:47 | INFO | train_inner | epoch 027:     23 / 157 loss=2.658, ppl=6.31, wps=34529.5, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.7, loss_scale=4, train_wall=30, gb_free=15.2, wall=2401
2022-03-14 08:01:17 | INFO | train_inner | epoch 027:    123 / 157 loss=2.672, ppl=6.37, wps=81264.8, ups=3.25, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.724, loss_scale=4, train_wall=30, gb_free=14, wall=2431
2022-03-14 08:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:01:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 08:01:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:01:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-14 08:01:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:01:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-14 08:01:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:01:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog is served with salz and psuitcase.
2022-03-14 08:01:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:01:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:01:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:01:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew again, and this is a foundation for conservation in namibia.
2022-03-14 08:01:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:01:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught inside, but the superconductor doesn't like it if they're moving, because their energy moves, and so the superconducting disorder.
2022-03-14 08:01:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:01:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection of reflection, we can start with a traditional facial, which resembles the big constellations of the face and the basic shape, and through the one of the information that uses the whole porter structure and all the fits.
2022-03-14 08:01:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:02:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's going to be highly interesting and appropriate to me here at tedwomen is that... well, when he was best summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "the truth is that we support you're already supporting you."
2022-03-14 08:02:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:02:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at airplanes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable drive and a cooling system that allows us to use a refrigerator to use aircraft.
2022-03-14 08:02:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:02:04 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.74 | ppl 6.68 | bleu 29.23 | wps 5099.9 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.81
2022-03-14 08:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-14 08:02:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.23) (writing took 0.8766625979915261 seconds)
2022-03-14 08:02:05 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 08:02:05 | INFO | train | epoch 027 | loss 2.633 | ppl 6.2 | wps 46010.8 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.698 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2478
2022-03-14 08:02:05 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 08:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:02:26 | INFO | train_inner | epoch 028:     66 / 157 loss=2.573, ppl=5.95, wps=36571.3, ups=1.47, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.685, loss_scale=4, train_wall=30, gb_free=15.1, wall=2499
2022-03-14 08:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:02:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers on the clinic.
2022-03-14 08:02:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:03:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-14 08:03:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:03:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-14 08:03:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:03:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pills.
2022-03-14 08:03:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:03:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:03:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:03:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-14 08:03:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:03:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bamongst magnetic field lines are trapped inside, but the superconductor doesn't like it, if they move, because their energy will use, and so the superconducting disorders.
2022-03-14 08:03:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:03:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial that refers the big constructions of the face and the basic shape, and recontains it through the dietrasy structure and all the folds.
2022-03-14 08:03:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:03:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's going to be highly interesting and appropriate to me here at tedwomen is that -- well, when you were striking dinner, it's best summarized when someone said, "turn you to the men on your desk and tell you," if the revolution starts to support you. "the truth is that we've already supported you for a long period of sand spellers."
2022-03-14 08:03:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:03:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane on the crust, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a system of refrigerators that allows us to use a refrigerator in the aircraft, if you can either use the aircraft, or the air conditioning, if you can use the bumps that you can use the drill the aircraft, if you can use the bug, you can use the bug, the aircraft, or the burefrigerator of a specific device, if you can use the burefrigerator, the fly, you can either run the burefrigerator, you can use the fly, you can use the car conditioning, or the aircraft, if you can use it's drill you can use the aircraft, if you can use the aircraft, the
2022-03-14 08:03:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:03:32 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.711 | ppl 6.55 | bleu 30.17 | wps 4748.6 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.17
2022-03-14 08:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-14 08:03:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.17) (writing took 1.8694389669690281 seconds)
2022-03-14 08:03:34 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 08:03:34 | INFO | train | epoch 028 | loss 2.578 | ppl 5.97 | wps 44127.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.724 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 2568
2022-03-14 08:03:34 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 08:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:03:37 | INFO | train_inner | epoch 029:      9 / 157 loss=2.613, ppl=6.12, wps=35138.1, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.771, loss_scale=4, train_wall=30, gb_free=14, wall=2571
2022-03-14 08:04:08 | INFO | train_inner | epoch 029:    109 / 157 loss=2.484, ppl=5.59, wps=80851.9, ups=3.22, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.66, loss_scale=4, train_wall=31, gb_free=14, wall=2602
2022-03-14 08:04:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:04:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters up in the clinic.
2022-03-14 08:04:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:04:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-14 08:04:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:04:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and ppepper.
2022-03-14 08:04:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:04:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what everybody's thinking about the track.
2022-03-14 08:04:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:04:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildwildwildwildwildlife grew again, and that's become a basis for conservation in namibia.
2022-03-14 08:04:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:04:50 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like to move because their energy will use, and so the superconductor disorder.
2022-03-14 08:04:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:04:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that refers the big constructions of the face and the fundamental shape, and the theastern information that refers all the porting structure and all the folds.
2022-03-14 08:04:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:04:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when he was best summarized when someone said, "turn to men to ddesk and tell them," if revolution starts supporting you. "the truth is that we already supported you for a long time, we've been supported by silver sands."
2022-03-14 08:04:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:05:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system that allows us to stop aircraft traffic, or if you can see the tractors, if you can either go to the reliance, or if you can see the promotors.
2022-03-14 08:05:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:05:00 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.67 | ppl 6.37 | bleu 30.48 | wps 4931.1 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.48
2022-03-14 08:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-14 08:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.48) (writing took 1.892755444161594 seconds)
2022-03-14 08:05:02 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 08:05:02 | INFO | train | epoch 029 | loss 2.473 | ppl 5.55 | wps 44933.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.65 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2656
2022-03-14 08:05:02 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 08:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:05:19 | INFO | train_inner | epoch 030:     52 / 157 loss=2.437, ppl=5.41, wps=35623.4, ups=1.42, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.635, loss_scale=4, train_wall=30, gb_free=14.3, wall=2673
2022-03-14 08:05:50 | INFO | train_inner | epoch 030:    152 / 157 loss=2.392, ppl=5.25, wps=82037.8, ups=3.24, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.593, loss_scale=4, train_wall=30, gb_free=15.1, wall=2703
2022-03-14 08:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:05:55 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 08:05:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:05:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:05:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in the dinments that will generate two new pigs.
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:06:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salt and ppepper.
2022-03-14 08:06:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:06:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what they're all thinking on track.
2022-03-14 08:06:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:06:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife survivors grew again, and that's a basis for conservation in namibia.
2022-03-14 08:06:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:06:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconducting.
2022-03-14 08:06:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:06:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that retains the big constructures of the face and the basic shape, and through the one of the information that refers all the porting structure and all the folds.
2022-03-14 08:06:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:06:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, in the most strictly dinner, when someone said, "turn you to the men on your table," when the revolution starts to support you, "the truth is that we've already been supporting you for a long time."
2022-03-14 08:06:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:06:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work we're at our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a system of refrigeration, which allows us to use aircraft, until a particular device, or if you can see the aircraft, you can either run the aircraft, or when you can see the aircraft, you can see the aircraft, you can see the aircraft, or if you can either run it in a car station, or when you can see the aircraft, then you can see the aircraft, you can use it, you can see the vehicle, or when you can see the aircraft, or when you can use it, you can use it, then you can see the aircraft, you can see the aircraft, or when you can use it, you can see the aircraft, you can use it, or when you can use it,
2022-03-14 08:06:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:06:28 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.615 | ppl 6.13 | bleu 30.99 | wps 4926.5 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.99
2022-03-14 08:06:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-14 08:06:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:06:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.99) (writing took 1.9128177789971232 seconds)
2022-03-14 08:06:30 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 08:06:30 | INFO | train | epoch 030 | loss 2.399 | ppl 5.27 | wps 44801.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.621 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2744
2022-03-14 08:06:30 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 08:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:07:00 | INFO | train_inner | epoch 031:     95 / 157 loss=2.39, ppl=5.24, wps=36087.6, ups=1.41, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.691, loss_scale=4, train_wall=31, gb_free=14, wall=2774
2022-03-14 08:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:07:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 08:07:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:07:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you here.
2022-03-14 08:07:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:07:31 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will have two new gay headlines.
2022-03-14 08:07:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:07:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and ppepper.
2022-03-14 08:07:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:07:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:07:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:07:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-14 08:07:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:07:47 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside inside, but the superconductors don't like it if they move, because their movements use energy, and so the superconducting.
2022-03-14 08:07:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:07:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that resembles the big constraints of the face and restoring it through the one that pulls the entire portion structure and all the fits.
2022-03-14 08:07:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:07:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it highly interesting and appropriate to me here at tedwomen is that... tja, when you're very best summarized when someone said, "turn you to your men on your table and say," if the revolution begins, "the truth is that we have been supporting you for a long time."
2022-03-14 08:07:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:07:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane the stumble, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable and a refrigeration system, which allows us to use aircraft, until we see aircraft and traffic in a particular device, or if you're driven by propellism, or aggressive, if you can see the propellism, if you can see it, if you're driven by propellism, or, or, if you're driven by propella gps conditioning, you're going to a progressive it, you can see it, if you're going to a gps conditioning device, you can see it, if you can see it, you can see it, if you can see it, or your car cylinked to a gps conditioning system, you can see it, if you're going to your car
2022-03-14 08:07:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:07:57 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.591 | ppl 6.03 | bleu 31.58 | wps 4759.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.58
2022-03-14 08:07:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-14 08:07:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.58) (writing took 1.8468717390205711 seconds)
2022-03-14 08:07:59 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 08:07:59 | INFO | train | epoch 031 | loss 2.37 | ppl 5.17 | wps 44415.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.658 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2833
2022-03-14 08:07:59 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 08:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:08:12 | INFO | train_inner | epoch 032:     38 / 157 loss=2.275, ppl=4.84, wps=34882.5, ups=1.4, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.574, loss_scale=4, train_wall=30, gb_free=14.7, wall=2846
2022-03-14 08:08:43 | INFO | train_inner | epoch 032:    138 / 157 loss=2.309, ppl=4.96, wps=81529.2, ups=3.23, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.651, loss_scale=4, train_wall=31, gb_free=14.8, wall=2877
2022-03-14 08:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:08:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 08:08:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:08:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:08:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:09:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to cross two new pigs.
2022-03-14 08:09:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:09:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frogs are served with salt and pills.
2022-03-14 08:09:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:09:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:09:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:09:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife animals grew up again, and this is a foundation for conservation in namibia.
2022-03-14 08:09:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:09:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-14 08:09:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:09:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflection, we can start with a traditional reflection, which restores the size constructions of the face, and the basic shape, and reconcile it all the porting structure and all the fits.
2022-03-14 08:09:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:09:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when i was striking dinner, it's best summarized when someone said, "turn you to the men in your table and say to you, 'when the revolution starts, we support you.' the truth, women, we've been supporting you for a long time," silvertipie carrier, "and then we've been down," and then we're going to sando'clock. "
2022-03-14 08:09:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:09:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system, which allows us to use a vehicle in the aircraft, until we're going to go to a particular solution, or if you're going to a gps, if you're traveling, you're going to the ground, you're going to a gps, or if you're going to the airstripper, you're going to a gps, you're going to a gps, you're going to the ground, you're going to a gps, you're going to the airstrip, you're going to a gps, you're going to the ground, if you're going to the aircraft, you're going to the aircraft, you're going to a particular one, you're going to a gps, you're going to the vehicle,
2022-03-14 08:09:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:09:27 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.589 | ppl 6.02 | bleu 31.13 | wps 4794.7 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.58
2022-03-14 08:09:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-14 08:09:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.13) (writing took 0.8959096081089228 seconds)
2022-03-14 08:09:28 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 08:09:28 | INFO | train | epoch 032 | loss 2.285 | ppl 4.87 | wps 44599.9 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.622 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 2921
2022-03-14 08:09:28 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 08:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:09:53 | INFO | train_inner | epoch 033:     81 / 157 loss=2.198, ppl=4.59, wps=35548.7, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.598, loss_scale=4, train_wall=30, gb_free=14.4, wall=2947
2022-03-14 08:10:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:10:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieples in the clinic.
2022-03-14 08:10:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:10:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:10:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:10:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that generate two new pigs.
2022-03-14 08:10:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salce and ppepper.
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:10:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-14 08:10:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:10:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the name of the people who took responsibility for wildlife, the number of wild wildlife grew up again, and that has become a basis for conservation in namibia.
2022-03-14 08:10:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:10:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like to move, because their movements use, and so the superconductor disorders.
2022-03-14 08:10:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:10:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this mirror reflection, we can start with a traditional facial bar that repeats the big constructures of the face and the basic shape, and restored it through the dietryside of information that refers the whole porting structure and all the fits.
2022-03-14 08:10:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:10:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen, is that... well, dinner was best summarized when someone said, "turn you to men on your table and tell you," if the revolution starts to support you, "the truth is that we've already started supporting you for a long time with rael carson's talent," future cagan's talents. "
2022-03-14 08:10:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:10:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're going to use on our aircraft, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system of refrigeration and a refrigeration system that allows us to use aircraft and traffic, to a particular vehicle, if you're drifted, or if you're driven, the propelled, the promoting, the ground, if you're driven, the propelled, you can either, if you're driven by propella progressive, you can see the progressive, you can see the ground, the promoting machine, you can see the ground, the propella car space, or if you're driving market market market market market market market market market market market market market market, you're driving, you're driving, if you're driving, if you're driving, if you're driving, you're driving
2022-03-14 08:10:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:10:56 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.56 | ppl 5.9 | bleu 32.28 | wps 4653.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.28
2022-03-14 08:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-14 08:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt
2022-03-14 08:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.28) (writing took 1.902741712052375 seconds)
2022-03-14 08:10:58 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 08:10:58 | INFO | train | epoch 033 | loss 2.229 | ppl 4.69 | wps 43822 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.598 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 3012
2022-03-14 08:10:58 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 08:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:11:06 | INFO | train_inner | epoch 034:     24 / 157 loss=2.254, ppl=4.77, wps=34631.1, ups=1.38, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.61, loss_scale=4, train_wall=30, gb_free=14.2, wall=3020
2022-03-14 08:11:37 | INFO | train_inner | epoch 034:    124 / 157 loss=2.163, ppl=4.48, wps=81009.5, ups=3.22, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.618, loss_scale=4, train_wall=31, gb_free=14.1, wall=3051
2022-03-14 08:11:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:11:51 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-14 08:11:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:11:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:11:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:11:59 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dress that will generate two new pigs.
2022-03-14 08:11:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:12:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with saltz and ppersuade.
2022-03-14 08:12:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:12:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-14 08:12:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:12:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wild survivors grew again, and this is a basis for conservation in namibia.
2022-03-14 08:12:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:12:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy, and so the superconductor.
2022-03-14 08:12:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:12:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection that comes from this reflection, we can start with a traditional facial can start with the larger constraints of the face and the basic shape, and we recover it through the diechest of information, which refers the entire porter structure, and all the fits to fold.
2022-03-14 08:12:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:12:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "take you to your desk and tell you," when the revolution begins, we're going to support you, we're going to support you. '"the truth is that we already have been supporting you for a long time, we have been supporting you with four-time."] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-14 08:12:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:12:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on at our airplane the stumest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and a cooling system with refrigeration, which allows us to use aircraft aircraft, till we're not going to have to be able to use the aircraft conditionally beneficial, or if you're not going to be able to have to be able to be able to be able to be able to see the ground, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use a car conditionally appropriate, if you're able to be able to be able to be able to be able to be able to be able to use the ground
2022-03-14 08:12:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:12:26 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.564 | ppl 5.91 | bleu 31.93 | wps 4580.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.28
2022-03-14 08:12:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-14 08:12:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 34 @ 5333 updates, score 31.93) (writing took 0.9454691710416228 seconds)
2022-03-14 08:12:27 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 08:12:27 | INFO | train | epoch 034 | loss 2.187 | ppl 4.55 | wps 44028.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.636 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3101
2022-03-14 08:12:28 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 08:12:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:12:49 | INFO | train_inner | epoch 035:     67 / 157 loss=2.191, ppl=4.57, wps=35020, ups=1.4, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.651, loss_scale=4, train_wall=30, gb_free=15.1, wall=3123
2022-03-14 08:13:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:13:20 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-14 08:13:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:13:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:13:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:13:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that generate two new pigs.
2022-03-14 08:13:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:13:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:13:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:13:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-14 08:13:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:13:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildpopulation, the number of wildlife survivors grew back again, and this has become a foundation for conservation in namibia.
2022-03-14 08:13:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:13:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor.
2022-03-14 08:13:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:13:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial, which restores the size constructures of the face and the fundamental shape, and then restoring it through the information that refers all the pores structure and all the folds.
2022-03-14 08:13:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:13:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "take you to your men on your table and say," if the revolution starts supporting you, "the truth, love is that we've already started to support you for a long time."
2022-03-14 08:13:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:13:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable system and a cooling system of refrigeration, that allows us to use aircraft in a stop-and-the-shelf, to use to a particular vehicle, to the fly, or if you can see it's all over the air conditioning, if you're going to the ground, if you can see it's all over the air conditioner, if you're going to the air conditioning, you're going to the air conditioning, you're going to the ground, you're going to the air conditioner, you're going to the ground, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see, you can see,
2022-03-14 08:13:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:13:54 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.534 | ppl 5.79 | bleu 31.84 | wps 4816.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.28
2022-03-14 08:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-14 08:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:13:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:13:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.84) (writing took 0.8863991578109562 seconds)
2022-03-14 08:13:55 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 08:13:55 | INFO | train | epoch 035 | loss 2.123 | ppl 4.36 | wps 45026.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.59 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3189
2022-03-14 08:13:55 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 08:13:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:13:59 | INFO | train_inner | epoch 036:     10 / 157 loss=2.1, ppl=4.29, wps=35588.8, ups=1.43, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.564, loss_scale=4, train_wall=30, gb_free=15.1, wall=3193
2022-03-14 08:14:30 | INFO | train_inner | epoch 036:    110 / 157 loss=2.079, ppl=4.22, wps=81133, ups=3.21, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.612, loss_scale=4, train_wall=31, gb_free=15.1, wall=3224
2022-03-14 08:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:14:48 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-14 08:14:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:14:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-14 08:14:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:14:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are becoming new goldilocks beds that generate two new pigs.
2022-03-14 08:14:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:15:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:15:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:15:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what everyone's thinking on the track.
2022-03-14 08:15:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:15:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people refused responsibility for wildlife, the majority of wildlife grew up again, and this is a basis for conservation in namibia.
2022-03-14 08:15:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:15:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like to move, because their movements use, and so the superconductor.
2022-03-14 08:15:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:15:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial programmer that restores the groundy contextures of the face and the basic shape, and then passes it through the information that refers the entire porter structure and all the fits.
2022-03-14 08:15:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:15:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate, for me being here at tedwomen, is that... well, when compelling dinner was best summarized when someone said, "turn to men at your desk and tell them, 'when the revolution begins,'" 'when the revolution begins, we'll support you.' '' '"'" '"'" '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-14 08:15:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:15:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we're at our airplane at the stumest, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable drive, and a cooling system of refrigerator that allows us to use a vehicle to stop, to fly, or if you're not going to move the propellant, or if you're going to move the burider, you're either propelled to the wheel, you're going to the wheel, and if you're going to the airstrike, you're going to the crash, or if you're going to the buriot, you're going to the drum, you're going to the drum, you're going to the bug, you're going to the drum, you're going to the bumps, you're going to the drum, you're going to go to the
2022-03-14 08:15:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:15:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.534 | ppl 5.79 | bleu 32.27 | wps 4620.9 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.28
2022-03-14 08:15:23 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 08:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-14 08:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:15:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt
2022-03-14 08:15:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.25/checkpoint_last.pt (epoch 36 @ 5647 updates, score 32.27) (writing took 0.8455326319672167 seconds)
2022-03-14 08:15:24 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 08:15:24 | INFO | train | epoch 036 | loss 2.093 | ppl 4.27 | wps 44293.7 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.625 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3278
2022-03-14 08:15:24 | INFO | fairseq_cli.train | done training in 3277.7 seconds
