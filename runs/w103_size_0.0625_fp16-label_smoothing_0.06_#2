Sender: LSF System <lsfadmin@eu-g3-028>
Subject: Job 207345553: <w103_size_0.0625_fp16_label_smoothing_0.06_#2> in cluster <euler> Done

Job <w103_size_0.0625_fp16_label_smoothing_0.06_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 12:50:55 2022
Job was executed on host(s) <eu-g3-028>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 12:51:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 12:51:15 2022
Terminated at Tue Mar  8 05:51:01 2022
Results reported at Tue Mar  8 05:51:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.06 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147464.00 sec.
    Max Memory :                                 8113 MB
    Average Memory :                             3744.17 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               11887.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   147586 sec.
    Turnaround time :                            147606 sec.

The output (if any) follows:

2022-03-06 12:51:23 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.06, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 12:51:23 | INFO | fairseq.tasks.language_modeling | dictionary: 138136 types
2022-03-06 12:51:25 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(138136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=138136, bias=False)
  )
)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 12:51:25 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 12:51:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. shared model params: 89,639,936 (num. trained: 89,639,936)
2022-03-06 12:51:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 12:51:25 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.0625/valid
2022-03-06 12:51:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 12:51:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 12:51:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 12:51:28 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 12:51:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 12:51:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 12:51:28 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-raw-size-0.0625/train
2022-03-06 12:51:28 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 12:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:51:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 12:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 12:51:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 12:51:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 12:52:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 12:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 12:56:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.741 | nll_loss 14.544 | ppl 23884.6 | wps 42982 | wpb 510.9 | bsz 1 | num_updates 92
2022-03-06 12:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 92 updates
2022-03-06 12:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 12:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 12:56:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 1 @ 92 updates, score 14.741) (writing took 5.281760826706886 seconds)
2022-03-06 12:56:37 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 12:56:37 | INFO | train | epoch 001 | loss 16.331 | nll_loss 16.236 | ppl 77156.8 | wps 21896.3 | ups 0.33 | wpb 65489.2 | bsz 127.9 | num_updates 92 | lr 1.15977e-05 | gnorm 3.362 | loss_scale 4 | train_wall 276 | gb_free 8.1 | wall 309
2022-03-06 12:56:37 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 12:56:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 12:57:00 | INFO | train_inner | epoch 002:      8 / 97 loss=16.209, nll_loss=16.105, ppl=70486.2, wps=21970.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=100, lr=1.25975e-05, gnorm=3.23, loss_scale=4, train_wall=297, gb_free=8.1, wall=332
2022-03-06 13:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:01:19 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.071 | nll_loss 12.765 | ppl 6959.19 | wps 42940.9 | wpb 510.9 | bsz 1 | num_updates 189 | best_loss 13.071
2022-03-06 13:01:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 189 updates
2022-03-06 13:01:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:01:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 2 @ 189 updates, score 13.071) (writing took 5.2775337737984955 seconds)
2022-03-06 13:01:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:01:24 | INFO | train | epoch 002 | loss 14.1 | nll_loss 13.864 | ppl 14912.6 | wps 22167.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 189 | lr 2.37203e-05 | gnorm 1.535 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 596
2022-03-06 13:01:24 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:01:55 | INFO | train_inner | epoch 003:     11 / 97 loss=13.933, nll_loss=13.686, ppl=13180.8, wps=22195.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=200, lr=2.5095e-05, gnorm=1.492, loss_scale=8, train_wall=262, gb_free=8.1, wall=627
2022-03-06 13:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:06:05 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.516 | nll_loss 11.078 | ppl 2162.19 | wps 43018.3 | wpb 510.9 | bsz 1 | num_updates 286 | best_loss 11.516
2022-03-06 13:06:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 286 updates
2022-03-06 13:06:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:06:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 3 @ 286 updates, score 11.516) (writing took 5.2056944807991385 seconds)
2022-03-06 13:06:10 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:06:10 | INFO | train | epoch 003 | loss 12.342 | nll_loss 11.981 | ppl 4041.8 | wps 22180.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 286 | lr 3.58429e-05 | gnorm 1.009 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 882
2022-03-06 13:06:10 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:06:50 | INFO | train_inner | epoch 004:     14 / 97 loss=12.142, nll_loss=11.764, ppl=3476.99, wps=22195.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=300, lr=3.75925e-05, gnorm=0.946, loss_scale=16, train_wall=262, gb_free=8.1, wall=922
2022-03-06 13:10:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:10:52 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.79 | nll_loss 10.254 | ppl 1221.53 | wps 42847.9 | wpb 510.9 | bsz 1 | num_updates 383 | best_loss 10.79
2022-03-06 13:10:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 383 updates
2022-03-06 13:10:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:10:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 4 @ 383 updates, score 10.79) (writing took 5.055559142958373 seconds)
2022-03-06 13:10:57 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:10:57 | INFO | train | epoch 004 | loss 11.134 | nll_loss 10.651 | ppl 1607.79 | wps 22164.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 383 | lr 4.79654e-05 | gnorm 0.58 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 1169
2022-03-06 13:10:57 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:46 | INFO | train_inner | epoch 005:     17 / 97 loss=11.023, nll_loss=10.525, ppl=1473.65, wps=22192.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=400, lr=5.009e-05, gnorm=0.531, loss_scale=32, train_wall=262, gb_free=8.1, wall=1218
2022-03-06 13:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.464 | nll_loss 9.874 | ppl 938.55 | wps 43050.8 | wpb 510.9 | bsz 1 | num_updates 480 | best_loss 10.464
2022-03-06 13:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 480 updates
2022-03-06 13:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 5 @ 480 updates, score 10.464) (writing took 4.7978998981416225 seconds)
2022-03-06 13:15:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:15:43 | INFO | train | epoch 005 | loss 10.63 | nll_loss 10.069 | ppl 1074.34 | wps 22182.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 480 | lr 6.0088e-05 | gnorm 0.475 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 1455
2022-03-06 13:15:43 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:41 | INFO | train_inner | epoch 006:     20 / 97 loss=10.561, nll_loss=9.99, ppl=1017.21, wps=22201.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=500, lr=6.25875e-05, gnorm=0.489, loss_scale=32, train_wall=262, gb_free=8.1, wall=1513
2022-03-06 13:17:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:25 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.203 | nll_loss 9.582 | ppl 766.52 | wps 42975 | wpb 510.9 | bsz 1 | num_updates 576 | best_loss 10.203
2022-03-06 13:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 576 updates
2022-03-06 13:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:20:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:20:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 6 @ 576 updates, score 10.203) (writing took 4.74992347182706 seconds)
2022-03-06 13:20:30 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:20:30 | INFO | train | epoch 006 | loss 10.321 | nll_loss 9.72 | ppl 843.61 | wps 21956.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 576 | lr 7.20856e-05 | gnorm 0.523 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 1742
2022-03-06 13:20:30 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:20:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:21:38 | INFO | train_inner | epoch 007:     24 / 97 loss=10.257, nll_loss=9.65, ppl=803.39, wps=21990, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=600, lr=7.5085e-05, gnorm=0.534, loss_scale=32, train_wall=265, gb_free=8.1, wall=1810
2022-03-06 13:23:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:25:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:25:11 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.961 | nll_loss 9.322 | ppl 640.1 | wps 42851.3 | wpb 510.9 | bsz 1 | num_updates 672 | best_loss 9.961
2022-03-06 13:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 672 updates
2022-03-06 13:25:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 7 @ 672 updates, score 9.961) (writing took 4.781787718646228 seconds)
2022-03-06 13:25:16 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:25:16 | INFO | train | epoch 007 | loss 10.054 | nll_loss 9.426 | ppl 688.11 | wps 21949.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 672 | lr 8.40832e-05 | gnorm 0.576 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2028
2022-03-06 13:25:16 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:26:36 | INFO | train_inner | epoch 008:     28 / 97 loss=9.985, nll_loss=9.352, ppl=653.4, wps=22000.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=700, lr=8.75825e-05, gnorm=0.611, loss_scale=32, train_wall=265, gb_free=8.1, wall=2108
2022-03-06 13:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:29:58 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.748 | nll_loss 9.083 | ppl 542.5 | wps 43010.4 | wpb 510.9 | bsz 1 | num_updates 769 | best_loss 9.748
2022-03-06 13:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 769 updates
2022-03-06 13:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 8 @ 769 updates, score 9.748) (writing took 4.671813393943012 seconds)
2022-03-06 13:30:02 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:30:02 | INFO | train | epoch 008 | loss 9.807 | nll_loss 9.157 | ppl 570.85 | wps 22210.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 769 | lr 9.62058e-05 | gnorm 0.671 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2314
2022-03-06 13:30:02 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:30:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:30:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:31:33 | INFO | train_inner | epoch 009:     32 / 97 loss=9.735, nll_loss=9.078, ppl=540.61, wps=22024.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=800, lr=0.00010008, gnorm=0.706, loss_scale=32, train_wall=264, gb_free=8.1, wall=2405
2022-03-06 13:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:34:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.558 | nll_loss 8.879 | ppl 470.88 | wps 42828.9 | wpb 510.9 | bsz 1 | num_updates 865 | best_loss 9.558
2022-03-06 13:34:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 865 updates
2022-03-06 13:34:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:34:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 9 @ 865 updates, score 9.558) (writing took 4.658294858876616 seconds)
2022-03-06 13:34:48 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:34:48 | INFO | train | epoch 009 | loss 9.582 | nll_loss 8.91 | ppl 481.02 | wps 21977.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 865 | lr 0.000108203 | gnorm 0.761 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2600
2022-03-06 13:34:48 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:36:28 | INFO | train_inner | epoch 010:     35 / 97 loss=9.507, nll_loss=8.828, ppl=454.53, wps=22219.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=900, lr=0.000112578, gnorm=0.761, loss_scale=32, train_wall=262, gb_free=8.1, wall=2700
2022-03-06 13:37:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:30 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.377 | nll_loss 8.672 | ppl 408.01 | wps 43230.1 | wpb 510.9 | bsz 1 | num_updates 961 | best_loss 9.377
2022-03-06 13:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 961 updates
2022-03-06 13:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:39:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:39:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 10 @ 961 updates, score 9.377) (writing took 4.691971911583096 seconds)
2022-03-06 13:39:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:39:34 | INFO | train | epoch 010 | loss 9.374 | nll_loss 8.682 | ppl 410.84 | wps 21979.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 961 | lr 0.000120201 | gnorm 0.804 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 2886
2022-03-06 13:39:34 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:26 | INFO | train_inner | epoch 011:     39 / 97 loss=9.299, nll_loss=8.601, ppl=388.22, wps=22007.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=1000, lr=0.000125075, gnorm=0.826, loss_scale=32, train_wall=265, gb_free=8.1, wall=2998
2022-03-06 13:43:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:44:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:16 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.233 | nll_loss 8.522 | ppl 367.63 | wps 42913.3 | wpb 510.9 | bsz 1 | num_updates 1057 | best_loss 9.233
2022-03-06 13:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1057 updates
2022-03-06 13:44:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 11 @ 1057 updates, score 9.233) (writing took 4.619241518899798 seconds)
2022-03-06 13:44:21 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:44:21 | INFO | train | epoch 011 | loss 9.184 | nll_loss 8.475 | ppl 355.86 | wps 21944.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1057 | lr 0.000132199 | gnorm 0.872 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3173
2022-03-06 13:44:21 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:46:24 | INFO | train_inner | epoch 012:     43 / 97 loss=9.106, nll_loss=8.389, ppl=335.27, wps=21990.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=1100, lr=0.000137573, gnorm=0.874, loss_scale=32, train_wall=265, gb_free=8.1, wall=3296
2022-03-06 13:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:49:02 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.095 | nll_loss 8.367 | ppl 330.07 | wps 43221.4 | wpb 510.9 | bsz 1 | num_updates 1154 | best_loss 9.095
2022-03-06 13:49:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1154 updates
2022-03-06 13:49:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:49:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 12 @ 1154 updates, score 9.095) (writing took 4.599349879659712 seconds)
2022-03-06 13:49:07 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:49:07 | INFO | train | epoch 012 | loss 9.01 | nll_loss 8.284 | ppl 311.75 | wps 22199.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1154 | lr 0.000144321 | gnorm 0.861 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3459
2022-03-06 13:49:07 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:49:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:51:21 | INFO | train_inner | epoch 013:     47 / 97 loss=8.937, nll_loss=8.204, ppl=294.81, wps=22012.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1200, lr=0.00015007, gnorm=0.841, loss_scale=32, train_wall=265, gb_free=8.1, wall=3593
2022-03-06 13:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:53:48 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.978 | nll_loss 8.236 | ppl 301.58 | wps 43130.3 | wpb 510.9 | bsz 1 | num_updates 1250 | best_loss 8.978
2022-03-06 13:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1250 updates
2022-03-06 13:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 13 @ 1250 updates, score 8.978) (writing took 4.609224824234843 seconds)
2022-03-06 13:53:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:53:53 | INFO | train | epoch 013 | loss 8.847 | nll_loss 8.105 | ppl 275.36 | wps 21973 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1250 | lr 0.000156319 | gnorm 0.856 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 3745
2022-03-06 13:53:53 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:16 | INFO | train_inner | epoch 014:     50 / 97 loss=8.762, nll_loss=8.012, ppl=258.14, wps=22233, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1300, lr=0.000162568, gnorm=0.883, loss_scale=64, train_wall=262, gb_free=8.1, wall=3888
2022-03-06 13:56:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:58:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:58:35 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.867 | nll_loss 8.11 | ppl 276.21 | wps 42725.1 | wpb 510.9 | bsz 1 | num_updates 1346 | best_loss 8.867
2022-03-06 13:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1346 updates
2022-03-06 13:58:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:58:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 13:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 14 @ 1346 updates, score 8.867) (writing took 4.588322848081589 seconds)
2022-03-06 13:58:39 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:58:39 | INFO | train | epoch 014 | loss 8.693 | nll_loss 7.937 | ppl 245.06 | wps 21980.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1346 | lr 0.000168316 | gnorm 0.876 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4031
2022-03-06 13:58:39 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:01:13 | INFO | train_inner | epoch 015:     54 / 97 loss=8.618, nll_loss=7.854, ppl=231.32, wps=22029.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1400, lr=0.000175065, gnorm=0.887, loss_scale=32, train_wall=264, gb_free=8.1, wall=4185
2022-03-06 14:03:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:20 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.765 | nll_loss 7.999 | ppl 255.8 | wps 42986 | wpb 510.9 | bsz 1 | num_updates 1442 | best_loss 8.765
2022-03-06 14:03:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1442 updates
2022-03-06 14:03:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:03:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:03:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 15 @ 1442 updates, score 8.765) (writing took 4.84115187311545 seconds)
2022-03-06 14:03:25 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 14:03:25 | INFO | train | epoch 015 | loss 8.544 | nll_loss 7.773 | ppl 218.72 | wps 21979.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1442 | lr 0.000180314 | gnorm 0.887 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4317
2022-03-06 14:03:25 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 14:03:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:06:11 | INFO | train_inner | epoch 016:     58 / 97 loss=8.454, nll_loss=7.675, ppl=204.3, wps=22001.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1500, lr=0.000187563, gnorm=0.892, loss_scale=32, train_wall=264, gb_free=8.1, wall=4483
2022-03-06 14:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:08:07 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.676 | nll_loss 7.896 | ppl 238.23 | wps 43059.6 | wpb 510.9 | bsz 1 | num_updates 1539 | best_loss 8.676
2022-03-06 14:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1539 updates
2022-03-06 14:08:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:08:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 16 @ 1539 updates, score 8.676) (writing took 4.810700214002281 seconds)
2022-03-06 14:08:12 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 14:08:12 | INFO | train | epoch 016 | loss 8.395 | nll_loss 7.61 | ppl 195.39 | wps 22185.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1539 | lr 0.000192437 | gnorm 0.895 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4603
2022-03-06 14:08:12 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 14:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:09:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:11:09 | INFO | train_inner | epoch 017:     62 / 97 loss=8.303, nll_loss=7.509, ppl=182.18, wps=21992.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1600, lr=0.00020006, gnorm=0.921, loss_scale=32, train_wall=265, gb_free=8.1, wall=4780
2022-03-06 14:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:53 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.602 | nll_loss 7.818 | ppl 225.63 | wps 43110.2 | wpb 510.9 | bsz 1 | num_updates 1635 | best_loss 8.602
2022-03-06 14:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1635 updates
2022-03-06 14:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:12:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:12:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 17 @ 1635 updates, score 8.602) (writing took 4.777175760827959 seconds)
2022-03-06 14:12:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 14:12:58 | INFO | train | epoch 017 | loss 8.252 | nll_loss 7.453 | ppl 175.18 | wps 21950.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1635 | lr 0.000204434 | gnorm 0.922 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 4890
2022-03-06 14:12:58 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 14:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:16:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:16:07 | INFO | train_inner | epoch 018:     66 / 97 loss=8.156, nll_loss=7.348, ppl=162.93, wps=21977.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1700, lr=0.000212558, gnorm=0.88, loss_scale=32, train_wall=265, gb_free=8.1, wall=5078
2022-03-06 14:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:17:40 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.514 | nll_loss 7.705 | ppl 208.69 | wps 42999.5 | wpb 510.9 | bsz 1 | num_updates 1731 | best_loss 8.514
2022-03-06 14:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1731 updates
2022-03-06 14:17:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 18 @ 1731 updates, score 8.514) (writing took 4.557399434037507 seconds)
2022-03-06 14:17:45 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 14:17:45 | INFO | train | epoch 018 | loss 8.108 | nll_loss 7.295 | ppl 156.99 | wps 21941 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1731 | lr 0.000216432 | gnorm 0.871 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 5176
2022-03-06 14:17:45 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 14:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:21:01 | INFO | train_inner | epoch 019:     69 / 97 loss=8.014, nll_loss=7.191, ppl=146.13, wps=22210.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=1800, lr=0.000225055, gnorm=0.879, loss_scale=32, train_wall=262, gb_free=8.1, wall=5373
2022-03-06 14:22:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:22:26 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.463 | nll_loss 7.653 | ppl 201.29 | wps 43287 | wpb 510.9 | bsz 1 | num_updates 1828 | best_loss 8.463
2022-03-06 14:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1828 updates
2022-03-06 14:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:22:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 19 @ 1828 updates, score 8.463) (writing took 4.5564966686069965 seconds)
2022-03-06 14:22:31 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 14:22:31 | INFO | train | epoch 019 | loss 7.971 | nll_loss 7.144 | ppl 141.45 | wps 22200.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 1828 | lr 0.000228554 | gnorm 0.914 | loss_scale 64 | train_wall 254 | gb_free 8.1 | wall 5463
2022-03-06 14:22:31 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 14:22:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:22:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:25:59 | INFO | train_inner | epoch 020:     73 / 97 loss=7.871, nll_loss=7.035, ppl=131.12, wps=22027.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=1900, lr=0.000237553, gnorm=0.913, loss_scale=32, train_wall=264, gb_free=8.1, wall=5671
2022-03-06 14:27:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:12 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.392 | nll_loss 7.572 | ppl 190.25 | wps 43333.7 | wpb 510.9 | bsz 1 | num_updates 1924 | best_loss 8.392
2022-03-06 14:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 1924 updates
2022-03-06 14:27:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:27:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 20 @ 1924 updates, score 8.392) (writing took 4.562375544104725 seconds)
2022-03-06 14:27:17 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 14:27:17 | INFO | train | epoch 020 | loss 7.833 | nll_loss 6.992 | ppl 127.33 | wps 21991.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 1924 | lr 0.000240552 | gnorm 0.886 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 5748
2022-03-06 14:27:17 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 14:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:28:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:30:56 | INFO | train_inner | epoch 021:     77 / 97 loss=7.731, nll_loss=6.88, ppl=117.8, wps=22023.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=2000, lr=0.00025005, gnorm=0.891, loss_scale=32, train_wall=264, gb_free=8.1, wall=5968
2022-03-06 14:31:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:31:58 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.359 | nll_loss 7.537 | ppl 185.77 | wps 43022.6 | wpb 510.9 | bsz 1 | num_updates 2020 | best_loss 8.359
2022-03-06 14:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2020 updates
2022-03-06 14:31:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 21 @ 2020 updates, score 8.359) (writing took 4.578247817233205 seconds)
2022-03-06 14:32:03 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 14:32:03 | INFO | train | epoch 021 | loss 7.701 | nll_loss 6.847 | ppl 115.13 | wps 21981.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2020 | lr 0.00025255 | gnorm 0.9 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6034
2022-03-06 14:32:03 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 14:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:35:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:35:53 | INFO | train_inner | epoch 022:     81 / 97 loss=7.601, nll_loss=6.737, ppl=106.69, wps=22023.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2100, lr=0.000262548, gnorm=0.918, loss_scale=32, train_wall=264, gb_free=8.1, wall=6265
2022-03-06 14:36:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:36:44 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.285 | nll_loss 7.447 | ppl 174.52 | wps 43137.8 | wpb 510.9 | bsz 1 | num_updates 2116 | best_loss 8.285
2022-03-06 14:36:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2116 updates
2022-03-06 14:36:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:36:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:36:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 22 @ 2116 updates, score 8.285) (writing took 4.5612836657091975 seconds)
2022-03-06 14:36:48 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 14:36:48 | INFO | train | epoch 022 | loss 7.573 | nll_loss 6.706 | ppl 104.44 | wps 21989 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2116 | lr 0.000264547 | gnorm 0.909 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6320
2022-03-06 14:36:49 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 14:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:48 | INFO | train_inner | epoch 023:     84 / 97 loss=7.469, nll_loss=6.591, ppl=96.4, wps=22212.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2200, lr=0.000275045, gnorm=0.901, loss_scale=32, train_wall=262, gb_free=8.1, wall=6560
2022-03-06 14:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:41:30 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.275 | nll_loss 7.441 | ppl 173.78 | wps 42932.6 | wpb 510.9 | bsz 1 | num_updates 2213 | best_loss 8.275
2022-03-06 14:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2213 updates
2022-03-06 14:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 23 @ 2213 updates, score 8.275) (writing took 4.679950867779553 seconds)
2022-03-06 14:41:35 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 14:41:35 | INFO | train | epoch 023 | loss 7.451 | nll_loss 6.572 | ppl 95.14 | wps 22170.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2213 | lr 0.00027667 | gnorm 0.908 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6607
2022-03-06 14:41:35 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 14:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:41:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:45:46 | INFO | train_inner | epoch 024:     88 / 97 loss=7.347, nll_loss=6.456, ppl=87.8, wps=22003.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2300, lr=0.000287543, gnorm=0.884, loss_scale=32, train_wall=265, gb_free=8.1, wall=6858
2022-03-06 14:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:16 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.241 | nll_loss 7.401 | ppl 169.01 | wps 43193.1 | wpb 510.9 | bsz 1 | num_updates 2309 | best_loss 8.241
2022-03-06 14:46:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2309 updates
2022-03-06 14:46:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:46:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 24 @ 2309 updates, score 8.241) (writing took 4.571946990210563 seconds)
2022-03-06 14:46:21 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 14:46:21 | INFO | train | epoch 024 | loss 7.328 | nll_loss 6.436 | ppl 86.6 | wps 21979.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2309 | lr 0.000288667 | gnorm 0.897 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 6893
2022-03-06 14:46:21 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 14:46:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:48:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:50:46 | INFO | train_inner | epoch 025:     93 / 97 loss=7.221, nll_loss=6.317, ppl=79.73, wps=21813.6, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=2400, lr=0.00030004, gnorm=0.928, loss_scale=16, train_wall=267, gb_free=8.1, wall=7158
2022-03-06 14:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:51:02 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.248 | nll_loss 7.404 | ppl 169.38 | wps 43321 | wpb 510.9 | bsz 1 | num_updates 2404 | best_loss 8.241
2022-03-06 14:51:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2404 updates
2022-03-06 14:51:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 14:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 14:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 25 @ 2404 updates, score 8.248) (writing took 2.229094883892685 seconds)
2022-03-06 14:51:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 14:51:05 | INFO | train | epoch 025 | loss 7.215 | nll_loss 6.311 | ppl 79.37 | wps 21934.7 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 2404 | lr 0.00030054 | gnorm 0.915 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 7177
2022-03-06 14:51:05 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 14:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:55:39 | INFO | train_inner | epoch 026:     96 / 97 loss=7.107, nll_loss=6.192, ppl=73.11, wps=22395.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2500, lr=0.000312538, gnorm=0.923, loss_scale=32, train_wall=262, gb_free=8.1, wall=7451
2022-03-06 14:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:46 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.233 | nll_loss 7.376 | ppl 166.17 | wps 42972.6 | wpb 510.9 | bsz 1 | num_updates 2501 | best_loss 8.233
2022-03-06 14:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2501 updates
2022-03-06 14:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt
2022-03-06 14:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_best.pt (epoch 26 @ 2501 updates, score 8.233) (writing took 4.6012765429914 seconds)
2022-03-06 14:55:51 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 14:55:51 | INFO | train | epoch 026 | loss 7.102 | nll_loss 6.186 | ppl 72.8 | wps 22187.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2501 | lr 0.000312662 | gnorm 0.925 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7463
2022-03-06 14:55:51 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 14:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:00:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.276 | nll_loss 7.428 | ppl 172.23 | wps 43063.7 | wpb 510.9 | bsz 1 | num_updates 2598 | best_loss 8.233
2022-03-06 15:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2598 updates
2022-03-06 15:00:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 27 @ 2598 updates, score 8.276) (writing took 2.1725107529200613 seconds)
2022-03-06 15:00:34 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 15:00:34 | INFO | train | epoch 027 | loss 6.991 | nll_loss 6.063 | ppl 66.86 | wps 22412.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2598 | lr 0.000324785 | gnorm 0.926 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 7746
2022-03-06 15:00:34 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 15:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:40 | INFO | train_inner | epoch 028:      2 / 97 loss=6.99, nll_loss=6.062, ppl=66.83, wps=21699.3, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=2600, lr=0.000325035, gnorm=0.925, loss_scale=32, train_wall=262, gb_free=8.1, wall=7752
2022-03-06 15:01:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:05:16 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.262 | nll_loss 7.41 | ppl 170.11 | wps 43201 | wpb 510.9 | bsz 1 | num_updates 2694 | best_loss 8.233
2022-03-06 15:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2694 updates
2022-03-06 15:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:05:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:05:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 28 @ 2694 updates, score 8.262) (writing took 2.2303223689086735 seconds)
2022-03-06 15:05:18 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 15:05:18 | INFO | train | epoch 028 | loss 6.879 | nll_loss 5.939 | ppl 61.35 | wps 22158.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2694 | lr 0.000336783 | gnorm 0.9 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8030
2022-03-06 15:05:18 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 15:05:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:35 | INFO | train_inner | epoch 029:      6 / 97 loss=6.871, nll_loss=5.93, ppl=60.99, wps=22190.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2700, lr=0.000337533, gnorm=0.906, loss_scale=32, train_wall=265, gb_free=8.1, wall=8047
2022-03-06 15:08:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 15:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:10:00 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.332 | nll_loss 7.486 | ppl 179.29 | wps 42950.8 | wpb 510.9 | bsz 1 | num_updates 2790 | best_loss 8.233
2022-03-06 15:10:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2790 updates
2022-03-06 15:10:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:10:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 29 @ 2790 updates, score 8.332) (writing took 2.180352025665343 seconds)
2022-03-06 15:10:02 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 15:10:02 | INFO | train | epoch 029 | loss 6.777 | nll_loss 5.826 | ppl 56.75 | wps 22150.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2790 | lr 0.00034878 | gnorm 0.938 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 8314
2022-03-06 15:10:02 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 15:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:10:31 | INFO | train_inner | epoch 030:     10 / 97 loss=6.765, nll_loss=5.813, ppl=56.23, wps=22180.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2800, lr=0.00035003, gnorm=0.927, loss_scale=32, train_wall=265, gb_free=8.1, wall=8343
2022-03-06 15:13:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:44 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.294 | nll_loss 7.43 | ppl 172.44 | wps 42999 | wpb 510.9 | bsz 1 | num_updates 2886 | best_loss 8.233
2022-03-06 15:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 2886 updates
2022-03-06 15:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 30 @ 2886 updates, score 8.294) (writing took 2.190258041024208 seconds)
2022-03-06 15:14:46 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 15:14:46 | INFO | train | epoch 030 | loss 6.674 | nll_loss 5.713 | ppl 52.44 | wps 22158.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 2886 | lr 0.000360778 | gnorm 0.941 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 8598
2022-03-06 15:14:46 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 15:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:26 | INFO | train_inner | epoch 031:     14 / 97 loss=6.656, nll_loss=5.692, ppl=51.69, wps=22180.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=2900, lr=0.000362528, gnorm=0.935, loss_scale=16, train_wall=265, gb_free=8.1, wall=8638
2022-03-06 15:19:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:19:27 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.385 | nll_loss 7.538 | ppl 185.87 | wps 43040.7 | wpb 510.9 | bsz 1 | num_updates 2983 | best_loss 8.233
2022-03-06 15:19:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 2983 updates
2022-03-06 15:19:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:19:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:19:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 31 @ 2983 updates, score 8.385) (writing took 2.2931067678146064 seconds)
2022-03-06 15:19:30 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 15:19:30 | INFO | train | epoch 031 | loss 6.571 | nll_loss 5.598 | ppl 48.43 | wps 22372.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 2983 | lr 0.0003729 | gnorm 0.944 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 8882
2022-03-06 15:19:30 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 15:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:20:18 | INFO | train_inner | epoch 032:     17 / 97 loss=6.556, nll_loss=5.581, ppl=47.86, wps=22391.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3000, lr=0.000375025, gnorm=0.963, loss_scale=32, train_wall=262, gb_free=8.1, wall=8930
2022-03-06 15:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:24:11 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.401 | nll_loss 7.551 | ppl 187.52 | wps 42997.3 | wpb 510.9 | bsz 1 | num_updates 3079 | best_loss 8.233
2022-03-06 15:24:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3079 updates
2022-03-06 15:24:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 32 @ 3079 updates, score 8.401) (writing took 2.1862284489907324 seconds)
2022-03-06 15:24:13 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 15:24:13 | INFO | train | epoch 032 | loss 6.471 | nll_loss 5.487 | ppl 44.83 | wps 22159 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3079 | lr 0.000384898 | gnorm 0.979 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 9165
2022-03-06 15:24:13 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 15:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:25:13 | INFO | train_inner | epoch 033:     21 / 97 loss=6.45, nll_loss=5.463, ppl=44.11, wps=22197.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3100, lr=0.000387523, gnorm=0.985, loss_scale=16, train_wall=264, gb_free=8.1, wall=9225
2022-03-06 15:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:28:55 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.401 | nll_loss 7.555 | ppl 188.11 | wps 42797.5 | wpb 510.9 | bsz 1 | num_updates 3176 | best_loss 8.233
2022-03-06 15:28:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3176 updates
2022-03-06 15:28:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:28:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 33 @ 3176 updates, score 8.401) (writing took 2.14930556435138 seconds)
2022-03-06 15:28:57 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 15:28:57 | INFO | train | epoch 033 | loss 6.373 | nll_loss 5.378 | ppl 41.57 | wps 22389.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3176 | lr 0.000397021 | gnorm 0.977 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 9449
2022-03-06 15:28:57 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 15:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:30:06 | INFO | train_inner | epoch 034:     24 / 97 loss=6.345, nll_loss=5.347, ppl=40.71, wps=22406.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3200, lr=0.00040002, gnorm=0.956, loss_scale=32, train_wall=262, gb_free=8.1, wall=9518
2022-03-06 15:30:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:33:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:33:39 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.463 | nll_loss 7.595 | ppl 193.36 | wps 43293.9 | wpb 510.9 | bsz 1 | num_updates 3272 | best_loss 8.233
2022-03-06 15:33:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3272 updates
2022-03-06 15:33:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:33:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:33:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 34 @ 3272 updates, score 8.463) (writing took 2.196554542053491 seconds)
2022-03-06 15:33:41 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 15:33:41 | INFO | train | epoch 034 | loss 6.276 | nll_loss 5.27 | ppl 38.59 | wps 22156.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3272 | lr 0.000409018 | gnorm 0.983 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 9733
2022-03-06 15:33:41 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 15:33:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:35:01 | INFO | train_inner | epoch 035:     28 / 97 loss=6.244, nll_loss=5.235, ppl=37.65, wps=22190.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3300, lr=0.000412518, gnorm=1.001, loss_scale=16, train_wall=265, gb_free=8.1, wall=9813
2022-03-06 15:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:38:23 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.469 | nll_loss 7.599 | ppl 193.83 | wps 42640.6 | wpb 510.9 | bsz 1 | num_updates 3369 | best_loss 8.233
2022-03-06 15:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3369 updates
2022-03-06 15:38:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 35 @ 3369 updates, score 8.469) (writing took 2.137730235699564 seconds)
2022-03-06 15:38:25 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 15:38:25 | INFO | train | epoch 035 | loss 6.18 | nll_loss 5.162 | ppl 35.81 | wps 22376.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3369 | lr 0.000421141 | gnorm 0.992 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 10017
2022-03-06 15:38:25 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 15:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:54 | INFO | train_inner | epoch 036:     31 / 97 loss=6.154, nll_loss=5.134, ppl=35.11, wps=22384.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3400, lr=0.000425015, gnorm=1.007, loss_scale=32, train_wall=262, gb_free=8.1, wall=10105
2022-03-06 15:40:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:43:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:07 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.525 | nll_loss 7.654 | ppl 201.38 | wps 42945.1 | wpb 510.9 | bsz 1 | num_updates 3465 | best_loss 8.233
2022-03-06 15:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3465 updates
2022-03-06 15:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:43:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:43:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 36 @ 3465 updates, score 8.525) (writing took 2.1128950733691454 seconds)
2022-03-06 15:43:09 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 15:43:09 | INFO | train | epoch 036 | loss 6.085 | nll_loss 5.057 | ppl 33.28 | wps 22145.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3465 | lr 0.000433138 | gnorm 1.015 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10301
2022-03-06 15:43:09 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 15:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:44:49 | INFO | train_inner | epoch 037:     35 / 97 loss=6.053, nll_loss=5.021, ppl=32.48, wps=22184.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3500, lr=0.000437513, gnorm=1.043, loss_scale=16, train_wall=265, gb_free=8.1, wall=10401
2022-03-06 15:47:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:47:50 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.564 | nll_loss 7.701 | ppl 208.04 | wps 42938.1 | wpb 510.9 | bsz 1 | num_updates 3562 | best_loss 8.233
2022-03-06 15:47:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3562 updates
2022-03-06 15:47:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 37 @ 3562 updates, score 8.564) (writing took 2.126481084153056 seconds)
2022-03-06 15:47:53 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 15:47:53 | INFO | train | epoch 037 | loss 5.994 | nll_loss 4.955 | ppl 31.02 | wps 22384.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3562 | lr 0.000445261 | gnorm 1 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 10584
2022-03-06 15:47:53 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 15:47:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:48:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:49:44 | INFO | train_inner | epoch 038:     39 / 97 loss=5.952, nll_loss=4.909, ppl=30.04, wps=22192.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=3600, lr=0.00045001, gnorm=0.99, loss_scale=16, train_wall=265, gb_free=8.1, wall=10696
2022-03-06 15:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:34 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.65 | nll_loss 7.789 | ppl 221.24 | wps 43263.7 | wpb 510.9 | bsz 1 | num_updates 3658 | best_loss 8.233
2022-03-06 15:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3658 updates
2022-03-06 15:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 38 @ 3658 updates, score 8.65) (writing took 2.18703718110919 seconds)
2022-03-06 15:52:36 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 15:52:36 | INFO | train | epoch 038 | loss 5.9 | nll_loss 4.85 | ppl 28.83 | wps 22168.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3658 | lr 0.000457259 | gnorm 1.053 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 10868
2022-03-06 15:52:36 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 15:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:54:36 | INFO | train_inner | epoch 039:     42 / 97 loss=5.865, nll_loss=4.811, ppl=28.06, wps=22404.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3700, lr=0.000462508, gnorm=1.028, loss_scale=32, train_wall=262, gb_free=8.1, wall=10988
2022-03-06 15:54:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:57:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:57:18 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.685 | nll_loss 7.807 | ppl 223.93 | wps 42930.5 | wpb 510.9 | bsz 1 | num_updates 3754 | best_loss 8.233
2022-03-06 15:57:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 3754 updates
2022-03-06 15:57:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:57:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 15:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 39 @ 3754 updates, score 8.685) (writing took 2.1310682049952447 seconds)
2022-03-06 15:57:20 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 15:57:20 | INFO | train | epoch 039 | loss 5.808 | nll_loss 4.748 | ppl 26.86 | wps 22159.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3754 | lr 0.000469256 | gnorm 1.022 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11152
2022-03-06 15:57:20 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 15:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:59:31 | INFO | train_inner | epoch 040:     46 / 97 loss=5.763, nll_loss=4.697, ppl=25.95, wps=22204.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3800, lr=0.000475005, gnorm=1.029, loss_scale=16, train_wall=264, gb_free=8.1, wall=11283
2022-03-06 16:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:02:01 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.696 | nll_loss 7.823 | ppl 226.49 | wps 42954.9 | wpb 510.9 | bsz 1 | num_updates 3851 | best_loss 8.233
2022-03-06 16:02:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 3851 updates
2022-03-06 16:02:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:02:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:02:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 40 @ 3851 updates, score 8.696) (writing took 2.122703659813851 seconds)
2022-03-06 16:02:03 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 16:02:03 | INFO | train | epoch 040 | loss 5.727 | nll_loss 4.656 | ppl 25.2 | wps 22403 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 3851 | lr 0.000481379 | gnorm 1.075 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 11435
2022-03-06 16:02:03 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 16:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:04:26 | INFO | train_inner | epoch 041:     50 / 97 loss=5.683, nll_loss=4.607, ppl=24.37, wps=22204.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=3900, lr=0.000487503, gnorm=1.09, loss_scale=16, train_wall=264, gb_free=8.1, wall=11578
2022-03-06 16:06:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:06:45 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.763 | nll_loss 7.88 | ppl 235.49 | wps 43019.1 | wpb 510.9 | bsz 1 | num_updates 3947 | best_loss 8.233
2022-03-06 16:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 3947 updates
2022-03-06 16:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 41 @ 3947 updates, score 8.763) (writing took 2.1390916178934276 seconds)
2022-03-06 16:06:47 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 16:06:47 | INFO | train | epoch 041 | loss 5.633 | nll_loss 4.551 | ppl 23.45 | wps 22158.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 3947 | lr 0.000493376 | gnorm 1.061 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 11719
2022-03-06 16:06:47 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 16:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:09:19 | INFO | train_inner | epoch 042:     53 / 97 loss=5.586, nll_loss=4.498, ppl=22.6, wps=22393.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=4000, lr=0.0005, gnorm=1.038, loss_scale=16, train_wall=262, gb_free=8.1, wall=11870
2022-03-06 16:10:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:11:29 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.855 | nll_loss 7.958 | ppl 248.63 | wps 42985.8 | wpb 510.9 | bsz 1 | num_updates 4043 | best_loss 8.233
2022-03-06 16:11:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4043 updates
2022-03-06 16:11:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:11:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 42 @ 4043 updates, score 8.855) (writing took 2.134979698807001 seconds)
2022-03-06 16:11:31 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 16:11:31 | INFO | train | epoch 042 | loss 5.545 | nll_loss 4.453 | ppl 21.9 | wps 22148.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4043 | lr 0.000497334 | gnorm 1.05 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 12003
2022-03-06 16:11:31 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 16:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:14:14 | INFO | train_inner | epoch 043:     57 / 97 loss=5.493, nll_loss=4.394, ppl=21.03, wps=22181.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4100, lr=0.000493865, gnorm=1.061, loss_scale=16, train_wall=265, gb_free=8.1, wall=12166
2022-03-06 16:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:16:13 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.885 | nll_loss 8.001 | ppl 256.18 | wps 42877.1 | wpb 510.9 | bsz 1 | num_updates 4140 | best_loss 8.233
2022-03-06 16:16:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4140 updates
2022-03-06 16:16:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 43 @ 4140 updates, score 8.885) (writing took 2.152430393733084 seconds)
2022-03-06 16:16:15 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 16:16:15 | INFO | train | epoch 043 | loss 5.456 | nll_loss 4.352 | ppl 20.42 | wps 22378.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4140 | lr 0.000491473 | gnorm 1.051 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 12287
2022-03-06 16:16:15 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 16:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:16:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:19:09 | INFO | train_inner | epoch 044:     61 / 97 loss=5.401, nll_loss=4.291, ppl=19.57, wps=22186.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4200, lr=0.00048795, gnorm=1.047, loss_scale=16, train_wall=265, gb_free=8.1, wall=12461
2022-03-06 16:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:56 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.952 | nll_loss 8.068 | ppl 268.42 | wps 43358.3 | wpb 510.9 | bsz 1 | num_updates 4236 | best_loss 8.233
2022-03-06 16:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4236 updates
2022-03-06 16:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 44 @ 4236 updates, score 8.952) (writing took 2.12782797915861 seconds)
2022-03-06 16:20:59 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 16:20:59 | INFO | train | epoch 044 | loss 5.363 | nll_loss 4.249 | ppl 19.01 | wps 22169 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4236 | lr 0.000485872 | gnorm 1.061 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 12570
2022-03-06 16:20:59 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 16:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:24:04 | INFO | train_inner | epoch 045:     65 / 97 loss=5.307, nll_loss=4.185, ppl=18.19, wps=22208.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4300, lr=0.000482243, gnorm=1.052, loss_scale=8, train_wall=264, gb_free=8.1, wall=12756
2022-03-06 16:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:25:40 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.054 | nll_loss 8.173 | ppl 288.58 | wps 43343.1 | wpb 510.9 | bsz 1 | num_updates 4332 | best_loss 8.233
2022-03-06 16:25:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4332 updates
2022-03-06 16:25:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:25:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 45 @ 4332 updates, score 9.054) (writing took 2.148727383930236 seconds)
2022-03-06 16:25:42 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 16:25:42 | INFO | train | epoch 045 | loss 5.272 | nll_loss 4.146 | ppl 17.71 | wps 22170.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4332 | lr 0.000480458 | gnorm 1.028 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 12854
2022-03-06 16:25:42 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 16:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:56 | INFO | train_inner | epoch 046:     68 / 97 loss=5.215, nll_loss=4.083, ppl=16.94, wps=22417.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4400, lr=0.000476731, gnorm=1.03, loss_scale=16, train_wall=262, gb_free=8.1, wall=13048
2022-03-06 16:30:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:30:24 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.119 | nll_loss 8.231 | ppl 300.42 | wps 42977.8 | wpb 510.9 | bsz 1 | num_updates 4429 | best_loss 8.233
2022-03-06 16:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4429 updates
2022-03-06 16:30:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:30:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:30:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 46 @ 4429 updates, score 9.119) (writing took 2.1224058717489243 seconds)
2022-03-06 16:30:26 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 16:30:26 | INFO | train | epoch 046 | loss 5.187 | nll_loss 4.051 | ppl 16.58 | wps 22399.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4429 | lr 0.000475168 | gnorm 1.024 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13138
2022-03-06 16:30:26 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 16:30:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:33:48 | INFO | train_inner | epoch 047:     71 / 97 loss=5.131, nll_loss=3.988, ppl=15.87, wps=22418.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4500, lr=0.000471405, gnorm=1.018, loss_scale=16, train_wall=262, gb_free=8.1, wall=13340
2022-03-06 16:34:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:35:07 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.21 | nll_loss 8.338 | ppl 323.6 | wps 42943 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.233
2022-03-06 16:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4525 updates
2022-03-06 16:35:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:35:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 47 @ 4525 updates, score 9.21) (writing took 2.122036079876125 seconds)
2022-03-06 16:35:09 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 16:35:09 | INFO | train | epoch 047 | loss 5.105 | nll_loss 3.959 | ppl 15.55 | wps 22161.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4525 | lr 0.0004701 | gnorm 1.03 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13421
2022-03-06 16:35:09 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 16:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:38:43 | INFO | train_inner | epoch 048:     75 / 97 loss=5.048, nll_loss=3.894, ppl=14.87, wps=22179.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4600, lr=0.000466252, gnorm=1.041, loss_scale=16, train_wall=265, gb_free=8.1, wall=13635
2022-03-06 16:39:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:39:51 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.275 | nll_loss 8.397 | ppl 337.02 | wps 42907.4 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 8.233
2022-03-06 16:39:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4622 updates
2022-03-06 16:39:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:39:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 48 @ 4622 updates, score 9.275) (writing took 2.137946703005582 seconds)
2022-03-06 16:39:53 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 16:39:53 | INFO | train | epoch 048 | loss 5.025 | nll_loss 3.869 | ppl 14.61 | wps 22377.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4622 | lr 0.000465141 | gnorm 1.028 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13705
2022-03-06 16:39:53 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 16:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:40:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:43:39 | INFO | train_inner | epoch 049:     79 / 97 loss=4.963, nll_loss=3.799, ppl=13.92, wps=22179.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=4700, lr=0.000461266, gnorm=1.022, loss_scale=16, train_wall=265, gb_free=8.1, wall=13931
2022-03-06 16:44:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:44:35 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.378 | nll_loss 8.507 | ppl 363.85 | wps 42730.6 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 8.233
2022-03-06 16:44:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 4718 updates
2022-03-06 16:44:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:44:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:44:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 49 @ 4718 updates, score 9.378) (writing took 2.159988353960216 seconds)
2022-03-06 16:44:37 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 16:44:37 | INFO | train | epoch 049 | loss 4.945 | nll_loss 3.779 | ppl 13.72 | wps 22146.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4718 | lr 0.000460385 | gnorm 1.022 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 13989
2022-03-06 16:44:37 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 16:44:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:48:34 | INFO | train_inner | epoch 050:     83 / 97 loss=4.884, nll_loss=3.71, ppl=13.09, wps=22196.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=4800, lr=0.000456435, gnorm=1.039, loss_scale=16, train_wall=264, gb_free=8.1, wall=14226
2022-03-06 16:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:19 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.419 | nll_loss 8.532 | ppl 370.19 | wps 42751.1 | wpb 510.9 | bsz 1 | num_updates 4814 | best_loss 8.233
2022-03-06 16:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 4814 updates
2022-03-06 16:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 50 @ 4814 updates, score 9.419) (writing took 2.1148242806084454 seconds)
2022-03-06 16:49:21 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 16:49:21 | INFO | train | epoch 050 | loss 4.87 | nll_loss 3.694 | ppl 12.95 | wps 22170.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 4814 | lr 0.000455771 | gnorm 1.036 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 14273
2022-03-06 16:49:21 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 16:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:26 | INFO | train_inner | epoch 051:     86 / 97 loss=4.815, nll_loss=3.632, ppl=12.4, wps=22416.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=4900, lr=0.000451754, gnorm=1.014, loss_scale=16, train_wall=262, gb_free=8.1, wall=14518
2022-03-06 16:53:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:02 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.466 | nll_loss 8.579 | ppl 382.46 | wps 43103.5 | wpb 510.9 | bsz 1 | num_updates 4911 | best_loss 8.233
2022-03-06 16:54:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 4911 updates
2022-03-06 16:54:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 51 @ 4911 updates, score 9.466) (writing took 2.142454063054174 seconds)
2022-03-06 16:54:04 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 16:54:04 | INFO | train | epoch 051 | loss 4.8 | nll_loss 3.615 | ppl 12.25 | wps 22399 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 4911 | lr 0.000451248 | gnorm 1.018 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 14556
2022-03-06 16:54:04 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 16:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:54:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:58:24 | INFO | train_inner | epoch 052:     91 / 97 loss=4.74, nll_loss=3.547, ppl=11.69, wps=21984.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5000, lr=0.000447214, gnorm=1.024, loss_scale=8, train_wall=267, gb_free=8.1, wall=14816
2022-03-06 16:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:58:46 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.645 | nll_loss 8.778 | ppl 439.1 | wps 43002.3 | wpb 510.9 | bsz 1 | num_updates 5006 | best_loss 8.233
2022-03-06 16:58:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5006 updates
2022-03-06 16:58:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 16:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 52 @ 5006 updates, score 9.645) (writing took 2.2789085539989173 seconds)
2022-03-06 16:58:48 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 16:58:48 | INFO | train | epoch 052 | loss 4.729 | nll_loss 3.536 | ppl 11.6 | wps 21919.9 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 5006 | lr 0.000446946 | gnorm 1.027 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 14840
2022-03-06 16:58:48 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 16:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:03:16 | INFO | train_inner | epoch 053:     94 / 97 loss=4.668, nll_loss=3.467, ppl=11.06, wps=22385.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5100, lr=0.000442807, gnorm=1.018, loss_scale=16, train_wall=262, gb_free=8.1, wall=15108
2022-03-06 17:03:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:03:30 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.649 | nll_loss 8.774 | ppl 437.89 | wps 42994.3 | wpb 510.9 | bsz 1 | num_updates 5103 | best_loss 8.233
2022-03-06 17:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5103 updates
2022-03-06 17:03:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:03:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:03:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 53 @ 5103 updates, score 9.649) (writing took 2.3756742980331182 seconds)
2022-03-06 17:03:32 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 17:03:32 | INFO | train | epoch 053 | loss 4.664 | nll_loss 3.462 | ppl 11.02 | wps 22359.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5103 | lr 0.000442677 | gnorm 1.019 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 15124
2022-03-06 17:03:32 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 17:03:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:04:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:08:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:08:14 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.748 | nll_loss 8.867 | ppl 466.86 | wps 43128.2 | wpb 510.9 | bsz 1 | num_updates 5199 | best_loss 8.233
2022-03-06 17:08:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5199 updates
2022-03-06 17:08:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:08:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 54 @ 5199 updates, score 9.748) (writing took 2.347857820801437 seconds)
2022-03-06 17:08:17 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 17:08:17 | INFO | train | epoch 054 | loss 4.599 | nll_loss 3.389 | ppl 10.48 | wps 22123.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5199 | lr 0.000438571 | gnorm 1.037 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 15408
2022-03-06 17:08:17 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 17:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:19 | INFO | train_inner | epoch 055:      1 / 97 loss=4.602, nll_loss=3.392, ppl=10.5, wps=21601.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=5200, lr=0.000438529, gnorm=1.036, loss_scale=8, train_wall=265, gb_free=8.1, wall=15411
2022-03-06 17:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:12:59 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.797 | nll_loss 8.929 | ppl 487.48 | wps 42968.6 | wpb 510.9 | bsz 1 | num_updates 5296 | best_loss 8.233
2022-03-06 17:12:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5296 updates
2022-03-06 17:12:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:13:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:13:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 55 @ 5296 updates, score 9.797) (writing took 2.3302280348725617 seconds)
2022-03-06 17:13:01 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 17:13:01 | INFO | train | epoch 055 | loss 4.535 | nll_loss 3.317 | ppl 9.97 | wps 22340.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5296 | lr 0.000434536 | gnorm 1.021 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 15693
2022-03-06 17:13:01 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 17:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:13:12 | INFO | train_inner | epoch 056:      4 / 97 loss=4.53, nll_loss=3.311, ppl=9.93, wps=22358.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5300, lr=0.000434372, gnorm=1.018, loss_scale=16, train_wall=262, gb_free=8.1, wall=15704
2022-03-06 17:14:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:17:43 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.849 | nll_loss 8.987 | ppl 507.5 | wps 43021.5 | wpb 510.9 | bsz 1 | num_updates 5392 | best_loss 8.233
2022-03-06 17:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5392 updates
2022-03-06 17:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 56 @ 5392 updates, score 9.849) (writing took 2.3890560218133032 seconds)
2022-03-06 17:17:45 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 17:17:45 | INFO | train | epoch 056 | loss 4.475 | nll_loss 3.249 | ppl 9.5 | wps 22129.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5392 | lr 0.000430651 | gnorm 1.039 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 15977
2022-03-06 17:17:45 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 17:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:18:08 | INFO | train_inner | epoch 057:      8 / 97 loss=4.469, nll_loss=3.242, ppl=9.46, wps=22160.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5400, lr=0.000430331, gnorm=1.049, loss_scale=8, train_wall=265, gb_free=8.1, wall=16000
2022-03-06 17:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:22:27 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 10.012 | nll_loss 9.143 | ppl 565.3 | wps 42935.7 | wpb 510.9 | bsz 1 | num_updates 5489 | best_loss 8.233
2022-03-06 17:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5489 updates
2022-03-06 17:22:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:22:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 57 @ 5489 updates, score 10.012) (writing took 2.3394849998876452 seconds)
2022-03-06 17:22:29 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 17:22:29 | INFO | train | epoch 057 | loss 4.417 | nll_loss 3.183 | ppl 9.08 | wps 22359.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5489 | lr 0.000426828 | gnorm 1.016 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 16261
2022-03-06 17:22:29 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 17:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:23:01 | INFO | train_inner | epoch 058:     11 / 97 loss=4.408, nll_loss=3.173, ppl=9.02, wps=22383.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5500, lr=0.000426401, gnorm=1.003, loss_scale=16, train_wall=262, gb_free=8.1, wall=16292
2022-03-06 17:23:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:27:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:27:11 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 10.08 | nll_loss 9.224 | ppl 597.87 | wps 43029.2 | wpb 510.9 | bsz 1 | num_updates 5585 | best_loss 8.233
2022-03-06 17:27:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5585 updates
2022-03-06 17:27:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 58 @ 5585 updates, score 10.08) (writing took 2.3434729729779065 seconds)
2022-03-06 17:27:13 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 17:27:13 | INFO | train | epoch 058 | loss 4.362 | nll_loss 3.121 | ppl 8.7 | wps 22130.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5585 | lr 0.000423144 | gnorm 1.046 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 16545
2022-03-06 17:27:13 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 17:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:27:56 | INFO | train_inner | epoch 059:     15 / 97 loss=4.354, nll_loss=3.112, ppl=8.65, wps=22164, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=5600, lr=0.000422577, gnorm=1.047, loss_scale=8, train_wall=265, gb_free=8.1, wall=16588
2022-03-06 17:31:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:31:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:31:55 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 10.141 | nll_loss 9.298 | ppl 629.54 | wps 43173.1 | wpb 510.9 | bsz 1 | num_updates 5681 | best_loss 8.233
2022-03-06 17:31:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 5681 updates
2022-03-06 17:31:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:31:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 59 @ 5681 updates, score 10.141) (writing took 2.3415364609099925 seconds)
2022-03-06 17:31:57 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 17:31:57 | INFO | train | epoch 059 | loss 4.308 | nll_loss 3.06 | ppl 8.34 | wps 22132.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5681 | lr 0.000419554 | gnorm 1.036 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 16829
2022-03-06 17:31:57 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 17:31:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:32:52 | INFO | train_inner | epoch 060:     19 / 97 loss=4.291, nll_loss=3.041, ppl=8.23, wps=22158.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=5700, lr=0.000418854, gnorm=1.042, loss_scale=8, train_wall=265, gb_free=8.1, wall=16884
2022-03-06 17:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:36:39 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 10.203 | nll_loss 9.341 | ppl 648.41 | wps 43188.7 | wpb 510.9 | bsz 1 | num_updates 5778 | best_loss 8.233
2022-03-06 17:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 5778 updates
2022-03-06 17:36:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 60 @ 5778 updates, score 10.203) (writing took 2.29435146227479 seconds)
2022-03-06 17:36:42 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 17:36:42 | INFO | train | epoch 060 | loss 4.255 | nll_loss 3 | ppl 8 | wps 22336.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 5778 | lr 0.000416017 | gnorm 1.036 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 17114
2022-03-06 17:36:42 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 17:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:37:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:37:47 | INFO | train_inner | epoch 061:     23 / 97 loss=4.245, nll_loss=2.989, ppl=7.94, wps=22140.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=5800, lr=0.000415227, gnorm=1.023, loss_scale=8, train_wall=265, gb_free=8.1, wall=17179
2022-03-06 17:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:41:24 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 10.23 | nll_loss 9.375 | ppl 663.86 | wps 42810.7 | wpb 510.9 | bsz 1 | num_updates 5874 | best_loss 8.233
2022-03-06 17:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 5874 updates
2022-03-06 17:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 61 @ 5874 updates, score 10.23) (writing took 2.3248349470086396 seconds)
2022-03-06 17:41:26 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 17:41:26 | INFO | train | epoch 061 | loss 4.203 | nll_loss 2.941 | ppl 7.68 | wps 22116.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5874 | lr 0.000412604 | gnorm 1.013 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 17398
2022-03-06 17:41:26 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 17:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:42:40 | INFO | train_inner | epoch 062:     26 / 97 loss=4.185, nll_loss=2.922, ppl=7.58, wps=22357, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=5900, lr=0.000411693, gnorm=1.026, loss_scale=8, train_wall=262, gb_free=8.1, wall=17472
2022-03-06 17:44:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:46:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:08 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 10.342 | nll_loss 9.48 | ppl 713.91 | wps 42762.5 | wpb 510.9 | bsz 1 | num_updates 5970 | best_loss 8.233
2022-03-06 17:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 5970 updates
2022-03-06 17:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 62 @ 5970 updates, score 10.342) (writing took 2.274930441286415 seconds)
2022-03-06 17:46:10 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 17:46:10 | INFO | train | epoch 062 | loss 4.156 | nll_loss 2.889 | ppl 7.41 | wps 22123.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 5970 | lr 0.000409273 | gnorm 1.034 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 17682
2022-03-06 17:46:10 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 17:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:47:36 | INFO | train_inner | epoch 063:     30 / 97 loss=4.139, nll_loss=2.869, ppl=7.31, wps=22169.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=6000, lr=0.000408248, gnorm=1.03, loss_scale=8, train_wall=265, gb_free=8.1, wall=17768
2022-03-06 17:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:50:52 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.391 | nll_loss 9.545 | ppl 747.07 | wps 42823.1 | wpb 510.9 | bsz 1 | num_updates 6067 | best_loss 8.233
2022-03-06 17:50:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6067 updates
2022-03-06 17:50:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:50:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:50:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 63 @ 6067 updates, score 10.391) (writing took 2.348521762061864 seconds)
2022-03-06 17:50:54 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 17:50:54 | INFO | train | epoch 063 | loss 4.11 | nll_loss 2.837 | ppl 7.14 | wps 22370.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6067 | lr 0.000405988 | gnorm 1.039 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 17966
2022-03-06 17:50:54 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 17:50:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:51:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:52:31 | INFO | train_inner | epoch 064:     34 / 97 loss=4.097, nll_loss=2.821, ppl=7.07, wps=22163.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6100, lr=0.000404888, gnorm=1.05, loss_scale=8, train_wall=265, gb_free=8.1, wall=18063
2022-03-06 17:55:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:55:36 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 10.444 | nll_loss 9.588 | ppl 769.76 | wps 43179.9 | wpb 510.9 | bsz 1 | num_updates 6163 | best_loss 8.233
2022-03-06 17:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6163 updates
2022-03-06 17:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:55:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 17:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 64 @ 6163 updates, score 10.444) (writing took 3.2571595939807594 seconds)
2022-03-06 17:55:39 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 17:55:39 | INFO | train | epoch 064 | loss 4.064 | nll_loss 2.785 | ppl 6.89 | wps 22057.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6163 | lr 0.000402813 | gnorm 1.034 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 18251
2022-03-06 17:55:39 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 17:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:57:25 | INFO | train_inner | epoch 065:     37 / 97 loss=4.042, nll_loss=2.76, ppl=6.78, wps=22302.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6200, lr=0.00040161, gnorm=1.023, loss_scale=8, train_wall=262, gb_free=8.1, wall=18357
2022-03-06 17:59:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:00:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:00:21 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.537 | nll_loss 9.692 | ppl 827.32 | wps 42645.2 | wpb 510.9 | bsz 1 | num_updates 6259 | best_loss 8.233
2022-03-06 18:00:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6259 updates
2022-03-06 18:00:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:00:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:00:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 65 @ 6259 updates, score 10.537) (writing took 2.3190606418065727 seconds)
2022-03-06 18:00:23 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 18:00:23 | INFO | train | epoch 065 | loss 4.019 | nll_loss 2.734 | ppl 6.65 | wps 22115.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6259 | lr 0.000399712 | gnorm 1.025 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 18535
2022-03-06 18:00:23 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 18:00:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:02:21 | INFO | train_inner | epoch 066:     41 / 97 loss=4.005, nll_loss=2.718, ppl=6.58, wps=22158.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6300, lr=0.00039841, gnorm=1.036, loss_scale=8, train_wall=265, gb_free=8.1, wall=18652
2022-03-06 18:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:05:05 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.587 | nll_loss 9.75 | ppl 860.84 | wps 42832.6 | wpb 510.9 | bsz 1 | num_updates 6356 | best_loss 8.233
2022-03-06 18:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6356 updates
2022-03-06 18:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 66 @ 6356 updates, score 10.587) (writing took 2.372735104057938 seconds)
2022-03-06 18:05:08 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 18:05:08 | INFO | train | epoch 066 | loss 3.979 | nll_loss 2.689 | ppl 6.45 | wps 22338.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6356 | lr 0.000396651 | gnorm 1.043 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 18820
2022-03-06 18:05:08 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 18:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:06:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:07:16 | INFO | train_inner | epoch 067:     45 / 97 loss=3.96, nll_loss=2.667, ppl=6.35, wps=22139.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6400, lr=0.000395285, gnorm=1.045, loss_scale=8, train_wall=265, gb_free=8.1, wall=18948
2022-03-06 18:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:09:50 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.644 | nll_loss 9.806 | ppl 895.39 | wps 42539.2 | wpb 510.9 | bsz 1 | num_updates 6452 | best_loss 8.233
2022-03-06 18:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6452 updates
2022-03-06 18:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 67 @ 6452 updates, score 10.644) (writing took 2.3412030092440546 seconds)
2022-03-06 18:09:52 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 18:09:52 | INFO | train | epoch 067 | loss 3.934 | nll_loss 2.638 | ppl 6.22 | wps 22127.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6452 | lr 0.000393689 | gnorm 1.04 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 19104
2022-03-06 18:09:52 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 18:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:12:09 | INFO | train_inner | epoch 068:     48 / 97 loss=3.917, nll_loss=2.619, ppl=6.14, wps=22369.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6500, lr=0.000392232, gnorm=1.03, loss_scale=8, train_wall=262, gb_free=8.1, wall=19241
2022-03-06 18:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:14:34 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.674 | nll_loss 9.838 | ppl 915.2 | wps 42995.3 | wpb 510.9 | bsz 1 | num_updates 6549 | best_loss 8.233
2022-03-06 18:14:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6549 updates
2022-03-06 18:14:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:14:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:14:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 68 @ 6549 updates, score 10.674) (writing took 2.3287672461010516 seconds)
2022-03-06 18:14:36 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 18:14:36 | INFO | train | epoch 068 | loss 3.897 | nll_loss 2.596 | ppl 6.05 | wps 22358.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6549 | lr 0.000390762 | gnorm 1.04 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 19388
2022-03-06 18:14:36 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 18:14:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:14:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:17:05 | INFO | train_inner | epoch 069:     52 / 97 loss=3.878, nll_loss=2.574, ppl=5.96, wps=22165.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=6600, lr=0.000389249, gnorm=1.045, loss_scale=8, train_wall=265, gb_free=8.1, wall=19537
2022-03-06 18:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:19:18 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.78 | nll_loss 9.941 | ppl 982.91 | wps 43098.4 | wpb 510.9 | bsz 1 | num_updates 6645 | best_loss 8.233
2022-03-06 18:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 6645 updates
2022-03-06 18:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:19:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 69 @ 6645 updates, score 10.78) (writing took 2.312865105923265 seconds)
2022-03-06 18:19:20 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 18:19:20 | INFO | train | epoch 069 | loss 3.857 | nll_loss 2.551 | ppl 5.86 | wps 22135.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6645 | lr 0.000387929 | gnorm 1.031 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 19672
2022-03-06 18:19:20 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 18:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:21:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:22:00 | INFO | train_inner | epoch 070:     56 / 97 loss=3.839, nll_loss=2.53, ppl=5.78, wps=22167.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=6700, lr=0.000386334, gnorm=1.035, loss_scale=8, train_wall=265, gb_free=8.1, wall=19832
2022-03-06 18:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:24:02 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.824 | nll_loss 9.998 | ppl 1022.38 | wps 42287.2 | wpb 510.9 | bsz 1 | num_updates 6741 | best_loss 8.233
2022-03-06 18:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 6741 updates
2022-03-06 18:24:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:24:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 70 @ 6741 updates, score 10.824) (writing took 2.326155328191817 seconds)
2022-03-06 18:24:04 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 18:24:04 | INFO | train | epoch 070 | loss 3.821 | nll_loss 2.51 | ppl 5.69 | wps 22125.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6741 | lr 0.000385157 | gnorm 1.035 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 19956
2022-03-06 18:24:04 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 18:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:26:53 | INFO | train_inner | epoch 071:     59 / 97 loss=3.801, nll_loss=2.488, ppl=5.61, wps=22386.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=6800, lr=0.000383482, gnorm=1.018, loss_scale=8, train_wall=262, gb_free=8.1, wall=20125
2022-03-06 18:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:28:46 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.872 | nll_loss 10.026 | ppl 1042.62 | wps 43131.3 | wpb 510.9 | bsz 1 | num_updates 6838 | best_loss 8.233
2022-03-06 18:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 6838 updates
2022-03-06 18:28:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 71 @ 6838 updates, score 10.872) (writing took 2.378428746946156 seconds)
2022-03-06 18:28:48 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 18:28:48 | INFO | train | epoch 071 | loss 3.786 | nll_loss 2.471 | ppl 5.55 | wps 22366.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 6838 | lr 0.000382415 | gnorm 1.022 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 20240
2022-03-06 18:28:48 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 18:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:29:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:31:48 | INFO | train_inner | epoch 072:     63 / 97 loss=3.762, nll_loss=2.444, ppl=5.44, wps=22157.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=6900, lr=0.000380693, gnorm=1.028, loss_scale=8, train_wall=265, gb_free=8.1, wall=20420
2022-03-06 18:33:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:33:30 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.911 | nll_loss 10.075 | ppl 1078.36 | wps 43272 | wpb 510.9 | bsz 1 | num_updates 6934 | best_loss 8.233
2022-03-06 18:33:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 6934 updates
2022-03-06 18:33:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 72 @ 6934 updates, score 10.911) (writing took 2.303197065833956 seconds)
2022-03-06 18:33:32 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 18:33:32 | INFO | train | epoch 072 | loss 3.749 | nll_loss 2.429 | ppl 5.38 | wps 22135.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 6934 | lr 0.000379759 | gnorm 1.027 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 20524
2022-03-06 18:33:32 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 18:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:36:44 | INFO | train_inner | epoch 073:     67 / 97 loss=3.729, nll_loss=2.407, ppl=5.3, wps=22156.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7000, lr=0.000377964, gnorm=1.029, loss_scale=8, train_wall=265, gb_free=8.1, wall=20716
2022-03-06 18:38:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:38:14 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.992 | nll_loss 10.158 | ppl 1142.55 | wps 42884.6 | wpb 510.9 | bsz 1 | num_updates 7030 | best_loss 8.233
2022-03-06 18:38:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7030 updates
2022-03-06 18:38:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:38:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 73 @ 7030 updates, score 10.992) (writing took 2.6358401593752205 seconds)
2022-03-06 18:38:17 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 18:38:17 | INFO | train | epoch 073 | loss 3.715 | nll_loss 2.391 | ppl 5.25 | wps 22080.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7030 | lr 0.000377157 | gnorm 1.032 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 20809
2022-03-06 18:38:17 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 18:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:37 | INFO | train_inner | epoch 074:     70 / 97 loss=3.693, nll_loss=2.366, ppl=5.15, wps=22328.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7100, lr=0.000375293, gnorm=1.022, loss_scale=8, train_wall=262, gb_free=8.1, wall=21009
2022-03-06 18:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:42:59 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.994 | nll_loss 10.172 | ppl 1153.85 | wps 43052.8 | wpb 510.9 | bsz 1 | num_updates 7127 | best_loss 8.233
2022-03-06 18:42:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7127 updates
2022-03-06 18:42:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 74 @ 7127 updates, score 10.994) (writing took 2.457209578715265 seconds)
2022-03-06 18:43:02 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 18:43:02 | INFO | train | epoch 074 | loss 3.685 | nll_loss 2.357 | ppl 5.12 | wps 22335.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7127 | lr 0.000374582 | gnorm 1.027 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 21093
2022-03-06 18:43:02 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 18:43:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:30 | INFO | train_inner | epoch 075:     73 / 97 loss=3.664, nll_loss=2.333, ppl=5.04, wps=22356.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7200, lr=0.000372678, gnorm=1.026, loss_scale=16, train_wall=262, gb_free=8.1, wall=21302
2022-03-06 18:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:47:43 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 11.121 | nll_loss 10.3 | ppl 1260.54 | wps 42724.9 | wpb 510.9 | bsz 1 | num_updates 7224 | best_loss 8.233
2022-03-06 18:47:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7224 updates
2022-03-06 18:47:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 75 @ 7224 updates, score 11.121) (writing took 2.4205192453227937 seconds)
2022-03-06 18:47:46 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 18:47:46 | INFO | train | epoch 075 | loss 3.654 | nll_loss 2.322 | ppl 5 | wps 22341.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7224 | lr 0.000372058 | gnorm 1.023 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 21378
2022-03-06 18:47:46 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 18:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:48:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:49:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:51:33 | INFO | train_inner | epoch 076:     78 / 97 loss=3.632, nll_loss=2.297, ppl=4.91, wps=21639.9, ups=0.33, wpb=65495, bsz=127.9, num_updates=7300, lr=0.000370117, gnorm=1.026, loss_scale=8, train_wall=270, gb_free=8.1, wall=21605
2022-03-06 18:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:32 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 11.115 | nll_loss 10.288 | ppl 1249.89 | wps 42866.6 | wpb 510.9 | bsz 1 | num_updates 7319 | best_loss 8.233
2022-03-06 18:52:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7319 updates
2022-03-06 18:52:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 76 @ 7319 updates, score 11.115) (writing took 2.6361551112495363 seconds)
2022-03-06 18:52:35 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 18:52:35 | INFO | train | epoch 076 | loss 3.621 | nll_loss 2.284 | ppl 4.87 | wps 21551.4 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 7319 | lr 0.000369636 | gnorm 1.025 | loss_scale 8 | train_wall 257 | gb_free 8.1 | wall 21666
2022-03-06 18:52:35 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 18:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 18:56:29 | INFO | train_inner | epoch 077:     82 / 97 loss=3.597, nll_loss=2.257, ppl=4.78, wps=22078.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7400, lr=0.000367607, gnorm=1.036, loss_scale=8, train_wall=265, gb_free=8.1, wall=21901
2022-03-06 18:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:57:17 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.223 | nll_loss 10.412 | ppl 1362.29 | wps 42948.6 | wpb 510.9 | bsz 1 | num_updates 7415 | best_loss 8.233
2022-03-06 18:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7415 updates
2022-03-06 18:57:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:57:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 18:57:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 77 @ 7415 updates, score 11.223) (writing took 2.458331936970353 seconds)
2022-03-06 18:57:20 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 18:57:20 | INFO | train | epoch 077 | loss 3.591 | nll_loss 2.251 | ppl 4.76 | wps 22059.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7415 | lr 0.000367235 | gnorm 1.038 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 21951
2022-03-06 18:57:20 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 18:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:01:23 | INFO | train_inner | epoch 078:     85 / 97 loss=3.572, nll_loss=2.229, ppl=4.69, wps=22320.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7500, lr=0.000365148, gnorm=1.039, loss_scale=8, train_wall=263, gb_free=8.1, wall=22195
2022-03-06 19:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:02:02 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.262 | nll_loss 10.446 | ppl 1394.49 | wps 42338.6 | wpb 510.9 | bsz 1 | num_updates 7512 | best_loss 8.233
2022-03-06 19:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 7512 updates
2022-03-06 19:02:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 78 @ 7512 updates, score 11.262) (writing took 2.653411435894668 seconds)
2022-03-06 19:02:05 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 19:02:05 | INFO | train | epoch 078 | loss 3.564 | nll_loss 2.22 | ppl 4.66 | wps 22275.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7512 | lr 0.000364857 | gnorm 1.039 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 22237
2022-03-06 19:02:05 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 19:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:03:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:06:19 | INFO | train_inner | epoch 079:     89 / 97 loss=3.541, nll_loss=2.194, ppl=4.58, wps=22076.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=7600, lr=0.000362738, gnorm=1.031, loss_scale=8, train_wall=265, gb_free=8.1, wall=22491
2022-03-06 19:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:06:47 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.275 | nll_loss 10.455 | ppl 1403.73 | wps 42766.3 | wpb 510.9 | bsz 1 | num_updates 7608 | best_loss 8.233
2022-03-06 19:06:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 7608 updates
2022-03-06 19:06:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:06:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:06:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 79 @ 7608 updates, score 11.275) (writing took 2.357550655025989 seconds)
2022-03-06 19:06:50 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 19:06:50 | INFO | train | epoch 079 | loss 3.533 | nll_loss 2.186 | ppl 4.55 | wps 22071.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7608 | lr 0.000362547 | gnorm 1.026 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 22521
2022-03-06 19:06:50 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 19:06:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:11:13 | INFO | train_inner | epoch 080:     92 / 97 loss=3.514, nll_loss=2.164, ppl=4.48, wps=22340, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=7700, lr=0.000360375, gnorm=1.022, loss_scale=16, train_wall=262, gb_free=8.1, wall=22784
2022-03-06 19:11:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:11:32 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.346 | nll_loss 10.534 | ppl 1482.77 | wps 42913.8 | wpb 510.9 | bsz 1 | num_updates 7705 | best_loss 8.233
2022-03-06 19:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 7705 updates
2022-03-06 19:11:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 80 @ 7705 updates, score 11.346) (writing took 2.408616235014051 seconds)
2022-03-06 19:11:34 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 19:11:34 | INFO | train | epoch 080 | loss 3.51 | nll_loss 2.16 | ppl 4.47 | wps 22320.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7705 | lr 0.000360258 | gnorm 1.025 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 22806
2022-03-06 19:11:34 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 19:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:15:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:16:08 | INFO | train_inner | epoch 081:     96 / 97 loss=3.486, nll_loss=2.132, ppl=4.38, wps=22161.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=7800, lr=0.000358057, gnorm=1.025, loss_scale=8, train_wall=265, gb_free=8.1, wall=23080
2022-03-06 19:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:16:16 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.325 | nll_loss 10.508 | ppl 1455.88 | wps 42986.2 | wpb 510.9 | bsz 1 | num_updates 7801 | best_loss 8.233
2022-03-06 19:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 7801 updates
2022-03-06 19:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:16:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 81 @ 7801 updates, score 11.325) (writing took 2.4817766593769193 seconds)
2022-03-06 19:16:18 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 19:16:18 | INFO | train | epoch 081 | loss 3.482 | nll_loss 2.128 | ppl 4.37 | wps 22124.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7801 | lr 0.000358034 | gnorm 1.026 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 23090
2022-03-06 19:16:18 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 19:16:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:21:01 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.418 | nll_loss 10.614 | ppl 1566.98 | wps 39823.4 | wpb 510.9 | bsz 1 | num_updates 7898 | best_loss 8.233
2022-03-06 19:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 7898 updates
2022-03-06 19:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:21:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 82 @ 7898 updates, score 11.418) (writing took 2.445324143860489 seconds)
2022-03-06 19:21:03 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 19:21:03 | INFO | train | epoch 082 | loss 3.457 | nll_loss 2.1 | ppl 4.29 | wps 22281.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 7898 | lr 0.000355829 | gnorm 1.01 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 23375
2022-03-06 19:21:04 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 19:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:21:10 | INFO | train_inner | epoch 083:      2 / 97 loss=3.455, nll_loss=2.098, ppl=4.28, wps=21716.7, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=7900, lr=0.000355784, gnorm=1.009, loss_scale=8, train_wall=262, gb_free=8.1, wall=23381
2022-03-06 19:24:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:25:46 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.461 | nll_loss 10.657 | ppl 1614.71 | wps 42918.2 | wpb 510.9 | bsz 1 | num_updates 7994 | best_loss 8.233
2022-03-06 19:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 7994 updates
2022-03-06 19:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:25:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 83 @ 7994 updates, score 11.461) (writing took 2.543444545008242 seconds)
2022-03-06 19:25:49 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 19:25:49 | INFO | train | epoch 083 | loss 3.432 | nll_loss 2.072 | ppl 4.2 | wps 22035.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 7994 | lr 0.000353686 | gnorm 1.029 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 23661
2022-03-06 19:25:49 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 19:25:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:26:06 | INFO | train_inner | epoch 084:      6 / 97 loss=3.428, nll_loss=2.067, ppl=4.19, wps=22086.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8000, lr=0.000353553, gnorm=1.032, loss_scale=8, train_wall=265, gb_free=8.1, wall=23678
2022-03-06 19:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:30:31 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.434 | nll_loss 10.626 | ppl 1580.55 | wps 43037.5 | wpb 510.9 | bsz 1 | num_updates 8091 | best_loss 8.233
2022-03-06 19:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8091 updates
2022-03-06 19:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:30:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:30:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 84 @ 8091 updates, score 11.434) (writing took 2.606105408165604 seconds)
2022-03-06 19:30:34 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 19:30:34 | INFO | train | epoch 084 | loss 3.408 | nll_loss 2.044 | ppl 4.13 | wps 22282.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8091 | lr 0.00035156 | gnorm 1.032 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 23946
2022-03-06 19:30:34 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 19:30:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:00 | INFO | train_inner | epoch 085:      9 / 97 loss=3.404, nll_loss=2.04, ppl=4.11, wps=22299.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8100, lr=0.000351364, gnorm=1.025, loss_scale=16, train_wall=263, gb_free=8.1, wall=23972
2022-03-06 19:32:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:35:16 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.479 | nll_loss 10.674 | ppl 1634.11 | wps 42681.2 | wpb 510.9 | bsz 1 | num_updates 8187 | best_loss 8.233
2022-03-06 19:35:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8187 updates
2022-03-06 19:35:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:35:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 85 @ 8187 updates, score 11.479) (writing took 2.655420572962612 seconds)
2022-03-06 19:35:19 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 19:35:19 | INFO | train | epoch 085 | loss 3.383 | nll_loss 2.018 | ppl 4.05 | wps 22050 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8187 | lr 0.000349492 | gnorm 1.018 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 24231
2022-03-06 19:35:19 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 19:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:35:56 | INFO | train_inner | epoch 086:     13 / 97 loss=3.376, nll_loss=2.01, ppl=4.03, wps=22079.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8200, lr=0.000349215, gnorm=1.021, loss_scale=8, train_wall=265, gb_free=8.1, wall=24268
2022-03-06 19:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:01 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.562 | nll_loss 10.755 | ppl 1728.5 | wps 43208 | wpb 510.9 | bsz 1 | num_updates 8284 | best_loss 8.233
2022-03-06 19:40:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8284 updates
2022-03-06 19:40:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:40:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 86 @ 8284 updates, score 11.562) (writing took 2.405317662283778 seconds)
2022-03-06 19:40:04 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 19:40:04 | INFO | train | epoch 086 | loss 3.362 | nll_loss 1.993 | ppl 3.98 | wps 22301.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8284 | lr 0.00034744 | gnorm 1.019 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 24516
2022-03-06 19:40:04 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 19:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:40:50 | INFO | train_inner | epoch 087:     16 / 97 loss=3.358, nll_loss=1.989, ppl=3.97, wps=22330.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8300, lr=0.000347105, gnorm=1.013, loss_scale=16, train_wall=263, gb_free=8.1, wall=24562
2022-03-06 19:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 19:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:44:46 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.571 | nll_loss 10.778 | ppl 1755.97 | wps 42852.1 | wpb 510.9 | bsz 1 | num_updates 8380 | best_loss 8.233
2022-03-06 19:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8380 updates
2022-03-06 19:44:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 87 @ 8380 updates, score 11.571) (writing took 2.4381906990893185 seconds)
2022-03-06 19:44:48 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 19:44:48 | INFO | train | epoch 087 | loss 3.34 | nll_loss 1.969 | ppl 3.91 | wps 22097.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8380 | lr 0.000345444 | gnorm 1.014 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 24800
2022-03-06 19:44:48 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 19:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:45:46 | INFO | train_inner | epoch 088:     20 / 97 loss=3.332, nll_loss=1.96, ppl=3.89, wps=22126.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8400, lr=0.000345033, gnorm=1.023, loss_scale=8, train_wall=265, gb_free=8.1, wall=24858
2022-03-06 19:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:49:31 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.624 | nll_loss 10.813 | ppl 1799.56 | wps 42577.6 | wpb 510.9 | bsz 1 | num_updates 8477 | best_loss 8.233
2022-03-06 19:49:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 8477 updates
2022-03-06 19:49:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:49:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:49:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 88 @ 8477 updates, score 11.624) (writing took 2.364217343274504 seconds)
2022-03-06 19:49:33 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 19:49:33 | INFO | train | epoch 088 | loss 3.317 | nll_loss 1.944 | ppl 3.85 | wps 22329.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8477 | lr 0.000343462 | gnorm 1.028 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 25085
2022-03-06 19:49:33 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 19:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:50:39 | INFO | train_inner | epoch 089:     23 / 97 loss=3.312, nll_loss=1.937, ppl=3.83, wps=22351.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8500, lr=0.000342997, gnorm=1.022, loss_scale=16, train_wall=262, gb_free=8.1, wall=25151
2022-03-06 19:54:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:54:15 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.594 | nll_loss 10.785 | ppl 1765.03 | wps 42820 | wpb 510.9 | bsz 1 | num_updates 8574 | best_loss 8.233
2022-03-06 19:54:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 8574 updates
2022-03-06 19:54:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 89 @ 8574 updates, score 11.594) (writing took 2.6438577421940863 seconds)
2022-03-06 19:54:18 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 19:54:18 | INFO | train | epoch 089 | loss 3.298 | nll_loss 1.922 | ppl 3.79 | wps 22299 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 8574 | lr 0.000341514 | gnorm 1.008 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 25370
2022-03-06 19:54:18 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 19:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:55:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:55:35 | INFO | train_inner | epoch 090:     27 / 97 loss=3.29, nll_loss=1.913, ppl=3.77, wps=22094.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=8600, lr=0.000340997, gnorm=1.002, loss_scale=16, train_wall=265, gb_free=8.1, wall=25447
2022-03-06 19:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:59:00 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.705 | nll_loss 10.903 | ppl 1915.29 | wps 42139.3 | wpb 510.9 | bsz 1 | num_updates 8670 | best_loss 8.233
2022-03-06 19:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 8670 updates
2022-03-06 19:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:59:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 19:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 90 @ 8670 updates, score 11.705) (writing took 2.4781799581833184 seconds)
2022-03-06 19:59:03 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 19:59:03 | INFO | train | epoch 090 | loss 3.276 | nll_loss 1.897 | ppl 3.72 | wps 22052.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8670 | lr 0.000339618 | gnorm 1.014 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 25655
2022-03-06 19:59:03 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 19:59:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:29 | INFO | train_inner | epoch 091:     30 / 97 loss=3.269, nll_loss=1.89, ppl=3.71, wps=22295.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=8700, lr=0.000339032, gnorm=1.015, loss_scale=16, train_wall=263, gb_free=8.1, wall=25741
2022-03-06 20:01:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:03:45 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.718 | nll_loss 10.925 | ppl 1944.52 | wps 42441 | wpb 510.9 | bsz 1 | num_updates 8766 | best_loss 8.233
2022-03-06 20:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 8766 updates
2022-03-06 20:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:03:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 91 @ 8766 updates, score 11.718) (writing took 2.5970397079363465 seconds)
2022-03-06 20:03:48 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 20:03:48 | INFO | train | epoch 091 | loss 3.257 | nll_loss 1.876 | ppl 3.67 | wps 22046.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8766 | lr 0.000337753 | gnorm 1.008 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 25940
2022-03-06 20:03:48 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 20:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:26 | INFO | train_inner | epoch 092:     34 / 97 loss=3.25, nll_loss=1.868, ppl=3.65, wps=22074.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=8800, lr=0.0003371, gnorm=1.007, loss_scale=16, train_wall=265, gb_free=8.1, wall=26037
2022-03-06 20:07:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:08:31 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 11.714 | nll_loss 10.917 | ppl 1933.14 | wps 42778.2 | wpb 510.9 | bsz 1 | num_updates 8862 | best_loss 8.233
2022-03-06 20:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 8862 updates
2022-03-06 20:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:08:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:08:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 92 @ 8862 updates, score 11.714) (writing took 2.3932842798531055 seconds)
2022-03-06 20:08:33 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 20:08:33 | INFO | train | epoch 092 | loss 3.237 | nll_loss 1.854 | ppl 3.62 | wps 22063.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8862 | lr 0.000335919 | gnorm 1.013 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 26225
2022-03-06 20:08:33 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 20:08:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:09:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:10:25 | INFO | train_inner | epoch 093:     39 / 97 loss=3.23, nll_loss=1.845, ppl=3.59, wps=21902.5, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=8900, lr=0.000335201, gnorm=1.014, loss_scale=8, train_wall=268, gb_free=8.1, wall=26336
2022-03-06 20:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:13:15 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 11.745 | nll_loss 10.948 | ppl 1976.08 | wps 42620.8 | wpb 510.9 | bsz 1 | num_updates 8958 | best_loss 8.233
2022-03-06 20:13:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 8958 updates
2022-03-06 20:13:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 93 @ 8958 updates, score 11.745) (writing took 2.40207513095811 seconds)
2022-03-06 20:13:18 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 20:13:18 | INFO | train | epoch 093 | loss 3.219 | nll_loss 1.834 | ppl 3.56 | wps 22089.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 8958 | lr 0.000334114 | gnorm 1.014 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 26510
2022-03-06 20:13:18 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 20:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:18 | INFO | train_inner | epoch 094:     42 / 97 loss=3.209, nll_loss=1.823, ppl=3.54, wps=22336.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=9000, lr=0.000333333, gnorm=1.014, loss_scale=8, train_wall=262, gb_free=8.1, wall=26630
2022-03-06 20:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:18:00 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 11.779 | nll_loss 10.983 | ppl 2024.09 | wps 42605.9 | wpb 510.9 | bsz 1 | num_updates 9055 | best_loss 8.233
2022-03-06 20:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9055 updates
2022-03-06 20:18:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:18:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 94 @ 9055 updates, score 11.779) (writing took 2.4677468026056886 seconds)
2022-03-06 20:18:02 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 20:18:02 | INFO | train | epoch 094 | loss 3.202 | nll_loss 1.815 | ppl 3.52 | wps 22324.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9055 | lr 0.000332319 | gnorm 1.013 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 26794
2022-03-06 20:18:02 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 20:18:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:20:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:20:14 | INFO | train_inner | epoch 095:     46 / 97 loss=3.196, nll_loss=1.808, ppl=3.5, wps=22121, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9100, lr=0.000331497, gnorm=1.017, loss_scale=8, train_wall=265, gb_free=8.1, wall=26926
2022-03-06 20:22:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:22:45 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 11.789 | nll_loss 10.998 | ppl 2044.54 | wps 42738.8 | wpb 510.9 | bsz 1 | num_updates 9151 | best_loss 8.233
2022-03-06 20:22:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9151 updates
2022-03-06 20:22:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:22:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 95 @ 9151 updates, score 11.789) (writing took 2.6352854557335377 seconds)
2022-03-06 20:22:47 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 20:22:47 | INFO | train | epoch 095 | loss 3.182 | nll_loss 1.792 | ppl 3.46 | wps 22045.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9151 | lr 0.000330572 | gnorm 1.008 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 27079
2022-03-06 20:22:47 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 20:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:25:08 | INFO | train_inner | epoch 096:     49 / 97 loss=3.174, nll_loss=1.783, ppl=3.44, wps=22293.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=9200, lr=0.00032969, gnorm=1.004, loss_scale=8, train_wall=263, gb_free=8.1, wall=27219
2022-03-06 20:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:27:30 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 11.849 | nll_loss 11.061 | ppl 2136.48 | wps 42723.8 | wpb 510.9 | bsz 1 | num_updates 9248 | best_loss 8.233
2022-03-06 20:27:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9248 updates
2022-03-06 20:27:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 96 @ 9248 updates, score 11.849) (writing took 2.5642723608762026 seconds)
2022-03-06 20:27:33 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 20:27:33 | INFO | train | epoch 096 | loss 3.167 | nll_loss 1.775 | ppl 3.42 | wps 22282.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9248 | lr 0.000328834 | gnorm 1.012 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 27364
2022-03-06 20:27:33 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 20:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:30:02 | INFO | train_inner | epoch 097:     52 / 97 loss=3.158, nll_loss=1.766, ppl=3.4, wps=22281, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9300, lr=0.000327913, gnorm=1.004, loss_scale=16, train_wall=263, gb_free=8.1, wall=27513
2022-03-06 20:31:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:15 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 11.908 | nll_loss 11.133 | ppl 2246.2 | wps 41879 | wpb 510.9 | bsz 1 | num_updates 9344 | best_loss 8.233
2022-03-06 20:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9344 updates
2022-03-06 20:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 97 @ 9344 updates, score 11.908) (writing took 2.6226547467522323 seconds)
2022-03-06 20:32:18 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 20:32:18 | INFO | train | epoch 097 | loss 3.148 | nll_loss 1.754 | ppl 3.37 | wps 22024.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9344 | lr 0.00032714 | gnorm 1.003 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 27650
2022-03-06 20:32:18 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 20:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:34:58 | INFO | train_inner | epoch 098:     56 / 97 loss=3.141, nll_loss=1.747, ppl=3.36, wps=22063.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9400, lr=0.000326164, gnorm=1.01, loss_scale=8, train_wall=265, gb_free=8.1, wall=27810
2022-03-06 20:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:37:01 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 11.925 | nll_loss 11.154 | ppl 2278.68 | wps 42441.2 | wpb 510.9 | bsz 1 | num_updates 9441 | best_loss 8.233
2022-03-06 20:37:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 9441 updates
2022-03-06 20:37:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:37:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:37:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 98 @ 9441 updates, score 11.925) (writing took 2.6528735579922795 seconds)
2022-03-06 20:37:03 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 20:37:03 | INFO | train | epoch 098 | loss 3.132 | nll_loss 1.736 | ppl 3.33 | wps 22260.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9441 | lr 0.000325455 | gnorm 0.999 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 27935
2022-03-06 20:37:03 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 20:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:39:52 | INFO | train_inner | epoch 099:     59 / 97 loss=3.12, nll_loss=1.723, ppl=3.3, wps=22277.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=9500, lr=0.000324443, gnorm=1.006, loss_scale=16, train_wall=263, gb_free=8.1, wall=28104
2022-03-06 20:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:41:46 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 11.897 | nll_loss 11.112 | ppl 2214.02 | wps 43088.9 | wpb 510.9 | bsz 1 | num_updates 9538 | best_loss 8.233
2022-03-06 20:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 9538 updates
2022-03-06 20:41:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:41:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:41:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 99 @ 9538 updates, score 11.897) (writing took 2.4946473883464932 seconds)
2022-03-06 20:41:48 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 20:41:48 | INFO | train | epoch 099 | loss 3.117 | nll_loss 1.72 | ppl 3.29 | wps 22302.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9538 | lr 0.000323796 | gnorm 1.016 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 28220
2022-03-06 20:41:48 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 20:41:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:44:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:44:48 | INFO | train_inner | epoch 100:     63 / 97 loss=3.109, nll_loss=1.711, ppl=3.27, wps=22134.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9600, lr=0.000322749, gnorm=1.01, loss_scale=16, train_wall=265, gb_free=8.1, wall=28400
2022-03-06 20:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:46:30 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 11.952 | nll_loss 11.167 | ppl 2299.92 | wps 42656.5 | wpb 510.9 | bsz 1 | num_updates 9634 | best_loss 8.233
2022-03-06 20:46:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 9634 updates
2022-03-06 20:46:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:46:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:46:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 100 @ 9634 updates, score 11.952) (writing took 2.501389896031469 seconds)
2022-03-06 20:46:33 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 20:46:33 | INFO | train | epoch 100 | loss 3.099 | nll_loss 1.7 | ppl 3.25 | wps 22096.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9634 | lr 0.000322179 | gnorm 1.014 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 28505
2022-03-06 20:46:33 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 20:46:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:49:44 | INFO | train_inner | epoch 101:     67 / 97 loss=3.088, nll_loss=1.687, ppl=3.22, wps=22135.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9700, lr=0.000321081, gnorm=1.013, loss_scale=8, train_wall=265, gb_free=8.1, wall=28696
2022-03-06 20:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:51:15 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 11.962 | nll_loss 11.183 | ppl 2324.65 | wps 42553.3 | wpb 510.9 | bsz 1 | num_updates 9730 | best_loss 8.233
2022-03-06 20:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 9730 updates
2022-03-06 20:51:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:51:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:51:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 101 @ 9730 updates, score 11.962) (writing took 2.386930054984987 seconds)
2022-03-06 20:51:17 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 20:51:17 | INFO | train | epoch 101 | loss 3.084 | nll_loss 1.684 | ppl 3.21 | wps 22111.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9730 | lr 0.000320585 | gnorm 1.009 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 28789
2022-03-06 20:51:17 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 20:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:54:37 | INFO | train_inner | epoch 102:     70 / 97 loss=3.079, nll_loss=1.678, ppl=3.2, wps=22338.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=9800, lr=0.000319438, gnorm=1.016, loss_scale=8, train_wall=262, gb_free=8.1, wall=28989
2022-03-06 20:55:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 20:55:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:56:00 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 11.942 | nll_loss 11.167 | ppl 2299.39 | wps 42619.1 | wpb 510.9 | bsz 1 | num_updates 9826 | best_loss 8.233
2022-03-06 20:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 9826 updates
2022-03-06 20:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:56:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 20:56:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 102 @ 9826 updates, score 11.942) (writing took 2.647000038996339 seconds)
2022-03-06 20:56:02 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 20:56:02 | INFO | train | epoch 102 | loss 3.069 | nll_loss 1.667 | ppl 3.18 | wps 22052 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 9826 | lr 0.000319015 | gnorm 1.013 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 29074
2022-03-06 20:56:02 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 20:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:59:34 | INFO | train_inner | epoch 103:     74 / 97 loss=3.059, nll_loss=1.656, ppl=3.15, wps=22069.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=9900, lr=0.000317821, gnorm=0.998, loss_scale=8, train_wall=265, gb_free=8.1, wall=29286
2022-03-06 21:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:00:45 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.044 | nll_loss 11.274 | ppl 2476.12 | wps 42468.1 | wpb 510.9 | bsz 1 | num_updates 9923 | best_loss 8.233
2022-03-06 21:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 9923 updates
2022-03-06 21:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 103 @ 9923 updates, score 12.044) (writing took 2.610102484934032 seconds)
2022-03-06 21:00:48 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 21:00:48 | INFO | train | epoch 103 | loss 3.056 | nll_loss 1.652 | ppl 3.14 | wps 22263.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 9923 | lr 0.000317452 | gnorm 0.997 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 29359
2022-03-06 21:00:48 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 21:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:04:31 | INFO | train_inner | epoch 104:     78 / 97 loss=3.048, nll_loss=1.644, ppl=3.13, wps=22063.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10000, lr=0.000316228, gnorm=0.996, loss_scale=8, train_wall=265, gb_free=8.1, wall=29583
2022-03-06 21:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:05:30 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.025 | nll_loss 11.249 | ppl 2433.73 | wps 42665.6 | wpb 510.9 | bsz 1 | num_updates 10019 | best_loss 8.233
2022-03-06 21:05:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10019 updates
2022-03-06 21:05:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:05:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 104 @ 10019 updates, score 12.025) (writing took 2.6602475130930543 seconds)
2022-03-06 21:05:33 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 21:05:33 | INFO | train | epoch 104 | loss 3.042 | nll_loss 1.637 | ppl 3.11 | wps 22032.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10019 | lr 0.000315928 | gnorm 0.995 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 29645
2022-03-06 21:05:33 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 21:05:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:25 | INFO | train_inner | epoch 105:     81 / 97 loss=3.03, nll_loss=1.623, ppl=3.08, wps=22292.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=10100, lr=0.000314658, gnorm=1.004, loss_scale=8, train_wall=263, gb_free=8.1, wall=29877
2022-03-06 21:10:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:10:15 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.08 | nll_loss 11.307 | ppl 2532.95 | wps 42673.8 | wpb 510.9 | bsz 1 | num_updates 10116 | best_loss 8.233
2022-03-06 21:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10116 updates
2022-03-06 21:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:10:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:10:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 105 @ 10116 updates, score 12.08) (writing took 2.4392031240276992 seconds)
2022-03-06 21:10:18 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 21:10:18 | INFO | train | epoch 105 | loss 3.028 | nll_loss 1.621 | ppl 3.08 | wps 22290 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10116 | lr 0.000314409 | gnorm 1 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 29930
2022-03-06 21:10:18 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 21:10:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:14:18 | INFO | train_inner | epoch 106:     84 / 97 loss=3.018, nll_loss=1.611, ppl=3.05, wps=22342.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10200, lr=0.000313112, gnorm=0.998, loss_scale=16, train_wall=262, gb_free=8.1, wall=30170
2022-03-06 21:14:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:15:00 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.068 | nll_loss 11.296 | ppl 2514.75 | wps 42847.6 | wpb 510.9 | bsz 1 | num_updates 10213 | best_loss 8.233
2022-03-06 21:15:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10213 updates
2022-03-06 21:15:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:15:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:15:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 106 @ 10213 updates, score 12.068) (writing took 2.3781514717265964 seconds)
2022-03-06 21:15:02 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 21:15:02 | INFO | train | epoch 106 | loss 3.012 | nll_loss 1.604 | ppl 3.04 | wps 22339.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10213 | lr 0.000312913 | gnorm 0.994 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 30214
2022-03-06 21:15:02 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 21:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:16:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:19:14 | INFO | train_inner | epoch 107:     88 / 97 loss=3.002, nll_loss=1.593, ppl=3.02, wps=22147.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10300, lr=0.000311588, gnorm=0.996, loss_scale=16, train_wall=265, gb_free=8.1, wall=30465
2022-03-06 21:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:19:44 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.158 | nll_loss 11.391 | ppl 2685.5 | wps 43338.4 | wpb 510.9 | bsz 1 | num_updates 10309 | best_loss 8.233
2022-03-06 21:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10309 updates
2022-03-06 21:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 107 @ 10309 updates, score 12.158) (writing took 2.6535681933164597 seconds)
2022-03-06 21:19:47 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 21:19:47 | INFO | train | epoch 107 | loss 2.999 | nll_loss 1.59 | ppl 3.01 | wps 22097.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10309 | lr 0.000311452 | gnorm 1.001 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 30499
2022-03-06 21:19:47 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 21:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:24:10 | INFO | train_inner | epoch 108:     92 / 97 loss=2.988, nll_loss=1.578, ppl=2.98, wps=22113.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10400, lr=0.000310087, gnorm=0.998, loss_scale=16, train_wall=265, gb_free=8.1, wall=30762
2022-03-06 21:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:24:29 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.092 | nll_loss 11.316 | ppl 2548.62 | wps 41372.1 | wpb 510.9 | bsz 1 | num_updates 10405 | best_loss 8.233
2022-03-06 21:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 10405 updates
2022-03-06 21:24:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:24:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 108 @ 10405 updates, score 12.092) (writing took 2.4882476152852178 seconds)
2022-03-06 21:24:32 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 21:24:32 | INFO | train | epoch 108 | loss 2.986 | nll_loss 1.575 | ppl 2.98 | wps 22069.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10405 | lr 0.000310012 | gnorm 0.995 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 30784
2022-03-06 21:24:32 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 21:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:04 | INFO | train_inner | epoch 109:     95 / 97 loss=2.979, nll_loss=1.568, ppl=2.97, wps=22276.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10500, lr=0.000308607, gnorm=1.003, loss_scale=16, train_wall=263, gb_free=8.1, wall=31056
2022-03-06 21:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:14 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.202 | nll_loss 11.443 | ppl 2783.56 | wps 42820.2 | wpb 510.9 | bsz 1 | num_updates 10502 | best_loss 8.233
2022-03-06 21:29:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 10502 updates
2022-03-06 21:29:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:29:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 109 @ 10502 updates, score 12.202) (writing took 2.7083582039922476 seconds)
2022-03-06 21:29:17 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 21:29:17 | INFO | train | epoch 109 | loss 2.975 | nll_loss 1.563 | ppl 2.96 | wps 22257 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10502 | lr 0.000308577 | gnorm 1.003 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 31069
2022-03-06 21:29:17 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 21:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:30:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:33:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:34:00 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.145 | nll_loss 11.387 | ppl 2677.59 | wps 42758.9 | wpb 510.9 | bsz 1 | num_updates 10597 | best_loss 8.233
2022-03-06 21:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 10597 updates
2022-03-06 21:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 110 @ 10597 updates, score 12.145) (writing took 2.5277575440704823 seconds)
2022-03-06 21:34:02 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 21:34:02 | INFO | train | epoch 110 | loss 2.96 | nll_loss 1.546 | ppl 2.92 | wps 21831.8 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 10597 | lr 0.000307191 | gnorm 0.987 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 31354
2022-03-06 21:34:02 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 21:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:11 | INFO | train_inner | epoch 111:      3 / 97 loss=2.958, nll_loss=1.544, ppl=2.92, wps=21317, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=10600, lr=0.000307148, gnorm=0.988, loss_scale=8, train_wall=268, gb_free=8.1, wall=31363
2022-03-06 21:38:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:44 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.224 | nll_loss 11.466 | ppl 2828.5 | wps 43083.4 | wpb 510.9 | bsz 1 | num_updates 10694 | best_loss 8.233
2022-03-06 21:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 10694 updates
2022-03-06 21:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:38:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 111 @ 10694 updates, score 12.224) (writing took 2.6566208759322762 seconds)
2022-03-06 21:38:47 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 21:38:47 | INFO | train | epoch 111 | loss 2.951 | nll_loss 1.537 | ppl 2.9 | wps 22295.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10694 | lr 0.000305795 | gnorm 0.999 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 31639
2022-03-06 21:38:47 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 21:38:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:04 | INFO | train_inner | epoch 112:      6 / 97 loss=2.949, nll_loss=1.535, ppl=2.9, wps=22315.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10700, lr=0.000305709, gnorm=0.998, loss_scale=16, train_wall=262, gb_free=8.1, wall=31656
2022-03-06 21:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:43:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:29 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.225 | nll_loss 11.466 | ppl 2829.35 | wps 43026.4 | wpb 510.9 | bsz 1 | num_updates 10790 | best_loss 8.233
2022-03-06 21:43:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 10790 updates
2022-03-06 21:43:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:43:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:43:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 112 @ 10790 updates, score 12.225) (writing took 2.3956034467555583 seconds)
2022-03-06 21:43:32 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 21:43:32 | INFO | train | epoch 112 | loss 2.938 | nll_loss 1.522 | ppl 2.87 | wps 22092 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10790 | lr 0.000304431 | gnorm 0.986 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 31923
2022-03-06 21:43:32 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 21:43:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:44:00 | INFO | train_inner | epoch 113:     10 / 97 loss=2.934, nll_loss=1.518, ppl=2.86, wps=22124.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=10800, lr=0.00030429, gnorm=0.988, loss_scale=8, train_wall=265, gb_free=8.1, wall=31952
2022-03-06 21:48:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:14 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.202 | nll_loss 11.437 | ppl 2773.39 | wps 42005.6 | wpb 510.9 | bsz 1 | num_updates 10887 | best_loss 8.233
2022-03-06 21:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 10887 updates
2022-03-06 21:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:48:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 113 @ 10887 updates, score 12.202) (writing took 2.4497606228105724 seconds)
2022-03-06 21:48:16 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 21:48:16 | INFO | train | epoch 113 | loss 2.925 | nll_loss 1.508 | ppl 2.84 | wps 22332.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 10887 | lr 0.000303072 | gnorm 0.99 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 32208
2022-03-06 21:48:16 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 21:48:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:48:53 | INFO | train_inner | epoch 114:     13 / 97 loss=2.922, nll_loss=1.505, ppl=2.84, wps=22350, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=10900, lr=0.000302891, gnorm=0.989, loss_scale=16, train_wall=262, gb_free=8.1, wall=32245
2022-03-06 21:50:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 21:52:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:58 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.25 | nll_loss 11.49 | ppl 2876.43 | wps 42779.3 | wpb 510.9 | bsz 1 | num_updates 10983 | best_loss 8.233
2022-03-06 21:52:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 10983 updates
2022-03-06 21:52:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:53:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:53:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 114 @ 10983 updates, score 12.25) (writing took 2.415494291111827 seconds)
2022-03-06 21:53:00 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 21:53:00 | INFO | train | epoch 114 | loss 2.914 | nll_loss 1.496 | ppl 2.82 | wps 22104.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 10983 | lr 0.000301745 | gnorm 0.981 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 32492
2022-03-06 21:53:00 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 21:53:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:53:49 | INFO | train_inner | epoch 115:     17 / 97 loss=2.909, nll_loss=1.49, ppl=2.81, wps=22138.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11000, lr=0.000301511, gnorm=0.975, loss_scale=8, train_wall=265, gb_free=8.1, wall=32541
2022-03-06 21:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:57:43 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.241 | nll_loss 11.48 | ppl 2857.41 | wps 42633.3 | wpb 510.9 | bsz 1 | num_updates 11080 | best_loss 8.233
2022-03-06 21:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11080 updates
2022-03-06 21:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 21:57:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 115 @ 11080 updates, score 12.241) (writing took 2.6104630078189075 seconds)
2022-03-06 21:57:45 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 21:57:45 | INFO | train | epoch 115 | loss 2.903 | nll_loss 1.484 | ppl 2.8 | wps 22295.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11080 | lr 0.000300421 | gnorm 0.985 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 32777
2022-03-06 21:57:45 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 21:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:43 | INFO | train_inner | epoch 116:     20 / 97 loss=2.9, nll_loss=1.48, ppl=2.79, wps=22305.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=11100, lr=0.00030015, gnorm=0.985, loss_scale=16, train_wall=263, gb_free=8.1, wall=32835
2022-03-06 22:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:02:28 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.293 | nll_loss 11.543 | ppl 2984.35 | wps 42723.7 | wpb 510.9 | bsz 1 | num_updates 11177 | best_loss 8.233
2022-03-06 22:02:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11177 updates
2022-03-06 22:02:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:02:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:02:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 116 @ 11177 updates, score 12.293) (writing took 2.6094445679336786 seconds)
2022-03-06 22:02:31 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 22:02:31 | INFO | train | epoch 116 | loss 2.893 | nll_loss 1.472 | ppl 2.77 | wps 22282.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11177 | lr 0.000299114 | gnorm 0.977 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 33062
2022-03-06 22:02:31 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 22:02:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:03:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:03:39 | INFO | train_inner | epoch 117:     24 / 97 loss=2.892, nll_loss=1.471, ppl=2.77, wps=22091.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11200, lr=0.000298807, gnorm=0.982, loss_scale=16, train_wall=265, gb_free=8.1, wall=33131
2022-03-06 22:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:07:13 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.272 | nll_loss 11.52 | ppl 2936.49 | wps 42552.2 | wpb 510.9 | bsz 1 | num_updates 11273 | best_loss 8.233
2022-03-06 22:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 11273 updates
2022-03-06 22:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:07:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:07:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 117 @ 11273 updates, score 12.272) (writing took 2.5919533129781485 seconds)
2022-03-06 22:07:15 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 22:07:15 | INFO | train | epoch 117 | loss 2.88 | nll_loss 1.458 | ppl 2.75 | wps 22060.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11273 | lr 0.000297838 | gnorm 0.976 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 33347
2022-03-06 22:07:16 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 22:07:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:08:33 | INFO | train_inner | epoch 118:     27 / 97 loss=2.873, nll_loss=1.451, ppl=2.73, wps=22309.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11300, lr=0.000297482, gnorm=0.969, loss_scale=16, train_wall=262, gb_free=8.1, wall=33425
2022-03-06 22:09:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:11:58 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 12.317 | nll_loss 11.57 | ppl 3041.14 | wps 42581.1 | wpb 510.9 | bsz 1 | num_updates 11369 | best_loss 8.233
2022-03-06 22:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 11369 updates
2022-03-06 22:11:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:12:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:12:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 118 @ 11369 updates, score 12.317) (writing took 2.612040770240128 seconds)
2022-03-06 22:12:00 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 22:12:00 | INFO | train | epoch 118 | loss 2.871 | nll_loss 1.449 | ppl 2.73 | wps 22067.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11369 | lr 0.000296578 | gnorm 0.974 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 33632
2022-03-06 22:12:00 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 22:12:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:13:29 | INFO | train_inner | epoch 119:     31 / 97 loss=2.868, nll_loss=1.446, ppl=2.72, wps=22105.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11400, lr=0.000296174, gnorm=0.967, loss_scale=16, train_wall=265, gb_free=8.1, wall=33721
2022-03-06 22:16:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:16:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:16:42 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.362 | nll_loss 11.609 | ppl 3123.47 | wps 42958.7 | wpb 510.9 | bsz 1 | num_updates 11465 | best_loss 8.233
2022-03-06 22:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 11465 updates
2022-03-06 22:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:16:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 119 @ 11465 updates, score 12.362) (writing took 2.5978161618113518 seconds)
2022-03-06 22:16:45 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 22:16:45 | INFO | train | epoch 119 | loss 2.861 | nll_loss 1.438 | ppl 2.71 | wps 22092.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11465 | lr 0.000295334 | gnorm 0.975 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 33917
2022-03-06 22:16:45 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 22:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:18:25 | INFO | train_inner | epoch 120:     35 / 97 loss=2.859, nll_loss=1.436, ppl=2.71, wps=22141.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11500, lr=0.000294884, gnorm=0.977, loss_scale=16, train_wall=265, gb_free=8.1, wall=34017
2022-03-06 22:21:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:21:27 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.333 | nll_loss 11.573 | ppl 3046.88 | wps 42720 | wpb 510.9 | bsz 1 | num_updates 11562 | best_loss 8.233
2022-03-06 22:21:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 11562 updates
2022-03-06 22:21:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:21:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 120 @ 11562 updates, score 12.333) (writing took 2.2481318446807563 seconds)
2022-03-06 22:21:29 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 22:21:29 | INFO | train | epoch 120 | loss 2.85 | nll_loss 1.426 | ppl 2.69 | wps 22372.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11562 | lr 0.000294092 | gnorm 0.976 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 34201
2022-03-06 22:21:29 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 22:21:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:23:20 | INFO | train_inner | epoch 121:     39 / 97 loss=2.844, nll_loss=1.419, ppl=2.67, wps=22156.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=11600, lr=0.00029361, gnorm=0.988, loss_scale=16, train_wall=265, gb_free=8.1, wall=34312
2022-03-06 22:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:11 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.322 | nll_loss 11.569 | ppl 3038.88 | wps 42523.5 | wpb 510.9 | bsz 1 | num_updates 11658 | best_loss 8.233
2022-03-06 22:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 11658 updates
2022-03-06 22:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 121 @ 11658 updates, score 12.322) (writing took 2.27476239297539 seconds)
2022-03-06 22:26:14 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 22:26:14 | INFO | train | epoch 121 | loss 2.841 | nll_loss 1.416 | ppl 2.67 | wps 22081.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 11658 | lr 0.000292879 | gnorm 0.986 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 34486
2022-03-06 22:26:14 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 22:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:14 | INFO | train_inner | epoch 122:     42 / 97 loss=2.838, nll_loss=1.412, ppl=2.66, wps=22316.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=11700, lr=0.000292353, gnorm=0.977, loss_scale=16, train_wall=263, gb_free=8.1, wall=34606
2022-03-06 22:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:30:56 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.345 | nll_loss 11.595 | ppl 3093.28 | wps 42702.4 | wpb 510.9 | bsz 1 | num_updates 11755 | best_loss 8.233
2022-03-06 22:30:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 11755 updates
2022-03-06 22:30:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:30:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:30:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 122 @ 11755 updates, score 12.345) (writing took 2.428008586168289 seconds)
2022-03-06 22:30:59 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 22:30:59 | INFO | train | epoch 122 | loss 2.832 | nll_loss 1.407 | ppl 2.65 | wps 22294.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11755 | lr 0.000291668 | gnorm 0.982 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 34771
2022-03-06 22:30:59 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 22:30:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:31:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:33:10 | INFO | train_inner | epoch 123:     46 / 97 loss=2.826, nll_loss=1.4, ppl=2.64, wps=22104.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=11800, lr=0.000291111, gnorm=0.975, loss_scale=16, train_wall=265, gb_free=8.1, wall=34902
2022-03-06 22:34:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:35:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:41 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.337 | nll_loss 11.592 | ppl 3086.74 | wps 42990.9 | wpb 510.9 | bsz 1 | num_updates 11850 | best_loss 8.233
2022-03-06 22:35:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 11850 updates
2022-03-06 22:35:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:35:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:35:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 123 @ 11850 updates, score 12.337) (writing took 2.3339201947674155 seconds)
2022-03-06 22:35:43 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 22:35:43 | INFO | train | epoch 123 | loss 2.821 | nll_loss 1.394 | ppl 2.63 | wps 21865 | ups 0.33 | wpb 65490.6 | bsz 127.9 | num_updates 11850 | lr 0.000290496 | gnorm 0.971 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 35055
2022-03-06 22:35:43 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 22:35:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:38:06 | INFO | train_inner | epoch 124:     50 / 97 loss=2.818, nll_loss=1.391, ppl=2.62, wps=22135.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=11900, lr=0.000289886, gnorm=0.977, loss_scale=8, train_wall=265, gb_free=8.1, wall=35198
2022-03-06 22:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:40:25 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 12.419 | nll_loss 11.675 | ppl 3270.25 | wps 42502.7 | wpb 510.9 | bsz 1 | num_updates 11947 | best_loss 8.233
2022-03-06 22:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 11947 updates
2022-03-06 22:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:40:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:40:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 124 @ 11947 updates, score 12.419) (writing took 2.286912522278726 seconds)
2022-03-06 22:40:28 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 22:40:28 | INFO | train | epoch 124 | loss 2.813 | nll_loss 1.385 | ppl 2.61 | wps 22334 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 11947 | lr 0.000289315 | gnorm 0.973 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 35340
2022-03-06 22:40:28 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 22:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:59 | INFO | train_inner | epoch 125:     53 / 97 loss=2.808, nll_loss=1.38, ppl=2.6, wps=22353.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=12000, lr=0.000288675, gnorm=0.972, loss_scale=16, train_wall=262, gb_free=8.1, wall=35491
2022-03-06 22:43:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 22:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:45:10 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 12.405 | nll_loss 11.659 | ppl 3234.09 | wps 42732.9 | wpb 510.9 | bsz 1 | num_updates 12043 | best_loss 8.233
2022-03-06 22:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12043 updates
2022-03-06 22:45:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:45:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 125 @ 12043 updates, score 12.405) (writing took 2.282485736068338 seconds)
2022-03-06 22:45:12 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 22:45:12 | INFO | train | epoch 125 | loss 2.802 | nll_loss 1.374 | ppl 2.59 | wps 22114.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12043 | lr 0.000288159 | gnorm 0.968 | loss_scale 8 | train_wall 254 | gb_free 8.1 | wall 35624
2022-03-06 22:45:12 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 22:45:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:47:55 | INFO | train_inner | epoch 126:     57 / 97 loss=2.797, nll_loss=1.368, ppl=2.58, wps=22145.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12100, lr=0.00028748, gnorm=0.966, loss_scale=8, train_wall=265, gb_free=8.1, wall=35787
2022-03-06 22:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:49:54 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 12.439 | nll_loss 11.699 | ppl 3324.9 | wps 42657.1 | wpb 510.9 | bsz 1 | num_updates 12140 | best_loss 8.233
2022-03-06 22:49:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12140 updates
2022-03-06 22:49:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:49:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:49:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 126 @ 12140 updates, score 12.439) (writing took 2.325228284113109 seconds)
2022-03-06 22:49:56 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 22:49:56 | INFO | train | epoch 126 | loss 2.794 | nll_loss 1.366 | ppl 2.58 | wps 22332.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12140 | lr 0.000287006 | gnorm 0.97 | loss_scale 8 | train_wall 255 | gb_free 8.1 | wall 35908
2022-03-06 22:49:56 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 22:49:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:52:48 | INFO | train_inner | epoch 127:     60 / 97 loss=2.789, nll_loss=1.359, ppl=2.57, wps=22335.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12200, lr=0.000286299, gnorm=0.978, loss_scale=16, train_wall=263, gb_free=8.1, wall=36080
2022-03-06 22:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:54:39 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 12.418 | nll_loss 11.674 | ppl 3267.99 | wps 42598.1 | wpb 510.9 | bsz 1 | num_updates 12237 | best_loss 8.233
2022-03-06 22:54:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 12237 updates
2022-03-06 22:54:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:54:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 127 @ 12237 updates, score 12.418) (writing took 2.20788397686556 seconds)
2022-03-06 22:54:41 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 22:54:41 | INFO | train | epoch 127 | loss 2.784 | nll_loss 1.354 | ppl 2.56 | wps 22327.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12237 | lr 0.000285866 | gnorm 0.971 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 36193
2022-03-06 22:54:41 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 22:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:56:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:57:44 | INFO | train_inner | epoch 128:     64 / 97 loss=2.781, nll_loss=1.351, ppl=2.55, wps=22126, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12300, lr=0.000285133, gnorm=0.961, loss_scale=16, train_wall=265, gb_free=8.1, wall=36376
2022-03-06 22:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:59:23 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 12.42 | nll_loss 11.676 | ppl 3272.35 | wps 42637.8 | wpb 510.9 | bsz 1 | num_updates 12333 | best_loss 8.233
2022-03-06 22:59:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 12333 updates
2022-03-06 22:59:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 22:59:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 128 @ 12333 updates, score 12.42) (writing took 2.242643900681287 seconds)
2022-03-06 22:59:26 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 22:59:26 | INFO | train | epoch 128 | loss 2.775 | nll_loss 1.345 | ppl 2.54 | wps 22087.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12333 | lr 0.000284751 | gnorm 0.972 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 36477
2022-03-06 22:59:26 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 22:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:02:37 | INFO | train_inner | epoch 129:     67 / 97 loss=2.77, nll_loss=1.34, ppl=2.53, wps=22345.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12400, lr=0.000283981, gnorm=0.97, loss_scale=32, train_wall=262, gb_free=8.1, wall=36669
2022-03-06 23:03:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:04:08 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 12.455 | nll_loss 11.714 | ppl 3359.14 | wps 42630.7 | wpb 510.9 | bsz 1 | num_updates 12429 | best_loss 8.233
2022-03-06 23:04:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 12429 updates
2022-03-06 23:04:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:04:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:04:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 129 @ 12429 updates, score 12.455) (writing took 2.230867193080485 seconds)
2022-03-06 23:04:10 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 23:04:10 | INFO | train | epoch 129 | loss 2.767 | nll_loss 1.336 | ppl 2.52 | wps 22107.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12429 | lr 0.000283649 | gnorm 0.964 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 36762
2022-03-06 23:04:10 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 23:04:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:33 | INFO | train_inner | epoch 130:     71 / 97 loss=2.765, nll_loss=1.333, ppl=2.52, wps=22140, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12500, lr=0.000282843, gnorm=0.984, loss_scale=16, train_wall=265, gb_free=8.1, wall=36965
2022-03-06 23:08:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:08:52 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 12.443 | nll_loss 11.701 | ppl 3329.06 | wps 42700.9 | wpb 510.9 | bsz 1 | num_updates 12526 | best_loss 8.233
2022-03-06 23:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 12526 updates
2022-03-06 23:08:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:08:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 130 @ 12526 updates, score 12.443) (writing took 2.2701191222295165 seconds)
2022-03-06 23:08:54 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 23:08:54 | INFO | train | epoch 130 | loss 2.761 | nll_loss 1.329 | ppl 2.51 | wps 22329.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12526 | lr 0.000282549 | gnorm 0.986 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 37046
2022-03-06 23:08:54 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 23:08:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:09:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:12:29 | INFO | train_inner | epoch 131:     75 / 97 loss=2.751, nll_loss=1.319, ppl=2.49, wps=22128.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12600, lr=0.000281718, gnorm=0.963, loss_scale=16, train_wall=265, gb_free=8.1, wall=37261
2022-03-06 23:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:13:37 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 12.492 | nll_loss 11.76 | ppl 3468.6 | wps 42827 | wpb 510.9 | bsz 1 | num_updates 12622 | best_loss 8.233
2022-03-06 23:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 12622 updates
2022-03-06 23:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 131 @ 12622 updates, score 12.492) (writing took 2.2600637478753924 seconds)
2022-03-06 23:13:39 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 23:13:39 | INFO | train | epoch 131 | loss 2.75 | nll_loss 1.317 | ppl 2.49 | wps 22102 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12622 | lr 0.000281472 | gnorm 0.954 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 37331
2022-03-06 23:13:39 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 23:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:16:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:17:25 | INFO | train_inner | epoch 132:     79 / 97 loss=2.745, nll_loss=1.313, ppl=2.48, wps=22144, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12700, lr=0.000280607, gnorm=0.956, loss_scale=16, train_wall=265, gb_free=8.1, wall=37557
2022-03-06 23:18:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:21 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 12.513 | nll_loss 11.772 | ppl 3497.54 | wps 43107.9 | wpb 510.9 | bsz 1 | num_updates 12718 | best_loss 8.233
2022-03-06 23:18:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 12718 updates
2022-03-06 23:18:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 132 @ 12718 updates, score 12.513) (writing took 2.224083033390343 seconds)
2022-03-06 23:18:23 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 23:18:23 | INFO | train | epoch 132 | loss 2.743 | nll_loss 1.309 | ppl 2.48 | wps 22113.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12718 | lr 0.000280408 | gnorm 0.957 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 37615
2022-03-06 23:18:23 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 23:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:22:18 | INFO | train_inner | epoch 133:     82 / 97 loss=2.739, nll_loss=1.306, ppl=2.47, wps=22346.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12800, lr=0.000279508, gnorm=0.963, loss_scale=16, train_wall=262, gb_free=8.1, wall=37850
2022-03-06 23:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:23:05 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 12.47 | nll_loss 11.727 | ppl 3390.68 | wps 42853.8 | wpb 510.9 | bsz 1 | num_updates 12815 | best_loss 8.233
2022-03-06 23:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 12815 updates
2022-03-06 23:23:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:23:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:23:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 133 @ 12815 updates, score 12.47) (writing took 2.419310415163636 seconds)
2022-03-06 23:23:08 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 23:23:08 | INFO | train | epoch 133 | loss 2.736 | nll_loss 1.302 | ppl 2.47 | wps 22312.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 12815 | lr 0.000279345 | gnorm 0.966 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 37900
2022-03-06 23:23:08 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 23:23:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:27:14 | INFO | train_inner | epoch 134:     86 / 97 loss=2.73, nll_loss=1.295, ppl=2.45, wps=22125.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=12900, lr=0.000278423, gnorm=0.958, loss_scale=16, train_wall=265, gb_free=8.1, wall=38146
2022-03-06 23:27:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:50 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 12.514 | nll_loss 11.784 | ppl 3526.17 | wps 42909.7 | wpb 510.9 | bsz 1 | num_updates 12911 | best_loss 8.233
2022-03-06 23:27:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 12911 updates
2022-03-06 23:27:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:27:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 134 @ 12911 updates, score 12.514) (writing took 2.3215029323473573 seconds)
2022-03-06 23:27:52 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 23:27:52 | INFO | train | epoch 134 | loss 2.727 | nll_loss 1.293 | ppl 2.45 | wps 22100.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 12911 | lr 0.000278304 | gnorm 0.952 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 38184
2022-03-06 23:27:52 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 23:27:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:29:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:32:10 | INFO | train_inner | epoch 135:     90 / 97 loss=2.722, nll_loss=1.288, ppl=2.44, wps=22131.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13000, lr=0.00027735, gnorm=0.954, loss_scale=16, train_wall=265, gb_free=8.1, wall=38442
2022-03-06 23:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:35 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 12.542 | nll_loss 11.812 | ppl 3595.04 | wps 42587.1 | wpb 510.9 | bsz 1 | num_updates 13007 | best_loss 8.233
2022-03-06 23:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13007 updates
2022-03-06 23:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 135 @ 13007 updates, score 12.542) (writing took 2.274419183842838 seconds)
2022-03-06 23:32:37 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 23:32:37 | INFO | train | epoch 135 | loss 2.719 | nll_loss 1.284 | ppl 2.43 | wps 22094.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13007 | lr 0.000277275 | gnorm 0.955 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 38469
2022-03-06 23:32:37 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 23:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:36:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:37:06 | INFO | train_inner | epoch 136:     94 / 97 loss=2.715, nll_loss=1.28, ppl=2.43, wps=22118.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13100, lr=0.000276289, gnorm=0.979, loss_scale=16, train_wall=265, gb_free=8.1, wall=38738
2022-03-06 23:37:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:37:19 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 12.548 | nll_loss 11.822 | ppl 3620.27 | wps 42668.5 | wpb 510.9 | bsz 1 | num_updates 13103 | best_loss 8.233
2022-03-06 23:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13103 updates
2022-03-06 23:37:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:37:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:37:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 136 @ 13103 updates, score 12.548) (writing took 2.347868859767914 seconds)
2022-03-06 23:37:22 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 23:37:22 | INFO | train | epoch 136 | loss 2.713 | nll_loss 1.278 | ppl 2.42 | wps 22083.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13103 | lr 0.000276258 | gnorm 0.98 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 38754
2022-03-06 23:37:22 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 23:37:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:41:59 | INFO | train_inner | epoch 137:     97 / 97 loss=2.706, nll_loss=1.27, ppl=2.41, wps=22346.4, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=13200, lr=0.000275241, gnorm=0.959, loss_scale=16, train_wall=262, gb_free=8.1, wall=39031
2022-03-06 23:41:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:42:04 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 12.547 | nll_loss 11.814 | ppl 3600.81 | wps 43198.1 | wpb 510.9 | bsz 1 | num_updates 13200 | best_loss 8.233
2022-03-06 23:42:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 13200 updates
2022-03-06 23:42:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:42:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 137 @ 13200 updates, score 12.547) (writing took 2.463096781168133 seconds)
2022-03-06 23:42:06 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 23:42:06 | INFO | train | epoch 137 | loss 2.704 | nll_loss 1.268 | ppl 2.41 | wps 22323.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13200 | lr 0.000275241 | gnorm 0.957 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 39038
2022-03-06 23:42:06 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 23:42:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:43:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:46:48 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 12.568 | nll_loss 11.841 | ppl 3669.24 | wps 43263.2 | wpb 510.9 | bsz 1 | num_updates 13296 | best_loss 8.233
2022-03-06 23:46:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 13296 updates
2022-03-06 23:46:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 138 @ 13296 updates, score 12.568) (writing took 2.341930175665766 seconds)
2022-03-06 23:46:51 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 23:46:51 | INFO | train | epoch 138 | loss 2.697 | nll_loss 1.261 | ppl 2.4 | wps 22110.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13296 | lr 0.000274245 | gnorm 0.957 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 39322
2022-03-06 23:46:51 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 23:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:47:02 | INFO | train_inner | epoch 139:      4 / 97 loss=2.695, nll_loss=1.258, ppl=2.39, wps=21584.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=13300, lr=0.000274204, gnorm=0.957, loss_scale=16, train_wall=265, gb_free=8.1, wall=39334
2022-03-06 23:49:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:51:33 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 12.553 | nll_loss 11.824 | ppl 3626.49 | wps 42626.2 | wpb 510.9 | bsz 1 | num_updates 13392 | best_loss 8.233
2022-03-06 23:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 13392 updates
2022-03-06 23:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 139 @ 13392 updates, score 12.553) (writing took 2.2748844767920673 seconds)
2022-03-06 23:51:35 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 23:51:35 | INFO | train | epoch 139 | loss 2.69 | nll_loss 1.253 | ppl 2.38 | wps 22104.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13392 | lr 0.000273261 | gnorm 0.968 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 39607
2022-03-06 23:51:35 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 23:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:58 | INFO | train_inner | epoch 140:      8 / 97 loss=2.688, nll_loss=1.251, ppl=2.38, wps=22136.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13400, lr=0.000273179, gnorm=0.964, loss_scale=16, train_wall=265, gb_free=8.1, wall=39630
2022-03-06 23:56:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:56:17 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 12.568 | nll_loss 11.843 | ppl 3673.69 | wps 42692.4 | wpb 510.9 | bsz 1 | num_updates 13488 | best_loss 8.233
2022-03-06 23:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 13488 updates
2022-03-06 23:56:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-06 23:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 140 @ 13488 updates, score 12.568) (writing took 2.327273073140532 seconds)
2022-03-06 23:56:19 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 23:56:19 | INFO | train | epoch 140 | loss 2.684 | nll_loss 1.246 | ppl 2.37 | wps 22100.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13488 | lr 0.000272287 | gnorm 0.946 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 39891
2022-03-06 23:56:19 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 23:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:54 | INFO | train_inner | epoch 141:     12 / 97 loss=2.683, nll_loss=1.245, ppl=2.37, wps=22131, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13500, lr=0.000272166, gnorm=0.949, loss_scale=16, train_wall=265, gb_free=8.1, wall=39926
2022-03-07 00:00:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:02 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 12.53 | nll_loss 11.799 | ppl 3562.75 | wps 42739.6 | wpb 510.9 | bsz 1 | num_updates 13585 | best_loss 8.233
2022-03-07 00:01:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 13585 updates
2022-03-07 00:01:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:01:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:01:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 141 @ 13585 updates, score 12.53) (writing took 2.2137402431108057 seconds)
2022-03-07 00:01:04 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-07 00:01:04 | INFO | train | epoch 141 | loss 2.677 | nll_loss 1.239 | ppl 2.36 | wps 22302.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13585 | lr 0.000271313 | gnorm 0.952 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 40176
2022-03-07 00:01:04 | INFO | fairseq.trainer | begin training epoch 142
2022-03-07 00:01:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:47 | INFO | train_inner | epoch 142:     15 / 97 loss=2.673, nll_loss=1.235, ppl=2.35, wps=22322.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13600, lr=0.000271163, gnorm=0.95, loss_scale=16, train_wall=263, gb_free=8.1, wall=40219
2022-03-07 00:02:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:05:47 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 12.565 | nll_loss 11.839 | ppl 3663.39 | wps 43233.2 | wpb 510.9 | bsz 1 | num_updates 13681 | best_loss 8.233
2022-03-07 00:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 13681 updates
2022-03-07 00:05:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:05:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 142 @ 13681 updates, score 12.565) (writing took 2.2976390458643436 seconds)
2022-03-07 00:05:49 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-07 00:05:49 | INFO | train | epoch 142 | loss 2.669 | nll_loss 1.23 | ppl 2.35 | wps 22096.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13681 | lr 0.000270359 | gnorm 0.949 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 40461
2022-03-07 00:05:49 | INFO | fairseq.trainer | begin training epoch 143
2022-03-07 00:05:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:43 | INFO | train_inner | epoch 143:     19 / 97 loss=2.666, nll_loss=1.227, ppl=2.34, wps=22133, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13700, lr=0.000270172, gnorm=0.938, loss_scale=16, train_wall=265, gb_free=8.1, wall=40515
2022-03-07 00:09:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:31 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 12.626 | nll_loss 11.907 | ppl 3840.81 | wps 42900.4 | wpb 510.9 | bsz 1 | num_updates 13777 | best_loss 8.233
2022-03-07 00:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 13777 updates
2022-03-07 00:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 143 @ 13777 updates, score 12.626) (writing took 2.3778906669467688 seconds)
2022-03-07 00:10:33 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-07 00:10:33 | INFO | train | epoch 143 | loss 2.664 | nll_loss 1.225 | ppl 2.34 | wps 22101.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13777 | lr 0.000269416 | gnorm 0.95 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 40745
2022-03-07 00:10:33 | INFO | fairseq.trainer | begin training epoch 144
2022-03-07 00:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:11:39 | INFO | train_inner | epoch 144:     23 / 97 loss=2.66, nll_loss=1.221, ppl=2.33, wps=22134.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13800, lr=0.000269191, gnorm=0.961, loss_scale=16, train_wall=265, gb_free=8.1, wall=40811
2022-03-07 00:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:15 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 12.646 | nll_loss 11.935 | ppl 3914.71 | wps 42799.8 | wpb 510.9 | bsz 1 | num_updates 13874 | best_loss 8.233
2022-03-07 00:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 13874 updates
2022-03-07 00:15:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:15:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 144 @ 13874 updates, score 12.646) (writing took 2.2230010679923 seconds)
2022-03-07 00:15:18 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-07 00:15:18 | INFO | train | epoch 144 | loss 2.656 | nll_loss 1.217 | ppl 2.32 | wps 22343.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 13874 | lr 0.000268472 | gnorm 0.944 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41030
2022-03-07 00:15:18 | INFO | fairseq.trainer | begin training epoch 145
2022-03-07 00:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:15:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:16:35 | INFO | train_inner | epoch 145:     27 / 97 loss=2.653, nll_loss=1.214, ppl=2.32, wps=22146.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=13900, lr=0.000268221, gnorm=0.941, loss_scale=16, train_wall=265, gb_free=8.1, wall=41107
2022-03-07 00:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:20:00 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 12.627 | nll_loss 11.907 | ppl 3841.05 | wps 42668.5 | wpb 510.9 | bsz 1 | num_updates 13970 | best_loss 8.233
2022-03-07 00:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 13970 updates
2022-03-07 00:20:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 145 @ 13970 updates, score 12.627) (writing took 2.2527743759565055 seconds)
2022-03-07 00:20:02 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-07 00:20:02 | INFO | train | epoch 145 | loss 2.649 | nll_loss 1.209 | ppl 2.31 | wps 22101.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 13970 | lr 0.000267548 | gnorm 0.941 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41314
2022-03-07 00:20:02 | INFO | fairseq.trainer | begin training epoch 146
2022-03-07 00:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:21:28 | INFO | train_inner | epoch 146:     30 / 97 loss=2.647, nll_loss=1.207, ppl=2.31, wps=22334, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14000, lr=0.000267261, gnorm=0.939, loss_scale=16, train_wall=263, gb_free=8.1, wall=41400
2022-03-07 00:22:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:45 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 12.644 | nll_loss 11.93 | ppl 3903.05 | wps 42877.9 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 8.233
2022-03-07 00:24:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 14066 updates
2022-03-07 00:24:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:24:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:24:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 146 @ 14066 updates, score 12.644) (writing took 2.2338418369181454 seconds)
2022-03-07 00:24:47 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-07 00:24:47 | INFO | train | epoch 146 | loss 2.643 | nll_loss 1.202 | ppl 2.3 | wps 22081.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14066 | lr 0.000266633 | gnorm 0.942 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41599
2022-03-07 00:24:47 | INFO | fairseq.trainer | begin training epoch 147
2022-03-07 00:24:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:24 | INFO | train_inner | epoch 147:     34 / 97 loss=2.64, nll_loss=1.2, ppl=2.3, wps=22126.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14100, lr=0.000266312, gnorm=0.946, loss_scale=16, train_wall=265, gb_free=8.1, wall=41696
2022-03-07 00:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:29:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:29:29 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 12.584 | nll_loss 11.863 | ppl 3723.67 | wps 43061 | wpb 510.9 | bsz 1 | num_updates 14162 | best_loss 8.233
2022-03-07 00:29:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 14162 updates
2022-03-07 00:29:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:29:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 147 @ 14162 updates, score 12.584) (writing took 2.3375834012404084 seconds)
2022-03-07 00:29:31 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-07 00:29:31 | INFO | train | epoch 147 | loss 2.638 | nll_loss 1.198 | ppl 2.29 | wps 22093.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14162 | lr 0.000265728 | gnorm 0.954 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 41883
2022-03-07 00:29:31 | INFO | fairseq.trainer | begin training epoch 148
2022-03-07 00:29:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:20 | INFO | train_inner | epoch 148:     38 / 97 loss=2.634, nll_loss=1.193, ppl=2.29, wps=22127.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14200, lr=0.000265372, gnorm=0.946, loss_scale=16, train_wall=265, gb_free=8.1, wall=41992
2022-03-07 00:34:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:34:14 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 12.647 | nll_loss 11.929 | ppl 3898.3 | wps 42713.7 | wpb 510.9 | bsz 1 | num_updates 14259 | best_loss 8.233
2022-03-07 00:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 14259 updates
2022-03-07 00:34:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:34:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 148 @ 14259 updates, score 12.647) (writing took 2.2513736309483647 seconds)
2022-03-07 00:34:16 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-07 00:34:16 | INFO | train | epoch 148 | loss 2.63 | nll_loss 1.189 | ppl 2.28 | wps 22336.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14259 | lr 0.000264823 | gnorm 0.934 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 42168
2022-03-07 00:34:16 | INFO | fairseq.trainer | begin training epoch 149
2022-03-07 00:34:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:36:16 | INFO | train_inner | epoch 149:     42 / 97 loss=2.628, nll_loss=1.187, ppl=2.28, wps=22134.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14300, lr=0.000264443, gnorm=0.938, loss_scale=16, train_wall=265, gb_free=8.1, wall=42288
2022-03-07 00:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:38:58 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 12.691 | nll_loss 11.981 | ppl 4042.73 | wps 42952.4 | wpb 510.9 | bsz 1 | num_updates 14355 | best_loss 8.233
2022-03-07 00:38:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 14355 updates
2022-03-07 00:38:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 149 @ 14355 updates, score 12.691) (writing took 2.28013568604365 seconds)
2022-03-07 00:39:00 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-07 00:39:00 | INFO | train | epoch 149 | loss 2.623 | nll_loss 1.182 | ppl 2.27 | wps 22101.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14355 | lr 0.000263936 | gnorm 0.934 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 42452
2022-03-07 00:39:00 | INFO | fairseq.trainer | begin training epoch 150
2022-03-07 00:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:41:09 | INFO | train_inner | epoch 150:     45 / 97 loss=2.623, nll_loss=1.181, ppl=2.27, wps=22345.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=14400, lr=0.000263523, gnorm=0.931, loss_scale=16, train_wall=262, gb_free=8.1, wall=42581
2022-03-07 00:41:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:43:43 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 12.694 | nll_loss 11.98 | ppl 4040.02 | wps 42724.6 | wpb 510.9 | bsz 1 | num_updates 14451 | best_loss 8.233
2022-03-07 00:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 14451 updates
2022-03-07 00:43:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:43:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 150 @ 14451 updates, score 12.694) (writing took 2.2632250781171024 seconds)
2022-03-07 00:43:45 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-07 00:43:45 | INFO | train | epoch 150 | loss 2.62 | nll_loss 1.178 | ppl 2.26 | wps 22094.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14451 | lr 0.000263058 | gnorm 0.946 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 42737
2022-03-07 00:43:45 | INFO | fairseq.trainer | begin training epoch 151
2022-03-07 00:43:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:46:05 | INFO | train_inner | epoch 151:     49 / 97 loss=2.615, nll_loss=1.173, ppl=2.25, wps=22132.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14500, lr=0.000262613, gnorm=0.943, loss_scale=16, train_wall=265, gb_free=8.1, wall=42877
2022-03-07 00:47:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:48:27 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 12.675 | nll_loss 11.968 | ppl 4007.41 | wps 42659.5 | wpb 510.9 | bsz 1 | num_updates 14547 | best_loss 8.233
2022-03-07 00:48:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 14547 updates
2022-03-07 00:48:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:48:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:48:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 151 @ 14547 updates, score 12.675) (writing took 2.2282959218136966 seconds)
2022-03-07 00:48:29 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-07 00:48:29 | INFO | train | epoch 151 | loss 2.612 | nll_loss 1.169 | ppl 2.25 | wps 22097.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14547 | lr 0.000262188 | gnorm 0.936 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 43021
2022-03-07 00:48:29 | INFO | fairseq.trainer | begin training epoch 152
2022-03-07 00:48:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:51:01 | INFO | train_inner | epoch 152:     53 / 97 loss=2.609, nll_loss=1.167, ppl=2.25, wps=22125.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=14600, lr=0.000261712, gnorm=0.937, loss_scale=16, train_wall=265, gb_free=8.1, wall=43173
2022-03-07 00:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:12 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 12.705 | nll_loss 12 | ppl 4097.15 | wps 42590.2 | wpb 510.9 | bsz 1 | num_updates 14644 | best_loss 8.233
2022-03-07 00:53:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 14644 updates
2022-03-07 00:53:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:53:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:53:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 152 @ 14644 updates, score 12.705) (writing took 2.3268052926287055 seconds)
2022-03-07 00:53:14 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-07 00:53:14 | INFO | train | epoch 152 | loss 2.608 | nll_loss 1.166 | ppl 2.24 | wps 22315.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 14644 | lr 0.000261318 | gnorm 0.936 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 43306
2022-03-07 00:53:14 | INFO | fairseq.trainer | begin training epoch 153
2022-03-07 00:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 00:55:57 | INFO | train_inner | epoch 153:     57 / 97 loss=2.606, nll_loss=1.163, ppl=2.24, wps=22108.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=14700, lr=0.00026082, gnorm=0.945, loss_scale=16, train_wall=265, gb_free=8.1, wall=43469
2022-03-07 00:57:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:57:56 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 12.632 | nll_loss 11.918 | ppl 3868.51 | wps 42728.9 | wpb 510.9 | bsz 1 | num_updates 14740 | best_loss 8.233
2022-03-07 00:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 14740 updates
2022-03-07 00:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 00:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 153 @ 14740 updates, score 12.632) (writing took 2.3919387757778168 seconds)
2022-03-07 00:57:59 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-07 00:57:59 | INFO | train | epoch 153 | loss 2.602 | nll_loss 1.159 | ppl 2.23 | wps 22069.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14740 | lr 0.000260466 | gnorm 0.95 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 43591
2022-03-07 00:57:59 | INFO | fairseq.trainer | begin training epoch 154
2022-03-07 00:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:00:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:00:53 | INFO | train_inner | epoch 154:     61 / 97 loss=2.597, nll_loss=1.154, ppl=2.22, wps=22117.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14800, lr=0.000259938, gnorm=0.938, loss_scale=16, train_wall=265, gb_free=8.1, wall=43765
2022-03-07 01:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:41 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 12.638 | nll_loss 11.92 | ppl 3875.72 | wps 42727 | wpb 510.9 | bsz 1 | num_updates 14836 | best_loss 8.233
2022-03-07 01:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 14836 updates
2022-03-07 01:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 154 @ 14836 updates, score 12.638) (writing took 2.344556574244052 seconds)
2022-03-07 01:02:43 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-07 01:02:43 | INFO | train | epoch 154 | loss 2.595 | nll_loss 1.152 | ppl 2.22 | wps 22097.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14836 | lr 0.000259622 | gnorm 0.93 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 43875
2022-03-07 01:02:43 | INFO | fairseq.trainer | begin training epoch 155
2022-03-07 01:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:05:46 | INFO | train_inner | epoch 155:     64 / 97 loss=2.593, nll_loss=1.15, ppl=2.22, wps=22338.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=14900, lr=0.000259064, gnorm=0.938, loss_scale=16, train_wall=263, gb_free=8.1, wall=44058
2022-03-07 01:07:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:26 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 12.685 | nll_loss 11.97 | ppl 4012.09 | wps 42535.4 | wpb 510.9 | bsz 1 | num_updates 14932 | best_loss 8.233
2022-03-07 01:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 14932 updates
2022-03-07 01:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:07:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 155 @ 14932 updates, score 12.685) (writing took 2.2757668383419514 seconds)
2022-03-07 01:07:28 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-07 01:07:28 | INFO | train | epoch 155 | loss 2.59 | nll_loss 1.146 | ppl 2.21 | wps 22092.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 14932 | lr 0.000258786 | gnorm 0.938 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 44160
2022-03-07 01:07:28 | INFO | fairseq.trainer | begin training epoch 156
2022-03-07 01:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:10:42 | INFO | train_inner | epoch 156:     68 / 97 loss=2.586, nll_loss=1.143, ppl=2.21, wps=22123.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15000, lr=0.000258199, gnorm=0.939, loss_scale=16, train_wall=265, gb_free=8.1, wall=44354
2022-03-07 01:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:12:10 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 12.665 | nll_loss 11.952 | ppl 3962.42 | wps 42851.1 | wpb 510.9 | bsz 1 | num_updates 15029 | best_loss 8.233
2022-03-07 01:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 15029 updates
2022-03-07 01:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:12:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:12:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 156 @ 15029 updates, score 12.665) (writing took 2.344855281058699 seconds)
2022-03-07 01:12:13 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-07 01:12:13 | INFO | train | epoch 156 | loss 2.585 | nll_loss 1.141 | ppl 2.21 | wps 22324.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15029 | lr 0.00025795 | gnorm 0.943 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 44444
2022-03-07 01:12:13 | INFO | fairseq.trainer | begin training epoch 157
2022-03-07 01:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:14:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:15:39 | INFO | train_inner | epoch 157:     72 / 97 loss=2.582, nll_loss=1.138, ppl=2.2, wps=22119.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=15100, lr=0.000257343, gnorm=0.942, loss_scale=16, train_wall=265, gb_free=8.1, wall=44650
2022-03-07 01:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:55 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 12.701 | nll_loss 11.994 | ppl 4079.95 | wps 42718.7 | wpb 510.9 | bsz 1 | num_updates 15125 | best_loss 8.233
2022-03-07 01:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 15125 updates
2022-03-07 01:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 157 @ 15125 updates, score 12.701) (writing took 2.288330242037773 seconds)
2022-03-07 01:16:57 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-07 01:16:57 | INFO | train | epoch 157 | loss 2.578 | nll_loss 1.134 | ppl 2.19 | wps 22086.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15125 | lr 0.00025713 | gnorm 0.936 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 44729
2022-03-07 01:16:57 | INFO | fairseq.trainer | begin training epoch 158
2022-03-07 01:16:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:32 | INFO | train_inner | epoch 158:     75 / 97 loss=2.577, nll_loss=1.134, ppl=2.19, wps=22325.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15200, lr=0.000256495, gnorm=0.938, loss_scale=32, train_wall=263, gb_free=8.1, wall=44944
2022-03-07 01:20:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:21:40 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 12.733 | nll_loss 12.026 | ppl 4171.68 | wps 43182.3 | wpb 510.9 | bsz 1 | num_updates 15221 | best_loss 8.233
2022-03-07 01:21:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 15221 updates
2022-03-07 01:21:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 158 @ 15221 updates, score 12.733) (writing took 3.2153544262982905 seconds)
2022-03-07 01:21:43 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-07 01:21:43 | INFO | train | epoch 158 | loss 2.574 | nll_loss 1.129 | ppl 2.19 | wps 22009.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15221 | lr 0.000256318 | gnorm 0.934 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45015
2022-03-07 01:21:43 | INFO | fairseq.trainer | begin training epoch 159
2022-03-07 01:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:29 | INFO | train_inner | epoch 159:     79 / 97 loss=2.569, nll_loss=1.124, ppl=2.18, wps=22050, ups=0.34, wpb=65495, bsz=127.9, num_updates=15300, lr=0.000255655, gnorm=0.928, loss_scale=16, train_wall=265, gb_free=8.1, wall=45241
2022-03-07 01:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:26:25 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 12.74 | nll_loss 12.04 | ppl 4210.13 | wps 42911.8 | wpb 510.9 | bsz 1 | num_updates 15318 | best_loss 8.233
2022-03-07 01:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 15318 updates
2022-03-07 01:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 159 @ 15318 updates, score 12.74) (writing took 2.2613288471475244 seconds)
2022-03-07 01:26:28 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-07 01:26:28 | INFO | train | epoch 159 | loss 2.568 | nll_loss 1.123 | ppl 2.18 | wps 22311.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15318 | lr 0.000255505 | gnorm 0.93 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45300
2022-03-07 01:26:28 | INFO | fairseq.trainer | begin training epoch 160
2022-03-07 01:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:28:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:30:25 | INFO | train_inner | epoch 160:     83 / 97 loss=2.563, nll_loss=1.118, ppl=2.17, wps=22140.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=15400, lr=0.000254824, gnorm=0.924, loss_scale=16, train_wall=265, gb_free=8.1, wall=45537
2022-03-07 01:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:31:10 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 12.763 | nll_loss 12.062 | ppl 4275.23 | wps 43100.8 | wpb 510.9 | bsz 1 | num_updates 15414 | best_loss 8.233
2022-03-07 01:31:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 15414 updates
2022-03-07 01:31:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:31:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 160 @ 15414 updates, score 12.763) (writing took 2.240569083020091 seconds)
2022-03-07 01:31:12 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-07 01:31:12 | INFO | train | epoch 160 | loss 2.563 | nll_loss 1.118 | ppl 2.17 | wps 22117.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15414 | lr 0.000254708 | gnorm 0.925 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 45584
2022-03-07 01:31:12 | INFO | fairseq.trainer | begin training epoch 161
2022-03-07 01:31:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:34:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:35:21 | INFO | train_inner | epoch 161:     87 / 97 loss=2.562, nll_loss=1.117, ppl=2.17, wps=22137.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15500, lr=0.000254, gnorm=0.931, loss_scale=16, train_wall=265, gb_free=8.1, wall=45832
2022-03-07 01:35:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:35:54 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 12.697 | nll_loss 11.992 | ppl 4074.49 | wps 42347.6 | wpb 510.9 | bsz 1 | num_updates 15510 | best_loss 8.233
2022-03-07 01:35:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 15510 updates
2022-03-07 01:35:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 161 @ 15510 updates, score 12.697) (writing took 2.226089032832533 seconds)
2022-03-07 01:35:56 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-07 01:35:56 | INFO | train | epoch 161 | loss 2.558 | nll_loss 1.113 | ppl 2.16 | wps 22100.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15510 | lr 0.000253918 | gnorm 0.927 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 45868
2022-03-07 01:35:56 | INFO | fairseq.trainer | begin training epoch 162
2022-03-07 01:35:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:40:13 | INFO | train_inner | epoch 162:     90 / 97 loss=2.555, nll_loss=1.109, ppl=2.16, wps=22365.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15600, lr=0.000253185, gnorm=0.928, loss_scale=16, train_wall=262, gb_free=8.1, wall=46125
2022-03-07 01:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:40:38 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 12.712 | nll_loss 12.005 | ppl 4110.2 | wps 42931.5 | wpb 510.9 | bsz 1 | num_updates 15607 | best_loss 8.233
2022-03-07 01:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 15607 updates
2022-03-07 01:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 162 @ 15607 updates, score 12.712) (writing took 2.260986204724759 seconds)
2022-03-07 01:40:41 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-07 01:40:41 | INFO | train | epoch 162 | loss 2.553 | nll_loss 1.107 | ppl 2.15 | wps 22351.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15607 | lr 0.000253128 | gnorm 0.931 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 46152
2022-03-07 01:40:41 | INFO | fairseq.trainer | begin training epoch 163
2022-03-07 01:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:45:09 | INFO | train_inner | epoch 163:     94 / 97 loss=2.548, nll_loss=1.102, ppl=2.15, wps=22131.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15700, lr=0.000252377, gnorm=0.925, loss_scale=16, train_wall=265, gb_free=8.1, wall=46421
2022-03-07 01:45:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:23 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 12.783 | nll_loss 12.089 | ppl 4355.53 | wps 42573 | wpb 510.9 | bsz 1 | num_updates 15703 | best_loss 8.233
2022-03-07 01:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 15703 updates
2022-03-07 01:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 163 @ 15703 updates, score 12.783) (writing took 2.2949214037507772 seconds)
2022-03-07 01:45:25 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-07 01:45:25 | INFO | train | epoch 163 | loss 2.546 | nll_loss 1.099 | ppl 2.14 | wps 22088.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15703 | lr 0.000252353 | gnorm 0.921 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 46437
2022-03-07 01:45:25 | INFO | fairseq.trainer | begin training epoch 164
2022-03-07 01:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:47:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:50:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:07 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 12.745 | nll_loss 12.046 | ppl 4229.81 | wps 42873.7 | wpb 510.9 | bsz 1 | num_updates 15799 | best_loss 8.233
2022-03-07 01:50:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 15799 updates
2022-03-07 01:50:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:50:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:50:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 164 @ 15799 updates, score 12.745) (writing took 2.2206313572824 seconds)
2022-03-07 01:50:10 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-07 01:50:10 | INFO | train | epoch 164 | loss 2.542 | nll_loss 1.096 | ppl 2.14 | wps 22096.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15799 | lr 0.000251585 | gnorm 0.922 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 46722
2022-03-07 01:50:10 | INFO | fairseq.trainer | begin training epoch 165
2022-03-07 01:50:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:13 | INFO | train_inner | epoch 165:      1 / 97 loss=2.542, nll_loss=1.096, ppl=2.14, wps=21576.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=15800, lr=0.000251577, gnorm=0.922, loss_scale=16, train_wall=265, gb_free=8.1, wall=46725
2022-03-07 01:54:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 01:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:54:52 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 12.767 | nll_loss 12.068 | ppl 4292.49 | wps 42753.4 | wpb 510.9 | bsz 1 | num_updates 15895 | best_loss 8.233
2022-03-07 01:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 15895 updates
2022-03-07 01:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:54:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:54:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 165 @ 15895 updates, score 12.767) (writing took 2.225195722654462 seconds)
2022-03-07 01:54:54 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-07 01:54:54 | INFO | train | epoch 165 | loss 2.538 | nll_loss 1.092 | ppl 2.13 | wps 22090.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 15895 | lr 0.000250824 | gnorm 0.923 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47006
2022-03-07 01:54:54 | INFO | fairseq.trainer | begin training epoch 166
2022-03-07 01:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:09 | INFO | train_inner | epoch 166:      5 / 97 loss=2.536, nll_loss=1.09, ppl=2.13, wps=22125.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=15900, lr=0.000250785, gnorm=0.922, loss_scale=16, train_wall=265, gb_free=8.1, wall=47021
2022-03-07 01:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:36 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 12.792 | nll_loss 12.094 | ppl 4373.08 | wps 42825.5 | wpb 510.9 | bsz 1 | num_updates 15992 | best_loss 8.233
2022-03-07 01:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 15992 updates
2022-03-07 01:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 01:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 166 @ 15992 updates, score 12.792) (writing took 2.348313146736473 seconds)
2022-03-07 01:59:39 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-07 01:59:39 | INFO | train | epoch 166 | loss 2.533 | nll_loss 1.087 | ppl 2.12 | wps 22333.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 15992 | lr 0.000250063 | gnorm 0.931 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 47291
2022-03-07 01:59:39 | INFO | fairseq.trainer | begin training epoch 167
2022-03-07 01:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:02 | INFO | train_inner | epoch 167:      8 / 97 loss=2.532, nll_loss=1.086, ppl=2.12, wps=22347.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16000, lr=0.00025, gnorm=0.928, loss_scale=16, train_wall=262, gb_free=8.1, wall=47314
2022-03-07 02:00:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:04:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:21 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 12.749 | nll_loss 12.053 | ppl 4248.23 | wps 42927.2 | wpb 510.9 | bsz 1 | num_updates 16088 | best_loss 8.233
2022-03-07 02:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 16088 updates
2022-03-07 02:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:04:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:04:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 167 @ 16088 updates, score 12.749) (writing took 2.2883404502645135 seconds)
2022-03-07 02:04:23 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-07 02:04:23 | INFO | train | epoch 167 | loss 2.527 | nll_loss 1.081 | ppl 2.11 | wps 22089.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16088 | lr 0.000249315 | gnorm 0.926 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47575
2022-03-07 02:04:23 | INFO | fairseq.trainer | begin training epoch 168
2022-03-07 02:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:58 | INFO | train_inner | epoch 168:     12 / 97 loss=2.525, nll_loss=1.078, ppl=2.11, wps=22125.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16100, lr=0.000249222, gnorm=0.926, loss_scale=16, train_wall=265, gb_free=8.1, wall=47610
2022-03-07 02:08:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:09:05 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 12.795 | nll_loss 12.097 | ppl 4380.62 | wps 42793 | wpb 510.9 | bsz 1 | num_updates 16184 | best_loss 8.233
2022-03-07 02:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 16184 updates
2022-03-07 02:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 168 @ 16184 updates, score 12.795) (writing took 2.1983439018949866 seconds)
2022-03-07 02:09:08 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-07 02:09:08 | INFO | train | epoch 168 | loss 2.524 | nll_loss 1.077 | ppl 2.11 | wps 22114.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16184 | lr 0.000248575 | gnorm 0.929 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 47860
2022-03-07 02:09:08 | INFO | fairseq.trainer | begin training epoch 169
2022-03-07 02:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:09:53 | INFO | train_inner | epoch 169:     16 / 97 loss=2.522, nll_loss=1.075, ppl=2.11, wps=22146.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16200, lr=0.000248452, gnorm=0.928, loss_scale=16, train_wall=265, gb_free=8.1, wall=47905
2022-03-07 02:13:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:50 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 12.798 | nll_loss 12.103 | ppl 4399.12 | wps 42612 | wpb 510.9 | bsz 1 | num_updates 16281 | best_loss 8.233
2022-03-07 02:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 16281 updates
2022-03-07 02:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:13:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:13:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 169 @ 16281 updates, score 12.798) (writing took 2.2426162026822567 seconds)
2022-03-07 02:13:52 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-07 02:13:52 | INFO | train | epoch 169 | loss 2.519 | nll_loss 1.071 | ppl 2.1 | wps 22320.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16281 | lr 0.000247833 | gnorm 0.929 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 48144
2022-03-07 02:13:52 | INFO | fairseq.trainer | begin training epoch 170
2022-03-07 02:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:14:47 | INFO | train_inner | epoch 170:     19 / 97 loss=2.515, nll_loss=1.067, ppl=2.1, wps=22332.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16300, lr=0.000247689, gnorm=0.923, loss_scale=32, train_wall=263, gb_free=8.1, wall=48199
2022-03-07 02:15:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:18:35 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 12.814 | nll_loss 12.118 | ppl 4444.87 | wps 42947.1 | wpb 510.9 | bsz 1 | num_updates 16377 | best_loss 8.233
2022-03-07 02:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 16377 updates
2022-03-07 02:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:18:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 170 @ 16377 updates, score 12.814) (writing took 2.288954729679972 seconds)
2022-03-07 02:18:37 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-07 02:18:37 | INFO | train | epoch 170 | loss 2.514 | nll_loss 1.067 | ppl 2.09 | wps 22097.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16377 | lr 0.000247106 | gnorm 0.916 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 48429
2022-03-07 02:18:37 | INFO | fairseq.trainer | begin training epoch 171
2022-03-07 02:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:19:43 | INFO | train_inner | epoch 171:     23 / 97 loss=2.515, nll_loss=1.067, ppl=2.1, wps=22136.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=16400, lr=0.000246932, gnorm=0.918, loss_scale=16, train_wall=265, gb_free=8.1, wall=48495
2022-03-07 02:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:23:19 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 12.777 | nll_loss 12.079 | ppl 4326.93 | wps 42675.9 | wpb 510.9 | bsz 1 | num_updates 16473 | best_loss 8.233
2022-03-07 02:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 16473 updates
2022-03-07 02:23:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:23:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:23:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 171 @ 16473 updates, score 12.777) (writing took 2.2448468790389597 seconds)
2022-03-07 02:23:21 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-07 02:23:21 | INFO | train | epoch 171 | loss 2.509 | nll_loss 1.061 | ppl 2.09 | wps 22101.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16473 | lr 0.000246385 | gnorm 0.903 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 48713
2022-03-07 02:23:21 | INFO | fairseq.trainer | begin training epoch 172
2022-03-07 02:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:24:39 | INFO | train_inner | epoch 172:     27 / 97 loss=2.505, nll_loss=1.057, ppl=2.08, wps=22131.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16500, lr=0.000246183, gnorm=0.906, loss_scale=16, train_wall=265, gb_free=8.1, wall=48790
2022-03-07 02:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:03 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 12.771 | nll_loss 12.075 | ppl 4314.91 | wps 42795.3 | wpb 510.9 | bsz 1 | num_updates 16570 | best_loss 8.233
2022-03-07 02:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 16570 updates
2022-03-07 02:28:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:28:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:28:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 172 @ 16570 updates, score 12.771) (writing took 2.291410765144974 seconds)
2022-03-07 02:28:06 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-07 02:28:06 | INFO | train | epoch 172 | loss 2.507 | nll_loss 1.059 | ppl 2.08 | wps 22334.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16570 | lr 0.000245662 | gnorm 0.912 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 48998
2022-03-07 02:28:06 | INFO | fairseq.trainer | begin training epoch 173
2022-03-07 02:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:28:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:29:34 | INFO | train_inner | epoch 173:     31 / 97 loss=2.507, nll_loss=1.059, ppl=2.08, wps=22136.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16600, lr=0.00024544, gnorm=0.917, loss_scale=16, train_wall=265, gb_free=8.1, wall=49086
2022-03-07 02:32:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:32:48 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 12.765 | nll_loss 12.071 | ppl 4302.51 | wps 42639.4 | wpb 510.9 | bsz 1 | num_updates 16666 | best_loss 8.233
2022-03-07 02:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 16666 updates
2022-03-07 02:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:32:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:32:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 173 @ 16666 updates, score 12.765) (writing took 2.332678338047117 seconds)
2022-03-07 02:32:50 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-07 02:32:50 | INFO | train | epoch 173 | loss 2.501 | nll_loss 1.053 | ppl 2.08 | wps 22099 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16666 | lr 0.000244954 | gnorm 0.924 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49282
2022-03-07 02:32:50 | INFO | fairseq.trainer | begin training epoch 174
2022-03-07 02:32:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:34:27 | INFO | train_inner | epoch 174:     34 / 97 loss=2.498, nll_loss=1.05, ppl=2.07, wps=22346.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=16700, lr=0.000244704, gnorm=0.91, loss_scale=16, train_wall=262, gb_free=8.1, wall=49379
2022-03-07 02:36:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:37:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:32 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 12.776 | nll_loss 12.078 | ppl 4322.54 | wps 43130.2 | wpb 510.9 | bsz 1 | num_updates 16762 | best_loss 8.233
2022-03-07 02:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 16762 updates
2022-03-07 02:37:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 174 @ 16762 updates, score 12.776) (writing took 2.291002608835697 seconds)
2022-03-07 02:37:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-07 02:37:35 | INFO | train | epoch 174 | loss 2.495 | nll_loss 1.047 | ppl 2.07 | wps 22105.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16762 | lr 0.000244251 | gnorm 0.906 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49567
2022-03-07 02:37:35 | INFO | fairseq.trainer | begin training epoch 175
2022-03-07 02:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:23 | INFO | train_inner | epoch 175:     38 / 97 loss=2.492, nll_loss=1.043, ppl=2.06, wps=22145.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=16800, lr=0.000243975, gnorm=0.912, loss_scale=16, train_wall=265, gb_free=8.1, wall=49675
2022-03-07 02:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:42:17 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 12.808 | nll_loss 12.109 | ppl 4418.15 | wps 42771.8 | wpb 510.9 | bsz 1 | num_updates 16859 | best_loss 8.233
2022-03-07 02:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 16859 updates
2022-03-07 02:42:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:42:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:42:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 175 @ 16859 updates, score 12.808) (writing took 2.2867114110849798 seconds)
2022-03-07 02:42:19 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-07 02:42:19 | INFO | train | epoch 175 | loss 2.493 | nll_loss 1.044 | ppl 2.06 | wps 22328.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 16859 | lr 0.000243548 | gnorm 0.914 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 49851
2022-03-07 02:42:19 | INFO | fairseq.trainer | begin training epoch 176
2022-03-07 02:42:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:42:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:44:19 | INFO | train_inner | epoch 176:     42 / 97 loss=2.492, nll_loss=1.044, ppl=2.06, wps=22122.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=16900, lr=0.000243252, gnorm=0.914, loss_scale=16, train_wall=265, gb_free=8.1, wall=49971
2022-03-07 02:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:47:01 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 12.8 | nll_loss 12.112 | ppl 4426.82 | wps 42864 | wpb 510.9 | bsz 1 | num_updates 16955 | best_loss 8.233
2022-03-07 02:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 16955 updates
2022-03-07 02:47:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:47:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 176 @ 16955 updates, score 12.8) (writing took 2.2499126279726624 seconds)
2022-03-07 02:47:04 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-07 02:47:04 | INFO | train | epoch 176 | loss 2.487 | nll_loss 1.039 | ppl 2.05 | wps 22100.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 16955 | lr 0.000242857 | gnorm 0.905 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 50136
2022-03-07 02:47:04 | INFO | fairseq.trainer | begin training epoch 177
2022-03-07 02:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:49:15 | INFO | train_inner | epoch 177:     46 / 97 loss=2.487, nll_loss=1.038, ppl=2.05, wps=22131.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17000, lr=0.000242536, gnorm=0.902, loss_scale=16, train_wall=265, gb_free=8.1, wall=50267
2022-03-07 02:51:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:46 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 12.796 | nll_loss 12.107 | ppl 4410.09 | wps 42823.6 | wpb 510.9 | bsz 1 | num_updates 17051 | best_loss 8.233
2022-03-07 02:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 17051 updates
2022-03-07 02:51:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:51:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 177 @ 17051 updates, score 12.796) (writing took 2.3157341862097383 seconds)
2022-03-07 02:51:48 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-07 02:51:48 | INFO | train | epoch 177 | loss 2.484 | nll_loss 1.036 | ppl 2.05 | wps 22088.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17051 | lr 0.000242173 | gnorm 0.91 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 50420
2022-03-07 02:51:48 | INFO | fairseq.trainer | begin training epoch 178
2022-03-07 02:51:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:54:08 | INFO | train_inner | epoch 178:     49 / 97 loss=2.481, nll_loss=1.032, ppl=2.04, wps=22338.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17100, lr=0.000241825, gnorm=0.912, loss_scale=16, train_wall=263, gb_free=8.1, wall=50560
2022-03-07 02:55:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:56:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:56:30 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 12.822 | nll_loss 12.133 | ppl 4490.58 | wps 42632.1 | wpb 510.9 | bsz 1 | num_updates 17147 | best_loss 8.233
2022-03-07 02:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 17147 updates
2022-03-07 02:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:56:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 02:56:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 178 @ 17147 updates, score 12.822) (writing took 2.2624430931173265 seconds)
2022-03-07 02:56:33 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-07 02:56:33 | INFO | train | epoch 178 | loss 2.481 | nll_loss 1.032 | ppl 2.04 | wps 22108.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17147 | lr 0.000241494 | gnorm 0.917 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 50705
2022-03-07 02:56:33 | INFO | fairseq.trainer | begin training epoch 179
2022-03-07 02:56:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:59:04 | INFO | train_inner | epoch 179:     53 / 97 loss=2.48, nll_loss=1.032, ppl=2.04, wps=22146.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17200, lr=0.000241121, gnorm=0.92, loss_scale=16, train_wall=265, gb_free=8.1, wall=50856
2022-03-07 03:01:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:01:15 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 12.775 | nll_loss 12.091 | ppl 4362.06 | wps 42574.8 | wpb 510.9 | bsz 1 | num_updates 17244 | best_loss 8.233
2022-03-07 03:01:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 17244 updates
2022-03-07 03:01:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:01:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:01:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 179 @ 17244 updates, score 12.775) (writing took 2.2426466797478497 seconds)
2022-03-07 03:01:17 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-07 03:01:17 | INFO | train | epoch 179 | loss 2.477 | nll_loss 1.028 | ppl 2.04 | wps 22319.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17244 | lr 0.000240814 | gnorm 0.914 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 50989
2022-03-07 03:01:17 | INFO | fairseq.trainer | begin training epoch 180
2022-03-07 03:01:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:04:00 | INFO | train_inner | epoch 180:     57 / 97 loss=2.472, nll_loss=1.022, ppl=2.03, wps=22125.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=17300, lr=0.000240424, gnorm=0.904, loss_scale=16, train_wall=265, gb_free=8.1, wall=51152
2022-03-07 03:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:59 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 12.832 | nll_loss 12.147 | ppl 4533.87 | wps 42644.3 | wpb 510.9 | bsz 1 | num_updates 17340 | best_loss 8.233
2022-03-07 03:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 17340 updates
2022-03-07 03:05:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:06:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:06:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 180 @ 17340 updates, score 12.832) (writing took 2.316859739366919 seconds)
2022-03-07 03:06:02 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-07 03:06:02 | INFO | train | epoch 180 | loss 2.472 | nll_loss 1.022 | ppl 2.03 | wps 22109.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17340 | lr 0.000240146 | gnorm 0.909 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 51274
2022-03-07 03:06:02 | INFO | fairseq.trainer | begin training epoch 181
2022-03-07 03:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:08:53 | INFO | train_inner | epoch 181:     60 / 97 loss=2.469, nll_loss=1.019, ppl=2.03, wps=22351, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=17400, lr=0.000239732, gnorm=0.908, loss_scale=16, train_wall=262, gb_free=8.1, wall=51445
2022-03-07 03:09:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:10:44 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 12.82 | nll_loss 12.136 | ppl 4501.07 | wps 43023.6 | wpb 510.9 | bsz 1 | num_updates 17436 | best_loss 8.233
2022-03-07 03:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 17436 updates
2022-03-07 03:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 181 @ 17436 updates, score 12.82) (writing took 2.2287750244140625 seconds)
2022-03-07 03:10:46 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-07 03:10:46 | INFO | train | epoch 181 | loss 2.468 | nll_loss 1.018 | ppl 2.03 | wps 22102.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17436 | lr 0.000239484 | gnorm 0.905 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 51558
2022-03-07 03:10:46 | INFO | fairseq.trainer | begin training epoch 182
2022-03-07 03:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:13:49 | INFO | train_inner | epoch 182:     64 / 97 loss=2.469, nll_loss=1.02, ppl=2.03, wps=22124.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17500, lr=0.000239046, gnorm=0.912, loss_scale=16, train_wall=265, gb_free=8.1, wall=51741
2022-03-07 03:15:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:15:28 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 12.796 | nll_loss 12.107 | ppl 4410.45 | wps 42701.9 | wpb 510.9 | bsz 1 | num_updates 17532 | best_loss 8.233
2022-03-07 03:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 17532 updates
2022-03-07 03:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 182 @ 17532 updates, score 12.796) (writing took 2.3418795340694487 seconds)
2022-03-07 03:15:31 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-07 03:15:31 | INFO | train | epoch 182 | loss 2.464 | nll_loss 1.015 | ppl 2.02 | wps 22102.7 | ups 0.34 | wpb 65533.8 | bsz 128 | num_updates 17532 | lr 0.000238827 | gnorm 0.907 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 51843
2022-03-07 03:15:31 | INFO | fairseq.trainer | begin training epoch 183
2022-03-07 03:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:18:45 | INFO | train_inner | epoch 183:     68 / 97 loss=2.462, nll_loss=1.013, ppl=2.02, wps=22130.6, ups=0.34, wpb=65533.9, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.909, loss_scale=16, train_wall=265, gb_free=8.1, wall=52037
2022-03-07 03:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:20:13 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 12.885 | nll_loss 12.204 | ppl 4718.03 | wps 42525 | wpb 510.9 | bsz 1 | num_updates 17629 | best_loss 8.233
2022-03-07 03:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 17629 updates
2022-03-07 03:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 183 @ 17629 updates, score 12.885) (writing took 2.289687652140856 seconds)
2022-03-07 03:20:15 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-07 03:20:15 | INFO | train | epoch 183 | loss 2.46 | nll_loss 1.01 | ppl 2.01 | wps 22309.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17629 | lr 0.00023817 | gnorm 0.908 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 52127
2022-03-07 03:20:16 | INFO | fairseq.trainer | begin training epoch 184
2022-03-07 03:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:21:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:23:41 | INFO | train_inner | epoch 184:     72 / 97 loss=2.457, nll_loss=1.007, ppl=2.01, wps=22119.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17700, lr=0.000237691, gnorm=0.895, loss_scale=16, train_wall=265, gb_free=8.1, wall=52333
2022-03-07 03:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:24:58 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 12.854 | nll_loss 12.172 | ppl 4614.03 | wps 42766.5 | wpb 510.9 | bsz 1 | num_updates 17725 | best_loss 8.233
2022-03-07 03:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 17725 updates
2022-03-07 03:24:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 184 @ 17725 updates, score 12.854) (writing took 2.2281440352089703 seconds)
2022-03-07 03:25:00 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-07 03:25:00 | INFO | train | epoch 184 | loss 2.455 | nll_loss 1.005 | ppl 2.01 | wps 22090.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17725 | lr 0.000237524 | gnorm 0.89 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 52412
2022-03-07 03:25:00 | INFO | fairseq.trainer | begin training epoch 185
2022-03-07 03:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:34 | INFO | train_inner | epoch 185:     75 / 97 loss=2.454, nll_loss=1.004, ppl=2.01, wps=22347.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=17800, lr=0.000237023, gnorm=0.896, loss_scale=32, train_wall=262, gb_free=8.1, wall=52626
2022-03-07 03:28:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:42 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 12.875 | nll_loss 12.195 | ppl 4689.86 | wps 42962.7 | wpb 510.9 | bsz 1 | num_updates 17821 | best_loss 8.233
2022-03-07 03:29:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 17821 updates
2022-03-07 03:29:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:29:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 185 @ 17821 updates, score 12.875) (writing took 2.274105687160045 seconds)
2022-03-07 03:29:44 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-07 03:29:44 | INFO | train | epoch 185 | loss 2.452 | nll_loss 1.002 | ppl 2 | wps 22107.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 17821 | lr 0.000236883 | gnorm 0.893 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 52696
2022-03-07 03:29:45 | INFO | fairseq.trainer | begin training epoch 186
2022-03-07 03:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:33:30 | INFO | train_inner | epoch 186:     79 / 97 loss=2.451, nll_loss=1.001, ppl=2, wps=22145.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=17900, lr=0.00023636, gnorm=0.89, loss_scale=16, train_wall=265, gb_free=8.1, wall=52922
2022-03-07 03:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:27 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 12.866 | nll_loss 12.18 | ppl 4639.19 | wps 42672.7 | wpb 510.9 | bsz 1 | num_updates 17918 | best_loss 8.233
2022-03-07 03:34:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 17918 updates
2022-03-07 03:34:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:34:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:34:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 186 @ 17918 updates, score 12.866) (writing took 2.216069234069437 seconds)
2022-03-07 03:34:29 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-07 03:34:29 | INFO | train | epoch 186 | loss 2.45 | nll_loss 1 | ppl 2 | wps 22336.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 17918 | lr 0.000236241 | gnorm 0.891 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 52981
2022-03-07 03:34:29 | INFO | fairseq.trainer | begin training epoch 187
2022-03-07 03:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:35:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:38:26 | INFO | train_inner | epoch 187:     83 / 97 loss=2.446, nll_loss=0.996, ppl=1.99, wps=22125.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18000, lr=0.000235702, gnorm=0.902, loss_scale=16, train_wall=265, gb_free=8.1, wall=53218
2022-03-07 03:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:39:11 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 12.868 | nll_loss 12.188 | ppl 4666.17 | wps 42832.2 | wpb 510.9 | bsz 1 | num_updates 18014 | best_loss 8.233
2022-03-07 03:39:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 18014 updates
2022-03-07 03:39:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:39:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:39:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 187 @ 18014 updates, score 12.868) (writing took 2.3166353958658874 seconds)
2022-03-07 03:39:13 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-07 03:39:13 | INFO | train | epoch 187 | loss 2.445 | nll_loss 0.995 | ppl 1.99 | wps 22091.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18014 | lr 0.000235611 | gnorm 0.906 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 53265
2022-03-07 03:39:14 | INFO | fairseq.trainer | begin training epoch 188
2022-03-07 03:39:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:42:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:43:22 | INFO | train_inner | epoch 188:     87 / 97 loss=2.444, nll_loss=0.994, ppl=1.99, wps=22112.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18100, lr=0.00023505, gnorm=0.9, loss_scale=16, train_wall=265, gb_free=8.1, wall=53514
2022-03-07 03:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:56 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 12.839 | nll_loss 12.154 | ppl 4556.39 | wps 42988.3 | wpb 510.9 | bsz 1 | num_updates 18110 | best_loss 8.233
2022-03-07 03:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 18110 updates
2022-03-07 03:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 188 @ 18110 updates, score 12.839) (writing took 2.224694811273366 seconds)
2022-03-07 03:43:58 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-07 03:43:58 | INFO | train | epoch 188 | loss 2.441 | nll_loss 0.991 | ppl 1.99 | wps 22092.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18110 | lr 0.000234985 | gnorm 0.898 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 53550
2022-03-07 03:43:58 | INFO | fairseq.trainer | begin training epoch 189
2022-03-07 03:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:48:16 | INFO | train_inner | epoch 189:     90 / 97 loss=2.439, nll_loss=0.989, ppl=1.98, wps=22340.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=18200, lr=0.000234404, gnorm=0.903, loss_scale=16, train_wall=263, gb_free=8.1, wall=53807
2022-03-07 03:48:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:40 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 12.891 | nll_loss 12.21 | ppl 4738.57 | wps 42518.2 | wpb 510.9 | bsz 1 | num_updates 18207 | best_loss 8.233
2022-03-07 03:48:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 18207 updates
2022-03-07 03:48:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 189 @ 18207 updates, score 12.891) (writing took 2.2318597161211073 seconds)
2022-03-07 03:48:43 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-07 03:48:43 | INFO | train | epoch 189 | loss 2.439 | nll_loss 0.988 | ppl 1.98 | wps 22317.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18207 | lr 0.000234359 | gnorm 0.902 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 53835
2022-03-07 03:48:43 | INFO | fairseq.trainer | begin training epoch 190
2022-03-07 03:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:49:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:53:11 | INFO | train_inner | epoch 190:     94 / 97 loss=2.436, nll_loss=0.986, ppl=1.98, wps=22131.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18300, lr=0.000233762, gnorm=0.9, loss_scale=16, train_wall=265, gb_free=8.1, wall=54103
2022-03-07 03:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:53:25 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 12.885 | nll_loss 12.204 | ppl 4718.31 | wps 42777.2 | wpb 510.9 | bsz 1 | num_updates 18303 | best_loss 8.233
2022-03-07 03:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 18303 updates
2022-03-07 03:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 190 @ 18303 updates, score 12.885) (writing took 2.2969716233201325 seconds)
2022-03-07 03:53:27 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-07 03:53:27 | INFO | train | epoch 190 | loss 2.434 | nll_loss 0.983 | ppl 1.98 | wps 22095.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18303 | lr 0.000233743 | gnorm 0.898 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 54119
2022-03-07 03:53:27 | INFO | fairseq.trainer | begin training epoch 191
2022-03-07 03:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 03:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:58:09 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 12.878 | nll_loss 12.194 | ppl 4685.63 | wps 42759 | wpb 510.9 | bsz 1 | num_updates 18399 | best_loss 8.233
2022-03-07 03:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 18399 updates
2022-03-07 03:58:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:58:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 03:58:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 191 @ 18399 updates, score 12.878) (writing took 2.227076891809702 seconds)
2022-03-07 03:58:11 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-07 03:58:12 | INFO | train | epoch 191 | loss 2.431 | nll_loss 0.98 | ppl 1.97 | wps 22120.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18399 | lr 0.000233133 | gnorm 0.903 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 54403
2022-03-07 03:58:12 | INFO | fairseq.trainer | begin training epoch 192
2022-03-07 03:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:58:14 | INFO | train_inner | epoch 192:      1 / 97 loss=2.431, nll_loss=0.98, ppl=1.97, wps=21601.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=18400, lr=0.000233126, gnorm=0.903, loss_scale=16, train_wall=265, gb_free=8.1, wall=54406
2022-03-07 04:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:02:54 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 12.879 | nll_loss 12.203 | ppl 4714.07 | wps 42787.7 | wpb 510.9 | bsz 1 | num_updates 18495 | best_loss 8.233
2022-03-07 04:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 18495 updates
2022-03-07 04:02:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:02:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 192 @ 18495 updates, score 12.879) (writing took 2.24939596792683 seconds)
2022-03-07 04:02:56 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-07 04:02:56 | INFO | train | epoch 192 | loss 2.426 | nll_loss 0.976 | ppl 1.97 | wps 22124.6 | ups 0.34 | wpb 65533.8 | bsz 128 | num_updates 18495 | lr 0.000232527 | gnorm 0.903 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 54688
2022-03-07 04:02:56 | INFO | fairseq.trainer | begin training epoch 193
2022-03-07 04:02:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:03:10 | INFO | train_inner | epoch 193:      5 / 97 loss=2.425, nll_loss=0.974, ppl=1.96, wps=22156.1, ups=0.34, wpb=65533.9, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.899, loss_scale=16, train_wall=265, gb_free=8.1, wall=54702
2022-03-07 04:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:07:38 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 12.874 | nll_loss 12.188 | ppl 4664.81 | wps 42752.8 | wpb 510.9 | bsz 1 | num_updates 18592 | best_loss 8.233
2022-03-07 04:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 18592 updates
2022-03-07 04:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 193 @ 18592 updates, score 12.874) (writing took 2.3067467212677 seconds)
2022-03-07 04:07:40 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-07 04:07:40 | INFO | train | epoch 193 | loss 2.423 | nll_loss 0.972 | ppl 1.96 | wps 22330.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18592 | lr 0.000231919 | gnorm 0.889 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 54972
2022-03-07 04:07:40 | INFO | fairseq.trainer | begin training epoch 194
2022-03-07 04:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:03 | INFO | train_inner | epoch 194:      8 / 97 loss=2.423, nll_loss=0.972, ppl=1.96, wps=22348.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18600, lr=0.000231869, gnorm=0.892, loss_scale=16, train_wall=262, gb_free=8.1, wall=54995
2022-03-07 04:09:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:12:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:12:23 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 12.879 | nll_loss 12.198 | ppl 4699.54 | wps 42732.2 | wpb 510.9 | bsz 1 | num_updates 18688 | best_loss 8.233
2022-03-07 04:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 18688 updates
2022-03-07 04:12:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:12:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:12:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 194 @ 18688 updates, score 12.879) (writing took 2.2459714440628886 seconds)
2022-03-07 04:12:25 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-07 04:12:25 | INFO | train | epoch 194 | loss 2.421 | nll_loss 0.97 | ppl 1.96 | wps 22077.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18688 | lr 0.000231323 | gnorm 0.896 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 55257
2022-03-07 04:12:25 | INFO | fairseq.trainer | begin training epoch 195
2022-03-07 04:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:13:00 | INFO | train_inner | epoch 195:     12 / 97 loss=2.419, nll_loss=0.968, ppl=1.96, wps=22107.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18700, lr=0.000231249, gnorm=0.896, loss_scale=16, train_wall=265, gb_free=8.1, wall=55291
2022-03-07 04:16:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:07 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 12.905 | nll_loss 12.231 | ppl 4805.71 | wps 42651.3 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.233
2022-03-07 04:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 18784 updates
2022-03-07 04:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:17:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 195 @ 18784 updates, score 12.905) (writing took 2.235663495026529 seconds)
2022-03-07 04:17:10 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-07 04:17:10 | INFO | train | epoch 195 | loss 2.416 | nll_loss 0.964 | ppl 1.95 | wps 22091.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18784 | lr 0.000230731 | gnorm 0.894 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 55542
2022-03-07 04:17:10 | INFO | fairseq.trainer | begin training epoch 196
2022-03-07 04:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:56 | INFO | train_inner | epoch 196:     16 / 97 loss=2.413, nll_loss=0.962, ppl=1.95, wps=22125, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18800, lr=0.000230633, gnorm=0.888, loss_scale=16, train_wall=265, gb_free=8.1, wall=55587
2022-03-07 04:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:21:52 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 12.866 | nll_loss 12.192 | ppl 4680.25 | wps 42916.7 | wpb 510.9 | bsz 1 | num_updates 18881 | best_loss 8.233
2022-03-07 04:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 18881 updates
2022-03-07 04:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 196 @ 18881 updates, score 12.866) (writing took 2.2304028309881687 seconds)
2022-03-07 04:21:54 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-07 04:21:54 | INFO | train | epoch 196 | loss 2.414 | nll_loss 0.963 | ppl 1.95 | wps 22334.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 18881 | lr 0.000230138 | gnorm 0.886 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 55826
2022-03-07 04:21:54 | INFO | fairseq.trainer | begin training epoch 197
2022-03-07 04:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:22:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:22:51 | INFO | train_inner | epoch 197:     20 / 97 loss=2.413, nll_loss=0.962, ppl=1.95, wps=22143.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=18900, lr=0.000230022, gnorm=0.887, loss_scale=16, train_wall=265, gb_free=8.1, wall=55883
2022-03-07 04:26:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:36 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 12.897 | nll_loss 12.22 | ppl 4769.7 | wps 42931.1 | wpb 510.9 | bsz 1 | num_updates 18977 | best_loss 8.233
2022-03-07 04:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 18977 updates
2022-03-07 04:26:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:26:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 197 @ 18977 updates, score 12.897) (writing took 2.378654341213405 seconds)
2022-03-07 04:26:39 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-07 04:26:39 | INFO | train | epoch 197 | loss 2.41 | nll_loss 0.959 | ppl 1.94 | wps 22086.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 18977 | lr 0.000229555 | gnorm 0.895 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 56111
2022-03-07 04:26:39 | INFO | fairseq.trainer | begin training epoch 198
2022-03-07 04:26:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:27:45 | INFO | train_inner | epoch 198:     23 / 97 loss=2.408, nll_loss=0.957, ppl=1.94, wps=22326.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19000, lr=0.000229416, gnorm=0.894, loss_scale=16, train_wall=263, gb_free=8.1, wall=56177
2022-03-07 04:30:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:31:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:21 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 12.916 | nll_loss 12.245 | ppl 4853.83 | wps 43053.7 | wpb 510.9 | bsz 1 | num_updates 19073 | best_loss 8.233
2022-03-07 04:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 19073 updates
2022-03-07 04:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:31:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 198 @ 19073 updates, score 12.916) (writing took 2.1900138780474663 seconds)
2022-03-07 04:31:23 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-07 04:31:23 | INFO | train | epoch 198 | loss 2.406 | nll_loss 0.955 | ppl 1.94 | wps 22117.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19073 | lr 0.000228976 | gnorm 0.876 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 56395
2022-03-07 04:31:23 | INFO | fairseq.trainer | begin training epoch 199
2022-03-07 04:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:32:40 | INFO | train_inner | epoch 199:     27 / 97 loss=2.404, nll_loss=0.952, ppl=1.93, wps=22159.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=19100, lr=0.000228814, gnorm=0.881, loss_scale=16, train_wall=265, gb_free=8.1, wall=56472
2022-03-07 04:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:36:05 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 12.905 | nll_loss 12.234 | ppl 4817.28 | wps 42943.6 | wpb 510.9 | bsz 1 | num_updates 19170 | best_loss 8.233
2022-03-07 04:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 19170 updates
2022-03-07 04:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 199 @ 19170 updates, score 12.905) (writing took 2.2326324093155563 seconds)
2022-03-07 04:36:07 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-07 04:36:07 | INFO | train | epoch 199 | loss 2.403 | nll_loss 0.952 | ppl 1.93 | wps 22347.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19170 | lr 0.000228396 | gnorm 0.895 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 56679
2022-03-07 04:36:07 | INFO | fairseq.trainer | begin training epoch 200
2022-03-07 04:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:37:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:37:36 | INFO | train_inner | epoch 200:     31 / 97 loss=2.402, nll_loss=0.951, ppl=1.93, wps=22131.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19200, lr=0.000228218, gnorm=0.891, loss_scale=16, train_wall=265, gb_free=8.1, wall=56768
2022-03-07 04:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:50 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 12.885 | nll_loss 12.205 | ppl 4719.93 | wps 42389.8 | wpb 510.9 | bsz 1 | num_updates 19266 | best_loss 8.233
2022-03-07 04:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 19266 updates
2022-03-07 04:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 200 @ 19266 updates, score 12.885) (writing took 2.2155693490058184 seconds)
2022-03-07 04:40:52 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-07 04:40:52 | INFO | train | epoch 200 | loss 2.399 | nll_loss 0.948 | ppl 1.93 | wps 22067.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19266 | lr 0.000227826 | gnorm 0.893 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 56964
2022-03-07 04:40:52 | INFO | fairseq.trainer | begin training epoch 201
2022-03-07 04:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:42:30 | INFO | train_inner | epoch 201:     34 / 97 loss=2.399, nll_loss=0.947, ppl=1.93, wps=22320.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=19300, lr=0.000227626, gnorm=0.898, loss_scale=16, train_wall=263, gb_free=8.1, wall=57061
2022-03-07 04:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:45:35 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 12.946 | nll_loss 12.28 | ppl 4973.35 | wps 42621.9 | wpb 510.9 | bsz 1 | num_updates 19362 | best_loss 8.233
2022-03-07 04:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 19362 updates
2022-03-07 04:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:45:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 201 @ 19362 updates, score 12.946) (writing took 2.2685235301032662 seconds)
2022-03-07 04:45:37 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-07 04:45:37 | INFO | train | epoch 201 | loss 2.397 | nll_loss 0.946 | ppl 1.93 | wps 22085.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19362 | lr 0.000227261 | gnorm 0.896 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 57249
2022-03-07 04:45:37 | INFO | fairseq.trainer | begin training epoch 202
2022-03-07 04:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:26 | INFO | train_inner | epoch 202:     38 / 97 loss=2.395, nll_loss=0.943, ppl=1.92, wps=22115.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19400, lr=0.000227038, gnorm=0.89, loss_scale=16, train_wall=265, gb_free=8.1, wall=57358
2022-03-07 04:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:50:19 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 12.926 | nll_loss 12.252 | ppl 4877.14 | wps 42962.7 | wpb 510.9 | bsz 1 | num_updates 19459 | best_loss 8.233
2022-03-07 04:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 19459 updates
2022-03-07 04:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 202 @ 19459 updates, score 12.926) (writing took 2.28537848778069 seconds)
2022-03-07 04:50:22 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-07 04:50:22 | INFO | train | epoch 202 | loss 2.394 | nll_loss 0.942 | ppl 1.92 | wps 22311.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19459 | lr 0.000226694 | gnorm 0.882 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 57534
2022-03-07 04:50:22 | INFO | fairseq.trainer | begin training epoch 203
2022-03-07 04:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:52:22 | INFO | train_inner | epoch 203:     42 / 97 loss=2.392, nll_loss=0.94, ppl=1.92, wps=22122.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19500, lr=0.000226455, gnorm=0.882, loss_scale=16, train_wall=265, gb_free=8.1, wall=57654
2022-03-07 04:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:04 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 12.878 | nll_loss 12.199 | ppl 4701.52 | wps 42821.6 | wpb 510.9 | bsz 1 | num_updates 19555 | best_loss 8.233
2022-03-07 04:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 19555 updates
2022-03-07 04:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 203 @ 19555 updates, score 12.878) (writing took 2.363235994707793 seconds)
2022-03-07 04:55:06 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-07 04:55:06 | INFO | train | epoch 203 | loss 2.391 | nll_loss 0.939 | ppl 1.92 | wps 22101.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19555 | lr 0.000226137 | gnorm 0.884 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 57818
2022-03-07 04:55:06 | INFO | fairseq.trainer | begin training epoch 204
2022-03-07 04:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:57:15 | INFO | train_inner | epoch 204:     45 / 97 loss=2.391, nll_loss=0.939, ppl=1.92, wps=22357.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=19600, lr=0.000225877, gnorm=0.878, loss_scale=16, train_wall=262, gb_free=8.1, wall=57947
2022-03-07 04:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:59:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:59:48 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 12.912 | nll_loss 12.237 | ppl 4826.46 | wps 42616.9 | wpb 510.9 | bsz 1 | num_updates 19651 | best_loss 8.233
2022-03-07 04:59:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 19651 updates
2022-03-07 04:59:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:59:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 04:59:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 204 @ 19651 updates, score 12.912) (writing took 2.427244341932237 seconds)
2022-03-07 04:59:51 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-07 04:59:51 | INFO | train | epoch 204 | loss 2.388 | nll_loss 0.936 | ppl 1.91 | wps 22094.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19651 | lr 0.000225584 | gnorm 0.878 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58103
2022-03-07 04:59:51 | INFO | fairseq.trainer | begin training epoch 205
2022-03-07 04:59:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:02:11 | INFO | train_inner | epoch 205:     49 / 97 loss=2.385, nll_loss=0.933, ppl=1.91, wps=22125.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19700, lr=0.000225303, gnorm=0.886, loss_scale=16, train_wall=265, gb_free=8.1, wall=58243
2022-03-07 05:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:33 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 12.981 | nll_loss 12.314 | ppl 5090.24 | wps 42782.7 | wpb 510.9 | bsz 1 | num_updates 19748 | best_loss 8.233
2022-03-07 05:04:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 19748 updates
2022-03-07 05:04:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 205 @ 19748 updates, score 12.981) (writing took 2.291937586851418 seconds)
2022-03-07 05:04:35 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-07 05:04:35 | INFO | train | epoch 205 | loss 2.385 | nll_loss 0.933 | ppl 1.91 | wps 22325.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 19748 | lr 0.000225029 | gnorm 0.885 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58387
2022-03-07 05:04:35 | INFO | fairseq.trainer | begin training epoch 206
2022-03-07 05:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:07:07 | INFO | train_inner | epoch 206:     53 / 97 loss=2.385, nll_loss=0.933, ppl=1.91, wps=22127.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=19800, lr=0.000224733, gnorm=0.878, loss_scale=16, train_wall=265, gb_free=8.1, wall=58539
2022-03-07 05:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:17 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 12.911 | nll_loss 12.238 | ppl 4829.09 | wps 42660.6 | wpb 510.9 | bsz 1 | num_updates 19844 | best_loss 8.233
2022-03-07 05:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 19844 updates
2022-03-07 05:09:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 206 @ 19844 updates, score 12.911) (writing took 2.2209617677144706 seconds)
2022-03-07 05:09:20 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-07 05:09:20 | INFO | train | epoch 206 | loss 2.382 | nll_loss 0.93 | ppl 1.91 | wps 22105.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19844 | lr 0.000224484 | gnorm 0.875 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58672
2022-03-07 05:09:20 | INFO | fairseq.trainer | begin training epoch 207
2022-03-07 05:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:12:03 | INFO | train_inner | epoch 207:     57 / 97 loss=2.38, nll_loss=0.929, ppl=1.9, wps=22121.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=19900, lr=0.000224168, gnorm=0.875, loss_scale=16, train_wall=265, gb_free=8.1, wall=58835
2022-03-07 05:13:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:14:02 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 12.956 | nll_loss 12.287 | ppl 4997.57 | wps 42551.6 | wpb 510.9 | bsz 1 | num_updates 19940 | best_loss 8.233
2022-03-07 05:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 19940 updates
2022-03-07 05:14:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:14:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 207 @ 19940 updates, score 12.956) (writing took 2.234434510115534 seconds)
2022-03-07 05:14:04 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-07 05:14:04 | INFO | train | epoch 207 | loss 2.379 | nll_loss 0.928 | ppl 1.9 | wps 22087.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 19940 | lr 0.000223943 | gnorm 0.882 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 58956
2022-03-07 05:14:04 | INFO | fairseq.trainer | begin training epoch 208
2022-03-07 05:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:16:56 | INFO | train_inner | epoch 208:     60 / 97 loss=2.377, nll_loss=0.925, ppl=1.9, wps=22333.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20000, lr=0.000223607, gnorm=0.88, loss_scale=16, train_wall=263, gb_free=8.1, wall=59128
2022-03-07 05:17:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:18:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:47 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 12.952 | nll_loss 12.28 | ppl 4974.65 | wps 42681.3 | wpb 510.9 | bsz 1 | num_updates 20036 | best_loss 8.233
2022-03-07 05:18:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 20036 updates
2022-03-07 05:18:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:18:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:18:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 208 @ 20036 updates, score 12.952) (writing took 2.2301927004009485 seconds)
2022-03-07 05:18:49 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-07 05:18:49 | INFO | train | epoch 208 | loss 2.374 | nll_loss 0.922 | ppl 1.9 | wps 22079.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20036 | lr 0.000223406 | gnorm 0.877 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 59241
2022-03-07 05:18:49 | INFO | fairseq.trainer | begin training epoch 209
2022-03-07 05:18:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:21:52 | INFO | train_inner | epoch 209:     64 / 97 loss=2.375, nll_loss=0.923, ppl=1.9, wps=22118.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=20100, lr=0.00022305, gnorm=0.879, loss_scale=16, train_wall=265, gb_free=8.1, wall=59424
2022-03-07 05:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:23:32 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 12.941 | nll_loss 12.272 | ppl 4946.66 | wps 42716.7 | wpb 510.9 | bsz 1 | num_updates 20133 | best_loss 8.233
2022-03-07 05:23:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 20133 updates
2022-03-07 05:23:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:23:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:23:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 209 @ 20133 updates, score 12.941) (writing took 2.225470193196088 seconds)
2022-03-07 05:23:34 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-07 05:23:34 | INFO | train | epoch 209 | loss 2.373 | nll_loss 0.921 | ppl 1.89 | wps 22313 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20133 | lr 0.000222867 | gnorm 0.886 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 59526
2022-03-07 05:23:34 | INFO | fairseq.trainer | begin training epoch 210
2022-03-07 05:23:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:26:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:26:48 | INFO | train_inner | epoch 210:     68 / 97 loss=2.37, nll_loss=0.918, ppl=1.89, wps=22114.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20200, lr=0.000222497, gnorm=0.873, loss_scale=16, train_wall=265, gb_free=8.1, wall=59720
2022-03-07 05:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:28:16 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 12.943 | nll_loss 12.278 | ppl 4967.67 | wps 43192 | wpb 510.9 | bsz 1 | num_updates 20229 | best_loss 8.233
2022-03-07 05:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 20229 updates
2022-03-07 05:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 210 @ 20229 updates, score 12.943) (writing took 2.292512378655374 seconds)
2022-03-07 05:28:18 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-07 05:28:18 | INFO | train | epoch 210 | loss 2.369 | nll_loss 0.917 | ppl 1.89 | wps 22093.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20229 | lr 0.000222338 | gnorm 0.867 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 59810
2022-03-07 05:28:18 | INFO | fairseq.trainer | begin training epoch 211
2022-03-07 05:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:31:41 | INFO | train_inner | epoch 211:     71 / 97 loss=2.369, nll_loss=0.917, ppl=1.89, wps=22361.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=20300, lr=0.000221948, gnorm=0.881, loss_scale=16, train_wall=262, gb_free=8.1, wall=60013
2022-03-07 05:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:00 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.001 | nll_loss 12.336 | ppl 5171.33 | wps 43133.2 | wpb 510.9 | bsz 1 | num_updates 20326 | best_loss 8.233
2022-03-07 05:33:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 20326 updates
2022-03-07 05:33:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 211 @ 20326 updates, score 13.001) (writing took 2.206956085283309 seconds)
2022-03-07 05:33:03 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-07 05:33:03 | INFO | train | epoch 211 | loss 2.367 | nll_loss 0.915 | ppl 1.89 | wps 22353.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20326 | lr 0.000221806 | gnorm 0.871 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 60094
2022-03-07 05:33:03 | INFO | fairseq.trainer | begin training epoch 212
2022-03-07 05:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:36:37 | INFO | train_inner | epoch 212:     75 / 97 loss=2.366, nll_loss=0.914, ppl=1.88, wps=22132.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20400, lr=0.000221404, gnorm=0.879, loss_scale=16, train_wall=265, gb_free=8.1, wall=60309
2022-03-07 05:37:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:37:45 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 12.94 | nll_loss 12.273 | ppl 4948.15 | wps 42573.6 | wpb 510.9 | bsz 1 | num_updates 20422 | best_loss 8.233
2022-03-07 05:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 20422 updates
2022-03-07 05:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:37:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:37:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 212 @ 20422 updates, score 12.94) (writing took 2.282944766804576 seconds)
2022-03-07 05:37:47 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-07 05:37:47 | INFO | train | epoch 212 | loss 2.365 | nll_loss 0.913 | ppl 1.88 | wps 22082.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20422 | lr 0.000221284 | gnorm 0.885 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60379
2022-03-07 05:37:47 | INFO | fairseq.trainer | begin training epoch 213
2022-03-07 05:37:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:41:33 | INFO | train_inner | epoch 213:     79 / 97 loss=2.362, nll_loss=0.91, ppl=1.88, wps=22124.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=20500, lr=0.000220863, gnorm=0.868, loss_scale=16, train_wall=265, gb_free=8.1, wall=60605
2022-03-07 05:42:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:30 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 12.97 | nll_loss 12.302 | ppl 5049.03 | wps 42782.5 | wpb 510.9 | bsz 1 | num_updates 20518 | best_loss 8.233
2022-03-07 05:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 20518 updates
2022-03-07 05:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:42:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:42:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 213 @ 20518 updates, score 12.97) (writing took 2.285602738149464 seconds)
2022-03-07 05:42:32 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-07 05:42:32 | INFO | train | epoch 213 | loss 2.362 | nll_loss 0.909 | ppl 1.88 | wps 22089.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20518 | lr 0.000220766 | gnorm 0.869 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60664
2022-03-07 05:42:32 | INFO | fairseq.trainer | begin training epoch 214
2022-03-07 05:42:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:46:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:46:29 | INFO | train_inner | epoch 214:     83 / 97 loss=2.36, nll_loss=0.908, ppl=1.88, wps=22122.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20600, lr=0.000220326, gnorm=0.871, loss_scale=16, train_wall=265, gb_free=8.1, wall=60901
2022-03-07 05:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:14 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 12.976 | nll_loss 12.312 | ppl 5085.71 | wps 42716.7 | wpb 510.9 | bsz 1 | num_updates 20614 | best_loss 8.233
2022-03-07 05:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 20614 updates
2022-03-07 05:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:47:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:47:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 214 @ 20614 updates, score 12.976) (writing took 2.237573313061148 seconds)
2022-03-07 05:47:16 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-07 05:47:16 | INFO | train | epoch 214 | loss 2.358 | nll_loss 0.906 | ppl 1.87 | wps 22098.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20614 | lr 0.000220251 | gnorm 0.872 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 60948
2022-03-07 05:47:16 | INFO | fairseq.trainer | begin training epoch 215
2022-03-07 05:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:51:22 | INFO | train_inner | epoch 215:     86 / 97 loss=2.358, nll_loss=0.906, ppl=1.87, wps=22357.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20700, lr=0.000219793, gnorm=0.878, loss_scale=16, train_wall=262, gb_free=8.1, wall=61194
2022-03-07 05:51:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:58 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 12.996 | nll_loss 12.336 | ppl 5171.38 | wps 42990.1 | wpb 510.9 | bsz 1 | num_updates 20711 | best_loss 8.233
2022-03-07 05:51:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 20711 updates
2022-03-07 05:51:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:52:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:52:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 215 @ 20711 updates, score 12.996) (writing took 2.234554753638804 seconds)
2022-03-07 05:52:01 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-07 05:52:01 | INFO | train | epoch 215 | loss 2.357 | nll_loss 0.905 | ppl 1.87 | wps 22342.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 20711 | lr 0.000219735 | gnorm 0.872 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 61233
2022-03-07 05:52:01 | INFO | fairseq.trainer | begin training epoch 216
2022-03-07 05:52:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 05:56:18 | INFO | train_inner | epoch 216:     90 / 97 loss=2.354, nll_loss=0.901, ppl=1.87, wps=22130.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20800, lr=0.000219265, gnorm=0.869, loss_scale=16, train_wall=265, gb_free=8.1, wall=61490
2022-03-07 05:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:43 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 12.917 | nll_loss 12.249 | ppl 4869.12 | wps 42466.4 | wpb 510.9 | bsz 1 | num_updates 20807 | best_loss 8.233
2022-03-07 05:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 20807 updates
2022-03-07 05:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 05:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 216 @ 20807 updates, score 12.917) (writing took 2.201696991920471 seconds)
2022-03-07 05:56:45 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-07 05:56:45 | INFO | train | epoch 216 | loss 2.353 | nll_loss 0.9 | ppl 1.87 | wps 22094.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20807 | lr 0.000219228 | gnorm 0.871 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 61517
2022-03-07 05:56:45 | INFO | fairseq.trainer | begin training epoch 217
2022-03-07 05:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:01:14 | INFO | train_inner | epoch 217:     94 / 97 loss=2.352, nll_loss=0.9, ppl=1.87, wps=22142.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=20900, lr=0.000218739, gnorm=0.87, loss_scale=16, train_wall=265, gb_free=8.1, wall=61786
2022-03-07 06:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:01:27 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 12.939 | nll_loss 12.277 | ppl 4962.27 | wps 42815.6 | wpb 510.9 | bsz 1 | num_updates 20903 | best_loss 8.233
2022-03-07 06:01:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 20903 updates
2022-03-07 06:01:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:01:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 217 @ 20903 updates, score 12.939) (writing took 2.245335646905005 seconds)
2022-03-07 06:01:30 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-07 06:01:30 | INFO | train | epoch 217 | loss 2.351 | nll_loss 0.899 | ppl 1.86 | wps 22116.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 20903 | lr 0.000218724 | gnorm 0.869 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 61801
2022-03-07 06:01:30 | INFO | fairseq.trainer | begin training epoch 218
2022-03-07 06:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:06:07 | INFO | train_inner | epoch 218:     97 / 97 loss=2.35, nll_loss=0.897, ppl=1.86, wps=22342.7, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=21000, lr=0.000218218, gnorm=0.869, loss_scale=16, train_wall=262, gb_free=8.1, wall=62079
2022-03-07 06:06:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:06:12 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 12.971 | nll_loss 12.308 | ppl 5071.18 | wps 42837 | wpb 510.9 | bsz 1 | num_updates 21000 | best_loss 8.233
2022-03-07 06:06:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 21000 updates
2022-03-07 06:06:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 218 @ 21000 updates, score 12.971) (writing took 2.24402092769742 seconds)
2022-03-07 06:06:14 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-07 06:06:14 | INFO | train | epoch 218 | loss 2.349 | nll_loss 0.896 | ppl 1.86 | wps 22325.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21000 | lr 0.000218218 | gnorm 0.868 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62086
2022-03-07 06:06:14 | INFO | fairseq.trainer | begin training epoch 219
2022-03-07 06:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:06:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:10:56 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 12.989 | nll_loss 12.323 | ppl 5124.5 | wps 42590.5 | wpb 510.9 | bsz 1 | num_updates 21096 | best_loss 8.233
2022-03-07 06:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 21096 updates
2022-03-07 06:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:10:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:10:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 219 @ 21096 updates, score 12.989) (writing took 2.285579788032919 seconds)
2022-03-07 06:10:59 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-07 06:10:59 | INFO | train | epoch 219 | loss 2.345 | nll_loss 0.892 | ppl 1.86 | wps 22096.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21096 | lr 0.000217721 | gnorm 0.871 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62371
2022-03-07 06:10:59 | INFO | fairseq.trainer | begin training epoch 220
2022-03-07 06:10:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:11:10 | INFO | train_inner | epoch 220:      4 / 97 loss=2.343, nll_loss=0.89, ppl=1.85, wps=21585, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=21100, lr=0.0002177, gnorm=0.87, loss_scale=16, train_wall=265, gb_free=8.1, wall=62382
2022-03-07 06:13:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:15:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:15:41 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 12.956 | nll_loss 12.289 | ppl 5004.87 | wps 42619.7 | wpb 510.9 | bsz 1 | num_updates 21192 | best_loss 8.233
2022-03-07 06:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 21192 updates
2022-03-07 06:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:15:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 220 @ 21192 updates, score 12.956) (writing took 2.1906143059022725 seconds)
2022-03-07 06:15:43 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-07 06:15:43 | INFO | train | epoch 220 | loss 2.343 | nll_loss 0.89 | ppl 1.85 | wps 22101.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21192 | lr 0.000217227 | gnorm 0.873 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 62655
2022-03-07 06:15:43 | INFO | fairseq.trainer | begin training epoch 221
2022-03-07 06:15:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:16:06 | INFO | train_inner | epoch 221:      8 / 97 loss=2.341, nll_loss=0.889, ppl=1.85, wps=22133.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21200, lr=0.000217186, gnorm=0.873, loss_scale=16, train_wall=265, gb_free=8.1, wall=62678
2022-03-07 06:20:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:20:25 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 12.979 | nll_loss 12.316 | ppl 5099.82 | wps 42888.5 | wpb 510.9 | bsz 1 | num_updates 21289 | best_loss 8.233
2022-03-07 06:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 21289 updates
2022-03-07 06:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:20:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:20:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 221 @ 21289 updates, score 12.979) (writing took 2.449364949017763 seconds)
2022-03-07 06:20:28 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-07 06:20:28 | INFO | train | epoch 221 | loss 2.341 | nll_loss 0.888 | ppl 1.85 | wps 22327.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21289 | lr 0.000216732 | gnorm 0.868 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 62939
2022-03-07 06:20:28 | INFO | fairseq.trainer | begin training epoch 222
2022-03-07 06:20:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:20:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:21:02 | INFO | train_inner | epoch 222:     12 / 97 loss=2.339, nll_loss=0.887, ppl=1.85, wps=22131.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21300, lr=0.000216676, gnorm=0.867, loss_scale=16, train_wall=265, gb_free=8.1, wall=62974
2022-03-07 06:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:10 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 12.981 | nll_loss 12.321 | ppl 5115.33 | wps 43021.4 | wpb 510.9 | bsz 1 | num_updates 21385 | best_loss 8.233
2022-03-07 06:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 21385 updates
2022-03-07 06:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 222 @ 21385 updates, score 12.981) (writing took 2.354101455770433 seconds)
2022-03-07 06:25:12 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-07 06:25:12 | INFO | train | epoch 222 | loss 2.337 | nll_loss 0.884 | ppl 1.85 | wps 22096.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21385 | lr 0.000216245 | gnorm 0.869 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63224
2022-03-07 06:25:12 | INFO | fairseq.trainer | begin training epoch 223
2022-03-07 06:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:25:55 | INFO | train_inner | epoch 223:     15 / 97 loss=2.336, nll_loss=0.883, ppl=1.84, wps=22346.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21400, lr=0.000216169, gnorm=0.869, loss_scale=16, train_wall=262, gb_free=8.1, wall=63267
2022-03-07 06:28:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:29:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:54 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 12.982 | nll_loss 12.325 | ppl 5129.72 | wps 42782.5 | wpb 510.9 | bsz 1 | num_updates 21481 | best_loss 8.233
2022-03-07 06:29:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 21481 updates
2022-03-07 06:29:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:29:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:29:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 223 @ 21481 updates, score 12.982) (writing took 2.2156717418693006 seconds)
2022-03-07 06:29:56 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-07 06:29:56 | INFO | train | epoch 223 | loss 2.335 | nll_loss 0.882 | ppl 1.84 | wps 22111.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21481 | lr 0.000215761 | gnorm 0.863 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63508
2022-03-07 06:29:56 | INFO | fairseq.trainer | begin training epoch 224
2022-03-07 06:29:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:30:51 | INFO | train_inner | epoch 224:     19 / 97 loss=2.333, nll_loss=0.88, ppl=1.84, wps=22145.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21500, lr=0.000215666, gnorm=0.861, loss_scale=16, train_wall=265, gb_free=8.1, wall=63563
2022-03-07 06:34:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:39 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.013 | nll_loss 12.357 | ppl 5247.32 | wps 42305.9 | wpb 510.9 | bsz 1 | num_updates 21577 | best_loss 8.233
2022-03-07 06:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 21577 updates
2022-03-07 06:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 224 @ 21577 updates, score 13.013) (writing took 2.224469137378037 seconds)
2022-03-07 06:34:41 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-07 06:34:41 | INFO | train | epoch 224 | loss 2.332 | nll_loss 0.879 | ppl 1.84 | wps 22090 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21577 | lr 0.00021528 | gnorm 0.866 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 63793
2022-03-07 06:34:41 | INFO | fairseq.trainer | begin training epoch 225
2022-03-07 06:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:35:47 | INFO | train_inner | epoch 225:     23 / 97 loss=2.329, nll_loss=0.877, ppl=1.84, wps=22117.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21600, lr=0.000215166, gnorm=0.863, loss_scale=16, train_wall=265, gb_free=8.1, wall=63859
2022-03-07 06:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:39:24 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 12.946 | nll_loss 12.28 | ppl 4974.9 | wps 41735.9 | wpb 510.9 | bsz 1 | num_updates 21674 | best_loss 8.233
2022-03-07 06:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 21674 updates
2022-03-07 06:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:39:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:39:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 225 @ 21674 updates, score 12.946) (writing took 2.2216965961270034 seconds)
2022-03-07 06:39:26 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-07 06:39:26 | INFO | train | epoch 225 | loss 2.331 | nll_loss 0.879 | ppl 1.84 | wps 22314.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21674 | lr 0.000214798 | gnorm 0.87 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64078
2022-03-07 06:39:26 | INFO | fairseq.trainer | begin training epoch 226
2022-03-07 06:39:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:40 | INFO | train_inner | epoch 226:     26 / 97 loss=2.33, nll_loss=0.878, ppl=1.84, wps=22319.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21700, lr=0.000214669, gnorm=0.869, loss_scale=16, train_wall=263, gb_free=8.1, wall=64152
2022-03-07 06:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:44:08 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 12.937 | nll_loss 12.273 | ppl 4949.1 | wps 41767.9 | wpb 510.9 | bsz 1 | num_updates 21770 | best_loss 8.233
2022-03-07 06:44:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 21770 updates
2022-03-07 06:44:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:44:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 226 @ 21770 updates, score 12.937) (writing took 2.343011550139636 seconds)
2022-03-07 06:44:11 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-07 06:44:11 | INFO | train | epoch 226 | loss 2.326 | nll_loss 0.874 | ppl 1.83 | wps 22069 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21770 | lr 0.000214324 | gnorm 0.865 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64363
2022-03-07 06:44:11 | INFO | fairseq.trainer | begin training epoch 227
2022-03-07 06:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:36 | INFO | train_inner | epoch 227:     30 / 97 loss=2.326, nll_loss=0.873, ppl=1.83, wps=22117.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=21800, lr=0.000214176, gnorm=0.87, loss_scale=16, train_wall=265, gb_free=8.1, wall=64448
2022-03-07 06:47:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:48:53 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.041 | nll_loss 12.382 | ppl 5337.28 | wps 41615.6 | wpb 510.9 | bsz 1 | num_updates 21866 | best_loss 8.233
2022-03-07 06:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 21866 updates
2022-03-07 06:48:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 227 @ 21866 updates, score 13.041) (writing took 2.2859334400855005 seconds)
2022-03-07 06:48:55 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-07 06:48:55 | INFO | train | epoch 227 | loss 2.325 | nll_loss 0.872 | ppl 1.83 | wps 22085.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 21866 | lr 0.000213853 | gnorm 0.864 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64647
2022-03-07 06:48:55 | INFO | fairseq.trainer | begin training epoch 228
2022-03-07 06:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:50:33 | INFO | train_inner | epoch 228:     34 / 97 loss=2.322, nll_loss=0.868, ppl=1.83, wps=22117.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=21900, lr=0.000213687, gnorm=0.859, loss_scale=16, train_wall=265, gb_free=8.1, wall=64744
2022-03-07 06:53:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:53:38 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.028 | nll_loss 12.372 | ppl 5300.64 | wps 42077.3 | wpb 510.9 | bsz 1 | num_updates 21963 | best_loss 8.233
2022-03-07 06:53:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 21963 updates
2022-03-07 06:53:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:53:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:53:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 228 @ 21963 updates, score 13.028) (writing took 2.34187691565603 seconds)
2022-03-07 06:53:40 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-07 06:53:40 | INFO | train | epoch 228 | loss 2.323 | nll_loss 0.87 | ppl 1.83 | wps 22317.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 21963 | lr 0.00021338 | gnorm 0.865 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 64932
2022-03-07 06:53:40 | INFO | fairseq.trainer | begin training epoch 229
2022-03-07 06:53:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 06:55:29 | INFO | train_inner | epoch 229:     38 / 97 loss=2.322, nll_loss=0.869, ppl=1.83, wps=22127.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22000, lr=0.000213201, gnorm=0.859, loss_scale=16, train_wall=265, gb_free=8.1, wall=65040
2022-03-07 06:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:22 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.061 | nll_loss 12.409 | ppl 5437.6 | wps 42652.5 | wpb 510.9 | bsz 1 | num_updates 22059 | best_loss 8.233
2022-03-07 06:58:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 22059 updates
2022-03-07 06:58:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:58:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 06:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 229 @ 22059 updates, score 13.061) (writing took 2.2982921595685184 seconds)
2022-03-07 06:58:24 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-07 06:58:24 | INFO | train | epoch 229 | loss 2.319 | nll_loss 0.866 | ppl 1.82 | wps 22112.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22059 | lr 0.000212915 | gnorm 0.849 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 65216
2022-03-07 06:58:24 | INFO | fairseq.trainer | begin training epoch 230
2022-03-07 06:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:00:21 | INFO | train_inner | epoch 230:     41 / 97 loss=2.319, nll_loss=0.866, ppl=1.82, wps=22358.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=22100, lr=0.000212718, gnorm=0.858, loss_scale=16, train_wall=262, gb_free=8.1, wall=65333
2022-03-07 07:01:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:03:06 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 12.979 | nll_loss 12.324 | ppl 5128.61 | wps 42522.8 | wpb 510.9 | bsz 1 | num_updates 22155 | best_loss 8.233
2022-03-07 07:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 22155 updates
2022-03-07 07:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:03:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:03:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 230 @ 22155 updates, score 12.979) (writing took 2.380840891972184 seconds)
2022-03-07 07:03:09 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-07 07:03:09 | INFO | train | epoch 230 | loss 2.318 | nll_loss 0.865 | ppl 1.82 | wps 22105 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22155 | lr 0.000212454 | gnorm 0.876 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 65501
2022-03-07 07:03:09 | INFO | fairseq.trainer | begin training epoch 231
2022-03-07 07:03:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:05:17 | INFO | train_inner | epoch 231:     45 / 97 loss=2.319, nll_loss=0.866, ppl=1.82, wps=22127.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22200, lr=0.000212238, gnorm=0.874, loss_scale=16, train_wall=265, gb_free=8.1, wall=65629
2022-03-07 07:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:51 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 12.997 | nll_loss 12.342 | ppl 5190.63 | wps 42497 | wpb 510.9 | bsz 1 | num_updates 22252 | best_loss 8.233
2022-03-07 07:07:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 22252 updates
2022-03-07 07:07:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 231 @ 22252 updates, score 12.997) (writing took 2.377365972381085 seconds)
2022-03-07 07:07:54 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-07 07:07:54 | INFO | train | epoch 231 | loss 2.315 | nll_loss 0.862 | ppl 1.82 | wps 22300.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22252 | lr 0.00021199 | gnorm 0.854 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 65785
2022-03-07 07:07:54 | INFO | fairseq.trainer | begin training epoch 232
2022-03-07 07:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:07:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:10:14 | INFO | train_inner | epoch 232:     49 / 97 loss=2.312, nll_loss=0.858, ppl=1.81, wps=22103.5, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22300, lr=0.000211762, gnorm=0.851, loss_scale=16, train_wall=265, gb_free=8.1, wall=65926
2022-03-07 07:12:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:12:36 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.02 | nll_loss 12.364 | ppl 5269.9 | wps 42824.5 | wpb 510.9 | bsz 1 | num_updates 22348 | best_loss 8.233
2022-03-07 07:12:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 22348 updates
2022-03-07 07:12:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 232 @ 22348 updates, score 13.02) (writing took 2.2888394030742347 seconds)
2022-03-07 07:12:38 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-07 07:12:38 | INFO | train | epoch 232 | loss 2.312 | nll_loss 0.859 | ppl 1.81 | wps 22077.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22348 | lr 0.000211534 | gnorm 0.859 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66070
2022-03-07 07:12:38 | INFO | fairseq.trainer | begin training epoch 233
2022-03-07 07:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:15:10 | INFO | train_inner | epoch 233:     53 / 97 loss=2.312, nll_loss=0.859, ppl=1.81, wps=22119.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=22400, lr=0.000211289, gnorm=0.864, loss_scale=16, train_wall=265, gb_free=8.1, wall=66222
2022-03-07 07:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:17:21 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 12.975 | nll_loss 12.311 | ppl 5081.77 | wps 42796.9 | wpb 510.9 | bsz 1 | num_updates 22444 | best_loss 8.233
2022-03-07 07:17:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 22444 updates
2022-03-07 07:17:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:17:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 233 @ 22444 updates, score 12.975) (writing took 2.307399721350521 seconds)
2022-03-07 07:17:23 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-07 07:17:23 | INFO | train | epoch 233 | loss 2.311 | nll_loss 0.858 | ppl 1.81 | wps 22098.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22444 | lr 0.000211081 | gnorm 0.86 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66355
2022-03-07 07:17:23 | INFO | fairseq.trainer | begin training epoch 234
2022-03-07 07:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:20:03 | INFO | train_inner | epoch 234:     56 / 97 loss=2.31, nll_loss=0.857, ppl=1.81, wps=22344.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22500, lr=0.000210819, gnorm=0.851, loss_scale=16, train_wall=262, gb_free=8.1, wall=66515
2022-03-07 07:21:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:22:05 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 12.977 | nll_loss 12.318 | ppl 5104.98 | wps 42909.2 | wpb 510.9 | bsz 1 | num_updates 22540 | best_loss 8.233
2022-03-07 07:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 22540 updates
2022-03-07 07:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 234 @ 22540 updates, score 12.977) (writing took 2.285097874235362 seconds)
2022-03-07 07:22:07 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-07 07:22:07 | INFO | train | epoch 234 | loss 2.309 | nll_loss 0.856 | ppl 1.81 | wps 22108.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22540 | lr 0.000210631 | gnorm 0.856 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 66639
2022-03-07 07:22:07 | INFO | fairseq.trainer | begin training epoch 235
2022-03-07 07:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:24:59 | INFO | train_inner | epoch 235:     60 / 97 loss=2.308, nll_loss=0.855, ppl=1.81, wps=22129, ups=0.34, wpb=65495, bsz=127.9, num_updates=22600, lr=0.000210352, gnorm=0.863, loss_scale=16, train_wall=265, gb_free=8.1, wall=66811
2022-03-07 07:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:26:50 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 12.978 | nll_loss 12.321 | ppl 5116.05 | wps 42592.1 | wpb 510.9 | bsz 1 | num_updates 22637 | best_loss 8.233
2022-03-07 07:26:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 22637 updates
2022-03-07 07:26:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:26:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:26:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 235 @ 22637 updates, score 12.978) (writing took 2.2536182827316225 seconds)
2022-03-07 07:26:52 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-07 07:26:52 | INFO | train | epoch 235 | loss 2.306 | nll_loss 0.853 | ppl 1.81 | wps 22320.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22637 | lr 0.00021018 | gnorm 0.863 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 66924
2022-03-07 07:26:52 | INFO | fairseq.trainer | begin training epoch 236
2022-03-07 07:26:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:28:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:29:55 | INFO | train_inner | epoch 236:     64 / 97 loss=2.304, nll_loss=0.851, ppl=1.8, wps=22140.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=22700, lr=0.000209888, gnorm=0.869, loss_scale=16, train_wall=265, gb_free=8.1, wall=67107
2022-03-07 07:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:31:34 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.044 | nll_loss 12.392 | ppl 5373.89 | wps 42678.3 | wpb 510.9 | bsz 1 | num_updates 22733 | best_loss 8.233
2022-03-07 07:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 22733 updates
2022-03-07 07:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:31:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:31:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 236 @ 22733 updates, score 13.044) (writing took 2.3403878146782517 seconds)
2022-03-07 07:31:36 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-07 07:31:36 | INFO | train | epoch 236 | loss 2.304 | nll_loss 0.851 | ppl 1.8 | wps 22095.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22733 | lr 0.000209735 | gnorm 0.869 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67208
2022-03-07 07:31:36 | INFO | fairseq.trainer | begin training epoch 237
2022-03-07 07:31:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:34:48 | INFO | train_inner | epoch 237:     67 / 97 loss=2.303, nll_loss=0.85, ppl=1.8, wps=22331.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22800, lr=0.000209427, gnorm=0.848, loss_scale=32, train_wall=263, gb_free=8.1, wall=67400
2022-03-07 07:34:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:36:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:19 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 12.985 | nll_loss 12.322 | ppl 5119.87 | wps 42788.3 | wpb 510.9 | bsz 1 | num_updates 22829 | best_loss 8.233
2022-03-07 07:36:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 22829 updates
2022-03-07 07:36:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:36:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:36:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 237 @ 22829 updates, score 12.985) (writing took 2.2540885657072067 seconds)
2022-03-07 07:36:21 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-07 07:36:21 | INFO | train | epoch 237 | loss 2.301 | nll_loss 0.848 | ppl 1.8 | wps 22102.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 22829 | lr 0.000209294 | gnorm 0.844 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67493
2022-03-07 07:36:21 | INFO | fairseq.trainer | begin training epoch 238
2022-03-07 07:36:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:39:44 | INFO | train_inner | epoch 238:     71 / 97 loss=2.301, nll_loss=0.848, ppl=1.8, wps=22122.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=22900, lr=0.000208969, gnorm=0.855, loss_scale=16, train_wall=265, gb_free=8.1, wall=67696
2022-03-07 07:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:03 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.004 | nll_loss 12.35 | ppl 5220.26 | wps 42676.1 | wpb 510.9 | bsz 1 | num_updates 22926 | best_loss 8.233
2022-03-07 07:41:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 22926 updates
2022-03-07 07:41:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:41:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 238 @ 22926 updates, score 13.004) (writing took 2.2547805891372263 seconds)
2022-03-07 07:41:06 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-07 07:41:06 | INFO | train | epoch 238 | loss 2.3 | nll_loss 0.847 | ppl 1.8 | wps 22307.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 22926 | lr 0.000208851 | gnorm 0.851 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 67778
2022-03-07 07:41:06 | INFO | fairseq.trainer | begin training epoch 239
2022-03-07 07:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:41:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:44:40 | INFO | train_inner | epoch 239:     75 / 97 loss=2.299, nll_loss=0.846, ppl=1.8, wps=22122.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23000, lr=0.000208514, gnorm=0.853, loss_scale=16, train_wall=265, gb_free=8.1, wall=67992
2022-03-07 07:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:48 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.003 | nll_loss 12.346 | ppl 5206.15 | wps 42974 | wpb 510.9 | bsz 1 | num_updates 23022 | best_loss 8.233
2022-03-07 07:45:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 23022 updates
2022-03-07 07:45:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 239 @ 23022 updates, score 13.003) (writing took 2.286433330271393 seconds)
2022-03-07 07:45:50 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-07 07:45:50 | INFO | train | epoch 239 | loss 2.298 | nll_loss 0.845 | ppl 1.8 | wps 22101.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23022 | lr 0.000208415 | gnorm 0.861 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 68062
2022-03-07 07:45:50 | INFO | fairseq.trainer | begin training epoch 240
2022-03-07 07:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:48:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:49:36 | INFO | train_inner | epoch 240:     79 / 97 loss=2.295, nll_loss=0.842, ppl=1.79, wps=22133.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23100, lr=0.000208063, gnorm=0.852, loss_scale=16, train_wall=265, gb_free=8.1, wall=68288
2022-03-07 07:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:32 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.006 | nll_loss 12.35 | ppl 5221.05 | wps 42837.1 | wpb 510.9 | bsz 1 | num_updates 23118 | best_loss 8.233
2022-03-07 07:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 23118 updates
2022-03-07 07:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 240 @ 23118 updates, score 13.006) (writing took 2.2763035115785897 seconds)
2022-03-07 07:50:35 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-07 07:50:35 | INFO | train | epoch 240 | loss 2.294 | nll_loss 0.841 | ppl 1.79 | wps 22103.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23118 | lr 0.000207982 | gnorm 0.848 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68346
2022-03-07 07:50:35 | INFO | fairseq.trainer | begin training epoch 241
2022-03-07 07:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 07:54:32 | INFO | train_inner | epoch 241:     83 / 97 loss=2.295, nll_loss=0.842, ppl=1.79, wps=22129, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23200, lr=0.000207614, gnorm=0.864, loss_scale=16, train_wall=265, gb_free=8.1, wall=68584
2022-03-07 07:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:55:17 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 12.953 | nll_loss 12.298 | ppl 5035.23 | wps 42783.7 | wpb 510.9 | bsz 1 | num_updates 23214 | best_loss 8.233
2022-03-07 07:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 23214 updates
2022-03-07 07:55:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 07:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 241 @ 23214 updates, score 12.953) (writing took 2.452669888269156 seconds)
2022-03-07 07:55:19 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-07 07:55:19 | INFO | train | epoch 241 | loss 2.293 | nll_loss 0.84 | ppl 1.79 | wps 22075.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23214 | lr 0.000207551 | gnorm 0.863 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68631
2022-03-07 07:55:19 | INFO | fairseq.trainer | begin training epoch 242
2022-03-07 07:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:59:25 | INFO | train_inner | epoch 242:     86 / 97 loss=2.29, nll_loss=0.838, ppl=1.79, wps=22313.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23300, lr=0.000207168, gnorm=0.853, loss_scale=16, train_wall=263, gb_free=8.1, wall=68877
2022-03-07 07:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:00:02 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.02 | nll_loss 12.367 | ppl 5280.85 | wps 42890.1 | wpb 510.9 | bsz 1 | num_updates 23311 | best_loss 8.233
2022-03-07 08:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 23311 updates
2022-03-07 08:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:00:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 242 @ 23311 updates, score 13.02) (writing took 2.138707152567804 seconds)
2022-03-07 08:00:04 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-07 08:00:04 | INFO | train | epoch 242 | loss 2.29 | nll_loss 0.837 | ppl 1.79 | wps 22318.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23311 | lr 0.000207119 | gnorm 0.849 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 68916
2022-03-07 08:00:04 | INFO | fairseq.trainer | begin training epoch 243
2022-03-07 08:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:04:21 | INFO | train_inner | epoch 243:     90 / 97 loss=2.29, nll_loss=0.837, ppl=1.79, wps=22132.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23400, lr=0.000206725, gnorm=0.84, loss_scale=16, train_wall=265, gb_free=8.1, wall=69173
2022-03-07 08:04:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:04:46 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.023 | nll_loss 12.375 | ppl 5312.2 | wps 42666.2 | wpb 510.9 | bsz 1 | num_updates 23407 | best_loss 8.233
2022-03-07 08:04:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 23407 updates
2022-03-07 08:04:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:04:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:04:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 243 @ 23407 updates, score 13.023) (writing took 2.2329376921989024 seconds)
2022-03-07 08:04:49 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-07 08:04:49 | INFO | train | epoch 243 | loss 2.288 | nll_loss 0.835 | ppl 1.78 | wps 22094.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23407 | lr 0.000206694 | gnorm 0.841 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69200
2022-03-07 08:04:49 | INFO | fairseq.trainer | begin training epoch 244
2022-03-07 08:04:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:08:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:09:17 | INFO | train_inner | epoch 244:     94 / 97 loss=2.287, nll_loss=0.834, ppl=1.78, wps=22130.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=23500, lr=0.000206284, gnorm=0.849, loss_scale=16, train_wall=265, gb_free=8.1, wall=69469
2022-03-07 08:09:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:09:31 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.006 | nll_loss 12.352 | ppl 5228.9 | wps 42686.6 | wpb 510.9 | bsz 1 | num_updates 23503 | best_loss 8.233
2022-03-07 08:09:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 23503 updates
2022-03-07 08:09:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 244 @ 23503 updates, score 13.006) (writing took 2.300174015108496 seconds)
2022-03-07 08:09:33 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-07 08:09:33 | INFO | train | epoch 244 | loss 2.286 | nll_loss 0.833 | ppl 1.78 | wps 22093.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23503 | lr 0.000206271 | gnorm 0.846 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 69485
2022-03-07 08:09:33 | INFO | fairseq.trainer | begin training epoch 245
2022-03-07 08:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:14:10 | INFO | train_inner | epoch 245:     97 / 97 loss=2.286, nll_loss=0.833, ppl=1.78, wps=22349.3, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=23600, lr=0.000205847, gnorm=0.855, loss_scale=16, train_wall=262, gb_free=8.1, wall=69762
2022-03-07 08:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:15 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.036 | nll_loss 12.387 | ppl 5356.3 | wps 42781.1 | wpb 510.9 | bsz 1 | num_updates 23600 | best_loss 8.233
2022-03-07 08:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 23600 updates
2022-03-07 08:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 245 @ 23600 updates, score 13.036) (writing took 2.295102379284799 seconds)
2022-03-07 08:14:18 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-07 08:14:18 | INFO | train | epoch 245 | loss 2.285 | nll_loss 0.832 | ppl 1.78 | wps 22332.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23600 | lr 0.000205847 | gnorm 0.856 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 69769
2022-03-07 08:14:18 | INFO | fairseq.trainer | begin training epoch 246
2022-03-07 08:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:14:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:00 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.009 | nll_loss 12.354 | ppl 5234.44 | wps 42714.6 | wpb 510.9 | bsz 1 | num_updates 23696 | best_loss 8.233
2022-03-07 08:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 23696 updates
2022-03-07 08:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 246 @ 23696 updates, score 13.009) (writing took 2.2519561839289963 seconds)
2022-03-07 08:19:02 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-07 08:19:02 | INFO | train | epoch 246 | loss 2.281 | nll_loss 0.828 | ppl 1.78 | wps 22095.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23696 | lr 0.000205429 | gnorm 0.852 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 70054
2022-03-07 08:19:02 | INFO | fairseq.trainer | begin training epoch 247
2022-03-07 08:19:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:19:14 | INFO | train_inner | epoch 247:      4 / 97 loss=2.28, nll_loss=0.827, ppl=1.77, wps=21579.8, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=23700, lr=0.000205412, gnorm=0.851, loss_scale=16, train_wall=265, gb_free=8.1, wall=70066
2022-03-07 08:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:23:44 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.014 | nll_loss 12.363 | ppl 5268.13 | wps 42924.8 | wpb 510.9 | bsz 1 | num_updates 23792 | best_loss 8.233
2022-03-07 08:23:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 23792 updates
2022-03-07 08:23:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 247 @ 23792 updates, score 13.014) (writing took 2.2608480849303305 seconds)
2022-03-07 08:23:47 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-07 08:23:47 | INFO | train | epoch 247 | loss 2.279 | nll_loss 0.827 | ppl 1.77 | wps 22101.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23792 | lr 0.000205014 | gnorm 0.84 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 70338
2022-03-07 08:23:47 | INFO | fairseq.trainer | begin training epoch 248
2022-03-07 08:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:24:10 | INFO | train_inner | epoch 248:      8 / 97 loss=2.279, nll_loss=0.826, ppl=1.77, wps=22129.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=23800, lr=0.00020498, gnorm=0.842, loss_scale=16, train_wall=265, gb_free=8.1, wall=70361
2022-03-07 08:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:29 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 12.996 | nll_loss 12.337 | ppl 5172.12 | wps 42480.4 | wpb 510.9 | bsz 1 | num_updates 23889 | best_loss 8.233
2022-03-07 08:28:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 23889 updates
2022-03-07 08:28:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:28:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:28:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 248 @ 23889 updates, score 12.996) (writing took 2.3748305616900325 seconds)
2022-03-07 08:28:31 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-07 08:28:31 | INFO | train | epoch 248 | loss 2.278 | nll_loss 0.825 | ppl 1.77 | wps 22318.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 23889 | lr 0.000204598 | gnorm 0.85 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 70623
2022-03-07 08:28:31 | INFO | fairseq.trainer | begin training epoch 249
2022-03-07 08:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:28:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:29:06 | INFO | train_inner | epoch 249:     12 / 97 loss=2.277, nll_loss=0.824, ppl=1.77, wps=22123, ups=0.34, wpb=65495, bsz=127.9, num_updates=23900, lr=0.000204551, gnorm=0.849, loss_scale=16, train_wall=265, gb_free=8.1, wall=70658
2022-03-07 08:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:33:13 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 12.996 | nll_loss 12.345 | ppl 5204.14 | wps 42694.9 | wpb 510.9 | bsz 1 | num_updates 23985 | best_loss 8.233
2022-03-07 08:33:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 23985 updates
2022-03-07 08:33:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:33:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:33:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 249 @ 23985 updates, score 12.996) (writing took 2.2242152779363096 seconds)
2022-03-07 08:33:16 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-07 08:33:16 | INFO | train | epoch 249 | loss 2.277 | nll_loss 0.824 | ppl 1.77 | wps 22103.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 23985 | lr 0.000204188 | gnorm 0.853 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 70908
2022-03-07 08:33:16 | INFO | fairseq.trainer | begin training epoch 250
2022-03-07 08:33:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:33:59 | INFO | train_inner | epoch 250:     15 / 97 loss=2.276, nll_loss=0.823, ppl=1.77, wps=22348.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24000, lr=0.000204124, gnorm=0.852, loss_scale=16, train_wall=262, gb_free=8.1, wall=70951
2022-03-07 08:35:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:58 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.066 | nll_loss 12.418 | ppl 5473.96 | wps 42679.7 | wpb 510.9 | bsz 1 | num_updates 24081 | best_loss 8.233
2022-03-07 08:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 24081 updates
2022-03-07 08:37:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 250 @ 24081 updates, score 13.066) (writing took 2.2460257979109883 seconds)
2022-03-07 08:38:00 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-07 08:38:00 | INFO | train | epoch 250 | loss 2.273 | nll_loss 0.82 | ppl 1.77 | wps 22095.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24081 | lr 0.000203781 | gnorm 0.844 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 71192
2022-03-07 08:38:00 | INFO | fairseq.trainer | begin training epoch 251
2022-03-07 08:38:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:38:55 | INFO | train_inner | epoch 251:     19 / 97 loss=2.272, nll_loss=0.819, ppl=1.76, wps=22128.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24100, lr=0.0002037, gnorm=0.842, loss_scale=16, train_wall=265, gb_free=8.1, wall=71247
2022-03-07 08:41:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:42:42 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.044 | nll_loss 12.391 | ppl 5369.66 | wps 43026.7 | wpb 510.9 | bsz 1 | num_updates 24177 | best_loss 8.233
2022-03-07 08:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 24177 updates
2022-03-07 08:42:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:42:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:42:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 251 @ 24177 updates, score 13.044) (writing took 2.3212703447788954 seconds)
2022-03-07 08:42:45 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-07 08:42:45 | INFO | train | epoch 251 | loss 2.273 | nll_loss 0.82 | ppl 1.76 | wps 22103.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24177 | lr 0.000203376 | gnorm 0.846 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 71477
2022-03-07 08:42:45 | INFO | fairseq.trainer | begin training epoch 252
2022-03-07 08:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:43:50 | INFO | train_inner | epoch 252:     23 / 97 loss=2.271, nll_loss=0.818, ppl=1.76, wps=22136, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24200, lr=0.000203279, gnorm=0.844, loss_scale=16, train_wall=265, gb_free=8.1, wall=71542
2022-03-07 08:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:47:27 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.024 | nll_loss 12.376 | ppl 5315.01 | wps 42640.6 | wpb 510.9 | bsz 1 | num_updates 24274 | best_loss 8.233
2022-03-07 08:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 24274 updates
2022-03-07 08:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 252 @ 24274 updates, score 13.024) (writing took 2.3180808341130614 seconds)
2022-03-07 08:47:29 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-07 08:47:29 | INFO | train | epoch 252 | loss 2.269 | nll_loss 0.816 | ppl 1.76 | wps 22308.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24274 | lr 0.000202969 | gnorm 0.844 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 71761
2022-03-07 08:47:29 | INFO | fairseq.trainer | begin training epoch 253
2022-03-07 08:47:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:48:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:48:47 | INFO | train_inner | epoch 253:     27 / 97 loss=2.268, nll_loss=0.815, ppl=1.76, wps=22111.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=24300, lr=0.00020286, gnorm=0.846, loss_scale=16, train_wall=265, gb_free=8.1, wall=71839
2022-03-07 08:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:12 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.056 | nll_loss 12.408 | ppl 5436.08 | wps 42553.8 | wpb 510.9 | bsz 1 | num_updates 24370 | best_loss 8.233
2022-03-07 08:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 24370 updates
2022-03-07 08:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 253 @ 24370 updates, score 13.056) (writing took 2.2735310359857976 seconds)
2022-03-07 08:52:14 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-07 08:52:14 | INFO | train | epoch 253 | loss 2.268 | nll_loss 0.815 | ppl 1.76 | wps 22096.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24370 | lr 0.000202569 | gnorm 0.838 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 72046
2022-03-07 08:52:14 | INFO | fairseq.trainer | begin training epoch 254
2022-03-07 08:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:53:40 | INFO | train_inner | epoch 254:     30 / 97 loss=2.267, nll_loss=0.814, ppl=1.76, wps=22344, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=24400, lr=0.000202444, gnorm=0.835, loss_scale=16, train_wall=262, gb_free=8.1, wall=72132
2022-03-07 08:54:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 08:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:56:56 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.038 | nll_loss 12.393 | ppl 5379.08 | wps 42972.6 | wpb 510.9 | bsz 1 | num_updates 24466 | best_loss 8.233
2022-03-07 08:56:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 24466 updates
2022-03-07 08:56:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 08:56:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 254 @ 24466 updates, score 13.038) (writing took 2.25027941679582 seconds)
2022-03-07 08:56:58 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-07 08:56:58 | INFO | train | epoch 254 | loss 2.266 | nll_loss 0.813 | ppl 1.76 | wps 22109.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24466 | lr 0.000202171 | gnorm 0.849 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 72330
2022-03-07 08:56:58 | INFO | fairseq.trainer | begin training epoch 255
2022-03-07 08:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:58:36 | INFO | train_inner | epoch 255:     34 / 97 loss=2.266, nll_loss=0.813, ppl=1.76, wps=22137.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24500, lr=0.000202031, gnorm=0.849, loss_scale=16, train_wall=265, gb_free=8.1, wall=72428
2022-03-07 09:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:41 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.052 | nll_loss 12.4 | ppl 5405.9 | wps 42475.4 | wpb 510.9 | bsz 1 | num_updates 24562 | best_loss 8.233
2022-03-07 09:01:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 24562 updates
2022-03-07 09:01:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:01:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 255 @ 24562 updates, score 13.052) (writing took 2.373222829774022 seconds)
2022-03-07 09:01:43 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-07 09:01:43 | INFO | train | epoch 255 | loss 2.264 | nll_loss 0.811 | ppl 1.75 | wps 22079 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24562 | lr 0.000201775 | gnorm 0.848 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 72615
2022-03-07 09:01:43 | INFO | fairseq.trainer | begin training epoch 256
2022-03-07 09:01:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:32 | INFO | train_inner | epoch 256:     38 / 97 loss=2.262, nll_loss=0.809, ppl=1.75, wps=22119.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=24600, lr=0.000201619, gnorm=0.849, loss_scale=16, train_wall=265, gb_free=8.1, wall=72724
2022-03-07 09:06:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:06:25 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.039 | nll_loss 12.388 | ppl 5361.71 | wps 42737.4 | wpb 510.9 | bsz 1 | num_updates 24659 | best_loss 8.233
2022-03-07 09:06:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 24659 updates
2022-03-07 09:06:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 256 @ 24659 updates, score 13.039) (writing took 2.3949833982624114 seconds)
2022-03-07 09:06:28 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-07 09:06:28 | INFO | train | epoch 256 | loss 2.262 | nll_loss 0.809 | ppl 1.75 | wps 22318.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 24659 | lr 0.000201378 | gnorm 0.832 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 72900
2022-03-07 09:06:28 | INFO | fairseq.trainer | begin training epoch 257
2022-03-07 09:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:08:28 | INFO | train_inner | epoch 257:     42 / 97 loss=2.261, nll_loss=0.808, ppl=1.75, wps=22124.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24700, lr=0.000201211, gnorm=0.833, loss_scale=16, train_wall=265, gb_free=8.1, wall=73020
2022-03-07 09:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:11:10 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.075 | nll_loss 12.43 | ppl 5518.95 | wps 42215.1 | wpb 510.9 | bsz 1 | num_updates 24755 | best_loss 8.233
2022-03-07 09:11:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 24755 updates
2022-03-07 09:11:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:11:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:11:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 257 @ 24755 updates, score 13.075) (writing took 2.2185071031562984 seconds)
2022-03-07 09:11:12 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-07 09:11:12 | INFO | train | epoch 257 | loss 2.26 | nll_loss 0.807 | ppl 1.75 | wps 22115.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24755 | lr 0.000200987 | gnorm 0.843 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 73184
2022-03-07 09:11:12 | INFO | fairseq.trainer | begin training epoch 258
2022-03-07 09:11:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:13:20 | INFO | train_inner | epoch 258:     45 / 97 loss=2.259, nll_loss=0.806, ppl=1.75, wps=22373.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=24800, lr=0.000200805, gnorm=0.845, loss_scale=16, train_wall=262, gb_free=8.1, wall=73312
2022-03-07 09:13:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:15:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:54 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.085 | nll_loss 12.443 | ppl 5567.29 | wps 42909 | wpb 510.9 | bsz 1 | num_updates 24851 | best_loss 8.233
2022-03-07 09:15:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 24851 updates
2022-03-07 09:15:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:15:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:15:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 258 @ 24851 updates, score 13.085) (writing took 2.2162921731360257 seconds)
2022-03-07 09:15:56 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-07 09:15:56 | INFO | train | epoch 258 | loss 2.258 | nll_loss 0.805 | ppl 1.75 | wps 22133.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24851 | lr 0.000200599 | gnorm 0.847 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 73468
2022-03-07 09:15:56 | INFO | fairseq.trainer | begin training epoch 259
2022-03-07 09:15:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:16 | INFO | train_inner | epoch 259:     49 / 97 loss=2.256, nll_loss=0.803, ppl=1.74, wps=22156.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=24900, lr=0.000200401, gnorm=0.843, loss_scale=16, train_wall=265, gb_free=8.1, wall=73608
2022-03-07 09:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:20:38 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.024 | nll_loss 12.373 | ppl 5303.27 | wps 43030.8 | wpb 510.9 | bsz 1 | num_updates 24947 | best_loss 8.233
2022-03-07 09:20:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 24947 updates
2022-03-07 09:20:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 259 @ 24947 updates, score 13.024) (writing took 2.1892414623871446 seconds)
2022-03-07 09:20:40 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-07 09:20:40 | INFO | train | epoch 259 | loss 2.255 | nll_loss 0.802 | ppl 1.74 | wps 22124.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 24947 | lr 0.000200212 | gnorm 0.84 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 73752
2022-03-07 09:20:40 | INFO | fairseq.trainer | begin training epoch 260
2022-03-07 09:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:12 | INFO | train_inner | epoch 260:     53 / 97 loss=2.255, nll_loss=0.803, ppl=1.74, wps=22158.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25000, lr=0.0002, gnorm=0.834, loss_scale=16, train_wall=265, gb_free=8.1, wall=73904
2022-03-07 09:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:25:22 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.002 | nll_loss 12.351 | ppl 5224.53 | wps 42881.5 | wpb 510.9 | bsz 1 | num_updates 25044 | best_loss 8.233
2022-03-07 09:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 25044 updates
2022-03-07 09:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 260 @ 25044 updates, score 13.002) (writing took 2.26526804221794 seconds)
2022-03-07 09:25:24 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-07 09:25:24 | INFO | train | epoch 260 | loss 2.255 | nll_loss 0.803 | ppl 1.74 | wps 22348.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25044 | lr 0.000199824 | gnorm 0.846 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 74036
2022-03-07 09:25:25 | INFO | fairseq.trainer | begin training epoch 261
2022-03-07 09:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:28:07 | INFO | train_inner | epoch 261:     57 / 97 loss=2.255, nll_loss=0.802, ppl=1.74, wps=22141.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25100, lr=0.000199601, gnorm=0.843, loss_scale=16, train_wall=265, gb_free=8.1, wall=74199
2022-03-07 09:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:07 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.08 | nll_loss 12.439 | ppl 5551.59 | wps 43123.7 | wpb 510.9 | bsz 1 | num_updates 25140 | best_loss 8.233
2022-03-07 09:30:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 25140 updates
2022-03-07 09:30:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:30:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:30:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 261 @ 25140 updates, score 13.08) (writing took 2.663901835680008 seconds)
2022-03-07 09:30:09 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-07 09:30:09 | INFO | train | epoch 261 | loss 2.252 | nll_loss 0.799 | ppl 1.74 | wps 22069.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25140 | lr 0.000199442 | gnorm 0.829 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 74321
2022-03-07 09:30:09 | INFO | fairseq.trainer | begin training epoch 262
2022-03-07 09:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:33:01 | INFO | train_inner | epoch 262:     60 / 97 loss=2.252, nll_loss=0.799, ppl=1.74, wps=22321.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25200, lr=0.000199205, gnorm=0.828, loss_scale=16, train_wall=262, gb_free=8.1, wall=74493
2022-03-07 09:33:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:34:52 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.016 | nll_loss 12.371 | ppl 5296.32 | wps 43044.7 | wpb 510.9 | bsz 1 | num_updates 25236 | best_loss 8.233
2022-03-07 09:34:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 25236 updates
2022-03-07 09:34:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:34:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:34:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 262 @ 25236 updates, score 13.016) (writing took 2.1703650751151145 seconds)
2022-03-07 09:34:54 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-07 09:34:54 | INFO | train | epoch 262 | loss 2.251 | nll_loss 0.799 | ppl 1.74 | wps 22103.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25236 | lr 0.000199063 | gnorm 0.837 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 74606
2022-03-07 09:34:54 | INFO | fairseq.trainer | begin training epoch 263
2022-03-07 09:34:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:57 | INFO | train_inner | epoch 263:     64 / 97 loss=2.25, nll_loss=0.797, ppl=1.74, wps=22140.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=25300, lr=0.000198811, gnorm=0.848, loss_scale=16, train_wall=265, gb_free=8.1, wall=74789
2022-03-07 09:39:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:36 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.033 | nll_loss 12.382 | ppl 5339.05 | wps 43225 | wpb 510.9 | bsz 1 | num_updates 25333 | best_loss 8.233
2022-03-07 09:39:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 25333 updates
2022-03-07 09:39:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 263 @ 25333 updates, score 13.033) (writing took 2.28354555927217 seconds)
2022-03-07 09:39:38 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-07 09:39:38 | INFO | train | epoch 263 | loss 2.25 | nll_loss 0.797 | ppl 1.74 | wps 22351.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25333 | lr 0.000198681 | gnorm 0.84 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 74890
2022-03-07 09:39:38 | INFO | fairseq.trainer | begin training epoch 264
2022-03-07 09:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:40:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:42:52 | INFO | train_inner | epoch 264:     68 / 97 loss=2.249, nll_loss=0.796, ppl=1.74, wps=22165, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25400, lr=0.000198419, gnorm=0.835, loss_scale=16, train_wall=265, gb_free=8.1, wall=75084
2022-03-07 09:44:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:20 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.098 | nll_loss 12.458 | ppl 5625.25 | wps 42601.1 | wpb 510.9 | bsz 1 | num_updates 25429 | best_loss 8.233
2022-03-07 09:44:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 25429 updates
2022-03-07 09:44:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:44:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:44:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 264 @ 25429 updates, score 13.098) (writing took 2.3314212560653687 seconds)
2022-03-07 09:44:22 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-07 09:44:22 | INFO | train | epoch 264 | loss 2.247 | nll_loss 0.794 | ppl 1.73 | wps 22109.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25429 | lr 0.000198306 | gnorm 0.836 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 75174
2022-03-07 09:44:22 | INFO | fairseq.trainer | begin training epoch 265
2022-03-07 09:44:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:46:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:47:48 | INFO | train_inner | epoch 265:     72 / 97 loss=2.245, nll_loss=0.792, ppl=1.73, wps=22139.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25500, lr=0.00019803, gnorm=0.831, loss_scale=16, train_wall=265, gb_free=8.1, wall=75380
2022-03-07 09:48:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:49:04 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.06 | nll_loss 12.411 | ppl 5446 | wps 42660.2 | wpb 510.9 | bsz 1 | num_updates 25525 | best_loss 8.233
2022-03-07 09:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 25525 updates
2022-03-07 09:49:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:49:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:49:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 265 @ 25525 updates, score 13.06) (writing took 2.232968387193978 seconds)
2022-03-07 09:49:07 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-07 09:49:07 | INFO | train | epoch 265 | loss 2.245 | nll_loss 0.792 | ppl 1.73 | wps 22126.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25525 | lr 0.000197933 | gnorm 0.828 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 75458
2022-03-07 09:49:07 | INFO | fairseq.trainer | begin training epoch 266
2022-03-07 09:49:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:52:41 | INFO | train_inner | epoch 266:     75 / 97 loss=2.245, nll_loss=0.792, ppl=1.73, wps=22368.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=25600, lr=0.000197642, gnorm=0.835, loss_scale=16, train_wall=262, gb_free=8.1, wall=75673
2022-03-07 09:52:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 09:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:49 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.113 | nll_loss 12.472 | ppl 5680.37 | wps 42674.2 | wpb 510.9 | bsz 1 | num_updates 25621 | best_loss 8.233
2022-03-07 09:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 25621 updates
2022-03-07 09:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:53:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:53:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 266 @ 25621 updates, score 13.113) (writing took 2.2744701760821044 seconds)
2022-03-07 09:53:51 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-07 09:53:51 | INFO | train | epoch 266 | loss 2.244 | nll_loss 0.791 | ppl 1.73 | wps 22113.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25621 | lr 0.000197561 | gnorm 0.839 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 75743
2022-03-07 09:53:51 | INFO | fairseq.trainer | begin training epoch 267
2022-03-07 09:53:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:57:37 | INFO | train_inner | epoch 267:     79 / 97 loss=2.242, nll_loss=0.789, ppl=1.73, wps=22116, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=25700, lr=0.000197257, gnorm=0.835, loss_scale=16, train_wall=265, gb_free=8.1, wall=75969
2022-03-07 09:58:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:58:33 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.035 | nll_loss 12.388 | ppl 5358.97 | wps 42854.4 | wpb 510.9 | bsz 1 | num_updates 25718 | best_loss 8.233
2022-03-07 09:58:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 25718 updates
2022-03-07 09:58:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 09:58:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 267 @ 25718 updates, score 13.035) (writing took 2.2538636387325823 seconds)
2022-03-07 09:58:36 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-07 09:58:36 | INFO | train | epoch 267 | loss 2.242 | nll_loss 0.789 | ppl 1.73 | wps 22312.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 25718 | lr 0.000197188 | gnorm 0.829 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76027
2022-03-07 09:58:36 | INFO | fairseq.trainer | begin training epoch 268
2022-03-07 09:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:02:33 | INFO | train_inner | epoch 268:     83 / 97 loss=2.242, nll_loss=0.789, ppl=1.73, wps=22129.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25800, lr=0.000196875, gnorm=0.839, loss_scale=16, train_wall=265, gb_free=8.1, wall=76265
2022-03-07 10:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:03:18 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.095 | nll_loss 12.456 | ppl 5619.66 | wps 42964.5 | wpb 510.9 | bsz 1 | num_updates 25814 | best_loss 8.233
2022-03-07 10:03:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 25814 updates
2022-03-07 10:03:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:03:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:03:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 268 @ 25814 updates, score 13.095) (writing took 2.2444365420378745 seconds)
2022-03-07 10:03:20 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-07 10:03:20 | INFO | train | epoch 268 | loss 2.241 | nll_loss 0.788 | ppl 1.73 | wps 22104.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25814 | lr 0.000196821 | gnorm 0.843 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76312
2022-03-07 10:03:20 | INFO | fairseq.trainer | begin training epoch 269
2022-03-07 10:03:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:05:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:07:29 | INFO | train_inner | epoch 269:     87 / 97 loss=2.239, nll_loss=0.786, ppl=1.72, wps=22150.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=25900, lr=0.000196494, gnorm=0.826, loss_scale=16, train_wall=265, gb_free=8.1, wall=76560
2022-03-07 10:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:02 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.081 | nll_loss 12.44 | ppl 5557.06 | wps 42910.6 | wpb 510.9 | bsz 1 | num_updates 25910 | best_loss 8.233
2022-03-07 10:08:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 25910 updates
2022-03-07 10:08:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:08:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:08:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 269 @ 25910 updates, score 13.081) (writing took 2.229623874183744 seconds)
2022-03-07 10:08:04 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-07 10:08:04 | INFO | train | epoch 269 | loss 2.237 | nll_loss 0.784 | ppl 1.72 | wps 22119.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 25910 | lr 0.000196456 | gnorm 0.824 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 76596
2022-03-07 10:08:04 | INFO | fairseq.trainer | begin training epoch 270
2022-03-07 10:08:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:11:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:12:24 | INFO | train_inner | epoch 270:     91 / 97 loss=2.239, nll_loss=0.786, ppl=1.72, wps=22132.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26000, lr=0.000196116, gnorm=0.83, loss_scale=16, train_wall=265, gb_free=8.1, wall=76856
2022-03-07 10:12:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:12:47 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.099 | nll_loss 12.46 | ppl 5633.02 | wps 42872.9 | wpb 510.9 | bsz 1 | num_updates 26006 | best_loss 8.233
2022-03-07 10:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 26006 updates
2022-03-07 10:12:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 270 @ 26006 updates, score 13.099) (writing took 2.241365972906351 seconds)
2022-03-07 10:12:49 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-07 10:12:49 | INFO | train | epoch 270 | loss 2.238 | nll_loss 0.785 | ppl 1.72 | wps 22097.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26006 | lr 0.000196094 | gnorm 0.827 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 76881
2022-03-07 10:12:49 | INFO | fairseq.trainer | begin training epoch 271
2022-03-07 10:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:18 | INFO | train_inner | epoch 271:     94 / 97 loss=2.235, nll_loss=0.782, ppl=1.72, wps=22340.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26100, lr=0.00019574, gnorm=0.83, loss_scale=16, train_wall=263, gb_free=8.1, wall=77150
2022-03-07 10:17:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:31 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.116 | nll_loss 12.477 | ppl 5702.72 | wps 42936.7 | wpb 510.9 | bsz 1 | num_updates 26103 | best_loss 8.233
2022-03-07 10:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 26103 updates
2022-03-07 10:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:17:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 271 @ 26103 updates, score 13.116) (writing took 2.328507541678846 seconds)
2022-03-07 10:17:33 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-07 10:17:33 | INFO | train | epoch 271 | loss 2.235 | nll_loss 0.782 | ppl 1.72 | wps 22314.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26103 | lr 0.000195729 | gnorm 0.831 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 77165
2022-03-07 10:17:33 | INFO | fairseq.trainer | begin training epoch 272
2022-03-07 10:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:22:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:15 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.041 | nll_loss 12.399 | ppl 5400.04 | wps 43167.1 | wpb 510.9 | bsz 1 | num_updates 26199 | best_loss 8.233
2022-03-07 10:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 26199 updates
2022-03-07 10:22:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:22:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:22:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 272 @ 26199 updates, score 13.041) (writing took 2.2691025780513883 seconds)
2022-03-07 10:22:18 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-07 10:22:18 | INFO | train | epoch 272 | loss 2.233 | nll_loss 0.78 | ppl 1.72 | wps 22130.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26199 | lr 0.00019537 | gnorm 0.826 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 77449
2022-03-07 10:22:18 | INFO | fairseq.trainer | begin training epoch 273
2022-03-07 10:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:22:20 | INFO | train_inner | epoch 273:      1 / 97 loss=2.234, nll_loss=0.781, ppl=1.72, wps=21609.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=26200, lr=0.000195366, gnorm=0.827, loss_scale=16, train_wall=265, gb_free=8.1, wall=77452
2022-03-07 10:25:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:27:00 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.15 | nll_loss 12.511 | ppl 5838.38 | wps 43142.7 | wpb 510.9 | bsz 1 | num_updates 26295 | best_loss 8.233
2022-03-07 10:27:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 26295 updates
2022-03-07 10:27:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 273 @ 26295 updates, score 13.15) (writing took 2.2700485959649086 seconds)
2022-03-07 10:27:02 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-07 10:27:02 | INFO | train | epoch 273 | loss 2.232 | nll_loss 0.779 | ppl 1.72 | wps 22096 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26295 | lr 0.000195013 | gnorm 0.839 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 77734
2022-03-07 10:27:02 | INFO | fairseq.trainer | begin training epoch 274
2022-03-07 10:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:16 | INFO | train_inner | epoch 274:      5 / 97 loss=2.231, nll_loss=0.778, ppl=1.71, wps=22129.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26300, lr=0.000194994, gnorm=0.839, loss_scale=16, train_wall=265, gb_free=8.1, wall=77748
2022-03-07 10:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:44 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.126 | nll_loss 12.49 | ppl 5753.04 | wps 42469.5 | wpb 510.9 | bsz 1 | num_updates 26392 | best_loss 8.233
2022-03-07 10:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 26392 updates
2022-03-07 10:31:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:31:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:31:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 274 @ 26392 updates, score 13.126) (writing took 2.203249934129417 seconds)
2022-03-07 10:31:47 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-07 10:31:47 | INFO | train | epoch 274 | loss 2.23 | nll_loss 0.777 | ppl 1.71 | wps 22330.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26392 | lr 0.000194654 | gnorm 0.826 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78018
2022-03-07 10:31:47 | INFO | fairseq.trainer | begin training epoch 275
2022-03-07 10:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:32:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:32:12 | INFO | train_inner | epoch 275:      9 / 97 loss=2.229, nll_loss=0.776, ppl=1.71, wps=22132.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26400, lr=0.000194625, gnorm=0.823, loss_scale=16, train_wall=265, gb_free=8.1, wall=78044
2022-03-07 10:36:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:36:29 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.077 | nll_loss 12.439 | ppl 5551.19 | wps 42847.5 | wpb 510.9 | bsz 1 | num_updates 26488 | best_loss 8.233
2022-03-07 10:36:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 26488 updates
2022-03-07 10:36:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:36:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 275 @ 26488 updates, score 13.077) (writing took 2.2052877037785947 seconds)
2022-03-07 10:36:31 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-07 10:36:31 | INFO | train | epoch 275 | loss 2.228 | nll_loss 0.775 | ppl 1.71 | wps 22092.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26488 | lr 0.000194301 | gnorm 0.828 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 78303
2022-03-07 10:36:31 | INFO | fairseq.trainer | begin training epoch 276
2022-03-07 10:36:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:37:05 | INFO | train_inner | epoch 276:     12 / 97 loss=2.226, nll_loss=0.773, ppl=1.71, wps=22343.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26500, lr=0.000194257, gnorm=0.827, loss_scale=16, train_wall=262, gb_free=8.1, wall=78337
2022-03-07 10:38:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:41:13 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.088 | nll_loss 12.45 | ppl 5595.54 | wps 42691.8 | wpb 510.9 | bsz 1 | num_updates 26584 | best_loss 8.233
2022-03-07 10:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 26584 updates
2022-03-07 10:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 276 @ 26584 updates, score 13.088) (writing took 2.1640752060338855 seconds)
2022-03-07 10:41:15 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-07 10:41:15 | INFO | train | epoch 276 | loss 2.227 | nll_loss 0.774 | ppl 1.71 | wps 22129.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26584 | lr 0.00019395 | gnorm 0.84 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 78587
2022-03-07 10:41:15 | INFO | fairseq.trainer | begin training epoch 277
2022-03-07 10:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:42:01 | INFO | train_inner | epoch 277:     16 / 97 loss=2.226, nll_loss=0.774, ppl=1.71, wps=22161.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26600, lr=0.000193892, gnorm=0.84, loss_scale=16, train_wall=265, gb_free=8.1, wall=78633
2022-03-07 10:44:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:45:57 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.057 | nll_loss 12.416 | ppl 5465.17 | wps 43190.5 | wpb 510.9 | bsz 1 | num_updates 26680 | best_loss 8.233
2022-03-07 10:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 26680 updates
2022-03-07 10:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 277 @ 26680 updates, score 13.057) (writing took 2.3814858496189117 seconds)
2022-03-07 10:45:59 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-07 10:45:59 | INFO | train | epoch 277 | loss 2.225 | nll_loss 0.772 | ppl 1.71 | wps 22144.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26680 | lr 0.000193601 | gnorm 0.827 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 78871
2022-03-07 10:45:59 | INFO | fairseq.trainer | begin training epoch 278
2022-03-07 10:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:56 | INFO | train_inner | epoch 278:     20 / 97 loss=2.224, nll_loss=0.771, ppl=1.71, wps=22180.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26700, lr=0.000193528, gnorm=0.826, loss_scale=16, train_wall=264, gb_free=8.1, wall=78928
2022-03-07 10:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:50:40 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.079 | nll_loss 12.443 | ppl 5567.93 | wps 43318.9 | wpb 510.9 | bsz 1 | num_updates 26777 | best_loss 8.233
2022-03-07 10:50:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 26777 updates
2022-03-07 10:50:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:50:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:50:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 278 @ 26777 updates, score 13.079) (writing took 2.330316523090005 seconds)
2022-03-07 10:50:43 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-07 10:50:43 | INFO | train | epoch 278 | loss 2.224 | nll_loss 0.771 | ppl 1.71 | wps 22405.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 26777 | lr 0.00019325 | gnorm 0.825 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 79155
2022-03-07 10:50:43 | INFO | fairseq.trainer | begin training epoch 279
2022-03-07 10:50:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:51:48 | INFO | train_inner | epoch 279:     23 / 97 loss=2.223, nll_loss=0.77, ppl=1.71, wps=22425.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26800, lr=0.000193167, gnorm=0.821, loss_scale=32, train_wall=262, gb_free=8.1, wall=79220
2022-03-07 10:52:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 10:55:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:55:24 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.051 | nll_loss 12.41 | ppl 5443 | wps 42798.5 | wpb 510.9 | bsz 1 | num_updates 26873 | best_loss 8.233
2022-03-07 10:55:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 26873 updates
2022-03-07 10:55:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:55:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 10:55:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 279 @ 26873 updates, score 13.051) (writing took 2.224887741263956 seconds)
2022-03-07 10:55:27 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-07 10:55:27 | INFO | train | epoch 279 | loss 2.221 | nll_loss 0.768 | ppl 1.7 | wps 22152.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26873 | lr 0.000192904 | gnorm 0.822 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 79438
2022-03-07 10:55:27 | INFO | fairseq.trainer | begin training epoch 280
2022-03-07 10:55:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:56:44 | INFO | train_inner | epoch 280:     27 / 97 loss=2.219, nll_loss=0.767, ppl=1.7, wps=22175.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=26900, lr=0.000192807, gnorm=0.825, loss_scale=16, train_wall=265, gb_free=8.1, wall=79516
2022-03-07 10:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:08 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.028 | nll_loss 12.389 | ppl 5363.37 | wps 42956.1 | wpb 510.9 | bsz 1 | num_updates 26969 | best_loss 8.233
2022-03-07 11:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 26969 updates
2022-03-07 11:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 280 @ 26969 updates, score 13.028) (writing took 2.212033092044294 seconds)
2022-03-07 11:00:10 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-07 11:00:10 | INFO | train | epoch 280 | loss 2.22 | nll_loss 0.768 | ppl 1.7 | wps 22148.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 26969 | lr 0.000192561 | gnorm 0.828 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 79722
2022-03-07 11:00:10 | INFO | fairseq.trainer | begin training epoch 281
2022-03-07 11:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:01:39 | INFO | train_inner | epoch 281:     31 / 97 loss=2.22, nll_loss=0.768, ppl=1.7, wps=22180.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27000, lr=0.00019245, gnorm=0.83, loss_scale=16, train_wall=265, gb_free=8.1, wall=79811
2022-03-07 11:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:04:52 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.112 | nll_loss 12.474 | ppl 5687.95 | wps 42816.6 | wpb 510.9 | bsz 1 | num_updates 27066 | best_loss 8.233
2022-03-07 11:04:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 27066 updates
2022-03-07 11:04:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:04:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:04:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 281 @ 27066 updates, score 13.112) (writing took 2.255819879937917 seconds)
2022-03-07 11:04:54 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-07 11:04:54 | INFO | train | epoch 281 | loss 2.218 | nll_loss 0.766 | ppl 1.7 | wps 22371.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27066 | lr 0.000192215 | gnorm 0.828 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80006
2022-03-07 11:04:54 | INFO | fairseq.trainer | begin training epoch 282
2022-03-07 11:04:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:05:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:06:34 | INFO | train_inner | epoch 282:     35 / 97 loss=2.216, nll_loss=0.763, ppl=1.7, wps=22183.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=27100, lr=0.000192095, gnorm=0.817, loss_scale=16, train_wall=264, gb_free=8.1, wall=80106
2022-03-07 11:09:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:09:36 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.049 | nll_loss 12.412 | ppl 5448.38 | wps 42894.2 | wpb 510.9 | bsz 1 | num_updates 27162 | best_loss 8.233
2022-03-07 11:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 27162 updates
2022-03-07 11:09:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:09:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 282 @ 27162 updates, score 13.049) (writing took 2.320899683982134 seconds)
2022-03-07 11:09:38 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-07 11:09:38 | INFO | train | epoch 282 | loss 2.217 | nll_loss 0.765 | ppl 1.7 | wps 22154.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27162 | lr 0.000191875 | gnorm 0.818 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80290
2022-03-07 11:09:38 | INFO | fairseq.trainer | begin training epoch 283
2022-03-07 11:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:11:27 | INFO | train_inner | epoch 283:     38 / 97 loss=2.217, nll_loss=0.764, ppl=1.7, wps=22393.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27200, lr=0.000191741, gnorm=0.824, loss_scale=16, train_wall=262, gb_free=8.1, wall=80399
2022-03-07 11:11:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:14:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:14:19 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.07 | nll_loss 12.435 | ppl 5536.63 | wps 43496.7 | wpb 510.9 | bsz 1 | num_updates 27258 | best_loss 8.233
2022-03-07 11:14:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 27258 updates
2022-03-07 11:14:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:14:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:14:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 283 @ 27258 updates, score 13.07) (writing took 2.26034435397014 seconds)
2022-03-07 11:14:22 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-07 11:14:22 | INFO | train | epoch 283 | loss 2.215 | nll_loss 0.763 | ppl 1.7 | wps 22174.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27258 | lr 0.000191537 | gnorm 0.835 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 80574
2022-03-07 11:14:22 | INFO | fairseq.trainer | begin training epoch 284
2022-03-07 11:14:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:16:21 | INFO | train_inner | epoch 284:     42 / 97 loss=2.214, nll_loss=0.761, ppl=1.69, wps=22247.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=27300, lr=0.00019139, gnorm=0.826, loss_scale=16, train_wall=264, gb_free=8.1, wall=80693
2022-03-07 11:17:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:18:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:19:02 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.073 | nll_loss 12.437 | ppl 5545.09 | wps 43638 | wpb 510.9 | bsz 1 | num_updates 27354 | best_loss 8.233
2022-03-07 11:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 27354 updates
2022-03-07 11:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:19:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:19:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 284 @ 27354 updates, score 13.073) (writing took 2.253603687044233 seconds)
2022-03-07 11:19:04 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-07 11:19:04 | INFO | train | epoch 284 | loss 2.213 | nll_loss 0.76 | ppl 1.69 | wps 22234.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27354 | lr 0.000191201 | gnorm 0.818 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 80856
2022-03-07 11:19:04 | INFO | fairseq.trainer | begin training epoch 285
2022-03-07 11:19:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:15 | INFO | train_inner | epoch 285:     46 / 97 loss=2.214, nll_loss=0.762, ppl=1.7, wps=22262.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27400, lr=0.00019104, gnorm=0.829, loss_scale=16, train_wall=264, gb_free=8.1, wall=80987
2022-03-07 11:23:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:23:45 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.165 | nll_loss 12.531 | ppl 5918.09 | wps 43674.7 | wpb 510.9 | bsz 1 | num_updates 27451 | best_loss 8.233
2022-03-07 11:23:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 27451 updates
2022-03-07 11:23:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:23:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:23:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 285 @ 27451 updates, score 13.165) (writing took 2.3271830920130014 seconds)
2022-03-07 11:23:47 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-07 11:23:47 | INFO | train | epoch 285 | loss 2.213 | nll_loss 0.761 | ppl 1.69 | wps 22464.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27451 | lr 0.000190863 | gnorm 0.82 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81139
2022-03-07 11:23:47 | INFO | fairseq.trainer | begin training epoch 286
2022-03-07 11:23:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:26:09 | INFO | train_inner | epoch 286:     50 / 97 loss=2.212, nll_loss=0.76, ppl=1.69, wps=22264.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27500, lr=0.000190693, gnorm=0.819, loss_scale=16, train_wall=264, gb_free=8.1, wall=81281
2022-03-07 11:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:28:28 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.044 | nll_loss 12.405 | ppl 5422.21 | wps 43725.5 | wpb 510.9 | bsz 1 | num_updates 27547 | best_loss 8.233
2022-03-07 11:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 27547 updates
2022-03-07 11:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 286 @ 27547 updates, score 13.044) (writing took 2.267372750211507 seconds)
2022-03-07 11:28:30 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-07 11:28:30 | INFO | train | epoch 286 | loss 2.211 | nll_loss 0.758 | ppl 1.69 | wps 22237.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27547 | lr 0.00019053 | gnorm 0.827 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81422
2022-03-07 11:28:30 | INFO | fairseq.trainer | begin training epoch 287
2022-03-07 11:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:00 | INFO | train_inner | epoch 287:     53 / 97 loss=2.208, nll_loss=0.755, ppl=1.69, wps=22494.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27600, lr=0.000190347, gnorm=0.825, loss_scale=16, train_wall=261, gb_free=8.1, wall=81572
2022-03-07 11:31:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:33:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:33:10 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.112 | nll_loss 12.474 | ppl 5689.08 | wps 43483.6 | wpb 510.9 | bsz 1 | num_updates 27643 | best_loss 8.233
2022-03-07 11:33:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 27643 updates
2022-03-07 11:33:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 287 @ 27643 updates, score 13.112) (writing took 2.2150611616671085 seconds)
2022-03-07 11:33:13 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-07 11:33:13 | INFO | train | epoch 287 | loss 2.208 | nll_loss 0.755 | ppl 1.69 | wps 22248.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27643 | lr 0.000190199 | gnorm 0.821 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81704
2022-03-07 11:33:13 | INFO | fairseq.trainer | begin training epoch 288
2022-03-07 11:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:54 | INFO | train_inner | epoch 288:     57 / 97 loss=2.208, nll_loss=0.755, ppl=1.69, wps=22286, ups=0.34, wpb=65495, bsz=127.9, num_updates=27700, lr=0.000190003, gnorm=0.816, loss_scale=16, train_wall=264, gb_free=8.1, wall=81866
2022-03-07 11:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:37:53 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.087 | nll_loss 12.453 | ppl 5608.65 | wps 43188.1 | wpb 510.9 | bsz 1 | num_updates 27740 | best_loss 8.233
2022-03-07 11:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 27740 updates
2022-03-07 11:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 288 @ 27740 updates, score 13.087) (writing took 2.2282795761711895 seconds)
2022-03-07 11:37:55 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-07 11:37:55 | INFO | train | epoch 288 | loss 2.208 | nll_loss 0.756 | ppl 1.69 | wps 22479.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 27740 | lr 0.000189866 | gnorm 0.826 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 81987
2022-03-07 11:37:55 | INFO | fairseq.trainer | begin training epoch 289
2022-03-07 11:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:39:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:40:48 | INFO | train_inner | epoch 289:     61 / 97 loss=2.209, nll_loss=0.757, ppl=1.69, wps=22280, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=27800, lr=0.000189661, gnorm=0.828, loss_scale=16, train_wall=264, gb_free=8.1, wall=82160
2022-03-07 11:42:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:42:35 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.11 | nll_loss 12.475 | ppl 5693.44 | wps 43570.2 | wpb 510.9 | bsz 1 | num_updates 27836 | best_loss 8.233
2022-03-07 11:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 27836 updates
2022-03-07 11:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:42:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 289 @ 27836 updates, score 13.11) (writing took 2.2131344848312438 seconds)
2022-03-07 11:42:38 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-07 11:42:38 | INFO | train | epoch 289 | loss 2.206 | nll_loss 0.754 | ppl 1.69 | wps 22259.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27836 | lr 0.000189538 | gnorm 0.82 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82269
2022-03-07 11:42:38 | INFO | fairseq.trainer | begin training epoch 290
2022-03-07 11:42:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:39 | INFO | train_inner | epoch 290:     64 / 97 loss=2.205, nll_loss=0.753, ppl=1.68, wps=22511.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=27900, lr=0.000189321, gnorm=0.817, loss_scale=16, train_wall=261, gb_free=8.1, wall=82451
2022-03-07 11:46:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:18 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.044 | nll_loss 12.406 | ppl 5427.11 | wps 43712 | wpb 510.9 | bsz 1 | num_updates 27932 | best_loss 8.233
2022-03-07 11:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 27932 updates
2022-03-07 11:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:47:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 290 @ 27932 updates, score 13.044) (writing took 2.243526096921414 seconds)
2022-03-07 11:47:20 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-07 11:47:20 | INFO | train | epoch 290 | loss 2.204 | nll_loss 0.752 | ppl 1.68 | wps 22261.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 27932 | lr 0.000189212 | gnorm 0.819 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82552
2022-03-07 11:47:20 | INFO | fairseq.trainer | begin training epoch 291
2022-03-07 11:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:33 | INFO | train_inner | epoch 291:     68 / 97 loss=2.203, nll_loss=0.751, ppl=1.68, wps=22292.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=28000, lr=0.000188982, gnorm=0.829, loss_scale=16, train_wall=264, gb_free=8.1, wall=82745
2022-03-07 11:51:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:52:00 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.073 | nll_loss 12.437 | ppl 5543.81 | wps 43512 | wpb 510.9 | bsz 1 | num_updates 28029 | best_loss 8.233
2022-03-07 11:52:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 28029 updates
2022-03-07 11:52:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:52:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:52:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 291 @ 28029 updates, score 13.073) (writing took 2.2437086221762 seconds)
2022-03-07 11:52:03 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-07 11:52:03 | INFO | train | epoch 291 | loss 2.204 | nll_loss 0.751 | ppl 1.68 | wps 22485 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28029 | lr 0.000188884 | gnorm 0.826 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 82834
2022-03-07 11:52:03 | INFO | fairseq.trainer | begin training epoch 292
2022-03-07 11:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 11:55:27 | INFO | train_inner | epoch 292:     72 / 97 loss=2.202, nll_loss=0.749, ppl=1.68, wps=22267.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=28100, lr=0.000188646, gnorm=0.822, loss_scale=16, train_wall=264, gb_free=8.1, wall=83039
2022-03-07 11:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:56:43 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.11 | nll_loss 12.48 | ppl 5712.4 | wps 43613.4 | wpb 510.9 | bsz 1 | num_updates 28125 | best_loss 8.233
2022-03-07 11:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 28125 updates
2022-03-07 11:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 11:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 292 @ 28125 updates, score 13.11) (writing took 2.1974478559568524 seconds)
2022-03-07 11:56:45 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-07 11:56:45 | INFO | train | epoch 292 | loss 2.201 | nll_loss 0.748 | ppl 1.68 | wps 22237.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28125 | lr 0.000188562 | gnorm 0.82 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 83117
2022-03-07 11:56:45 | INFO | fairseq.trainer | begin training epoch 293
2022-03-07 11:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:00:21 | INFO | train_inner | epoch 293:     76 / 97 loss=2.201, nll_loss=0.749, ppl=1.68, wps=22293.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28200, lr=0.000188311, gnorm=0.82, loss_scale=16, train_wall=264, gb_free=8.1, wall=83333
2022-03-07 12:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:01:25 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.096 | nll_loss 12.462 | ppl 5643.74 | wps 43499.6 | wpb 510.9 | bsz 1 | num_updates 28221 | best_loss 8.233
2022-03-07 12:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 28221 updates
2022-03-07 12:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 293 @ 28221 updates, score 13.096) (writing took 2.193559646140784 seconds)
2022-03-07 12:01:28 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-07 12:01:28 | INFO | train | epoch 293 | loss 2.2 | nll_loss 0.748 | ppl 1.68 | wps 22262.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28221 | lr 0.000188241 | gnorm 0.818 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 83400
2022-03-07 12:01:28 | INFO | fairseq.trainer | begin training epoch 294
2022-03-07 12:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:05:12 | INFO | train_inner | epoch 294:     79 / 97 loss=2.2, nll_loss=0.747, ppl=1.68, wps=22504.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28300, lr=0.000187978, gnorm=0.816, loss_scale=16, train_wall=261, gb_free=8.1, wall=83624
2022-03-07 12:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:06:08 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.07 | nll_loss 12.434 | ppl 5534.34 | wps 43789.8 | wpb 510.9 | bsz 1 | num_updates 28318 | best_loss 8.233
2022-03-07 12:06:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 28318 updates
2022-03-07 12:06:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 294 @ 28318 updates, score 13.07) (writing took 2.2353044291958213 seconds)
2022-03-07 12:06:10 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-07 12:06:10 | INFO | train | epoch 294 | loss 2.199 | nll_loss 0.747 | ppl 1.68 | wps 22483.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28318 | lr 0.000187918 | gnorm 0.821 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 83682
2022-03-07 12:06:10 | INFO | fairseq.trainer | begin training epoch 295
2022-03-07 12:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:10:06 | INFO | train_inner | epoch 295:     83 / 97 loss=2.197, nll_loss=0.745, ppl=1.68, wps=22289, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28400, lr=0.000187647, gnorm=0.816, loss_scale=16, train_wall=264, gb_free=8.1, wall=83918
2022-03-07 12:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:10:50 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.151 | nll_loss 12.524 | ppl 5889.17 | wps 43507.5 | wpb 510.9 | bsz 1 | num_updates 28414 | best_loss 8.233
2022-03-07 12:10:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 28414 updates
2022-03-07 12:10:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:10:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:10:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 295 @ 28414 updates, score 13.151) (writing took 2.2399640921503305 seconds)
2022-03-07 12:10:53 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 12:10:53 | INFO | train | epoch 295 | loss 2.196 | nll_loss 0.743 | ppl 1.67 | wps 22257.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28414 | lr 0.0001876 | gnorm 0.812 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 83965
2022-03-07 12:10:53 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 12:10:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:15:00 | INFO | train_inner | epoch 296:     87 / 97 loss=2.198, nll_loss=0.745, ppl=1.68, wps=22299.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28500, lr=0.000187317, gnorm=0.816, loss_scale=16, train_wall=264, gb_free=8.1, wall=84211
2022-03-07 12:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:15:33 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.133 | nll_loss 12.501 | ppl 5798 | wps 43563.3 | wpb 510.9 | bsz 1 | num_updates 28510 | best_loss 8.233
2022-03-07 12:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 28510 updates
2022-03-07 12:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 296 @ 28510 updates, score 13.133) (writing took 2.2232565940357745 seconds)
2022-03-07 12:15:35 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 12:15:35 | INFO | train | epoch 296 | loss 2.196 | nll_loss 0.744 | ppl 1.67 | wps 22265.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28510 | lr 0.000187284 | gnorm 0.815 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 84247
2022-03-07 12:15:35 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 12:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:19:53 | INFO | train_inner | epoch 297:     91 / 97 loss=2.196, nll_loss=0.744, ppl=1.67, wps=22280.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28600, lr=0.000186989, gnorm=0.813, loss_scale=16, train_wall=264, gb_free=8.1, wall=84505
2022-03-07 12:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:20:15 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.11 | nll_loss 12.475 | ppl 5694.4 | wps 43654.1 | wpb 510.9 | bsz 1 | num_updates 28606 | best_loss 8.233
2022-03-07 12:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 28606 updates
2022-03-07 12:20:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 297 @ 28606 updates, score 13.11) (writing took 2.211750125978142 seconds)
2022-03-07 12:20:18 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 12:20:18 | INFO | train | epoch 297 | loss 2.195 | nll_loss 0.742 | ppl 1.67 | wps 22257.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28606 | lr 0.00018697 | gnorm 0.811 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 84529
2022-03-07 12:20:18 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 12:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:24:45 | INFO | train_inner | epoch 298:     94 / 97 loss=2.194, nll_loss=0.741, ppl=1.67, wps=22501.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28700, lr=0.000186663, gnorm=0.818, loss_scale=16, train_wall=261, gb_free=8.1, wall=84796
2022-03-07 12:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:24:58 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.072 | nll_loss 12.437 | ppl 5544.54 | wps 43462 | wpb 510.9 | bsz 1 | num_updates 28703 | best_loss 8.233
2022-03-07 12:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 28703 updates
2022-03-07 12:24:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 298 @ 28703 updates, score 13.072) (writing took 2.2487335870973766 seconds)
2022-03-07 12:25:00 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 12:25:00 | INFO | train | epoch 298 | loss 2.193 | nll_loss 0.741 | ppl 1.67 | wps 22477.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28703 | lr 0.000186654 | gnorm 0.818 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 84812
2022-03-07 12:25:00 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 12:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:29:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:29:41 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.089 | nll_loss 12.456 | ppl 5617.35 | wps 43546.3 | wpb 510.9 | bsz 1 | num_updates 28799 | best_loss 8.233
2022-03-07 12:29:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 28799 updates
2022-03-07 12:29:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:29:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 299 @ 28799 updates, score 13.089) (writing took 2.22185564879328 seconds)
2022-03-07 12:29:43 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 12:29:43 | INFO | train | epoch 299 | loss 2.191 | nll_loss 0.739 | ppl 1.67 | wps 22250.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28799 | lr 0.000186342 | gnorm 0.813 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85095
2022-03-07 12:29:43 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 12:29:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:29:46 | INFO | train_inner | epoch 300:      1 / 97 loss=2.192, nll_loss=0.739, ppl=1.67, wps=21733.8, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=28800, lr=0.000186339, gnorm=0.813, loss_scale=16, train_wall=264, gb_free=8.1, wall=85098
2022-03-07 12:32:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:23 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.081 | nll_loss 12.447 | ppl 5581.87 | wps 43487.1 | wpb 510.9 | bsz 1 | num_updates 28895 | best_loss 8.233
2022-03-07 12:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 28895 updates
2022-03-07 12:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:34:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 300 @ 28895 updates, score 13.081) (writing took 2.252222347073257 seconds)
2022-03-07 12:34:25 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 12:34:25 | INFO | train | epoch 300 | loss 2.19 | nll_loss 0.738 | ppl 1.67 | wps 22245.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 28895 | lr 0.000186032 | gnorm 0.815 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85377
2022-03-07 12:34:25 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 12:34:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:40 | INFO | train_inner | epoch 301:      5 / 97 loss=2.189, nll_loss=0.737, ppl=1.67, wps=22280.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=28900, lr=0.000186016, gnorm=0.816, loss_scale=16, train_wall=264, gb_free=8.1, wall=85392
2022-03-07 12:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:06 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.109 | nll_loss 12.476 | ppl 5696.69 | wps 43465.9 | wpb 510.9 | bsz 1 | num_updates 28992 | best_loss 8.233
2022-03-07 12:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 28992 updates
2022-03-07 12:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 301 @ 28992 updates, score 13.109) (writing took 2.337052179966122 seconds)
2022-03-07 12:39:08 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 12:39:08 | INFO | train | epoch 301 | loss 2.189 | nll_loss 0.737 | ppl 1.67 | wps 22473.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 28992 | lr 0.000185721 | gnorm 0.82 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85660
2022-03-07 12:39:08 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 12:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:39:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:39:34 | INFO | train_inner | epoch 302:      9 / 97 loss=2.188, nll_loss=0.736, ppl=1.67, wps=22270.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29000, lr=0.000185695, gnorm=0.818, loss_scale=16, train_wall=264, gb_free=8.1, wall=85686
2022-03-07 12:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:48 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.112 | nll_loss 12.483 | ppl 5724.6 | wps 43483.8 | wpb 510.9 | bsz 1 | num_updates 29088 | best_loss 8.233
2022-03-07 12:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 29088 updates
2022-03-07 12:43:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:43:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 302 @ 29088 updates, score 13.112) (writing took 2.253687652759254 seconds)
2022-03-07 12:43:51 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 12:43:51 | INFO | train | epoch 302 | loss 2.188 | nll_loss 0.736 | ppl 1.67 | wps 22238.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29088 | lr 0.000185414 | gnorm 0.816 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 85943
2022-03-07 12:43:51 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 12:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:44:25 | INFO | train_inner | epoch 303:     12 / 97 loss=2.186, nll_loss=0.734, ppl=1.66, wps=22491.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29100, lr=0.000185376, gnorm=0.813, loss_scale=16, train_wall=261, gb_free=8.1, wall=85977
2022-03-07 12:45:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:48:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:31 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.108 | nll_loss 12.478 | ppl 5705.34 | wps 43203.2 | wpb 510.9 | bsz 1 | num_updates 29184 | best_loss 8.233
2022-03-07 12:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 29184 updates
2022-03-07 12:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 303 @ 29184 updates, score 13.108) (writing took 2.2554530408233404 seconds)
2022-03-07 12:48:33 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 12:48:33 | INFO | train | epoch 303 | loss 2.186 | nll_loss 0.734 | ppl 1.66 | wps 22236.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29184 | lr 0.000185109 | gnorm 0.807 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86225
2022-03-07 12:48:33 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 12:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:19 | INFO | train_inner | epoch 304:     16 / 97 loss=2.185, nll_loss=0.733, ppl=1.66, wps=22273.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29200, lr=0.000185058, gnorm=0.804, loss_scale=16, train_wall=264, gb_free=8.1, wall=86271
2022-03-07 12:51:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:53:14 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.15 | nll_loss 12.521 | ppl 5877.58 | wps 43402.1 | wpb 510.9 | bsz 1 | num_updates 29280 | best_loss 8.233
2022-03-07 12:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 29280 updates
2022-03-07 12:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 304 @ 29280 updates, score 13.15) (writing took 2.2349141780287027 seconds)
2022-03-07 12:53:16 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 12:53:16 | INFO | train | epoch 304 | loss 2.184 | nll_loss 0.732 | ppl 1.66 | wps 22262 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29280 | lr 0.000184805 | gnorm 0.809 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86508
2022-03-07 12:53:16 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 12:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:13 | INFO | train_inner | epoch 305:     20 / 97 loss=2.184, nll_loss=0.731, ppl=1.66, wps=22287, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29300, lr=0.000184742, gnorm=0.809, loss_scale=16, train_wall=264, gb_free=8.1, wall=86565
2022-03-07 12:57:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:56 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.146 | nll_loss 12.52 | ppl 5873.17 | wps 43716 | wpb 510.9 | bsz 1 | num_updates 29377 | best_loss 8.233
2022-03-07 12:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 29377 updates
2022-03-07 12:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:57:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 12:57:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 305 @ 29377 updates, score 13.146) (writing took 2.2704145247116685 seconds)
2022-03-07 12:57:58 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 12:57:58 | INFO | train | epoch 305 | loss 2.185 | nll_loss 0.733 | ppl 1.66 | wps 22479.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29377 | lr 0.0001845 | gnorm 0.81 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 86790
2022-03-07 12:57:59 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 12:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:58:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 12:59:07 | INFO | train_inner | epoch 306:     24 / 97 loss=2.184, nll_loss=0.732, ppl=1.66, wps=22288, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=29400, lr=0.000184428, gnorm=0.817, loss_scale=16, train_wall=264, gb_free=8.1, wall=86859
2022-03-07 13:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:02:39 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.119 | nll_loss 12.488 | ppl 5745.95 | wps 43554.7 | wpb 510.9 | bsz 1 | num_updates 29473 | best_loss 8.233
2022-03-07 13:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 29473 updates
2022-03-07 13:02:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:02:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:02:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 306 @ 29473 updates, score 13.119) (writing took 2.255513729993254 seconds)
2022-03-07 13:02:41 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 13:02:41 | INFO | train | epoch 306 | loss 2.182 | nll_loss 0.73 | ppl 1.66 | wps 22252.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29473 | lr 0.000184199 | gnorm 0.809 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87073
2022-03-07 13:02:41 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 13:02:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:03:58 | INFO | train_inner | epoch 307:     27 / 97 loss=2.181, nll_loss=0.729, ppl=1.66, wps=22496.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29500, lr=0.000184115, gnorm=0.797, loss_scale=16, train_wall=261, gb_free=8.1, wall=87150
2022-03-07 13:05:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:07:21 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.101 | nll_loss 12.472 | ppl 5679.63 | wps 43347.5 | wpb 510.9 | bsz 1 | num_updates 29569 | best_loss 8.233
2022-03-07 13:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 29569 updates
2022-03-07 13:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:07:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 307 @ 29569 updates, score 13.101) (writing took 2.2761281370185316 seconds)
2022-03-07 13:07:24 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 13:07:24 | INFO | train | epoch 307 | loss 2.18 | nll_loss 0.728 | ppl 1.66 | wps 22250.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29569 | lr 0.0001839 | gnorm 0.803 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87356
2022-03-07 13:07:24 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 13:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:52 | INFO | train_inner | epoch 308:     31 / 97 loss=2.179, nll_loss=0.727, ppl=1.66, wps=22289.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29600, lr=0.000183804, gnorm=0.812, loss_scale=16, train_wall=264, gb_free=8.1, wall=87444
2022-03-07 13:11:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:04 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.156 | nll_loss 12.527 | ppl 5900.65 | wps 43664.8 | wpb 510.9 | bsz 1 | num_updates 29666 | best_loss 8.233
2022-03-07 13:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 29666 updates
2022-03-07 13:12:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:12:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:12:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 308 @ 29666 updates, score 13.156) (writing took 2.24934012722224 seconds)
2022-03-07 13:12:06 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 13:12:06 | INFO | train | epoch 308 | loss 2.18 | nll_loss 0.728 | ppl 1.66 | wps 22495.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29666 | lr 0.000183599 | gnorm 0.814 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 87638
2022-03-07 13:12:06 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 13:12:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:13:46 | INFO | train_inner | epoch 309:     35 / 97 loss=2.179, nll_loss=0.727, ppl=1.66, wps=22282.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29700, lr=0.000183494, gnorm=0.809, loss_scale=16, train_wall=264, gb_free=8.1, wall=87737
2022-03-07 13:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:16:46 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.109 | nll_loss 12.479 | ppl 5707.72 | wps 43695.6 | wpb 510.9 | bsz 1 | num_updates 29762 | best_loss 8.233
2022-03-07 13:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 29762 updates
2022-03-07 13:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 309 @ 29762 updates, score 13.109) (writing took 2.3058811626397073 seconds)
2022-03-07 13:16:49 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 13:16:49 | INFO | train | epoch 309 | loss 2.177 | nll_loss 0.725 | ppl 1.65 | wps 22241 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29762 | lr 0.000183303 | gnorm 0.799 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 87921
2022-03-07 13:16:49 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 13:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:37 | INFO | train_inner | epoch 310:     38 / 97 loss=2.178, nll_loss=0.725, ppl=1.65, wps=22496.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=29800, lr=0.000183186, gnorm=0.801, loss_scale=16, train_wall=261, gb_free=8.1, wall=88029
2022-03-07 13:18:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:21:29 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.112 | nll_loss 12.487 | ppl 5739.38 | wps 43860.1 | wpb 510.9 | bsz 1 | num_updates 29858 | best_loss 8.233
2022-03-07 13:21:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 29858 updates
2022-03-07 13:21:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:21:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:21:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 310 @ 29858 updates, score 13.112) (writing took 2.2746057440526783 seconds)
2022-03-07 13:21:31 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 13:21:31 | INFO | train | epoch 310 | loss 2.177 | nll_loss 0.725 | ppl 1.65 | wps 22253.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 29858 | lr 0.000183008 | gnorm 0.808 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 88203
2022-03-07 13:21:31 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 13:21:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:23:31 | INFO | train_inner | epoch 311:     42 / 97 loss=2.176, nll_loss=0.724, ppl=1.65, wps=22281.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=29900, lr=0.000182879, gnorm=0.812, loss_scale=16, train_wall=264, gb_free=8.1, wall=88322
2022-03-07 13:26:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:12 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.067 | nll_loss 12.433 | ppl 5529.93 | wps 43717.1 | wpb 510.9 | bsz 1 | num_updates 29955 | best_loss 8.233
2022-03-07 13:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 29955 updates
2022-03-07 13:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:26:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:26:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 311 @ 29955 updates, score 13.067) (writing took 2.29231861513108 seconds)
2022-03-07 13:26:14 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 13:26:14 | INFO | train | epoch 311 | loss 2.176 | nll_loss 0.724 | ppl 1.65 | wps 22478.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 29955 | lr 0.000182711 | gnorm 0.814 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 88486
2022-03-07 13:26:14 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 13:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:28:24 | INFO | train_inner | epoch 312:     46 / 97 loss=2.174, nll_loss=0.722, ppl=1.65, wps=22289.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30000, lr=0.000182574, gnorm=0.805, loss_scale=16, train_wall=264, gb_free=8.1, wall=88616
2022-03-07 13:30:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:54 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.143 | nll_loss 12.519 | ppl 5870.33 | wps 43264.4 | wpb 510.9 | bsz 1 | num_updates 30051 | best_loss 8.233
2022-03-07 13:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 30051 updates
2022-03-07 13:30:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 312 @ 30051 updates, score 13.143) (writing took 2.2310950411483645 seconds)
2022-03-07 13:30:56 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 13:30:56 | INFO | train | epoch 312 | loss 2.173 | nll_loss 0.722 | ppl 1.65 | wps 22257.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30051 | lr 0.000182419 | gnorm 0.807 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 88768
2022-03-07 13:30:56 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 13:30:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:33:18 | INFO | train_inner | epoch 313:     50 / 97 loss=2.174, nll_loss=0.722, ppl=1.65, wps=22288, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30100, lr=0.000182271, gnorm=0.809, loss_scale=16, train_wall=264, gb_free=8.1, wall=88910
2022-03-07 13:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:36 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.051 | nll_loss 12.42 | ppl 5481.58 | wps 43356.6 | wpb 510.9 | bsz 1 | num_updates 30147 | best_loss 8.233
2022-03-07 13:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 30147 updates
2022-03-07 13:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:35:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:35:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 313 @ 30147 updates, score 13.051) (writing took 2.235867280047387 seconds)
2022-03-07 13:35:39 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 13:35:39 | INFO | train | epoch 313 | loss 2.173 | nll_loss 0.721 | ppl 1.65 | wps 22261.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30147 | lr 0.000182129 | gnorm 0.807 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89051
2022-03-07 13:35:39 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 13:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:38:09 | INFO | train_inner | epoch 314:     53 / 97 loss=2.172, nll_loss=0.72, ppl=1.65, wps=22509, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30200, lr=0.000181969, gnorm=0.807, loss_scale=16, train_wall=261, gb_free=8.1, wall=89201
2022-03-07 13:39:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:40:19 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.113 | nll_loss 12.486 | ppl 5737.65 | wps 43383 | wpb 510.9 | bsz 1 | num_updates 30243 | best_loss 8.233
2022-03-07 13:40:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 30243 updates
2022-03-07 13:40:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:40:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:40:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 314 @ 30243 updates, score 13.113) (writing took 2.1883556242100894 seconds)
2022-03-07 13:40:21 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 13:40:21 | INFO | train | epoch 314 | loss 2.172 | nll_loss 0.72 | ppl 1.65 | wps 22263.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30243 | lr 0.000181839 | gnorm 0.803 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89333
2022-03-07 13:40:21 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 13:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:43:03 | INFO | train_inner | epoch 315:     57 / 97 loss=2.171, nll_loss=0.719, ppl=1.65, wps=22296.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30300, lr=0.000181668, gnorm=0.802, loss_scale=16, train_wall=264, gb_free=8.1, wall=89495
2022-03-07 13:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:45:01 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.124 | nll_loss 12.501 | ppl 5797.59 | wps 43380.4 | wpb 510.9 | bsz 1 | num_updates 30340 | best_loss 8.233
2022-03-07 13:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 30340 updates
2022-03-07 13:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:45:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:45:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 315 @ 30340 updates, score 13.124) (writing took 2.2781209917739034 seconds)
2022-03-07 13:45:04 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 13:45:04 | INFO | train | epoch 315 | loss 2.17 | nll_loss 0.718 | ppl 1.65 | wps 22485 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30340 | lr 0.000181548 | gnorm 0.803 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89616
2022-03-07 13:45:04 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 13:45:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:45:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:47:57 | INFO | train_inner | epoch 316:     61 / 97 loss=2.17, nll_loss=0.718, ppl=1.65, wps=22279.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30400, lr=0.000181369, gnorm=0.802, loss_scale=16, train_wall=264, gb_free=8.1, wall=89789
2022-03-07 13:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:49:44 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.121 | nll_loss 12.497 | ppl 5779 | wps 43540.8 | wpb 510.9 | bsz 1 | num_updates 30436 | best_loss 8.233
2022-03-07 13:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 30436 updates
2022-03-07 13:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 316 @ 30436 updates, score 13.121) (writing took 2.228129592258483 seconds)
2022-03-07 13:49:46 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 13:49:46 | INFO | train | epoch 316 | loss 2.17 | nll_loss 0.718 | ppl 1.65 | wps 22255.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30436 | lr 0.000181262 | gnorm 0.806 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 89898
2022-03-07 13:49:46 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 13:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:52:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:52:51 | INFO | train_inner | epoch 317:     65 / 97 loss=2.168, nll_loss=0.716, ppl=1.64, wps=22284.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=30500, lr=0.000181071, gnorm=0.811, loss_scale=16, train_wall=264, gb_free=8.1, wall=90083
2022-03-07 13:54:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:54:27 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.09 | nll_loss 12.459 | ppl 5629 | wps 43349.8 | wpb 510.9 | bsz 1 | num_updates 30532 | best_loss 8.233
2022-03-07 13:54:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 30532 updates
2022-03-07 13:54:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:54:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 317 @ 30532 updates, score 13.09) (writing took 2.244880684185773 seconds)
2022-03-07 13:54:29 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 13:54:29 | INFO | train | epoch 317 | loss 2.168 | nll_loss 0.716 | ppl 1.64 | wps 22242.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30532 | lr 0.000180977 | gnorm 0.812 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 90181
2022-03-07 13:54:29 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 13:54:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:42 | INFO | train_inner | epoch 318:     68 / 97 loss=2.167, nll_loss=0.715, ppl=1.64, wps=22506.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=30600, lr=0.000180775, gnorm=0.803, loss_scale=16, train_wall=261, gb_free=8.1, wall=90374
2022-03-07 13:58:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 13:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:09 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.151 | nll_loss 12.526 | ppl 5896.93 | wps 43497.8 | wpb 510.9 | bsz 1 | num_updates 30628 | best_loss 8.233
2022-03-07 13:59:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 30628 updates
2022-03-07 13:59:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:59:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 13:59:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 318 @ 30628 updates, score 13.151) (writing took 2.2092137690633535 seconds)
2022-03-07 13:59:11 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 13:59:11 | INFO | train | epoch 318 | loss 2.166 | nll_loss 0.714 | ppl 1.64 | wps 22266.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30628 | lr 0.000180693 | gnorm 0.796 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 90463
2022-03-07 13:59:11 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 13:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:02:36 | INFO | train_inner | epoch 319:     72 / 97 loss=2.167, nll_loss=0.715, ppl=1.64, wps=22298, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30700, lr=0.000180481, gnorm=0.8, loss_scale=16, train_wall=264, gb_free=8.1, wall=90667
2022-03-07 14:03:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:03:51 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.187 | nll_loss 12.563 | ppl 6051.56 | wps 43356.7 | wpb 510.9 | bsz 1 | num_updates 30725 | best_loss 8.233
2022-03-07 14:03:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 30725 updates
2022-03-07 14:03:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:03:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 319 @ 30725 updates, score 13.187) (writing took 2.276780206244439 seconds)
2022-03-07 14:03:54 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 14:03:54 | INFO | train | epoch 319 | loss 2.166 | nll_loss 0.715 | ppl 1.64 | wps 22492.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 30725 | lr 0.000180407 | gnorm 0.806 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 90746
2022-03-07 14:03:54 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 14:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:05:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:07:29 | INFO | train_inner | epoch 320:     76 / 97 loss=2.167, nll_loss=0.715, ppl=1.64, wps=22289.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30800, lr=0.000180187, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=90961
2022-03-07 14:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:08:34 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.115 | nll_loss 12.487 | ppl 5741.49 | wps 43444.7 | wpb 510.9 | bsz 1 | num_updates 30821 | best_loss 8.233
2022-03-07 14:08:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 30821 updates
2022-03-07 14:08:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:08:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:08:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 320 @ 30821 updates, score 13.115) (writing took 2.250019676052034 seconds)
2022-03-07 14:08:36 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 14:08:36 | INFO | train | epoch 320 | loss 2.165 | nll_loss 0.713 | ppl 1.64 | wps 22255.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30821 | lr 0.000180126 | gnorm 0.798 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91028
2022-03-07 14:08:36 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 14:08:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:11:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:12:23 | INFO | train_inner | epoch 321:     80 / 97 loss=2.163, nll_loss=0.711, ppl=1.64, wps=22287.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=30900, lr=0.000179896, gnorm=0.792, loss_scale=16, train_wall=264, gb_free=8.1, wall=91255
2022-03-07 14:13:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:16 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.084 | nll_loss 12.456 | ppl 5619.32 | wps 42517.4 | wpb 510.9 | bsz 1 | num_updates 30917 | best_loss 8.233
2022-03-07 14:13:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 30917 updates
2022-03-07 14:13:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:13:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:13:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 321 @ 30917 updates, score 13.084) (writing took 2.2048797900788486 seconds)
2022-03-07 14:13:19 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 14:13:19 | INFO | train | epoch 321 | loss 2.163 | nll_loss 0.711 | ppl 1.64 | wps 22250.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 30917 | lr 0.000179846 | gnorm 0.791 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91311
2022-03-07 14:13:19 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 14:13:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:14 | INFO | train_inner | epoch 322:     83 / 97 loss=2.163, nll_loss=0.711, ppl=1.64, wps=22507.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31000, lr=0.000179605, gnorm=0.8, loss_scale=16, train_wall=261, gb_free=8.1, wall=91546
2022-03-07 14:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:59 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.125 | nll_loss 12.498 | ppl 5782.67 | wps 42234.3 | wpb 510.9 | bsz 1 | num_updates 31014 | best_loss 8.233
2022-03-07 14:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 31014 updates
2022-03-07 14:17:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 322 @ 31014 updates, score 13.125) (writing took 2.2838022522628307 seconds)
2022-03-07 14:18:01 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 14:18:01 | INFO | train | epoch 322 | loss 2.162 | nll_loss 0.71 | ppl 1.64 | wps 22484.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31014 | lr 0.000179565 | gnorm 0.799 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 91593
2022-03-07 14:18:01 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 14:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:22:08 | INFO | train_inner | epoch 323:     87 / 97 loss=2.161, nll_loss=0.71, ppl=1.64, wps=22280.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31100, lr=0.000179316, gnorm=0.799, loss_scale=16, train_wall=264, gb_free=8.1, wall=91840
2022-03-07 14:22:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:42 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.112 | nll_loss 12.486 | ppl 5737.76 | wps 42379.9 | wpb 510.9 | bsz 1 | num_updates 31110 | best_loss 8.233
2022-03-07 14:22:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 31110 updates
2022-03-07 14:22:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 323 @ 31110 updates, score 13.112) (writing took 2.1821258598938584 seconds)
2022-03-07 14:22:44 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 14:22:44 | INFO | train | epoch 323 | loss 2.16 | nll_loss 0.709 | ppl 1.63 | wps 22255.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31110 | lr 0.000179287 | gnorm 0.8 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 91876
2022-03-07 14:22:44 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 14:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:25:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:27:02 | INFO | train_inner | epoch 324:     91 / 97 loss=2.159, nll_loss=0.707, ppl=1.63, wps=22282, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31200, lr=0.000179029, gnorm=0.804, loss_scale=16, train_wall=264, gb_free=8.1, wall=92134
2022-03-07 14:27:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:27:24 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.083 | nll_loss 12.456 | ppl 5617.91 | wps 42311.2 | wpb 510.9 | bsz 1 | num_updates 31206 | best_loss 8.233
2022-03-07 14:27:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 31206 updates
2022-03-07 14:27:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:27:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 324 @ 31206 updates, score 13.083) (writing took 2.2384763062000275 seconds)
2022-03-07 14:27:26 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 14:27:26 | INFO | train | epoch 324 | loss 2.159 | nll_loss 0.707 | ppl 1.63 | wps 22243.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31206 | lr 0.000179012 | gnorm 0.803 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 92158
2022-03-07 14:27:26 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 14:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:31:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:31:56 | INFO | train_inner | epoch 325:     95 / 97 loss=2.16, nll_loss=0.709, ppl=1.63, wps=22276.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31300, lr=0.000178743, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=92428
2022-03-07 14:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:32:07 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.148 | nll_loss 12.524 | ppl 5891.64 | wps 42144.7 | wpb 510.9 | bsz 1 | num_updates 31302 | best_loss 8.233
2022-03-07 14:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 31302 updates
2022-03-07 14:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 325 @ 31302 updates, score 13.148) (writing took 2.2661726833321154 seconds)
2022-03-07 14:32:09 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 14:32:09 | INFO | train | epoch 325 | loss 2.158 | nll_loss 0.707 | ppl 1.63 | wps 22239.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31302 | lr 0.000178737 | gnorm 0.802 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 92441
2022-03-07 14:32:09 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 14:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:36:49 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.164 | nll_loss 12.541 | ppl 5959.51 | wps 42651.7 | wpb 510.9 | bsz 1 | num_updates 31399 | best_loss 8.233
2022-03-07 14:36:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 31399 updates
2022-03-07 14:36:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:36:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 326 @ 31399 updates, score 13.164) (writing took 2.2685430138371885 seconds)
2022-03-07 14:36:52 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 14:36:52 | INFO | train | epoch 326 | loss 2.157 | nll_loss 0.706 | ppl 1.63 | wps 22471.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31399 | lr 0.00017846 | gnorm 0.8 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 92724
2022-03-07 14:36:52 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 14:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:55 | INFO | train_inner | epoch 327:      1 / 97 loss=2.157, nll_loss=0.706, ppl=1.63, wps=21918.1, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=31400, lr=0.000178458, gnorm=0.8, loss_scale=16, train_wall=261, gb_free=8.1, wall=92727
2022-03-07 14:38:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:41:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:41:32 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.18 | nll_loss 12.557 | ppl 6027.52 | wps 42987.8 | wpb 510.9 | bsz 1 | num_updates 31495 | best_loss 8.233
2022-03-07 14:41:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 31495 updates
2022-03-07 14:41:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:41:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 327 @ 31495 updates, score 13.18) (writing took 2.286793453153223 seconds)
2022-03-07 14:41:34 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 14:41:34 | INFO | train | epoch 327 | loss 2.155 | nll_loss 0.704 | ppl 1.63 | wps 22240.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31495 | lr 0.000178188 | gnorm 0.796 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93006
2022-03-07 14:41:34 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 14:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:49 | INFO | train_inner | epoch 328:      5 / 97 loss=2.154, nll_loss=0.703, ppl=1.63, wps=22269.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31500, lr=0.000178174, gnorm=0.795, loss_scale=16, train_wall=264, gb_free=8.1, wall=93021
2022-03-07 14:45:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:15 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.085 | nll_loss 12.462 | ppl 5642.78 | wps 43460.1 | wpb 510.9 | bsz 1 | num_updates 31591 | best_loss 8.233
2022-03-07 14:46:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 31591 updates
2022-03-07 14:46:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:46:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:46:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 328 @ 31591 updates, score 13.085) (writing took 2.3334883712232113 seconds)
2022-03-07 14:46:17 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 14:46:17 | INFO | train | epoch 328 | loss 2.156 | nll_loss 0.704 | ppl 1.63 | wps 22250.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31591 | lr 0.000177917 | gnorm 0.804 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93289
2022-03-07 14:46:17 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 14:46:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:46:43 | INFO | train_inner | epoch 329:      9 / 97 loss=2.154, nll_loss=0.702, ppl=1.63, wps=22285.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31600, lr=0.000177892, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=93315
2022-03-07 14:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:50:57 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.114 | nll_loss 12.49 | ppl 5751.49 | wps 43293.4 | wpb 510.9 | bsz 1 | num_updates 31688 | best_loss 8.233
2022-03-07 14:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 31688 updates
2022-03-07 14:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 329 @ 31688 updates, score 13.114) (writing took 2.2675188980065286 seconds)
2022-03-07 14:51:00 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 14:51:00 | INFO | train | epoch 329 | loss 2.153 | nll_loss 0.702 | ppl 1.63 | wps 22467.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 31688 | lr 0.000177645 | gnorm 0.808 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93572
2022-03-07 14:51:00 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 14:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:51:34 | INFO | train_inner | epoch 330:     12 / 97 loss=2.153, nll_loss=0.702, ppl=1.63, wps=22484, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31700, lr=0.000177611, gnorm=0.806, loss_scale=32, train_wall=261, gb_free=8.1, wall=93606
2022-03-07 14:52:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 14:55:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:40 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.131 | nll_loss 12.511 | ppl 5837.4 | wps 43580.4 | wpb 510.9 | bsz 1 | num_updates 31784 | best_loss 8.233
2022-03-07 14:55:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 31784 updates
2022-03-07 14:55:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 14:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 330 @ 31784 updates, score 13.131) (writing took 2.2872235071845353 seconds)
2022-03-07 14:55:42 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 14:55:42 | INFO | train | epoch 330 | loss 2.151 | nll_loss 0.7 | ppl 1.62 | wps 22240.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31784 | lr 0.000177376 | gnorm 0.79 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 93854
2022-03-07 14:55:42 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 14:55:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:56:28 | INFO | train_inner | epoch 331:     16 / 97 loss=2.151, nll_loss=0.699, ppl=1.62, wps=22276.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31800, lr=0.000177332, gnorm=0.788, loss_scale=16, train_wall=264, gb_free=8.1, wall=93900
2022-03-07 14:58:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:00:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:23 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.179 | nll_loss 12.557 | ppl 6026.56 | wps 43317.7 | wpb 510.9 | bsz 1 | num_updates 31880 | best_loss 8.233
2022-03-07 15:00:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 31880 updates
2022-03-07 15:00:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:00:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 331 @ 31880 updates, score 13.179) (writing took 2.326574676204473 seconds)
2022-03-07 15:00:25 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 15:00:25 | INFO | train | epoch 331 | loss 2.15 | nll_loss 0.699 | ppl 1.62 | wps 22251.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31880 | lr 0.000177109 | gnorm 0.792 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94137
2022-03-07 15:00:25 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 15:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:22 | INFO | train_inner | epoch 332:     20 / 97 loss=2.149, nll_loss=0.697, ppl=1.62, wps=22282.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=31900, lr=0.000177054, gnorm=0.791, loss_scale=16, train_wall=264, gb_free=8.1, wall=94194
2022-03-07 15:04:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:05:05 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.135 | nll_loss 12.516 | ppl 5856.17 | wps 43355.4 | wpb 510.9 | bsz 1 | num_updates 31976 | best_loss 8.233
2022-03-07 15:05:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 31976 updates
2022-03-07 15:05:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:05:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 332 @ 31976 updates, score 13.135) (writing took 2.293314642738551 seconds)
2022-03-07 15:05:08 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 15:05:08 | INFO | train | epoch 332 | loss 2.15 | nll_loss 0.698 | ppl 1.62 | wps 22252.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 31976 | lr 0.000176843 | gnorm 0.801 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94419
2022-03-07 15:05:08 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 15:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:16 | INFO | train_inner | epoch 333:     24 / 97 loss=2.149, nll_loss=0.698, ppl=1.62, wps=22285.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32000, lr=0.000176777, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=94488
2022-03-07 15:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:48 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.09 | nll_loss 12.464 | ppl 5648.36 | wps 43386.9 | wpb 510.9 | bsz 1 | num_updates 32073 | best_loss 8.233
2022-03-07 15:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 32073 updates
2022-03-07 15:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 333 @ 32073 updates, score 13.09) (writing took 2.2822809941135347 seconds)
2022-03-07 15:09:50 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 15:09:50 | INFO | train | epoch 333 | loss 2.148 | nll_loss 0.697 | ppl 1.62 | wps 22474.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32073 | lr 0.000176575 | gnorm 0.791 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94702
2022-03-07 15:09:50 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 15:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:07 | INFO | train_inner | epoch 334:     27 / 97 loss=2.147, nll_loss=0.696, ppl=1.62, wps=22488.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32100, lr=0.000176501, gnorm=0.788, loss_scale=16, train_wall=261, gb_free=8.1, wall=94779
2022-03-07 15:11:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:14:31 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.082 | nll_loss 12.457 | ppl 5622.27 | wps 43437.6 | wpb 510.9 | bsz 1 | num_updates 32169 | best_loss 8.233
2022-03-07 15:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 32169 updates
2022-03-07 15:14:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 334 @ 32169 updates, score 13.082) (writing took 2.272709112148732 seconds)
2022-03-07 15:14:33 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 15:14:33 | INFO | train | epoch 334 | loss 2.148 | nll_loss 0.696 | ppl 1.62 | wps 22245.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32169 | lr 0.000176312 | gnorm 0.801 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 94985
2022-03-07 15:14:33 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 15:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:16:01 | INFO | train_inner | epoch 335:     31 / 97 loss=2.148, nll_loss=0.696, ppl=1.62, wps=22273.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32200, lr=0.000176227, gnorm=0.803, loss_scale=16, train_wall=264, gb_free=8.1, wall=95073
2022-03-07 15:17:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:19:13 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.152 | nll_loss 12.528 | ppl 5908.18 | wps 43468.3 | wpb 510.9 | bsz 1 | num_updates 32265 | best_loss 8.233
2022-03-07 15:19:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 32265 updates
2022-03-07 15:19:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:19:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 335 @ 32265 updates, score 13.152) (writing took 2.2419822541996837 seconds)
2022-03-07 15:19:15 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 15:19:15 | INFO | train | epoch 335 | loss 2.146 | nll_loss 0.695 | ppl 1.62 | wps 22239.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32265 | lr 0.000176049 | gnorm 0.793 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 95267
2022-03-07 15:19:16 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 15:19:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:55 | INFO | train_inner | epoch 336:     35 / 97 loss=2.145, nll_loss=0.694, ppl=1.62, wps=22282.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32300, lr=0.000175954, gnorm=0.79, loss_scale=16, train_wall=264, gb_free=8.1, wall=95367
2022-03-07 15:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:23:56 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.156 | nll_loss 12.536 | ppl 5939.62 | wps 43394.6 | wpb 510.9 | bsz 1 | num_updates 32362 | best_loss 8.233
2022-03-07 15:23:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 32362 updates
2022-03-07 15:23:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 336 @ 32362 updates, score 13.156) (writing took 2.255237635690719 seconds)
2022-03-07 15:23:58 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 15:23:58 | INFO | train | epoch 336 | loss 2.146 | nll_loss 0.694 | ppl 1.62 | wps 22486 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32362 | lr 0.000175785 | gnorm 0.794 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 95550
2022-03-07 15:23:58 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 15:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:24:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:25:49 | INFO | train_inner | epoch 337:     39 / 97 loss=2.145, nll_loss=0.693, ppl=1.62, wps=22282.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32400, lr=0.000175682, gnorm=0.795, loss_scale=16, train_wall=264, gb_free=8.1, wall=95661
2022-03-07 15:28:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:28:38 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.056 | nll_loss 12.427 | ppl 5508 | wps 43868.1 | wpb 510.9 | bsz 1 | num_updates 32458 | best_loss 8.233
2022-03-07 15:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 32458 updates
2022-03-07 15:28:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 337 @ 32458 updates, score 13.056) (writing took 2.254054549150169 seconds)
2022-03-07 15:28:40 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 15:28:40 | INFO | train | epoch 337 | loss 2.144 | nll_loss 0.693 | ppl 1.62 | wps 22258.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32458 | lr 0.000175525 | gnorm 0.793 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 95832
2022-03-07 15:28:40 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 15:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:30:40 | INFO | train_inner | epoch 338:     42 / 97 loss=2.144, nll_loss=0.693, ppl=1.62, wps=22504, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32500, lr=0.000175412, gnorm=0.802, loss_scale=16, train_wall=261, gb_free=8.1, wall=95952
2022-03-07 15:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:21 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.138 | nll_loss 12.518 | ppl 5864.96 | wps 42845.6 | wpb 510.9 | bsz 1 | num_updates 32554 | best_loss 8.233
2022-03-07 15:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 32554 updates
2022-03-07 15:33:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:33:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:33:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 338 @ 32554 updates, score 13.138) (writing took 2.2442522179335356 seconds)
2022-03-07 15:33:23 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 15:33:23 | INFO | train | epoch 338 | loss 2.143 | nll_loss 0.692 | ppl 1.62 | wps 22243.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32554 | lr 0.000175266 | gnorm 0.8 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96115
2022-03-07 15:33:23 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 15:33:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:35:34 | INFO | train_inner | epoch 339:     46 / 97 loss=2.143, nll_loss=0.692, ppl=1.62, wps=22281.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32600, lr=0.000175142, gnorm=0.787, loss_scale=16, train_wall=264, gb_free=8.1, wall=96246
2022-03-07 15:37:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:03 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.118 | nll_loss 12.495 | ppl 5773.89 | wps 43378.9 | wpb 510.9 | bsz 1 | num_updates 32650 | best_loss 8.233
2022-03-07 15:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 32650 updates
2022-03-07 15:38:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 339 @ 32650 updates, score 13.118) (writing took 2.2066825730726123 seconds)
2022-03-07 15:38:06 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 15:38:06 | INFO | train | epoch 339 | loss 2.142 | nll_loss 0.691 | ppl 1.61 | wps 22253.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32650 | lr 0.000175008 | gnorm 0.789 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96398
2022-03-07 15:38:06 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 15:38:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:28 | INFO | train_inner | epoch 340:     50 / 97 loss=2.141, nll_loss=0.69, ppl=1.61, wps=22284.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=32700, lr=0.000174874, gnorm=0.796, loss_scale=16, train_wall=264, gb_free=8.1, wall=96540
2022-03-07 15:42:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:46 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.093 | nll_loss 12.464 | ppl 5648.9 | wps 43086.5 | wpb 510.9 | bsz 1 | num_updates 32747 | best_loss 8.233
2022-03-07 15:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 32747 updates
2022-03-07 15:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:42:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:42:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 340 @ 32747 updates, score 13.093) (writing took 2.2733905389904976 seconds)
2022-03-07 15:42:48 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 15:42:48 | INFO | train | epoch 340 | loss 2.141 | nll_loss 0.69 | ppl 1.61 | wps 22487.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 32747 | lr 0.000174749 | gnorm 0.796 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96680
2022-03-07 15:42:48 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 15:42:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:45:21 | INFO | train_inner | epoch 341:     54 / 97 loss=2.141, nll_loss=0.69, ppl=1.61, wps=22291.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=32800, lr=0.000174608, gnorm=0.793, loss_scale=16, train_wall=264, gb_free=8.1, wall=96833
2022-03-07 15:47:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:28 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.123 | nll_loss 12.502 | ppl 5799.04 | wps 43485.3 | wpb 510.9 | bsz 1 | num_updates 32843 | best_loss 8.233
2022-03-07 15:47:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 32843 updates
2022-03-07 15:47:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 341 @ 32843 updates, score 13.123) (writing took 2.2554464670829475 seconds)
2022-03-07 15:47:31 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 15:47:31 | INFO | train | epoch 341 | loss 2.139 | nll_loss 0.688 | ppl 1.61 | wps 22253.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32843 | lr 0.000174493 | gnorm 0.792 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 96963
2022-03-07 15:47:31 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 15:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:13 | INFO | train_inner | epoch 342:     57 / 97 loss=2.137, nll_loss=0.686, ppl=1.61, wps=22490.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=32900, lr=0.000174342, gnorm=0.787, loss_scale=32, train_wall=261, gb_free=8.1, wall=97125
2022-03-07 15:50:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 15:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:52:11 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.175 | nll_loss 12.55 | ppl 5997.83 | wps 43521.1 | wpb 510.9 | bsz 1 | num_updates 32939 | best_loss 8.233
2022-03-07 15:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 32939 updates
2022-03-07 15:52:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 342 @ 32939 updates, score 13.175) (writing took 2.2474204702302814 seconds)
2022-03-07 15:52:13 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 15:52:13 | INFO | train | epoch 342 | loss 2.139 | nll_loss 0.689 | ppl 1.61 | wps 22238.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 32939 | lr 0.000174239 | gnorm 0.787 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 97245
2022-03-07 15:52:13 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 15:52:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:55:07 | INFO | train_inner | epoch 343:     61 / 97 loss=2.14, nll_loss=0.689, ppl=1.61, wps=22274.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33000, lr=0.000174078, gnorm=0.79, loss_scale=16, train_wall=264, gb_free=8.1, wall=97419
2022-03-07 15:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:56:54 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.09 | nll_loss 12.469 | ppl 5668.49 | wps 43351.1 | wpb 510.9 | bsz 1 | num_updates 33036 | best_loss 8.233
2022-03-07 15:56:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 33036 updates
2022-03-07 15:56:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:56:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 15:56:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 343 @ 33036 updates, score 13.09) (writing took 2.263561010826379 seconds)
2022-03-07 15:56:56 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 15:56:56 | INFO | train | epoch 343 | loss 2.138 | nll_loss 0.687 | ppl 1.61 | wps 22475.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33036 | lr 0.000173983 | gnorm 0.782 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 97528
2022-03-07 15:56:56 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 15:56:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:57:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:00:01 | INFO | train_inner | epoch 344:     65 / 97 loss=2.137, nll_loss=0.687, ppl=1.61, wps=22283.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33100, lr=0.000173814, gnorm=0.782, loss_scale=16, train_wall=264, gb_free=8.1, wall=97713
2022-03-07 16:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:01:36 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.148 | nll_loss 12.526 | ppl 5895.98 | wps 43345.9 | wpb 510.9 | bsz 1 | num_updates 33132 | best_loss 8.233
2022-03-07 16:01:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 33132 updates
2022-03-07 16:01:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:01:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 344 @ 33132 updates, score 13.148) (writing took 2.26403590105474 seconds)
2022-03-07 16:01:39 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 16:01:39 | INFO | train | epoch 344 | loss 2.137 | nll_loss 0.686 | ppl 1.61 | wps 22251.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33132 | lr 0.000173731 | gnorm 0.792 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 97810
2022-03-07 16:01:39 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 16:01:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:04:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:04:55 | INFO | train_inner | epoch 345:     69 / 97 loss=2.137, nll_loss=0.686, ppl=1.61, wps=22279.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33200, lr=0.000173553, gnorm=0.796, loss_scale=16, train_wall=264, gb_free=8.1, wall=98006
2022-03-07 16:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:06:19 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.157 | nll_loss 12.539 | ppl 5950.83 | wps 43474.5 | wpb 510.9 | bsz 1 | num_updates 33228 | best_loss 8.233
2022-03-07 16:06:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 33228 updates
2022-03-07 16:06:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:06:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 345 @ 33228 updates, score 13.157) (writing took 2.223400193732232 seconds)
2022-03-07 16:06:21 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 16:06:21 | INFO | train | epoch 345 | loss 2.136 | nll_loss 0.685 | ppl 1.61 | wps 22251.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33228 | lr 0.000173479 | gnorm 0.795 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 98093
2022-03-07 16:06:21 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 16:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:09:46 | INFO | train_inner | epoch 346:     72 / 97 loss=2.134, nll_loss=0.683, ppl=1.61, wps=22498.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=33300, lr=0.000173292, gnorm=0.793, loss_scale=16, train_wall=261, gb_free=8.1, wall=98298
2022-03-07 16:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:01 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.133 | nll_loss 12.511 | ppl 5836.01 | wps 43675.2 | wpb 510.9 | bsz 1 | num_updates 33325 | best_loss 8.233
2022-03-07 16:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 33325 updates
2022-03-07 16:11:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 346 @ 33325 updates, score 13.133) (writing took 2.216467081103474 seconds)
2022-03-07 16:11:04 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 16:11:04 | INFO | train | epoch 346 | loss 2.134 | nll_loss 0.683 | ppl 1.61 | wps 22481.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33325 | lr 0.000173227 | gnorm 0.791 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 98376
2022-03-07 16:11:04 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 16:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:11:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:14:40 | INFO | train_inner | epoch 347:     76 / 97 loss=2.133, nll_loss=0.683, ppl=1.6, wps=22289.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33400, lr=0.000173032, gnorm=0.792, loss_scale=16, train_wall=264, gb_free=8.1, wall=98591
2022-03-07 16:15:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:15:44 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.138 | nll_loss 12.514 | ppl 5847.64 | wps 43651.6 | wpb 510.9 | bsz 1 | num_updates 33421 | best_loss 8.233
2022-03-07 16:15:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 33421 updates
2022-03-07 16:15:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:15:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:15:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 347 @ 33421 updates, score 13.138) (writing took 2.237678537145257 seconds)
2022-03-07 16:15:46 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 16:15:46 | INFO | train | epoch 347 | loss 2.133 | nll_loss 0.682 | ppl 1.6 | wps 22261.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33421 | lr 0.000172978 | gnorm 0.795 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 98658
2022-03-07 16:15:46 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 16:15:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:18:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:19:33 | INFO | train_inner | epoch 348:     80 / 97 loss=2.134, nll_loss=0.683, ppl=1.61, wps=22295.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=33500, lr=0.000172774, gnorm=0.791, loss_scale=16, train_wall=264, gb_free=8.1, wall=98885
2022-03-07 16:20:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:26 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.126 | nll_loss 12.501 | ppl 5797.95 | wps 43442.5 | wpb 510.9 | bsz 1 | num_updates 33517 | best_loss 8.233
2022-03-07 16:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 33517 updates
2022-03-07 16:20:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:20:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:20:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 348 @ 33517 updates, score 13.126) (writing took 2.2898411629721522 seconds)
2022-03-07 16:20:29 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 16:20:29 | INFO | train | epoch 348 | loss 2.133 | nll_loss 0.682 | ppl 1.6 | wps 22254.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33517 | lr 0.00017273 | gnorm 0.784 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 98941
2022-03-07 16:20:29 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 16:20:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:24 | INFO | train_inner | epoch 349:     83 / 97 loss=2.132, nll_loss=0.681, ppl=1.6, wps=22499.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=33600, lr=0.000172516, gnorm=0.789, loss_scale=16, train_wall=261, gb_free=8.1, wall=99176
2022-03-07 16:24:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:25:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:25:09 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.129 | nll_loss 12.511 | ppl 5836.87 | wps 43282.2 | wpb 510.9 | bsz 1 | num_updates 33613 | best_loss 8.233
2022-03-07 16:25:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 33613 updates
2022-03-07 16:25:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:25:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 349 @ 33613 updates, score 13.129) (writing took 2.2264350540935993 seconds)
2022-03-07 16:25:11 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 16:25:11 | INFO | train | epoch 349 | loss 2.131 | nll_loss 0.681 | ppl 1.6 | wps 22256.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33613 | lr 0.000172483 | gnorm 0.795 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 99223
2022-03-07 16:25:11 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 16:25:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:29:18 | INFO | train_inner | epoch 350:     87 / 97 loss=2.131, nll_loss=0.681, ppl=1.6, wps=22284.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33700, lr=0.00017226, gnorm=0.801, loss_scale=16, train_wall=264, gb_free=8.1, wall=99470
2022-03-07 16:29:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:29:51 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.142 | nll_loss 12.523 | ppl 5887.48 | wps 43631 | wpb 510.9 | bsz 1 | num_updates 33710 | best_loss 8.233
2022-03-07 16:29:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 33710 updates
2022-03-07 16:29:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:29:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:29:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 350 @ 33710 updates, score 13.142) (writing took 2.2161957141943276 seconds)
2022-03-07 16:29:54 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 16:29:54 | INFO | train | epoch 350 | loss 2.13 | nll_loss 0.679 | ppl 1.6 | wps 22483.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33710 | lr 0.000172235 | gnorm 0.796 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 99506
2022-03-07 16:29:54 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 16:29:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:31:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:34:12 | INFO | train_inner | epoch 351:     91 / 97 loss=2.13, nll_loss=0.679, ppl=1.6, wps=22284, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33800, lr=0.000172005, gnorm=0.8, loss_scale=16, train_wall=264, gb_free=8.1, wall=99764
2022-03-07 16:34:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:34:34 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.164 | nll_loss 12.548 | ppl 5986.75 | wps 43548.7 | wpb 510.9 | bsz 1 | num_updates 33806 | best_loss 8.233
2022-03-07 16:34:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 33806 updates
2022-03-07 16:34:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:34:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 351 @ 33806 updates, score 13.164) (writing took 2.2642912128940225 seconds)
2022-03-07 16:34:36 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 16:34:36 | INFO | train | epoch 351 | loss 2.13 | nll_loss 0.679 | ppl 1.6 | wps 22247.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33806 | lr 0.00017199 | gnorm 0.802 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 99788
2022-03-07 16:34:36 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 16:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:39:06 | INFO | train_inner | epoch 352:     95 / 97 loss=2.129, nll_loss=0.678, ppl=1.6, wps=22283.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=33900, lr=0.000171751, gnorm=0.788, loss_scale=16, train_wall=264, gb_free=8.1, wall=100058
2022-03-07 16:39:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:17 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.151 | nll_loss 12.534 | ppl 5932.46 | wps 43710.4 | wpb 510.9 | bsz 1 | num_updates 33902 | best_loss 8.233
2022-03-07 16:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 33902 updates
2022-03-07 16:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:39:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:39:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 352 @ 33902 updates, score 13.151) (writing took 2.2202108004130423 seconds)
2022-03-07 16:39:19 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 16:39:19 | INFO | train | epoch 352 | loss 2.127 | nll_loss 0.677 | ppl 1.6 | wps 22255.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 33902 | lr 0.000171746 | gnorm 0.785 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100071
2022-03-07 16:39:19 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 16:39:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:59 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.155 | nll_loss 12.531 | ppl 5916.52 | wps 43482.9 | wpb 510.9 | bsz 1 | num_updates 33999 | best_loss 8.233
2022-03-07 16:43:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 33999 updates
2022-03-07 16:43:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 353 @ 33999 updates, score 13.155) (writing took 2.2727506747469306 seconds)
2022-03-07 16:44:01 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 16:44:01 | INFO | train | epoch 353 | loss 2.127 | nll_loss 0.676 | ppl 1.6 | wps 22481.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 33999 | lr 0.000171501 | gnorm 0.783 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 100353
2022-03-07 16:44:01 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 16:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:44:04 | INFO | train_inner | epoch 354:      1 / 97 loss=2.127, nll_loss=0.676, ppl=1.6, wps=21944, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=34000, lr=0.000171499, gnorm=0.783, loss_scale=32, train_wall=261, gb_free=8.1, wall=100356
2022-03-07 16:44:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:48:42 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.105 | nll_loss 12.48 | ppl 5714.35 | wps 43448.6 | wpb 510.9 | bsz 1 | num_updates 34095 | best_loss 8.233
2022-03-07 16:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 34095 updates
2022-03-07 16:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 354 @ 34095 updates, score 13.105) (writing took 2.2385291401296854 seconds)
2022-03-07 16:48:44 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 16:48:44 | INFO | train | epoch 354 | loss 2.127 | nll_loss 0.677 | ppl 1.6 | wps 22248.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34095 | lr 0.000171259 | gnorm 0.788 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100636
2022-03-07 16:48:44 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 16:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:48:58 | INFO | train_inner | epoch 355:      5 / 97 loss=2.125, nll_loss=0.675, ppl=1.6, wps=22281.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34100, lr=0.000171247, gnorm=0.787, loss_scale=16, train_wall=264, gb_free=8.1, wall=100650
2022-03-07 16:51:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:53:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:53:24 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.126 | nll_loss 12.503 | ppl 5806.16 | wps 43615.7 | wpb 510.9 | bsz 1 | num_updates 34191 | best_loss 8.233
2022-03-07 16:53:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 34191 updates
2022-03-07 16:53:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:53:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:53:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 355 @ 34191 updates, score 13.126) (writing took 2.218770002014935 seconds)
2022-03-07 16:53:27 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 16:53:27 | INFO | train | epoch 355 | loss 2.124 | nll_loss 0.673 | ppl 1.59 | wps 22245.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34191 | lr 0.000171019 | gnorm 0.78 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 100919
2022-03-07 16:53:27 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 16:53:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:53:52 | INFO | train_inner | epoch 356:      9 / 97 loss=2.123, nll_loss=0.673, ppl=1.59, wps=22274.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34200, lr=0.000170996, gnorm=0.779, loss_scale=16, train_wall=264, gb_free=8.1, wall=100944
2022-03-07 16:58:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:07 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.167 | nll_loss 12.552 | ppl 6004.54 | wps 43620.2 | wpb 510.9 | bsz 1 | num_updates 34288 | best_loss 8.233
2022-03-07 16:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 34288 updates
2022-03-07 16:58:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 16:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 356 @ 34288 updates, score 13.167) (writing took 2.1946349176578224 seconds)
2022-03-07 16:58:09 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 16:58:09 | INFO | train | epoch 356 | loss 2.124 | nll_loss 0.674 | ppl 1.6 | wps 22481.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34288 | lr 0.000170777 | gnorm 0.789 | loss_scale 32 | train_wall 253 | gb_free 8.1 | wall 101201
2022-03-07 16:58:09 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 16:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:58:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 16:58:46 | INFO | train_inner | epoch 357:     13 / 97 loss=2.124, nll_loss=0.673, ppl=1.59, wps=22282.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34300, lr=0.000170747, gnorm=0.79, loss_scale=16, train_wall=264, gb_free=8.1, wall=101238
2022-03-07 17:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:02:50 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.118 | nll_loss 12.501 | ppl 5796.29 | wps 43408.5 | wpb 510.9 | bsz 1 | num_updates 34384 | best_loss 8.233
2022-03-07 17:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 34384 updates
2022-03-07 17:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:02:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 357 @ 34384 updates, score 13.118) (writing took 2.1792801381088793 seconds)
2022-03-07 17:02:52 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 17:02:52 | INFO | train | epoch 357 | loss 2.123 | nll_loss 0.673 | ppl 1.59 | wps 22251.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34384 | lr 0.000170538 | gnorm 0.786 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 101484
2022-03-07 17:02:52 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 17:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:03:37 | INFO | train_inner | epoch 358:     16 / 97 loss=2.123, nll_loss=0.673, ppl=1.59, wps=22502.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=34400, lr=0.000170499, gnorm=0.787, loss_scale=16, train_wall=261, gb_free=8.1, wall=101529
2022-03-07 17:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:07:32 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.103 | nll_loss 12.48 | ppl 5713.22 | wps 43414 | wpb 510.9 | bsz 1 | num_updates 34480 | best_loss 8.233
2022-03-07 17:07:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 34480 updates
2022-03-07 17:07:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:07:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 358 @ 34480 updates, score 13.103) (writing took 2.2268742597661912 seconds)
2022-03-07 17:07:34 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 17:07:34 | INFO | train | epoch 358 | loss 2.122 | nll_loss 0.672 | ppl 1.59 | wps 22263 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34480 | lr 0.000170301 | gnorm 0.792 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 101766
2022-03-07 17:07:34 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 17:07:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:08:31 | INFO | train_inner | epoch 359:     20 / 97 loss=2.122, nll_loss=0.671, ppl=1.59, wps=22292.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34500, lr=0.000170251, gnorm=0.788, loss_scale=16, train_wall=264, gb_free=8.1, wall=101823
2022-03-07 17:10:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:12:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:14 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.173 | nll_loss 12.558 | ppl 6029.73 | wps 43415.5 | wpb 510.9 | bsz 1 | num_updates 34576 | best_loss 8.233
2022-03-07 17:12:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 34576 updates
2022-03-07 17:12:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 359 @ 34576 updates, score 13.173) (writing took 2.183805350214243 seconds)
2022-03-07 17:12:17 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 17:12:17 | INFO | train | epoch 359 | loss 2.121 | nll_loss 0.67 | ppl 1.59 | wps 22258.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34576 | lr 0.000170064 | gnorm 0.782 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102048
2022-03-07 17:12:17 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 17:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:25 | INFO | train_inner | epoch 360:     24 / 97 loss=2.119, nll_loss=0.668, ppl=1.59, wps=22293.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=34600, lr=0.000170005, gnorm=0.781, loss_scale=16, train_wall=264, gb_free=8.1, wall=102117
2022-03-07 17:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:57 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.179 | nll_loss 12.563 | ppl 6050.73 | wps 43125 | wpb 510.9 | bsz 1 | num_updates 34673 | best_loss 8.233
2022-03-07 17:16:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 34673 updates
2022-03-07 17:16:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:16:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 360 @ 34673 updates, score 13.179) (writing took 2.2095486209727824 seconds)
2022-03-07 17:16:59 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 17:16:59 | INFO | train | epoch 360 | loss 2.12 | nll_loss 0.67 | ppl 1.59 | wps 22482.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 34673 | lr 0.000169826 | gnorm 0.774 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102331
2022-03-07 17:16:59 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 17:16:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:18:19 | INFO | train_inner | epoch 361:     28 / 97 loss=2.12, nll_loss=0.67, ppl=1.59, wps=22285.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34700, lr=0.00016976, gnorm=0.778, loss_scale=16, train_wall=264, gb_free=8.1, wall=102411
2022-03-07 17:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:39 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.124 | nll_loss 12.509 | ppl 5827.9 | wps 43450.4 | wpb 510.9 | bsz 1 | num_updates 34769 | best_loss 8.233
2022-03-07 17:21:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 34769 updates
2022-03-07 17:21:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:21:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 361 @ 34769 updates, score 13.124) (writing took 2.1903928322717547 seconds)
2022-03-07 17:21:42 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 17:21:42 | INFO | train | epoch 361 | loss 2.119 | nll_loss 0.669 | ppl 1.59 | wps 22253.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34769 | lr 0.000169591 | gnorm 0.783 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102614
2022-03-07 17:21:42 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 17:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:23:10 | INFO | train_inner | epoch 362:     31 / 97 loss=2.118, nll_loss=0.668, ppl=1.59, wps=22499.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34800, lr=0.000169516, gnorm=0.779, loss_scale=16, train_wall=261, gb_free=8.1, wall=102702
2022-03-07 17:24:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:26:22 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.183 | nll_loss 12.569 | ppl 6077.72 | wps 43689.9 | wpb 510.9 | bsz 1 | num_updates 34865 | best_loss 8.233
2022-03-07 17:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 34865 updates
2022-03-07 17:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 362 @ 34865 updates, score 13.183) (writing took 2.2533845813013613 seconds)
2022-03-07 17:26:24 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 17:26:24 | INFO | train | epoch 362 | loss 2.118 | nll_loss 0.668 | ppl 1.59 | wps 22252.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34865 | lr 0.000169358 | gnorm 0.781 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 102896
2022-03-07 17:26:24 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 17:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:28:04 | INFO | train_inner | epoch 363:     35 / 97 loss=2.119, nll_loss=0.668, ppl=1.59, wps=22288.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=34900, lr=0.000169273, gnorm=0.783, loss_scale=16, train_wall=264, gb_free=8.1, wall=102996
2022-03-07 17:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:31:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:05 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.169 | nll_loss 12.553 | ppl 6008.37 | wps 43339.4 | wpb 510.9 | bsz 1 | num_updates 34961 | best_loss 8.233
2022-03-07 17:31:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 34961 updates
2022-03-07 17:31:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:31:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:31:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 363 @ 34961 updates, score 13.169) (writing took 2.192178150638938 seconds)
2022-03-07 17:31:07 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 17:31:07 | INFO | train | epoch 363 | loss 2.117 | nll_loss 0.667 | ppl 1.59 | wps 22244.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 34961 | lr 0.000169125 | gnorm 0.782 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103179
2022-03-07 17:31:07 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 17:31:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:32:58 | INFO | train_inner | epoch 364:     39 / 97 loss=2.116, nll_loss=0.666, ppl=1.59, wps=22274.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35000, lr=0.000169031, gnorm=0.775, loss_scale=16, train_wall=264, gb_free=8.1, wall=103290
2022-03-07 17:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:47 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.199 | nll_loss 12.583 | ppl 6134.74 | wps 43437.4 | wpb 510.9 | bsz 1 | num_updates 35058 | best_loss 8.233
2022-03-07 17:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 35058 updates
2022-03-07 17:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 364 @ 35058 updates, score 13.199) (writing took 2.1822151127271354 seconds)
2022-03-07 17:35:49 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 17:35:49 | INFO | train | epoch 364 | loss 2.116 | nll_loss 0.666 | ppl 1.59 | wps 22480.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35058 | lr 0.000168891 | gnorm 0.779 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103461
2022-03-07 17:35:49 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 17:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:37:52 | INFO | train_inner | epoch 365:     43 / 97 loss=2.116, nll_loss=0.666, ppl=1.59, wps=22279.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35100, lr=0.00016879, gnorm=0.784, loss_scale=16, train_wall=264, gb_free=8.1, wall=103584
2022-03-07 17:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:40:30 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.233 | nll_loss 12.624 | ppl 6312.1 | wps 43595.6 | wpb 510.9 | bsz 1 | num_updates 35154 | best_loss 8.233
2022-03-07 17:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 35154 updates
2022-03-07 17:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 365 @ 35154 updates, score 13.233) (writing took 2.1929884469136596 seconds)
2022-03-07 17:40:32 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 17:40:32 | INFO | train | epoch 365 | loss 2.116 | nll_loss 0.666 | ppl 1.59 | wps 22258.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35154 | lr 0.00016866 | gnorm 0.789 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 103744
2022-03-07 17:40:32 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 17:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:42:43 | INFO | train_inner | epoch 366:     46 / 97 loss=2.116, nll_loss=0.666, ppl=1.59, wps=22512.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35200, lr=0.00016855, gnorm=0.79, loss_scale=16, train_wall=261, gb_free=8.1, wall=103874
2022-03-07 17:44:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:45:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:45:12 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.187 | nll_loss 12.572 | ppl 6087.04 | wps 43648.6 | wpb 510.9 | bsz 1 | num_updates 35250 | best_loss 8.233
2022-03-07 17:45:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 35250 updates
2022-03-07 17:45:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:45:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 366 @ 35250 updates, score 13.187) (writing took 2.1920341406948864 seconds)
2022-03-07 17:45:14 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 17:45:14 | INFO | train | epoch 366 | loss 2.114 | nll_loss 0.664 | ppl 1.58 | wps 22263.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35250 | lr 0.00016843 | gnorm 0.783 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 104026
2022-03-07 17:45:14 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 17:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:36 | INFO | train_inner | epoch 367:     50 / 97 loss=2.113, nll_loss=0.663, ppl=1.58, wps=22300, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35300, lr=0.000168311, gnorm=0.774, loss_scale=16, train_wall=264, gb_free=8.1, wall=104168
2022-03-07 17:49:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:49:55 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.115 | nll_loss 12.498 | ppl 5786.32 | wps 43642.5 | wpb 510.9 | bsz 1 | num_updates 35347 | best_loss 8.233
2022-03-07 17:49:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 35347 updates
2022-03-07 17:49:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:49:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:49:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 367 @ 35347 updates, score 13.115) (writing took 2.2406689398922026 seconds)
2022-03-07 17:49:57 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 17:49:57 | INFO | train | epoch 367 | loss 2.113 | nll_loss 0.664 | ppl 1.58 | wps 22488.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35347 | lr 0.000168199 | gnorm 0.785 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 104309
2022-03-07 17:49:57 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 17:49:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:51:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:52:30 | INFO | train_inner | epoch 368:     54 / 97 loss=2.113, nll_loss=0.663, ppl=1.58, wps=22288.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35400, lr=0.000168073, gnorm=0.791, loss_scale=16, train_wall=264, gb_free=8.1, wall=104462
2022-03-07 17:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:37 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.177 | nll_loss 12.562 | ppl 6048.47 | wps 43446.1 | wpb 510.9 | bsz 1 | num_updates 35443 | best_loss 8.233
2022-03-07 17:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 35443 updates
2022-03-07 17:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 368 @ 35443 updates, score 13.177) (writing took 2.19251591200009 seconds)
2022-03-07 17:54:39 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 17:54:39 | INFO | train | epoch 368 | loss 2.111 | nll_loss 0.661 | ppl 1.58 | wps 22268.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35443 | lr 0.000167971 | gnorm 0.78 | loss_scale 16 | train_wall 253 | gb_free 8.1 | wall 104591
2022-03-07 17:54:39 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 17:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:57:21 | INFO | train_inner | epoch 369:     57 / 97 loss=2.112, nll_loss=0.662, ppl=1.58, wps=22507.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=35500, lr=0.000167836, gnorm=0.779, loss_scale=16, train_wall=261, gb_free=8.1, wall=104753
2022-03-07 17:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 17:59:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:59:20 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.128 | nll_loss 12.513 | ppl 5843.6 | wps 43249.3 | wpb 510.9 | bsz 1 | num_updates 35539 | best_loss 8.233
2022-03-07 17:59:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 35539 updates
2022-03-07 17:59:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 17:59:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 369 @ 35539 updates, score 13.128) (writing took 2.1948297168128192 seconds)
2022-03-07 17:59:22 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 17:59:22 | INFO | train | epoch 369 | loss 2.111 | nll_loss 0.661 | ppl 1.58 | wps 22189.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35539 | lr 0.000167744 | gnorm 0.778 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 104874
2022-03-07 17:59:22 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 17:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:16 | INFO | train_inner | epoch 370:     61 / 97 loss=2.11, nll_loss=0.661, ppl=1.58, wps=22188.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35600, lr=0.0001676, gnorm=0.78, loss_scale=16, train_wall=265, gb_free=8.1, wall=105048
2022-03-07 18:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:04:04 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.189 | nll_loss 12.578 | ppl 6114.97 | wps 43605.3 | wpb 510.9 | bsz 1 | num_updates 35636 | best_loss 8.233
2022-03-07 18:04:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 35636 updates
2022-03-07 18:04:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:04:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 370 @ 35636 updates, score 13.189) (writing took 2.203776966780424 seconds)
2022-03-07 18:04:06 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 18:04:06 | INFO | train | epoch 370 | loss 2.111 | nll_loss 0.661 | ppl 1.58 | wps 22416 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35636 | lr 0.000167516 | gnorm 0.777 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 105158
2022-03-07 18:04:06 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 18:04:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:06:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:07:11 | INFO | train_inner | epoch 371:     65 / 97 loss=2.11, nll_loss=0.661, ppl=1.58, wps=22215.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=35700, lr=0.000167365, gnorm=0.779, loss_scale=16, train_wall=265, gb_free=8.1, wall=105343
2022-03-07 18:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:08:47 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.171 | nll_loss 12.557 | ppl 6024.58 | wps 43653.2 | wpb 510.9 | bsz 1 | num_updates 35732 | best_loss 8.233
2022-03-07 18:08:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 35732 updates
2022-03-07 18:08:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:08:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:08:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 371 @ 35732 updates, score 13.171) (writing took 2.16652613831684 seconds)
2022-03-07 18:08:49 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 18:08:49 | INFO | train | epoch 371 | loss 2.11 | nll_loss 0.66 | ppl 1.58 | wps 22197.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35732 | lr 0.000167291 | gnorm 0.78 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 105441
2022-03-07 18:08:49 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 18:08:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:12:03 | INFO | train_inner | epoch 372:     68 / 97 loss=2.109, nll_loss=0.66, ppl=1.58, wps=22444, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35800, lr=0.000167132, gnorm=0.774, loss_scale=16, train_wall=262, gb_free=8.1, wall=105635
2022-03-07 18:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:30 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.157 | nll_loss 12.544 | ppl 5971.2 | wps 43138.1 | wpb 510.9 | bsz 1 | num_updates 35829 | best_loss 8.233
2022-03-07 18:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 35829 updates
2022-03-07 18:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 372 @ 35829 updates, score 13.157) (writing took 2.156327772885561 seconds)
2022-03-07 18:13:32 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 18:13:32 | INFO | train | epoch 372 | loss 2.109 | nll_loss 0.659 | ppl 1.58 | wps 22419.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 35829 | lr 0.000167064 | gnorm 0.775 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 105724
2022-03-07 18:13:32 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 18:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:16:57 | INFO | train_inner | epoch 373:     72 / 97 loss=2.108, nll_loss=0.659, ppl=1.58, wps=22227.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=35900, lr=0.000166899, gnorm=0.774, loss_scale=16, train_wall=264, gb_free=8.1, wall=105929
2022-03-07 18:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:18:13 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.188 | nll_loss 12.573 | ppl 6093.44 | wps 43461.8 | wpb 510.9 | bsz 1 | num_updates 35925 | best_loss 8.233
2022-03-07 18:18:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 35925 updates
2022-03-07 18:18:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:18:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:18:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 373 @ 35925 updates, score 13.188) (writing took 2.2203000872395933 seconds)
2022-03-07 18:18:16 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 18:18:16 | INFO | train | epoch 373 | loss 2.108 | nll_loss 0.658 | ppl 1.58 | wps 22197 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 35925 | lr 0.000166841 | gnorm 0.771 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106008
2022-03-07 18:18:16 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 18:18:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:20:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:21:53 | INFO | train_inner | epoch 374:     76 / 97 loss=2.107, nll_loss=0.658, ppl=1.58, wps=22187.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=36000, lr=0.000166667, gnorm=0.773, loss_scale=16, train_wall=265, gb_free=8.1, wall=106225
2022-03-07 18:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:22:57 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.219 | nll_loss 12.605 | ppl 6231.03 | wps 43477.7 | wpb 510.9 | bsz 1 | num_updates 36021 | best_loss 8.233
2022-03-07 18:22:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 36021 updates
2022-03-07 18:22:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:22:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:22:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 374 @ 36021 updates, score 13.219) (writing took 2.2304551689885557 seconds)
2022-03-07 18:22:59 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 18:22:59 | INFO | train | epoch 374 | loss 2.106 | nll_loss 0.657 | ppl 1.58 | wps 22152.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36021 | lr 0.000166618 | gnorm 0.774 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106291
2022-03-07 18:22:59 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 18:22:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:26:45 | INFO | train_inner | epoch 375:     79 / 97 loss=2.106, nll_loss=0.657, ppl=1.58, wps=22441, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36100, lr=0.000166436, gnorm=0.782, loss_scale=16, train_wall=262, gb_free=8.1, wall=106516
2022-03-07 18:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:27:41 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.094 | nll_loss 12.478 | ppl 5706.87 | wps 43326.3 | wpb 510.9 | bsz 1 | num_updates 36118 | best_loss 8.233
2022-03-07 18:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 36118 updates
2022-03-07 18:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:27:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 375 @ 36118 updates, score 13.094) (writing took 2.202110690996051 seconds)
2022-03-07 18:27:43 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 18:27:43 | INFO | train | epoch 375 | loss 2.106 | nll_loss 0.656 | ppl 1.58 | wps 22422.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36118 | lr 0.000166394 | gnorm 0.782 | loss_scale 32 | train_wall 254 | gb_free 8.1 | wall 106575
2022-03-07 18:27:43 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 18:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:29:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:31:39 | INFO | train_inner | epoch 376:     83 / 97 loss=2.106, nll_loss=0.656, ppl=1.58, wps=22233.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36200, lr=0.000166206, gnorm=0.769, loss_scale=16, train_wall=264, gb_free=8.1, wall=106811
2022-03-07 18:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:32:24 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.201 | nll_loss 12.593 | ppl 6177.97 | wps 43279.5 | wpb 510.9 | bsz 1 | num_updates 36214 | best_loss 8.233
2022-03-07 18:32:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 36214 updates
2022-03-07 18:32:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:32:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:32:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 376 @ 36214 updates, score 13.201) (writing took 2.241411021910608 seconds)
2022-03-07 18:32:26 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 18:32:26 | INFO | train | epoch 376 | loss 2.104 | nll_loss 0.655 | ppl 1.57 | wps 22194.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36214 | lr 0.000166173 | gnorm 0.768 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 106858
2022-03-07 18:32:26 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 18:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:36:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:36:34 | INFO | train_inner | epoch 377:     87 / 97 loss=2.105, nll_loss=0.655, ppl=1.58, wps=22218.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=36300, lr=0.000165977, gnorm=0.769, loss_scale=16, train_wall=265, gb_free=8.1, wall=107106
2022-03-07 18:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:37:07 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.095 | nll_loss 12.476 | ppl 5697.95 | wps 43040.2 | wpb 510.9 | bsz 1 | num_updates 36310 | best_loss 8.233
2022-03-07 18:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 36310 updates
2022-03-07 18:37:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:37:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 377 @ 36310 updates, score 13.095) (writing took 2.2595590511336923 seconds)
2022-03-07 18:37:10 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 18:37:10 | INFO | train | epoch 377 | loss 2.104 | nll_loss 0.655 | ppl 1.57 | wps 22181.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36310 | lr 0.000165954 | gnorm 0.77 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107141
2022-03-07 18:37:10 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 18:37:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:41:26 | INFO | train_inner | epoch 378:     90 / 97 loss=2.104, nll_loss=0.655, ppl=1.57, wps=22391.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36400, lr=0.000165748, gnorm=0.781, loss_scale=16, train_wall=262, gb_free=8.1, wall=107398
2022-03-07 18:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:41:51 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.122 | nll_loss 12.505 | ppl 5813.49 | wps 43621 | wpb 510.9 | bsz 1 | num_updates 36407 | best_loss 8.233
2022-03-07 18:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 36407 updates
2022-03-07 18:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:41:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 378 @ 36407 updates, score 13.122) (writing took 2.3105995738878846 seconds)
2022-03-07 18:41:53 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 18:41:53 | INFO | train | epoch 378 | loss 2.104 | nll_loss 0.655 | ppl 1.57 | wps 22374.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36407 | lr 0.000165732 | gnorm 0.781 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107425
2022-03-07 18:41:53 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 18:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:46:21 | INFO | train_inner | epoch 379:     94 / 97 loss=2.103, nll_loss=0.654, ppl=1.57, wps=22218.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36500, lr=0.000165521, gnorm=0.776, loss_scale=16, train_wall=264, gb_free=8.1, wall=107693
2022-03-07 18:46:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:34 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.14 | nll_loss 12.526 | ppl 5899.83 | wps 43589.4 | wpb 510.9 | bsz 1 | num_updates 36503 | best_loss 8.233
2022-03-07 18:46:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 36503 updates
2022-03-07 18:46:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:46:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 379 @ 36503 updates, score 13.14) (writing took 2.223730233963579 seconds)
2022-03-07 18:46:37 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 18:46:37 | INFO | train | epoch 379 | loss 2.102 | nll_loss 0.653 | ppl 1.57 | wps 22193 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36503 | lr 0.000165514 | gnorm 0.774 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107709
2022-03-07 18:46:37 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 18:46:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:50:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 18:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:18 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.189 | nll_loss 12.575 | ppl 6103.68 | wps 43378 | wpb 510.9 | bsz 1 | num_updates 36599 | best_loss 8.233
2022-03-07 18:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 36599 updates
2022-03-07 18:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 380 @ 36599 updates, score 13.189) (writing took 2.2675486621446908 seconds)
2022-03-07 18:51:20 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 18:51:20 | INFO | train | epoch 380 | loss 2.101 | nll_loss 0.652 | ppl 1.57 | wps 22191.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36599 | lr 0.000165297 | gnorm 0.771 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 107992
2022-03-07 18:51:20 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 18:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:51:23 | INFO | train_inner | epoch 381:      1 / 97 loss=2.101, nll_loss=0.652, ppl=1.57, wps=21682.3, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=36600, lr=0.000165295, gnorm=0.771, loss_scale=16, train_wall=264, gb_free=8.1, wall=107995
2022-03-07 18:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:56:01 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.197 | nll_loss 12.586 | ppl 6147.64 | wps 42796.2 | wpb 510.9 | bsz 1 | num_updates 36696 | best_loss 8.233
2022-03-07 18:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 36696 updates
2022-03-07 18:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 18:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 381 @ 36696 updates, score 13.197) (writing took 2.2677938900887966 seconds)
2022-03-07 18:56:03 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 18:56:03 | INFO | train | epoch 381 | loss 2.1 | nll_loss 0.651 | ppl 1.57 | wps 22421.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 36696 | lr 0.000165079 | gnorm 0.774 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 108275
2022-03-07 18:56:03 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 18:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:56:15 | INFO | train_inner | epoch 382:      4 / 97 loss=2.1, nll_loss=0.65, ppl=1.57, wps=22437.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36700, lr=0.00016507, gnorm=0.774, loss_scale=16, train_wall=262, gb_free=8.1, wall=108287
2022-03-07 18:57:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:00:45 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.109 | nll_loss 12.494 | ppl 5770 | wps 42349.2 | wpb 510.9 | bsz 1 | num_updates 36792 | best_loss 8.233
2022-03-07 19:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 36792 updates
2022-03-07 19:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 382 @ 36792 updates, score 13.109) (writing took 2.1956026991829276 seconds)
2022-03-07 19:00:47 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 19:00:47 | INFO | train | epoch 382 | loss 2.099 | nll_loss 0.65 | ppl 1.57 | wps 22162.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36792 | lr 0.000164863 | gnorm 0.78 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 108559
2022-03-07 19:00:47 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 19:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:01:10 | INFO | train_inner | epoch 383:      8 / 97 loss=2.099, nll_loss=0.649, ppl=1.57, wps=22189.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36800, lr=0.000164845, gnorm=0.781, loss_scale=16, train_wall=265, gb_free=8.1, wall=108582
2022-03-07 19:03:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:05:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:29 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.123 | nll_loss 12.51 | ppl 5834.51 | wps 42922.6 | wpb 510.9 | bsz 1 | num_updates 36888 | best_loss 8.233
2022-03-07 19:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 36888 updates
2022-03-07 19:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:05:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 383 @ 36888 updates, score 13.123) (writing took 2.2421317263506353 seconds)
2022-03-07 19:05:31 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 19:05:31 | INFO | train | epoch 383 | loss 2.098 | nll_loss 0.649 | ppl 1.57 | wps 22107.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36888 | lr 0.000164648 | gnorm 0.789 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 108843
2022-03-07 19:05:31 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 19:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:06:06 | INFO | train_inner | epoch 384:     12 / 97 loss=2.098, nll_loss=0.649, ppl=1.57, wps=22145.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=36900, lr=0.000164622, gnorm=0.786, loss_scale=16, train_wall=265, gb_free=8.1, wall=108878
2022-03-07 19:09:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:10:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:10:14 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.133 | nll_loss 12.519 | ppl 5868.83 | wps 42648.5 | wpb 510.9 | bsz 1 | num_updates 36984 | best_loss 8.233
2022-03-07 19:10:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 36984 updates
2022-03-07 19:10:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 384 @ 36984 updates, score 13.133) (writing took 2.2051167637109756 seconds)
2022-03-07 19:10:16 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 19:10:16 | INFO | train | epoch 384 | loss 2.097 | nll_loss 0.648 | ppl 1.57 | wps 22103.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 36984 | lr 0.000164435 | gnorm 0.77 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109128
2022-03-07 19:10:16 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 19:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:11:02 | INFO | train_inner | epoch 385:     16 / 97 loss=2.096, nll_loss=0.647, ppl=1.57, wps=22123.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37000, lr=0.000164399, gnorm=0.768, loss_scale=16, train_wall=265, gb_free=8.1, wall=109174
2022-03-07 19:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:58 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.173 | nll_loss 12.562 | ppl 6047.05 | wps 42507.3 | wpb 510.9 | bsz 1 | num_updates 37081 | best_loss 8.233
2022-03-07 19:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 37081 updates
2022-03-07 19:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:15:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 385 @ 37081 updates, score 13.173) (writing took 2.2775841341353953 seconds)
2022-03-07 19:15:00 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 19:15:00 | INFO | train | epoch 385 | loss 2.097 | nll_loss 0.648 | ppl 1.57 | wps 22322.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37081 | lr 0.000164219 | gnorm 0.781 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109412
2022-03-07 19:15:00 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 19:15:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:15:55 | INFO | train_inner | epoch 386:     19 / 97 loss=2.097, nll_loss=0.648, ppl=1.57, wps=22342.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37100, lr=0.000164177, gnorm=0.781, loss_scale=16, train_wall=263, gb_free=8.1, wall=109467
2022-03-07 19:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:19:43 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.164 | nll_loss 12.551 | ppl 6000.17 | wps 42783.8 | wpb 510.9 | bsz 1 | num_updates 37177 | best_loss 8.233
2022-03-07 19:19:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 37177 updates
2022-03-07 19:19:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 386 @ 37177 updates, score 13.164) (writing took 2.2105094911530614 seconds)
2022-03-07 19:19:45 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 19:19:45 | INFO | train | epoch 386 | loss 2.096 | nll_loss 0.647 | ppl 1.57 | wps 22095.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37177 | lr 0.000164007 | gnorm 0.771 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109697
2022-03-07 19:19:45 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 19:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:20:51 | INFO | train_inner | epoch 387:     23 / 97 loss=2.095, nll_loss=0.646, ppl=1.56, wps=22124.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37200, lr=0.000163956, gnorm=0.77, loss_scale=16, train_wall=265, gb_free=8.1, wall=109763
2022-03-07 19:23:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:27 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.2 | nll_loss 12.592 | ppl 6175.4 | wps 42752.3 | wpb 510.9 | bsz 1 | num_updates 37273 | best_loss 8.233
2022-03-07 19:24:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 37273 updates
2022-03-07 19:24:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:24:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 387 @ 37273 updates, score 13.2) (writing took 2.2696778420358896 seconds)
2022-03-07 19:24:30 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 19:24:30 | INFO | train | epoch 387 | loss 2.095 | nll_loss 0.646 | ppl 1.56 | wps 22090.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37273 | lr 0.000163796 | gnorm 0.771 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 109982
2022-03-07 19:24:30 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 19:24:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:25:47 | INFO | train_inner | epoch 388:     27 / 97 loss=2.094, nll_loss=0.644, ppl=1.56, wps=22133.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=37300, lr=0.000163737, gnorm=0.767, loss_scale=16, train_wall=265, gb_free=8.1, wall=110059
2022-03-07 19:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:12 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.136 | nll_loss 12.525 | ppl 5892.97 | wps 42660.5 | wpb 510.9 | bsz 1 | num_updates 37370 | best_loss 8.233
2022-03-07 19:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 37370 updates
2022-03-07 19:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 388 @ 37370 updates, score 13.136) (writing took 2.197234578896314 seconds)
2022-03-07 19:29:14 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 19:29:14 | INFO | train | epoch 388 | loss 2.095 | nll_loss 0.646 | ppl 1.56 | wps 22335.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37370 | lr 0.000163583 | gnorm 0.764 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110266
2022-03-07 19:29:14 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 19:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:30:40 | INFO | train_inner | epoch 389:     30 / 97 loss=2.095, nll_loss=0.646, ppl=1.57, wps=22356.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37400, lr=0.000163517, gnorm=0.77, loss_scale=32, train_wall=263, gb_free=8.1, wall=110352
2022-03-07 19:31:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:56 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.135 | nll_loss 12.524 | ppl 5888.39 | wps 42448 | wpb 510.9 | bsz 1 | num_updates 37466 | best_loss 8.233
2022-03-07 19:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 37466 updates
2022-03-07 19:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 389 @ 37466 updates, score 13.135) (writing took 2.2743713641539216 seconds)
2022-03-07 19:33:58 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 19:33:58 | INFO | train | epoch 389 | loss 2.094 | nll_loss 0.646 | ppl 1.56 | wps 22106.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37466 | lr 0.000163373 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110550
2022-03-07 19:33:58 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 19:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:36 | INFO | train_inner | epoch 390:     34 / 97 loss=2.094, nll_loss=0.645, ppl=1.56, wps=22135.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37500, lr=0.000163299, gnorm=0.761, loss_scale=16, train_wall=265, gb_free=8.1, wall=110648
2022-03-07 19:37:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:38:40 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.157 | nll_loss 12.545 | ppl 5975.3 | wps 43199.1 | wpb 510.9 | bsz 1 | num_updates 37562 | best_loss 8.233
2022-03-07 19:38:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 37562 updates
2022-03-07 19:38:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 390 @ 37562 updates, score 13.157) (writing took 2.235037002246827 seconds)
2022-03-07 19:38:43 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 19:38:43 | INFO | train | epoch 390 | loss 2.092 | nll_loss 0.643 | ppl 1.56 | wps 22120.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37562 | lr 0.000163164 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 110835
2022-03-07 19:38:43 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 19:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:31 | INFO | train_inner | epoch 391:     38 / 97 loss=2.092, nll_loss=0.643, ppl=1.56, wps=22156.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37600, lr=0.000163082, gnorm=0.771, loss_scale=16, train_wall=265, gb_free=8.1, wall=110943
2022-03-07 19:43:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:24 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.126 | nll_loss 12.51 | ppl 5833.13 | wps 43491.6 | wpb 510.9 | bsz 1 | num_updates 37659 | best_loss 8.233
2022-03-07 19:43:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 37659 updates
2022-03-07 19:43:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:43:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 391 @ 37659 updates, score 13.126) (writing took 2.271515193860978 seconds)
2022-03-07 19:43:27 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 19:43:27 | INFO | train | epoch 391 | loss 2.092 | nll_loss 0.643 | ppl 1.56 | wps 22378 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37659 | lr 0.000162954 | gnorm 0.771 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111118
2022-03-07 19:43:27 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 19:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:45:26 | INFO | train_inner | epoch 392:     42 / 97 loss=2.091, nll_loss=0.642, ppl=1.56, wps=22206, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=37700, lr=0.000162866, gnorm=0.772, loss_scale=16, train_wall=265, gb_free=8.1, wall=111238
2022-03-07 19:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:08 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.179 | nll_loss 12.569 | ppl 6077.69 | wps 43337.2 | wpb 510.9 | bsz 1 | num_updates 37755 | best_loss 8.233
2022-03-07 19:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 37755 updates
2022-03-07 19:48:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 392 @ 37755 updates, score 13.179) (writing took 2.2756405198015273 seconds)
2022-03-07 19:48:10 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 19:48:10 | INFO | train | epoch 392 | loss 2.091 | nll_loss 0.643 | ppl 1.56 | wps 22184.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37755 | lr 0.000162747 | gnorm 0.771 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111402
2022-03-07 19:48:10 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 19:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:50:18 | INFO | train_inner | epoch 393:     45 / 97 loss=2.09, nll_loss=0.642, ppl=1.56, wps=22429.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=37800, lr=0.00016265, gnorm=0.766, loss_scale=16, train_wall=262, gb_free=8.1, wall=111530
2022-03-07 19:51:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 19:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:52:51 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.188 | nll_loss 12.581 | ppl 6127.61 | wps 43379.5 | wpb 510.9 | bsz 1 | num_updates 37851 | best_loss 8.233
2022-03-07 19:52:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 37851 updates
2022-03-07 19:52:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:52:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:52:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 393 @ 37851 updates, score 13.188) (writing took 2.2954374901019037 seconds)
2022-03-07 19:52:53 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 19:52:53 | INFO | train | epoch 393 | loss 2.089 | nll_loss 0.64 | ppl 1.56 | wps 22180.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 37851 | lr 0.00016254 | gnorm 0.765 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111685
2022-03-07 19:52:53 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 19:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:13 | INFO | train_inner | epoch 394:     49 / 97 loss=2.089, nll_loss=0.641, ppl=1.56, wps=22214.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=37900, lr=0.000162435, gnorm=0.772, loss_scale=16, train_wall=264, gb_free=8.1, wall=111825
2022-03-07 19:57:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:57:34 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.148 | nll_loss 12.536 | ppl 5939.98 | wps 43523.6 | wpb 510.9 | bsz 1 | num_updates 37948 | best_loss 8.233
2022-03-07 19:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 37948 updates
2022-03-07 19:57:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 19:57:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 394 @ 37948 updates, score 13.148) (writing took 2.2529740845784545 seconds)
2022-03-07 19:57:37 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 19:57:37 | INFO | train | epoch 394 | loss 2.09 | nll_loss 0.642 | ppl 1.56 | wps 22423.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 37948 | lr 0.000162333 | gnorm 0.77 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 111969
2022-03-07 19:57:37 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 19:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:58:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:00:08 | INFO | train_inner | epoch 395:     53 / 97 loss=2.089, nll_loss=0.641, ppl=1.56, wps=22232.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38000, lr=0.000162221, gnorm=0.765, loss_scale=16, train_wall=264, gb_free=8.1, wall=112119
2022-03-07 20:02:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:18 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.143 | nll_loss 12.536 | ppl 5940.79 | wps 43398.7 | wpb 510.9 | bsz 1 | num_updates 38044 | best_loss 8.233
2022-03-07 20:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 38044 updates
2022-03-07 20:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:02:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 395 @ 38044 updates, score 13.143) (writing took 2.2529991939663887 seconds)
2022-03-07 20:02:20 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 20:02:20 | INFO | train | epoch 395 | loss 2.088 | nll_loss 0.639 | ppl 1.56 | wps 22197.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38044 | lr 0.000162128 | gnorm 0.767 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112252
2022-03-07 20:02:20 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 20:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:05:02 | INFO | train_inner | epoch 396:     57 / 97 loss=2.088, nll_loss=0.639, ppl=1.56, wps=22207.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38100, lr=0.000162008, gnorm=0.775, loss_scale=16, train_wall=265, gb_free=8.1, wall=112414
2022-03-07 20:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:01 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.117 | nll_loss 12.502 | ppl 5800.76 | wps 43473.2 | wpb 510.9 | bsz 1 | num_updates 38140 | best_loss 8.233
2022-03-07 20:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 38140 updates
2022-03-07 20:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:07:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 396 @ 38140 updates, score 13.117) (writing took 2.108738081995398 seconds)
2022-03-07 20:07:04 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 20:07:04 | INFO | train | epoch 396 | loss 2.088 | nll_loss 0.64 | ppl 1.56 | wps 22167.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38140 | lr 0.000161923 | gnorm 0.781 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112535
2022-03-07 20:07:04 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 20:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:55 | INFO | train_inner | epoch 397:     60 / 97 loss=2.088, nll_loss=0.64, ppl=1.56, wps=22414.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=38200, lr=0.000161796, gnorm=0.777, loss_scale=16, train_wall=262, gb_free=8.1, wall=112707
2022-03-07 20:11:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:11:45 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.188 | nll_loss 12.579 | ppl 6119.54 | wps 43003.9 | wpb 510.9 | bsz 1 | num_updates 38236 | best_loss 8.233
2022-03-07 20:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 38236 updates
2022-03-07 20:11:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:11:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:11:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 397 @ 38236 updates, score 13.188) (writing took 2.2688798056915402 seconds)
2022-03-07 20:11:47 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 20:11:47 | INFO | train | epoch 397 | loss 2.086 | nll_loss 0.637 | ppl 1.56 | wps 22153.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38236 | lr 0.00016172 | gnorm 0.767 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 112819
2022-03-07 20:11:47 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 20:11:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:14:50 | INFO | train_inner | epoch 398:     64 / 97 loss=2.084, nll_loss=0.636, ppl=1.55, wps=22175.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38300, lr=0.000161585, gnorm=0.77, loss_scale=16, train_wall=265, gb_free=8.1, wall=113002
2022-03-07 20:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:16:29 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.142 | nll_loss 12.53 | ppl 5913.01 | wps 42933.6 | wpb 510.9 | bsz 1 | num_updates 38333 | best_loss 8.233
2022-03-07 20:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 38333 updates
2022-03-07 20:16:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:16:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:16:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 398 @ 38333 updates, score 13.142) (writing took 2.3307395838201046 seconds)
2022-03-07 20:16:31 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 20:16:31 | INFO | train | epoch 398 | loss 2.086 | nll_loss 0.637 | ppl 1.56 | wps 22358.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38333 | lr 0.000161515 | gnorm 0.775 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113103
2022-03-07 20:16:32 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 20:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:19:46 | INFO | train_inner | epoch 399:     68 / 97 loss=2.086, nll_loss=0.638, ppl=1.56, wps=22152.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=38400, lr=0.000161374, gnorm=0.771, loss_scale=16, train_wall=265, gb_free=8.1, wall=113298
2022-03-07 20:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:13 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.173 | nll_loss 12.566 | ppl 6063.85 | wps 43014.2 | wpb 510.9 | bsz 1 | num_updates 38429 | best_loss 8.233
2022-03-07 20:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 38429 updates
2022-03-07 20:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 399 @ 38429 updates, score 13.173) (writing took 2.3023081040009856 seconds)
2022-03-07 20:21:16 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 20:21:16 | INFO | train | epoch 399 | loss 2.085 | nll_loss 0.637 | ppl 1.55 | wps 22117 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38429 | lr 0.000161313 | gnorm 0.775 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113388
2022-03-07 20:21:16 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 20:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:24:42 | INFO | train_inner | epoch 400:     72 / 97 loss=2.086, nll_loss=0.638, ppl=1.56, wps=22119.9, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38500, lr=0.000161165, gnorm=0.777, loss_scale=16, train_wall=266, gb_free=8.1, wall=113594
2022-03-07 20:25:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:25:58 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.187 | nll_loss 12.58 | ppl 6122.76 | wps 43147 | wpb 510.9 | bsz 1 | num_updates 38525 | best_loss 8.233
2022-03-07 20:25:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 38525 updates
2022-03-07 20:25:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 400 @ 38525 updates, score 13.187) (writing took 2.2519291592761874 seconds)
2022-03-07 20:26:00 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 20:26:00 | INFO | train | epoch 400 | loss 2.085 | nll_loss 0.636 | ppl 1.55 | wps 22088.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38525 | lr 0.000161112 | gnorm 0.771 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 113672
2022-03-07 20:26:00 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 20:26:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:29:35 | INFO | train_inner | epoch 401:     75 / 97 loss=2.083, nll_loss=0.635, ppl=1.55, wps=22344.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38600, lr=0.000160956, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=113887
2022-03-07 20:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:30:43 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.183 | nll_loss 12.573 | ppl 6093.56 | wps 42820.6 | wpb 510.9 | bsz 1 | num_updates 38622 | best_loss 8.233
2022-03-07 20:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 38622 updates
2022-03-07 20:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 401 @ 38622 updates, score 13.183) (writing took 2.2934611393138766 seconds)
2022-03-07 20:30:45 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 20:30:45 | INFO | train | epoch 401 | loss 2.083 | nll_loss 0.634 | ppl 1.55 | wps 22321.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38622 | lr 0.00016091 | gnorm 0.763 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 113957
2022-03-07 20:30:45 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 20:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:31:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:34:31 | INFO | train_inner | epoch 402:     79 / 97 loss=2.083, nll_loss=0.634, ppl=1.55, wps=22129.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=38700, lr=0.000160748, gnorm=0.768, loss_scale=16, train_wall=265, gb_free=8.1, wall=114183
2022-03-07 20:35:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:35:27 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.211 | nll_loss 12.602 | ppl 6217.9 | wps 43183.9 | wpb 510.9 | bsz 1 | num_updates 38718 | best_loss 8.233
2022-03-07 20:35:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 38718 updates
2022-03-07 20:35:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:35:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 402 @ 38718 updates, score 13.211) (writing took 2.292218961752951 seconds)
2022-03-07 20:35:30 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 20:35:30 | INFO | train | epoch 402 | loss 2.083 | nll_loss 0.635 | ppl 1.55 | wps 22095.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38718 | lr 0.00016071 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114241
2022-03-07 20:35:30 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 20:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:39:27 | INFO | train_inner | epoch 403:     83 / 97 loss=2.082, nll_loss=0.634, ppl=1.55, wps=22120.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=38800, lr=0.00016054, gnorm=0.762, loss_scale=16, train_wall=266, gb_free=8.1, wall=114479
2022-03-07 20:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:12 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.171 | nll_loss 12.562 | ppl 6046.5 | wps 42990.7 | wpb 510.9 | bsz 1 | num_updates 38814 | best_loss 8.233
2022-03-07 20:40:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 38814 updates
2022-03-07 20:40:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 403 @ 38814 updates, score 13.171) (writing took 2.3212218061089516 seconds)
2022-03-07 20:40:14 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 20:40:14 | INFO | train | epoch 403 | loss 2.081 | nll_loss 0.633 | ppl 1.55 | wps 22088.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 38814 | lr 0.000160511 | gnorm 0.764 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114526
2022-03-07 20:40:14 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 20:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:44:20 | INFO | train_inner | epoch 404:     86 / 97 loss=2.083, nll_loss=0.634, ppl=1.55, wps=22332.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=38900, lr=0.000160334, gnorm=0.787, loss_scale=16, train_wall=263, gb_free=8.1, wall=114772
2022-03-07 20:44:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:44:56 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.178 | nll_loss 12.569 | ppl 6077.18 | wps 43255.6 | wpb 510.9 | bsz 1 | num_updates 38911 | best_loss 8.233
2022-03-07 20:44:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 38911 updates
2022-03-07 20:44:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 404 @ 38911 updates, score 13.178) (writing took 2.332068965304643 seconds)
2022-03-07 20:44:59 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 20:44:59 | INFO | train | epoch 404 | loss 2.081 | nll_loss 0.633 | ppl 1.55 | wps 22317.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 38911 | lr 0.000160311 | gnorm 0.783 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 114811
2022-03-07 20:44:59 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 20:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:45:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:49:16 | INFO | train_inner | epoch 405:     90 / 97 loss=2.08, nll_loss=0.632, ppl=1.55, wps=22137, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39000, lr=0.000160128, gnorm=0.769, loss_scale=16, train_wall=265, gb_free=8.1, wall=115068
2022-03-07 20:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:49:41 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.136 | nll_loss 12.524 | ppl 5890.84 | wps 43225.2 | wpb 510.9 | bsz 1 | num_updates 39007 | best_loss 8.233
2022-03-07 20:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 39007 updates
2022-03-07 20:49:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:49:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:49:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 405 @ 39007 updates, score 13.136) (writing took 2.2688454310409725 seconds)
2022-03-07 20:49:43 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 20:49:43 | INFO | train | epoch 405 | loss 2.079 | nll_loss 0.631 | ppl 1.55 | wps 22109 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39007 | lr 0.000160114 | gnorm 0.768 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115095
2022-03-07 20:49:43 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 20:49:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:54:12 | INFO | train_inner | epoch 406:     94 / 97 loss=2.08, nll_loss=0.632, ppl=1.55, wps=22135.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39100, lr=0.000159923, gnorm=0.768, loss_scale=16, train_wall=265, gb_free=8.1, wall=115364
2022-03-07 20:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:54:25 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.149 | nll_loss 12.538 | ppl 5946.23 | wps 43332.5 | wpb 510.9 | bsz 1 | num_updates 39103 | best_loss 8.233
2022-03-07 20:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 39103 updates
2022-03-07 20:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 406 @ 39103 updates, score 13.149) (writing took 2.315083713270724 seconds)
2022-03-07 20:54:28 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 20:54:28 | INFO | train | epoch 406 | loss 2.08 | nll_loss 0.632 | ppl 1.55 | wps 22100.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39103 | lr 0.000159917 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115380
2022-03-07 20:54:28 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 20:54:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:58:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 20:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:10 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.211 | nll_loss 12.602 | ppl 6218.02 | wps 43566.1 | wpb 510.9 | bsz 1 | num_updates 39199 | best_loss 8.233
2022-03-07 20:59:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 39199 updates
2022-03-07 20:59:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:59:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 20:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 407 @ 39199 updates, score 13.211) (writing took 2.302562543656677 seconds)
2022-03-07 20:59:12 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 20:59:12 | INFO | train | epoch 407 | loss 2.08 | nll_loss 0.632 | ppl 1.55 | wps 22104.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39199 | lr 0.000159721 | gnorm 0.77 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115664
2022-03-07 20:59:12 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 20:59:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:59:15 | INFO | train_inner | epoch 408:      1 / 97 loss=2.08, nll_loss=0.632, ppl=1.55, wps=21589.5, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=39200, lr=0.000159719, gnorm=0.771, loss_scale=16, train_wall=265, gb_free=8.1, wall=115667
2022-03-07 21:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:03:55 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.146 | nll_loss 12.536 | ppl 5939 | wps 43236.5 | wpb 510.9 | bsz 1 | num_updates 39296 | best_loss 8.233
2022-03-07 21:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 39296 updates
2022-03-07 21:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 408 @ 39296 updates, score 13.146) (writing took 2.2606286630034447 seconds)
2022-03-07 21:03:57 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 21:03:57 | INFO | train | epoch 408 | loss 2.078 | nll_loss 0.63 | ppl 1.55 | wps 22302.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39296 | lr 0.000159524 | gnorm 0.768 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 115949
2022-03-07 21:03:57 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 21:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:04:08 | INFO | train_inner | epoch 409:      4 / 97 loss=2.078, nll_loss=0.63, ppl=1.55, wps=22321.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39300, lr=0.000159516, gnorm=0.768, loss_scale=16, train_wall=263, gb_free=8.1, wall=115960
2022-03-07 21:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:08:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:39 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.215 | nll_loss 12.609 | ppl 6246.36 | wps 43058.3 | wpb 510.9 | bsz 1 | num_updates 39392 | best_loss 8.233
2022-03-07 21:08:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 39392 updates
2022-03-07 21:08:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:08:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:08:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 409 @ 39392 updates, score 13.215) (writing took 2.3826268892735243 seconds)
2022-03-07 21:08:42 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 21:08:42 | INFO | train | epoch 409 | loss 2.076 | nll_loss 0.628 | ppl 1.55 | wps 22076.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39392 | lr 0.000159329 | gnorm 0.762 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116234
2022-03-07 21:08:42 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 21:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:09:05 | INFO | train_inner | epoch 410:      8 / 97 loss=2.075, nll_loss=0.627, ppl=1.54, wps=22108.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39400, lr=0.000159313, gnorm=0.762, loss_scale=16, train_wall=266, gb_free=8.1, wall=116257
2022-03-07 21:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:13:24 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.201 | nll_loss 12.596 | ppl 6190.16 | wps 42977.1 | wpb 510.9 | bsz 1 | num_updates 39489 | best_loss 8.233
2022-03-07 21:13:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 39489 updates
2022-03-07 21:13:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:13:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:13:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 410 @ 39489 updates, score 13.201) (writing took 2.2490212228149176 seconds)
2022-03-07 21:13:26 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 21:13:26 | INFO | train | epoch 410 | loss 2.076 | nll_loss 0.628 | ppl 1.55 | wps 22313.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39489 | lr 0.000159134 | gnorm 0.757 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 116518
2022-03-07 21:13:26 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 21:13:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:13:58 | INFO | train_inner | epoch 411:     11 / 97 loss=2.076, nll_loss=0.628, ppl=1.55, wps=22329.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39500, lr=0.000159111, gnorm=0.757, loss_scale=32, train_wall=263, gb_free=8.1, wall=116550
2022-03-07 21:14:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:18:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:09 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.187 | nll_loss 12.578 | ppl 6112.62 | wps 43183.5 | wpb 510.9 | bsz 1 | num_updates 39585 | best_loss 8.233
2022-03-07 21:18:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 39585 updates
2022-03-07 21:18:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:18:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:18:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 411 @ 39585 updates, score 13.187) (writing took 2.267606134992093 seconds)
2022-03-07 21:18:11 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 21:18:11 | INFO | train | epoch 411 | loss 2.075 | nll_loss 0.627 | ppl 1.54 | wps 22090 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39585 | lr 0.000158941 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 116803
2022-03-07 21:18:11 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 21:18:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:54 | INFO | train_inner | epoch 412:     15 / 97 loss=2.075, nll_loss=0.627, ppl=1.54, wps=22128.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=39600, lr=0.00015891, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=116846
2022-03-07 21:22:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:22:53 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.135 | nll_loss 12.52 | ppl 5872.7 | wps 43310 | wpb 510.9 | bsz 1 | num_updates 39681 | best_loss 8.233
2022-03-07 21:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 39681 updates
2022-03-07 21:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:22:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:22:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 412 @ 39681 updates, score 13.135) (writing took 2.2844471149146557 seconds)
2022-03-07 21:22:56 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 21:22:56 | INFO | train | epoch 412 | loss 2.074 | nll_loss 0.627 | ppl 1.54 | wps 22089.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39681 | lr 0.000158748 | gnorm 0.762 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117088
2022-03-07 21:22:56 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 21:22:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:23:50 | INFO | train_inner | epoch 413:     19 / 97 loss=2.073, nll_loss=0.625, ppl=1.54, wps=22111.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=39700, lr=0.00015871, gnorm=0.762, loss_scale=16, train_wall=266, gb_free=8.1, wall=117142
2022-03-07 21:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:27:38 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.195 | nll_loss 12.587 | ppl 6151.7 | wps 43268.6 | wpb 510.9 | bsz 1 | num_updates 39778 | best_loss 8.233
2022-03-07 21:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 39778 updates
2022-03-07 21:27:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 413 @ 39778 updates, score 13.195) (writing took 2.2539264080114663 seconds)
2022-03-07 21:27:40 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 21:27:40 | INFO | train | epoch 413 | loss 2.075 | nll_loss 0.627 | ppl 1.54 | wps 22343.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 39778 | lr 0.000158554 | gnorm 0.762 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117372
2022-03-07 21:27:40 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 21:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:43 | INFO | train_inner | epoch 414:     22 / 97 loss=2.074, nll_loss=0.626, ppl=1.54, wps=22359.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=39800, lr=0.000158511, gnorm=0.763, loss_scale=32, train_wall=263, gb_free=8.1, wall=117435
2022-03-07 21:29:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:32:22 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.167 | nll_loss 12.558 | ppl 6031.85 | wps 43446.5 | wpb 510.9 | bsz 1 | num_updates 39874 | best_loss 8.233
2022-03-07 21:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 39874 updates
2022-03-07 21:32:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:32:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:32:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 414 @ 39874 updates, score 13.167) (writing took 2.3052135561592877 seconds)
2022-03-07 21:32:25 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 21:32:25 | INFO | train | epoch 414 | loss 2.073 | nll_loss 0.626 | ppl 1.54 | wps 22087.2 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 39874 | lr 0.000158364 | gnorm 0.769 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117657
2022-03-07 21:32:25 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 21:32:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:39 | INFO | train_inner | epoch 415:     26 / 97 loss=2.073, nll_loss=0.626, ppl=1.54, wps=22126.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=39900, lr=0.000158312, gnorm=0.767, loss_scale=16, train_wall=266, gb_free=8.1, wall=117731
2022-03-07 21:36:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:07 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.18 | nll_loss 12.572 | ppl 6090.87 | wps 43312.7 | wpb 510.9 | bsz 1 | num_updates 39970 | best_loss 8.233
2022-03-07 21:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 39970 updates
2022-03-07 21:37:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 415 @ 39970 updates, score 13.18) (writing took 2.323244618717581 seconds)
2022-03-07 21:37:09 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 21:37:09 | INFO | train | epoch 415 | loss 2.073 | nll_loss 0.625 | ppl 1.54 | wps 22089.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 39970 | lr 0.000158173 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 117941
2022-03-07 21:37:09 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 21:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:38:35 | INFO | train_inner | epoch 416:     30 / 97 loss=2.072, nll_loss=0.625, ppl=1.54, wps=22118.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40000, lr=0.000158114, gnorm=0.765, loss_scale=16, train_wall=265, gb_free=8.1, wall=118027
2022-03-07 21:41:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:52 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.161 | nll_loss 12.555 | ppl 6016.98 | wps 43441 | wpb 510.9 | bsz 1 | num_updates 40067 | best_loss 8.233
2022-03-07 21:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 40067 updates
2022-03-07 21:41:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:41:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:41:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 416 @ 40067 updates, score 13.161) (writing took 2.288512364961207 seconds)
2022-03-07 21:41:54 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 21:41:54 | INFO | train | epoch 416 | loss 2.072 | nll_loss 0.624 | ppl 1.54 | wps 22314.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40067 | lr 0.000157982 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118226
2022-03-07 21:41:54 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 21:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:43:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:43:31 | INFO | train_inner | epoch 417:     34 / 97 loss=2.071, nll_loss=0.623, ppl=1.54, wps=22112.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40100, lr=0.000157917, gnorm=0.755, loss_scale=16, train_wall=265, gb_free=8.1, wall=118323
2022-03-07 21:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:36 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.104 | nll_loss 12.492 | ppl 5762 | wps 43270.7 | wpb 510.9 | bsz 1 | num_updates 40163 | best_loss 8.233
2022-03-07 21:46:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 40163 updates
2022-03-07 21:46:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:46:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 417 @ 40163 updates, score 13.104) (writing took 2.2737818439491093 seconds)
2022-03-07 21:46:39 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 21:46:39 | INFO | train | epoch 417 | loss 2.071 | nll_loss 0.624 | ppl 1.54 | wps 22084.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40163 | lr 0.000157793 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118511
2022-03-07 21:46:39 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 21:46:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:25 | INFO | train_inner | epoch 418:     37 / 97 loss=2.072, nll_loss=0.624, ppl=1.54, wps=22332.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40200, lr=0.00015772, gnorm=0.767, loss_scale=16, train_wall=263, gb_free=8.1, wall=118617
2022-03-07 21:49:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:51:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:51:21 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.152 | nll_loss 12.545 | ppl 5977.46 | wps 43200.8 | wpb 510.9 | bsz 1 | num_updates 40259 | best_loss 8.233
2022-03-07 21:51:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 40259 updates
2022-03-07 21:51:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:51:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:51:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 418 @ 40259 updates, score 13.152) (writing took 2.344605704769492 seconds)
2022-03-07 21:51:23 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 21:51:23 | INFO | train | epoch 418 | loss 2.07 | nll_loss 0.623 | ppl 1.54 | wps 22075.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40259 | lr 0.000157604 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 118795
2022-03-07 21:51:23 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 21:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:53:21 | INFO | train_inner | epoch 419:     41 / 97 loss=2.069, nll_loss=0.621, ppl=1.54, wps=22108.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40300, lr=0.000157524, gnorm=0.756, loss_scale=16, train_wall=266, gb_free=8.1, wall=118913
2022-03-07 21:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:06 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.154 | nll_loss 12.546 | ppl 5979.24 | wps 43490.8 | wpb 510.9 | bsz 1 | num_updates 40356 | best_loss 8.233
2022-03-07 21:56:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 40356 updates
2022-03-07 21:56:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 21:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 419 @ 40356 updates, score 13.154) (writing took 2.323331318795681 seconds)
2022-03-07 21:56:08 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 21:56:08 | INFO | train | epoch 419 | loss 2.07 | nll_loss 0.623 | ppl 1.54 | wps 22316.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40356 | lr 0.000157415 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119080
2022-03-07 21:56:08 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 21:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:56:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 21:58:17 | INFO | train_inner | epoch 420:     45 / 97 loss=2.07, nll_loss=0.623, ppl=1.54, wps=22118.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40400, lr=0.000157329, gnorm=0.763, loss_scale=16, train_wall=265, gb_free=8.1, wall=119209
2022-03-07 22:00:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:50 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.124 | nll_loss 12.513 | ppl 5846.15 | wps 43723.9 | wpb 510.9 | bsz 1 | num_updates 40452 | best_loss 8.233
2022-03-07 22:00:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 40452 updates
2022-03-07 22:00:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 420 @ 40452 updates, score 13.124) (writing took 2.2783450563438237 seconds)
2022-03-07 22:00:53 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 22:00:53 | INFO | train | epoch 420 | loss 2.068 | nll_loss 0.62 | ppl 1.54 | wps 22091.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40452 | lr 0.000157228 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119365
2022-03-07 22:00:53 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 22:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:10 | INFO | train_inner | epoch 421:     48 / 97 loss=2.067, nll_loss=0.619, ppl=1.54, wps=22334.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40500, lr=0.000157135, gnorm=0.747, loss_scale=32, train_wall=263, gb_free=8.1, wall=119502
2022-03-07 22:03:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:05:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:35 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.18 | nll_loss 12.575 | ppl 6103.07 | wps 43138.3 | wpb 510.9 | bsz 1 | num_updates 40548 | best_loss 8.233
2022-03-07 22:05:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 40548 updates
2022-03-07 22:05:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 421 @ 40548 updates, score 13.18) (writing took 2.3038721182383597 seconds)
2022-03-07 22:05:38 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 22:05:38 | INFO | train | epoch 421 | loss 2.068 | nll_loss 0.621 | ppl 1.54 | wps 22070.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40548 | lr 0.000157042 | gnorm 0.757 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 119649
2022-03-07 22:05:38 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 22:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:08:06 | INFO | train_inner | epoch 422:     52 / 97 loss=2.07, nll_loss=0.623, ppl=1.54, wps=22111, ups=0.34, wpb=65495, bsz=127.9, num_updates=40600, lr=0.000156941, gnorm=0.769, loss_scale=16, train_wall=266, gb_free=8.1, wall=119798
2022-03-07 22:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:10:20 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.171 | nll_loss 12.563 | ppl 6050.8 | wps 43100.2 | wpb 510.9 | bsz 1 | num_updates 40645 | best_loss 8.233
2022-03-07 22:10:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 40645 updates
2022-03-07 22:10:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:10:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:10:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 422 @ 40645 updates, score 13.171) (writing took 2.2706928169354796 seconds)
2022-03-07 22:10:22 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 22:10:22 | INFO | train | epoch 422 | loss 2.067 | nll_loss 0.62 | ppl 1.54 | wps 22316.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 40645 | lr 0.000156854 | gnorm 0.761 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 119934
2022-03-07 22:10:22 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 22:10:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:13:02 | INFO | train_inner | epoch 423:     56 / 97 loss=2.067, nll_loss=0.62, ppl=1.54, wps=22117.8, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=40700, lr=0.000156748, gnorm=0.753, loss_scale=16, train_wall=266, gb_free=8.1, wall=120094
2022-03-07 22:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:05 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.189 | nll_loss 12.583 | ppl 6133.56 | wps 43288 | wpb 510.9 | bsz 1 | num_updates 40741 | best_loss 8.233
2022-03-07 22:15:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 40741 updates
2022-03-07 22:15:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 423 @ 40741 updates, score 13.189) (writing took 2.297753675840795 seconds)
2022-03-07 22:15:07 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 22:15:07 | INFO | train | epoch 423 | loss 2.067 | nll_loss 0.62 | ppl 1.54 | wps 22086.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40741 | lr 0.000156669 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120219
2022-03-07 22:15:07 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 22:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:17:56 | INFO | train_inner | epoch 424:     59 / 97 loss=2.066, nll_loss=0.619, ppl=1.54, wps=22331.7, ups=0.34, wpb=65495, bsz=127.9, num_updates=40800, lr=0.000156556, gnorm=0.763, loss_scale=16, train_wall=263, gb_free=8.1, wall=120388
2022-03-07 22:18:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:49 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.159 | nll_loss 12.553 | ppl 6011.23 | wps 43170 | wpb 510.9 | bsz 1 | num_updates 40837 | best_loss 8.233
2022-03-07 22:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 40837 updates
2022-03-07 22:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 424 @ 40837 updates, score 13.159) (writing took 2.325697859749198 seconds)
2022-03-07 22:19:52 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 22:19:52 | INFO | train | epoch 424 | loss 2.066 | nll_loss 0.619 | ppl 1.54 | wps 22076.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40837 | lr 0.000156485 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120504
2022-03-07 22:19:52 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 22:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:22:52 | INFO | train_inner | epoch 425:     63 / 97 loss=2.067, nll_loss=0.62, ppl=1.54, wps=22116.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=40900, lr=0.000156365, gnorm=0.768, loss_scale=16, train_wall=266, gb_free=8.1, wall=120684
2022-03-07 22:24:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:24:34 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.192 | nll_loss 12.589 | ppl 6162.89 | wps 42817.1 | wpb 510.9 | bsz 1 | num_updates 40933 | best_loss 8.233
2022-03-07 22:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 40933 updates
2022-03-07 22:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:24:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 425 @ 40933 updates, score 13.192) (writing took 2.334421867970377 seconds)
2022-03-07 22:24:36 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 22:24:36 | INFO | train | epoch 425 | loss 2.066 | nll_loss 0.619 | ppl 1.54 | wps 22089 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 40933 | lr 0.000156302 | gnorm 0.768 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 120788
2022-03-07 22:24:36 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 22:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:27:48 | INFO | train_inner | epoch 426:     67 / 97 loss=2.064, nll_loss=0.617, ppl=1.53, wps=22116.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=41000, lr=0.000156174, gnorm=0.768, loss_scale=16, train_wall=265, gb_free=8.1, wall=120980
2022-03-07 22:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:29:19 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.147 | nll_loss 12.542 | ppl 5965.17 | wps 43207.4 | wpb 510.9 | bsz 1 | num_updates 41030 | best_loss 8.233
2022-03-07 22:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 41030 updates
2022-03-07 22:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 426 @ 41030 updates, score 13.147) (writing took 2.3109852098859847 seconds)
2022-03-07 22:29:21 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 22:29:21 | INFO | train | epoch 426 | loss 2.065 | nll_loss 0.617 | ppl 1.53 | wps 22312.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41030 | lr 0.000156117 | gnorm 0.765 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121073
2022-03-07 22:29:21 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 22:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:32:44 | INFO | train_inner | epoch 427:     71 / 97 loss=2.066, nll_loss=0.619, ppl=1.54, wps=22131.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=41100, lr=0.000155984, gnorm=0.762, loss_scale=16, train_wall=265, gb_free=8.1, wall=121276
2022-03-07 22:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:03 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.204 | nll_loss 12.603 | ppl 6221.54 | wps 43307 | wpb 510.9 | bsz 1 | num_updates 41126 | best_loss 8.233
2022-03-07 22:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 41126 updates
2022-03-07 22:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:34:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 427 @ 41126 updates, score 13.204) (writing took 2.3129832460545003 seconds)
2022-03-07 22:34:06 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 22:34:06 | INFO | train | epoch 427 | loss 2.063 | nll_loss 0.616 | ppl 1.53 | wps 22098.3 | ups 0.34 | wpb 65493.3 | bsz 127.9 | num_updates 41126 | lr 0.000155934 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121357
2022-03-07 22:34:06 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 22:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:37:40 | INFO | train_inner | epoch 428:     75 / 97 loss=2.063, nll_loss=0.616, ppl=1.53, wps=22114.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41200, lr=0.000155794, gnorm=0.765, loss_scale=16, train_wall=266, gb_free=8.1, wall=121572
2022-03-07 22:38:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:38:48 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.255 | nll_loss 12.656 | ppl 6452.73 | wps 43481.7 | wpb 510.9 | bsz 1 | num_updates 41222 | best_loss 8.233
2022-03-07 22:38:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 41222 updates
2022-03-07 22:38:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:38:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:38:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 428 @ 41222 updates, score 13.255) (writing took 2.273431439884007 seconds)
2022-03-07 22:38:50 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 22:38:50 | INFO | train | epoch 428 | loss 2.063 | nll_loss 0.616 | ppl 1.53 | wps 22087.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41222 | lr 0.000155753 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 121642
2022-03-07 22:38:50 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 22:38:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:42:33 | INFO | train_inner | epoch 429:     78 / 97 loss=2.063, nll_loss=0.616, ppl=1.53, wps=22333, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41300, lr=0.000155606, gnorm=0.758, loss_scale=16, train_wall=263, gb_free=8.1, wall=121865
2022-03-07 22:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:43:33 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.198 | nll_loss 12.596 | ppl 6191.2 | wps 43173.5 | wpb 510.9 | bsz 1 | num_updates 41319 | best_loss 8.233
2022-03-07 22:43:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 41319 updates
2022-03-07 22:43:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:43:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:43:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 429 @ 41319 updates, score 13.198) (writing took 2.2970326291397214 seconds)
2022-03-07 22:43:35 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 22:43:35 | INFO | train | epoch 429 | loss 2.063 | nll_loss 0.616 | ppl 1.53 | wps 22313.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41319 | lr 0.00015557 | gnorm 0.764 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 121927
2022-03-07 22:43:35 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 22:43:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:47:30 | INFO | train_inner | epoch 430:     82 / 97 loss=2.062, nll_loss=0.615, ppl=1.53, wps=22110.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41400, lr=0.000155417, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=122161
2022-03-07 22:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:48:17 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.072 | nll_loss 12.458 | ppl 5625.74 | wps 43425.7 | wpb 510.9 | bsz 1 | num_updates 41415 | best_loss 8.233
2022-03-07 22:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 41415 updates
2022-03-07 22:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 430 @ 41415 updates, score 13.072) (writing took 2.3354228921234608 seconds)
2022-03-07 22:48:20 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 22:48:20 | INFO | train | epoch 430 | loss 2.061 | nll_loss 0.614 | ppl 1.53 | wps 22077.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41415 | lr 0.000155389 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122212
2022-03-07 22:48:20 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 22:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:52:26 | INFO | train_inner | epoch 431:     86 / 97 loss=2.062, nll_loss=0.615, ppl=1.53, wps=22103.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41500, lr=0.00015523, gnorm=0.764, loss_scale=16, train_wall=266, gb_free=8.1, wall=122458
2022-03-07 22:52:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:02 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.168 | nll_loss 12.561 | ppl 6043.09 | wps 43256.9 | wpb 510.9 | bsz 1 | num_updates 41511 | best_loss 8.233
2022-03-07 22:53:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 41511 updates
2022-03-07 22:53:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 431 @ 41511 updates, score 13.168) (writing took 2.307663458865136 seconds)
2022-03-07 22:53:05 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 22:53:05 | INFO | train | epoch 431 | loss 2.061 | nll_loss 0.614 | ppl 1.53 | wps 22070.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41511 | lr 0.00015521 | gnorm 0.763 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122496
2022-03-07 22:53:05 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 22:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:56:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 22:57:22 | INFO | train_inner | epoch 432:     90 / 97 loss=2.06, nll_loss=0.614, ppl=1.53, wps=22103.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=41600, lr=0.000155043, gnorm=0.755, loss_scale=16, train_wall=265, gb_free=8.1, wall=122754
2022-03-07 22:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:47 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.175 | nll_loss 12.571 | ppl 6083.24 | wps 43092.6 | wpb 510.9 | bsz 1 | num_updates 41607 | best_loss 8.233
2022-03-07 22:57:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 41607 updates
2022-03-07 22:57:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 22:57:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 432 @ 41607 updates, score 13.175) (writing took 2.327718611806631 seconds)
2022-03-07 22:57:49 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 22:57:49 | INFO | train | epoch 432 | loss 2.06 | nll_loss 0.613 | ppl 1.53 | wps 22065.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41607 | lr 0.00015503 | gnorm 0.756 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 122781
2022-03-07 22:57:49 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 22:57:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:16 | INFO | train_inner | epoch 433:     93 / 97 loss=2.06, nll_loss=0.613, ppl=1.53, wps=22305.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=41700, lr=0.000154857, gnorm=0.755, loss_scale=16, train_wall=263, gb_free=8.1, wall=123048
2022-03-07 23:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:02:32 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.2 | nll_loss 12.599 | ppl 6204.97 | wps 43662.8 | wpb 510.9 | bsz 1 | num_updates 41704 | best_loss 8.233
2022-03-07 23:02:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 41704 updates
2022-03-07 23:02:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:02:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:02:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 433 @ 41704 updates, score 13.2) (writing took 2.2436844101175666 seconds)
2022-03-07 23:02:34 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 23:02:34 | INFO | train | epoch 433 | loss 2.059 | nll_loss 0.612 | ppl 1.53 | wps 22302.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41704 | lr 0.00015485 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123066
2022-03-07 23:02:34 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 23:02:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:03:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:07:12 | INFO | train_inner | epoch 434:     97 / 97 loss=2.059, nll_loss=0.613, ppl=1.53, wps=22100.9, ups=0.34, wpb=65449.8, bsz=127.8, num_updates=41800, lr=0.000154672, gnorm=0.751, loss_scale=16, train_wall=265, gb_free=8.1, wall=123344
2022-03-07 23:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:07:17 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.233 | nll_loss 12.631 | ppl 6344.32 | wps 43460.1 | wpb 510.9 | bsz 1 | num_updates 41800 | best_loss 8.233
2022-03-07 23:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 41800 updates
2022-03-07 23:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 434 @ 41800 updates, score 13.233) (writing took 2.238286844920367 seconds)
2022-03-07 23:07:19 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 23:07:19 | INFO | train | epoch 434 | loss 2.059 | nll_loss 0.612 | ppl 1.53 | wps 22067.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41800 | lr 0.000154672 | gnorm 0.752 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123351
2022-03-07 23:07:19 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 23:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:10:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:12:02 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.211 | nll_loss 12.61 | ppl 6251.4 | wps 43139.8 | wpb 510.9 | bsz 1 | num_updates 41896 | best_loss 8.233
2022-03-07 23:12:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 41896 updates
2022-03-07 23:12:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:12:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 435 @ 41896 updates, score 13.211) (writing took 2.2177061438560486 seconds)
2022-03-07 23:12:04 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 23:12:04 | INFO | train | epoch 435 | loss 2.059 | nll_loss 0.612 | ppl 1.53 | wps 22085.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 41896 | lr 0.000154495 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123636
2022-03-07 23:12:04 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 23:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:12:15 | INFO | train_inner | epoch 436:      4 / 97 loss=2.059, nll_loss=0.612, ppl=1.53, wps=21578.2, ups=0.33, wpb=65490.8, bsz=127.9, num_updates=41900, lr=0.000154487, gnorm=0.76, loss_scale=16, train_wall=266, gb_free=8.1, wall=123647
2022-03-07 23:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:16:46 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.171 | nll_loss 12.565 | ppl 6058.81 | wps 43515.3 | wpb 510.9 | bsz 1 | num_updates 41993 | best_loss 8.233
2022-03-07 23:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 41993 updates
2022-03-07 23:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 436 @ 41993 updates, score 13.171) (writing took 2.3571584206074476 seconds)
2022-03-07 23:16:49 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 23:16:49 | INFO | train | epoch 436 | loss 2.058 | nll_loss 0.611 | ppl 1.53 | wps 22310.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 41993 | lr 0.000154316 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 123921
2022-03-07 23:16:49 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 23:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:17:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:17:12 | INFO | train_inner | epoch 437:      8 / 97 loss=2.057, nll_loss=0.61, ppl=1.53, wps=22115.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=42000, lr=0.000154303, gnorm=0.759, loss_scale=16, train_wall=265, gb_free=8.1, wall=123943
2022-03-07 23:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:21:31 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.193 | nll_loss 12.589 | ppl 6161.1 | wps 43406.5 | wpb 510.9 | bsz 1 | num_updates 42089 | best_loss 8.233
2022-03-07 23:21:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 42089 updates
2022-03-07 23:21:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:21:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 437 @ 42089 updates, score 13.193) (writing took 2.24729546578601 seconds)
2022-03-07 23:21:33 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 23:21:33 | INFO | train | epoch 437 | loss 2.057 | nll_loss 0.61 | ppl 1.53 | wps 22074.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42089 | lr 0.00015414 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124205
2022-03-07 23:21:33 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 23:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:22:05 | INFO | train_inner | epoch 438:     11 / 97 loss=2.056, nll_loss=0.61, ppl=1.53, wps=22324.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42100, lr=0.00015412, gnorm=0.758, loss_scale=16, train_wall=263, gb_free=8.1, wall=124237
2022-03-07 23:23:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:26:16 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.21 | nll_loss 12.609 | ppl 6245.53 | wps 43402.8 | wpb 510.9 | bsz 1 | num_updates 42185 | best_loss 8.233
2022-03-07 23:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 42185 updates
2022-03-07 23:26:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:26:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:26:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 438 @ 42185 updates, score 13.21) (writing took 2.2132727028802037 seconds)
2022-03-07 23:26:18 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 23:26:18 | INFO | train | epoch 438 | loss 2.056 | nll_loss 0.61 | ppl 1.53 | wps 22100.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42185 | lr 0.000153965 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124490
2022-03-07 23:26:18 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 23:26:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:27:01 | INFO | train_inner | epoch 439:     15 / 97 loss=2.056, nll_loss=0.61, ppl=1.53, wps=22126.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42200, lr=0.000153937, gnorm=0.761, loss_scale=16, train_wall=266, gb_free=8.1, wall=124533
2022-03-07 23:30:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:30:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:31:00 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.144 | nll_loss 12.536 | ppl 5940.73 | wps 43128.9 | wpb 510.9 | bsz 1 | num_updates 42281 | best_loss 8.233
2022-03-07 23:31:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 42281 updates
2022-03-07 23:31:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 439 @ 42281 updates, score 13.144) (writing took 2.2781247226521373 seconds)
2022-03-07 23:31:03 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 23:31:03 | INFO | train | epoch 439 | loss 2.056 | nll_loss 0.609 | ppl 1.53 | wps 22081.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42281 | lr 0.00015379 | gnorm 0.76 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 124775
2022-03-07 23:31:03 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 23:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:31:57 | INFO | train_inner | epoch 440:     19 / 97 loss=2.054, nll_loss=0.608, ppl=1.52, wps=22109.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42300, lr=0.000153755, gnorm=0.759, loss_scale=16, train_wall=266, gb_free=8.1, wall=124829
2022-03-07 23:35:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:35:45 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.109 | nll_loss 12.503 | ppl 5804.71 | wps 43425.8 | wpb 510.9 | bsz 1 | num_updates 42378 | best_loss 8.233
2022-03-07 23:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 42378 updates
2022-03-07 23:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 440 @ 42378 updates, score 13.109) (writing took 2.210872479248792 seconds)
2022-03-07 23:35:47 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 23:35:47 | INFO | train | epoch 440 | loss 2.056 | nll_loss 0.609 | ppl 1.53 | wps 22317.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42378 | lr 0.000153614 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125059
2022-03-07 23:35:47 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 23:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:36:53 | INFO | train_inner | epoch 441:     23 / 97 loss=2.056, nll_loss=0.609, ppl=1.53, wps=22128.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42400, lr=0.000153574, gnorm=0.755, loss_scale=16, train_wall=266, gb_free=8.1, wall=125125
2022-03-07 23:40:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:40:30 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.169 | nll_loss 12.566 | ppl 6065 | wps 43243.7 | wpb 510.9 | bsz 1 | num_updates 42474 | best_loss 8.233
2022-03-07 23:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 42474 updates
2022-03-07 23:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:40:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:40:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 441 @ 42474 updates, score 13.169) (writing took 2.293532941956073 seconds)
2022-03-07 23:40:32 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 23:40:32 | INFO | train | epoch 441 | loss 2.054 | nll_loss 0.608 | ppl 1.52 | wps 22095.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42474 | lr 0.00015344 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125344
2022-03-07 23:40:32 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 23:40:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:41:46 | INFO | train_inner | epoch 442:     26 / 97 loss=2.053, nll_loss=0.607, ppl=1.52, wps=22334.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42500, lr=0.000153393, gnorm=0.753, loss_scale=16, train_wall=263, gb_free=8.1, wall=125418
2022-03-07 23:43:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:45:14 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.166 | nll_loss 12.564 | ppl 6053.45 | wps 43327.3 | wpb 510.9 | bsz 1 | num_updates 42570 | best_loss 8.233
2022-03-07 23:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 42570 updates
2022-03-07 23:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 442 @ 42570 updates, score 13.166) (writing took 2.242981235962361 seconds)
2022-03-07 23:45:16 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 23:45:16 | INFO | train | epoch 442 | loss 2.053 | nll_loss 0.607 | ppl 1.52 | wps 22087.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42570 | lr 0.000153267 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 125628
2022-03-07 23:45:17 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 23:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:42 | INFO | train_inner | epoch 443:     30 / 97 loss=2.053, nll_loss=0.607, ppl=1.52, wps=22119.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42600, lr=0.000153213, gnorm=0.741, loss_scale=16, train_wall=266, gb_free=8.1, wall=125714
2022-03-07 23:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:49:59 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.2 | nll_loss 12.595 | ppl 6188.16 | wps 43481.2 | wpb 510.9 | bsz 1 | num_updates 42667 | best_loss 8.233
2022-03-07 23:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 42667 updates
2022-03-07 23:49:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 443 @ 42667 updates, score 13.2) (writing took 2.2261722828261554 seconds)
2022-03-07 23:50:01 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 23:50:01 | INFO | train | epoch 443 | loss 2.053 | nll_loss 0.606 | ppl 1.52 | wps 22309.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42667 | lr 0.000153093 | gnorm 0.745 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 125913
2022-03-07 23:50:01 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 23:50:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:51:36 | INFO | train_inner | epoch 444:     33 / 97 loss=2.053, nll_loss=0.606, ppl=1.52, wps=22328.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42700, lr=0.000153033, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=126008
2022-03-07 23:52:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:54:44 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.156 | nll_loss 12.551 | ppl 5999.06 | wps 43071.6 | wpb 510.9 | bsz 1 | num_updates 42763 | best_loss 8.233
2022-03-07 23:54:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 42763 updates
2022-03-07 23:54:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 444 @ 42763 updates, score 13.156) (writing took 2.269861539825797 seconds)
2022-03-07 23:54:46 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 23:54:46 | INFO | train | epoch 444 | loss 2.053 | nll_loss 0.607 | ppl 1.52 | wps 22070.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42763 | lr 0.000152921 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126198
2022-03-07 23:54:46 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 23:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:56:32 | INFO | train_inner | epoch 445:     37 / 97 loss=2.051, nll_loss=0.604, ppl=1.52, wps=22106.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42800, lr=0.000152854, gnorm=0.751, loss_scale=16, train_wall=266, gb_free=8.1, wall=126304
2022-03-07 23:59:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 23:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:59:29 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.179 | nll_loss 12.577 | ppl 6111.44 | wps 43246 | wpb 510.9 | bsz 1 | num_updates 42859 | best_loss 8.233
2022-03-07 23:59:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 42859 updates
2022-03-07 23:59:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-07 23:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 445 @ 42859 updates, score 13.179) (writing took 2.2894554249942303 seconds)
2022-03-07 23:59:31 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 23:59:31 | INFO | train | epoch 445 | loss 2.051 | nll_loss 0.605 | ppl 1.52 | wps 22081.8 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 42859 | lr 0.000152749 | gnorm 0.747 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126483
2022-03-07 23:59:31 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 23:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:01:28 | INFO | train_inner | epoch 446:     41 / 97 loss=2.052, nll_loss=0.605, ppl=1.52, wps=22100.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=42900, lr=0.000152676, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=126600
2022-03-08 00:04:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:04:13 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.174 | nll_loss 12.567 | ppl 6067.57 | wps 43268.5 | wpb 510.9 | bsz 1 | num_updates 42956 | best_loss 8.233
2022-03-08 00:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 42956 updates
2022-03-08 00:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:04:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:04:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 446 @ 42956 updates, score 13.174) (writing took 2.2761247190646827 seconds)
2022-03-08 00:04:16 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-08 00:04:16 | INFO | train | epoch 446 | loss 2.051 | nll_loss 0.605 | ppl 1.52 | wps 22296.9 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 42956 | lr 0.000152577 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 126768
2022-03-08 00:04:16 | INFO | fairseq.trainer | begin training epoch 447
2022-03-08 00:04:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:05:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:06:25 | INFO | train_inner | epoch 447:     45 / 97 loss=2.052, nll_loss=0.606, ppl=1.52, wps=22112.6, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43000, lr=0.000152499, gnorm=0.752, loss_scale=16, train_wall=266, gb_free=8.1, wall=126896
2022-03-08 00:08:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:58 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.191 | nll_loss 12.589 | ppl 6160.72 | wps 43110 | wpb 510.9 | bsz 1 | num_updates 43052 | best_loss 8.233
2022-03-08 00:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 43052 updates
2022-03-08 00:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:09:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:09:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 447 @ 43052 updates, score 13.191) (writing took 2.2470399690791965 seconds)
2022-03-08 00:09:01 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-08 00:09:01 | INFO | train | epoch 447 | loss 2.05 | nll_loss 0.604 | ppl 1.52 | wps 22072.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43052 | lr 0.000152406 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127052
2022-03-08 00:09:01 | INFO | fairseq.trainer | begin training epoch 448
2022-03-08 00:09:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:11:18 | INFO | train_inner | epoch 448:     48 / 97 loss=2.049, nll_loss=0.603, ppl=1.52, wps=22315.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43100, lr=0.000152322, gnorm=0.753, loss_scale=16, train_wall=263, gb_free=8.1, wall=127190
2022-03-08 00:13:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:13:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:13:43 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.187 | nll_loss 12.588 | ppl 6157.88 | wps 43289.8 | wpb 510.9 | bsz 1 | num_updates 43148 | best_loss 8.233
2022-03-08 00:13:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 43148 updates
2022-03-08 00:13:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:13:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 448 @ 43148 updates, score 13.187) (writing took 2.26309842383489 seconds)
2022-03-08 00:13:45 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-08 00:13:45 | INFO | train | epoch 448 | loss 2.05 | nll_loss 0.604 | ppl 1.52 | wps 22078.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43148 | lr 0.000152237 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127337
2022-03-08 00:13:45 | INFO | fairseq.trainer | begin training epoch 449
2022-03-08 00:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:14 | INFO | train_inner | epoch 449:     52 / 97 loss=2.049, nll_loss=0.603, ppl=1.52, wps=22104.8, ups=0.34, wpb=65495, bsz=127.9, num_updates=43200, lr=0.000152145, gnorm=0.746, loss_scale=16, train_wall=266, gb_free=8.1, wall=127486
2022-03-08 00:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:18:28 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.173 | nll_loss 12.569 | ppl 6077.26 | wps 43472 | wpb 510.9 | bsz 1 | num_updates 43245 | best_loss 8.233
2022-03-08 00:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 43245 updates
2022-03-08 00:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 449 @ 43245 updates, score 13.173) (writing took 2.294947552960366 seconds)
2022-03-08 00:18:30 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-08 00:18:30 | INFO | train | epoch 449 | loss 2.048 | nll_loss 0.602 | ppl 1.52 | wps 22288.4 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43245 | lr 0.000152066 | gnorm 0.752 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127622
2022-03-08 00:18:30 | INFO | fairseq.trainer | begin training epoch 450
2022-03-08 00:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:21:11 | INFO | train_inner | epoch 450:     56 / 97 loss=2.049, nll_loss=0.602, ppl=1.52, wps=22095.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43300, lr=0.000151969, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=127783
2022-03-08 00:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:23:13 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.215 | nll_loss 12.616 | ppl 6276.6 | wps 43155.6 | wpb 510.9 | bsz 1 | num_updates 43341 | best_loss 8.233
2022-03-08 00:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 43341 updates
2022-03-08 00:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:23:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:23:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 450 @ 43341 updates, score 13.215) (writing took 2.2302588503807783 seconds)
2022-03-08 00:23:15 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-08 00:23:15 | INFO | train | epoch 450 | loss 2.048 | nll_loss 0.602 | ppl 1.52 | wps 22069.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43341 | lr 0.000151897 | gnorm 0.755 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 127907
2022-03-08 00:23:15 | INFO | fairseq.trainer | begin training epoch 451
2022-03-08 00:23:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:26:04 | INFO | train_inner | epoch 451:     59 / 97 loss=2.048, nll_loss=0.602, ppl=1.52, wps=22317.4, ups=0.34, wpb=65495, bsz=127.9, num_updates=43400, lr=0.000151794, gnorm=0.756, loss_scale=32, train_wall=263, gb_free=8.1, wall=128076
2022-03-08 00:26:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:27:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:58 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.25 | nll_loss 12.655 | ppl 6448.49 | wps 43395.4 | wpb 510.9 | bsz 1 | num_updates 43437 | best_loss 8.233
2022-03-08 00:27:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 43437 updates
2022-03-08 00:27:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 451 @ 43437 updates, score 13.25) (writing took 2.299273382872343 seconds)
2022-03-08 00:28:00 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-08 00:28:00 | INFO | train | epoch 451 | loss 2.047 | nll_loss 0.601 | ppl 1.52 | wps 22074.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43437 | lr 0.00015173 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128192
2022-03-08 00:28:00 | INFO | fairseq.trainer | begin training epoch 452
2022-03-08 00:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:31:00 | INFO | train_inner | epoch 452:     63 / 97 loss=2.048, nll_loss=0.601, ppl=1.52, wps=22109.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43500, lr=0.00015162, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=128372
2022-03-08 00:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:32:43 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.23 | nll_loss 12.634 | ppl 6354.6 | wps 43162.6 | wpb 510.9 | bsz 1 | num_updates 43534 | best_loss 8.233
2022-03-08 00:32:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 43534 updates
2022-03-08 00:32:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:32:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:32:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 452 @ 43534 updates, score 13.23) (writing took 2.204173728823662 seconds)
2022-03-08 00:32:45 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-08 00:32:45 | INFO | train | epoch 452 | loss 2.047 | nll_loss 0.601 | ppl 1.52 | wps 22310.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43534 | lr 0.00015156 | gnorm 0.758 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128477
2022-03-08 00:32:45 | INFO | fairseq.trainer | begin training epoch 453
2022-03-08 00:32:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:35:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:35:57 | INFO | train_inner | epoch 453:     67 / 97 loss=2.046, nll_loss=0.6, ppl=1.52, wps=22115.4, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43600, lr=0.000151446, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=128668
2022-03-08 00:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:27 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.195 | nll_loss 12.594 | ppl 6183.45 | wps 43496 | wpb 510.9 | bsz 1 | num_updates 43630 | best_loss 8.233
2022-03-08 00:37:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 43630 updates
2022-03-08 00:37:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:37:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 453 @ 43630 updates, score 13.195) (writing took 2.313619060907513 seconds)
2022-03-08 00:37:30 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-08 00:37:30 | INFO | train | epoch 453 | loss 2.046 | nll_loss 0.6 | ppl 1.52 | wps 22077.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43630 | lr 0.000151394 | gnorm 0.748 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 128761
2022-03-08 00:37:30 | INFO | fairseq.trainer | begin training epoch 454
2022-03-08 00:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:40:50 | INFO | train_inner | epoch 454:     70 / 97 loss=2.047, nll_loss=0.601, ppl=1.52, wps=22320.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=43700, lr=0.000151272, gnorm=0.757, loss_scale=16, train_wall=263, gb_free=8.1, wall=128962
2022-03-08 00:41:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:42:12 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.157 | nll_loss 12.554 | ppl 6011.62 | wps 43404.3 | wpb 510.9 | bsz 1 | num_updates 43726 | best_loss 8.233
2022-03-08 00:42:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 43726 updates
2022-03-08 00:42:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:42:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:42:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 454 @ 43726 updates, score 13.157) (writing took 2.283358542714268 seconds)
2022-03-08 00:42:14 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-08 00:42:14 | INFO | train | epoch 454 | loss 2.045 | nll_loss 0.599 | ppl 1.51 | wps 22072.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43726 | lr 0.000151227 | gnorm 0.759 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129046
2022-03-08 00:42:14 | INFO | fairseq.trainer | begin training epoch 455
2022-03-08 00:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:45:46 | INFO | train_inner | epoch 455:     74 / 97 loss=2.045, nll_loss=0.599, ppl=1.51, wps=22114.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=43800, lr=0.000151099, gnorm=0.754, loss_scale=16, train_wall=266, gb_free=8.1, wall=129258
2022-03-08 00:46:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:57 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.224 | nll_loss 12.627 | ppl 6325.42 | wps 43385.7 | wpb 510.9 | bsz 1 | num_updates 43823 | best_loss 8.233
2022-03-08 00:46:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 43823 updates
2022-03-08 00:46:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:46:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 455 @ 43823 updates, score 13.224) (writing took 2.30728260288015 seconds)
2022-03-08 00:46:59 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-08 00:46:59 | INFO | train | epoch 455 | loss 2.045 | nll_loss 0.599 | ppl 1.51 | wps 22313.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 43823 | lr 0.00015106 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129331
2022-03-08 00:46:59 | INFO | fairseq.trainer | begin training epoch 456
2022-03-08 00:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:48:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:50:42 | INFO | train_inner | epoch 456:     78 / 97 loss=2.046, nll_loss=0.6, ppl=1.52, wps=22108.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=43900, lr=0.000150927, gnorm=0.75, loss_scale=16, train_wall=266, gb_free=8.1, wall=129554
2022-03-08 00:51:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:51:42 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.193 | nll_loss 12.593 | ppl 6177.22 | wps 43615.2 | wpb 510.9 | bsz 1 | num_updates 43919 | best_loss 8.233
2022-03-08 00:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 43919 updates
2022-03-08 00:51:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:51:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 456 @ 43919 updates, score 13.193) (writing took 2.3714616834186018 seconds)
2022-03-08 00:51:44 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-08 00:51:44 | INFO | train | epoch 456 | loss 2.044 | nll_loss 0.598 | ppl 1.51 | wps 22070.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 43919 | lr 0.000150895 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129616
2022-03-08 00:51:44 | INFO | fairseq.trainer | begin training epoch 457
2022-03-08 00:51:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:55:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 00:55:38 | INFO | train_inner | epoch 457:     82 / 97 loss=2.044, nll_loss=0.598, ppl=1.51, wps=22120.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=44000, lr=0.000150756, gnorm=0.754, loss_scale=16, train_wall=265, gb_free=8.1, wall=129850
2022-03-08 00:56:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:26 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.231 | nll_loss 12.632 | ppl 6348.27 | wps 43283.5 | wpb 510.9 | bsz 1 | num_updates 44015 | best_loss 8.233
2022-03-08 00:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 44015 updates
2022-03-08 00:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:56:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 00:56:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 457 @ 44015 updates, score 13.231) (writing took 2.2808160721324384 seconds)
2022-03-08 00:56:29 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-08 00:56:29 | INFO | train | epoch 457 | loss 2.044 | nll_loss 0.598 | ppl 1.51 | wps 22096.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44015 | lr 0.00015073 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 129900
2022-03-08 00:56:29 | INFO | fairseq.trainer | begin training epoch 458
2022-03-08 00:56:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:00:32 | INFO | train_inner | epoch 458:     85 / 97 loss=2.043, nll_loss=0.597, ppl=1.51, wps=22340.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44100, lr=0.000150585, gnorm=0.748, loss_scale=16, train_wall=263, gb_free=8.1, wall=130143
2022-03-08 01:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:01:11 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.161 | nll_loss 12.559 | ppl 6033.05 | wps 43330.5 | wpb 510.9 | bsz 1 | num_updates 44112 | best_loss 8.233
2022-03-08 01:01:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 44112 updates
2022-03-08 01:01:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:01:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 458 @ 44112 updates, score 13.161) (writing took 2.2905422202311456 seconds)
2022-03-08 01:01:13 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-08 01:01:13 | INFO | train | epoch 458 | loss 2.043 | nll_loss 0.597 | ppl 1.51 | wps 22322.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44112 | lr 0.000150564 | gnorm 0.745 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 130185
2022-03-08 01:01:13 | INFO | fairseq.trainer | begin training epoch 459
2022-03-08 01:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:05:28 | INFO | train_inner | epoch 459:     89 / 97 loss=2.042, nll_loss=0.596, ppl=1.51, wps=22118.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44200, lr=0.000150414, gnorm=0.745, loss_scale=16, train_wall=266, gb_free=8.1, wall=130440
2022-03-08 01:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:05:55 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.187 | nll_loss 12.584 | ppl 6141.79 | wps 43342.8 | wpb 510.9 | bsz 1 | num_updates 44208 | best_loss 8.233
2022-03-08 01:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 44208 updates
2022-03-08 01:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 459 @ 44208 updates, score 13.187) (writing took 2.259578735101968 seconds)
2022-03-08 01:05:58 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-08 01:05:58 | INFO | train | epoch 459 | loss 2.042 | nll_loss 0.596 | ppl 1.51 | wps 22091.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44208 | lr 0.000150401 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 130470
2022-03-08 01:05:58 | INFO | fairseq.trainer | begin training epoch 460
2022-03-08 01:05:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:10:24 | INFO | train_inner | epoch 460:     93 / 97 loss=2.043, nll_loss=0.597, ppl=1.51, wps=22124.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44300, lr=0.000150244, gnorm=0.755, loss_scale=16, train_wall=265, gb_free=8.1, wall=130736
2022-03-08 01:10:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:10:40 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.243 | nll_loss 12.641 | ppl 6387.51 | wps 43012.1 | wpb 510.9 | bsz 1 | num_updates 44304 | best_loss 8.233
2022-03-08 01:10:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 44304 updates
2022-03-08 01:10:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 460 @ 44304 updates, score 13.243) (writing took 2.3216790850274265 seconds)
2022-03-08 01:10:42 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-08 01:10:42 | INFO | train | epoch 460 | loss 2.042 | nll_loss 0.596 | ppl 1.51 | wps 22084.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44304 | lr 0.000150238 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 130754
2022-03-08 01:10:42 | INFO | fairseq.trainer | begin training epoch 461
2022-03-08 01:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:14:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:15:20 | INFO | train_inner | epoch 461:     97 / 97 loss=2.041, nll_loss=0.595, ppl=1.51, wps=22115.7, ups=0.34, wpb=65451.9, bsz=127.8, num_updates=44400, lr=0.000150075, gnorm=0.752, loss_scale=16, train_wall=265, gb_free=8.1, wall=131032
2022-03-08 01:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:25 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.198 | nll_loss 12.601 | ppl 6211.92 | wps 43117 | wpb 510.9 | bsz 1 | num_updates 44400 | best_loss 8.233
2022-03-08 01:15:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 44400 updates
2022-03-08 01:15:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 461 @ 44400 updates, score 13.198) (writing took 2.307862212881446 seconds)
2022-03-08 01:15:27 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-08 01:15:27 | INFO | train | epoch 461 | loss 2.04 | nll_loss 0.595 | ppl 1.51 | wps 22086.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44400 | lr 0.000150075 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131039
2022-03-08 01:15:27 | INFO | fairseq.trainer | begin training epoch 462
2022-03-08 01:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:20:10 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.228 | nll_loss 12.628 | ppl 6330.16 | wps 43091.3 | wpb 510.9 | bsz 1 | num_updates 44497 | best_loss 8.233
2022-03-08 01:20:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 44497 updates
2022-03-08 01:20:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:20:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:20:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 462 @ 44497 updates, score 13.228) (writing took 2.313732596579939 seconds)
2022-03-08 01:20:12 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-08 01:20:12 | INFO | train | epoch 462 | loss 2.041 | nll_loss 0.596 | ppl 1.51 | wps 22308.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44497 | lr 0.000149911 | gnorm 0.745 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131324
2022-03-08 01:20:12 | INFO | fairseq.trainer | begin training epoch 463
2022-03-08 01:20:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:20:20 | INFO | train_inner | epoch 463:      3 / 97 loss=2.041, nll_loss=0.595, ppl=1.51, wps=21770.2, ups=0.33, wpb=65492.9, bsz=127.9, num_updates=44500, lr=0.000149906, gnorm=0.744, loss_scale=16, train_wall=263, gb_free=8.1, wall=131332
2022-03-08 01:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:24:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:24:54 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.209 | nll_loss 12.608 | ppl 6244.31 | wps 43343.9 | wpb 510.9 | bsz 1 | num_updates 44593 | best_loss 8.233
2022-03-08 01:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 44593 updates
2022-03-08 01:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:24:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 463 @ 44593 updates, score 13.209) (writing took 2.3427659231238067 seconds)
2022-03-08 01:24:56 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-08 01:24:56 | INFO | train | epoch 463 | loss 2.041 | nll_loss 0.595 | ppl 1.51 | wps 22087.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44593 | lr 0.00014975 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131608
2022-03-08 01:24:56 | INFO | fairseq.trainer | begin training epoch 464
2022-03-08 01:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:25:17 | INFO | train_inner | epoch 464:      7 / 97 loss=2.04, nll_loss=0.594, ppl=1.51, wps=22122.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44600, lr=0.000149738, gnorm=0.751, loss_scale=16, train_wall=266, gb_free=8.1, wall=131628
2022-03-08 01:28:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:29:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:29:39 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.192 | nll_loss 12.588 | ppl 6158.33 | wps 43142.2 | wpb 510.9 | bsz 1 | num_updates 44689 | best_loss 8.233
2022-03-08 01:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 44689 updates
2022-03-08 01:29:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 464 @ 44689 updates, score 13.192) (writing took 2.3210368789732456 seconds)
2022-03-08 01:29:41 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-08 01:29:41 | INFO | train | epoch 464 | loss 2.04 | nll_loss 0.594 | ppl 1.51 | wps 22106.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44689 | lr 0.000149589 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 131893
2022-03-08 01:29:41 | INFO | fairseq.trainer | begin training epoch 465
2022-03-08 01:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:30:12 | INFO | train_inner | epoch 465:     11 / 97 loss=2.039, nll_loss=0.593, ppl=1.51, wps=22134.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44700, lr=0.000149571, gnorm=0.748, loss_scale=16, train_wall=265, gb_free=8.1, wall=131924
2022-03-08 01:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:23 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.14 | nll_loss 12.537 | ppl 5942.66 | wps 43142.2 | wpb 510.9 | bsz 1 | num_updates 44786 | best_loss 8.233
2022-03-08 01:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 44786 updates
2022-03-08 01:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 465 @ 44786 updates, score 13.14) (writing took 2.324451732914895 seconds)
2022-03-08 01:34:26 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-08 01:34:26 | INFO | train | epoch 465 | loss 2.039 | nll_loss 0.593 | ppl 1.51 | wps 22318.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 44786 | lr 0.000149427 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132177
2022-03-08 01:34:26 | INFO | fairseq.trainer | begin training epoch 466
2022-03-08 01:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:35:06 | INFO | train_inner | epoch 466:     14 / 97 loss=2.038, nll_loss=0.593, ppl=1.51, wps=22335.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=44800, lr=0.000149404, gnorm=0.743, loss_scale=32, train_wall=263, gb_free=8.1, wall=132218
2022-03-08 01:35:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:39:08 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.232 | nll_loss 12.633 | ppl 6351.54 | wps 43466.1 | wpb 510.9 | bsz 1 | num_updates 44882 | best_loss 8.233
2022-03-08 01:39:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 44882 updates
2022-03-08 01:39:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 466 @ 44882 updates, score 13.232) (writing took 2.2797381510026753 seconds)
2022-03-08 01:39:10 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-08 01:39:10 | INFO | train | epoch 466 | loss 2.037 | nll_loss 0.592 | ppl 1.51 | wps 22087.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44882 | lr 0.000149267 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132462
2022-03-08 01:39:10 | INFO | fairseq.trainer | begin training epoch 467
2022-03-08 01:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:02 | INFO | train_inner | epoch 467:     18 / 97 loss=2.038, nll_loss=0.592, ppl=1.51, wps=22119.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=44900, lr=0.000149237, gnorm=0.745, loss_scale=16, train_wall=266, gb_free=8.1, wall=132514
2022-03-08 01:41:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:43:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:43:53 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.229 | nll_loss 12.632 | ppl 6347.56 | wps 43063.9 | wpb 510.9 | bsz 1 | num_updates 44978 | best_loss 8.233
2022-03-08 01:43:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 44978 updates
2022-03-08 01:43:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 467 @ 44978 updates, score 13.229) (writing took 2.2891347729600966 seconds)
2022-03-08 01:43:55 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-08 01:43:55 | INFO | train | epoch 467 | loss 2.038 | nll_loss 0.592 | ppl 1.51 | wps 22079.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 44978 | lr 0.000149108 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 132747
2022-03-08 01:43:55 | INFO | fairseq.trainer | begin training epoch 468
2022-03-08 01:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:44:58 | INFO | train_inner | epoch 468:     22 / 97 loss=2.037, nll_loss=0.591, ppl=1.51, wps=22113.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45000, lr=0.000149071, gnorm=0.749, loss_scale=16, train_wall=266, gb_free=8.1, wall=132810
2022-03-08 01:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:48:37 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.232 | nll_loss 12.635 | ppl 6358.69 | wps 43298.8 | wpb 510.9 | bsz 1 | num_updates 45074 | best_loss 8.233
2022-03-08 01:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 45074 updates
2022-03-08 01:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 468 @ 45074 updates, score 13.232) (writing took 2.380353649146855 seconds)
2022-03-08 01:48:39 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-08 01:48:39 | INFO | train | epoch 468 | loss 2.037 | nll_loss 0.591 | ppl 1.51 | wps 22096.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45074 | lr 0.000148949 | gnorm 0.743 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133031
2022-03-08 01:48:39 | INFO | fairseq.trainer | begin training epoch 469
2022-03-08 01:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:49:54 | INFO | train_inner | epoch 469:     26 / 97 loss=2.037, nll_loss=0.591, ppl=1.51, wps=22126.3, ups=0.34, wpb=65495, bsz=127.9, num_updates=45100, lr=0.000148906, gnorm=0.744, loss_scale=16, train_wall=265, gb_free=8.1, wall=133106
2022-03-08 01:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:22 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.219 | nll_loss 12.62 | ppl 6296.78 | wps 43272.4 | wpb 510.9 | bsz 1 | num_updates 45171 | best_loss 8.233
2022-03-08 01:53:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 45171 updates
2022-03-08 01:53:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:53:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:53:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 469 @ 45171 updates, score 13.219) (writing took 2.362433999311179 seconds)
2022-03-08 01:53:24 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-08 01:53:24 | INFO | train | epoch 469 | loss 2.036 | nll_loss 0.591 | ppl 1.51 | wps 22315.2 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45171 | lr 0.000148789 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133316
2022-03-08 01:53:24 | INFO | fairseq.trainer | begin training epoch 470
2022-03-08 01:53:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:54:47 | INFO | train_inner | epoch 470:     29 / 97 loss=2.036, nll_loss=0.591, ppl=1.51, wps=22327.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=45200, lr=0.000148741, gnorm=0.743, loss_scale=32, train_wall=263, gb_free=8.1, wall=133399
2022-03-08 01:57:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 01:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:58:07 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.184 | nll_loss 12.584 | ppl 6139.4 | wps 43040.2 | wpb 510.9 | bsz 1 | num_updates 45267 | best_loss 8.233
2022-03-08 01:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 45267 updates
2022-03-08 01:58:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 01:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 470 @ 45267 updates, score 13.184) (writing took 2.3246858892962337 seconds)
2022-03-08 01:58:09 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-08 01:58:09 | INFO | train | epoch 470 | loss 2.035 | nll_loss 0.59 | ppl 1.51 | wps 22077.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45267 | lr 0.000148631 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133601
2022-03-08 01:58:09 | INFO | fairseq.trainer | begin training epoch 471
2022-03-08 01:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:43 | INFO | train_inner | epoch 471:     33 / 97 loss=2.035, nll_loss=0.589, ppl=1.5, wps=22116.2, ups=0.34, wpb=65495, bsz=127.9, num_updates=45300, lr=0.000148577, gnorm=0.74, loss_scale=16, train_wall=266, gb_free=8.1, wall=133695
2022-03-08 02:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:02:51 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.26 | nll_loss 12.666 | ppl 6499.18 | wps 43008.2 | wpb 510.9 | bsz 1 | num_updates 45364 | best_loss 8.233
2022-03-08 02:02:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 45364 updates
2022-03-08 02:02:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:02:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:02:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 471 @ 45364 updates, score 13.26) (writing took 2.2763024996966124 seconds)
2022-03-08 02:02:54 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-08 02:02:54 | INFO | train | epoch 471 | loss 2.035 | nll_loss 0.59 | ppl 1.51 | wps 22309.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45364 | lr 0.000148472 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 133886
2022-03-08 02:02:54 | INFO | fairseq.trainer | begin training epoch 472
2022-03-08 02:02:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:04:40 | INFO | train_inner | epoch 472:     37 / 97 loss=2.034, nll_loss=0.589, ppl=1.5, wps=22106.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45400, lr=0.000148413, gnorm=0.747, loss_scale=16, train_wall=266, gb_free=8.1, wall=133992
2022-03-08 02:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:07:36 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.178 | nll_loss 12.579 | ppl 6119.42 | wps 43048.3 | wpb 510.9 | bsz 1 | num_updates 45460 | best_loss 8.233
2022-03-08 02:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 45460 updates
2022-03-08 02:07:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:07:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 472 @ 45460 updates, score 13.178) (writing took 2.3207368631847203 seconds)
2022-03-08 02:07:39 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-08 02:07:39 | INFO | train | epoch 472 | loss 2.035 | nll_loss 0.589 | ppl 1.5 | wps 22072.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45460 | lr 0.000148315 | gnorm 0.751 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134170
2022-03-08 02:07:39 | INFO | fairseq.trainer | begin training epoch 473
2022-03-08 02:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:09:33 | INFO | train_inner | epoch 473:     40 / 97 loss=2.035, nll_loss=0.59, ppl=1.51, wps=22323.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45500, lr=0.00014825, gnorm=0.753, loss_scale=16, train_wall=263, gb_free=8.1, wall=134285
2022-03-08 02:11:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:21 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.16 | nll_loss 12.562 | ppl 6045.54 | wps 43156.9 | wpb 510.9 | bsz 1 | num_updates 45556 | best_loss 8.233
2022-03-08 02:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 45556 updates
2022-03-08 02:12:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 473 @ 45556 updates, score 13.16) (writing took 2.369219890795648 seconds)
2022-03-08 02:12:23 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-08 02:12:23 | INFO | train | epoch 473 | loss 2.034 | nll_loss 0.588 | ppl 1.5 | wps 22078.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45556 | lr 0.000148159 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134455
2022-03-08 02:12:23 | INFO | fairseq.trainer | begin training epoch 474
2022-03-08 02:12:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:14:29 | INFO | train_inner | epoch 474:     44 / 97 loss=2.034, nll_loss=0.589, ppl=1.5, wps=22112.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45600, lr=0.000148087, gnorm=0.747, loss_scale=16, train_wall=266, gb_free=8.1, wall=134581
2022-03-08 02:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:17:06 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.225 | nll_loss 12.627 | ppl 6323.57 | wps 43378.6 | wpb 510.9 | bsz 1 | num_updates 45653 | best_loss 8.233
2022-03-08 02:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 45653 updates
2022-03-08 02:17:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 474 @ 45653 updates, score 13.225) (writing took 2.3167824391275644 seconds)
2022-03-08 02:17:08 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-08 02:17:08 | INFO | train | epoch 474 | loss 2.033 | nll_loss 0.588 | ppl 1.5 | wps 22313.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45653 | lr 0.000148001 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 134740
2022-03-08 02:17:08 | INFO | fairseq.trainer | begin training epoch 475
2022-03-08 02:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:18:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:19:25 | INFO | train_inner | epoch 475:     48 / 97 loss=2.033, nll_loss=0.588, ppl=1.5, wps=22119.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45700, lr=0.000147925, gnorm=0.747, loss_scale=16, train_wall=266, gb_free=8.1, wall=134877
2022-03-08 02:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:21:50 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.18 | nll_loss 12.578 | ppl 6115.21 | wps 42932.4 | wpb 510.9 | bsz 1 | num_updates 45749 | best_loss 8.233
2022-03-08 02:21:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 45749 updates
2022-03-08 02:21:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 475 @ 45749 updates, score 13.18) (writing took 2.280155284330249 seconds)
2022-03-08 02:21:53 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-08 02:21:53 | INFO | train | epoch 475 | loss 2.033 | nll_loss 0.589 | ppl 1.5 | wps 22096.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45749 | lr 0.000147846 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135024
2022-03-08 02:21:53 | INFO | fairseq.trainer | begin training epoch 476
2022-03-08 02:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:24:18 | INFO | train_inner | epoch 476:     51 / 97 loss=2.033, nll_loss=0.588, ppl=1.5, wps=22338.4, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45800, lr=0.000147764, gnorm=0.741, loss_scale=16, train_wall=263, gb_free=8.1, wall=135170
2022-03-08 02:25:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:26:35 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.222 | nll_loss 12.625 | ppl 6315.99 | wps 43337.7 | wpb 510.9 | bsz 1 | num_updates 45845 | best_loss 8.233
2022-03-08 02:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 45845 updates
2022-03-08 02:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 476 @ 45845 updates, score 13.222) (writing took 2.3654584013856947 seconds)
2022-03-08 02:26:37 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-08 02:26:37 | INFO | train | epoch 476 | loss 2.032 | nll_loss 0.587 | ppl 1.5 | wps 22083.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 45845 | lr 0.000147691 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135309
2022-03-08 02:26:37 | INFO | fairseq.trainer | begin training epoch 477
2022-03-08 02:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:15 | INFO | train_inner | epoch 477:     55 / 97 loss=2.031, nll_loss=0.586, ppl=1.5, wps=22116.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=45900, lr=0.000147602, gnorm=0.751, loss_scale=16, train_wall=266, gb_free=8.1, wall=135467
2022-03-08 02:31:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:31:20 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.21 | nll_loss 12.61 | ppl 6252.05 | wps 43143.5 | wpb 510.9 | bsz 1 | num_updates 45942 | best_loss 8.233
2022-03-08 02:31:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 45942 updates
2022-03-08 02:31:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 477 @ 45942 updates, score 13.21) (writing took 2.2980799707584083 seconds)
2022-03-08 02:31:22 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-08 02:31:22 | INFO | train | epoch 477 | loss 2.032 | nll_loss 0.587 | ppl 1.5 | wps 22314 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 45942 | lr 0.000147535 | gnorm 0.75 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135594
2022-03-08 02:31:22 | INFO | fairseq.trainer | begin training epoch 478
2022-03-08 02:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:34:11 | INFO | train_inner | epoch 478:     59 / 97 loss=2.032, nll_loss=0.587, ppl=1.5, wps=22116.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46000, lr=0.000147442, gnorm=0.737, loss_scale=16, train_wall=265, gb_free=8.1, wall=135763
2022-03-08 02:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:36:04 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.215 | nll_loss 12.614 | ppl 6269.46 | wps 43309.1 | wpb 510.9 | bsz 1 | num_updates 46038 | best_loss 8.233
2022-03-08 02:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 46038 updates
2022-03-08 02:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 478 @ 46038 updates, score 13.215) (writing took 2.3692636098712683 seconds)
2022-03-08 02:36:07 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-08 02:36:07 | INFO | train | epoch 478 | loss 2.03 | nll_loss 0.586 | ppl 1.5 | wps 22080 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46038 | lr 0.000147381 | gnorm 0.74 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 135879
2022-03-08 02:36:07 | INFO | fairseq.trainer | begin training epoch 479
2022-03-08 02:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:38:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:39:07 | INFO | train_inner | epoch 479:     63 / 97 loss=2.03, nll_loss=0.585, ppl=1.5, wps=22117.9, ups=0.34, wpb=65495, bsz=127.9, num_updates=46100, lr=0.000147282, gnorm=0.756, loss_scale=16, train_wall=265, gb_free=8.1, wall=136059
2022-03-08 02:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:40:49 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.182 | nll_loss 12.583 | ppl 6137.62 | wps 43354.5 | wpb 510.9 | bsz 1 | num_updates 46134 | best_loss 8.233
2022-03-08 02:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 46134 updates
2022-03-08 02:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 479 @ 46134 updates, score 13.182) (writing took 2.3224344039335847 seconds)
2022-03-08 02:40:51 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-08 02:40:51 | INFO | train | epoch 479 | loss 2.03 | nll_loss 0.585 | ppl 1.5 | wps 22089.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46134 | lr 0.000147228 | gnorm 0.754 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136163
2022-03-08 02:40:51 | INFO | fairseq.trainer | begin training epoch 480
2022-03-08 02:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:44:00 | INFO | train_inner | epoch 480:     66 / 97 loss=2.03, nll_loss=0.586, ppl=1.5, wps=22331.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46200, lr=0.000147122, gnorm=0.749, loss_scale=16, train_wall=263, gb_free=8.1, wall=136352
2022-03-08 02:44:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:45:34 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.249 | nll_loss 12.653 | ppl 6440.64 | wps 43260.7 | wpb 510.9 | bsz 1 | num_updates 46230 | best_loss 8.233
2022-03-08 02:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 46230 updates
2022-03-08 02:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:45:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 480 @ 46230 updates, score 13.249) (writing took 2.2773486878722906 seconds)
2022-03-08 02:45:36 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-08 02:45:36 | INFO | train | epoch 480 | loss 2.03 | nll_loss 0.585 | ppl 1.5 | wps 22086.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46230 | lr 0.000147075 | gnorm 0.748 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136448
2022-03-08 02:45:36 | INFO | fairseq.trainer | begin training epoch 481
2022-03-08 02:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:48:56 | INFO | train_inner | epoch 481:     70 / 97 loss=2.03, nll_loss=0.585, ppl=1.5, wps=22128.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46300, lr=0.000146964, gnorm=0.742, loss_scale=16, train_wall=265, gb_free=8.1, wall=136648
2022-03-08 02:50:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:50:18 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.17 | nll_loss 12.571 | ppl 6082.92 | wps 43093.1 | wpb 510.9 | bsz 1 | num_updates 46327 | best_loss 8.233
2022-03-08 02:50:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 46327 updates
2022-03-08 02:50:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:50:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:50:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 481 @ 46327 updates, score 13.17) (writing took 2.3023136109113693 seconds)
2022-03-08 02:50:20 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-08 02:50:20 | INFO | train | epoch 481 | loss 2.029 | nll_loss 0.585 | ppl 1.5 | wps 22333.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46327 | lr 0.000146921 | gnorm 0.74 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 136732
2022-03-08 02:50:20 | INFO | fairseq.trainer | begin training epoch 482
2022-03-08 02:50:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:52:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:53:52 | INFO | train_inner | epoch 482:     74 / 97 loss=2.03, nll_loss=0.585, ppl=1.5, wps=22134.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46400, lr=0.000146805, gnorm=0.744, loss_scale=16, train_wall=265, gb_free=8.1, wall=136944
2022-03-08 02:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:55:03 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.218 | nll_loss 12.621 | ppl 6300.21 | wps 43337.6 | wpb 510.9 | bsz 1 | num_updates 46423 | best_loss 8.233
2022-03-08 02:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 46423 updates
2022-03-08 02:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 482 @ 46423 updates, score 13.218) (writing took 2.297398960683495 seconds)
2022-03-08 02:55:05 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-08 02:55:05 | INFO | train | epoch 482 | loss 2.029 | nll_loss 0.584 | ppl 1.5 | wps 22097 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46423 | lr 0.000146769 | gnorm 0.745 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137017
2022-03-08 02:55:05 | INFO | fairseq.trainer | begin training epoch 483
2022-03-08 02:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:58:45 | INFO | train_inner | epoch 483:     77 / 97 loss=2.029, nll_loss=0.584, ppl=1.5, wps=22336.1, ups=0.34, wpb=65495, bsz=127.9, num_updates=46500, lr=0.000146647, gnorm=0.739, loss_scale=32, train_wall=263, gb_free=8.1, wall=137237
2022-03-08 02:59:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 02:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:59:47 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.231 | nll_loss 12.635 | ppl 6362.94 | wps 43396.3 | wpb 510.9 | bsz 1 | num_updates 46519 | best_loss 8.233
2022-03-08 02:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 46519 updates
2022-03-08 02:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:59:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 02:59:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 483 @ 46519 updates, score 13.231) (writing took 2.3581309290602803 seconds)
2022-03-08 02:59:50 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-08 02:59:50 | INFO | train | epoch 483 | loss 2.028 | nll_loss 0.584 | ppl 1.5 | wps 22081.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46519 | lr 0.000146617 | gnorm 0.74 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137302
2022-03-08 02:59:50 | INFO | fairseq.trainer | begin training epoch 484
2022-03-08 02:59:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:03:41 | INFO | train_inner | epoch 484:     81 / 97 loss=2.028, nll_loss=0.584, ppl=1.5, wps=22118.7, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=46600, lr=0.00014649, gnorm=0.743, loss_scale=16, train_wall=265, gb_free=8.1, wall=137533
2022-03-08 03:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:04:32 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.155 | nll_loss 12.557 | ppl 6024.68 | wps 43274.1 | wpb 510.9 | bsz 1 | num_updates 46616 | best_loss 8.233
2022-03-08 03:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 46616 updates
2022-03-08 03:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:04:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:04:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 484 @ 46616 updates, score 13.155) (writing took 2.301566680893302 seconds)
2022-03-08 03:04:34 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-08 03:04:34 | INFO | train | epoch 484 | loss 2.028 | nll_loss 0.583 | ppl 1.5 | wps 22319.7 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46616 | lr 0.000146465 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137586
2022-03-08 03:04:34 | INFO | fairseq.trainer | begin training epoch 485
2022-03-08 03:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:05:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:08:37 | INFO | train_inner | epoch 485:     85 / 97 loss=2.028, nll_loss=0.583, ppl=1.5, wps=22112, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46700, lr=0.000146333, gnorm=0.742, loss_scale=16, train_wall=265, gb_free=8.1, wall=137829
2022-03-08 03:09:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:09:17 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.284 | nll_loss 12.692 | ppl 6615.32 | wps 43491.8 | wpb 510.9 | bsz 1 | num_updates 46712 | best_loss 8.233
2022-03-08 03:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 46712 updates
2022-03-08 03:09:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:09:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:09:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 485 @ 46712 updates, score 13.284) (writing took 2.2881212229840457 seconds)
2022-03-08 03:09:19 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-08 03:09:19 | INFO | train | epoch 485 | loss 2.027 | nll_loss 0.582 | ppl 1.5 | wps 22081.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46712 | lr 0.000146314 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 137871
2022-03-08 03:09:19 | INFO | fairseq.trainer | begin training epoch 486
2022-03-08 03:09:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:12:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:13:33 | INFO | train_inner | epoch 486:     89 / 97 loss=2.027, nll_loss=0.582, ppl=1.5, wps=22127.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46800, lr=0.000146176, gnorm=0.743, loss_scale=16, train_wall=265, gb_free=8.1, wall=138125
2022-03-08 03:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:14:01 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.132 | nll_loss 12.53 | ppl 5913.22 | wps 43369.1 | wpb 510.9 | bsz 1 | num_updates 46808 | best_loss 8.233
2022-03-08 03:14:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 46808 updates
2022-03-08 03:14:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:14:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:14:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 486 @ 46808 updates, score 13.132) (writing took 2.2607769249007106 seconds)
2022-03-08 03:14:04 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-08 03:14:04 | INFO | train | epoch 486 | loss 2.026 | nll_loss 0.582 | ppl 1.5 | wps 22096.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 46808 | lr 0.000146164 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138155
2022-03-08 03:14:04 | INFO | fairseq.trainer | begin training epoch 487
2022-03-08 03:14:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:18:27 | INFO | train_inner | epoch 487:     92 / 97 loss=2.027, nll_loss=0.582, ppl=1.5, wps=22330.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=46900, lr=0.00014602, gnorm=0.745, loss_scale=32, train_wall=263, gb_free=8.1, wall=138419
2022-03-08 03:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:18:46 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.168 | nll_loss 12.567 | ppl 6069.24 | wps 43262.4 | wpb 510.9 | bsz 1 | num_updates 46905 | best_loss 8.233
2022-03-08 03:18:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 46905 updates
2022-03-08 03:18:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 487 @ 46905 updates, score 13.168) (writing took 2.2855960079468787 seconds)
2022-03-08 03:18:48 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-08 03:18:48 | INFO | train | epoch 487 | loss 2.026 | nll_loss 0.581 | ppl 1.5 | wps 22309.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 46905 | lr 0.000146013 | gnorm 0.745 | loss_scale 32 | train_wall 255 | gb_free 8.1 | wall 138440
2022-03-08 03:18:48 | INFO | fairseq.trainer | begin training epoch 488
2022-03-08 03:18:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:19:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:23:23 | INFO | train_inner | epoch 488:     96 / 97 loss=2.025, nll_loss=0.581, ppl=1.5, wps=22129.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47000, lr=0.000145865, gnorm=0.743, loss_scale=16, train_wall=265, gb_free=8.1, wall=138715
2022-03-08 03:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:23:30 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.15 | nll_loss 12.555 | ppl 6016.71 | wps 43251.1 | wpb 510.9 | bsz 1 | num_updates 47001 | best_loss 8.233
2022-03-08 03:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 47001 updates
2022-03-08 03:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:23:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:23:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 488 @ 47001 updates, score 13.15) (writing took 2.3918067263439298 seconds)
2022-03-08 03:23:33 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-08 03:23:33 | INFO | train | epoch 488 | loss 2.025 | nll_loss 0.58 | ppl 1.5 | wps 22092.6 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47001 | lr 0.000145863 | gnorm 0.743 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 138725
2022-03-08 03:23:33 | INFO | fairseq.trainer | begin training epoch 489
2022-03-08 03:23:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:26:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:28:15 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.173 | nll_loss 12.572 | ppl 6090.13 | wps 43207.4 | wpb 510.9 | bsz 1 | num_updates 47097 | best_loss 8.233
2022-03-08 03:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 47097 updates
2022-03-08 03:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 489 @ 47097 updates, score 13.173) (writing took 2.3223885018378496 seconds)
2022-03-08 03:28:18 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-08 03:28:18 | INFO | train | epoch 489 | loss 2.024 | nll_loss 0.58 | ppl 1.49 | wps 22086.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47097 | lr 0.000145715 | gnorm 0.738 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139009
2022-03-08 03:28:18 | INFO | fairseq.trainer | begin training epoch 490
2022-03-08 03:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:28:26 | INFO | train_inner | epoch 490:      3 / 97 loss=2.024, nll_loss=0.58, ppl=1.49, wps=21565.9, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=47100, lr=0.00014571, gnorm=0.738, loss_scale=16, train_wall=265, gb_free=8.1, wall=139018
2022-03-08 03:32:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:32:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:33:00 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.185 | nll_loss 12.587 | ppl 6152.78 | wps 43236.4 | wpb 510.9 | bsz 1 | num_updates 47193 | best_loss 8.233
2022-03-08 03:33:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 47193 updates
2022-03-08 03:33:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 490 @ 47193 updates, score 13.185) (writing took 2.2637689281255007 seconds)
2022-03-08 03:33:02 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-08 03:33:02 | INFO | train | epoch 490 | loss 2.024 | nll_loss 0.579 | ppl 1.49 | wps 22087 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47193 | lr 0.000145566 | gnorm 0.736 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139294
2022-03-08 03:33:02 | INFO | fairseq.trainer | begin training epoch 491
2022-03-08 03:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:33:22 | INFO | train_inner | epoch 491:      7 / 97 loss=2.023, nll_loss=0.578, ppl=1.49, wps=22120.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47200, lr=0.000145556, gnorm=0.737, loss_scale=16, train_wall=266, gb_free=8.1, wall=139314
2022-03-08 03:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:37:44 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.223 | nll_loss 12.625 | ppl 6317.73 | wps 43417.2 | wpb 510.9 | bsz 1 | num_updates 47290 | best_loss 8.233
2022-03-08 03:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 47290 updates
2022-03-08 03:37:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 491 @ 47290 updates, score 13.223) (writing took 2.3023238708265126 seconds)
2022-03-08 03:37:46 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-08 03:37:46 | INFO | train | epoch 491 | loss 2.025 | nll_loss 0.581 | ppl 1.5 | wps 22349.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47290 | lr 0.000145417 | gnorm 0.753 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139578
2022-03-08 03:37:46 | INFO | fairseq.trainer | begin training epoch 492
2022-03-08 03:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:38:15 | INFO | train_inner | epoch 492:     10 / 97 loss=2.024, nll_loss=0.58, ppl=1.49, wps=22373.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47300, lr=0.000145402, gnorm=0.752, loss_scale=16, train_wall=263, gb_free=8.1, wall=139607
2022-03-08 03:41:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:42:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:42:28 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.155 | nll_loss 12.555 | ppl 6017.49 | wps 43315.4 | wpb 510.9 | bsz 1 | num_updates 47386 | best_loss 8.233
2022-03-08 03:42:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 47386 updates
2022-03-08 03:42:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:42:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:42:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 492 @ 47386 updates, score 13.155) (writing took 2.3605060861445963 seconds)
2022-03-08 03:42:30 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-08 03:42:30 | INFO | train | epoch 492 | loss 2.023 | nll_loss 0.579 | ppl 1.49 | wps 22131.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47386 | lr 0.00014527 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 139862
2022-03-08 03:42:31 | INFO | fairseq.trainer | begin training epoch 493
2022-03-08 03:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:43:11 | INFO | train_inner | epoch 493:     14 / 97 loss=2.022, nll_loss=0.578, ppl=1.49, wps=22161.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47400, lr=0.000145248, gnorm=0.741, loss_scale=16, train_wall=265, gb_free=8.1, wall=139902
2022-03-08 03:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:47:12 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.201 | nll_loss 12.607 | ppl 6239.42 | wps 43369.6 | wpb 510.9 | bsz 1 | num_updates 47483 | best_loss 8.233
2022-03-08 03:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 47483 updates
2022-03-08 03:47:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 493 @ 47483 updates, score 13.201) (writing took 2.2990801609121263 seconds)
2022-03-08 03:47:15 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-08 03:47:15 | INFO | train | epoch 493 | loss 2.023 | nll_loss 0.579 | ppl 1.49 | wps 22357.1 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47483 | lr 0.000145121 | gnorm 0.746 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140147
2022-03-08 03:47:15 | INFO | fairseq.trainer | begin training epoch 494
2022-03-08 03:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:48:03 | INFO | train_inner | epoch 494:     17 / 97 loss=2.023, nll_loss=0.578, ppl=1.49, wps=22373.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47500, lr=0.000145095, gnorm=0.744, loss_scale=32, train_wall=263, gb_free=8.1, wall=140195
2022-03-08 03:49:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:51:57 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.198 | nll_loss 12.598 | ppl 6198.48 | wps 43310.9 | wpb 510.9 | bsz 1 | num_updates 47579 | best_loss 8.233
2022-03-08 03:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 47579 updates
2022-03-08 03:51:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 494 @ 47579 updates, score 13.198) (writing took 2.31477103382349 seconds)
2022-03-08 03:51:59 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-08 03:51:59 | INFO | train | epoch 494 | loss 2.021 | nll_loss 0.577 | ppl 1.49 | wps 22121.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47579 | lr 0.000144975 | gnorm 0.744 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140431
2022-03-08 03:51:59 | INFO | fairseq.trainer | begin training epoch 495
2022-03-08 03:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:52:59 | INFO | train_inner | epoch 495:     21 / 97 loss=2.021, nll_loss=0.577, ppl=1.49, wps=22150, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47600, lr=0.000144943, gnorm=0.746, loss_scale=16, train_wall=265, gb_free=8.1, wall=140491
2022-03-08 03:55:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 03:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 03:56:41 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.193 | nll_loss 12.598 | ppl 6200.8 | wps 43446.9 | wpb 510.9 | bsz 1 | num_updates 47675 | best_loss 8.233
2022-03-08 03:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 47675 updates
2022-03-08 03:56:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:56:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 03:56:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 495 @ 47675 updates, score 13.193) (writing took 2.3185366322286427 seconds)
2022-03-08 03:56:43 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-08 03:56:43 | INFO | train | epoch 495 | loss 2.02 | nll_loss 0.576 | ppl 1.49 | wps 22124 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47675 | lr 0.000144829 | gnorm 0.733 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140715
2022-03-08 03:56:43 | INFO | fairseq.trainer | begin training epoch 496
2022-03-08 03:56:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 03:57:54 | INFO | train_inner | epoch 496:     25 / 97 loss=2.02, nll_loss=0.576, ppl=1.49, wps=22162.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47700, lr=0.000144791, gnorm=0.73, loss_scale=16, train_wall=265, gb_free=8.1, wall=140786
2022-03-08 04:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:01:25 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.297 | nll_loss 12.71 | ppl 6701.88 | wps 43432.8 | wpb 510.9 | bsz 1 | num_updates 47772 | best_loss 8.233
2022-03-08 04:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 47772 updates
2022-03-08 04:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 496 @ 47772 updates, score 13.297) (writing took 2.262556849978864 seconds)
2022-03-08 04:01:27 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-08 04:01:27 | INFO | train | epoch 496 | loss 2.021 | nll_loss 0.577 | ppl 1.49 | wps 22365 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 47772 | lr 0.000144682 | gnorm 0.742 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 140999
2022-03-08 04:01:27 | INFO | fairseq.trainer | begin training epoch 497
2022-03-08 04:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:02:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:02:50 | INFO | train_inner | epoch 497:     29 / 97 loss=2.019, nll_loss=0.575, ppl=1.49, wps=22164.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47800, lr=0.000144639, gnorm=0.742, loss_scale=16, train_wall=265, gb_free=8.1, wall=141082
2022-03-08 04:06:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:06:09 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.179 | nll_loss 12.584 | ppl 6139.83 | wps 43239.1 | wpb 510.9 | bsz 1 | num_updates 47868 | best_loss 8.233
2022-03-08 04:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 47868 updates
2022-03-08 04:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:06:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 497 @ 47868 updates, score 13.179) (writing took 2.3126609320752323 seconds)
2022-03-08 04:06:11 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-08 04:06:11 | INFO | train | epoch 497 | loss 2.02 | nll_loss 0.576 | ppl 1.49 | wps 22125.1 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47868 | lr 0.000144536 | gnorm 0.733 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141283
2022-03-08 04:06:11 | INFO | fairseq.trainer | begin training epoch 498
2022-03-08 04:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:07:43 | INFO | train_inner | epoch 498:     32 / 97 loss=2.021, nll_loss=0.577, ppl=1.49, wps=22373.1, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=47900, lr=0.000144488, gnorm=0.733, loss_scale=16, train_wall=263, gb_free=8.1, wall=141375
2022-03-08 04:08:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:10:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:10:53 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.191 | nll_loss 12.598 | ppl 6197.88 | wps 43422.4 | wpb 510.9 | bsz 1 | num_updates 47964 | best_loss 8.233
2022-03-08 04:10:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 47964 updates
2022-03-08 04:10:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 498 @ 47964 updates, score 13.191) (writing took 2.2567479289136827 seconds)
2022-03-08 04:10:55 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-08 04:10:55 | INFO | train | epoch 498 | loss 2.02 | nll_loss 0.576 | ppl 1.49 | wps 22124.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 47964 | lr 0.000144392 | gnorm 0.741 | loss_scale 16 | train_wall 255 | gb_free 8.1 | wall 141567
2022-03-08 04:10:55 | INFO | fairseq.trainer | begin training epoch 499
2022-03-08 04:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:12:38 | INFO | train_inner | epoch 499:     36 / 97 loss=2.019, nll_loss=0.575, ppl=1.49, wps=22163.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48000, lr=0.000144338, gnorm=0.738, loss_scale=16, train_wall=265, gb_free=8.1, wall=141670
2022-03-08 04:15:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:15:37 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.254 | nll_loss 12.661 | ppl 6475.74 | wps 43315.1 | wpb 510.9 | bsz 1 | num_updates 48060 | best_loss 8.233
2022-03-08 04:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 48060 updates
2022-03-08 04:15:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:15:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 499 @ 48060 updates, score 13.254) (writing took 2.2417602189816535 seconds)
2022-03-08 04:15:39 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-08 04:15:39 | INFO | train | epoch 499 | loss 2.019 | nll_loss 0.575 | ppl 1.49 | wps 22153 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48060 | lr 0.000144247 | gnorm 0.74 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 141851
2022-03-08 04:15:39 | INFO | fairseq.trainer | begin training epoch 500
2022-03-08 04:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:17:33 | INFO | train_inner | epoch 500:     40 / 97 loss=2.018, nll_loss=0.574, ppl=1.49, wps=22194.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48100, lr=0.000144187, gnorm=0.741, loss_scale=16, train_wall=265, gb_free=8.1, wall=141965
2022-03-08 04:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:20:21 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.132 | nll_loss 12.53 | ppl 5915.85 | wps 43099.9 | wpb 510.9 | bsz 1 | num_updates 48157 | best_loss 8.233
2022-03-08 04:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 48157 updates
2022-03-08 04:20:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:20:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:20:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 500 @ 48157 updates, score 13.132) (writing took 2.3624161072075367 seconds)
2022-03-08 04:20:23 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-08 04:20:23 | INFO | train | epoch 500 | loss 2.018 | nll_loss 0.573 | ppl 1.49 | wps 22395.5 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48157 | lr 0.000144102 | gnorm 0.734 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142135
2022-03-08 04:20:23 | INFO | fairseq.trainer | begin training epoch 501
2022-03-08 04:20:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:21:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:22:28 | INFO | train_inner | epoch 501:     44 / 97 loss=2.018, nll_loss=0.574, ppl=1.49, wps=22200.3, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48200, lr=0.000144038, gnorm=0.734, loss_scale=16, train_wall=265, gb_free=8.1, wall=142260
2022-03-08 04:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:25:04 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.193 | nll_loss 12.593 | ppl 6178.74 | wps 42983.6 | wpb 510.9 | bsz 1 | num_updates 48253 | best_loss 8.233
2022-03-08 04:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 48253 updates
2022-03-08 04:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:25:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 501 @ 48253 updates, score 13.193) (writing took 2.3123648571781814 seconds)
2022-03-08 04:25:07 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-08 04:25:07 | INFO | train | epoch 501 | loss 2.019 | nll_loss 0.575 | ppl 1.49 | wps 22163.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48253 | lr 0.000143959 | gnorm 0.735 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142418
2022-03-08 04:25:07 | INFO | fairseq.trainer | begin training epoch 502
2022-03-08 04:25:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:27:21 | INFO | train_inner | epoch 502:     47 / 97 loss=2.018, nll_loss=0.574, ppl=1.49, wps=22395.5, ups=0.34, wpb=65495, bsz=127.9, num_updates=48300, lr=0.000143889, gnorm=0.74, loss_scale=16, train_wall=262, gb_free=8.1, wall=142553
2022-03-08 04:27:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:29:48 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.298 | nll_loss 12.705 | ppl 6675.35 | wps 43041.4 | wpb 510.9 | bsz 1 | num_updates 48349 | best_loss 8.233
2022-03-08 04:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 48349 updates
2022-03-08 04:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:29:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:29:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 502 @ 48349 updates, score 13.298) (writing took 2.3749014171771705 seconds)
2022-03-08 04:29:51 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-08 04:29:51 | INFO | train | epoch 502 | loss 2.018 | nll_loss 0.574 | ppl 1.49 | wps 22137.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48349 | lr 0.000143816 | gnorm 0.742 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142702
2022-03-08 04:29:51 | INFO | fairseq.trainer | begin training epoch 503
2022-03-08 04:29:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:32:16 | INFO | train_inner | epoch 503:     51 / 97 loss=2.017, nll_loss=0.574, ppl=1.49, wps=22181.2, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48400, lr=0.00014374, gnorm=0.74, loss_scale=16, train_wall=265, gb_free=8.1, wall=142848
2022-03-08 04:34:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:34:32 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.216 | nll_loss 12.621 | ppl 6299.46 | wps 43335.5 | wpb 510.9 | bsz 1 | num_updates 48445 | best_loss 8.233
2022-03-08 04:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 48445 updates
2022-03-08 04:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 503 @ 48445 updates, score 13.216) (writing took 2.295567509252578 seconds)
2022-03-08 04:34:34 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-08 04:34:34 | INFO | train | epoch 503 | loss 2.017 | nll_loss 0.573 | ppl 1.49 | wps 22166.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48445 | lr 0.000143673 | gnorm 0.734 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 142986
2022-03-08 04:34:34 | INFO | fairseq.trainer | begin training epoch 504
2022-03-08 04:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:37:11 | INFO | train_inner | epoch 504:     55 / 97 loss=2.018, nll_loss=0.574, ppl=1.49, wps=22191.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48500, lr=0.000143592, gnorm=0.736, loss_scale=16, train_wall=265, gb_free=8.1, wall=143143
2022-03-08 04:39:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:39:16 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.178 | nll_loss 12.581 | ppl 6126.67 | wps 43309.6 | wpb 510.9 | bsz 1 | num_updates 48542 | best_loss 8.233
2022-03-08 04:39:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 48542 updates
2022-03-08 04:39:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:39:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:39:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 504 @ 48542 updates, score 13.178) (writing took 2.351919033098966 seconds)
2022-03-08 04:39:18 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-08 04:39:18 | INFO | train | epoch 504 | loss 2.017 | nll_loss 0.573 | ppl 1.49 | wps 22373 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48542 | lr 0.000143529 | gnorm 0.739 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143270
2022-03-08 04:39:18 | INFO | fairseq.trainer | begin training epoch 505
2022-03-08 04:39:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:40:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:42:06 | INFO | train_inner | epoch 505:     59 / 97 loss=2.016, nll_loss=0.572, ppl=1.49, wps=22179.5, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48600, lr=0.000143444, gnorm=0.73, loss_scale=16, train_wall=265, gb_free=8.1, wall=143438
2022-03-08 04:43:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:44:00 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.193 | nll_loss 12.596 | ppl 6190.6 | wps 43248.7 | wpb 510.9 | bsz 1 | num_updates 48638 | best_loss 8.233
2022-03-08 04:44:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 48638 updates
2022-03-08 04:44:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:44:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:44:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 505 @ 48638 updates, score 13.193) (writing took 2.344107241369784 seconds)
2022-03-08 04:44:02 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-08 04:44:02 | INFO | train | epoch 505 | loss 2.016 | nll_loss 0.572 | ppl 1.49 | wps 22151.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48638 | lr 0.000143388 | gnorm 0.732 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143554
2022-03-08 04:44:02 | INFO | fairseq.trainer | begin training epoch 506
2022-03-08 04:44:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:46:59 | INFO | train_inner | epoch 506:     62 / 97 loss=2.017, nll_loss=0.573, ppl=1.49, wps=22413.6, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=48700, lr=0.000143296, gnorm=0.737, loss_scale=16, train_wall=262, gb_free=8.1, wall=143730
2022-03-08 04:47:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:48:43 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.191 | nll_loss 12.593 | ppl 6176.3 | wps 42734.9 | wpb 510.9 | bsz 1 | num_updates 48734 | best_loss 8.233
2022-03-08 04:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 48734 updates
2022-03-08 04:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:48:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 506 @ 48734 updates, score 13.191) (writing took 2.4100185530260205 seconds)
2022-03-08 04:48:46 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-08 04:48:46 | INFO | train | epoch 506 | loss 2.016 | nll_loss 0.572 | ppl 1.49 | wps 22169.5 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48734 | lr 0.000143246 | gnorm 0.733 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 143837
2022-03-08 04:48:46 | INFO | fairseq.trainer | begin training epoch 507
2022-03-08 04:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:51:54 | INFO | train_inner | epoch 507:     66 / 97 loss=2.015, nll_loss=0.571, ppl=1.49, wps=22192, ups=0.34, wpb=65495, bsz=127.9, num_updates=48800, lr=0.00014315, gnorm=0.738, loss_scale=16, train_wall=264, gb_free=8.1, wall=144026
2022-03-08 04:53:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:53:27 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.159 | nll_loss 12.56 | ppl 6038.31 | wps 42414.7 | wpb 510.9 | bsz 1 | num_updates 48831 | best_loss 8.233
2022-03-08 04:53:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 48831 updates
2022-03-08 04:53:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:53:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:53:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 507 @ 48831 updates, score 13.159) (writing took 2.2821671129204333 seconds)
2022-03-08 04:53:29 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-08 04:53:29 | INFO | train | epoch 507 | loss 2.015 | nll_loss 0.571 | ppl 1.49 | wps 22390.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 48831 | lr 0.000143104 | gnorm 0.742 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144121
2022-03-08 04:53:29 | INFO | fairseq.trainer | begin training epoch 508
2022-03-08 04:53:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 04:54:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 04:56:49 | INFO | train_inner | epoch 508:     70 / 97 loss=2.014, nll_loss=0.57, ppl=1.48, wps=22206.1, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=48900, lr=0.000143003, gnorm=0.743, loss_scale=16, train_wall=264, gb_free=8.1, wall=144321
2022-03-08 04:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 04:58:11 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.249 | nll_loss 12.656 | ppl 6453.13 | wps 41960 | wpb 510.9 | bsz 1 | num_updates 48927 | best_loss 8.233
2022-03-08 04:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 48927 updates
2022-03-08 04:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 04:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 508 @ 48927 updates, score 13.249) (writing took 2.358416149392724 seconds)
2022-03-08 04:58:13 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-08 04:58:13 | INFO | train | epoch 508 | loss 2.014 | nll_loss 0.57 | ppl 1.48 | wps 22167.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 48927 | lr 0.000142964 | gnorm 0.744 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144405
2022-03-08 04:58:13 | INFO | fairseq.trainer | begin training epoch 509
2022-03-08 04:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:01:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:01:44 | INFO | train_inner | epoch 509:     74 / 97 loss=2.015, nll_loss=0.571, ppl=1.49, wps=22196.7, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49000, lr=0.000142857, gnorm=0.735, loss_scale=16, train_wall=265, gb_free=8.1, wall=144616
2022-03-08 05:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:02:54 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.215 | nll_loss 12.619 | ppl 6289.89 | wps 42267.9 | wpb 510.9 | bsz 1 | num_updates 49023 | best_loss 8.233
2022-03-08 05:02:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 49023 updates
2022-03-08 05:02:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:02:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:02:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 509 @ 49023 updates, score 13.215) (writing took 2.39173346105963 seconds)
2022-03-08 05:02:57 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-08 05:02:57 | INFO | train | epoch 509 | loss 2.014 | nll_loss 0.57 | ppl 1.48 | wps 22163.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49023 | lr 0.000142824 | gnorm 0.73 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144688
2022-03-08 05:02:57 | INFO | fairseq.trainer | begin training epoch 510
2022-03-08 05:02:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:06:36 | INFO | train_inner | epoch 510:     77 / 97 loss=2.013, nll_loss=0.569, ppl=1.48, wps=22411.9, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49100, lr=0.000142712, gnorm=0.743, loss_scale=16, train_wall=262, gb_free=8.1, wall=144908
2022-03-08 05:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:07:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:07:38 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.214 | nll_loss 12.62 | ppl 6296.54 | wps 42380.8 | wpb 510.9 | bsz 1 | num_updates 49119 | best_loss 8.233
2022-03-08 05:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 49119 updates
2022-03-08 05:07:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:07:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 510 @ 49119 updates, score 13.214) (writing took 2.229464608244598 seconds)
2022-03-08 05:07:40 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-08 05:07:40 | INFO | train | epoch 510 | loss 2.013 | nll_loss 0.57 | ppl 1.48 | wps 22179.7 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49119 | lr 0.000142684 | gnorm 0.75 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 144972
2022-03-08 05:07:40 | INFO | fairseq.trainer | begin training epoch 511
2022-03-08 05:07:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:11:31 | INFO | train_inner | epoch 511:     81 / 97 loss=2.013, nll_loss=0.569, ppl=1.48, wps=22220.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49200, lr=0.000142566, gnorm=0.741, loss_scale=16, train_wall=264, gb_free=8.1, wall=145203
2022-03-08 05:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:12:21 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.198 | nll_loss 12.604 | ppl 6223.92 | wps 42306.4 | wpb 510.9 | bsz 1 | num_updates 49216 | best_loss 8.233
2022-03-08 05:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 49216 updates
2022-03-08 05:12:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:12:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 511 @ 49216 updates, score 13.198) (writing took 2.304224716965109 seconds)
2022-03-08 05:12:24 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-08 05:12:24 | INFO | train | epoch 511 | loss 2.012 | nll_loss 0.569 | ppl 1.48 | wps 22407.3 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49216 | lr 0.000142543 | gnorm 0.738 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145255
2022-03-08 05:12:24 | INFO | fairseq.trainer | begin training epoch 512
2022-03-08 05:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:14:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:16:26 | INFO | train_inner | epoch 512:     85 / 97 loss=2.013, nll_loss=0.57, ppl=1.48, wps=22206.6, ups=0.34, wpb=65495, bsz=127.9, num_updates=49300, lr=0.000142422, gnorm=0.735, loss_scale=16, train_wall=265, gb_free=8.1, wall=145497
2022-03-08 05:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:17:05 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.171 | nll_loss 12.575 | ppl 6101.86 | wps 42505 | wpb 510.9 | bsz 1 | num_updates 49312 | best_loss 8.233
2022-03-08 05:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 49312 updates
2022-03-08 05:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:17:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 512 @ 49312 updates, score 13.171) (writing took 2.279684673063457 seconds)
2022-03-08 05:17:07 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-08 05:17:07 | INFO | train | epoch 512 | loss 2.012 | nll_loss 0.569 | ppl 1.48 | wps 22174.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49312 | lr 0.000142404 | gnorm 0.731 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145539
2022-03-08 05:17:07 | INFO | fairseq.trainer | begin training epoch 513
2022-03-08 05:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:20:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:21:21 | INFO | train_inner | epoch 513:     89 / 97 loss=2.012, nll_loss=0.569, ppl=1.48, wps=22184, ups=0.34, wpb=65490.8, bsz=127.9, num_updates=49400, lr=0.000142278, gnorm=0.734, loss_scale=16, train_wall=265, gb_free=8.1, wall=145793
2022-03-08 05:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:21:49 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.21 | nll_loss 12.615 | ppl 6274.78 | wps 42885.5 | wpb 510.9 | bsz 1 | num_updates 49408 | best_loss 8.233
2022-03-08 05:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 49408 updates
2022-03-08 05:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:21:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 513 @ 49408 updates, score 13.21) (writing took 2.2906096898950636 seconds)
2022-03-08 05:21:51 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-08 05:21:51 | INFO | train | epoch 513 | loss 2.012 | nll_loss 0.568 | ppl 1.48 | wps 22156.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49408 | lr 0.000142266 | gnorm 0.735 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 145823
2022-03-08 05:21:51 | INFO | fairseq.trainer | begin training epoch 514
2022-03-08 05:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:26:13 | INFO | train_inner | epoch 514:     92 / 97 loss=2.012, nll_loss=0.568, ppl=1.48, wps=22427.8, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49500, lr=0.000142134, gnorm=0.729, loss_scale=16, train_wall=262, gb_free=8.1, wall=146085
2022-03-08 05:26:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:26:32 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.236 | nll_loss 12.64 | ppl 6381.02 | wps 43195.1 | wpb 510.9 | bsz 1 | num_updates 49505 | best_loss 8.233
2022-03-08 05:26:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 49505 updates
2022-03-08 05:26:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:26:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:26:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 514 @ 49505 updates, score 13.236) (writing took 2.285600339062512 seconds)
2022-03-08 05:26:34 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-08 05:26:34 | INFO | train | epoch 514 | loss 2.011 | nll_loss 0.567 | ppl 1.48 | wps 22414.6 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49505 | lr 0.000142127 | gnorm 0.728 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146106
2022-03-08 05:26:34 | INFO | fairseq.trainer | begin training epoch 515
2022-03-08 05:26:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:27:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:31:08 | INFO | train_inner | epoch 515:     96 / 97 loss=2.011, nll_loss=0.568, ppl=1.48, wps=22191, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49600, lr=0.00014199, gnorm=0.732, loss_scale=16, train_wall=265, gb_free=8.1, wall=146380
2022-03-08 05:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:31:16 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.22 | nll_loss 12.624 | ppl 6313.95 | wps 43040.8 | wpb 510.9 | bsz 1 | num_updates 49601 | best_loss 8.233
2022-03-08 05:31:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 49601 updates
2022-03-08 05:31:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:31:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:31:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 515 @ 49601 updates, score 13.22) (writing took 2.3278011670336127 seconds)
2022-03-08 05:31:18 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-08 05:31:18 | INFO | train | epoch 515 | loss 2.011 | nll_loss 0.567 | ppl 1.48 | wps 22150.9 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49601 | lr 0.000141989 | gnorm 0.731 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146390
2022-03-08 05:31:18 | INFO | fairseq.trainer | begin training epoch 516
2022-03-08 05:31:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:34:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:35:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:35:59 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.225 | nll_loss 12.634 | ppl 6356.27 | wps 43169.2 | wpb 510.9 | bsz 1 | num_updates 49697 | best_loss 8.233
2022-03-08 05:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 49697 updates
2022-03-08 05:35:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 516 @ 49697 updates, score 13.225) (writing took 2.2225144170224667 seconds)
2022-03-08 05:36:02 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-08 05:36:02 | INFO | train | epoch 516 | loss 2.01 | nll_loss 0.567 | ppl 1.48 | wps 22177.4 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49697 | lr 0.000141852 | gnorm 0.733 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146673
2022-03-08 05:36:02 | INFO | fairseq.trainer | begin training epoch 517
2022-03-08 05:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:36:10 | INFO | train_inner | epoch 517:      3 / 97 loss=2.01, nll_loss=0.567, ppl=1.48, wps=21651.6, ups=0.33, wpb=65451.9, bsz=127.8, num_updates=49700, lr=0.000141848, gnorm=0.733, loss_scale=16, train_wall=264, gb_free=8.1, wall=146682
2022-03-08 05:40:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:40:43 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.198 | nll_loss 12.609 | ppl 6249.37 | wps 43369.7 | wpb 510.9 | bsz 1 | num_updates 49793 | best_loss 8.233
2022-03-08 05:40:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 49793 updates
2022-03-08 05:40:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:40:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:40:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 517 @ 49793 updates, score 13.198) (writing took 2.2631010129116476 seconds)
2022-03-08 05:40:45 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-08 05:40:45 | INFO | train | epoch 517 | loss 2.01 | nll_loss 0.567 | ppl 1.48 | wps 22160.2 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49793 | lr 0.000141715 | gnorm 0.735 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 146957
2022-03-08 05:40:45 | INFO | fairseq.trainer | begin training epoch 518
2022-03-08 05:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:41:05 | INFO | train_inner | epoch 518:      7 / 97 loss=2.009, nll_loss=0.566, ppl=1.48, wps=22194.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49800, lr=0.000141705, gnorm=0.734, loss_scale=16, train_wall=265, gb_free=8.1, wall=146977
2022-03-08 05:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:45:27 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.223 | nll_loss 12.629 | ppl 6334.24 | wps 43543.4 | wpb 510.9 | bsz 1 | num_updates 49890 | best_loss 8.233
2022-03-08 05:45:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 49890 updates
2022-03-08 05:45:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:45:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 518 @ 49890 updates, score 13.223) (writing took 2.231237004045397 seconds)
2022-03-08 05:45:29 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-08 05:45:29 | INFO | train | epoch 518 | loss 2.009 | nll_loss 0.566 | ppl 1.48 | wps 22409.8 | ups 0.34 | wpb 65491.6 | bsz 127.9 | num_updates 49890 | lr 0.000141577 | gnorm 0.73 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 147241
2022-03-08 05:45:29 | INFO | fairseq.trainer | begin training epoch 519
2022-03-08 05:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:45:57 | INFO | train_inner | epoch 519:     10 / 97 loss=2.009, nll_loss=0.565, ppl=1.48, wps=22428.3, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=49900, lr=0.000141563, gnorm=0.733, loss_scale=16, train_wall=262, gb_free=8.1, wall=147269
2022-03-08 05:47:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 05:50:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:50:10 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.19 | nll_loss 12.596 | ppl 6191.74 | wps 43468.6 | wpb 510.9 | bsz 1 | num_updates 49986 | best_loss 8.233
2022-03-08 05:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 49986 updates
2022-03-08 05:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 519 @ 49986 updates, score 13.19) (writing took 2.2457605940289795 seconds)
2022-03-08 05:50:12 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-08 05:50:12 | INFO | train | epoch 519 | loss 2.01 | nll_loss 0.567 | ppl 1.48 | wps 22179.3 | ups 0.34 | wpb 65491.1 | bsz 127.9 | num_updates 49986 | lr 0.000141441 | gnorm 0.736 | loss_scale 16 | train_wall 254 | gb_free 8.1 | wall 147524
2022-03-08 05:50:12 | INFO | fairseq.trainer | begin training epoch 520
2022-03-08 05:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 05:50:52 | INFO | train_inner | epoch 520:     14 / 97 loss=2.009, nll_loss=0.566, ppl=1.48, wps=22205.2, ups=0.34, wpb=65492.9, bsz=127.9, num_updates=50000, lr=0.000141421, gnorm=0.736, loss_scale=16, train_wall=265, gb_free=8.1, wall=147564
2022-03-08 05:50:52 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 05:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 05:50:57 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.14 | nll_loss 12.549 | ppl 5991.21 | wps 43440.2 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.233
2022-03-08 05:50:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 50000 updates
2022-03-08 05:50:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt
2022-03-08 05:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.0625_fp16-label_smoothing_0.06_#2/checkpoint_last.pt (epoch 520 @ 50000 updates, score 13.14) (writing took 2.2579232049174607 seconds)
2022-03-08 05:51:00 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-08 05:51:00 | INFO | train | epoch 520 | loss 1.994 | nll_loss 0.549 | ppl 1.46 | wps 19357 | ups 0.3 | wpb 65536 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.734 | loss_scale 16 | train_wall 37 | gb_free 8.1 | wall 147572
2022-03-08 05:51:00 | INFO | fairseq_cli.train | done training in 147571.4 seconds
