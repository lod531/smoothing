Sender: LSF System <lsfadmin@eu-g3-059>
Subject: Job 210581379: <iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:24:27 2022
Job was executed on host(s) <eu-g3-059>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:24:52 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:24:52 2022
Terminated at Wed Mar 23 10:34:57 2022
Results reported at Wed Mar 23 10:34:57 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.25 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4190.44 sec.
    Max Memory :                                 5933 MB
    Average Memory :                             4675.27 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14067.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4205 sec.
    Turnaround time :                            4230 sec.

The output (if any) follows:

2022-03-23 09:25:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.25, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.25, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:25:05 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:25:05 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:25:05 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:25:05 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:25:05 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:25:05 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:25:05 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:25:05 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:25:05 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:25:05 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:25:05 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:25:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:25:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:12 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:25:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:25:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:25:12 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:25:12 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:25:12 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:25:12 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:25:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:25:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:25:12 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:25:12 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:25:46 | INFO | train_inner | epoch 001:    104 / 157 loss=12.261, nll_loss=11.861, ppl=3719.71, wps=80619.4, ups=3.21, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.733, loss_scale=8, train_wall=33, gb_free=14, wall=34
2022-03-23 09:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:05 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:26:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:26:08 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:26:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:26:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:26:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:26:23 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.895 | nll_loss 10.017 | ppl 1036.29 | bleu 0.01 | wps 4286.8 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:26:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:26:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6222796812653542 seconds)
2022-03-23 09:26:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:26:45 | INFO | train | epoch 001 | loss 11.9 | nll_loss 11.378 | ppl 2661.53 | wps 42316.2 | ups 1.69 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.176 | loss_scale 8 | train_wall 49 | gb_free 22.4 | wall 94
2022-03-23 09:26:46 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:26:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:00 | INFO | train_inner | epoch 002:     47 / 157 loss=11.02, nll_loss=10.204, ppl=1179.37, wps=34061.5, ups=1.34, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.067, loss_scale=8, train_wall=30, gb_free=14.7, wall=109
2022-03-23 09:27:32 | INFO | train_inner | epoch 002:    147 / 157 loss=10.479, nll_loss=9.428, ppl=688.98, wps=80227.8, ups=3.19, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.157, loss_scale=8, train_wall=31, gb_free=14, wall=140
2022-03-23 09:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:38 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:27:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the.
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:27:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:27:51 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:27:56 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:13 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "
2022-03-23 09:28:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:28:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:23 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.224 | nll_loss 8.978 | ppl 504.21 | bleu 0.01 | wps 3651.1 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:28:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:28:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:28:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.711719451006502 seconds)
2022-03-23 09:28:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:28:24 | INFO | train | epoch 002 | loss 10.57 | nll_loss 9.564 | ppl 757.17 | wps 39813 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.1 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 193
2022-03-23 09:28:25 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:28:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:53 | INFO | train_inner | epoch 003:     90 / 157 loss=10.261, nll_loss=9.08, ppl=541.35, wps=30394.3, ups=1.24, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.089, loss_scale=8, train_wall=30, gb_free=13.7, wall=221
2022-03-23 09:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:20 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the.
2022-03-23 09:29:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example hypothesis: and the the the of the of the the of the of the of the.
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:28 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's, and it's's, and it's's.
2022-03-23 09:29:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and it's's, and it's's's, and it's's's, and it's's's's, and it's's's's's.
2022-03-23 09:29:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:29:39 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:29:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:29:44 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's, and it's, it's, and it's's, and it's, and it's's's's's's's, and it's, and it's's's's's, and it's's's's's, it's's's's, and it's, and it's's,
2022-03-23 09:29:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:51 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, and we, and the the, and the the, and we, and we, and the the, and the the, and the the the the the the, and the the the the the the the the the the the the the, and the the, and the the, and the the, and the the the, and the the, and the the the, and the the the, and the the the the the the the the the
2022-03-23 09:29:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:58 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:29:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:01 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we a a a, we, we, we, we, we, the, the, the the the a a a a, and the a, and the, and the, and the, and the a a a a a a a a a a, and the, and the, and the the the the the the the a a a a a a a a a a a a a a a a, and the the, and the, and the a a a a a a a a a a a a a a a a a a a a, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the the, and the, and the, and the, and the, and the, and the, and the, and the, and the a a a a a a a a a a a a a a a a a a a a a,
2022-03-23 09:30:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.053 | nll_loss 8.69 | ppl 413.14 | bleu 0.13 | wps 3734.7 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.13
2022-03-23 09:30:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:30:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:30:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.13) (writing took 1.7410380146466196 seconds)
2022-03-23 09:30:02 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:30:02 | INFO | train | epoch 003 | loss 10.201 | nll_loss 8.991 | ppl 508.79 | wps 40327 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.16 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 291
2022-03-23 09:30:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:13 | INFO | train_inner | epoch 004:     33 / 157 loss=10.09, nll_loss=8.831, ppl=455.27, wps=31583.3, ups=1.24, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.158, loss_scale=8, train_wall=31, gb_free=13.9, wall=302
2022-03-23 09:30:44 | INFO | train_inner | epoch 004:    133 / 157 loss=9.918, nll_loss=8.586, ppl=384.21, wps=81008.6, ups=3.21, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.24, loss_scale=8, train_wall=31, gb_free=12.6, wall=333
2022-03-23 09:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 09:30:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:30:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world of the world.
2022-03-23 09:30:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:04 | INFO | fairseq.tasks.translation | example hypothesis: so we have to have to be the world of the world.
2022-03-23 09:31:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:08 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world, and it's the world, and it's a world.
2022-03-23 09:31:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:13 | INFO | fairseq.tasks.translation | example hypothesis: and it's what we're not not not not not not not not not not not not not not not not not not not not not not not not not it.
2022-03-23 09:31:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:18 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and the world, and the world of the world, and the world of the world of the world of the world.
2022-03-23 09:31:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example hypothesis: but it's the world, but they're are the world, but they are are are are are are the world, but it's the world.
2022-03-23 09:31:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can can see the the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 09:31:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:31:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to have to be the world, and we have the world, and we have the world of the world, and we have the world of the world of the world of the world, and we have the world, and we have the world of the world of the world, which is the world of the world, and we have to do we have to have to be be be be be be be be be be be be be be be be be be to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be to be be be be be to be be be be be be be be be be be be to be, and we can can can can can can can can can can can can can can can can can can can can can can have
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:40 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.654 | nll_loss 8.106 | ppl 275.45 | bleu 0.94 | wps 3687.6 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.94
2022-03-23 09:31:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:31:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:31:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:31:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.94) (writing took 1.7544666319154203 seconds)
2022-03-23 09:31:41 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:31:41 | INFO | train | epoch 004 | loss 9.922 | nll_loss 8.593 | ppl 386.15 | wps 39892.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.196 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 390
2022-03-23 09:31:42 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:31:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:05 | INFO | train_inner | epoch 005:     76 / 157 loss=9.736, nll_loss=8.324, ppl=320.45, wps=30346.2, ups=1.24, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.404, loss_scale=8, train_wall=30, gb_free=13.4, wall=414
2022-03-23 09:32:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:34 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 09:32:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example hypothesis: this is this is the world.
2022-03-23 09:32:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be to be two.
2022-03-23 09:32:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:32:49 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do that we're not not not not going to do it.
2022-03-23 09:32:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world in the world in the world in the world in the world.
2022-03-23 09:32:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be a lot of the world, but they're going to be to be a lot of the world, but they're going to be the world.
2022-03-23 09:32:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:02 | INFO | fairseq.tasks.translation | example hypothesis: and we can see that we can see the world that we can see the way to see the world and we can see the world.
2022-03-23 09:33:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example hypothesis: and "this is," "" "" "" "" "" "this is," "" this is this is, "" "" "" this is, "" "" "" "" "" "" "" "" this is, "" "this is," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "this is," "" "" "" "this is," "" "" "" "" "" "" "" "" "
2022-03-23 09:33:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a lot that we're going to be a lot that we're going to be a lot that we're going to be a lot that we're going to be a lot to be a lot to be a lot of the world to be a lot of the world, and we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world, and we're going to be be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to be a lot of the world that we're going to get to get to get to be a lot of the world is to be be be be be be a lot of the world to be
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:11 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.385 | nll_loss 7.694 | ppl 207.13 | bleu 1.59 | wps 4491.9 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.59
2022-03-23 09:33:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:33:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:33:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.59) (writing took 1.7557071489281952 seconds)
2022-03-23 09:33:13 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:33:13 | INFO | train | epoch 005 | loss 9.597 | nll_loss 8.123 | ppl 278.78 | wps 43227 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.262 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 481
2022-03-23 09:33:13 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:19 | INFO | train_inner | epoch 006:     19 / 157 loss=9.505, nll_loss=7.99, ppl=254.16, wps=34504.7, ups=1.36, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.243, loss_scale=8, train_wall=30, gb_free=14.6, wall=487
2022-03-23 09:33:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:33:51 | INFO | train_inner | epoch 006:    120 / 157 loss=9.369, nll_loss=7.786, ppl=220.7, wps=79771.5, ups=3.16, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=1.219, loss_scale=4, train_wall=31, gb_free=14.1, wall=519
2022-03-23 09:34:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:06 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:34:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the idea.
2022-03-23 09:34:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a new new new new lot of two.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:18 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of fact, there's a lot of the world.
2022-03-23 09:34:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:23 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we're going to do that we're going to do it's going to do it's going to do that we're going to do it's going to do that we're going to do it's going to do it
2022-03-23 09:34:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, in the world, and in the world, in the world, in the world, in the world, and people are in the world.
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example hypothesis: but they're not a lot of the world, but they're going to be a lot of the world.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see, we can see the world, we can see the world, and we can see the world, we can see the world, and we can see the world, we can see the world.
2022-03-23 09:34:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" you know, "you're going to say," "it's going to say," "" you're going to say, "it's going to say," "" "" "it's a lot of this is a lot of this is," it's going to say, "" it's going to say, "it's going to say," "" "" "" "" "" "" "" "" "" "" it's a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world, we're going to do that we're going to be a lot of the world, and then we're going to do that we're going to be a lot of the world.
2022-03-23 09:34:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:46 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.12 | nll_loss 7.317 | ppl 159.43 | bleu 2.08 | wps 4051.9 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 2.08
2022-03-23 09:34:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:34:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:34:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:34:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 2.08) (writing took 1.7753785056993365 seconds)
2022-03-23 09:34:48 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:34:48 | INFO | train | epoch 006 | loss 9.361 | nll_loss 7.773 | ppl 218.76 | wps 41063.3 | ups 1.63 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 1.296 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 577
2022-03-23 09:34:48 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:34:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:08 | INFO | train_inner | epoch 007:     63 / 157 loss=9.203, nll_loss=7.547, ppl=187.02, wps=32407.1, ups=1.29, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.096, loss_scale=4, train_wall=30, gb_free=14.9, wall=597
2022-03-23 09:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:41 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the brain.
2022-03-23 09:35:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:35:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most of the most of the most of the most of the most of the most of the most of the world.
2022-03-23 09:35:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:35:50 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a new new new new new new new new new new new new new new new york.
2022-03-23 09:35:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:35:55 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of example, and there's a lot, and it's going to be, and it's going to be a lot, and you're going to be a lot.
2022-03-23 09:35:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: it's it's not just just just just just just just just to be, and we're going to do that we're going to do it, and we're going to do it, and we're going to do that we're going to
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the world, in the world, in the world, and it's in the world, and it's in the world, and it's the world for the world, and it's the world, and it's the world,
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example hypothesis: well, if you're going to get a lot of course, but it's not, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be able to be able, but they're going to be able to be able to be able to be able to be able
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the brain, and we can see that we can see that we can see the world, and then we can see that we can see the brain, we can see that we can see the world, and then we can see the world, we can see the brain, we can see the brain, we can see that we can see the brain, we can see it's going to see the world, and then it
2022-03-23 09:36:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if you know, "you're going to say," you know, "you know," you know, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say,"
2022-03-23 09:36:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the world, we're going to get a lot of the world, we're going to be a lot of the world, and we're going to be able to see that we're going to take a lot of the world, and we're going to be a lot of the world that we're going to see that we're going to take a lot of the world, we're going to get a lot of that we're going to see that we're going to see that we're going to get a lot of the world, and we're going to be able to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to take a lot of the world, and then we're going to be a lot of the world, and then we're going to see that we're going to see that we're going to take a lot of the world, and then we're going to see that we're going to get to
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:28 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.905 | nll_loss 7 | ppl 128.01 | bleu 2.11 | wps 3499.7 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.11
2022-03-23 09:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.11) (writing took 1.8288750010542572 seconds)
2022-03-23 09:36:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:36:30 | INFO | train | epoch 007 | loss 9.113 | nll_loss 7.417 | ppl 170.94 | wps 38902.8 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.074 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 678
2022-03-23 09:36:30 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:32 | INFO | train_inner | epoch 008:      6 / 157 loss=9.062, nll_loss=7.344, ppl=162.45, wps=29871.4, ups=1.19, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.124, loss_scale=4, train_wall=30, gb_free=14.4, wall=680
2022-03-23 09:37:03 | INFO | train_inner | epoch 008:    106 / 157 loss=8.872, nll_loss=7.072, ppl=134.55, wps=81272.9, ups=3.22, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.017, loss_scale=4, train_wall=31, gb_free=14.7, wall=711
2022-03-23 09:37:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the brain.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most of the most most most most most of the most most most most most most of the most most most most most most of
2022-03-23 09:37:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new york
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:37:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot of example, and there's a lot of life, where you're going to see where are going to see where are going to be where where you're going to see where
2022-03-23 09:37:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:37:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't think that we're going to think that we're not going to do that's going to be a little bit of what we're going to do.
2022-03-23 09:37:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the world, in the people who are in the most people for the people, for the people who are a lot of people in the people for people for the people, for the people, and the people who are in the people in the people for people
2022-03-23 09:37:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:37:55 | INFO | fairseq.tasks.translation | example hypothesis: are some of some of some of these are some of them, but it's a lot, but it's a lot of course, but if you can't get to get the same, but it, but it, but it, but but it's the same, but it's also also also, but it's a lot of the right, but it
2022-03-23 09:37:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain that we can take the brain, and then we can take the brain, and then we can take the brain, the brain, the brain, the brain, we can take the brain, the brain, the brain, and the brain, the brain, and the brain, and we can take the brain, and we can take the brain, the brain, the brain, the brain, that we can take the brain,
2022-03-23 09:38:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example hypothesis: one: one: the first one of the first one of the first thing, and it's going to say, "" and it's the first first first first first thing, "" and it's the first first first first first first thing, "and it's the first thing," and then it's the first first thing, "you know," you know, "you know," you know, "you know," you know, "you're going to say," you know, "you know," you're going to say, "you know," you're going to say, "you're going to say," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say,"
2022-03-23 09:38:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, if we're going to get a lot of course, that we're going to get the world, that we're going to be able to be a lot of the world, and then we're going to make a lot of the world, and then we're going to make a lot of the world that we're going to get to make a lot of the world that we're going to take the world, the world that we're going to take the world, that we're going to make a lot of the world, and so that we're going to take the world, that we're going to make a lot of the world, and so that we're going to take the world, that we're going to be a lot of the world, that we're going to be a lot of the world in the world, which is that we're going to make a lot of the world, and so that we're going to make a lot of the way that we're going to get to take the world, which is a
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.715 | nll_loss 6.694 | ppl 103.54 | bleu 3.01 | wps 3416 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.01
2022-03-23 09:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.01) (writing took 1.7721111071296036 seconds)
2022-03-23 09:38:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:38:13 | INFO | train | epoch 008 | loss 8.91 | nll_loss 7.124 | ppl 139.49 | wps 38303.3 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.047 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 781
2022-03-23 09:38:13 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:29 | INFO | train_inner | epoch 009:     49 / 157 loss=8.845, nll_loss=7.029, ppl=130.57, wps=29958.6, ups=1.17, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.037, loss_scale=4, train_wall=31, gb_free=14.9, wall=797
2022-03-23 09:39:00 | INFO | train_inner | epoch 009:    149 / 157 loss=8.74, nll_loss=6.876, ppl=117.42, wps=80235.2, ups=3.23, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.067, loss_scale=4, train_wall=31, gb_free=14.3, wall=828
2022-03-23 09:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the way.
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most most most of the most most most most most most.
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:14 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-23 09:39:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's example, there's a coooooooand where it's going to go up, and it's going to go up with the air.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just just a few years on his life, and what's going to do.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of how people like people for people for the people for the people, and the most people who are a few people in the most people in the most people, and it's a few years.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of some of some of the things, but it doesn't have to be able, but if it's not able to be able to be able, but if you can't see it, but it's not even even even even even even even even even even even even even even even even even even even even if
2022-03-23 09:39:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see that we can see that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able, and we can see that we can see the brain, and then we can see that we can see the brain, and then we can see that we can see the world can see the brain can see the
2022-03-23 09:39:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example hypothesis: jo: one of the one of the one, and it says, "and it says," and it's a lot of people who said, "" "" "" "" "" "" "" "" "" "" "" "and" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:51 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still still more than the same time, and if we're going to get a lot of the world, and then we're going to do that we're going to make a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do
2022-03-23 09:39:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:51 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.47 | nll_loss 6.338 | ppl 80.89 | bleu 4.68 | wps 3673.6 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.68
2022-03-23 09:39:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:39:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:39:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.68) (writing took 1.7954148212447762 seconds)
2022-03-23 09:39:52 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:39:52 | INFO | train | epoch 009 | loss 8.728 | nll_loss 6.86 | ppl 116.13 | wps 39636.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.042 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 881
2022-03-23 09:39:53 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:22 | INFO | train_inner | epoch 010:     92 / 157 loss=8.562, nll_loss=6.622, ppl=98.5, wps=30547.3, ups=1.22, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.919, loss_scale=4, train_wall=31, gb_free=14.3, wall=910
2022-03-23 09:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the top of the house.
2022-03-23 09:40:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example hypothesis: that's the second, from the yeah, you know, most of the most most thing here here.
2022-03-23 09:40:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example hypothesis: they're going to be new new new new new new new new two two two two two two cells.
2022-03-23 09:40:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese food, where you're going to go, and it's going on.
2022-03-23 09:40:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're just just just just a few few years, and what's going on.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people like people for people for the people for the number of people, and that's a few years, and it's a lot of people.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are in the brain, but if you're not able to go, but if you have the energy, it's not able to be able to get the energy, and it's going to be able to be able to be able.
2022-03-23 09:41:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this information, we can use a brain, and we can use the brain, and that's the brain, and the brain is a brain, and all the brain, and all of the brain, and all of the brain, and all of the brain, and the brain, and the brain, and the brain will be able to be able to be able.
2022-03-23 09:41:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reasons, and it's interesting, and it's interesting for me that i'm going to show you, and if you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go to go to be a little bit about that's going to be in the first time for the first time, and you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go to go to be a very good for this is that's going to go to be a very good for that's a little bit about that's going to go for the first time, and you're going to
2022-03-23 09:41:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:23 | INFO | fairseq.tasks.translation | example hypothesis: so, it's still still still still, and the last year, and we're going to get a little bit that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:41:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:23 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.238 | nll_loss 5.994 | ppl 63.74 | bleu 7.49 | wps 4361.5 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.49
2022-03-23 09:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:41:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:41:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:41:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.49) (writing took 1.7864381661638618 seconds)
2022-03-23 09:41:25 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:41:25 | INFO | train | epoch 010 | loss 8.507 | nll_loss 6.543 | ppl 93.25 | wps 42703.2 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.99 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 973
2022-03-23 09:41:25 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:41:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:36 | INFO | train_inner | epoch 011:     35 / 157 loss=8.447, nll_loss=6.456, ppl=87.81, wps=33351.3, ups=1.34, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.059, loss_scale=4, train_wall=30, gb_free=13.4, wall=985
2022-03-23 09:42:07 | INFO | train_inner | epoch 011:    135 / 157 loss=8.27, nll_loss=6.203, ppl=73.66, wps=82253, ups=3.22, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.972, loss_scale=4, train_wall=31, gb_free=13.3, wall=1016
2022-03-23 09:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:18 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppm in the center.
2022-03-23 09:42:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:22 | INFO | fairseq.tasks.translation | example hypothesis: that's what most of you know, most of most of the most most here.
2022-03-23 09:42:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:26 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new york.
2022-03-23 09:42:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese, where they're going to go with the ppg, and they're going to be going on.
2022-03-23 09:42:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just take a few few years on his head, and what's going on.
2022-03-23 09:42:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:42:39 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as people like people for people for the number of the number, and the number of the number of the number of the number of the number is a lot of reviiiiiiiiiiiiiiity.
2022-03-23 09:42:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:42:43 | INFO | fairseq.tasks.translation | example hypothesis: first of some of you are a little bit of the surface, but if you don't need to use the energy, you don't need to use your energy, and you need to need the energy.
2022-03-23 09:42:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can go from this structure, we can use a structure of information that we can use the structure of the information, and that's all the information.
2022-03-23 09:42:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:51 | INFO | fairseq.tasks.translation | example hypothesis: thank one of the reasons, and it's interesting for me that i'm going to say, "you," you know, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know
2022-03-23 09:42:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still still the mother, and a lot of work that we were going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 09:42:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:53 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.038 | nll_loss 5.665 | ppl 50.73 | bleu 9.52 | wps 4710 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.52
2022-03-23 09:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:42:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.52) (writing took 1.8046346618793905 seconds)
2022-03-23 09:42:55 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:42:55 | INFO | train | epoch 011 | loss 8.31 | nll_loss 6.259 | ppl 76.6 | wps 43909.1 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.965 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1063
2022-03-23 09:42:55 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:20 | INFO | train_inner | epoch 012:     78 / 157 loss=8.178, nll_loss=6.071, ppl=67.23, wps=34638.4, ups=1.39, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.944, loss_scale=4, train_wall=30, gb_free=14, wall=1088
2022-03-23 09:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:48 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppm in the middle of the center.
2022-03-23 09:43:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of the doha, most of most of most of the most.
2022-03-23 09:43:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:56 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to create two new york new york.
2022-03-23 09:43:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese food, where they're going to get up with, and they're going to be able.
2022-03-23 09:44:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:05 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just just a few few ways on his head, and what's going to understand what's going on.
2022-03-23 09:44:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamated people who were used for the number of animals, and the number of animals, and that's a number for the most important way.
2022-03-23 09:44:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the riddddddle, but if you don't need to use it, it doesn't need to use the energy, and you need to use your energy, and you need to use the energy.
2022-03-23 09:44:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information, we can go from this kind of structure, we can start with a huge structure, and we can start with the structure of the structure of information, and all the information that's all the structure of the structure, and all the structure of the structure of the information that we're all the structure, and all the structure of the structure, and all the structure of the structure of the structure of the structure of the information,
2022-03-23 09:44:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, it's interesting, and it's interesting for me to be here for me to be here, "well, if we said," well, "well," you'll say, "well," well, "well," you know, "well," well, "you're going to tell you know," well, "you know," you know, "you know," you're going to say, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," you know, "well," you know, "you know," you know, "well," well, "
2022-03-23 09:44:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the big part of the design, and we had to see that we had to use a lot of the world that we had to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to see that if we had to be able to be able to be able to see that we were able to see that if we had to use a little bit of a little bit of a little bit of the same system, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we had to see that we had to be able to be able to be able to be able to see that if we had to be able to be able to be able to be able to be able to be able to be able to see that if
2022-03-23 09:44:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:25 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.786 | nll_loss 5.273 | ppl 38.66 | bleu 11.26 | wps 4382.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.26
2022-03-23 09:44:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:44:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.26) (writing took 1.7708260100334883 seconds)
2022-03-23 09:44:27 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:44:27 | INFO | train | epoch 012 | loss 8.091 | nll_loss 5.946 | ppl 61.66 | wps 42746 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.968 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1156
2022-03-23 09:44:27 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:34 | INFO | train_inner | epoch 013:     21 / 157 loss=8.008, nll_loss=5.827, ppl=56.77, wps=33658.8, ups=1.34, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.028, loss_scale=4, train_wall=30, gb_free=13.9, wall=1163
2022-03-23 09:45:05 | INFO | train_inner | epoch 013:    121 / 157 loss=7.907, nll_loss=5.679, ppl=51.24, wps=80903.7, ups=3.2, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.925, loss_scale=4, train_wall=31, gb_free=13.6, wall=1194
2022-03-23 09:45:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppon in the clinic.
2022-03-23 09:45:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of doha, most of most of most of here.
2022-03-23 09:45:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:28 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to create two new ways.
2022-03-23 09:45:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese food, where they're going to do with ppace.
2022-03-23 09:45:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we're not just going to understand a couple of brain on his head, and what's going on on.
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamase people like the responsibility for the number of animals, and this is a number of animals that has become a priiiiiiicide.
2022-03-23 09:45:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:43 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magic, but it doesn't be able to go into the same energy, and if you don't need your energy, and you need your energy.
2022-03-23 09:45:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we're going to start with this kind of abstract, we can start to start with a big form of the structure, and the structure of the structure of the structure.
2022-03-23 09:45:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to do, and for me, "oh, it's the best time to say," when we said, "the best revolution," and then we've been working with you. "
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be a mother, and part of the work that we're going to be a lot of work on the ground, and that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a network.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:51 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.674 | nll_loss 5.066 | ppl 33.5 | bleu 12.62 | wps 5264.9 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.62
2022-03-23 09:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:45:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.62) (writing took 1.8556771641597152 seconds)
2022-03-23 09:45:53 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:45:53 | INFO | train | epoch 013 | loss 7.89 | nll_loss 5.655 | ppl 50.39 | wps 45840 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.931 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1242
2022-03-23 09:45:54 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:14 | INFO | train_inner | epoch 014:     64 / 157 loss=7.774, nll_loss=5.49, ppl=44.95, wps=36513, ups=1.46, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.878, loss_scale=4, train_wall=30, gb_free=14, wall=1262
2022-03-23 09:46:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppat the clinic clinic.
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:51 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of the doha, the most most most of the most most of here.
2022-03-23 09:46:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orts of the new orts that are going to get two new ways.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese food, where they're going to grow and get it.
2022-03-23 09:46:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrodes on his head, and what all of his mind are on the mind.
2022-03-23 09:47:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamare people like the responsibility of the responsibility, the number of people came to the number of animals, and that has become become become a very powerful.
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:11 | INFO | fairseq.tasks.translation | example hypothesis: first first of all, some of the magic of the lines in the lines, but it doesn't have to move into the alalalalaly, and the energy.
2022-03-23 09:47:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start to start with a traditional traditional animal that are going to start with the whole structure and all the information.
2022-03-23 09:47:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedtedtedwomen, "yes," when we're working with you, and then we've been working with you. "
2022-03-23 09:47:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the most important invention of the invention, and a big design part of the design that we have to see that if we had to use a huge system to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:20 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 7.528 | nll_loss 4.847 | ppl 28.78 | bleu 15.05 | wps 4819.4 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.05
2022-03-23 09:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:47:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:47:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:47:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.05) (writing took 1.7929667038843036 seconds)
2022-03-23 09:47:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:47:22 | INFO | train | epoch 014 | loss 7.673 | nll_loss 5.344 | ppl 40.63 | wps 44492.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.87 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1331
2022-03-23 09:47:22 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:47:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:25 | INFO | train_inner | epoch 015:      7 / 157 loss=7.596, nll_loss=5.233, ppl=37.61, wps=35874.6, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.827, loss_scale=4, train_wall=30, gb_free=13.9, wall=1333
2022-03-23 09:47:56 | INFO | train_inner | epoch 015:    107 / 157 loss=7.494, nll_loss=5.084, ppl=33.91, wps=80665.5, ups=3.21, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.888, loss_scale=4, train_wall=31, gb_free=13.9, wall=1365
2022-03-23 09:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:15 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 09:48:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the car line from doha, most of the most knows here.
2022-03-23 09:48:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that will create two new clients.
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where they're going to do and ppace.
2022-03-23 09:48:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a couple of electrodes on his head and understand what all his thoughts are on the mind.
2022-03-23 09:48:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamating people like the responsibility of the responsibility, the number of animals, and this is a number of the animals that has become a devaiiiiiiiiibia.
2022-03-23 09:48:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of the magic field in the lines, but it doesn't be able to move if you don't need your energy energy, and you need your energy, and you need your energy.
2022-03-23 09:48:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start able to start with a traditional face of the traditional light, and we can start able to start with the shape of the structure of the structure and the structure of the structure of the structure, and the structure of the structure of the structure.
2022-03-23 09:48:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedtedwomen -- that it's the best time, as someone said, "oh, as someone said," the best thing that we've been working with you're working with a long time, "oh," and then we've started working with you're working with you're working with you're working with you're working with you're working with you're working with you're working with a long time, "] [" long time. "
2022-03-23 09:48:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother's mother's mother's mother's mother's mother and a lot of design that we had to use the airplane on our airplane, that we had to use a unique result of the car, and if you had to use it in the ground, it's a network of a drug system, if you had to see that we had to use the power of a drug system, or to use the power of a drug system, if you're going to see that if you're going to see that it's going to see that it's going to see that it's going to be able to see that if you're going to be able to see that if you're going to use the power, or a lot of a lot of a lot of a lot of a lot of the power, or a lot of the power of the power of the power of the power, or a lot of a lot of a lot of the market, or a lot of the market, or a lot of the market, or a lot of the car,
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:52 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 7.262 | nll_loss 4.45 | ppl 21.86 | bleu 16.6 | wps 4475.3 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.6
2022-03-23 09:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:48:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.6) (writing took 1.8097319998778403 seconds)
2022-03-23 09:48:54 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:48:54 | INFO | train | epoch 015 | loss 7.508 | nll_loss 5.102 | ppl 34.35 | wps 43021.4 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.857 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1422
2022-03-23 09:48:54 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:10 | INFO | train_inner | epoch 016:     50 / 157 loss=7.499, nll_loss=5.084, ppl=33.92, wps=34196.4, ups=1.34, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.831, loss_scale=4, train_wall=31, gb_free=14.3, wall=1439
2022-03-23 09:49:41 | INFO | train_inner | epoch 016:    150 / 157 loss=7.264, nll_loss=4.75, ppl=26.91, wps=80217.6, ups=3.25, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.75, loss_scale=4, train_wall=30, gb_free=14.5, wall=1470
2022-03-23 09:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:48 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-23 09:49:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are going to be made.
2022-03-23 09:49:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just using a few electrodes on his head and understand what all its thoughts are on.
2022-03-23 09:50:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the entire life, the number of animals, and that has become a process for conservation.
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but the sulungs don't move if you need your energy, and you need your energy, and so you need your energy.
2022-03-23 09:50:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face that can start able to start able to start able to start with a great form of the face of the shape and the information.
2022-03-23 09:50:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here for tedwomen, "well, it was the best thing that someone said," and then, "the best thing is that we've been working with you," and then we've been working with you are working on this talk. "
2022-03-23 09:50:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention of the invention, and a large design on our airplane is that we had to use a result that we had to solve a very unique result that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, and if you're able to see all of the ground.
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:19 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.171 | nll_loss 4.327 | ppl 20.07 | bleu 15.75 | wps 5180.4 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.6
2022-03-23 09:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:50:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:50:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 15.75) (writing took 0.8171022250317037 seconds)
2022-03-23 09:50:20 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:50:20 | INFO | train | epoch 016 | loss 7.319 | nll_loss 4.829 | ppl 28.42 | wps 45782.2 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.8 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1509
2022-03-23 09:50:21 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:50:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:50 | INFO | train_inner | epoch 017:     93 / 157 loss=7.183, nll_loss=4.634, ppl=24.83, wps=36849.2, ups=1.46, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.798, loss_scale=4, train_wall=31, gb_free=14.9, wall=1538
2022-03-23 09:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:13 | INFO | fairseq.tasks.translation | example hypothesis: we did this pink in the clinic clinic.
2022-03-23 09:51:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha doha, probably the most of you know.
2022-03-23 09:51:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:22 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create the two new picks.
2022-03-23 09:51:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs are, and salt with salsalsales.
2022-03-23 09:51:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electroelectrodes on his head and understand what all its thoughts are on the top of the way.
2022-03-23 09:51:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the lives of the life, the number of animals, and this is a foundation of conservation in namibia.
2022-03-23 09:51:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloodl of magnetic magnetic lines, but the sulungs, but the sulens may not move, if you need your energy, and so you need a few of them.
2022-03-23 09:51:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:44 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information, the reflection of this reflection, we can start with a traditional face, we can start able to start with a traditional face of the face of the interfaces and reform it through the information, and the whole structure of the structure of the structure, which is a structure.
2022-03-23 09:51:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, for me, "in tedth, is that in tedwomen," well, it was the best thing that someone said, "and someone said," when you're working on a table, "the men," and then we've been working with you've been working with this game, "and then we've been working with a game," and then we've been working with you've been working with you've been working with you've been working with a game, "and you've been working with a game," and then we've been working with a game, "and you've been working on the game," and you've been working with a game, "and then you've been working on the game," and then we've been working with the game, "and then you've been working with a
2022-03-23 09:51:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's needed to be the mother of the invention, and a big design of the design work that we're on the airplane, and we've got to solve a result of them, that we had to solve the unique problems that we've had to solve with a level of the ground, and if you're going to be able to be able to be able to be able to use the power of a level of the propheheartartwork in the power, or to see that we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 09:51:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:52 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.008 | nll_loss 4.074 | ppl 16.84 | bleu 18.57 | wps 4270.6 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.57
2022-03-23 09:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:51:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.57) (writing took 1.7411046451888978 seconds)
2022-03-23 09:51:54 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:51:54 | INFO | train | epoch 017 | loss 7.175 | nll_loss 4.62 | ppl 24.6 | wps 42263.7 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.802 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1602
2022-03-23 09:51:54 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:05 | INFO | train_inner | epoch 018:     36 / 157 loss=7.126, nll_loss=4.548, ppl=23.39, wps=33442.4, ups=1.33, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.81, loss_scale=4, train_wall=30, gb_free=14.3, wall=1614
2022-03-23 09:52:36 | INFO | train_inner | epoch 018:    136 / 157 loss=7.014, nll_loss=4.391, ppl=20.98, wps=80052.5, ups=3.22, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.726, loss_scale=4, train_wall=31, gb_free=14.1, wall=1645
2022-03-23 09:52:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:46 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:52:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:52:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs are made with salsalz.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get some electrodes on his head, and understand exactly what all his thoughts are on the road.
2022-03-23 09:53:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, people like the responsibility for the wild, grew up the number of animals, and this is a foundation for natural protection.
2022-03-23 09:53:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic rocks in the interior lines, but the susulant, if you don't move your energy, you need your energy, you need energy, and so that's how to disorder.
2022-03-23 09:53:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face, which can start with the great constructions of the face, and the form of the interfaces, and the information that's all the structure of the structure.
2022-03-23 09:53:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it interesting, for me in tedwomen, is that... "yes, it was the best thing that someone said," and if you're working on a table revolution. "
2022-03-23 09:53:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of the invention, and a big part of the design work on our plane, which is a result that we had to solve a unique way that we had to solve it -- it's all the way that it allows us to do the ground -- all the way that we're using the power of a refrigergergergered, or to see that it's an aircraft.
2022-03-23 09:53:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:20 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.819 | nll_loss 3.795 | ppl 13.88 | bleu 20.83 | wps 4863.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.83
2022-03-23 09:53:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:53:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:53:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.83) (writing took 1.7364757508039474 seconds)
2022-03-23 09:53:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:53:22 | INFO | train | epoch 018 | loss 7.017 | nll_loss 4.394 | ppl 21.03 | wps 44679.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.722 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1690
2022-03-23 09:53:22 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:53:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:47 | INFO | train_inner | epoch 019:     79 / 157 loss=6.926, nll_loss=4.266, ppl=19.24, wps=36081.6, ups=1.41, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.688, loss_scale=4, train_wall=31, gb_free=14, wall=1716
2022-03-23 09:54:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:15 | INFO | fairseq.tasks.translation | example hypothesis: we made these crapsy in the clinic.
2022-03-23 09:54:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:54:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks of dining the two new pigs.
2022-03-23 09:54:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being served with salz and fepure.
2022-03-23 09:54:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making some electrodes on his head and understand exactly what all his thoughts on the top.
2022-03-23 09:54:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, people like the responsibility for the wild, grew up the number of animals again, and this is a foundation of natural protection in namibia.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:38 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bars of magnetic lines in the inside the inner, but the sususuired altitude may not move when they need energy, and so the suick of the altitude of magnetic field.
2022-03-23 09:54:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial face, the big constructions of the face and reform it through the whole structure of this whole structure, the whole structure of portion, and all the portion of these reflection, and we can begin to fold it.
2022-03-23 09:54:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, for me to be here at tedwomen, "oh, if you're talking about, you know, you know, you know, you know, you know, you know, the men in a table and if you're going to do it, we've been talking about to you, we've been saying," you know, "you know, we've been saying," angry, "angry," angry, "angry, we've come up with you're going to support you know," angry, we've come to help you know, "angry," angry, we've come to tell you know, "angry, you know, we've come up with you know, if you know," angry, we've come up with you know, "angry,"
2022-03-23 09:54:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're using the plane, was a result that we had to solve the unique problems that were connected to the ground -- it's all the way to a continuous way of a continent, and it's a big part of the continents of the continent, and it allows us to use a major part of us to use that we're going to use a refrightening, or if we're going to use them to get a business, if you're going to get a refugegegegegegegegegestisticky, it's a refugegeous, it's a refugegeous, it's either, it's a refugeous, or that we're going to make us to be a refugegeous, or if you're going to be a business, it's going to take us to be a business, or that we're going to be a business, it's going to use
2022-03-23 09:54:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:50 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.774 | nll_loss 3.71 | ppl 13.09 | bleu 22.06 | wps 4713.7 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.06
2022-03-23 09:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:54:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:54:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.06) (writing took 1.947792218066752 seconds)
2022-03-23 09:54:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:54:52 | INFO | train | epoch 019 | loss 6.868 | nll_loss 4.185 | ppl 18.19 | wps 44059.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.694 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1780
2022-03-23 09:54:52 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:54:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:59 | INFO | train_inner | epoch 020:     22 / 157 loss=6.799, nll_loss=4.088, ppl=17, wps=34621.9, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.662, loss_scale=4, train_wall=30, gb_free=14.7, wall=1787
2022-03-23 09:55:31 | INFO | train_inner | epoch 020:    122 / 157 loss=6.738, nll_loss=4.001, ppl=16.01, wps=82059.7, ups=3.17, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.613, loss_scale=4, train_wall=31, gb_free=13.6, wall=1819
2022-03-23 09:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:55:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha who probably know most of you here.
2022-03-23 09:55:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:53 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 09:55:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are being served with salz and pure.
2022-03-23 09:55:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring some electrodes on his head and understand what all of his thoughts are on the way.
2022-03-23 09:56:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the maxia, how people had the responsibility for the wild, the number of wild animals, and this is a foundation of conservation in the namibia.
2022-03-23 09:56:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field lines in the inside the inner, but the suick may not be able to move if they need to move, their energy, and so the search of the aligign.
2022-03-23 09:56:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic shape of the information, and through that information, which is the entire portion of the whole portion of these reflection.
2022-03-23 09:56:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it very interesting, for me to be here at tedwomen, is that...... well, in the best, when someone said, "" you know, the men on a table, and when we're working on a table revolution, "'if we've been working on the harbor, we've been working here at tedwomen in tedwomen,"] ["] ["] ["] ["] ["] ["] ["well, we've got a piano, we've been working on the piano," well, we've been working on the piano, we've been working on the piano, "well, we've been working on the piano," well, we've been working on the piano, "well," well, we've been working on the piano, "well," well,
2022-03-23 09:56:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a big part of the design work that we're in our airplane at the plane, we had to solve a result that we had to solve the unique problems that were connected to the ground -- everything from a continent, and a big part of the ground, and a big part of the design of the design work that we can use to see in the aircraft, or a mechanism, if we can use it was an aircraft in the aircraft, or an aircraft, or a mechanism, or a mechanism, it was a mechanism that we're either see that we had to see that we had to see that we had to see that we had to see that we had to see that we had to see that we had to solve the united states, it was a mechanism, it was a mechanism, it was an aircraft that we had to solve the same output it was a mechanism in the same output it was a mechanism, or a
2022-03-23 09:56:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:21 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.658 | nll_loss 3.568 | ppl 11.86 | bleu 24.05 | wps 4497.2 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 24.05
2022-03-23 09:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:56:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 09:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 24.05) (writing took 1.760606145951897 seconds)
2022-03-23 09:56:23 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:56:23 | INFO | train | epoch 020 | loss 6.727 | nll_loss 3.986 | ppl 15.84 | wps 43328.6 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.638 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1871
2022-03-23 09:56:23 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:56:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:43 | INFO | train_inner | epoch 021:     65 / 157 loss=6.641, nll_loss=3.868, ppl=14.6, wps=34126.2, ups=1.37, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.682, loss_scale=4, train_wall=30, gb_free=13.9, wall=1892
2022-03-23 09:57:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create the two new pigs.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz and fat.
2022-03-23 09:57:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring some electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 09:57:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, as people have been taking responsibility for the wild animals, and this is a foundation for the natural protection in namibia.
2022-03-23 09:57:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic fields in the inner, but the superconductor doesn't like if they're moving, because their movements need energy, and so the superconducting disorder.
2022-03-23 09:57:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:42 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that makes the whole structure.
2022-03-23 09:57:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was to be very interesting to you about this. "
2022-03-23 09:57:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, one of the unique problems that were connected to the ground, and we're going to be able to be able to be able to be able to see it in a way that we're going to be able to be able to be able to be able to do it all the variable system.
2022-03-23 09:57:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:46 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.612 | nll_loss 3.548 | ppl 11.69 | bleu 21.54 | wps 5486.5 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.05
2022-03-23 09:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:57:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:57:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:57:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 21 @ 3292 updates, score 21.54) (writing took 0.7872379990294576 seconds)
2022-03-23 09:57:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:57:47 | INFO | train | epoch 021 | loss 6.624 | nll_loss 3.842 | ppl 14.34 | wps 47076.4 | ups 1.87 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.635 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1955
2022-03-23 09:57:47 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:57:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:50 | INFO | train_inner | epoch 022:      8 / 157 loss=6.636, nll_loss=3.858, ppl=14.5, wps=37433.6, ups=1.51, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.634, loss_scale=4, train_wall=30, gb_free=13.9, wall=1958
2022-03-23 09:58:21 | INFO | train_inner | epoch 022:    108 / 157 loss=6.594, nll_loss=3.8, ppl=13.93, wps=79390.8, ups=3.22, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.672, loss_scale=4, train_wall=31, gb_free=13.8, wall=1989
2022-03-23 09:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:58:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 09:58:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and ppeg.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all their thoughts are on the road.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild animals, and that's a foundation for conservation in namibia.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic rocks in the inner, but the superconductor doesn't like if they're moving, because they need their movements.
2022-03-23 09:59:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big concrete of the face and the basic shape of the face.
2022-03-23 09:59:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measured for me here at tedwomen, is that... "well, we've already been supported."
2022-03-23 09:59:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result of refrigergering, or if we had to solve the unique problems that we had to solve the unique problems that were connected to the ground, it was connected to a refrigergergergergergering, or to be able to be able to be able to refrightened by a refrightened, or to be able to refrigergergergergergergergergergergergergergerator.
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:12 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.535 | nll_loss 3.385 | ppl 10.45 | bleu 23.75 | wps 5096.3 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.05
2022-03-23 09:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 09:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 23.75) (writing took 0.7742324415594339 seconds)
2022-03-23 09:59:13 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:59:13 | INFO | train | epoch 022 | loss 6.566 | nll_loss 3.761 | ppl 13.56 | wps 45757.9 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.642 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2041
2022-03-23 09:59:13 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:29 | INFO | train_inner | epoch 023:     51 / 157 loss=6.506, nll_loss=3.675, ppl=12.77, wps=37122.9, ups=1.46, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.532, loss_scale=4, train_wall=31, gb_free=13.8, wall=2058
2022-03-23 10:00:00 | INFO | train_inner | epoch 023:    151 / 157 loss=6.402, nll_loss=3.537, ppl=11.61, wps=81921.3, ups=3.23, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.566, loss_scale=4, train_wall=31, gb_free=13.8, wall=2089
2022-03-23 10:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:00:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are creating new golden locks that create the two new pigs.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and ppeg.
2022-03-23 10:00:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:00:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:25 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of conservation in the wild, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 10:00:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet lines start inside, but the superconductor doesn't like if they're moving, because they need their energy, and the suile disorder.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and the basic constructions of the face, and through the basic form of the fundamental information that's going to reform the whole porter of the information that's all the ports and fold up with the ports.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me here in tedwomen is that we've started to help you -- "well, in fact, we've been working with a long time, when somebody said," turn you to the men on a table and say, "turn you to be here," well, we've started to help you. "& lt; / em & gt; & gt; & gt; & gt; & gt; & gt; & gt; & gt; & gt; / em & gt;"
2022-03-23 10:00:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of design work that we're going to use in our plane to be a result that we had to solve the unique problems that were connected to operate on the ground -- in fact, if we had to solve everything from a continuously, and a large part of the design, and a large part of the design work that we're going to refrightened to refrightened to refrightened to refrightened to refrightening, or a mechanism, if we're using a mechanism, if we're going to be able to be able to be able to be able to be able to be able to make a mechanism, if we're able to make a mechanism, if it's a mechanism, if we're able to be able to make a mechanism, if we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:00:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:42 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.448 | nll_loss 3.291 | ppl 9.79 | bleu 26.25 | wps 4570.1 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.25
2022-03-23 10:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:00:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.25) (writing took 1.7481078547425568 seconds)
2022-03-23 10:00:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:00:43 | INFO | train | epoch 023 | loss 6.436 | nll_loss 3.581 | ppl 11.97 | wps 43609.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.547 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2132
2022-03-23 10:00:44 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:13 | INFO | train_inner | epoch 024:     94 / 157 loss=6.388, nll_loss=3.517, ppl=11.45, wps=34224.4, ups=1.37, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.565, loss_scale=4, train_wall=30, gb_free=13.8, wall=2162
2022-03-23 10:01:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:01:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 10:01:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:44 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden lolocks that will create the two new pigs.
2022-03-23 10:01:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pit.
2022-03-23 10:01:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:01:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people had responsibility for the wild, the number of wild animals grew back, and this is a basis of conservation in namibia.
2022-03-23 10:01:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field lines are caught in the inside, but the superconductor may not be, if they're moving, because their movements need energy, and so the superconducting disorders.
2022-03-23 10:02:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape, and the basic form of information that contains the whole porter structure and a fold.
2022-03-23 10:02:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... yeah, it was the best dinner when someone said, "turn you to a table and tell you,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're at our airplane at the stumber, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable system and refrightening to a liquid system, or that it allows us to use the car, or to see that it's either available to the propelled to the air.
2022-03-23 10:02:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:11 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.347 | nll_loss 3.133 | ppl 8.78 | bleu 27.69 | wps 4751.7 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.69
2022-03-23 10:02:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:02:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:02:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.69) (writing took 1.7845955253578722 seconds)
2022-03-23 10:02:13 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:02:13 | INFO | train | epoch 024 | loss 6.362 | nll_loss 3.481 | ppl 11.16 | wps 44131.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.535 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2221
2022-03-23 10:02:13 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:25 | INFO | train_inner | epoch 025:     37 / 157 loss=6.29, nll_loss=3.381, ppl=10.42, wps=35498.1, ups=1.39, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.496, loss_scale=4, train_wall=30, gb_free=14, wall=2233
2022-03-23 10:02:56 | INFO | train_inner | epoch 025:    137 / 157 loss=6.343, nll_loss=3.456, ppl=10.97, wps=80155.7, ups=3.2, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.569, loss_scale=4, train_wall=31, gb_free=13.9, wall=2265
2022-03-23 10:03:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be two new pigs.
2022-03-23 10:03:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pcase.
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the case like people's responsibility for wildlife, the number of wild animals grew back, and this is a foundation for conservation in namibia.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field lines are caught inside, but the superconductor may not, if you move, your movements, and so the superconducting disorders.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the great constructions of the face and the basic form of information that pulls the whole porter structure and all the fits.
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are highly interesting to me here at tedwomen, is that -- well, when someone said, "turn to the men on your desk and say," if the revolution starts supporting you. "
2022-03-23 10:03:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuously variable system and a liquid system that allows us to get a refrigerator, or if we're going to be able to be able to use a car, if you're either going to get the propelled, if you're going to be able to get a mechanism, if you're going to operate the propelled by a mechanism, or if you're going to get a mechanism, if you're going to get a mechanism, if you're going to be able to operate it, or if you're going to be able to be able to be able to be able to be able to be able to be able to do it, if you're going to operate it, if you're going to be able to be able to be able to be able to be able to be able to get
2022-03-23 10:03:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:39 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.354 | nll_loss 3.147 | ppl 8.86 | bleu 26.53 | wps 4946.7 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.69
2022-03-23 10:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:03:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.53) (writing took 0.8212105371057987 seconds)
2022-03-23 10:03:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:03:40 | INFO | train | epoch 025 | loss 6.309 | nll_loss 3.409 | ppl 10.62 | wps 45436.1 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.542 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2308
2022-03-23 10:03:40 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:05 | INFO | train_inner | epoch 026:     80 / 157 loss=6.231, nll_loss=3.301, ppl=9.86, wps=36758.5, ups=1.44, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.49, loss_scale=4, train_wall=30, gb_free=14, wall=2334
2022-03-23 10:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:04:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:04:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldicks that make two new pigs.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:04:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wild, the number of wild animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 10:04:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:58 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it, if they're moving, because their movements are using energy, and so the superconducting disorders.
2022-03-23 10:04:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the grows concrete of the face, and the basic shape, and refuse it through the theft of information that refuses the whole portion structure and all the fuse.
2022-03-23 10:05:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate, for me here at tedwomen is that... well, when dinner was best summarized when someone said, "turning you to a table and say," if the revolution starts to support you, "the truth is that we've already been supporting you for a long time, we've already been working with a prior for the future of our spellers."
2022-03-23 10:05:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operate in the ground -- everything from a continuous variation and a large part of the refrigeration system that allows us to refrigerator that it allows us to use a refrigerator to become a promoting device that we're going to be able to do with a promotely refueling device that we're going to do, if we're going to be able to do that we're going to be able to be able to do, if we're going to be able to be able to be able to be able to be able to be able to be able to do that, if we're going to be able to do that we're going to do that we're going to do that it, if we're going to be able to be able to be able to be able to be able to be able to do,
2022-03-23 10:05:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:09 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.225 | nll_loss 2.976 | ppl 7.87 | bleu 29.32 | wps 4679.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.32
2022-03-23 10:05:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:05:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:05:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.32) (writing took 1.7506204792298377 seconds)
2022-03-23 10:05:10 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:05:10 | INFO | train | epoch 026 | loss 6.222 | nll_loss 3.291 | ppl 9.79 | wps 43654.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.498 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2399
2022-03-23 10:05:11 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:05:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:18 | INFO | train_inner | epoch 027:     23 / 157 loss=6.177, nll_loss=3.23, ppl=9.38, wps=34241.7, ups=1.37, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.495, loss_scale=4, train_wall=30, gb_free=14.8, wall=2407
2022-03-23 10:05:49 | INFO | train_inner | epoch 027:    123 / 157 loss=6.188, nll_loss=3.245, ppl=9.48, wps=80431, ups=3.21, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.487, loss_scale=4, train_wall=31, gb_free=13.6, wall=2438
2022-03-23 10:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:06:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are becoming new goldicks that create two new pigs.
2022-03-23 10:06:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:06:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:06:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wildanimals grew again. and this is a foundation for conservation in namibia.
2022-03-23 10:06:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can, which gives the big contures of the face and the basic shape, and refuse it through the theft of the information that pulls the whole porter structure and all the fits.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on a table and tell you," when the revolution starts to support you. "the truth is that we've been supporting you for a long time."
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of design work that we're on our airplane of the most proud toes, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system that allows us to use a refrigerator in the aircraft, or if you can see the most unique problems that we're going to be connected to the propelled to a mechanism, or if you can see the propelled to a mechanism, or if you can see the fly in the fly.
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:38 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.188 | nll_loss 2.935 | ppl 7.65 | bleu 29.58 | wps 4749.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.58
2022-03-23 10:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.58) (writing took 1.7403474282473326 seconds)
2022-03-23 10:06:40 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:06:40 | INFO | train | epoch 027 | loss 6.156 | nll_loss 3.202 | ppl 9.21 | wps 44137.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.473 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2488
2022-03-23 10:06:40 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:01 | INFO | train_inner | epoch 028:     66 / 157 loss=6.107, nll_loss=3.135, ppl=8.78, wps=34867, ups=1.4, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.45, loss_scale=4, train_wall=30, gb_free=14.7, wall=2509
2022-03-23 10:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep up in the clinic.
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transcend two new pigs.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pill.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:07:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big contures of the face and repeat the basic shape, and restoring it all the ports and fold.
2022-03-23 10:08:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen, is that... well, when dinner was the best summit, when someone said, "turn you to your men on your table and say," if the revolution starts to support you. "the truth is that we've already been supporting you for this long time."
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:08 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, need to be the mother of invention, and a big part of the design work that we are at our plane at the stumber, was a result that we had to solve the unique problems that were connected to operating the ground -- everything, from a continuous variation and a system that allows us to use a refrigerator in the aircraft, or to be able to use the propelled, if you can't see the trajecism, or when you can see the air, or when you can see the trajectory of a mechanism.
2022-03-23 10:08:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:08 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.151 | nll_loss 2.88 | ppl 7.36 | bleu 30.36 | wps 4768 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.36
2022-03-23 10:08:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:08:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:08:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.36) (writing took 1.8523705690167844 seconds)
2022-03-23 10:08:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:08:09 | INFO | train | epoch 028 | loss 6.111 | nll_loss 3.14 | ppl 8.81 | wps 44093.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.488 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2578
2022-03-23 10:08:10 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:08:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:13 | INFO | train_inner | epoch 029:      9 / 157 loss=6.133, nll_loss=3.171, ppl=9.01, wps=35134.2, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.525, loss_scale=4, train_wall=30, gb_free=13.6, wall=2581
2022-03-23 10:08:44 | INFO | train_inner | epoch 029:    109 / 157 loss=6.058, nll_loss=3.069, ppl=8.39, wps=80390.5, ups=3.2, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.46, loss_scale=4, train_wall=31, gb_free=13.6, wall=2612
2022-03-23 10:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:09:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:09:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcend two new pigs.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepsuitcase.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big contures of facial and the basic form, and refers it through the one information that refers the whole porter structure and all the fits.
2022-03-23 10:09:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it was very interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your men on your table and say," if the revolution starts to support you. "the truth is that we've already supported you for this long time."
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:37 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're at our most proud toes, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a system of liquid, that allows us to use a machine in the aircraft, or if you see a mechanism, that allows us to use it in the air, or if you can use it, or if you can use a mechanism, or if you can use a mechanism, or if you can use it, or if you see the air.
2022-03-23 10:09:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:37 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.134 | nll_loss 2.863 | ppl 7.28 | bleu 30.08 | wps 4746.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.36
2022-03-23 10:09:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:09:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:09:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 29 @ 4548 updates, score 30.08) (writing took 0.7696739197708666 seconds)
2022-03-23 10:09:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:09:38 | INFO | train | epoch 029 | loss 6.053 | nll_loss 3.063 | ppl 8.36 | wps 44670.5 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.465 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2666
2022-03-23 10:09:38 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:55 | INFO | train_inner | epoch 030:     52 / 157 loss=6.034, nll_loss=3.035, ppl=8.2, wps=35451.9, ups=1.41, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.455, loss_scale=4, train_wall=31, gb_free=13.9, wall=2683
2022-03-23 10:10:25 | INFO | train_inner | epoch 030:    152 / 157 loss=5.978, nll_loss=2.963, ppl=7.8, wps=81914.2, ups=3.24, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.398, loss_scale=4, train_wall=31, gb_free=14.7, wall=2714
2022-03-23 10:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:10:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here know.
2022-03-23 10:10:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be two new pigs.
2022-03-23 10:10:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for the wild, the number of wild animals grew again, and that's a basis for conservation in namibia.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inside, but the superconductor may not like it, if they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constraints of the face and the basic form, and restoring it through the one of the one information that pulls the whole portion structure and all the fits.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured for me here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn you to your men to your table and tell them," if the revolution starts to support you for this long time, we've already been supported with silly carel. "
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft to be specific to a specific way to a refrigerator.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:05 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.061 | nll_loss 2.806 | ppl 6.99 | bleu 30.99 | wps 4818.7 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.99
2022-03-23 10:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.99) (writing took 1.8059391779825091 seconds)
2022-03-23 10:11:07 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:11:07 | INFO | train | epoch 030 | loss 5.99 | nll_loss 2.978 | ppl 7.88 | wps 44424.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.418 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2755
2022-03-23 10:11:07 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:37 | INFO | train_inner | epoch 031:     95 / 157 loss=5.962, nll_loss=2.939, ppl=7.67, wps=35658.3, ups=1.4, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.43, loss_scale=4, train_wall=31, gb_free=13.6, wall=2786
2022-03-23 10:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:12:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:12:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be exposed to two new pigs.
2022-03-23 10:12:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:12:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:12:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildanimals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:12:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:12:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and restores the basic shape of that information that refuses the whole porter structure and all the fine.
2022-03-23 10:12:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me here at tedwomen is that... tyes, when dinner was best summarized, when someone said, "turn you to your men to your table and tell them," if the revolution starts to support you. "the truth is that we've already been supported you for a long time."
2022-03-23 10:12:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane at the stumber was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable, and a refrigeration system with a refrigeration, that allows us to use in the aircraft until you can use the very specific problems that we can either be connected to the air, or when you see it, or when you see it, you can see it, or you can see it, you can see it, or you can see it in the same way that you have to operate it, you can see it, or you can see it, you can see it in the same mechanism, or you can see it, you can see it, you can see it, you can see it, you can see it, or you can see it, you can see it, you can see it, you can see it, you can use it
2022-03-23 10:12:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:34 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.052 | nll_loss 2.773 | ppl 6.84 | bleu 31.4 | wps 4785.4 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.4
2022-03-23 10:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.4) (writing took 1.8903748197481036 seconds)
2022-03-23 10:12:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:12:36 | INFO | train | epoch 031 | loss 5.97 | nll_loss 2.951 | ppl 7.73 | wps 44105.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.459 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2845
2022-03-23 10:12:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:49 | INFO | train_inner | epoch 032:     38 / 157 loss=5.933, nll_loss=2.901, ppl=7.47, wps=34545.5, ups=1.39, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.453, loss_scale=4, train_wall=30, gb_free=14.3, wall=2858
2022-03-23 10:13:20 | INFO | train_inner | epoch 032:    138 / 157 loss=5.937, nll_loss=2.908, ppl=7.5, wps=80976.9, ups=3.2, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.465, loss_scale=4, train_wall=31, gb_free=14.4, wall=2889
2022-03-23 10:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:13:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be two new pigs.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:13:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:13:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:13:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional reflection, with a traditional facial can that restores the grows constraints of the face and the basic shape, and refuse it through the one that draws the whole porter structure and all the fits.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to your desk and tell you," 'when the revolution begins, then we support you.' "the truth is that we've already been supported you for this long time.
2022-03-23 10:14:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the most stumble, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation, and a refrigeration system, that allows us to use a machine in the aircraft to go and use, until one of them, until one of them, or one of them, or one of them, which is either, in particular, to be propelled, until you can see the land, or when you can see the same mechanism, you can see it, you can see it, and you can see it, from a continuous, you can see it's all from a continuously variable, from a continuously variable, you can see it, and you can see it, you can see it, from a continuously variable, from a continuously variable, and you can see it, and you can see it, and you
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:05 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.031 | nll_loss 2.735 | ppl 6.66 | bleu 31.62 | wps 4696.6 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.62
2022-03-23 10:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 32 @ 5019 updates, score 31.62) (writing took 1.8499030889943242 seconds)
2022-03-23 10:14:06 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:14:06 | INFO | train | epoch 032 | loss 5.92 | nll_loss 2.884 | ppl 7.38 | wps 43755.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.439 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2935
2022-03-23 10:14:07 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:32 | INFO | train_inner | epoch 033:     81 / 157 loss=5.846, nll_loss=2.785, ppl=6.89, wps=34877.3, ups=1.39, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.41, loss_scale=4, train_wall=30, gb_free=14, wall=2961
2022-03-23 10:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep sheets in the clinic.
2022-03-23 10:15:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to create two new pigs.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildanimals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorders.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic shape, and recongect it through the one of the one information that refers the whole porter structure and all the fine folds.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that has been highly interesting and appropriate for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you, "the truth is that we've already been supporting you for a long time."
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigeration system, that allows us to use a machine in the aircraft to go to a special way, to the ground, or if you're going to be able to do it, or if you're going to operate it, or if you're going to run the trajectory, or if you're going to be able, or if you're going to do it, or if you're going to run a mechanism.
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:35 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.989 | nll_loss 2.692 | ppl 6.46 | bleu 32.46 | wps 4680.8 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.46
2022-03-23 10:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.46) (writing took 1.8790823468007147 seconds)
2022-03-23 10:15:37 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:15:37 | INFO | train | epoch 033 | loss 5.877 | nll_loss 2.826 | ppl 7.09 | wps 43827.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.417 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3025
2022-03-23 10:15:37 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:45 | INFO | train_inner | epoch 034:     24 / 157 loss=5.903, nll_loss=2.861, ppl=7.26, wps=34655.6, ups=1.38, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.43, loss_scale=4, train_wall=31, gb_free=13.8, wall=3033
2022-03-23 10:16:16 | INFO | train_inner | epoch 034:    124 / 157 loss=5.831, nll_loss=2.763, ppl=6.79, wps=80818, ups=3.21, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.429, loss_scale=4, train_wall=31, gb_free=13.7, wall=3064
2022-03-23 10:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that will be two new pigs overwrite.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese chinese food, where frog legs are served with salz and peaks.
2022-03-23 10:16:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:16:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back again, and this is a basis for conservation in namibia.
2022-03-23 10:16:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements are using energy, so the superconductor.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and restores it through the one of the information that refuses the whole porter structure and all the fine folds.
2022-03-23 10:16:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when dinner was stripped, it was best summarized when someone said, "turn you to the men to your table and tell you," if the revolution begins, then we support you. "the truth, is that we've already been supporting you for a long time."
2022-03-23 10:17:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of the design work that we're most proud of at our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system that allows us to be able to use on the ground, to be able to be able to be able to be able to use a progressive, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate on a progressive, if you're either be able to operate on the exposed to be able to be able to be able to be able to be able to be able to operate on the ground, or if you can be able to operate on the exposure, if you can't be able to be able to be able to be able to be able to be able to be able to be able to be able to operate
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:06 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.992 | nll_loss 2.703 | ppl 6.51 | bleu 32.47 | wps 4574.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.47
2022-03-23 10:17:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:17:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:17:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:17:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.47) (writing took 1.8535928870551288 seconds)
2022-03-23 10:17:07 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:17:07 | INFO | train | epoch 034 | loss 5.848 | nll_loss 2.787 | ppl 6.9 | wps 43471.4 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.436 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3116
2022-03-23 10:17:08 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:29 | INFO | train_inner | epoch 035:     67 / 157 loss=5.858, nll_loss=2.799, ppl=6.96, wps=34536.9, ups=1.38, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.437, loss_scale=4, train_wall=30, gb_free=14.7, wall=3137
2022-03-23 10:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know here.
2022-03-23 10:18:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:18:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:18:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:18:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that has become a basis for conservation in namibia.
2022-03-23 10:18:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form of information that refers all the porter structure and all the fine folds.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate to be here for me here at tedwomen is that... well, when dinner was the best summarized, when someone said, "turn you to your table and tell them," if the revolution starts to support you. '"the truth, women, is that we've already been supporting you for a long time."
2022-03-23 10:18:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're the most proud of our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a cooling system of liquid that allows us to use an aircraft on the aircraft to a specially appropriate traffic, or when you can see the propelled, or if you can see the propelled the soil, all the way down the way down to a mechanism.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:35 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.961 | nll_loss 2.681 | ppl 6.41 | bleu 32.38 | wps 4724.5 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.47
2022-03-23 10:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:18:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.38) (writing took 0.8475170382298529 seconds)
2022-03-23 10:18:36 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:18:36 | INFO | train | epoch 035 | loss 5.812 | nll_loss 2.737 | ppl 6.67 | wps 44633.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.405 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3204
2022-03-23 10:18:36 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:39 | INFO | train_inner | epoch 036:     10 / 157 loss=5.794, nll_loss=2.715, ppl=6.56, wps=35211.9, ups=1.41, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.391, loss_scale=4, train_wall=30, gb_free=14.7, wall=3208
2022-03-23 10:19:11 | INFO | train_inner | epoch 036:    110 / 157 loss=5.768, nll_loss=2.678, ppl=6.4, wps=80668.4, ups=3.19, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.39, loss_scale=4, train_wall=31, gb_free=14.7, wall=3239
2022-03-23 10:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will generate two new pigs.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements are using energy, and so the superconductive disorder.
2022-03-23 10:19:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and restores the basic shape, and refers it through the thiefs of information that refers the entire porter structure and all the fine.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins, then we support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on our plane at the stumber, which was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation and a refrigerator system, that allows us to use a steady aircraft in the aircraft, until the most specific transportation, which is either the unique problems that we had to make it happen to be done, or if you're going to make it happen to be able to make it happen to be able to be able to be able to make it happen to be able to be able to be able to make it happen to be able to be able to be able to make it happen to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:04 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.951 | nll_loss 2.655 | ppl 6.3 | bleu 32.83 | wps 4630.1 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.83
2022-03-23 10:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:20:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.83) (writing took 1.8268977138213813 seconds)
2022-03-23 10:20:06 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:20:06 | INFO | train | epoch 036 | loss 5.779 | nll_loss 2.693 | ppl 6.47 | wps 43748.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.405 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3295
2022-03-23 10:20:06 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:23 | INFO | train_inner | epoch 037:     53 / 157 loss=5.745, nll_loss=2.649, ppl=6.27, wps=35164.8, ups=1.38, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.42, loss_scale=4, train_wall=30, gb_free=14.7, wall=3312
2022-03-23 10:20:54 | INFO | train_inner | epoch 037:    153 / 157 loss=5.806, nll_loss=2.728, ppl=6.62, wps=79989.1, ups=3.22, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.416, loss_scale=4, train_wall=31, gb_free=13.5, wall=3343
2022-03-23 10:20:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:20:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you here know.
2022-03-23 10:21:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks beds that will overwrite two new pigs.
2022-03-23 10:21:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:21:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:21:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:21:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:21:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional face that restores the big constraints of the face and restoring it through the most information that refers the whole porter structure and all the fine folds.
2022-03-23 10:21:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn you to the men on your table and say to you," if the revolution starts to support you, "the truth, we support you."
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation, and a cooling system of refrigeration, that it allows us to use a aircraft on the top of our airplane to the stumber traffic to a very stumber traffic to a specially appropriate car car car car vehicle, or a mechanism, if you can see that's going to run in the car storm.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:35 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.925 | nll_loss 2.62 | ppl 6.15 | bleu 33.14 | wps 4633 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.14
2022-03-23 10:21:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:21:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:21:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:21:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.14) (writing took 2.5153242461383343 seconds)
2022-03-23 10:21:37 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:21:37 | INFO | train | epoch 037 | loss 5.762 | nll_loss 2.67 | ppl 6.37 | wps 43322.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.41 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3386
2022-03-23 10:21:38 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:21:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:08 | INFO | train_inner | epoch 038:     96 / 157 loss=5.738, nll_loss=2.637, ppl=6.22, wps=33658.4, ups=1.37, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.4, loss_scale=4, train_wall=30, gb_free=14.3, wall=3416
2022-03-23 10:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:22:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:22:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:22:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:22:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 10:22:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconducting disorder.
2022-03-23 10:22:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial constraints that restore the size of the face and restore it through the one of the information that refers the whole porter structure and all the fine.
2022-03-23 10:22:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when we were striving dinner, it was best summarized when someone said, "turn you to your table and tell you," if the revolution starts to support you, "the truth of women, love is that we've already supported you for this long time." in fact, when we've already started with rachel: "with silly," in the future, "
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're the most proud of our aircraft was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a cooling system of liquid that allows us to use an aircraft in our aircraft to an aircraft, to a very stumber traffic, to a specially passing in particular passing the ground, or when you can see the propelled by which is either drilling the propelled by which is the earth to the earth to the power of an aircraft that will see the earth to the earth as a mechanical powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered powered by a mechanism, or a mechanism, to the earth to the earth, to the earth,
2022-03-23 10:23:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:05 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.921 | nll_loss 2.608 | ppl 6.1 | bleu 32.6 | wps 4817.2 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.14
2022-03-23 10:23:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:23:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:23:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.6) (writing took 0.8252741717733443 seconds)
2022-03-23 10:23:05 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:23:05 | INFO | train | epoch 038 | loss 5.738 | nll_loss 2.637 | ppl 6.22 | wps 44811.3 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.41 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3474
2022-03-23 10:23:06 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:18 | INFO | train_inner | epoch 039:     39 / 157 loss=5.683, nll_loss=2.565, ppl=5.92, wps=36863, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.39, loss_scale=4, train_wall=31, gb_free=13.6, wall=3487
2022-03-23 10:23:49 | INFO | train_inner | epoch 039:    139 / 157 loss=5.741, nll_loss=2.642, ppl=6.24, wps=80017.2, ups=3.22, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.435, loss_scale=4, train_wall=31, gb_free=14.7, wall=3518
2022-03-23 10:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:59 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:23:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you know here.
2022-03-23 10:24:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:24:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:24:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that has become a basis for conservation in namibia.
2022-03-23 10:24:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy, and so the superconductive disorder disorder.
2022-03-23 10:24:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial can that restores the big constraints of the face and restoring it through the very one that refuses the whole porter structure and all the fine.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be here for me here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, we support you. "]" the truth, women, love you, is that we've already supported you for a long time. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-23 10:24:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're the most proud of on our airplane was a result of solving the unique problems that were connected to operating it on the ground, all from a continuously variable system, and a cooling system of refrigeration, that it allows us to use an aircraft in the stop and the traffic to a special passenger, to a trajectory, or if you can see the operational, or if you look at the ground, in the same way that we can see the security system that we can see in a continuous, and see that's going to be operational system, and that's going to be operated in a mechanical system of a continuously variable in the safety system with a continuously variable system with a continuously variable, that allows us to see it, that allows us to use it, that allows us to use it, to use it, to use it, to use it
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:34 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.9 | nll_loss 2.595 | ppl 6.04 | bleu 33.46 | wps 4660.6 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.46
2022-03-23 10:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:24:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.46) (writing took 1.8368959710933268 seconds)
2022-03-23 10:24:36 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:24:36 | INFO | train | epoch 039 | loss 5.71 | nll_loss 2.599 | ppl 6.06 | wps 43598 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.405 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3565
2022-03-23 10:24:36 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:02 | INFO | train_inner | epoch 040:     82 / 157 loss=5.685, nll_loss=2.564, ppl=5.91, wps=34066.1, ups=1.37, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.361, loss_scale=4, train_wall=30, gb_free=14.1, wall=3591
2022-03-23 10:25:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:25:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you here know.
2022-03-23 10:25:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs transcend.
2022-03-23 10:25:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:25:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of your thoughts are on the track.
2022-03-23 10:25:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people adopted responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:25:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements are using energy, so the superconductive disorder.
2022-03-23 10:25:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face can that restores the big constraints of the face and the basic shape, and then deals it through the one of the information that refers the whole por-structure and all the folds.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, when i was strictly dinner, it was the best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, then we support you, 'the truth, is that we've already been supporting you for a long time. at rachel with silspring's future, and then, "
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously variable and a cooling system that allows us to use on the stop traffic to a special passenger, or if you run the propeller, or if you can see the propelled the propeller, or if you can see the propelled the aircraft, or if you can see the propelled the propeller, the aircraft, the aircraft system, and you can see the propeller in the same way, the same way, the aircraft system, and you can see the aircraft system, it allows us to use it allows us to use it allows us to use it, to use it to use it, either the aircraft, or if you can use it in a very much more specifically drift.
2022-03-23 10:26:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:04 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.917 | nll_loss 2.596 | ppl 6.05 | bleu 33.24 | wps 4794.9 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.46
2022-03-23 10:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:26:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.24) (writing took 0.7968814452178776 seconds)
2022-03-23 10:26:05 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:26:05 | INFO | train | epoch 040 | loss 5.677 | nll_loss 2.555 | ppl 5.88 | wps 44548.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.375 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3653
2022-03-23 10:26:05 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:26:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:13 | INFO | train_inner | epoch 041:     25 / 157 loss=5.692, nll_loss=2.576, ppl=5.96, wps=36015.7, ups=1.41, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.393, loss_scale=4, train_wall=30, gb_free=14.4, wall=3661
2022-03-23 10:26:44 | INFO | train_inner | epoch 041:    125 / 157 loss=5.665, nll_loss=2.538, ppl=5.81, wps=80449.4, ups=3.22, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.413, loss_scale=4, train_wall=31, gb_free=13.8, wall=3692
2022-03-23 10:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:57 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:26:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:27:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:27:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information coming from this mirror reflection, we can start with a traditional facial session that restores the big constraints of the face and the basic form, and then restore it through the one of the one information that refers the whole porter structure and all the folds.
2022-03-23 10:27:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when strictly dinner, it was the best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, then we support you. '"the truth, women is that we've already been supporting you for a long time. at rachel carel's" silspring, "and then"
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:32 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, need to still be the mother of invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously varied, and a cooling system of refrigeration, that allows us to use an aircraft on the stop and traffic until a special passenger, or a propeller device, to either run the propelled, or when you fly to the floor, to the propelled, to the safety system, until you can see the deployment of a mechanism, until you can see the car storm, and if you can see the bottom, or if you fly it's going to the earth, you can see a mechanism, you fly, you can see the safety system that's going to the bottom, or if you can see a mechanism, you can see it's going to the earth, you can see the safety system, you can't do it
2022-03-23 10:27:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:32 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.865 | nll_loss 2.557 | ppl 5.88 | bleu 33.83 | wps 4772.3 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.83
2022-03-23 10:27:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:27:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.83) (writing took 1.9265883401967585 seconds)
2022-03-23 10:27:34 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:27:34 | INFO | train | epoch 041 | loss 5.666 | nll_loss 2.539 | ppl 5.81 | wps 44032 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.398 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3743
2022-03-23 10:27:35 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:56 | INFO | train_inner | epoch 042:     68 / 157 loss=5.635, nll_loss=2.498, ppl=5.65, wps=34872.8, ups=1.39, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.375, loss_scale=4, train_wall=30, gb_free=22.4, wall=3764
2022-03-23 10:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:27 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:28:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:28:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will transcend two new pigs.
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:28:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back. and this has become a basis for conservation in namibia.
2022-03-23 10:28:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:28:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial sphere that restores the grows of the face and the basic shape, and then deploy it through the information that refers the whole porter structure and all the fine folds.
2022-03-23 10:28:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when strictly dinner, it got the best summarized when someone said, "turn to the men on your table and say to them," 'when the revolution begins, then we support you.' "the truth, women, love is that we've already been supporting you about this for a long time. at rachel carson's" with silent theaters, "and then" our gains "and our metroops" our metroops "to the future to downstream."
2022-03-23 10:28:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a cooling system of refrigeration that allows us to use an aircraft on stop and traffic to a special passenger, to either drive the vehicle, or when you fly, or when you see the propelled the soil, to the propelled, to the security facility, to the deployment of a mechanism, to see the air, to the air, to the deployment, to the air.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:02 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.898 | nll_loss 2.579 | ppl 5.97 | bleu 33.23 | wps 4772.7 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.83
2022-03-23 10:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:29:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.23) (writing took 0.8794260271824896 seconds)
2022-03-23 10:29:02 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:29:02 | INFO | train | epoch 042 | loss 5.636 | nll_loss 2.5 | ppl 5.66 | wps 44808.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.381 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3831
2022-03-23 10:29:03 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:06 | INFO | train_inner | epoch 043:     11 / 157 loss=5.621, nll_loss=2.481, ppl=5.58, wps=36197.4, ups=1.42, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.372, loss_scale=4, train_wall=31, gb_free=13.9, wall=3835
2022-03-23 10:29:37 | INFO | train_inner | epoch 043:    111 / 157 loss=5.659, nll_loss=2.528, ppl=5.77, wps=80447, ups=3.23, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.419, loss_scale=4, train_wall=31, gb_free=13.8, wall=3866
2022-03-23 10:29:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:55 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:29:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most people know here.
2022-03-23 10:30:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dines that are going to cross two new pigs.
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:07 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:30:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this mirror reflection, we can start with a traditional facial session that gives the big constrations of the face and restores it through the basic information that refers all the porn structure and all the fone folds.
2022-03-23 10:30:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it was the best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, we support you. '"' the truth, women is that we've been supporting you for a long time.
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example hypothesis: thankfully, the mother of the invention, and a large part of the design work that we're on our airplane is a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variables, and a cooling system of refrigeration, that it allows us to use an aircraft on stop traffic to a special passenger traffic, or a propeller that would be connected to the soil when you see the propelled, or when you see the trajectory of a mechanism going to the bottom of a continuously variable, until you see the air system that's going to become a continuously variable, until you get rid of a continuously variables.
2022-03-23 10:30:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:30 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.874 | nll_loss 2.55 | ppl 5.86 | bleu 33.85 | wps 4663.5 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.85
2022-03-23 10:30:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:30:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:30:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt
2022-03-23 10:30:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.85) (writing took 1.832463386002928 seconds)
2022-03-23 10:30:32 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:30:32 | INFO | train | epoch 043 | loss 5.624 | nll_loss 2.483 | ppl 5.59 | wps 43984.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.396 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3921
2022-03-23 10:30:33 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:30:50 | INFO | train_inner | epoch 044:     54 / 157 loss=5.589, nll_loss=2.436, ppl=5.41, wps=34482.6, ups=1.39, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.392, loss_scale=4, train_wall=30, gb_free=14.2, wall=3938
2022-03-23 10:31:20 | INFO | train_inner | epoch 044:    154 / 157 loss=5.602, nll_loss=2.454, ppl=5.48, wps=83202.8, ups=3.26, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.368, loss_scale=4, train_wall=30, gb_free=13.8, wall=3969
2022-03-23 10:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:25 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:31:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:31:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilock dinners that are going to write two new pigs.
2022-03-23 10:31:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:31:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the stove of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:31:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:31:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:31:53 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constrations of the face and returns it through the basic information that refers the whole porn structure and all the fine folds.
2022-03-23 10:31:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:31:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when i was striking dinner, it was the best summarized when someone said, "turn you to the men on your table and say," when the revolution begins, we support you. '"the truth, women are supporting you for a long time.
2022-03-23 10:31:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the invention, and a large part of the design work that we're on our airplane the stumble was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously varied, and a refrigerator system, that allows us to use an aircraft on the stand traffic to a special passage, or a propeller that would either drift the propeller, if you can see it, or when you can see it all the propelled it, you can see it all the way down to the way down to the ground, you can see it, all the propelled, all the way down to the way down to the floor, all the propellant, all the propellant, all the way down to the way down to the air conditioning device that you can see it.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:00 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.874 | nll_loss 2.545 | ppl 5.84 | bleu 33.71 | wps 4735.5 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.85
2022-03-23 10:32:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:32:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.71) (writing took 0.8696650359779596 seconds)
2022-03-23 10:32:01 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:32:01 | INFO | train | epoch 044 | loss 5.602 | nll_loss 2.453 | ppl 5.48 | wps 44762.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.387 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4009
2022-03-23 10:32:01 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:31 | INFO | train_inner | epoch 045:     97 / 157 loss=5.572, nll_loss=2.412, ppl=5.32, wps=36038, ups=1.41, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.383, loss_scale=4, train_wall=31, gb_free=14.6, wall=4040
2022-03-23 10:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:32:53 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:32:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:32:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most people here know.
2022-03-23 10:32:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will generate two new pigs.
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:33:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:33:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are captured inside, but the superconductor doesn't like moving because their movements are using energy, so the superconducting disorder is disrupting.
2022-03-23 10:33:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constrations of the face and the basic form, and then deploy it through the one of the information that refers the whole por-structure and all the fine folds.
2022-03-23 10:33:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it extremely interesting and appropriate for me here at tedwomen is that... well, when we were striking dinner, it was the best summarized when someone said, "turn you to the men on your table and say to you," if the revolution begins, we support you. "'the truth, women, love is that we've already supported you for a long time. starting with rachel carry theo, and then we're going to download our sandstone beaches."
2022-03-23 10:33:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of the invention, and a large part of the design system that we're on our airplane the proud toe was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation, and a refrigeration system with fluid, that allows us to use an aircraft in the stop traffic to a special passage, or when you see the propelled for the ground.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:27 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.861 | nll_loss 2.549 | ppl 5.85 | bleu 33.84 | wps 4808.9 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.85
2022-03-23 10:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.84) (writing took 0.8558352491818368 seconds)
2022-03-23 10:33:28 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:33:28 | INFO | train | epoch 045 | loss 5.601 | nll_loss 2.452 | ppl 5.47 | wps 44985.3 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.43 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4097
2022-03-23 10:33:29 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:33:41 | INFO | train_inner | epoch 046:     40 / 157 loss=5.624, nll_loss=2.482, ppl=5.59, wps=34927.6, ups=1.44, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.456, loss_scale=4, train_wall=30, gb_free=14.3, wall=4109
2022-03-23 10:34:12 | INFO | train_inner | epoch 046:    140 / 157 loss=5.563, nll_loss=2.401, ppl=5.28, wps=81377.3, ups=3.2, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.37, loss_scale=4, train_wall=31, gb_free=13.6, wall=4141
2022-03-23 10:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:21 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:34:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:34:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:34:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dines that will transcend two new pigs.
2022-03-23 10:34:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:34:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:34:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back, and that has become a basis for conservation in namibia.
2022-03-23 10:34:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:34:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:34:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:34:49 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constraints of the face and returns it through the one that refers all the porter structure and all the fine wrinkles.
2022-03-23 10:34:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, at strict dinner, it was best summarized when someone said, "turn you to the men on your table and say to them," if the revolution begins, then we support you. '"the truth, women, love you for a long time.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:34:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to doing it on the ground -- everything, from a continuously varied, and a refrigeration system with liquid that allows us to use an aircraft on the stop and traffic to a special passage that either drives the propelled or when you fly to the ground, all the mechanism.
2022-03-23 10:34:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:34:54 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.861 | nll_loss 2.533 | ppl 5.79 | bleu 33.75 | wps 4943.3 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.85
2022-03-23 10:34:54 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt
2022-03-23 10:34:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.25_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.75) (writing took 0.8270445330999792 seconds)
2022-03-23 10:34:55 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:34:55 | INFO | train | epoch 046 | loss 5.566 | nll_loss 2.404 | ppl 5.29 | wps 45503.2 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.375 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4184
2022-03-23 10:34:55 | INFO | fairseq_cli.train | done training in 4183.2 seconds
